title,abstract,keywords,all,subject
,,,  ,
" 1-Adamantylamidoxime   1-[1-(4-Chlorobenzenesulfonyl)-1H-indole-3-yl]-3-[4-(pyridin-2-yl)piperazin-1-yl]propan-1-one   Synthesis of 10-Methoxydiamantan-3-One   (Z)-4-[2-(3,4-Difluorophenyl)hydrazono]-3-methyl-1H-pyrazol-5(4H)-one "," Abstract
The title compound was prepared by the nucleophilic addition of hydroxylamine over 1-cyanoadamantane. The poor reactivity of the nitrile substrate, due to its scarcely electrophilic nature, prompted the need to employ several activating conditions. Energy supply via conventional heating, ultrasound, and microwave irradiation did not lead to product formation. Therefore, Lewis acid catalysis was attempted. Initial tests with ZnCl2 led to product formation in poor yields. Conversely, the use of AlCl3 led to the formation of the desired amidoxime in the moderate yield, which was further increased to an excellent yield by performing the reaction in a more concentrated medium. The structural identity of the title compound was proven by spectroscopic methods (IR, NMR). This compound was later employed as a starting material for the synthesis of 3,5-disubstituted 1,2,4-oxadiazole derivatives as potential 11β-HSD1 inhibitors. View Full-Text   Abstract
The title compound was prepared by an aza-Michael addition reaction between 1-[1-(4-chlorobenzenesulfonyl)-1H-indole-3-yl]prop-2-en-1-one and 2-piridylpiperazine catalyzed by SiO2. The structural identity of the title compound was proven by elemental analysis and spectroscopic methods (IR, NMR). The compound was assayed in a binding assay at the 5-HT6 receptor, showing poor affinity. View Full-Text   Abstract
The synthesis of diamondoids particles up to 1–5 nm, in order to detect the nanostructure in the construction of nanoelectronic devices, for which the present of quantum limitation effects are theoretically presaged, is at the present time problematic. Diamondoids have many important physical characteristics, including rigidity, lipophilicity, low strain energy, etc. Diamantane and their derivatives are also interesting for the study of nanoparticles. The present study deals with the development of the new synthetic route and diamantine-containing precursor for McMurry coupling reactions. View Full-Text   Abstract
The title compound (Z)-4-[2-(3,4-difluorophenyl)hydrazono]-3-methyl-1H-pyrazol-5(4H)-one 4 was synthesized by the reaction of ethyl 2-[2-(3,4-difluorophenyl)hydrazono]-3-oxobutanoate 3 with hydrazine hydrate. The diazotization of 3,4-difluoroaniline, followed by the treatment with ethyl acetoacetate, afforded intermediate 3. The synthesized compound 4 was characterized by FTIR, 1H-NMR, 13C-NMR and LCMS, and it showed synergistic anti-inflammatory, antiproliferative and antibacterial activities. View Full-Text "," catalysis,Lewis acid,aliphatic amidoximes,adamantane,11β-HSD1,1,2,4-oxadiazole   aza-Michael addition,indole,serotonin,5-HT6,arylpiperazine,arylsulfonylindole   McMurry coupling reaction,diamondoids,nanoelectronics,diamantane   pyrazol-5(4H)-one,hydrazine hydrate,anti-inflammatory,antiproliferative,antibacterial activity "," 1-Adamantylamidoxime   1-[1-(4-Chlorobenzenesulfonyl)-1H-indole-3-yl]-3-[4-(pyridin-2-yl)piperazin-1-yl]propan-1-one   Synthesis of 10-Methoxydiamantan-3-One   (Z)-4-[2-(3,4-Difluorophenyl)hydrazono]-3-methyl-1H-pyrazol-5(4H)-one   Abstract
The title compound was prepared by the nucleophilic addition of hydroxylamine over 1-cyanoadamantane. The poor reactivity of the nitrile substrate, due to its scarcely electrophilic nature, prompted the need to employ several activating conditions. Energy supply via conventional heating, ultrasound, and microwave irradiation did not lead to product formation. Therefore, Lewis acid catalysis was attempted. Initial tests with ZnCl2 led to product formation in poor yields. Conversely, the use of AlCl3 led to the formation of the desired amidoxime in the moderate yield, which was further increased to an excellent yield by performing the reaction in a more concentrated medium. The structural identity of the title compound was proven by spectroscopic methods (IR, NMR). This compound was later employed as a starting material for the synthesis of 3,5-disubstituted 1,2,4-oxadiazole derivatives as potential 11β-HSD1 inhibitors. View Full-Text   Abstract
The title compound was prepared by an aza-Michael addition reaction between 1-[1-(4-chlorobenzenesulfonyl)-1H-indole-3-yl]prop-2-en-1-one and 2-piridylpiperazine catalyzed by SiO2. The structural identity of the title compound was proven by elemental analysis and spectroscopic methods (IR, NMR). The compound was assayed in a binding assay at the 5-HT6 receptor, showing poor affinity. View Full-Text   Abstract
The synthesis of diamondoids particles up to 1–5 nm, in order to detect the nanostructure in the construction of nanoelectronic devices, for which the present of quantum limitation effects are theoretically presaged, is at the present time problematic. Diamondoids have many important physical characteristics, including rigidity, lipophilicity, low strain energy, etc. Diamantane and their derivatives are also interesting for the study of nanoparticles. The present study deals with the development of the new synthetic route and diamantine-containing precursor for McMurry coupling reactions. View Full-Text   Abstract
The title compound (Z)-4-[2-(3,4-difluorophenyl)hydrazono]-3-methyl-1H-pyrazol-5(4H)-one 4 was synthesized by the reaction of ethyl 2-[2-(3,4-difluorophenyl)hydrazono]-3-oxobutanoate 3 with hydrazine hydrate. The diazotization of 3,4-difluoroaniline, followed by the treatment with ethyl acetoacetate, afforded intermediate 3. The synthesized compound 4 was characterized by FTIR, 1H-NMR, 13C-NMR and LCMS, and it showed synergistic anti-inflammatory, antiproliferative and antibacterial activities. View Full-Text   catalysis,Lewis acid,aliphatic amidoximes,adamantane,11β-HSD1,1,2,4-oxadiazole   aza-Michael addition,indole,serotonin,5-HT6,arylpiperazine,arylsulfonylindole   McMurry coupling reaction,diamondoids,nanoelectronics,diamantane   pyrazol-5(4H)-one,hydrazine hydrate,anti-inflammatory,antiproliferative,antibacterial activity ", Molbank 
" On the Phylogenetic Position of the Weevil Tribe Acentrusini Alonso-Zarazaga, 2005 (Coleoptera: Curculionidae: Curculioninae)   Unveiling the History of a Peculiar Weevil-Plant Interaction in South America: A Phylogeographic Approach to Hydnorobius hydnorae (Belidae) Associated with Prosopanche americana (Aristolochiaceae)   Anthropogenic Impacts on Coral Reef Harpacticoid Copepods   Patterns of Long-Term Population Trends of Three Lupine-Feeding Butterflies in Wisconsin "," Abstract
Based on intrinsic morphological and extrinsic bionomic characters, the systematic position of the weevil tribe Acentrusini Alonso-Zarazaga, 2005 (Coleoptera: Curculionidae: Curculioninae) was determined. Maximum parsimony and Bayesian inference as well as nonmetric multi-dimensional scaling were used to analyze 34 morphological characters of adults, complemented by four host plant characters associated with particular weevil tribes. Sixteen species belonging to two subfamilies (Brachycerinae, Curculionidae) and seven tribes (Acentrusini, Anthonomini, Ellescini, Erirhinini, Smicronychini, Storeini, Styphlini) of the family Curculionidae and one outgroup species (Attelabidae) were studied. Phylogenetic and multi-dimensional analyses revealed the tribe Smicronychini as most closely related to Acentrusini. Of the tribes of Curculioninae studied, Styphlini, Anthonomini and Ellescini showed a certain degree of phylogenetic relation to Acentrusini, whereas Storeini were found to be least related. View Full-Text   Abstract
Interspecific interactions take place over both long and short time-frames. However, it is not completely understood if the interacting-partners persisted, migrated, or expanded in concert with Quaternary climate and landscape changes. We aim to understand whether there is concordance between the specialist weevil Hydnorobius hydnorae and its parasitic host plant, Prosopanche americana in space and time. We aim to determine whether Prosopanche had already established its range, and Hydnorobius later actively colonized this rare resource; or, if both host plant and herbivore expanded their range concomitantly. We performed population genetic, phylogeographic and Bayesian diffusion analysis of Cytochrome B sequences from 18 weevil localities and used paleodistribution models to infer host plant dispersal patterns. We found strong but uneven population structure across the range for H. hydnorae with weak signals of population growth, and haplotype network structure and SAMOVA groupings closely following biogeographic region boundaries. The ancestral areas for both Hydnorobius and Prosopanche are reconstructed in San Luis province within the Chaco Biogeographic province. Our results indicate a long trajectory of host-tracking through space and time, where the weevil has expanded its geographic range following its host plant, without significant demographic growth. We explore the past environmental changes that could underlie the boundaries between locality groups. We suggest that geographic dispersal without population growth in Hydnorobius could be enabled by the scarcity of the host plant itself, allowing for slow expansion rates and stable populations, with no need for significant demographic growth pulses to support range expansion. View Full-Text   Abstract
The number of studies demonstrating the susceptibility of benthic reef communities to anthropogenic impacts is growing. However, for some of the components of reef fauna, such as meiobenthic harpacticoid copepods, information is still lacking. Here, different diversity and taxonomic distinctness indexes and multivariate analyses were used to test whether the assemblage of harpacticoid copepods colonizing Artificial Substrate Units (ASUs) is an appropriate tool for the identification of reefs subjected to different levels of anthropogenic pressure. Furthermore, we also evaluate if diffused, persistent, anthropogenic impacts generate the homogenization and simplification of Harpacticoida assemblages. Six reefs were organized into two groups along the coast, depending on their proximity to very large urban centers. ASUs were used for meiofauna colonization and, for each reef, 320 Harpacticoida individuals were separated for identification at the species level. Abiotic parameters were analyzed, and significant differences were found between the two groups of reefs, with an increase in dissolved inorganic nutrients found in areas near large urban centers. Both the multivariate analyses and the indexes of diversity showed a clear separation between the reefs closer to the urban zones and those further away, as a response to the anthropogenic pressure. As hypothesized, in the impacted reef areas, there was a strong simplification and homogenization of the harpacticoid copepod assemblages. However, the results of the indexes, based on taxonomic distinctness, suggest that there was no phylogenetic signal of anthropogenic impact on coral reef harpacticoid copepods. View Full-Text   Abstract
We monitored consecutive generations of three lupine-feeding specialist butterflies in pine-oak barrens in central Wisconsin, USA: Frosted Elfin (Callophrys irus), Karner Blue (Lycaeides melissa samuelis), and Persius Duskywing (Erynnis persius) during 1991–2014. We also monitored the summer generation of Karner Blues in northwestern Wisconsin. We present results on 24 sites for Frosted Elfin and Persius Duskywing, and 39 sites for Karner Blue. Land uses in sites occupied by the federally endangered Karner Blue are regulated. Economically utilized lands classified as “Shifting Mosaic” (SM) (forestry land) or “Permanency of Habitat” (PH) (rights-of-way) are afforded a lower standard of conservation results than the more favorable management expected of Reserves (R). For all three species, reserve sites had more favorable trends than permanency of habitat and shifting mosaic sites. Frosted Elfin and Persius Duskywing had more strongly negative trends in permanency of habitat than shifting mosaic, but vice versa for Karner Blue. Shifting mosaic sites added more recently to the study had negative trends, but not as strongly as longer-monitored shifting mosaic sites. Another large shifting mosaic complex (Hunter Haven), monitored in 17 years during 1995–2014 for Frosted Elfin and Persius Duskywing, had non-negative trends. Individual reserve sites also had more favorable trends than collectively for all reserve sites, including significant positive trends for Persius Duskywing and Karner Blue, and a stable trend for Frosted Elfin. Thus, land use is implicated not only for declines but also for effective conservation of these species. View Full-Text "," Coleoptera,Curculionidae,Curculioninae,Acentrusini,phylogeny   spatio-temporal diffusion,specialist weevils,parasitic plants,co-dispersal through space and time,stable populations   meiobenthos,diversity indices,phytal,urban pollution   Frosted Elfin,Karner Blue,Persius Duskywing,conservation evidence,long-term trend,long-term monitoring,pine barren,habitat management,endangered species,recovery "," On the Phylogenetic Position of the Weevil Tribe Acentrusini Alonso-Zarazaga, 2005 (Coleoptera: Curculionidae: Curculioninae)   Unveiling the History of a Peculiar Weevil-Plant Interaction in South America: A Phylogeographic Approach to Hydnorobius hydnorae (Belidae) Associated with Prosopanche americana (Aristolochiaceae)   Anthropogenic Impacts on Coral Reef Harpacticoid Copepods   Patterns of Long-Term Population Trends of Three Lupine-Feeding Butterflies in Wisconsin   Abstract
Based on intrinsic morphological and extrinsic bionomic characters, the systematic position of the weevil tribe Acentrusini Alonso-Zarazaga, 2005 (Coleoptera: Curculionidae: Curculioninae) was determined. Maximum parsimony and Bayesian inference as well as nonmetric multi-dimensional scaling were used to analyze 34 morphological characters of adults, complemented by four host plant characters associated with particular weevil tribes. Sixteen species belonging to two subfamilies (Brachycerinae, Curculionidae) and seven tribes (Acentrusini, Anthonomini, Ellescini, Erirhinini, Smicronychini, Storeini, Styphlini) of the family Curculionidae and one outgroup species (Attelabidae) were studied. Phylogenetic and multi-dimensional analyses revealed the tribe Smicronychini as most closely related to Acentrusini. Of the tribes of Curculioninae studied, Styphlini, Anthonomini and Ellescini showed a certain degree of phylogenetic relation to Acentrusini, whereas Storeini were found to be least related. View Full-Text   Abstract
Interspecific interactions take place over both long and short time-frames. However, it is not completely understood if the interacting-partners persisted, migrated, or expanded in concert with Quaternary climate and landscape changes. We aim to understand whether there is concordance between the specialist weevil Hydnorobius hydnorae and its parasitic host plant, Prosopanche americana in space and time. We aim to determine whether Prosopanche had already established its range, and Hydnorobius later actively colonized this rare resource; or, if both host plant and herbivore expanded their range concomitantly. We performed population genetic, phylogeographic and Bayesian diffusion analysis of Cytochrome B sequences from 18 weevil localities and used paleodistribution models to infer host plant dispersal patterns. We found strong but uneven population structure across the range for H. hydnorae with weak signals of population growth, and haplotype network structure and SAMOVA groupings closely following biogeographic region boundaries. The ancestral areas for both Hydnorobius and Prosopanche are reconstructed in San Luis province within the Chaco Biogeographic province. Our results indicate a long trajectory of host-tracking through space and time, where the weevil has expanded its geographic range following its host plant, without significant demographic growth. We explore the past environmental changes that could underlie the boundaries between locality groups. We suggest that geographic dispersal without population growth in Hydnorobius could be enabled by the scarcity of the host plant itself, allowing for slow expansion rates and stable populations, with no need for significant demographic growth pulses to support range expansion. View Full-Text   Abstract
The number of studies demonstrating the susceptibility of benthic reef communities to anthropogenic impacts is growing. However, for some of the components of reef fauna, such as meiobenthic harpacticoid copepods, information is still lacking. Here, different diversity and taxonomic distinctness indexes and multivariate analyses were used to test whether the assemblage of harpacticoid copepods colonizing Artificial Substrate Units (ASUs) is an appropriate tool for the identification of reefs subjected to different levels of anthropogenic pressure. Furthermore, we also evaluate if diffused, persistent, anthropogenic impacts generate the homogenization and simplification of Harpacticoida assemblages. Six reefs were organized into two groups along the coast, depending on their proximity to very large urban centers. ASUs were used for meiofauna colonization and, for each reef, 320 Harpacticoida individuals were separated for identification at the species level. Abiotic parameters were analyzed, and significant differences were found between the two groups of reefs, with an increase in dissolved inorganic nutrients found in areas near large urban centers. Both the multivariate analyses and the indexes of diversity showed a clear separation between the reefs closer to the urban zones and those further away, as a response to the anthropogenic pressure. As hypothesized, in the impacted reef areas, there was a strong simplification and homogenization of the harpacticoid copepod assemblages. However, the results of the indexes, based on taxonomic distinctness, suggest that there was no phylogenetic signal of anthropogenic impact on coral reef harpacticoid copepods. View Full-Text   Abstract
We monitored consecutive generations of three lupine-feeding specialist butterflies in pine-oak barrens in central Wisconsin, USA: Frosted Elfin (Callophrys irus), Karner Blue (Lycaeides melissa samuelis), and Persius Duskywing (Erynnis persius) during 1991–2014. We also monitored the summer generation of Karner Blues in northwestern Wisconsin. We present results on 24 sites for Frosted Elfin and Persius Duskywing, and 39 sites for Karner Blue. Land uses in sites occupied by the federally endangered Karner Blue are regulated. Economically utilized lands classified as “Shifting Mosaic” (SM) (forestry land) or “Permanency of Habitat” (PH) (rights-of-way) are afforded a lower standard of conservation results than the more favorable management expected of Reserves (R). For all three species, reserve sites had more favorable trends than permanency of habitat and shifting mosaic sites. Frosted Elfin and Persius Duskywing had more strongly negative trends in permanency of habitat than shifting mosaic, but vice versa for Karner Blue. Shifting mosaic sites added more recently to the study had negative trends, but not as strongly as longer-monitored shifting mosaic sites. Another large shifting mosaic complex (Hunter Haven), monitored in 17 years during 1995–2014 for Frosted Elfin and Persius Duskywing, had non-negative trends. Individual reserve sites also had more favorable trends than collectively for all reserve sites, including significant positive trends for Persius Duskywing and Karner Blue, and a stable trend for Frosted Elfin. Thus, land use is implicated not only for declines but also for effective conservation of these species. View Full-Text   Coleoptera,Curculionidae,Curculioninae,Acentrusini,phylogeny   spatio-temporal diffusion,specialist weevils,parasitic plants,co-dispersal through space and time,stable populations   meiobenthos,diversity indices,phytal,urban pollution   Frosted Elfin,Karner Blue,Persius Duskywing,conservation evidence,long-term trend,long-term monitoring,pine barren,habitat management,endangered species,recovery ", Diversity 
 Mitoxantrone is More Toxic than Doxorubicin in SH-SY5Y Human Cells: A ‘Chemobrain’ In Vitro Study   Synthesis and Structure-Activity Relationships of (−)-cis-N-Normetazocine-Based LP1 Derivatives   Iron Release from Soybean Seed Ferritin Induced by Cinnamic Acid Derivatives ," Abstract
The potential neurotoxic effects of anticancer drugs, like doxorubicin (DOX) and mitoxantrone (MTX; also used in multiple sclerosis), are presently important reasons for concern, following epidemiological data indicating that cancer survivors submitted to chemotherapy may suffer cognitive deficits. We evaluated the in vitro neurotoxicity of two commonly used chemotherapeutic drugs, DOX and MTX, and study their underlying mechanisms in the SH-SY5Y human neuronal cell model. Undifferentiated human SH-SY5Y cells were exposed to DOX or MTX (0.13, 0.2 and 0.5 μM) for 48 h and two cytotoxicity assays were performed, the 3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium (MTT) reduction and the neutral red (NR) incorporation assays. Phase contrast microphotographs, Hoechst, and acridine orange/ethidium bromide stains were performed. Mitochondrial membrane potential was also assessed. Moreover, putative protective drugs, namely the antioxidants N-acetyl-l-cysteine (NAC; 1 mM) and 100 μM tiron, the inhibitor of caspase-3/7, Ac-DEVD-CHO (100 μM), and a protein synthesis inhibitor, cycloheximide (CHX; 10 nM), were tested to prevent DOX- or MTX-induced toxicity. The MTT reduction assay was also done in differentiated SH-SY5Y cells following exposure to 0.2 μM DOX or MTX. MTX was more toxic than DOX in both cytotoxicity assays and according to the morphological analyses. MTX also evoked a higher number of apoptotic nuclei than DOX. Both drugs, at the 0.13 μM concentration, caused mitochondrial membrane potential depolarization after a 48-h exposure. Regarding the putative neuroprotectors, 1 mM NAC was not able to prevent the cytotoxicity caused by either drug. Notwithstanding, 100 μM tiron was capable of partially reverting MTX-induced cytotoxicity in the NR uptake assay. One hundred μM Ac-DEVD-CHO and 10 nM cycloheximide (CHX) also partially prevented the toxicity induced by DOX in the NR uptake assay. MTX was more toxic than DOX in differentiated SH-SY5Y cells, while MTX had similar toxicity in differentiated and undifferentiated SH-SY5Y cells. In fact, MTX was the most neurotoxic drug tested and the mechanisms involved seem dissimilar among drugs. Thus, its toxicity mechanisms need to be further investigated as to determine the putative neurotoxicity for multiple sclerosis and cancer patients. View Full-Text   Abstract
(−)-cis-N-Normetazocine represents a rigid scaffold able to mimic the tyramine moiety of endogenous opioid peptides, and the introduction of different N-substituents influences affinity and efficacy of respective ligands at MOR (mu opioid receptor), DOR (delta opioid receptor), and KOR (kappa opioid receptor). We have previously identified LP1, a MOR/DOR multitarget opioid ligand, with an N-phenylpropanamido substituent linked to (−)-cis-N-Normetazocine scaffold. Herein, we report the synthesis, competition binding and calcium mobilization assays of new compounds 10–16 that differ from LP1 by the nature of the N-substituent. In radioligand binding experiments, the compounds 10–13, featured by an electron-withdrawing or electron-donating group in the para position of phenyl ring, displayed improved affinity for KOR (Ki = 0.85–4.80 μM) in comparison to LP1 (7.5 μM). On the contrary, their MOR and DOR affinities were worse (Ki = 0.18–0.28 μM and Ki = 0.38–1.10 μM, respectively) with respect to LP1 values (Ki = 0.049 and 0.033 μM). Analogous trends was recorded for the compounds 14–16, featured by indoline, tetrahydroquinoline, and diphenylamine functionalities in the N-substituent. In calcium mobilization assays, the compound 10 with a p-fluorophenyl in the N-substituent shared the functional profile of LP1 (pEC50MOR = 7.01), although it was less active. Moreover, the p-methyl- (11) and p-cyano- (12) substituted compounds resulted in MOR partial agonists and DOR/KOR antagonists. By contrast, the derivatives 13–15 resulted as MOR antagonists, and the derivative 16 as a MOR/KOR antagonist (pKBMOR = 6.12 and pKBKOR = 6.11). Collectively, these data corroborated the critical role of the N-substituent in (−)-cis-N-Normetazocine scaffold. Thus, the new synthesized compounds could represent a template to achieve a specific agonist, antagonist, or mixed agonist/antagonist functional profile. View Full-Text   Abstract
Plant ferritin represents a novel class of iron supplement, which widely co-exists with phenolic acids in a plant diet. However, there are few reports on the effect of these phenolic acids on function of ferritin. In this study, we demonstrated that cinnamic acid derivatives, as widely occurring phenolic acids, can induce iron release from holo soybean seed ferritin (SSF) in a structure-dependent manner. The ability of the iron release from SSF by five cinnamic acids follows the sequence of Cinnamic acid > Chlorogenic acid > Ferulic acid > p-Coumaric acid > Trans-Cinnamic acid. Fluorescence titration in conjunction with dialysis results showed that all of these five compounds have a similar, weak ability to bind with protein, suggesting that their protein-binding ability is not related to their iron release activity. In contrast, both Fe2+-chelating activity and reducibility of these cinnamic acid derivatives are in good agreement with their ability to induce iron release from ferritin. These studies indicate that cinnamic acid and its derivatives could have a negative effect on iron stability of holo soybean seed ferritin in diet, and the Fe2+-chelating activity and reducibility of cinnamic acid and its derivatives have strong relations to the iron release of soybean seed ferritin. View Full-Text "," mitoxantrone,doxorubicin,neurotoxicity,SH-SY5Y cells   opioid receptors,radioligand binding,calcium mobilization,benzomorphan   cinnamic acid derivatives,soybean seed ferritin,iron release,binding ability,Fe2+-chelating activity,reducibility "," Mitoxantrone is More Toxic than Doxorubicin in SH-SY5Y Human Cells: A ‘Chemobrain’ In Vitro Study   Synthesis and Structure-Activity Relationships of (−)-cis-N-Normetazocine-Based LP1 Derivatives   Iron Release from Soybean Seed Ferritin Induced by Cinnamic Acid Derivatives   Abstract
The potential neurotoxic effects of anticancer drugs, like doxorubicin (DOX) and mitoxantrone (MTX; also used in multiple sclerosis), are presently important reasons for concern, following epidemiological data indicating that cancer survivors submitted to chemotherapy may suffer cognitive deficits. We evaluated the in vitro neurotoxicity of two commonly used chemotherapeutic drugs, DOX and MTX, and study their underlying mechanisms in the SH-SY5Y human neuronal cell model. Undifferentiated human SH-SY5Y cells were exposed to DOX or MTX (0.13, 0.2 and 0.5 μM) for 48 h and two cytotoxicity assays were performed, the 3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium (MTT) reduction and the neutral red (NR) incorporation assays. Phase contrast microphotographs, Hoechst, and acridine orange/ethidium bromide stains were performed. Mitochondrial membrane potential was also assessed. Moreover, putative protective drugs, namely the antioxidants N-acetyl-l-cysteine (NAC; 1 mM) and 100 μM tiron, the inhibitor of caspase-3/7, Ac-DEVD-CHO (100 μM), and a protein synthesis inhibitor, cycloheximide (CHX; 10 nM), were tested to prevent DOX- or MTX-induced toxicity. The MTT reduction assay was also done in differentiated SH-SY5Y cells following exposure to 0.2 μM DOX or MTX. MTX was more toxic than DOX in both cytotoxicity assays and according to the morphological analyses. MTX also evoked a higher number of apoptotic nuclei than DOX. Both drugs, at the 0.13 μM concentration, caused mitochondrial membrane potential depolarization after a 48-h exposure. Regarding the putative neuroprotectors, 1 mM NAC was not able to prevent the cytotoxicity caused by either drug. Notwithstanding, 100 μM tiron was capable of partially reverting MTX-induced cytotoxicity in the NR uptake assay. One hundred μM Ac-DEVD-CHO and 10 nM cycloheximide (CHX) also partially prevented the toxicity induced by DOX in the NR uptake assay. MTX was more toxic than DOX in differentiated SH-SY5Y cells, while MTX had similar toxicity in differentiated and undifferentiated SH-SY5Y cells. In fact, MTX was the most neurotoxic drug tested and the mechanisms involved seem dissimilar among drugs. Thus, its toxicity mechanisms need to be further investigated as to determine the putative neurotoxicity for multiple sclerosis and cancer patients. View Full-Text   Abstract
(−)-cis-N-Normetazocine represents a rigid scaffold able to mimic the tyramine moiety of endogenous opioid peptides, and the introduction of different N-substituents influences affinity and efficacy of respective ligands at MOR (mu opioid receptor), DOR (delta opioid receptor), and KOR (kappa opioid receptor). We have previously identified LP1, a MOR/DOR multitarget opioid ligand, with an N-phenylpropanamido substituent linked to (−)-cis-N-Normetazocine scaffold. Herein, we report the synthesis, competition binding and calcium mobilization assays of new compounds 10–16 that differ from LP1 by the nature of the N-substituent. In radioligand binding experiments, the compounds 10–13, featured by an electron-withdrawing or electron-donating group in the para position of phenyl ring, displayed improved affinity for KOR (Ki = 0.85–4.80 μM) in comparison to LP1 (7.5 μM). On the contrary, their MOR and DOR affinities were worse (Ki = 0.18–0.28 μM and Ki = 0.38–1.10 μM, respectively) with respect to LP1 values (Ki = 0.049 and 0.033 μM). Analogous trends was recorded for the compounds 14–16, featured by indoline, tetrahydroquinoline, and diphenylamine functionalities in the N-substituent. In calcium mobilization assays, the compound 10 with a p-fluorophenyl in the N-substituent shared the functional profile of LP1 (pEC50MOR = 7.01), although it was less active. Moreover, the p-methyl- (11) and p-cyano- (12) substituted compounds resulted in MOR partial agonists and DOR/KOR antagonists. By contrast, the derivatives 13–15 resulted as MOR antagonists, and the derivative 16 as a MOR/KOR antagonist (pKBMOR = 6.12 and pKBKOR = 6.11). Collectively, these data corroborated the critical role of the N-substituent in (−)-cis-N-Normetazocine scaffold. Thus, the new synthesized compounds could represent a template to achieve a specific agonist, antagonist, or mixed agonist/antagonist functional profile. View Full-Text   Abstract
Plant ferritin represents a novel class of iron supplement, which widely co-exists with phenolic acids in a plant diet. However, there are few reports on the effect of these phenolic acids on function of ferritin. In this study, we demonstrated that cinnamic acid derivatives, as widely occurring phenolic acids, can induce iron release from holo soybean seed ferritin (SSF) in a structure-dependent manner. The ability of the iron release from SSF by five cinnamic acids follows the sequence of Cinnamic acid > Chlorogenic acid > Ferulic acid > p-Coumaric acid > Trans-Cinnamic acid. Fluorescence titration in conjunction with dialysis results showed that all of these five compounds have a similar, weak ability to bind with protein, suggesting that their protein-binding ability is not related to their iron release activity. In contrast, both Fe2+-chelating activity and reducibility of these cinnamic acid derivatives are in good agreement with their ability to induce iron release from ferritin. These studies indicate that cinnamic acid and its derivatives could have a negative effect on iron stability of holo soybean seed ferritin in diet, and the Fe2+-chelating activity and reducibility of cinnamic acid and its derivatives have strong relations to the iron release of soybean seed ferritin. View Full-Text   mitoxantrone,doxorubicin,neurotoxicity,SH-SY5Y cells   opioid receptors,radioligand binding,calcium mobilization,benzomorphan   cinnamic acid derivatives,soybean seed ferritin,iron release,binding ability,Fe2+-chelating activity,reducibility ", Pharmaceuticals 
 Genetic Aetiology of Nonsyndromic Hearing Loss in Moravia-Silesia   Parasitic Infections Associated with Unfavourable Outcomes in Transplant Recipients   Efficacy of Aortic Valve Replacement through Full Sternotomy and Minimal Invasion (Ministernotomy)   Vitamin D Levels of Out-Patients in Lithuania: Deficiency and Hypervitaminosis ," Abstract
Background and Objective: Hearing loss is the most common sensory deficit in humans. The aim of this study was to clarify the genetic aetiology of nonsyndromic hearing loss in the Moravian-Silesian population of the Czech Republic. Patients and Methods: This study included 200 patients (93 males, 107 females, mean age 16.9 years, ranging from 4 months to 62 years) with nonsyndromic sensorineural hearing loss. We screened all patients for mutations in GJB2 and the large deletion del(GJB6-D13S1830). We performed further screening for additional genes (SERPINB6, TMIE, COCH, ESPN, ACTG1, KCNQ4, and GJB3) with Sanger sequencing on a subset of patients that were negative for GJB2 mutations. Results: We detected biallelic GJB2 mutations in 44 patients (22%). Among these patients, 63.6%, 9.1% and 2.3% exhibited homozygous c.35delG, p.Trp24*, and p.Met34Thr mutations, respectively. The remaining 25% of these patients exhibited compound heterozygous c.35delG, c.-23+1G>A, p.Trp24*, p.Val37Ile, p.Met34Thr, p.Leu90Pro, c.235delC, c.313_326del14, p.Ser139Asn, and p.Gly147Leu mutations. We found a monoallelic GJB2 mutation in 12 patients (6.6%). We found no pathogenic mutations in the other tested genes. Conclusions: One fifth of our cohort had deafness related to GJB2 mutations. The del(GJB6-D13S1830), SERPINB6, TMIE, COCH, ESPN, ACTG1, GJB3, and KCNQ4 mutations were infrequently associated with deafness in the Moravian-Silesian population. Therefore, we suggest that del(GJB6-D13S1830) testing should be performed only when patients with deafness carry the monoallelic GJB2 mutation. View Full-Text   Abstract
Introduction. The immunosuppression used after transplantation (Tx) is associated with an increased risk of opportunistic infections. In Europe, parasitic infections after Tx are much less common than viral, bacterial and fungal ones. However, diseases caused by parasites are very common in tropical countries. In the last years the number of travellers with immunosuppression visiting tropical countries has increased. Methods. We performed a literature review to evaluate a risk of parasitic infections after Tx in Europe. Results. There is a real risk of parasitic infection in patients after Tx travelling to tropical countries. Malaria, leishmaniasis, strongyloidiasis and schistosomiasis are the most dangerous and relatively common. Although the incidence of these tropical infections after Tx has not increased, the course of disease could be fatal. There are also some cosmopolitan parasitic infections dangerous for patients after Tx. The greatest threat in Europe is toxoplasmosis, especially in heart and bone marrow recipients. The most severe manifestations of toxoplasmosis are myocarditis, encephalitis and disseminated disease. Diarrhoea is one of the most common symptoms of parasitic infection. In Europe the most prevalent pathogens causing diarrhoea are Giardia duodenalis and Cryptosporidium. Conclusions. Solid organ and bone marrow transplantations, blood transfusions and immunosuppressive treatment are associated with a small but real risk of parasitic infections in European citizens. In patients with severe parasitic infection, i.e., those with lung or brain involvement or a disseminated disease, the progression is very rapid and the prognosis is bad. Establishing a diagnosis before the patient’s death is challenging. View Full-Text   Abstract
Background: new minimally invasive sternotomy (mini-sternotomy) procedures have improved the treatment outcome and reduced the incidence of perioperative complications leading to improved patient satisfaction and a reduced cost of aortic valve replacement in comparison to the conventional median sternotomy (full sternotomy). The aim of this study is to compare and gain new insights into operative and early postoperative outcomes, long-term postoperative results, and 5-year survival rates after aortic valve replacement through a ministernotomy and full sternotomy. Methods: This is a retrospective study of patients who underwent an isolated replacement of the aortic valve via a full sternotomy or ministernotomy from 2011 to 2016. From 2011 to 2016, 426 cardiac interventions were performed, 70 of which (16.4%) were of the ministernotomy and 356 (83.6%) of the full sternotomy. Through propensity score matching, 70 patients who underwent the ministernotomy (ministernotomy group) were compared with 70 patients who underwent the full sternotomy (control group). Results: in the propensity matching cohort, no statistical difference in operative time was noted (p = 0.856). The ministernotomy had longer cross clamp (88.7 ± 20.7 vs. 80.3 ± 24.6 min, p = 0.007) and bypass (144.0 ± 29.9 vs. 132.9 ± 44.9 min, p = 0.049) times, less ventilation time (9.7 ± 1.7 vs. 11.7 ± 1.4 h, p < 0.001), shorter hospital stay (18.3 ± 1.9 vs. 21.9 ± 1.9 days, p = 0.012), less 24-h chest tube drainage (256.2 ± 28.6 vs. 407.3 ± 40.37 mL, p < 0.001), fewer corrections of coagulopathy (p < 0.001), fewer patients receiving catecholamine (5.71 vs. 30.0%, p < 0.001) and better cosmetic results (p < 0.001). Moreover, the number of patients without complaints at 1 year after the operation was significantly greater in the ministernotomy group (p = 0.002), and no significant differences in the 5-year survival between the groups were observed. In the overall cohort, the ministernotomy had longer cross clamp times (88.7 ± 20.7 vs. 79.9 ± 24.8 min, p < 0.001), longer operative times (263.5 ± 62.0 vs. 246.7 ± 74.2 min, p = 0.037) and bypass times (144.0 ± 29.9 vs. 132.7 ± 44.5 min, p = 0.026), lower incidence of 30-day mortality (1(1.4) vs. 13(3.7), p = 0.022), shorter hospital stays post-surgery p = 0.025, less 24-h chest tube drainage, p < 0.001, and fewer corrections of coagulopathy (p < 0.001). Conclusions: the ministernotomy has a number of advantages compared with the full sternotomy and thus could be a better approach for aortic valve replacement. View Full-Text   Abstract
Aim: Data on the prevalence of vitamin D deficiency in Lithuania are scarce. The aim was to assess the reserves of vitamin D in different age groups of out-patients, regarding the season of the year. Methods: Data on serum 25-hydroxyvitamin D (25(OH)D) levels from blood tests made in 2012–2014 were obtained from one laboratory, and a retrospective cross-sectional analysis was performed. Results: A total of 9581 subjects were included. The mean age of the participants was 33 ± 23 years. The mean levels of vitamin D were higher in males than in females (p < 0.001). The highest mean 25(OH)D levels were in 0–9-year-old group, the lowest were in the 10–19-year-old group and in the group of participants that were 70 years and older (p < 0.001). The lowest vitamin D status was found in January, February, March, and April. The highest status was found in August and September. Overall, vitamin D deficiency, sufficiency, and hypervitaminosis were detected in 67%, 21%, and 12% of cases, respectively. Most cases with hypervitaminosis were in the group of children up to 2 years of age. Conclusion: Vitamin D status demonstrated clear seasonality. Significant sex-related differences of vitamin D statuses were also determined. Vitamin D deficiency was very prevalent in almost all age groups. Young children (aged up to 2 years) are of special interest for further research involving other types of 25(OH)D assays, such as those based on high-performance liquid chromatography (HPLC), since the real prevalence of “true” vitamin D hypervitaminosis in Lithuania’s children is still to be determined. View Full-Text "," hearing loss,sensorineural,nonsyndromic,genetics   infection,immunosuppression,tropics   aortic valve replacement,ministernotomy,sternotomy   vitamin D,seasons,sex factors,age factors "," Genetic Aetiology of Nonsyndromic Hearing Loss in Moravia-Silesia   Parasitic Infections Associated with Unfavourable Outcomes in Transplant Recipients   Efficacy of Aortic Valve Replacement through Full Sternotomy and Minimal Invasion (Ministernotomy)   Vitamin D Levels of Out-Patients in Lithuania: Deficiency and Hypervitaminosis   Abstract
Background and Objective: Hearing loss is the most common sensory deficit in humans. The aim of this study was to clarify the genetic aetiology of nonsyndromic hearing loss in the Moravian-Silesian population of the Czech Republic. Patients and Methods: This study included 200 patients (93 males, 107 females, mean age 16.9 years, ranging from 4 months to 62 years) with nonsyndromic sensorineural hearing loss. We screened all patients for mutations in GJB2 and the large deletion del(GJB6-D13S1830). We performed further screening for additional genes (SERPINB6, TMIE, COCH, ESPN, ACTG1, KCNQ4, and GJB3) with Sanger sequencing on a subset of patients that were negative for GJB2 mutations. Results: We detected biallelic GJB2 mutations in 44 patients (22%). Among these patients, 63.6%, 9.1% and 2.3% exhibited homozygous c.35delG, p.Trp24*, and p.Met34Thr mutations, respectively. The remaining 25% of these patients exhibited compound heterozygous c.35delG, c.-23+1G>A, p.Trp24*, p.Val37Ile, p.Met34Thr, p.Leu90Pro, c.235delC, c.313_326del14, p.Ser139Asn, and p.Gly147Leu mutations. We found a monoallelic GJB2 mutation in 12 patients (6.6%). We found no pathogenic mutations in the other tested genes. Conclusions: One fifth of our cohort had deafness related to GJB2 mutations. The del(GJB6-D13S1830), SERPINB6, TMIE, COCH, ESPN, ACTG1, GJB3, and KCNQ4 mutations were infrequently associated with deafness in the Moravian-Silesian population. Therefore, we suggest that del(GJB6-D13S1830) testing should be performed only when patients with deafness carry the monoallelic GJB2 mutation. View Full-Text   Abstract
Introduction. The immunosuppression used after transplantation (Tx) is associated with an increased risk of opportunistic infections. In Europe, parasitic infections after Tx are much less common than viral, bacterial and fungal ones. However, diseases caused by parasites are very common in tropical countries. In the last years the number of travellers with immunosuppression visiting tropical countries has increased. Methods. We performed a literature review to evaluate a risk of parasitic infections after Tx in Europe. Results. There is a real risk of parasitic infection in patients after Tx travelling to tropical countries. Malaria, leishmaniasis, strongyloidiasis and schistosomiasis are the most dangerous and relatively common. Although the incidence of these tropical infections after Tx has not increased, the course of disease could be fatal. There are also some cosmopolitan parasitic infections dangerous for patients after Tx. The greatest threat in Europe is toxoplasmosis, especially in heart and bone marrow recipients. The most severe manifestations of toxoplasmosis are myocarditis, encephalitis and disseminated disease. Diarrhoea is one of the most common symptoms of parasitic infection. In Europe the most prevalent pathogens causing diarrhoea are Giardia duodenalis and Cryptosporidium. Conclusions. Solid organ and bone marrow transplantations, blood transfusions and immunosuppressive treatment are associated with a small but real risk of parasitic infections in European citizens. In patients with severe parasitic infection, i.e., those with lung or brain involvement or a disseminated disease, the progression is very rapid and the prognosis is bad. Establishing a diagnosis before the patient’s death is challenging. View Full-Text   Abstract
Background: new minimally invasive sternotomy (mini-sternotomy) procedures have improved the treatment outcome and reduced the incidence of perioperative complications leading to improved patient satisfaction and a reduced cost of aortic valve replacement in comparison to the conventional median sternotomy (full sternotomy). The aim of this study is to compare and gain new insights into operative and early postoperative outcomes, long-term postoperative results, and 5-year survival rates after aortic valve replacement through a ministernotomy and full sternotomy. Methods: This is a retrospective study of patients who underwent an isolated replacement of the aortic valve via a full sternotomy or ministernotomy from 2011 to 2016. From 2011 to 2016, 426 cardiac interventions were performed, 70 of which (16.4%) were of the ministernotomy and 356 (83.6%) of the full sternotomy. Through propensity score matching, 70 patients who underwent the ministernotomy (ministernotomy group) were compared with 70 patients who underwent the full sternotomy (control group). Results: in the propensity matching cohort, no statistical difference in operative time was noted (p = 0.856). The ministernotomy had longer cross clamp (88.7 ± 20.7 vs. 80.3 ± 24.6 min, p = 0.007) and bypass (144.0 ± 29.9 vs. 132.9 ± 44.9 min, p = 0.049) times, less ventilation time (9.7 ± 1.7 vs. 11.7 ± 1.4 h, p < 0.001), shorter hospital stay (18.3 ± 1.9 vs. 21.9 ± 1.9 days, p = 0.012), less 24-h chest tube drainage (256.2 ± 28.6 vs. 407.3 ± 40.37 mL, p < 0.001), fewer corrections of coagulopathy (p < 0.001), fewer patients receiving catecholamine (5.71 vs. 30.0%, p < 0.001) and better cosmetic results (p < 0.001). Moreover, the number of patients without complaints at 1 year after the operation was significantly greater in the ministernotomy group (p = 0.002), and no significant differences in the 5-year survival between the groups were observed. In the overall cohort, the ministernotomy had longer cross clamp times (88.7 ± 20.7 vs. 79.9 ± 24.8 min, p < 0.001), longer operative times (263.5 ± 62.0 vs. 246.7 ± 74.2 min, p = 0.037) and bypass times (144.0 ± 29.9 vs. 132.7 ± 44.5 min, p = 0.026), lower incidence of 30-day mortality (1(1.4) vs. 13(3.7), p = 0.022), shorter hospital stays post-surgery p = 0.025, less 24-h chest tube drainage, p < 0.001, and fewer corrections of coagulopathy (p < 0.001). Conclusions: the ministernotomy has a number of advantages compared with the full sternotomy and thus could be a better approach for aortic valve replacement. View Full-Text   Abstract
Aim: Data on the prevalence of vitamin D deficiency in Lithuania are scarce. The aim was to assess the reserves of vitamin D in different age groups of out-patients, regarding the season of the year. Methods: Data on serum 25-hydroxyvitamin D (25(OH)D) levels from blood tests made in 2012–2014 were obtained from one laboratory, and a retrospective cross-sectional analysis was performed. Results: A total of 9581 subjects were included. The mean age of the participants was 33 ± 23 years. The mean levels of vitamin D were higher in males than in females (p < 0.001). The highest mean 25(OH)D levels were in 0–9-year-old group, the lowest were in the 10–19-year-old group and in the group of participants that were 70 years and older (p < 0.001). The lowest vitamin D status was found in January, February, March, and April. The highest status was found in August and September. Overall, vitamin D deficiency, sufficiency, and hypervitaminosis were detected in 67%, 21%, and 12% of cases, respectively. Most cases with hypervitaminosis were in the group of children up to 2 years of age. Conclusion: Vitamin D status demonstrated clear seasonality. Significant sex-related differences of vitamin D statuses were also determined. Vitamin D deficiency was very prevalent in almost all age groups. Young children (aged up to 2 years) are of special interest for further research involving other types of 25(OH)D assays, such as those based on high-performance liquid chromatography (HPLC), since the real prevalence of “true” vitamin D hypervitaminosis in Lithuania’s children is still to be determined. View Full-Text   hearing loss,sensorineural,nonsyndromic,genetics   infection,immunosuppression,tropics   aortic valve replacement,ministernotomy,sternotomy   vitamin D,seasons,sex factors,age factors ", Medicina 
 Testing for Causality-In-Mean and Variance between the UK Housing and Stock Markets   Editorial Note: Review Papers for Journal of Risk and Financial Management (JRFM)   Exchange Rate Effects on International Commercial Trade Competitiveness   Value-at-Risk for South-East Asian Stock Markets: Stochastic Volatility vs. GARCH ," Abstract
This paper employs the two-step procedure to analyze the causality-in-mean and causality-in-variance between the housing and stock markets of the UK. The empirical findings make two key contributions. First, although previous studies have indicated a one-way causal relation from the housing market to the stock market in the UK, this paper discovered a two-way causal relation between them. Second, a causality-in-variance as well as a causality-in-mean was detected from the housing market to the stock market. View Full-Text   Abstract
The Journal of Risk and Financial Management (JRFM) was inaugurated in 2008 and has continued publishing successfully with Volume 11 in 2018. Since the journal was established, JRFM has published in excess of 110 topical and interesting theoretical and empirical papers in financial economics, financial econometrics, banking, finance, mathematical finance, statistical finance, accounting, decision sciences, information management, tourism economics and finance, international rankings of journals in financial economics, and bibliometric rankings of journals in cognate disciplines. Papers published in the journal range from novel technical and theoretical papers to innovative empirical contributions. The journal wishes to encourage critical review papers on topical subjects in any of the topics mentioned above in financial economics and in cognate disciplines. View Full-Text   Abstract
This study is meant to be an evaluation sustained by theoretical and empirical considerations of the exchange rate impact on international commercial trade competitiveness. In this respect, the study aims to find how the exchange rate influences Romanian competitiveness through assessing the effects generated on exports and imports. The main purpose of the study is to assess the complex action of the exchange rate on international commercial trade competitiveness in contemporaneity and the connections between these variables. The empirical part contains a regression analysis where exports and imports are dependent variables influenced by a series of determinants. View Full-Text   Abstract
This study compares the performance of several methods to calculate the Value-at-Risk of the six main ASEAN stock markets. We use filtered historical simulations, GARCH models, and stochastic volatility models. The out-of-sample performance is analyzed by various backtesting procedures. We find that simpler models fail to produce sufficient Value-at-Risk forecasts, which appears to stem from several econometric properties of the return distributions. With stochastic volatility models, we obtain better Value-at-Risk forecasts compared to GARCH. The quality varies over forecasting horizons and across markets. This indicates that, despite a regional proximity and homogeneity of the markets, index volatilities are driven by different factors. View Full-Text "," causality-in-variance,cross-correlation function,housing and stock markets      exchange rate,economic competitiveness,exports,imports,multiple regression   ASEAN,GARCH,stochastic volatility,Value-at-Risk "," Testing for Causality-In-Mean and Variance between the UK Housing and Stock Markets   Editorial Note: Review Papers for Journal of Risk and Financial Management (JRFM)   Exchange Rate Effects on International Commercial Trade Competitiveness   Value-at-Risk for South-East Asian Stock Markets: Stochastic Volatility vs. GARCH   Abstract
This paper employs the two-step procedure to analyze the causality-in-mean and causality-in-variance between the housing and stock markets of the UK. The empirical findings make two key contributions. First, although previous studies have indicated a one-way causal relation from the housing market to the stock market in the UK, this paper discovered a two-way causal relation between them. Second, a causality-in-variance as well as a causality-in-mean was detected from the housing market to the stock market. View Full-Text   Abstract
The Journal of Risk and Financial Management (JRFM) was inaugurated in 2008 and has continued publishing successfully with Volume 11 in 2018. Since the journal was established, JRFM has published in excess of 110 topical and interesting theoretical and empirical papers in financial economics, financial econometrics, banking, finance, mathematical finance, statistical finance, accounting, decision sciences, information management, tourism economics and finance, international rankings of journals in financial economics, and bibliometric rankings of journals in cognate disciplines. Papers published in the journal range from novel technical and theoretical papers to innovative empirical contributions. The journal wishes to encourage critical review papers on topical subjects in any of the topics mentioned above in financial economics and in cognate disciplines. View Full-Text   Abstract
This study is meant to be an evaluation sustained by theoretical and empirical considerations of the exchange rate impact on international commercial trade competitiveness. In this respect, the study aims to find how the exchange rate influences Romanian competitiveness through assessing the effects generated on exports and imports. The main purpose of the study is to assess the complex action of the exchange rate on international commercial trade competitiveness in contemporaneity and the connections between these variables. The empirical part contains a regression analysis where exports and imports are dependent variables influenced by a series of determinants. View Full-Text   Abstract
This study compares the performance of several methods to calculate the Value-at-Risk of the six main ASEAN stock markets. We use filtered historical simulations, GARCH models, and stochastic volatility models. The out-of-sample performance is analyzed by various backtesting procedures. We find that simpler models fail to produce sufficient Value-at-Risk forecasts, which appears to stem from several econometric properties of the return distributions. With stochastic volatility models, we obtain better Value-at-Risk forecasts compared to GARCH. The quality varies over forecasting horizons and across markets. This indicates that, despite a regional proximity and homogeneity of the markets, index volatilities are driven by different factors. View Full-Text   causality-in-variance,cross-correlation function,housing and stock markets      exchange rate,economic competitiveness,exports,imports,multiple regression   ASEAN,GARCH,stochastic volatility,Value-at-Risk ", Journal of Risk and Financial Management 
 Single Machine Scheduling Problem with Interval Processing Times and Total Completion Time Objective   Control Strategy of Speed Servo Systems Based on Deep Reinforcement Learning   Utility Distribution Strategy of the Task Agents in Coalition Skill Games ," Abstract
We consider a single machine scheduling problem with uncertain durations of the given jobs. The objective function is minimizing the sum of the job completion times. We apply the stability approach to the considered uncertain scheduling problem using a relative perimeter of the optimality box as a stability measure of the optimal job permutation. We investigated properties of the optimality box and developed algorithms for constructing job permutations that have the largest relative perimeters of the optimality box. Computational results for constructing such permutations showed that they provided the average error less than
0.74%
for the solved uncertain problems. View Full-Text   Abstract
We developed a novel control strategy of speed servo systems based on deep reinforcement learning. The control parameters of speed servo systems are difficult to regulate for practical applications, and problems of moment disturbance and inertia mutation occur during the operation process. A class of reinforcement learning agents for speed servo systems is designed based on the deep deterministic policy gradient algorithm. The agents are trained by a significant number of system data. After learning completion, they can automatically adjust the control parameters of servo systems and compensate for current online. Consequently, a servo system can always maintain good control performance. Numerous experiments are conducted to verify the proposed control strategy. Results show that the proposed method can achieve proportional–integral–derivative automatic tuning and effectively overcome the effects of inertia mutation and torque disturbance. View Full-Text   Abstract
This paper focuses on the rational distribution of task utilities in coalition skill games, which is a restricted form of coalition game, where each service agent has a set of skills and each task agent needs a set of skills in order to be completed. These two types of agents are assumed to be self-interested. Given the task selection strategy of service agents, the utility distribution strategies of task agents play an important role in improving their individual revenues and system total revenue. The problem that needs to be resolved is how to design the task selection strategies of the service agents and the utility distribution strategies of the task agents to make the self-interested decisions improve the system whole performance. However, to the best of our knowledge, this problem has been the topic of very few studies and has not been properly addressed. To address this problem, a task allocation algorithm for self-interested agents in a coalition skill game is proposed, it distributes the utilities of tasks to the needed skills according to the powers of the service agents that possess the corresponding skills. The final simulation results verify the effectiveness of the algorithm. View Full-Text "," scheduling,uncertain durations,single machine,total completion time   servo system,deep reinforcement learning,PID parameter tuning,torque disturbance,inertia change   multi-agent system,self-interested agent,coalition skill games,service agent,task agent,utility distribution "," Single Machine Scheduling Problem with Interval Processing Times and Total Completion Time Objective   Control Strategy of Speed Servo Systems Based on Deep Reinforcement Learning   Utility Distribution Strategy of the Task Agents in Coalition Skill Games   Abstract
We consider a single machine scheduling problem with uncertain durations of the given jobs. The objective function is minimizing the sum of the job completion times. We apply the stability approach to the considered uncertain scheduling problem using a relative perimeter of the optimality box as a stability measure of the optimal job permutation. We investigated properties of the optimality box and developed algorithms for constructing job permutations that have the largest relative perimeters of the optimality box. Computational results for constructing such permutations showed that they provided the average error less than
0.74%
for the solved uncertain problems. View Full-Text   Abstract
We developed a novel control strategy of speed servo systems based on deep reinforcement learning. The control parameters of speed servo systems are difficult to regulate for practical applications, and problems of moment disturbance and inertia mutation occur during the operation process. A class of reinforcement learning agents for speed servo systems is designed based on the deep deterministic policy gradient algorithm. The agents are trained by a significant number of system data. After learning completion, they can automatically adjust the control parameters of servo systems and compensate for current online. Consequently, a servo system can always maintain good control performance. Numerous experiments are conducted to verify the proposed control strategy. Results show that the proposed method can achieve proportional–integral–derivative automatic tuning and effectively overcome the effects of inertia mutation and torque disturbance. View Full-Text   Abstract
This paper focuses on the rational distribution of task utilities in coalition skill games, which is a restricted form of coalition game, where each service agent has a set of skills and each task agent needs a set of skills in order to be completed. These two types of agents are assumed to be self-interested. Given the task selection strategy of service agents, the utility distribution strategies of task agents play an important role in improving their individual revenues and system total revenue. The problem that needs to be resolved is how to design the task selection strategies of the service agents and the utility distribution strategies of the task agents to make the self-interested decisions improve the system whole performance. However, to the best of our knowledge, this problem has been the topic of very few studies and has not been properly addressed. To address this problem, a task allocation algorithm for self-interested agents in a coalition skill game is proposed, it distributes the utilities of tasks to the needed skills according to the powers of the service agents that possess the corresponding skills. The final simulation results verify the effectiveness of the algorithm. View Full-Text   scheduling,uncertain durations,single machine,total completion time   servo system,deep reinforcement learning,PID parameter tuning,torque disturbance,inertia change   multi-agent system,self-interested agent,coalition skill games,service agent,task agent,utility distribution ", Algorithms 
 Polymer–Surfactant System Based Amorphous Solid Dispersion: Precipitation Inhibition and Bioavailability Enhancement of Itraconazole   Wool-Like Hollow Polymeric Nanoparticles for CML Chemo-Combinatorial Therapy   Penetration Enhancement of Topical Formulations ," Abstract
The rapid release of poorly water-soluble drugs from amorphous solid dispersion (ASD) is often associated with the generation of supersaturated solution, which provides a strong driving force for precipitation and results in reduced absorption. Precipitation inhibitors, such as polymers and surfactants, are usually used to stabilize the supersaturated solution by blocking the way of kinetic or thermodynamic crystal growth. To evaluate the combined effect of polymers and surfactants on maintaining the supersaturated state of itraconazole (ITZ), various surfactants were integrated with enteric polymer hydroxypropyl methylcellulose acetate succinate (HPMC AS) to develop polymer–surfactant based solid dispersion. The supersaturation stability was investigated by in vitro supersaturation dissolution test and nucleation induction time measurement. Compared to the ASD prepared with HPMC AS alone, the addition of d-alpha-tocopheryl polyethylene glycol 1000 succinate (TPGS) exhibited a synergistic effect on precipitation inhibition. The results indicated that the TPGS not only significantly reduced the degree of supersaturation which is the driving force for precipitation, but also provided steric hindrance to delay crystal growth by absorbing onto the surface of small particles. Subsequently, the formulations were evaluated in vivo in beagle dogs. Compared with commercial product Sporanox®, the formulation prepared with HPMC AS/TPGS exhibited a 1.8-fold increase in the AUC (0–24 h) of ITZ and a 1.43-fold increase of hydroxyitraconazole (OH-ITZ) in the plasma. Similarly, the extent of absorption was increased by more than 40% when compared to the formulation prepared with HPMC AS alone. The results of this study demonstrated that the ASD based on polymer–surfactant system could obviously inhibit drug precipitation in vitro and in vivo, which provides a new access for the development of ASD for poorly water-soluble drug. View Full-Text   Abstract
Chronic myeloid leukaemia (CML) is caused by the BCR-ABL oncogene, which encodes the constitutively active BCR-ABL tyrosine kinase. Targeted therapy with tyrosine-kinase inhibitors induces a partial cytogenetic response in most patients. Nanosystems can represent an opportunity for combinatorial therapy with the capacity to simultaneously release different therapeutic agents, checking the pharmacokinetic properties. In this work, we have developed a novel poly-(ε-caprolactone) (PCL) nanosystem for combinatorial therapy in CML, composed of a biodegradable pH sensitive core releasing Nilotinib (Nil) and an enzymatic sensitive outer shell releasing Imatinib Mesylate (IM), resulting in wool-like nanoparticles (NPs). The resulting double loaded wool-like hollow PCL NPs showed a high dual-drug encapsulation efficiency, pH and enzymatic sensitivity and synchronized drug release capability. The combinatorial delivery of IM and Nil exhibited an importantly reduced IC50 value of IM and Nil on leukaemia cells compared to single free drugs administration. In vitro results, showed that combinatorial nanomixures preserved the biological activity of loaded drugs for extensive time windows and led to a constant release of active drug. In addition, the combination of IM and Nil in single PCL NPs have shown a more therapeutic efficiency at a low dose with respect to the single drug nanomixures, confirming that both drugs reached the target cell precisely, maximizing the cytotoxicity while minimizing the chances of cell resistance to drugs. View Full-Text   Abstract
This special issue, which is entitled “Penetration Enhancement of Topical Formulations”, presents a selection of the latest research that elucidates the challenges facing topical formulations for human skin in addition to proposing interesting solutions.[…] View Full-Text "," amorphous solid dispersion,precipitation,TPGS,HPMC AS,itraconazole,bioavailability   combinatorial therapy,polymeric nanoparticles,CML cells    "," Polymer–Surfactant System Based Amorphous Solid Dispersion: Precipitation Inhibition and Bioavailability Enhancement of Itraconazole   Wool-Like Hollow Polymeric Nanoparticles for CML Chemo-Combinatorial Therapy   Penetration Enhancement of Topical Formulations   Abstract
The rapid release of poorly water-soluble drugs from amorphous solid dispersion (ASD) is often associated with the generation of supersaturated solution, which provides a strong driving force for precipitation and results in reduced absorption. Precipitation inhibitors, such as polymers and surfactants, are usually used to stabilize the supersaturated solution by blocking the way of kinetic or thermodynamic crystal growth. To evaluate the combined effect of polymers and surfactants on maintaining the supersaturated state of itraconazole (ITZ), various surfactants were integrated with enteric polymer hydroxypropyl methylcellulose acetate succinate (HPMC AS) to develop polymer–surfactant based solid dispersion. The supersaturation stability was investigated by in vitro supersaturation dissolution test and nucleation induction time measurement. Compared to the ASD prepared with HPMC AS alone, the addition of d-alpha-tocopheryl polyethylene glycol 1000 succinate (TPGS) exhibited a synergistic effect on precipitation inhibition. The results indicated that the TPGS not only significantly reduced the degree of supersaturation which is the driving force for precipitation, but also provided steric hindrance to delay crystal growth by absorbing onto the surface of small particles. Subsequently, the formulations were evaluated in vivo in beagle dogs. Compared with commercial product Sporanox®, the formulation prepared with HPMC AS/TPGS exhibited a 1.8-fold increase in the AUC (0–24 h) of ITZ and a 1.43-fold increase of hydroxyitraconazole (OH-ITZ) in the plasma. Similarly, the extent of absorption was increased by more than 40% when compared to the formulation prepared with HPMC AS alone. The results of this study demonstrated that the ASD based on polymer–surfactant system could obviously inhibit drug precipitation in vitro and in vivo, which provides a new access for the development of ASD for poorly water-soluble drug. View Full-Text   Abstract
Chronic myeloid leukaemia (CML) is caused by the BCR-ABL oncogene, which encodes the constitutively active BCR-ABL tyrosine kinase. Targeted therapy with tyrosine-kinase inhibitors induces a partial cytogenetic response in most patients. Nanosystems can represent an opportunity for combinatorial therapy with the capacity to simultaneously release different therapeutic agents, checking the pharmacokinetic properties. In this work, we have developed a novel poly-(ε-caprolactone) (PCL) nanosystem for combinatorial therapy in CML, composed of a biodegradable pH sensitive core releasing Nilotinib (Nil) and an enzymatic sensitive outer shell releasing Imatinib Mesylate (IM), resulting in wool-like nanoparticles (NPs). The resulting double loaded wool-like hollow PCL NPs showed a high dual-drug encapsulation efficiency, pH and enzymatic sensitivity and synchronized drug release capability. The combinatorial delivery of IM and Nil exhibited an importantly reduced IC50 value of IM and Nil on leukaemia cells compared to single free drugs administration. In vitro results, showed that combinatorial nanomixures preserved the biological activity of loaded drugs for extensive time windows and led to a constant release of active drug. In addition, the combination of IM and Nil in single PCL NPs have shown a more therapeutic efficiency at a low dose with respect to the single drug nanomixures, confirming that both drugs reached the target cell precisely, maximizing the cytotoxicity while minimizing the chances of cell resistance to drugs. View Full-Text   Abstract
This special issue, which is entitled “Penetration Enhancement of Topical Formulations”, presents a selection of the latest research that elucidates the challenges facing topical formulations for human skin in addition to proposing interesting solutions.[…] View Full-Text   amorphous solid dispersion,precipitation,TPGS,HPMC AS,itraconazole,bioavailability   combinatorial therapy,polymeric nanoparticles,CML cells    ", Pharmaceutics 
 An EV Charging Scheduling Mechanism Based on Price Negotiation   A Fair Cooperative MAC Protocol in IEEE 802.11 WLAN   MinHash-Based Fuzzy Keyword Search of Encrypted Data across Multiple Cloud Servers ," Abstract
Scheduling EV user’s charging behavior based on charging price and applying renewable energy resources are the effective methods to release the load pressure of power grids brought about by the large-scale popularity of electric vehicles (EVs). This paper presents a novel approach for EV charging scheduling based on price negotiation. Firstly, the EV charging system framework based on price negotiation and renewable energy resources is discussed. Secondly, the price negotiation model is presented, including the initial price models and the conditions of transactions. Finally, an EV charging scheduling mechanism based on price negotiation (CSM-PN), including the price adjustment strategies of both the operator and EV users is proposed to seek a final transaction during multi-round price negotiation. Simulation results show that this novel approach can effectively improve the charging station operator’s income, reduce the EV users’ costs, and balance the load of the power grid while improving the efficiency of the EV charging system. View Full-Text   Abstract
Cooperative communication techniques have recently enabled wireless technologies to overcome their challenges. The main objective of these techniques is to improve resource allocation. In this paper, we propose a new protocol in medium access control (MAC) of the IEEE 802.11 standard. In our new protocol, which is called Fair Cooperative MAC (FC-MAC), every relay node participates in cooperation proportionally to its provided cooperation gain. This technique improves network resource allocation by exploiting the potential capacity of all relay candidates. Simulation results demonstrate that the FC-MAC protocol presents better performance in terms of throughput, fairness, and network lifetime. View Full-Text   Abstract
To enhance the efficiency of data searching, most data owners store their data files in different cloud servers in the form of cipher-text. Thus, efficient search using fuzzy keywords becomes a critical issue in such a cloud computing environment. This paper proposes a method that aims at improving the efficiency of cipher-text retrieval and lowering storage overhead for fuzzy keyword search. In contrast to traditional approaches, the proposed method can reduce the complexity of Min-Hash-based fuzzy keyword search by using Min-Hash fingerprints to avoid the need to construct the fuzzy keyword set. The method will utilize Jaccard similarity to rank the results of retrieval, thus reducing the amount of calculation for similarity and saving a lot of time and space overhead. The method will also take consideration of multiple user queries through re-encryption technology and update user permissions dynamically. Security analysis demonstrates that the method can provide better privacy preservation and experimental results show that efficiency of cipher-text using the proposed method can improve the retrieval time and lower storage overhead as well. View Full-Text "," electric vehicle,price negotiation,charging price,renewable energy resources   cooperation,relay selection,fairness,lifetime   cloud storage,multi-server,multi-user,fuzzy keyword search "," An EV Charging Scheduling Mechanism Based on Price Negotiation   A Fair Cooperative MAC Protocol in IEEE 802.11 WLAN   MinHash-Based Fuzzy Keyword Search of Encrypted Data across Multiple Cloud Servers   Abstract
Scheduling EV user’s charging behavior based on charging price and applying renewable energy resources are the effective methods to release the load pressure of power grids brought about by the large-scale popularity of electric vehicles (EVs). This paper presents a novel approach for EV charging scheduling based on price negotiation. Firstly, the EV charging system framework based on price negotiation and renewable energy resources is discussed. Secondly, the price negotiation model is presented, including the initial price models and the conditions of transactions. Finally, an EV charging scheduling mechanism based on price negotiation (CSM-PN), including the price adjustment strategies of both the operator and EV users is proposed to seek a final transaction during multi-round price negotiation. Simulation results show that this novel approach can effectively improve the charging station operator’s income, reduce the EV users’ costs, and balance the load of the power grid while improving the efficiency of the EV charging system. View Full-Text   Abstract
Cooperative communication techniques have recently enabled wireless technologies to overcome their challenges. The main objective of these techniques is to improve resource allocation. In this paper, we propose a new protocol in medium access control (MAC) of the IEEE 802.11 standard. In our new protocol, which is called Fair Cooperative MAC (FC-MAC), every relay node participates in cooperation proportionally to its provided cooperation gain. This technique improves network resource allocation by exploiting the potential capacity of all relay candidates. Simulation results demonstrate that the FC-MAC protocol presents better performance in terms of throughput, fairness, and network lifetime. View Full-Text   Abstract
To enhance the efficiency of data searching, most data owners store their data files in different cloud servers in the form of cipher-text. Thus, efficient search using fuzzy keywords becomes a critical issue in such a cloud computing environment. This paper proposes a method that aims at improving the efficiency of cipher-text retrieval and lowering storage overhead for fuzzy keyword search. In contrast to traditional approaches, the proposed method can reduce the complexity of Min-Hash-based fuzzy keyword search by using Min-Hash fingerprints to avoid the need to construct the fuzzy keyword set. The method will utilize Jaccard similarity to rank the results of retrieval, thus reducing the amount of calculation for similarity and saving a lot of time and space overhead. The method will also take consideration of multiple user queries through re-encryption technology and update user permissions dynamically. Security analysis demonstrates that the method can provide better privacy preservation and experimental results show that efficiency of cipher-text using the proposed method can improve the retrieval time and lower storage overhead as well. View Full-Text   electric vehicle,price negotiation,charging price,renewable energy resources   cooperation,relay selection,fairness,lifetime   cloud storage,multi-server,multi-user,fuzzy keyword search ", Future Internet 
 Comparing the Cost of Protecting Selected Lightweight Block Ciphers against Differential Power Analysis in Low-Cost FPGAs†   Designing Domain-Specific Heterogeneous Architectures from Dataflow Programs   Feedback-Based Admission Control for Firm Real-Time Task Allocation with Dynamic Voltage and Frequency Scaling   Scheduling and Tuning for Low Energy in Heterogeneous and Configurable Multicore Systems† ," Abstract
Lightweight block ciphers are an important topic in the Internet of Things (IoT) since they provide moderate security while requiring fewer resources than the Advanced Encryption Standard (AES). Ongoing cryptographic contests and standardization efforts evaluate lightweight block ciphers on their resistance to power analysis side channel attack (SCA), and the ability to apply countermeasures. While some ciphers have been individually evaluated, a large-scale comparison of resistance to side channel attack and the formulation of absolute and relative costs of implementing countermeasures is difficult, since researchers typically use varied architectures, optimization strategies, technologies, and evaluation techniques. In this research, we leverage the Test Vector Leakage Assessment (TVLA) methodology and the FOBOS SCA framework to compare FPGA implementations of AES, SIMON, SPECK, PRESENT, LED, and TWINE, using a choice of architecture targeted to optimize throughput-to-area (TP/A) ratio and suitable for introducing countermeasures to Differential Power Analysis (DPA). We then apply an equivalent level of protection to the above ciphers using 3-share threshold implementations (TI) and verify the improved resistance to DPA. We find that SIMON has the highest absolute TP/A ratio of protected versions, as well as the lowest relative cost of protection in terms of TP/A ratio. Additionally, PRESENT uses the least energy per bit (E/bit) of all protected implementations, while AES has the lowest relative cost of protection in terms of increased E/bit. View Full-Text   Abstract
The last ten years have seen performance and power requirements pushing computer architectures using only a single core towards so-called manycore systems with hundreds of cores on a single chip. To further increase performance and energy efficiency, we are now seeing the development of heterogeneous architectures with specialized and accelerated cores. However, designing these heterogeneous systems is a challenging task due to their inherent complexity. We proposed an approach for designing domain-specific heterogeneous architectures based on instruction augmentation through the integration of hardware accelerators into simple cores. These hardware accelerators were determined based on their common use among applications within a certain domain.The objective was to generate heterogeneous architectures by integrating many of these accelerated cores and connecting them with a network-on-chip. The proposed approach aimed to ease the design of heterogeneous manycore architectures—and, consequently, exploration of the design space—by automating the design steps. To evaluate our approach, we enhanced our software tool chain with a tool that can generate accelerated cores from dataflow programs. This new tool chain was evaluated with the aid of two use cases: radar signal processing and mobile baseband processing. We could achieve an approximately
4×
improvement in performance, while executing complete applications on the augmented cores with a small impact (2.5–13%) on area usage. The generated accelerators are competitive, achieving more than 90% of the performance of hand-written implementations. View Full-Text   Abstract
Feedback-based mechanisms can be employed to monitor the performance of Multiprocessor Systems-on-Chips (MPSoCs) and steer the task execution even if the exact knowledge of the workload is unknown a priori. In particular, traditional proportional-integral controllers can be used with firm real-time tasks to either admit them to the processing cores or reject in order not to violate the timeliness of the already admitted tasks. During periods with a lower computational power demand, dynamic voltage and frequency scaling (DVFS) can be used to reduce the dissipation of energy in the cores while still not violating the tasks’ time constraints. Depending on the workload pattern and weight, platform size and the granularity of DVFS, energy savings can reach even 60% at the cost of a slight performance degradation. View Full-Text   Abstract
Heterogeneous and configurable multicore systems provide hardware specialization to meet disparate application hardware requirements. However, effective multicore system specialization can require a priori knowledge of the applications, application profiling information, and/or dynamic hardware tuning to schedule and execute applications on the most energy efficient cores. Furthermore, even though highly disparate core heterogeneity and/or highly configurable parameters with numerous potential parameter values result in more fine-grained specialization and higher energy savings potential, these large design spaces are challenging to efficiently explore. To address these challenges, we propose a novel configuration-subsetted heterogeneous and configurable multicore system, wherein each core offers a small subset of the design space, and propose a novel scheduling and tuning (SaT) algorithm to efficiently exploit the energy savings potential of this system. Our proposed architecture and algorithm require no a priori application knowledge or profiling, and incur minimal runtime overhead. Results reveal energy savings potential and insights on energy trade-offs in heterogeneous, configurable systems. View Full-Text "," block cipher,encryption,field programmable gate array,side channel attack,countermeasure,lightweight,TVLA,t-test,FOBOS   heterogeneous architecture design,risc-v,dataflow,QR decomposition,domain-specific processor,accelerator,Autofocus,hardware software co-design   feedback,admission control,firm real-time,DVFS,MPSoC,task allocation   heterogeneous cores,configurable caches,energy optimizations,design space subsetting,embedded systems,multicore architectures,scheduling "," Comparing the Cost of Protecting Selected Lightweight Block Ciphers against Differential Power Analysis in Low-Cost FPGAs†   Designing Domain-Specific Heterogeneous Architectures from Dataflow Programs   Feedback-Based Admission Control for Firm Real-Time Task Allocation with Dynamic Voltage and Frequency Scaling   Scheduling and Tuning for Low Energy in Heterogeneous and Configurable Multicore Systems†   Abstract
Lightweight block ciphers are an important topic in the Internet of Things (IoT) since they provide moderate security while requiring fewer resources than the Advanced Encryption Standard (AES). Ongoing cryptographic contests and standardization efforts evaluate lightweight block ciphers on their resistance to power analysis side channel attack (SCA), and the ability to apply countermeasures. While some ciphers have been individually evaluated, a large-scale comparison of resistance to side channel attack and the formulation of absolute and relative costs of implementing countermeasures is difficult, since researchers typically use varied architectures, optimization strategies, technologies, and evaluation techniques. In this research, we leverage the Test Vector Leakage Assessment (TVLA) methodology and the FOBOS SCA framework to compare FPGA implementations of AES, SIMON, SPECK, PRESENT, LED, and TWINE, using a choice of architecture targeted to optimize throughput-to-area (TP/A) ratio and suitable for introducing countermeasures to Differential Power Analysis (DPA). We then apply an equivalent level of protection to the above ciphers using 3-share threshold implementations (TI) and verify the improved resistance to DPA. We find that SIMON has the highest absolute TP/A ratio of protected versions, as well as the lowest relative cost of protection in terms of TP/A ratio. Additionally, PRESENT uses the least energy per bit (E/bit) of all protected implementations, while AES has the lowest relative cost of protection in terms of increased E/bit. View Full-Text   Abstract
The last ten years have seen performance and power requirements pushing computer architectures using only a single core towards so-called manycore systems with hundreds of cores on a single chip. To further increase performance and energy efficiency, we are now seeing the development of heterogeneous architectures with specialized and accelerated cores. However, designing these heterogeneous systems is a challenging task due to their inherent complexity. We proposed an approach for designing domain-specific heterogeneous architectures based on instruction augmentation through the integration of hardware accelerators into simple cores. These hardware accelerators were determined based on their common use among applications within a certain domain.The objective was to generate heterogeneous architectures by integrating many of these accelerated cores and connecting them with a network-on-chip. The proposed approach aimed to ease the design of heterogeneous manycore architectures—and, consequently, exploration of the design space—by automating the design steps. To evaluate our approach, we enhanced our software tool chain with a tool that can generate accelerated cores from dataflow programs. This new tool chain was evaluated with the aid of two use cases: radar signal processing and mobile baseband processing. We could achieve an approximately
4×
improvement in performance, while executing complete applications on the augmented cores with a small impact (2.5–13%) on area usage. The generated accelerators are competitive, achieving more than 90% of the performance of hand-written implementations. View Full-Text   Abstract
Feedback-based mechanisms can be employed to monitor the performance of Multiprocessor Systems-on-Chips (MPSoCs) and steer the task execution even if the exact knowledge of the workload is unknown a priori. In particular, traditional proportional-integral controllers can be used with firm real-time tasks to either admit them to the processing cores or reject in order not to violate the timeliness of the already admitted tasks. During periods with a lower computational power demand, dynamic voltage and frequency scaling (DVFS) can be used to reduce the dissipation of energy in the cores while still not violating the tasks’ time constraints. Depending on the workload pattern and weight, platform size and the granularity of DVFS, energy savings can reach even 60% at the cost of a slight performance degradation. View Full-Text   Abstract
Heterogeneous and configurable multicore systems provide hardware specialization to meet disparate application hardware requirements. However, effective multicore system specialization can require a priori knowledge of the applications, application profiling information, and/or dynamic hardware tuning to schedule and execute applications on the most energy efficient cores. Furthermore, even though highly disparate core heterogeneity and/or highly configurable parameters with numerous potential parameter values result in more fine-grained specialization and higher energy savings potential, these large design spaces are challenging to efficiently explore. To address these challenges, we propose a novel configuration-subsetted heterogeneous and configurable multicore system, wherein each core offers a small subset of the design space, and propose a novel scheduling and tuning (SaT) algorithm to efficiently exploit the energy savings potential of this system. Our proposed architecture and algorithm require no a priori application knowledge or profiling, and incur minimal runtime overhead. Results reveal energy savings potential and insights on energy trade-offs in heterogeneous, configurable systems. View Full-Text   block cipher,encryption,field programmable gate array,side channel attack,countermeasure,lightweight,TVLA,t-test,FOBOS   heterogeneous architecture design,risc-v,dataflow,QR decomposition,domain-specific processor,accelerator,Autofocus,hardware software co-design   feedback,admission control,firm real-time,DVFS,MPSoC,task allocation   heterogeneous cores,configurable caches,energy optimizations,design space subsetting,embedded systems,multicore architectures,scheduling ", Computers 
" Bifurcation Mechanism Design—From Optimal Flat Taxes to Better Cancer Treatments   Ethics, Morality, and Game Theory   Fractionated Follow-Up Chemotherapy Delays the Onset of Resistance in Bone Metastatic Prostate Cancer   Generalized Trust, Need for Cognitive Closure, and the Perceived Acceptability of Personal Data Collection "," Abstract
Small changes to the parameters of a system can lead to abrupt qualitative changes of its behavior, a phenomenon known as bifurcation. Such instabilities are typically considered problematic, however, we show that their power can be leveraged to design novel types of mechanisms. Hysteresis mechanisms use transient changes of system parameters to induce a permanent improvement to its performance via optimal equilibrium selection. Optimal control mechanisms induce convergence to states whose performance is better than even the best equilibrium. We apply these mechanisms in two different settings that illustrate the versatility of bifurcation mechanism design. In the first one we explore how introducing flat taxation could improve social welfare, despite decreasing agent “rationality,” by destabilizing inefficient equilibria. From there we move on to consider a well known game of tumor metabolism and use our approach to derive potential new cancer treatment strategies. View Full-Text   Abstract
Ethics is a field in which the gap between words and actions looms large. Game theory and the empirical methods it inspires look at behavior instead of the lip service people sometimes pay to norms. We believe that this special issue comprises several illustrations of the fruitful application of this approach to ethics. View Full-Text   Abstract
Prostate cancer to bone metastases are almost always lethal. This results from the ability of metastatic prostate cancer cells to co-opt bone remodeling, leading to what is known as the vicious cycle. Understanding how tumor cells can disrupt bone homeostasis through their interactions with the stroma and how metastatic tumors respond to treatment is key to the development of new treatments for what remains an incurable disease. Here we describe an evolutionary game theoretical model of both the homeostatic bone remodeling and its co-option by prostate cancer metastases. This model extends past the evolutionary aspects typically considered in game theoretical models by also including ecological factors such as the physical microenvironment of the bone. Our model recapitulates the current paradigm of the “vicious cycle” driving tumor growth and sheds light on the interactions of heterogeneous tumor cells with the bone microenvironment and treatment response. Our results show that resistant populations naturally become dominant in the metastases under conventional cytotoxic treatment and that novel schedules could be used to better control the tumor and the associated bone disease compared to the current standard of care. Specifically, we introduce fractionated follow up therapy—chemotherapy where dosage is administered initially in one solid block followed by alternating smaller doses and holidays—and argue that it is better than either a continuous application or a periodic one. Furthermore, we also show that different regimens of chemotherapy can lead to different amounts of pathological bone that are known to correlate with poor quality of life for bone metastatic prostate cancer patients. View Full-Text   Abstract
This vignette-based study examines how generalized trust and the need for cognitive closure relate to the perceived acceptability of contemporary business methods of personal data collection. Subjects are exposed to four scenarios that describe a method of personal data collection, involving either brand-name companies or generic descriptors of companies. After each scenario, subjects rate how acceptable they find the practice of data collection, along with the frequency and quality of experiences that they have had with the company (for brand names) or type of company (for generic descriptors). Judgments of perceived acceptability are analyzed, both across the portfolio of judgments and within each separate scenario. While analyses of each separate scenario point to the context-dependency of the perceived acceptability of data collection, several results stand out when analyzing the subjects’ portfolios of responses in the aggregate. Higher generalized trust is linked to a higher average acceptability rating, and the effect is stronger when companies are described with brand names rather than generic descriptors. Uniformly, however, no relationship is found between need for cognitive closure and perceived acceptability. Additionally, positive experiences are found to be a stronger predictor of perceived acceptability of data collection than frequency of use. View Full-Text "," game theory,cancer,economics,hysteresis   morals,ethics,strategic interaction,game theory,behavior,economics,philosophy   evolutionary game theory,prostate cancer bone metastasis,chemotherapy,heterogeneity,resistance   privacy,trust,personal data,branding,data collection "," Bifurcation Mechanism Design—From Optimal Flat Taxes to Better Cancer Treatments   Ethics, Morality, and Game Theory   Fractionated Follow-Up Chemotherapy Delays the Onset of Resistance in Bone Metastatic Prostate Cancer   Generalized Trust, Need for Cognitive Closure, and the Perceived Acceptability of Personal Data Collection   Abstract
Small changes to the parameters of a system can lead to abrupt qualitative changes of its behavior, a phenomenon known as bifurcation. Such instabilities are typically considered problematic, however, we show that their power can be leveraged to design novel types of mechanisms. Hysteresis mechanisms use transient changes of system parameters to induce a permanent improvement to its performance via optimal equilibrium selection. Optimal control mechanisms induce convergence to states whose performance is better than even the best equilibrium. We apply these mechanisms in two different settings that illustrate the versatility of bifurcation mechanism design. In the first one we explore how introducing flat taxation could improve social welfare, despite decreasing agent “rationality,” by destabilizing inefficient equilibria. From there we move on to consider a well known game of tumor metabolism and use our approach to derive potential new cancer treatment strategies. View Full-Text   Abstract
Ethics is a field in which the gap between words and actions looms large. Game theory and the empirical methods it inspires look at behavior instead of the lip service people sometimes pay to norms. We believe that this special issue comprises several illustrations of the fruitful application of this approach to ethics. View Full-Text   Abstract
Prostate cancer to bone metastases are almost always lethal. This results from the ability of metastatic prostate cancer cells to co-opt bone remodeling, leading to what is known as the vicious cycle. Understanding how tumor cells can disrupt bone homeostasis through their interactions with the stroma and how metastatic tumors respond to treatment is key to the development of new treatments for what remains an incurable disease. Here we describe an evolutionary game theoretical model of both the homeostatic bone remodeling and its co-option by prostate cancer metastases. This model extends past the evolutionary aspects typically considered in game theoretical models by also including ecological factors such as the physical microenvironment of the bone. Our model recapitulates the current paradigm of the “vicious cycle” driving tumor growth and sheds light on the interactions of heterogeneous tumor cells with the bone microenvironment and treatment response. Our results show that resistant populations naturally become dominant in the metastases under conventional cytotoxic treatment and that novel schedules could be used to better control the tumor and the associated bone disease compared to the current standard of care. Specifically, we introduce fractionated follow up therapy—chemotherapy where dosage is administered initially in one solid block followed by alternating smaller doses and holidays—and argue that it is better than either a continuous application or a periodic one. Furthermore, we also show that different regimens of chemotherapy can lead to different amounts of pathological bone that are known to correlate with poor quality of life for bone metastatic prostate cancer patients. View Full-Text   Abstract
This vignette-based study examines how generalized trust and the need for cognitive closure relate to the perceived acceptability of contemporary business methods of personal data collection. Subjects are exposed to four scenarios that describe a method of personal data collection, involving either brand-name companies or generic descriptors of companies. After each scenario, subjects rate how acceptable they find the practice of data collection, along with the frequency and quality of experiences that they have had with the company (for brand names) or type of company (for generic descriptors). Judgments of perceived acceptability are analyzed, both across the portfolio of judgments and within each separate scenario. While analyses of each separate scenario point to the context-dependency of the perceived acceptability of data collection, several results stand out when analyzing the subjects’ portfolios of responses in the aggregate. Higher generalized trust is linked to a higher average acceptability rating, and the effect is stronger when companies are described with brand names rather than generic descriptors. Uniformly, however, no relationship is found between need for cognitive closure and perceived acceptability. Additionally, positive experiences are found to be a stronger predictor of perceived acceptability of data collection than frequency of use. View Full-Text   game theory,cancer,economics,hysteresis   morals,ethics,strategic interaction,game theory,behavior,economics,philosophy   evolutionary game theory,prostate cancer bone metastasis,chemotherapy,heterogeneity,resistance   privacy,trust,personal data,branding,data collection ", Games 
 Diluted Sugar Mill Effluent Application with PGPR Improves the Performance of Maize (Zea mays L.) under an Arid Climate   The Effects of Rice Straw and Biochar Applications on the Microbial Community in a Soil with a History of Continuous Tomato Planting History   Alleviation of Drought Stress by Nitrogen Application in Brassica campestris ssp. Chinensis L. ," Abstract
The disposal of sugar mill effluent is a serious matter of concern for the sugar industry. In this regard, the dilution of sugar mill effluent in combination with plant growth promoting rhizobacteria (PGPR) might be a viable option for improving crop growth. In this study, we evaluated the potential of diluted sugar mill effluent (SME) and PGPR to improve maize (Zea mays L.) performance. Seeds of a maize hybrid (Pioneer 1543) were sown in 20 kg soil-filled pots. The pots were irrigated with various sugar mill effluent concentrations (viz. 0, 15%, 30%, 45%, 60%, 75% and 100% v/v). The results indicated that application of SME up to a concentration of 75% improved the stay-green, leaf emergence, growth and productivity of maize. However, the application of SME at a concentration of 100% was detrimental for maize plants and decreased the maize growth. The application of PGPR was also beneficial for improvement in stay-green, leaf emergence, growth and productivity of maize as compared with control (no PGPR application). In conclusion, the use of SME at concentration of 75% in combination with PGPR was the most effective method for improvement in stay-green, leaf emergence, growth and productivity of maize. View Full-Text   Abstract
Soil microbial abundance and diversity change constantly in continuous cropping systems, resulting in the prevalence of soil-borne pathogens and a decline in crop yield in solar greenhouses. To investigate the effects of rice straw and biochar on soil microbial abundance and diversity in soils with a history of continuous planting, three treatments were examined: mixed rice straw and biochar addition (RC), rice straw addition (R), and biochar addition (C). The amount of C added in each treatment group was 3.78 g kg−1 soil. Soil without rice straw and biochar addition was treated as a control (CK). Results showed that RC treatment significantly increased soil pH, available nitrogen (AN), available phosphorus (AP), and potassium (AK) by 40.3%, 157.2%, and 24.2%, respectively, as compared to the CK soil. The amount of soil labile organic carbon (LOC), including readily oxidizable organic carbon (ROC), dissolved organic carbon (DOC), and light fraction organic carbon (LFOC), was significantly greater in the RC, R, and C treatment groups as compared to CK soil. LOC levels with RC treatment were higher than with the other treatments. Both rice straw and biochar addition significantly increased bacterial and total microbial abundance, whereas rice straw but not biochar addition improved soil microbial carbon metabolism and diversity. Thus, the significant effects of rice straw and biochar on soil microbial carbon metabolism and diversity were attributed to the quantity of DOC in the treatments. Therefore, our results indicated that soil microbial diversity is directly associated with DOC. Based on the results of this study, mixed rice straw and biochar addition, rather than their application individually, might be key to restoring degraded soil. View Full-Text   Abstract
To assess the influence of drought stress on the growth and nitrogen nutrition status of pakchoi (Brassica campestris ssp. Chinensis L.) at different nitrogen (N) levels, the changes in N accumulation and enzyme activities involved in N assimilation were investigated. The drought was induced by adding polyethylene glycol (PEG) under hydroponic culture conditions. Pakchoi seedlings were exposed to a modified nutrient solution with different nitrogen concentration (N1, N2, and N3 represent 2, 9 and 18 mM NaNO3, respectively) and osmotic potential (W1, W2 and W3 represent 0, 60 and 120 g·L−1 PEG 6000) in a full factorial, replicated randomized block design. A short time (seven days) of drought stress caused a significant decline in plant water content, transpiration rate, shoot biomass and shoot nitrogen concentration. Increasing N availability considerably alleviate drought stress by increasing the content of total free amino acids in the roots, promoting the acceleration of root biomass accumulation, and improving the activities of nitrate reductase (NR; EC 1.7.1.1) and glutamine synthetase (GS; EC 6.3.1.2) which would reduce moisture limitations. The results suggested that pakchoi supplied with relative higher N had better growth performance under drought stress. View Full-Text "," diluted sugar mill effluent,maize,stay-green,leaf emergence,PGPR,arid climate   rice straw,biochar,soil chemical and microbial properties,soil labile organic carbon,tomato,continuous cropping   pakchoi,drought stress,nitrogen concentration,enzyme activities,leafy vegetable "," Diluted Sugar Mill Effluent Application with PGPR Improves the Performance of Maize (Zea mays L.) under an Arid Climate   The Effects of Rice Straw and Biochar Applications on the Microbial Community in a Soil with a History of Continuous Tomato Planting History   Alleviation of Drought Stress by Nitrogen Application in Brassica campestris ssp. Chinensis L.   Abstract
The disposal of sugar mill effluent is a serious matter of concern for the sugar industry. In this regard, the dilution of sugar mill effluent in combination with plant growth promoting rhizobacteria (PGPR) might be a viable option for improving crop growth. In this study, we evaluated the potential of diluted sugar mill effluent (SME) and PGPR to improve maize (Zea mays L.) performance. Seeds of a maize hybrid (Pioneer 1543) were sown in 20 kg soil-filled pots. The pots were irrigated with various sugar mill effluent concentrations (viz. 0, 15%, 30%, 45%, 60%, 75% and 100% v/v). The results indicated that application of SME up to a concentration of 75% improved the stay-green, leaf emergence, growth and productivity of maize. However, the application of SME at a concentration of 100% was detrimental for maize plants and decreased the maize growth. The application of PGPR was also beneficial for improvement in stay-green, leaf emergence, growth and productivity of maize as compared with control (no PGPR application). In conclusion, the use of SME at concentration of 75% in combination with PGPR was the most effective method for improvement in stay-green, leaf emergence, growth and productivity of maize. View Full-Text   Abstract
Soil microbial abundance and diversity change constantly in continuous cropping systems, resulting in the prevalence of soil-borne pathogens and a decline in crop yield in solar greenhouses. To investigate the effects of rice straw and biochar on soil microbial abundance and diversity in soils with a history of continuous planting, three treatments were examined: mixed rice straw and biochar addition (RC), rice straw addition (R), and biochar addition (C). The amount of C added in each treatment group was 3.78 g kg−1 soil. Soil without rice straw and biochar addition was treated as a control (CK). Results showed that RC treatment significantly increased soil pH, available nitrogen (AN), available phosphorus (AP), and potassium (AK) by 40.3%, 157.2%, and 24.2%, respectively, as compared to the CK soil. The amount of soil labile organic carbon (LOC), including readily oxidizable organic carbon (ROC), dissolved organic carbon (DOC), and light fraction organic carbon (LFOC), was significantly greater in the RC, R, and C treatment groups as compared to CK soil. LOC levels with RC treatment were higher than with the other treatments. Both rice straw and biochar addition significantly increased bacterial and total microbial abundance, whereas rice straw but not biochar addition improved soil microbial carbon metabolism and diversity. Thus, the significant effects of rice straw and biochar on soil microbial carbon metabolism and diversity were attributed to the quantity of DOC in the treatments. Therefore, our results indicated that soil microbial diversity is directly associated with DOC. Based on the results of this study, mixed rice straw and biochar addition, rather than their application individually, might be key to restoring degraded soil. View Full-Text   Abstract
To assess the influence of drought stress on the growth and nitrogen nutrition status of pakchoi (Brassica campestris ssp. Chinensis L.) at different nitrogen (N) levels, the changes in N accumulation and enzyme activities involved in N assimilation were investigated. The drought was induced by adding polyethylene glycol (PEG) under hydroponic culture conditions. Pakchoi seedlings were exposed to a modified nutrient solution with different nitrogen concentration (N1, N2, and N3 represent 2, 9 and 18 mM NaNO3, respectively) and osmotic potential (W1, W2 and W3 represent 0, 60 and 120 g·L−1 PEG 6000) in a full factorial, replicated randomized block design. A short time (seven days) of drought stress caused a significant decline in plant water content, transpiration rate, shoot biomass and shoot nitrogen concentration. Increasing N availability considerably alleviate drought stress by increasing the content of total free amino acids in the roots, promoting the acceleration of root biomass accumulation, and improving the activities of nitrate reductase (NR; EC 1.7.1.1) and glutamine synthetase (GS; EC 6.3.1.2) which would reduce moisture limitations. The results suggested that pakchoi supplied with relative higher N had better growth performance under drought stress. View Full-Text   diluted sugar mill effluent,maize,stay-green,leaf emergence,PGPR,arid climate   rice straw,biochar,soil chemical and microbial properties,soil labile organic carbon,tomato,continuous cropping   pakchoi,drought stress,nitrogen concentration,enzyme activities,leafy vegetable ", Agronomy 
" Patient-Derived iPSCs and iNs—Shedding New Light on the Cellular Etiology of Neurodegenerative Diseases   Autophagy in Age-Associated Neurodegeneration   Reactive Oxygen Species, Superoxide Dimutases, and PTEN-p53-AKT-MDM2 Signaling Loop Network in Mesenchymal Stem/Stromal Cells Regulation "," Abstract
Induced pluripotent stem cells (iPSCs) and induced neuronal (iN) cells are very much touted in terms of their potential promises in therapeutics. However, from a more fundamental perspective, iPSCs and iNs are invaluable tools for the postnatal generation of specific diseased cell types from patients, which may offer insights into disease etiology that are otherwise unobtainable with available animal or human proxies. There are two good recent examples of such important insights with diseased neurons derived via either the iPSC or iN approaches. In one, induced motor neurons (iMNs) derived from iPSCs of Amyotrophic lateral sclerosis/Frontotemporal dementia (ALS/FTD) patients with a C9orf72 repeat expansion revealed a haploinsufficiency of protein function resulting from the intronic expansion and deficiencies in motor neuron vesicular trafficking and lysosomal biogenesis that were not previously obvious in knockout mouse models. In another, striatal medium spinal neurons (MSNs) derived directly from fibroblasts of Huntington’s disease (HD) patients recapitulated age-associated disease signatures of mutant Huntingtin (mHTT) aggregation and neurodegeneration that were not prominent in neurons differentiated indirectly via iPSCs from HD patients. These results attest to the tremendous potential for pathologically accurate and mechanistically revealing disease modelling with advances in the derivation of iPSCs and iNs. View Full-Text   Abstract
The elimination of abnormal and dysfunctional cellular constituents is an essential prerequisite for nerve cells to maintain their homeostasis and proper function. This is mainly achieved through autophagy, a process that eliminates abnormal and dysfunctional cellular components, including misfolded proteins and damaged organelles. Several studies suggest that age-related decline of autophagy impedes neuronal homeostasis and, subsequently, leads to the progression of neurodegenerative disorders due to the accumulation of toxic protein aggregates in neurons. Here, we discuss the involvement of autophagy perturbation in neurodegeneration and present evidence indicating that upregulation of autophagy holds potential for the development of therapeutic interventions towards confronting neurodegenerative diseases in humans. View Full-Text   Abstract
Mesenchymal stromal/stem cells (MSCs) are multipotent cells that can differentiate to various specialized cells, which have the potential capacity to differentiate properly and accelerate recovery in damaged sites of the body. This stem cell technology has become the fundamental element in regenerative medicine. As reactive oxygen species (ROS) have been reported to adversely influence stem cell properties, it is imperative to attenuate the extent of ROS to the promising protective approach with MSCs’ regenerative therapy. Oxidative stress also affects the culture expansion and longevity of MSCs. Therefore, there is great need to identify a method to prevent oxidative stress and replicative senescence in MSCs. Phosphatase and tensin homologue deleted on chromosome 10/Protein kinase B, PKB (PTEN/AKT) and the tumor suppressor p53 pathway have been proven to play a pivotal role in regulating cell apoptosis by regulating the oxidative stress and/or ROS quenching. In this review, we summarize the current research and our view of how PTEN/AKT and p53 with their partners transduce signals downstream, and what the implications are for MSCs’ biology. View Full-Text "," induced pluripotent stem cells (iPSCs),induced neuronal (iN) cells,C9ORF72,Huntingtin,amyotrophic lateral sclerosis (ALS),Huntington’s disease,neurodegenerative diseases   ageing,Alzheimer’s disease,amyotrophic lateral sclerosis,autophagy,Huntington’s disease,mitophagy,neurodegeneration,Parkinson’s sisease,protein aggregation,treatment   p53,PTEN,AKT,MDM2,superoxide dismutase,SOD,reactive oxygen species,ROS,mesenchymal stromal/stem cell,MSC,stemness "," Patient-Derived iPSCs and iNs—Shedding New Light on the Cellular Etiology of Neurodegenerative Diseases   Autophagy in Age-Associated Neurodegeneration   Reactive Oxygen Species, Superoxide Dimutases, and PTEN-p53-AKT-MDM2 Signaling Loop Network in Mesenchymal Stem/Stromal Cells Regulation   Abstract
Induced pluripotent stem cells (iPSCs) and induced neuronal (iN) cells are very much touted in terms of their potential promises in therapeutics. However, from a more fundamental perspective, iPSCs and iNs are invaluable tools for the postnatal generation of specific diseased cell types from patients, which may offer insights into disease etiology that are otherwise unobtainable with available animal or human proxies. There are two good recent examples of such important insights with diseased neurons derived via either the iPSC or iN approaches. In one, induced motor neurons (iMNs) derived from iPSCs of Amyotrophic lateral sclerosis/Frontotemporal dementia (ALS/FTD) patients with a C9orf72 repeat expansion revealed a haploinsufficiency of protein function resulting from the intronic expansion and deficiencies in motor neuron vesicular trafficking and lysosomal biogenesis that were not previously obvious in knockout mouse models. In another, striatal medium spinal neurons (MSNs) derived directly from fibroblasts of Huntington’s disease (HD) patients recapitulated age-associated disease signatures of mutant Huntingtin (mHTT) aggregation and neurodegeneration that were not prominent in neurons differentiated indirectly via iPSCs from HD patients. These results attest to the tremendous potential for pathologically accurate and mechanistically revealing disease modelling with advances in the derivation of iPSCs and iNs. View Full-Text   Abstract
The elimination of abnormal and dysfunctional cellular constituents is an essential prerequisite for nerve cells to maintain their homeostasis and proper function. This is mainly achieved through autophagy, a process that eliminates abnormal and dysfunctional cellular components, including misfolded proteins and damaged organelles. Several studies suggest that age-related decline of autophagy impedes neuronal homeostasis and, subsequently, leads to the progression of neurodegenerative disorders due to the accumulation of toxic protein aggregates in neurons. Here, we discuss the involvement of autophagy perturbation in neurodegeneration and present evidence indicating that upregulation of autophagy holds potential for the development of therapeutic interventions towards confronting neurodegenerative diseases in humans. View Full-Text   Abstract
Mesenchymal stromal/stem cells (MSCs) are multipotent cells that can differentiate to various specialized cells, which have the potential capacity to differentiate properly and accelerate recovery in damaged sites of the body. This stem cell technology has become the fundamental element in regenerative medicine. As reactive oxygen species (ROS) have been reported to adversely influence stem cell properties, it is imperative to attenuate the extent of ROS to the promising protective approach with MSCs’ regenerative therapy. Oxidative stress also affects the culture expansion and longevity of MSCs. Therefore, there is great need to identify a method to prevent oxidative stress and replicative senescence in MSCs. Phosphatase and tensin homologue deleted on chromosome 10/Protein kinase B, PKB (PTEN/AKT) and the tumor suppressor p53 pathway have been proven to play a pivotal role in regulating cell apoptosis by regulating the oxidative stress and/or ROS quenching. In this review, we summarize the current research and our view of how PTEN/AKT and p53 with their partners transduce signals downstream, and what the implications are for MSCs’ biology. View Full-Text   induced pluripotent stem cells (iPSCs),induced neuronal (iN) cells,C9ORF72,Huntingtin,amyotrophic lateral sclerosis (ALS),Huntington’s disease,neurodegenerative diseases   ageing,Alzheimer’s disease,amyotrophic lateral sclerosis,autophagy,Huntington’s disease,mitophagy,neurodegeneration,Parkinson’s sisease,protein aggregation,treatment   p53,PTEN,AKT,MDM2,superoxide dismutase,SOD,reactive oxygen species,ROS,mesenchymal stromal/stem cell,MSC,stemness ", Cells 
 Land Use Scenario Modeling Based on Local Knowledge for the Provision of Ecosystem Services in Northern Ghana   Merging Small Scattered Pastures into Large Pasture-Forest Mosaics Can Improve Profitability in Swedish Suckler-Based Beef Production ," Abstract
The understanding of multiple effects by possible future development is essential for adapted land use planning. This study assessed the potential of land use scenarios for the provision of ecosystem services using local knowledge in two districts of northern Ghana. Local knowledge was gathered through surveys with extension officers, who are regarded as eligible knowledge holders for agricultural land use. Firstly, ecosystem services that were perceived as important by the stakeholders were identified, namely food, fodder, energy, construction materials, marketable products, water provision, and erosion control. Quantitative indicators were then determined to analyze the capacity of land use types to supply the ecosystem services. Land use scenarios were developed based on their applicability and capacity to mitigate climate change impacts. The perception of stakeholders was applied to evaluate changes in ecosystem services provision by the scenarios. A modeling approach for a spatially explicit simulation was used to assess the potential to provide ecosystem services at a district level. The results reflected the different trade-offs and synergies between ecosystem services of each scenario, depending on the district. Along with the local perception, characteristics of land use patterns also influenced the regional potential of ecosystem services provision. View Full-Text   Abstract
A scattered structure of small pastures has negative effects on profitability in beef enterprises because small enclosures result in high labor costs per livestock unit. Moreover, larger enterprises distribute the costs across more livestock units and hence achieve lower operating costs. Creating larger coherent pastures makes it easier to increase herd size and yields positive effects due to economies of scale. This study on five Swedish organic cow-calf enterprises examined how profitability is affected by creating larger pastures from small scattered pastures and adjacent forest land. Additional income, additional costs, reduced income and reduced costs were taken into account using a partial budgeting technique. A change to larger coherent pastures was found to be profitable for all enterprises examined. Agri-environmental payments and supports were the most important benefit from creating larger pastures, followed by income increases and cost reductions resulting from economies of scale and improved consolidation. Income reductions due to premature final felling (clearcutting of forest land) and the opportunity cost of forest land did not have a major influence. To conclude, creating large coherent pasture-forest mosaics by merging small scattered enclosures is profitable for Swedish organic cow-calf enterprises. View Full-Text "," land use change,stakeholder,participation,planning,climate change impact,modeling,trade-off,synergy,transdisciplinarity,agriculture,West Africa   pasture,semi-natural grassland,pasture-forest mosaic,cow-calf,beef,cattle,cow,economic,profitability,consolidation "," Land Use Scenario Modeling Based on Local Knowledge for the Provision of Ecosystem Services in Northern Ghana   Merging Small Scattered Pastures into Large Pasture-Forest Mosaics Can Improve Profitability in Swedish Suckler-Based Beef Production   Abstract
The understanding of multiple effects by possible future development is essential for adapted land use planning. This study assessed the potential of land use scenarios for the provision of ecosystem services using local knowledge in two districts of northern Ghana. Local knowledge was gathered through surveys with extension officers, who are regarded as eligible knowledge holders for agricultural land use. Firstly, ecosystem services that were perceived as important by the stakeholders were identified, namely food, fodder, energy, construction materials, marketable products, water provision, and erosion control. Quantitative indicators were then determined to analyze the capacity of land use types to supply the ecosystem services. Land use scenarios were developed based on their applicability and capacity to mitigate climate change impacts. The perception of stakeholders was applied to evaluate changes in ecosystem services provision by the scenarios. A modeling approach for a spatially explicit simulation was used to assess the potential to provide ecosystem services at a district level. The results reflected the different trade-offs and synergies between ecosystem services of each scenario, depending on the district. Along with the local perception, characteristics of land use patterns also influenced the regional potential of ecosystem services provision. View Full-Text   Abstract
A scattered structure of small pastures has negative effects on profitability in beef enterprises because small enclosures result in high labor costs per livestock unit. Moreover, larger enterprises distribute the costs across more livestock units and hence achieve lower operating costs. Creating larger coherent pastures makes it easier to increase herd size and yields positive effects due to economies of scale. This study on five Swedish organic cow-calf enterprises examined how profitability is affected by creating larger pastures from small scattered pastures and adjacent forest land. Additional income, additional costs, reduced income and reduced costs were taken into account using a partial budgeting technique. A change to larger coherent pastures was found to be profitable for all enterprises examined. Agri-environmental payments and supports were the most important benefit from creating larger pastures, followed by income increases and cost reductions resulting from economies of scale and improved consolidation. Income reductions due to premature final felling (clearcutting of forest land) and the opportunity cost of forest land did not have a major influence. To conclude, creating large coherent pasture-forest mosaics by merging small scattered enclosures is profitable for Swedish organic cow-calf enterprises. View Full-Text   land use change,stakeholder,participation,planning,climate change impact,modeling,trade-off,synergy,transdisciplinarity,agriculture,West Africa   pasture,semi-natural grassland,pasture-forest mosaic,cow-calf,beef,cattle,cow,economic,profitability,consolidation ", Land 
 Small-Format Drug Conjugates: A Viable Alternative to ADCs for Solid Tumours?   Hydrophilic Auristatin Glycoside Payload Enables Improved Antibody-Drug Conjugate Efficacy and Biocompatibility   Infusion Reactions Associated with the Medical Application of Monoclonal Antibodies: The Role of Complement Activation and Possibility of Inhibition by Factor H ," Abstract
Antibody–Drug Conjugates (ADCs) have been through multiple cycles of technological innovation since the concept was first practically demonstrated ~40 years ago. Current technology is focusing on large, whole immunoglobulin formats (of which there are approaching 100 in clinical development), many with site-specifically conjugated payloads numbering 2 or 4. Despite the success of trastuzumab-emtansine in breast cancer, ADCs have generally failed to have an impact in solid tumours, leading many to explore alternative, smaller formats which have better penetrating properties as well as more rapid pharmacokinetics (PK). This review describes research and development progress over the last ~10 years obtained from the primary literature or conferences covering over a dozen different smaller format-drug conjugates from 80 kDa to around 1 kDa in total size. In general, these agents are potent in vitro, particularly more recent ones incorporating ultra-potent payloads such as auristatins or maytansinoids, but this potency profile changes when testing in vivo due to the more rapid clearance. Strategies to manipulate the PK properties, whilst retaining the more effective tumour penetrating properties could at last make small-format drug conjugates viable alternative therapeutics to the more established ADCs. View Full-Text   Abstract
Antibody-drug conjugates (ADCs) offer a combination of antibody therapy and specific delivery of potent small-molecule payloads to target cells. The properties of the ADC molecule are determined by the balance of its components. The efficacy of the payload component increases with higher drug-to-antibody ratio (DAR), while homogeneous DAR = 8 ADCs are easily prepared by conjugation to the four accessible antibody hinge cystines. However, use of hydrophobic payloads has permitted only DAR = 2–4, due to poor pharmacokinetics and aggregation problems. Here, we describe generation and characterization of homogeneous DAR = 8 ADCs carrying a novel auristatin β-D-glucuronide, MMAU. The glycoside payload contributed to overall hydrophilicity of the ADC reducing aggregation. Compared to standard DAR = 2–4 ADCs, cytotoxicity of the homogeneous DAR = 8 ADCs was improved to low-picomolar IC50 values against cancer cells in vitro. Bystander efficacy was restored after ADC internalization and subsequent cleavage of the glycoside, although unconjugated MMAU was relatively non-toxic to cells. DAR = 8 MMAU ADCs were effective against target antigen-expressing xenograft tumors. The ADCs were also studied in 3D in vitro patient-derived xenograft (PDX) assays where they outperformed clinically used ADC. In conclusion, increased hydrophilicity of the payload contributed to the ADC’s hydrophilicity, stability and safety to non-target cells, while significantly improving cytotoxicity and enabling bystander efficacy. View Full-Text   Abstract
Human application of monoclonal antibodies (mAbs), enzymes, as well as contrast media and many other particulate drugs and agents referred to as “nanomedicines”, can initiate pseudoallergic hypersensitivity reactions, also known as infusion reactions. These may in part be mediated by the activation of the complement system, a major humoral defense system of innate immunity. In this review, we provide a brief outline of complement activation-related pseudoallergy (CARPA) in general, and then focus on the reactions caused by mAb therapy. Because the alternative pathway of complement activation may amplify such adverse reactions, we highlight the potential use of complement factor H as an inhibitor of CARPA. View Full-Text "," antibody–drug conjugate,fragment,alternative scaffold,penetration,pharmacokinetics   glycoside,auristatin,MMAE,MMAU,ADC,hydrophilicity,therapeutic window   CARPA,complement,complement activation,factor H,hypersensitivity,infusion reaction,monoclonal antibody therapy,pseudoallergic reaction "," Small-Format Drug Conjugates: A Viable Alternative to ADCs for Solid Tumours?   Hydrophilic Auristatin Glycoside Payload Enables Improved Antibody-Drug Conjugate Efficacy and Biocompatibility   Infusion Reactions Associated with the Medical Application of Monoclonal Antibodies: The Role of Complement Activation and Possibility of Inhibition by Factor H   Abstract
Antibody–Drug Conjugates (ADCs) have been through multiple cycles of technological innovation since the concept was first practically demonstrated ~40 years ago. Current technology is focusing on large, whole immunoglobulin formats (of which there are approaching 100 in clinical development), many with site-specifically conjugated payloads numbering 2 or 4. Despite the success of trastuzumab-emtansine in breast cancer, ADCs have generally failed to have an impact in solid tumours, leading many to explore alternative, smaller formats which have better penetrating properties as well as more rapid pharmacokinetics (PK). This review describes research and development progress over the last ~10 years obtained from the primary literature or conferences covering over a dozen different smaller format-drug conjugates from 80 kDa to around 1 kDa in total size. In general, these agents are potent in vitro, particularly more recent ones incorporating ultra-potent payloads such as auristatins or maytansinoids, but this potency profile changes when testing in vivo due to the more rapid clearance. Strategies to manipulate the PK properties, whilst retaining the more effective tumour penetrating properties could at last make small-format drug conjugates viable alternative therapeutics to the more established ADCs. View Full-Text   Abstract
Antibody-drug conjugates (ADCs) offer a combination of antibody therapy and specific delivery of potent small-molecule payloads to target cells. The properties of the ADC molecule are determined by the balance of its components. The efficacy of the payload component increases with higher drug-to-antibody ratio (DAR), while homogeneous DAR = 8 ADCs are easily prepared by conjugation to the four accessible antibody hinge cystines. However, use of hydrophobic payloads has permitted only DAR = 2–4, due to poor pharmacokinetics and aggregation problems. Here, we describe generation and characterization of homogeneous DAR = 8 ADCs carrying a novel auristatin β-D-glucuronide, MMAU. The glycoside payload contributed to overall hydrophilicity of the ADC reducing aggregation. Compared to standard DAR = 2–4 ADCs, cytotoxicity of the homogeneous DAR = 8 ADCs was improved to low-picomolar IC50 values against cancer cells in vitro. Bystander efficacy was restored after ADC internalization and subsequent cleavage of the glycoside, although unconjugated MMAU was relatively non-toxic to cells. DAR = 8 MMAU ADCs were effective against target antigen-expressing xenograft tumors. The ADCs were also studied in 3D in vitro patient-derived xenograft (PDX) assays where they outperformed clinically used ADC. In conclusion, increased hydrophilicity of the payload contributed to the ADC’s hydrophilicity, stability and safety to non-target cells, while significantly improving cytotoxicity and enabling bystander efficacy. View Full-Text   Abstract
Human application of monoclonal antibodies (mAbs), enzymes, as well as contrast media and many other particulate drugs and agents referred to as “nanomedicines”, can initiate pseudoallergic hypersensitivity reactions, also known as infusion reactions. These may in part be mediated by the activation of the complement system, a major humoral defense system of innate immunity. In this review, we provide a brief outline of complement activation-related pseudoallergy (CARPA) in general, and then focus on the reactions caused by mAb therapy. Because the alternative pathway of complement activation may amplify such adverse reactions, we highlight the potential use of complement factor H as an inhibitor of CARPA. View Full-Text   antibody–drug conjugate,fragment,alternative scaffold,penetration,pharmacokinetics   glycoside,auristatin,MMAE,MMAU,ADC,hydrophilicity,therapeutic window   CARPA,complement,complement activation,factor H,hypersensitivity,infusion reaction,monoclonal antibody therapy,pseudoallergic reaction ", Antibodies 
" Yukawa Potential, Panharmonic Measure and Brownian Motion   Subordination Properties for Multivalent Functions Associated with a Generalized Fractional Differintegral Operator   Quotient Structures of BCK/BCI-Algebras Induced by Quasi-Valuation Maps "," Abstract
This paper continues our earlier investigation, where a walk-on-spheres (WOS) algorithm for Monte Carlo simulation of the solutions of the Yukawa and the Helmholtz partial differential equations (PDEs) was developed by using the Duffin correspondence. In this paper, we investigate the foundations behind the algorithm for the case of the Yukawa PDE. We study the panharmonic measure, which is a generalization of the harmonic measure for the Yukawa PDE. We show that there are natural stochastic definitions for the panharmonic measure in terms of the Brownian motion and that the harmonic and the panharmonic measures are all mutually equivalent. Furthermore, we calculate their Radon–Nikodym derivatives explicitly for some balls, which is a key result behind the WOS algorithm. View Full-Text   Abstract
Using of the principle of subordination, we investigate some subordination and convolution properties for classes of multivalent functions under certain assumptions on the parameters involved, which are defined by a generalized fractional differintegral operator under certain assumptions on the parameters involved. View Full-Text   Abstract
Relations between I-quasi-valuation maps and ideals in
BCK/BCI
-algebras are investigated. Using the notion of an I-quasi-valuation map of a
BCK/BCI
-algebra, the quasi-metric space is induced, and several properties are investigated. Relations between the I-quasi-valuation map and the I-valuation map are considered, and conditions for an I-quasi-valuation map to be an I-valuation map are provided. A congruence relation is introduced by using the I-valuation map, and then the quotient structures are established and related properties are investigated. Isomorphic quotient
BCK/BCI
-algebras are discussed. View Full-Text "," potential theory,Brownian motion,Duffin correspondence,harmonic measure,Bessel functions,Monte Carlo simulation,panharmonic measure,walk-on-spheres algorithm,Yukawa equation   differential subordination,p-valent functions,generalized fractional differintegral operator   ideal,I-quasi-valuation map,I-valuation map,quasi-metric "," Yukawa Potential, Panharmonic Measure and Brownian Motion   Subordination Properties for Multivalent Functions Associated with a Generalized Fractional Differintegral Operator   Quotient Structures of BCK/BCI-Algebras Induced by Quasi-Valuation Maps   Abstract
This paper continues our earlier investigation, where a walk-on-spheres (WOS) algorithm for Monte Carlo simulation of the solutions of the Yukawa and the Helmholtz partial differential equations (PDEs) was developed by using the Duffin correspondence. In this paper, we investigate the foundations behind the algorithm for the case of the Yukawa PDE. We study the panharmonic measure, which is a generalization of the harmonic measure for the Yukawa PDE. We show that there are natural stochastic definitions for the panharmonic measure in terms of the Brownian motion and that the harmonic and the panharmonic measures are all mutually equivalent. Furthermore, we calculate their Radon–Nikodym derivatives explicitly for some balls, which is a key result behind the WOS algorithm. View Full-Text   Abstract
Using of the principle of subordination, we investigate some subordination and convolution properties for classes of multivalent functions under certain assumptions on the parameters involved, which are defined by a generalized fractional differintegral operator under certain assumptions on the parameters involved. View Full-Text   Abstract
Relations between I-quasi-valuation maps and ideals in
BCK/BCI
-algebras are investigated. Using the notion of an I-quasi-valuation map of a
BCK/BCI
-algebra, the quasi-metric space is induced, and several properties are investigated. Relations between the I-quasi-valuation map and the I-valuation map are considered, and conditions for an I-quasi-valuation map to be an I-valuation map are provided. A congruence relation is introduced by using the I-valuation map, and then the quotient structures are established and related properties are investigated. Isomorphic quotient
BCK/BCI
-algebras are discussed. View Full-Text   potential theory,Brownian motion,Duffin correspondence,harmonic measure,Bessel functions,Monte Carlo simulation,panharmonic measure,walk-on-spheres algorithm,Yukawa equation   differential subordination,p-valent functions,generalized fractional differintegral operator   ideal,I-quasi-valuation map,I-valuation map,quasi-metric ", Axioms 
 Use of the Adjoint Method for Controlling the Mechanical Vibrations of Nonlinear Systems   Obstacle Avoidance System for Unmanned Ground Vehicles by Using Ultrasonic Sensors   Development of a Methodology for Condition-Based Maintenance in a Large-Scale Application Field   Influence of Hub Parameters on Joining Forces and Torque Transmission Output of Plastically-Joined Shaft-Hub-Connections with a Knurled Contact Surface ," Abstract
In this work, the analytical derivation and the computer implementation of the adjoint method are described. The adjoint method can be effectively used for solving the optimal control problem associated with a large class of nonlinear mechanical systems. As discussed in this investigation, the adjoint method represents a broad computational framework, rather than a single numerical algorithm, in which the control problem for nonlinear dynamical systems can be effectively formulated and implemented employing a set of advanced analytical methods as well as an array of well-established numerical procedures. A detailed theoretical derivation and a comprehensive description of the numerical algorithm suitable for the computer implementation of the methodology used for performing the adjoint analysis are provided in the paper. For this purpose, two important cases are analyzed in this work, namely the design of a feedforward control scheme and the development of a feedback control architecture. In this investigation, the control problem relative to the mechanical vibrations of a nonlinear oscillator characterized by a generalized Van der Pol damping model is considered in order to illustrate the effectiveness of the computational algorithm based on the adjoint method by means of numerical experiments. View Full-Text   Abstract
Artificial intelligence is the ability of a computer to perform the functions and reasoning typical of the human mind. In its purely informatic aspect, it includes the theory and techniques for the development of algorithms that allow machines to show an intelligent ability and/or perform an intelligent activity, at least in specific areas. In particular, there are automatic learning algorithms based on the same mechanisms that are thought to be the basis of all the cognitive processes developed by the human brain. Such a powerful tool has already started to produce a new class of self-driving vehicles. With the projections of population growth that will increase until the year 2100 up to 11.2 billion, research on innovating agricultural techniques must be continued. In order to improve the efficiency regarding precision agriculture, the use of autonomous agricultural machines must become an important issue. For this reason, it was decided to test the use of the “Neural Network Toolbox” tool already present in MATLAB to design an artificial neural network with supervised learning suitable for classification and pattern recognition by using data collected by an ultrasonic sensor. The idea is to use such a protocol to retrofit kits for agricultural machines already present on the market. View Full-Text   Abstract
This paper describes a methodology, developed by the authors, for condition monitoring and diagnostics of several critical components in the large-scale applications with machines. For industry, the main target of condition monitoring is to prevent the machine stopping suddenly and thus avoid economic losses due to lack of production. Once the target is reached at a local level, usually through an R&D project, the extension to a large-scale market gives rise to new goals, such as low computational costs for analysis, easily interpretable results by local technicians, collection of data from worldwide machine installations, and the development of historical datasets to improve methodology, etc. This paper details an approach to condition monitoring, developed together with a multinational corporation, that covers all the critical points mentioned above. View Full-Text   Abstract
A knurled interference fit is a machine part connection made by a plastic joining, which includes the advantages of commonly-used shaft-hub-connections. The combination of the friction and form fit, which are responsible for torque transmission, results in a higher power density than conventional connections. In this paper, parameter gaps are bridged with the aim of enhance the design calculation of the knurled interference fit. Experimental investigations on the shaft chamfer angle (100Cr6) and hub-diameter-ratio (AlSi1MgMn) were performed. The analytical approaches are developed for calculating the joining force and maximal torque capacity by accounting for experimentally investigated loss of load transmission at high hub-diameter-ratios and high shaft chamfer angles. The presented calculation approach is an accurate tool for the assessment of early machine designs of the knurled interference fit and helps to save from having to perform time-extensive tests. View Full-Text "," adjoint method,nonlinear optimal control,open-loop control scheme,closed-loop control scheme,nonlinear mechanical vibrations,generalized Van der Pol damping model   object recognition,neural network,unmanned vehicle,MATLAB,ultrasonic sensors   condition monitoring,data-driven diagnostics,model-based diagnostics   knurled interference fit,shaft-hub-connection,joining by plastic forming,torque capacity,joining force,drive train "," Use of the Adjoint Method for Controlling the Mechanical Vibrations of Nonlinear Systems   Obstacle Avoidance System for Unmanned Ground Vehicles by Using Ultrasonic Sensors   Development of a Methodology for Condition-Based Maintenance in a Large-Scale Application Field   Influence of Hub Parameters on Joining Forces and Torque Transmission Output of Plastically-Joined Shaft-Hub-Connections with a Knurled Contact Surface   Abstract
In this work, the analytical derivation and the computer implementation of the adjoint method are described. The adjoint method can be effectively used for solving the optimal control problem associated with a large class of nonlinear mechanical systems. As discussed in this investigation, the adjoint method represents a broad computational framework, rather than a single numerical algorithm, in which the control problem for nonlinear dynamical systems can be effectively formulated and implemented employing a set of advanced analytical methods as well as an array of well-established numerical procedures. A detailed theoretical derivation and a comprehensive description of the numerical algorithm suitable for the computer implementation of the methodology used for performing the adjoint analysis are provided in the paper. For this purpose, two important cases are analyzed in this work, namely the design of a feedforward control scheme and the development of a feedback control architecture. In this investigation, the control problem relative to the mechanical vibrations of a nonlinear oscillator characterized by a generalized Van der Pol damping model is considered in order to illustrate the effectiveness of the computational algorithm based on the adjoint method by means of numerical experiments. View Full-Text   Abstract
Artificial intelligence is the ability of a computer to perform the functions and reasoning typical of the human mind. In its purely informatic aspect, it includes the theory and techniques for the development of algorithms that allow machines to show an intelligent ability and/or perform an intelligent activity, at least in specific areas. In particular, there are automatic learning algorithms based on the same mechanisms that are thought to be the basis of all the cognitive processes developed by the human brain. Such a powerful tool has already started to produce a new class of self-driving vehicles. With the projections of population growth that will increase until the year 2100 up to 11.2 billion, research on innovating agricultural techniques must be continued. In order to improve the efficiency regarding precision agriculture, the use of autonomous agricultural machines must become an important issue. For this reason, it was decided to test the use of the “Neural Network Toolbox” tool already present in MATLAB to design an artificial neural network with supervised learning suitable for classification and pattern recognition by using data collected by an ultrasonic sensor. The idea is to use such a protocol to retrofit kits for agricultural machines already present on the market. View Full-Text   Abstract
This paper describes a methodology, developed by the authors, for condition monitoring and diagnostics of several critical components in the large-scale applications with machines. For industry, the main target of condition monitoring is to prevent the machine stopping suddenly and thus avoid economic losses due to lack of production. Once the target is reached at a local level, usually through an R&D project, the extension to a large-scale market gives rise to new goals, such as low computational costs for analysis, easily interpretable results by local technicians, collection of data from worldwide machine installations, and the development of historical datasets to improve methodology, etc. This paper details an approach to condition monitoring, developed together with a multinational corporation, that covers all the critical points mentioned above. View Full-Text   Abstract
A knurled interference fit is a machine part connection made by a plastic joining, which includes the advantages of commonly-used shaft-hub-connections. The combination of the friction and form fit, which are responsible for torque transmission, results in a higher power density than conventional connections. In this paper, parameter gaps are bridged with the aim of enhance the design calculation of the knurled interference fit. Experimental investigations on the shaft chamfer angle (100Cr6) and hub-diameter-ratio (AlSi1MgMn) were performed. The analytical approaches are developed for calculating the joining force and maximal torque capacity by accounting for experimentally investigated loss of load transmission at high hub-diameter-ratios and high shaft chamfer angles. The presented calculation approach is an accurate tool for the assessment of early machine designs of the knurled interference fit and helps to save from having to perform time-extensive tests. View Full-Text   adjoint method,nonlinear optimal control,open-loop control scheme,closed-loop control scheme,nonlinear mechanical vibrations,generalized Van der Pol damping model   object recognition,neural network,unmanned vehicle,MATLAB,ultrasonic sensors   condition monitoring,data-driven diagnostics,model-based diagnostics   knurled interference fit,shaft-hub-connection,joining by plastic forming,torque capacity,joining force,drive train ", Machines 
 Cystobasidium alpinum sp. nov. and Rhodosporidiobolus oreadorum sp. nov. from European Cold Environments and Arctic Region   Reporting Key Features in Cold-Adapted Bacteria   Potential Role of Inorganic Confined Environments in Prebiotic Phosphorylation   The Prevailing Catalytic Role of Meteorites in Formamide Prebiotic Processes ," Abstract
Over 80% of the Earth’s environments are permanently or periodically exposed to temperatures below 5 °C. Cold habitats harbour a wide diversity of psychrophilic and psychrotolerant yeasts. During ecological studies of yeast communities carried out in cold ecosystem in the Italian Alps, Svalbard (Norway, Arctic region), and Portugal, 23 yeast strains that could not be assigned to any known fungal taxa were isolated. In particular, two of them were first identified as Rhodotorula sp., showing the highest degree of D1/D2 sequence identity with Cystobasidum laryngis accounted to only 97% with the type strain (C. laryngis CBS 2221). The other 21 strains, exhibiting identical D1/D2 sequences, had low identity (97%) with Rhodosporidiobolus lusitaniae and Rhodosporidiobolus colostri. Similarly, ITS sequences of the type strains of the most closely related species (93–94%). In a 2-genes multilocus D1/D2 and ITS ML phylogenetic tree, the studied strains pooled in two well separated and supported groups. In order to classify the new 23 isolates based on phylogenetic evidences, we propose the description of two novel species Cystobasidium alpinum sp. nov. and Rhodosporidiobolus oreadorum sp. nov. View Full-Text   Abstract
It is well known that cold environments are predominant over the Earth and there are a great number of reports analyzing bacterial adaptations to cold. Most of these works are focused on characteristics traditionally involved in cold adaptation, such as the structural adjustment of enzymes, maintenance of membrane fluidity, expression of cold shock proteins and presence of compatible solutes. Recent works based mainly on novel “omic” technologies have presented evidence of the presence of other important features to thrive in cold. In this work, we analyze cold-adapted bacteria, looking for strategies involving novel features, and/or activation of non-classical metabolisms for a cold lifestyle. Metabolic traits related to energy generation, compounds and mechanisms involved in stress resistance and cold adaptation, as well as characteristics of the cell envelope, are analyzed in heterotrophic cold-adapted bacteria. In addition, metagenomic, metatranscriptomic and metaproteomic data are used to detect key functions in bacterial communities inhabiting cold environments. View Full-Text   Abstract
A concise outlook on the potential role of confinement in phosphorylation and phosphate condensation pertaining to prebiotic chemistry is presented. Inorganic confinement is a relatively uncharted domain in studies concerning prebiotic chemistry, and even more so in terms of experimentation. However, molecular crowding within confined dimensions is central to the functioning of contemporary biology. There are numerous advantages to confined environments and an attempt to highlight this fact, within this article, has been undertaken, keeping in context the limitations of aqueous phase chemistry in phosphorylation and, to a certain extent, traditional approaches in prebiotic chemistry. View Full-Text   Abstract
Meteorites are consensually considered to be involved in the origin of life on this Planet for several functions and at different levels: (i) as providers of impact energy during their passage through the atmosphere; (ii) as agents of geodynamics, intended both as starters of the Earth’s tectonics and as activators of local hydrothermal systems upon their fall; (iii) as sources of organic materials, at varying levels of limited complexity; and (iv) as catalysts. The consensus about the relevance of these functions differs. We focus on the catalytic activities of the various types of meteorites in reactions relevant for prebiotic chemistry. Formamide was selected as the chemical precursor and various sources of energy were analyzed. The results show that all the meteorites and all the different energy sources tested actively afford complex mixtures of biologically-relevant compounds, indicating the robustness of the formamide-based prebiotic chemistry involved. Although in some cases the yields of products are quite small, the diversity of the detected compounds of biochemical significance underlines the prebiotic importance of meteorite-catalyzed condensation of formamide. View Full-Text "," Cystobasidium alpinum sp. nov.,Rhodosporidiobolus oreadorum sp. nov.,psychrophilic yeasts,Arctic,Alps,cold-adapted biodiversity   psychrophile,energy generation,polyhydroxyalkanoates,cell envelopes,cold-adapted bacterial communities   nanoscopic confinement,prebiotic chemistry,phosphorylation,hydrogels,interface   meteorites,catalysis,formamide,prebiotic chemistry,geothermal scenarios,irradiation,radical chemistry,nucleosides "," Cystobasidium alpinum sp. nov. and Rhodosporidiobolus oreadorum sp. nov. from European Cold Environments and Arctic Region   Reporting Key Features in Cold-Adapted Bacteria   Potential Role of Inorganic Confined Environments in Prebiotic Phosphorylation   The Prevailing Catalytic Role of Meteorites in Formamide Prebiotic Processes   Abstract
Over 80% of the Earth’s environments are permanently or periodically exposed to temperatures below 5 °C. Cold habitats harbour a wide diversity of psychrophilic and psychrotolerant yeasts. During ecological studies of yeast communities carried out in cold ecosystem in the Italian Alps, Svalbard (Norway, Arctic region), and Portugal, 23 yeast strains that could not be assigned to any known fungal taxa were isolated. In particular, two of them were first identified as Rhodotorula sp., showing the highest degree of D1/D2 sequence identity with Cystobasidum laryngis accounted to only 97% with the type strain (C. laryngis CBS 2221). The other 21 strains, exhibiting identical D1/D2 sequences, had low identity (97%) with Rhodosporidiobolus lusitaniae and Rhodosporidiobolus colostri. Similarly, ITS sequences of the type strains of the most closely related species (93–94%). In a 2-genes multilocus D1/D2 and ITS ML phylogenetic tree, the studied strains pooled in two well separated and supported groups. In order to classify the new 23 isolates based on phylogenetic evidences, we propose the description of two novel species Cystobasidium alpinum sp. nov. and Rhodosporidiobolus oreadorum sp. nov. View Full-Text   Abstract
It is well known that cold environments are predominant over the Earth and there are a great number of reports analyzing bacterial adaptations to cold. Most of these works are focused on characteristics traditionally involved in cold adaptation, such as the structural adjustment of enzymes, maintenance of membrane fluidity, expression of cold shock proteins and presence of compatible solutes. Recent works based mainly on novel “omic” technologies have presented evidence of the presence of other important features to thrive in cold. In this work, we analyze cold-adapted bacteria, looking for strategies involving novel features, and/or activation of non-classical metabolisms for a cold lifestyle. Metabolic traits related to energy generation, compounds and mechanisms involved in stress resistance and cold adaptation, as well as characteristics of the cell envelope, are analyzed in heterotrophic cold-adapted bacteria. In addition, metagenomic, metatranscriptomic and metaproteomic data are used to detect key functions in bacterial communities inhabiting cold environments. View Full-Text   Abstract
A concise outlook on the potential role of confinement in phosphorylation and phosphate condensation pertaining to prebiotic chemistry is presented. Inorganic confinement is a relatively uncharted domain in studies concerning prebiotic chemistry, and even more so in terms of experimentation. However, molecular crowding within confined dimensions is central to the functioning of contemporary biology. There are numerous advantages to confined environments and an attempt to highlight this fact, within this article, has been undertaken, keeping in context the limitations of aqueous phase chemistry in phosphorylation and, to a certain extent, traditional approaches in prebiotic chemistry. View Full-Text   Abstract
Meteorites are consensually considered to be involved in the origin of life on this Planet for several functions and at different levels: (i) as providers of impact energy during their passage through the atmosphere; (ii) as agents of geodynamics, intended both as starters of the Earth’s tectonics and as activators of local hydrothermal systems upon their fall; (iii) as sources of organic materials, at varying levels of limited complexity; and (iv) as catalysts. The consensus about the relevance of these functions differs. We focus on the catalytic activities of the various types of meteorites in reactions relevant for prebiotic chemistry. Formamide was selected as the chemical precursor and various sources of energy were analyzed. The results show that all the meteorites and all the different energy sources tested actively afford complex mixtures of biologically-relevant compounds, indicating the robustness of the formamide-based prebiotic chemistry involved. Although in some cases the yields of products are quite small, the diversity of the detected compounds of biochemical significance underlines the prebiotic importance of meteorite-catalyzed condensation of formamide. View Full-Text   Cystobasidium alpinum sp. nov.,Rhodosporidiobolus oreadorum sp. nov.,psychrophilic yeasts,Arctic,Alps,cold-adapted biodiversity   psychrophile,energy generation,polyhydroxyalkanoates,cell envelopes,cold-adapted bacterial communities   nanoscopic confinement,prebiotic chemistry,phosphorylation,hydrogels,interface   meteorites,catalysis,formamide,prebiotic chemistry,geothermal scenarios,irradiation,radical chemistry,nucleosides ", Life 
 Sialidosis: A Review of Morphology and Molecular Biology of a Rare Pediatric Disorder   Fine Needle Aspiration Cytology for Neck Masses in Childhood. An Illustrative Approach ," Abstract
Sialidosis (MIM 256550) is a rare, autosomal recessive inherited disorder, caused by α-N-acetyl neuraminidase deficiency resulting from a mutation in the neuraminidase gene (NEU1), located on 6p21.33. This genetic alteration leads to abnormal intracellular accumulation as well as urinary excretion of sialyloligosaccharides. A definitive diagnosis is made after the identification of a mutation in the NEU1 gene. So far, 40 mutations of NEU1 have been reported. An association exists between the impact of the individual mutations and the severity of clinical presentation of sialidosis. According to the clinical symptoms, sialidosis has been divided into two subtypes with different ages of onset and severity, including sialidosis type I (normomorphic or mild form) and sialidosis type II (dysmorphic or severe form). Sialidosis II is further subdivided into (i) congenital; (ii) infantile; and (iii) juvenile. Despite being uncommon, sialidosis has enormous clinical relevance due to its debilitating character. A complete understanding of the underlying pathology remains a challenge, which in turn limits the development of effective therapeutic strategies. Furthermore, in the last few years, some atypical cases of sialidosis have been reported as well. We herein attempt to combine and discuss the underlying molecular biology, the clinical features, and the morphological patterns of sialidosis type I and II. View Full-Text   Abstract
The primary indication of fine-needle aspiration cytology of the head and neck region is a thyroid nodule or a mass located in the cervical area or the head. Although a thyroid nodule may raise the suspicion of malignancy, less than one in 20 cases results in a carcinoma. In addition, the list of differential diagnoses is quite different according to the age of the patient. A number of benign lesions, such as branchial cysts, sialadenosis, and sialoadenitis are often seen in childhood and youth. The malignant lesions that are on the top of the list of a pediatric mass of the head and neck (H&N) region include rhabdomyosarcoma, neuroblastoma, and papillary carcinoma of the thyroid gland. This critical review of the diagnostic features of a pediatric mass of the H&N region is accompanied by panels of several cytology features that may be of help to the cytopathologist and clinician. View Full-Text "," sialidosis,neuraminidase,sialidosis I,sialidosis II,lysosomal storage disease,lysosomal exocytosis   cytopathology,head and neck,children "," Sialidosis: A Review of Morphology and Molecular Biology of a Rare Pediatric Disorder   Fine Needle Aspiration Cytology for Neck Masses in Childhood. An Illustrative Approach   Abstract
Sialidosis (MIM 256550) is a rare, autosomal recessive inherited disorder, caused by α-N-acetyl neuraminidase deficiency resulting from a mutation in the neuraminidase gene (NEU1), located on 6p21.33. This genetic alteration leads to abnormal intracellular accumulation as well as urinary excretion of sialyloligosaccharides. A definitive diagnosis is made after the identification of a mutation in the NEU1 gene. So far, 40 mutations of NEU1 have been reported. An association exists between the impact of the individual mutations and the severity of clinical presentation of sialidosis. According to the clinical symptoms, sialidosis has been divided into two subtypes with different ages of onset and severity, including sialidosis type I (normomorphic or mild form) and sialidosis type II (dysmorphic or severe form). Sialidosis II is further subdivided into (i) congenital; (ii) infantile; and (iii) juvenile. Despite being uncommon, sialidosis has enormous clinical relevance due to its debilitating character. A complete understanding of the underlying pathology remains a challenge, which in turn limits the development of effective therapeutic strategies. Furthermore, in the last few years, some atypical cases of sialidosis have been reported as well. We herein attempt to combine and discuss the underlying molecular biology, the clinical features, and the morphological patterns of sialidosis type I and II. View Full-Text   Abstract
The primary indication of fine-needle aspiration cytology of the head and neck region is a thyroid nodule or a mass located in the cervical area or the head. Although a thyroid nodule may raise the suspicion of malignancy, less than one in 20 cases results in a carcinoma. In addition, the list of differential diagnoses is quite different according to the age of the patient. A number of benign lesions, such as branchial cysts, sialadenosis, and sialoadenitis are often seen in childhood and youth. The malignant lesions that are on the top of the list of a pediatric mass of the head and neck (H&N) region include rhabdomyosarcoma, neuroblastoma, and papillary carcinoma of the thyroid gland. This critical review of the diagnostic features of a pediatric mass of the H&N region is accompanied by panels of several cytology features that may be of help to the cytopathologist and clinician. View Full-Text   sialidosis,neuraminidase,sialidosis I,sialidosis II,lysosomal storage disease,lysosomal exocytosis   cytopathology,head and neck,children ", Diagnostics 
" Correction: Antoniou, M.; et al. Biomarker-Guided Non-Adaptive Trial Designs in Phase II and Phase III: A Methodological Review. J. Pers. Med. 2017, 7, 1   Applicability of Precision Medicine Approaches to Managing Hypertension in Rural Populations   Ten Years’ Experience with the CYP2D6 Activity Score: A Perspective on Future Investigations to Improve Clinical Predictions for Precision Therapeutics   Genetic Heterogeneity of SLC22 Family of Transporters in Drug Disposition "," No abstract available View Full-Text   Abstract
As part of the Heart Healthy Lenoir Project, we developed a practice level intervention to improve blood pressure control. The goal of this study was: (i) to determine if single nucleotide polymorphisms (SNPs) that associate with blood pressure variation, identified in large studies, are applicable to blood pressure control in subjects from a rural population; (ii) to measure the association of these SNPs with subjects’ responsiveness to the hypertension intervention; and (iii) to identify other SNPs that may help understand patient-specific responses to an intervention. We used a combination of candidate SNPs and genome-wide analyses to test associations with either baseline systolic blood pressure (SBP) or change in systolic blood pressure one year after the intervention in two genetically defined ancestral groups: African Americans (AA) and Caucasian Americans (CAU). Of the 48 candidate SNPs, 13 SNPs associated with baseline SBP in our study; however, one candidate SNP, rs592582, also associated with a change in SBP after one year. Using our study data, we identified 4 and 15 additional loci that associated with a change in SBP in the AA and CAU groups, respectively. Our analysis of gene-age interactions identified genotypes associated with SBP improvement within different age groups of our populations. Moreover, our integrative analysis identified AQP4-AS1 and PADI2 as genes whose expression levels may contribute to the pleiotropy of complex traits involved in cardiovascular health and blood pressure regulation in response to an intervention targeting hypertension. In conclusion, the identification of SNPs associated with the success of a hypertension treatment intervention suggests that genetic factors in combination with age may contribute to an individual’s success in lowering SBP. If these findings prove to be applicable to other populations, the use of this genetic variation in making patient-specific interventions may help providers with making decisions to improve patient outcomes. Further investigation is required to determine the role of this genetic variance with respect to the management of hypertension such that more precise treatment recommendations may be made in the future as part of personalized medicine.   Abstract
The seminal paper on the CYP2D6 Activity Score (AS) was first published ten years ago and, since its introduction in 2008, it has been widely accepted in the field of pharmacogenetics. This scoring system facilitates the translation of highly complex CYP2D6 diplotype data into a patient’s phenotype to guide drug therapy and is at the core of all CYP2D6 gene/drug pair guidelines issued by the Clinical Pharmacogenetics Implementation Consortium (CPIC). The AS, however, only explains a portion of the variability observed among individuals and ethnicities. In this review, we provide an overview of sources in addition to CYP2D6 genotype that contribute to the variability in CYP2D6-mediated drug metabolism and discuss other factors, genetic and non-genetic, that likely contribute to the observed variability in CYP2D6 enzymatic activity. View Full-Text   Abstract
An important aspect of modern medicine is its orientation to achieve more personalized pharmacological treatments. In this context, transporters involved in drug disposition have gained well-justified attention. Owing to its broad spectrum of substrate specificity, including endogenous compounds and xenobiotics, and its strategical expression in organs accounting for drug disposition, such as intestine, liver and kidney, the SLC22 family of transporters plays an important role in physiology, pharmacology and toxicology. Among these carriers are plasma membrane transporters for organic cations (OCTs) and anions (OATs) with a marked overlap in substrate specificity. These two major clades of SLC22 proteins share a similar membrane topology but differ in their degree of genetic variability. Members of the OCT subfamily are highly polymorphic, whereas OATs have a lower number of genetic variants. Regarding drug disposition, changes in the activity of these variants affect intestinal absorption and target tissue uptake, but more frequently they modify plasma levels due to enhanced or reduced clearance by the liver and secretion by the kidney. The consequences of these changes in transport-associated function markedly affect the effectiveness and toxicity of the treatment in patients carrying the mutation. In solid tumors, changes in the expression of these transporters and the existence of genetic variants substantially determine the response to anticancer drugs. Moreover, chemoresistance usually evolves in response to pharmacological and radiological treatment. Future personalized medicine will require monitoring these changes in a dynamic way to adapt the treatment to the weaknesses shown by each tumor at each stage in each patient. View Full-Text ","    hypertension,GWAS,precision medicine,rural population,SNP-age interaction   CYP2D6,activity score,dextromethorphan,inter-individual variability   cancer,carrier,chemotherapy,mutation,pharmacology,polymorphism,tumor "," Correction: Antoniou, M.; et al. Biomarker-Guided Non-Adaptive Trial Designs in Phase II and Phase III: A Methodological Review. J. Pers. Med. 2017, 7, 1   Applicability of Precision Medicine Approaches to Managing Hypertension in Rural Populations   Ten Years’ Experience with the CYP2D6 Activity Score: A Perspective on Future Investigations to Improve Clinical Predictions for Precision Therapeutics   Genetic Heterogeneity of SLC22 Family of Transporters in Drug Disposition   No abstract available View Full-Text   Abstract
As part of the Heart Healthy Lenoir Project, we developed a practice level intervention to improve blood pressure control. The goal of this study was: (i) to determine if single nucleotide polymorphisms (SNPs) that associate with blood pressure variation, identified in large studies, are applicable to blood pressure control in subjects from a rural population; (ii) to measure the association of these SNPs with subjects’ responsiveness to the hypertension intervention; and (iii) to identify other SNPs that may help understand patient-specific responses to an intervention. We used a combination of candidate SNPs and genome-wide analyses to test associations with either baseline systolic blood pressure (SBP) or change in systolic blood pressure one year after the intervention in two genetically defined ancestral groups: African Americans (AA) and Caucasian Americans (CAU). Of the 48 candidate SNPs, 13 SNPs associated with baseline SBP in our study; however, one candidate SNP, rs592582, also associated with a change in SBP after one year. Using our study data, we identified 4 and 15 additional loci that associated with a change in SBP in the AA and CAU groups, respectively. Our analysis of gene-age interactions identified genotypes associated with SBP improvement within different age groups of our populations. Moreover, our integrative analysis identified AQP4-AS1 and PADI2 as genes whose expression levels may contribute to the pleiotropy of complex traits involved in cardiovascular health and blood pressure regulation in response to an intervention targeting hypertension. In conclusion, the identification of SNPs associated with the success of a hypertension treatment intervention suggests that genetic factors in combination with age may contribute to an individual’s success in lowering SBP. If these findings prove to be applicable to other populations, the use of this genetic variation in making patient-specific interventions may help providers with making decisions to improve patient outcomes. Further investigation is required to determine the role of this genetic variance with respect to the management of hypertension such that more precise treatment recommendations may be made in the future as part of personalized medicine.   Abstract
The seminal paper on the CYP2D6 Activity Score (AS) was first published ten years ago and, since its introduction in 2008, it has been widely accepted in the field of pharmacogenetics. This scoring system facilitates the translation of highly complex CYP2D6 diplotype data into a patient’s phenotype to guide drug therapy and is at the core of all CYP2D6 gene/drug pair guidelines issued by the Clinical Pharmacogenetics Implementation Consortium (CPIC). The AS, however, only explains a portion of the variability observed among individuals and ethnicities. In this review, we provide an overview of sources in addition to CYP2D6 genotype that contribute to the variability in CYP2D6-mediated drug metabolism and discuss other factors, genetic and non-genetic, that likely contribute to the observed variability in CYP2D6 enzymatic activity. View Full-Text   Abstract
An important aspect of modern medicine is its orientation to achieve more personalized pharmacological treatments. In this context, transporters involved in drug disposition have gained well-justified attention. Owing to its broad spectrum of substrate specificity, including endogenous compounds and xenobiotics, and its strategical expression in organs accounting for drug disposition, such as intestine, liver and kidney, the SLC22 family of transporters plays an important role in physiology, pharmacology and toxicology. Among these carriers are plasma membrane transporters for organic cations (OCTs) and anions (OATs) with a marked overlap in substrate specificity. These two major clades of SLC22 proteins share a similar membrane topology but differ in their degree of genetic variability. Members of the OCT subfamily are highly polymorphic, whereas OATs have a lower number of genetic variants. Regarding drug disposition, changes in the activity of these variants affect intestinal absorption and target tissue uptake, but more frequently they modify plasma levels due to enhanced or reduced clearance by the liver and secretion by the kidney. The consequences of these changes in transport-associated function markedly affect the effectiveness and toxicity of the treatment in patients carrying the mutation. In solid tumors, changes in the expression of these transporters and the existence of genetic variants substantially determine the response to anticancer drugs. Moreover, chemoresistance usually evolves in response to pharmacological and radiological treatment. Future personalized medicine will require monitoring these changes in a dynamic way to adapt the treatment to the weaknesses shown by each tumor at each stage in each patient. View Full-Text      hypertension,GWAS,precision medicine,rural population,SNP-age interaction   CYP2D6,activity score,dextromethorphan,inter-individual variability   cancer,carrier,chemotherapy,mutation,pharmacology,polymorphism,tumor ", Journal of Personalized Medicine 
" A Changing-Look AGN to Be Probed by X-ray Polarimetry   Exoplanets: Past, Present, and Future   A Study of Background Conditions for Sphinx—The Satellite-Borne Gamma-Ray Burst Polarimeter   Effelsberg Monitoring of a Sample of RadioAstron Blazars: Analysis of Intra-Day Variability "," Abstract
Active galactic nuclei (AGN) produce the highest intrinsic luminosities in the Universe from within a compact region. The central engine is thought to be powered by accretion onto a supermassive black hole. A fraction of this huge release of energy influences the evolution of the host galaxy, and in particular, star formation. Thus, AGN are key astronomical sources not only because they play an important role in the evolution of the Universe, but also because they constitute a laboratory for extreme physics. However, these objects are under the resolution limit of current telescopes. Polarimetry is a unique technique capable of providing us with information on physical AGN structures. The incoming new era of X-ray polarimetry will give us the opportunity to explore the geometry and physical processes taking place in the innermost regions of the accretion disc. Here we exploit this future powerful tool in the particular case of changing-look AGN, which are key for understanding the complexity of AGN physics. View Full-Text   Abstract
Our understanding of extra-solar planet systems is highly driven by advances in observations in the past decade. Thanks to high precision spectrographs, we are able to reveal unseen companions to stars with the radial velocity method. High precision photometry from the space, especially with the Kepler mission, enables us to detect planets when they transit their stars and dim the stellar light by merely one percent or smaller. Ultra wide-field, high cadence, continuous monitoring of the Galactic bulge from different sites around the southern hemisphere provides us the opportunity to observe microlensing effects caused by planetary systems from the solar neighborhood, all the way to the Milky Way center. The exquisite AO imaging from ground-based large telescopes, coupled with high-contrast coronagraph, captured the photons directly emitted by planets around other stars. In this article, I present a concise review of the extra-solar planet discoveries, discussing the strengths and weaknesses of the major planetary detection methods, providing an overview of our current understanding of planetary formation and evolution given the tremendous observations delivered by various methods, as well as on-going and planned observation endeavors to provide a clear picture of extra-solar planetary systems. View Full-Text   Abstract
SPHiNX is a proposed satellite-borne gamma-ray burst polarimeter operating in the energy range 50–500 keV. The mission aims to probe the fundamental mechanism responsible for gamma-ray burst prompt emission through polarisation measurements. Optimising the signal-to-background ratio for SPHiNX is an important task during the design phase. The Geant4 Monte Carlo toolkit is used in this work. From the simulation, the total background outside the South Atlantic Anomaly (SAA) is about 323 counts/s, which is dominated by the cosmic X-ray background and albedo gamma rays, which contribute ∼60% and ∼35% of the total background, respectively. The background from albedo neutrons and primary and secondary cosmic rays is negligible. The delayed background induced by the SAA-trapped protons is about 190 counts/s when SPHiNX operates in orbit for one year. The resulting total background level of ∼513 counts/s allows the polarisation of ∼50 GRBs with minimum detectable polarisation less than 30% to be determined during the two-year mission lifetime. View Full-Text   Abstract
We present the first results of an ongoing intra-day variability (IDV) flux density monitoring program of 107 blazars, which were selected from a sample of RadioAstron space very long baseline interferometry (VLBI) targets. The IDV observations were performed with the Effelsberg 100-m radio telescope at 4.8 GHz, focusing on the statistical properties of IDV in a relatively large sample of compact active galactic nuclei (AGN). We investigated the dependence of rapid (<3 day) variability on various source properties through a likelihood approach. We found that the IDV amplitude depends on flux density and that fainter sources vary by about a factor of 3 more than their brighter counterparts. We also found a significant difference in the variability amplitude between inverted- and flat-spectrum radio sources, with the former exhibiting stronger variations.
γ
-ray loud sources were found to vary by up to a factor 4 more than
γ
-ray quiet ones, with 4
σ
significance. However a galactic latitude dependence was barely observed, which suggests that it is predominantly the intrinsic properties (e.g., angular size, core-dominance) of the blazars that determine how they scintillate, rather than the directional dependence in the interstellar medium (ISM). We showed that the uncertainty in the VLBI brightness temperatures obtained from the space VLBI data of the RadioAstron satellite can be as high as ~70% due to the presence of the rapid flux density variations. Our statistical results support the view that IDV at centimeter wavelengths is predominantly caused by interstellar scintillation (ISS) of the emission from the most compact, core-dominant region in an AGN. View Full-Text "," AGN polarization,X-ray polarization,changing-look AGN   planetary systems,planets and satellites: atmosphere,protoplanetary disks,techniques: radial velocities,techniques: high angular resolution,gravitational lensing: micro   polarimeter,Compton scattering,GRB,background   galaxies,active-method,statistical-radio continuum,ISM "," A Changing-Look AGN to Be Probed by X-ray Polarimetry   Exoplanets: Past, Present, and Future   A Study of Background Conditions for Sphinx—The Satellite-Borne Gamma-Ray Burst Polarimeter   Effelsberg Monitoring of a Sample of RadioAstron Blazars: Analysis of Intra-Day Variability   Abstract
Active galactic nuclei (AGN) produce the highest intrinsic luminosities in the Universe from within a compact region. The central engine is thought to be powered by accretion onto a supermassive black hole. A fraction of this huge release of energy influences the evolution of the host galaxy, and in particular, star formation. Thus, AGN are key astronomical sources not only because they play an important role in the evolution of the Universe, but also because they constitute a laboratory for extreme physics. However, these objects are under the resolution limit of current telescopes. Polarimetry is a unique technique capable of providing us with information on physical AGN structures. The incoming new era of X-ray polarimetry will give us the opportunity to explore the geometry and physical processes taking place in the innermost regions of the accretion disc. Here we exploit this future powerful tool in the particular case of changing-look AGN, which are key for understanding the complexity of AGN physics. View Full-Text   Abstract
Our understanding of extra-solar planet systems is highly driven by advances in observations in the past decade. Thanks to high precision spectrographs, we are able to reveal unseen companions to stars with the radial velocity method. High precision photometry from the space, especially with the Kepler mission, enables us to detect planets when they transit their stars and dim the stellar light by merely one percent or smaller. Ultra wide-field, high cadence, continuous monitoring of the Galactic bulge from different sites around the southern hemisphere provides us the opportunity to observe microlensing effects caused by planetary systems from the solar neighborhood, all the way to the Milky Way center. The exquisite AO imaging from ground-based large telescopes, coupled with high-contrast coronagraph, captured the photons directly emitted by planets around other stars. In this article, I present a concise review of the extra-solar planet discoveries, discussing the strengths and weaknesses of the major planetary detection methods, providing an overview of our current understanding of planetary formation and evolution given the tremendous observations delivered by various methods, as well as on-going and planned observation endeavors to provide a clear picture of extra-solar planetary systems. View Full-Text   Abstract
SPHiNX is a proposed satellite-borne gamma-ray burst polarimeter operating in the energy range 50–500 keV. The mission aims to probe the fundamental mechanism responsible for gamma-ray burst prompt emission through polarisation measurements. Optimising the signal-to-background ratio for SPHiNX is an important task during the design phase. The Geant4 Monte Carlo toolkit is used in this work. From the simulation, the total background outside the South Atlantic Anomaly (SAA) is about 323 counts/s, which is dominated by the cosmic X-ray background and albedo gamma rays, which contribute ∼60% and ∼35% of the total background, respectively. The background from albedo neutrons and primary and secondary cosmic rays is negligible. The delayed background induced by the SAA-trapped protons is about 190 counts/s when SPHiNX operates in orbit for one year. The resulting total background level of ∼513 counts/s allows the polarisation of ∼50 GRBs with minimum detectable polarisation less than 30% to be determined during the two-year mission lifetime. View Full-Text   Abstract
We present the first results of an ongoing intra-day variability (IDV) flux density monitoring program of 107 blazars, which were selected from a sample of RadioAstron space very long baseline interferometry (VLBI) targets. The IDV observations were performed with the Effelsberg 100-m radio telescope at 4.8 GHz, focusing on the statistical properties of IDV in a relatively large sample of compact active galactic nuclei (AGN). We investigated the dependence of rapid (<3 day) variability on various source properties through a likelihood approach. We found that the IDV amplitude depends on flux density and that fainter sources vary by about a factor of 3 more than their brighter counterparts. We also found a significant difference in the variability amplitude between inverted- and flat-spectrum radio sources, with the former exhibiting stronger variations.
γ
-ray loud sources were found to vary by up to a factor 4 more than
γ
-ray quiet ones, with 4
σ
significance. However a galactic latitude dependence was barely observed, which suggests that it is predominantly the intrinsic properties (e.g., angular size, core-dominance) of the blazars that determine how they scintillate, rather than the directional dependence in the interstellar medium (ISM). We showed that the uncertainty in the VLBI brightness temperatures obtained from the space VLBI data of the RadioAstron satellite can be as high as ~70% due to the presence of the rapid flux density variations. Our statistical results support the view that IDV at centimeter wavelengths is predominantly caused by interstellar scintillation (ISS) of the emission from the most compact, core-dominant region in an AGN. View Full-Text   AGN polarization,X-ray polarization,changing-look AGN   planetary systems,planets and satellites: atmosphere,protoplanetary disks,techniques: radial velocities,techniques: high angular resolution,gravitational lensing: micro   polarimeter,Compton scattering,GRB,background   galaxies,active-method,statistical-radio continuum,ISM ", Galaxies 
 Tribological and Rheological Characterization of New Completely Biogenic Lubricating Greases: A Comparative Experimental Investigation   Modeling the Friction Boundary Layer of an Entire Brake Pad with an Abstract Cellular Automaton   Molecular Dynamics Modeling of the Sliding Performance of an Amorphous Silica Nano-Layer—The Impact of Chosen Interatomic Potentials ," Abstract
Against the background of raw material shortage and the ever-expanding environmental consciousness, the use of biodegradable greases becomes more and more important. The aim of this experimental work is to investigate the tribological response of completely biodegradable greases. Complete biodegradable lubricating greases were formulated with high-oleic sunflower oil (HOSO) and/or castor oil, and different biodegradable thickener agents such as natural cellulose fibers of different lengths and some derivatives, as well as glyceryl and sorbitan stearates. To investigate the friction process, the model greases were tribologically examined with a nanotribometer at a normal force of 200 mN using a material combination of a steel ball on a steel disc. All frictional results, along with the volumes of wear tracks and micrographs of the main contacting area on the steel plate, are presented and discussed. In addition to this, rotational transient flow measurements were carried out on a rheometer at different temperatures to monitor the evolution of the shear stress with time at a constant shear rate, and to characterize the internal friction behavior by quantifying the energy density. All results were also analyzed from an energetic point of view. View Full-Text   Abstract
The principle energy exchange of a brake system occurs in the tribological boundary layer between the pad and the disc. The associated phenomena are primarily responsible for the dynamics of brake systems. The wear debris forms flat contact structures, or “patches,” which carry the majority of the normal load in the system and are highly influential on the friction behavior of the system. A new simulation tool is presented, which is capable of rapidly performing simulations of the contact between an entire brake pad and disc. The “Abstract Cellular Automaton” simulations accurately model the patch coverage state of a brake pad surface based on the system’s load history. This can be used to simulate the complex dissipation phenomena within the tribological contact of the entire pad, including time-dependent local friction coefficients, wear and wear debris transport, and vibrational effects on highly differing scales. View Full-Text   Abstract
The sliding behavior of an amorphous silica sample between two rigid surfaces is in the focus of the present paper. Molecular Dynamics using a classical Tersoff’s potential and a recently developed ReaxFF potential was applied for simulating sliding within a thin film corresponding to a tribofilm formed from silica nanoparticles. The simulations were performed at different temperatures corresponding to moderate and severe tribological stressing conditions. Simulations with both potentials revealed the need of considering different temperatures in order to obtain a sound interpretation of experimental findings. The results show the striking differences between the two potentials not only in terms of magnitude of the resistance stress (about one order of magnitude) but also in terms of friction mechanisms. The expected smooth sliding regime under high temperature conditions was predicted by both simulations, although with Tersoff’s potential smooth sliding was obtained only at the highest temperature. On the other hand, at room temperature Tersoff-style calculations demonstrate stick-slip behavior, which corresponds qualitatively with our experimental findings. Nevertheless, comparison with a macroscopic coefficient of friction is not possible because simulated resistance stresses do not depend on the applied normal pressure. View Full-Text "," biogenic lubricating greases,tribology,rheology,friction,transient flow   dynamic friction,boundary layer,brake,cellular automata simulation,patch dynamics,tribology   molecular dynamics,thin tribofilm,resistance stress,sliding simulation,amorphous silica,interatomic potential "," Tribological and Rheological Characterization of New Completely Biogenic Lubricating Greases: A Comparative Experimental Investigation   Modeling the Friction Boundary Layer of an Entire Brake Pad with an Abstract Cellular Automaton   Molecular Dynamics Modeling of the Sliding Performance of an Amorphous Silica Nano-Layer—The Impact of Chosen Interatomic Potentials   Abstract
Against the background of raw material shortage and the ever-expanding environmental consciousness, the use of biodegradable greases becomes more and more important. The aim of this experimental work is to investigate the tribological response of completely biodegradable greases. Complete biodegradable lubricating greases were formulated with high-oleic sunflower oil (HOSO) and/or castor oil, and different biodegradable thickener agents such as natural cellulose fibers of different lengths and some derivatives, as well as glyceryl and sorbitan stearates. To investigate the friction process, the model greases were tribologically examined with a nanotribometer at a normal force of 200 mN using a material combination of a steel ball on a steel disc. All frictional results, along with the volumes of wear tracks and micrographs of the main contacting area on the steel plate, are presented and discussed. In addition to this, rotational transient flow measurements were carried out on a rheometer at different temperatures to monitor the evolution of the shear stress with time at a constant shear rate, and to characterize the internal friction behavior by quantifying the energy density. All results were also analyzed from an energetic point of view. View Full-Text   Abstract
The principle energy exchange of a brake system occurs in the tribological boundary layer between the pad and the disc. The associated phenomena are primarily responsible for the dynamics of brake systems. The wear debris forms flat contact structures, or “patches,” which carry the majority of the normal load in the system and are highly influential on the friction behavior of the system. A new simulation tool is presented, which is capable of rapidly performing simulations of the contact between an entire brake pad and disc. The “Abstract Cellular Automaton” simulations accurately model the patch coverage state of a brake pad surface based on the system’s load history. This can be used to simulate the complex dissipation phenomena within the tribological contact of the entire pad, including time-dependent local friction coefficients, wear and wear debris transport, and vibrational effects on highly differing scales. View Full-Text   Abstract
The sliding behavior of an amorphous silica sample between two rigid surfaces is in the focus of the present paper. Molecular Dynamics using a classical Tersoff’s potential and a recently developed ReaxFF potential was applied for simulating sliding within a thin film corresponding to a tribofilm formed from silica nanoparticles. The simulations were performed at different temperatures corresponding to moderate and severe tribological stressing conditions. Simulations with both potentials revealed the need of considering different temperatures in order to obtain a sound interpretation of experimental findings. The results show the striking differences between the two potentials not only in terms of magnitude of the resistance stress (about one order of magnitude) but also in terms of friction mechanisms. The expected smooth sliding regime under high temperature conditions was predicted by both simulations, although with Tersoff’s potential smooth sliding was obtained only at the highest temperature. On the other hand, at room temperature Tersoff-style calculations demonstrate stick-slip behavior, which corresponds qualitatively with our experimental findings. Nevertheless, comparison with a macroscopic coefficient of friction is not possible because simulated resistance stresses do not depend on the applied normal pressure. View Full-Text   biogenic lubricating greases,tribology,rheology,friction,transient flow   dynamic friction,boundary layer,brake,cellular automata simulation,patch dynamics,tribology   molecular dynamics,thin tribofilm,resistance stress,sliding simulation,amorphous silica,interatomic potential ", Lubricants 
 Field Trapping Bactrocera latifrons (Diptera: Tephritidae) with Select Eugenol Analogs That Have Been Found to Attract Other ‘Non-Responsive’ Fruit Fly Species   Spore Acquisition and Survival of Ambrosia Beetles Associated with the Laurel Wilt Pathogen in Avocados after Exposure to Entomopathogenic Fungi ," Abstract
Bactrocera latifrons (Hendel) (Diptera: Tephritidae) is a pest fruit fly species native to Oriental Asia which has invaded and established in Hawaii and Tanzania and has been recovered in detection trapping in California. It is largely non-responsive to the male lures cuelure and methyl eugenol. Alpha-ionol + cade oil is a moderately effective male B. latifrons attractant, but is not as attractive as cuelure or methyl eugenol are to other fruit fly species. An improved attractant is therefore desired. With the recent success in finding other non-responsive fruit fly species attracted to isoeugenol, methyl-isoeugenol, or dihydroeugenol in Australia and other countries, we wanted to assess whether B. latifrons might also respond to these “eugenol analogs.” Working with wild B. latifrons populations in Hawaii, we assessed the relative catch of B. latifrons in traps baited with the eugenol analogs with catch in traps baited with alpha-ionol, alpha-ionol + cade oil, or alpha-ionol + eugenol. Catch was significantly higher in traps baited with alpha-ionol + cade oil relative to traps with any of the other baits. There was, though, some male B. latifrons catch in traps baited with dihydroeugenol or isoeugenol but none in traps baited with methyl-isoeugenol. View Full-Text   Abstract
Laurel wilt is a disease threatening the avocado industry in Florida. The causative agent of the disease is a fungus vectored by ambrosia beetles that bore into the trees. Until recently, management strategies for the vectors of the laurel wilt fungus relied solely on chemical control and sanitation practices. Beneficial entomopathogenic fungi (EPF) are the most common and prevalent natural enemies of pathogen vectors. Laboratory experiments demonstrated that commercial strains of EPF can increase the mortality of the primary vector, Xyleborus glabratus, and potential alternative vectors, Xylosandrus crassiusculus, Xyleborus volvulus and Xyleborus bispinatus (Coleoptera: Curculionidae: Scolytinae). Our study provides baseline data for three formulated commercially-available entomopathogenic fungi used as potential biocontrol agents against X. crassiusculus, X. volvulus and X. bispinatus. The specific objectives were to determine: (1) the mean number of viable spores acquired per beetle species adult after being exposed to formulated fungal products containing different strains of EPF (Isaria fumosorosea, Metarhizium brunneum and Beauveria bassiana); and (2) the median and mean survival times using paper disk bioassays. Prior to being used in experiments, all fungal suspensions were adjusted to 2.4 × 106 viable spores/mL. The number of spores acquired by X. crassiusculus was significantly higher after exposure to B. bassiana, compared to the other fungal treatments. For X. volvulus, the numbers of spores acquired per beetle were significantly different amongst the different fungal treatments, and the sequence of spore acquisition rates on X. volvulus from highest to lowest was I. fumosorosea > M. brunneum > B. bassiana. After X. bispinatus beetles were exposed to the different suspensions, the rates of acquisition of spores per beetle amongst the different fungal treatments were similar. Survival estimates (data pooled across two tests) indicated an impact for each entomopathogenic fungus per beetle species after exposure to a filter paper disk treated at the same fungal suspension concentration. Kaplan–Meier analysis (censored at day 7) revealed that each beetle species survived significantly shorter in bioassays containing disks treated with EPF compared to water only. This study demonstrated that ambrosia beetles associated with the laurel wilt pathogen in avocados are susceptible to infection by EPF under laboratory conditions. However, the EPF needs to be tested under field conditions to confirm their efficacy against the beetles. View Full-Text "," Bactrocera latifrons,dihydroeugenol,isoeugenol,methyl-isoeugenol,alpha-ionol,cade oil   ambrosia beetles,laurel wilt,avocados,entomopathogenic fungi,Kaplan–Meier analysis "," Field Trapping Bactrocera latifrons (Diptera: Tephritidae) with Select Eugenol Analogs That Have Been Found to Attract Other ‘Non-Responsive’ Fruit Fly Species   Spore Acquisition and Survival of Ambrosia Beetles Associated with the Laurel Wilt Pathogen in Avocados after Exposure to Entomopathogenic Fungi   Abstract
Bactrocera latifrons (Hendel) (Diptera: Tephritidae) is a pest fruit fly species native to Oriental Asia which has invaded and established in Hawaii and Tanzania and has been recovered in detection trapping in California. It is largely non-responsive to the male lures cuelure and methyl eugenol. Alpha-ionol + cade oil is a moderately effective male B. latifrons attractant, but is not as attractive as cuelure or methyl eugenol are to other fruit fly species. An improved attractant is therefore desired. With the recent success in finding other non-responsive fruit fly species attracted to isoeugenol, methyl-isoeugenol, or dihydroeugenol in Australia and other countries, we wanted to assess whether B. latifrons might also respond to these “eugenol analogs.” Working with wild B. latifrons populations in Hawaii, we assessed the relative catch of B. latifrons in traps baited with the eugenol analogs with catch in traps baited with alpha-ionol, alpha-ionol + cade oil, or alpha-ionol + eugenol. Catch was significantly higher in traps baited with alpha-ionol + cade oil relative to traps with any of the other baits. There was, though, some male B. latifrons catch in traps baited with dihydroeugenol or isoeugenol but none in traps baited with methyl-isoeugenol. View Full-Text   Abstract
Laurel wilt is a disease threatening the avocado industry in Florida. The causative agent of the disease is a fungus vectored by ambrosia beetles that bore into the trees. Until recently, management strategies for the vectors of the laurel wilt fungus relied solely on chemical control and sanitation practices. Beneficial entomopathogenic fungi (EPF) are the most common and prevalent natural enemies of pathogen vectors. Laboratory experiments demonstrated that commercial strains of EPF can increase the mortality of the primary vector, Xyleborus glabratus, and potential alternative vectors, Xylosandrus crassiusculus, Xyleborus volvulus and Xyleborus bispinatus (Coleoptera: Curculionidae: Scolytinae). Our study provides baseline data for three formulated commercially-available entomopathogenic fungi used as potential biocontrol agents against X. crassiusculus, X. volvulus and X. bispinatus. The specific objectives were to determine: (1) the mean number of viable spores acquired per beetle species adult after being exposed to formulated fungal products containing different strains of EPF (Isaria fumosorosea, Metarhizium brunneum and Beauveria bassiana); and (2) the median and mean survival times using paper disk bioassays. Prior to being used in experiments, all fungal suspensions were adjusted to 2.4 × 106 viable spores/mL. The number of spores acquired by X. crassiusculus was significantly higher after exposure to B. bassiana, compared to the other fungal treatments. For X. volvulus, the numbers of spores acquired per beetle were significantly different amongst the different fungal treatments, and the sequence of spore acquisition rates on X. volvulus from highest to lowest was I. fumosorosea > M. brunneum > B. bassiana. After X. bispinatus beetles were exposed to the different suspensions, the rates of acquisition of spores per beetle amongst the different fungal treatments were similar. Survival estimates (data pooled across two tests) indicated an impact for each entomopathogenic fungus per beetle species after exposure to a filter paper disk treated at the same fungal suspension concentration. Kaplan–Meier analysis (censored at day 7) revealed that each beetle species survived significantly shorter in bioassays containing disks treated with EPF compared to water only. This study demonstrated that ambrosia beetles associated with the laurel wilt pathogen in avocados are susceptible to infection by EPF under laboratory conditions. However, the EPF needs to be tested under field conditions to confirm their efficacy against the beetles. View Full-Text   Bactrocera latifrons,dihydroeugenol,isoeugenol,methyl-isoeugenol,alpha-ionol,cade oil   ambrosia beetles,laurel wilt,avocados,entomopathogenic fungi,Kaplan–Meier analysis ", Insects 
" Panobinostat Potentiates Temozolomide Effects and Reverses Epithelial–Mesenchymal Transition in Glioblastoma Cells   From Flies to Mice: The Emerging Role of Non-Canonical PRC1 Members in Mammalian Development   5-Hydroxymethylcytosine (5hmC), or How to Identify Your Favorite Cell   Acknowledgement to Reviewers of Epigenomes in 2017 "," Abstract
Glioblastoma is the most common form of glioma, as well as the most aggressive. Patients suffering from this disease have a very poor prognosis. Surgery, radiotherapy, and temozolomide are the only approved treatments nowadays. Panobinostat is a pan-inhibitor of histone deacetylases (HDACs) that has been shown to break some pathways which play an important role in cancer development. A global intention of using panobinostat as a therapeutic agent against glioblastoma is beginning to be a reality. We have treated the LN405 glioblastoma cell line with temozolomide, panobinostat, and combined treatment, in order to test apoptosis, colony formation, and a possible molecular reversion of the mesenchymal phenotype of the cells to an epithelial one. Our results show that panobinostat decreased N-cadherin levels in the LN405 glioblastoma cell line while it increased the expression of E-cadherin, which might be associated with a mesenchymal–epithelial transition in glioblastoma cells. Colony formation was reduced, and apoptosis was increased with treatments. Our research highlights the importance of panobinostat as a potential adjuvant therapy to be used with temozolomide to treat glioblastoma and the advantages of the combined treatment versus temozolomide alone, which is currently the first-line treatment used to treat this tumor. View Full-Text   Abstract
Originally two types of Polycomb Repressive Complexes (PRCs) were described, canonical PRC1 (cPRC1) and PRC2. Recently, a versatile set of complexes were identified and brought up several dilemmas in PRC mediated repression. These new class of complexes were named as non-canonical PRC1s (ncPRC1s). Both cPRC1s and ncPRC1s contain Ring finger protein (RING1, RNF2) and Polycomb group ring finger catalytic (PCGF) core, but in ncPRCs, RING and YY1 binding protein (RYBP), or YY1 associated factor 2 (YAF2), replaces the Chromobox (CBX) and Polyhomeotic (PHC) subunits found in cPRC1s. Additionally, ncPRC1 subunits can associate with versatile accessory proteins, which determine their functional specificity. Homozygous null mutations of the ncPRC members in mice are often lethal or cause infertility, which underlines their essential functions in mammalian development. In this review, we summarize the mouse knockout phenotypes of subunits of the six major ncPRCs. We highlight several aspects of their discovery from fly to mice and emerging role in target recognition, embryogenesis and cell-fate decision making. We gathered data from stem cell mediated in vitro differentiation assays and genetically engineered mouse models. Accumulating evidence suggests that ncPRC1s play profound role in mammalian embryogenesis by regulating gene expression during lineage specification of pluripotent stem cells. View Full-Text   Abstract
Recently described as the sixth base of the DNA macromolecule, the precise role of 5-hydroxymethylcytosine (5hmC) is the subject of debate. Early studies indicate that it is functionally distinct from cytosine DNA methylation (5mC), and there is evidence for 5hmC being a stable derivate of 5mC, rather than just an intermediate of demethylation. Moreover, 5hmC events correlate in time and space with key differentiation steps in mammalian cells. Such events span the three embryonic germ layers and multiple progenitor cell subtypes, suggesting a general mechanism. Because of the growing understanding of the role of progenitor cells in disease origin, we attempted to provide a detailed summary on the currently available literature supporting 5hmC as a key player in adult progenitor cell differentiation. This summary consolidates the emerging role for 5hmC in defining cellular fate. View Full-Text   Abstract
Peer review is an essential part in the publication process, ensuring that Epigenomes maintains high quality standards for its published papers. [...]
View Full-Text "," panobinostat,temozolomide,glioblastoma,epithelial-mesenchymal transition   Polycomb repression,epigenetic regulation,dynamic gene expression,non-canonical,PRC1,RING1,RYBP,covalent histone modification,embryonic stem cells,differentiation   DNA methylation,progenitor cells,differentiation,5mC,5hmC    "," Panobinostat Potentiates Temozolomide Effects and Reverses Epithelial–Mesenchymal Transition in Glioblastoma Cells   From Flies to Mice: The Emerging Role of Non-Canonical PRC1 Members in Mammalian Development   5-Hydroxymethylcytosine (5hmC), or How to Identify Your Favorite Cell   Acknowledgement to Reviewers of Epigenomes in 2017   Abstract
Glioblastoma is the most common form of glioma, as well as the most aggressive. Patients suffering from this disease have a very poor prognosis. Surgery, radiotherapy, and temozolomide are the only approved treatments nowadays. Panobinostat is a pan-inhibitor of histone deacetylases (HDACs) that has been shown to break some pathways which play an important role in cancer development. A global intention of using panobinostat as a therapeutic agent against glioblastoma is beginning to be a reality. We have treated the LN405 glioblastoma cell line with temozolomide, panobinostat, and combined treatment, in order to test apoptosis, colony formation, and a possible molecular reversion of the mesenchymal phenotype of the cells to an epithelial one. Our results show that panobinostat decreased N-cadherin levels in the LN405 glioblastoma cell line while it increased the expression of E-cadherin, which might be associated with a mesenchymal–epithelial transition in glioblastoma cells. Colony formation was reduced, and apoptosis was increased with treatments. Our research highlights the importance of panobinostat as a potential adjuvant therapy to be used with temozolomide to treat glioblastoma and the advantages of the combined treatment versus temozolomide alone, which is currently the first-line treatment used to treat this tumor. View Full-Text   Abstract
Originally two types of Polycomb Repressive Complexes (PRCs) were described, canonical PRC1 (cPRC1) and PRC2. Recently, a versatile set of complexes were identified and brought up several dilemmas in PRC mediated repression. These new class of complexes were named as non-canonical PRC1s (ncPRC1s). Both cPRC1s and ncPRC1s contain Ring finger protein (RING1, RNF2) and Polycomb group ring finger catalytic (PCGF) core, but in ncPRCs, RING and YY1 binding protein (RYBP), or YY1 associated factor 2 (YAF2), replaces the Chromobox (CBX) and Polyhomeotic (PHC) subunits found in cPRC1s. Additionally, ncPRC1 subunits can associate with versatile accessory proteins, which determine their functional specificity. Homozygous null mutations of the ncPRC members in mice are often lethal or cause infertility, which underlines their essential functions in mammalian development. In this review, we summarize the mouse knockout phenotypes of subunits of the six major ncPRCs. We highlight several aspects of their discovery from fly to mice and emerging role in target recognition, embryogenesis and cell-fate decision making. We gathered data from stem cell mediated in vitro differentiation assays and genetically engineered mouse models. Accumulating evidence suggests that ncPRC1s play profound role in mammalian embryogenesis by regulating gene expression during lineage specification of pluripotent stem cells. View Full-Text   Abstract
Recently described as the sixth base of the DNA macromolecule, the precise role of 5-hydroxymethylcytosine (5hmC) is the subject of debate. Early studies indicate that it is functionally distinct from cytosine DNA methylation (5mC), and there is evidence for 5hmC being a stable derivate of 5mC, rather than just an intermediate of demethylation. Moreover, 5hmC events correlate in time and space with key differentiation steps in mammalian cells. Such events span the three embryonic germ layers and multiple progenitor cell subtypes, suggesting a general mechanism. Because of the growing understanding of the role of progenitor cells in disease origin, we attempted to provide a detailed summary on the currently available literature supporting 5hmC as a key player in adult progenitor cell differentiation. This summary consolidates the emerging role for 5hmC in defining cellular fate. View Full-Text   Abstract
Peer review is an essential part in the publication process, ensuring that Epigenomes maintains high quality standards for its published papers. [...]
View Full-Text   panobinostat,temozolomide,glioblastoma,epithelial-mesenchymal transition   Polycomb repression,epigenetic regulation,dynamic gene expression,non-canonical,PRC1,RING1,RYBP,covalent histone modification,embryonic stem cells,differentiation   DNA methylation,progenitor cells,differentiation,5mC,5hmC    ", Epigenomes 
 Directional Change Mediates the Physiological Response to High-Intensity Shuttle Running in Professional Soccer Players   Relative Age Effect in Swedish Male and Female Tennis Players Born in 1998–2001   Neuromuscular Adaptations Following Training and Protein Supplementation in a Group of Trained Weightlifters   Is a Bimodal Force-Time Curve Related to Countermovement Jump Performance? ," Abstract
The purpose of this study was to investigate the influence that different frequencies of deceleration and acceleration actions had on the physiological demands in professional soccer players. Thirteen players were monitored via microelectromechanical devices during shuttle running protocols which involved one, three, or seven 180 degree directional changes. Heart rate exertion (HRE) (1.1 ± 0.7) and rating of perceived exertion (RPE) (5 ± 1) were significantly higher for the protocol which included seven directional changes when compared to the protocols which included one (HRE 0.5 ± 0.3, ES = 1.1, RPE 3 ± 0, ES = 2.7) or three (HRE 0.5 ± 0.2, ES = 1.1, RPE 3 ± 1, ES = 1.9) directional changes (p < 0.05). The gravitational force (g-force) as measured through accelerometry (ACC) also showed a similar trend when comparing the seven (8628.2 ± 1630.4 g) to the one (5888.6 ± 1159.1 g, ES = 1.9) or three (6526.9 ± 1257.6 g, ES = 1.4) directional change protocols (p < 0.05). The results of this study suggest that increasing the frequency of decelerations and accelerations at a high intensity running (HIR) speed alters the movement demands and elevates the physiological responses in professional players. This data has implications for the monitoring of physical performance and implementation of training drills. View Full-Text   Abstract
The relative age effect (RAE) has been extensively debated and researched in both popular media and academic discourse. This study examined RAE in Swedish tennis players born in 1998–2001. The study was conducted in 2015–2016 and includes all ranked Swedish tennis players (n = 1835) registered in the Swedish Tennis Association database from the year 2014. The results show that when the birth dates of the corresponding Swedish population and all the ranked players are compared, they show a moderate RAE; however, the higher up they are in the ranking system, the greater the RAE becomes. Top 10 players display an average of 64.1% being born in the first half of the year. Some gender differences were also found, with a greater proportion of both higher and lower ranked females being born in the first half of the year. In our discussion of the findings we raise several issues that need to be addressed to provide more equal opportunities for all junior players regardless of birth date. Resolving ongoing problems associated with RAE in competitive sports such as tennis is important both in term of prolonged participation in the sport and increased performance. Suggestions made in this article include recognising RAE when designing the format of competitions/tournaments, not using official rankings until the juniors get older, addressing RAE in a “gender sensitive” way, and conducting further in-depth studies in which RAE is understood/examined as being associated with environmental factors. Although these findings show the RAE effect in Swedish tennis players, thus pointing at the need for further consideration in terms of ranking and selection procedures to ensure equal opportunities for player development, the study also concludes by reasserting an emphasis on a holistic approach to player development in which coaches focus on the developmentally appropriate needs and potential of each individual player regardless of their biological age. View Full-Text   Abstract
The purpose of this study was to examine the effects of a recovery supplement compared with a placebo on muscle morphology in trained weightlifters. Vastus lateralis and muscle fiber cross sectional area of type I and type II fibers were compared between groups using a series of 2 × 2 (group × time) repeated measure ANOVAs. Both groups on average improved cross-sectional area of the vastus lateralis, type I and type II muscle fibers from pre-to-post but individual response varied within both groups. Greater magnitude of changes in type I and type II muscle fibers were observed for the placebo group but not for vastus lateralis cross sectional area. Additionally, subjects were divided into large and small fiber groups based on combined fiber size at the start of the investigation. These findings indicate that the recovery supplement utilized provided no greater effect compared with a placebo in a 12-week block periodization protocol in trained weightlifters. The primary determinate of fiber size changes in the study was determined to be the initial fiber size of muscle fibers with larger practical changes observed in the small fiber group compared with the large fiber group in type I, II, and ultrasound cross-sectional area (CSA). View Full-Text   Abstract
A countermovement jump (CMJ) represents one of the most frequently used performance tests for monitoring neuromuscular function in athletes. An often-overlooked feature that may provide some useful diagnostic information is the actual shape of the force-time curve. The aim of this study was therefore to consider how the shape of the force-time curve influences jump performance. Thirty-three male rugby union players performed two CMJs on a force plate, with discrete variables and continuous curve analysis used. The subjects were dichotomized based on shape of the force-time curve during the propulsion phase and by jump height. The differences between the unimodal and bimodal groups were unclear for jump height (ES = 0.28, ±0.58) and reactive strength index-modified (ES = −0.30, ±0.59). A substantial difference between high (40.2 ± 2.9 cm) and low (31.2 ± 3.2 cm) jumpers only existed in the late propulsion phase by 79.0% to 97.0% of the normalized force-time curve. A bimodal force-time curve is not representative of an optimal pattern of performance and simply reflects an inefficient stretch-shortening cycle. The inter-individual variability that exists in braking COM displacement renders temporal phase analysis impractical in cross-sectional type studies. View Full-Text "," change of direction,deceleration,acceleration,accelerometry,fatigue   relative age effect,tennis,Sweden,coaching,gender   protein,carbohydrate,weightlifting,supplementation   movement,attention,neuromuscular function,shape "," Directional Change Mediates the Physiological Response to High-Intensity Shuttle Running in Professional Soccer Players   Relative Age Effect in Swedish Male and Female Tennis Players Born in 1998–2001   Neuromuscular Adaptations Following Training and Protein Supplementation in a Group of Trained Weightlifters   Is a Bimodal Force-Time Curve Related to Countermovement Jump Performance?   Abstract
The purpose of this study was to investigate the influence that different frequencies of deceleration and acceleration actions had on the physiological demands in professional soccer players. Thirteen players were monitored via microelectromechanical devices during shuttle running protocols which involved one, three, or seven 180 degree directional changes. Heart rate exertion (HRE) (1.1 ± 0.7) and rating of perceived exertion (RPE) (5 ± 1) were significantly higher for the protocol which included seven directional changes when compared to the protocols which included one (HRE 0.5 ± 0.3, ES = 1.1, RPE 3 ± 0, ES = 2.7) or three (HRE 0.5 ± 0.2, ES = 1.1, RPE 3 ± 1, ES = 1.9) directional changes (p < 0.05). The gravitational force (g-force) as measured through accelerometry (ACC) also showed a similar trend when comparing the seven (8628.2 ± 1630.4 g) to the one (5888.6 ± 1159.1 g, ES = 1.9) or three (6526.9 ± 1257.6 g, ES = 1.4) directional change protocols (p < 0.05). The results of this study suggest that increasing the frequency of decelerations and accelerations at a high intensity running (HIR) speed alters the movement demands and elevates the physiological responses in professional players. This data has implications for the monitoring of physical performance and implementation of training drills. View Full-Text   Abstract
The relative age effect (RAE) has been extensively debated and researched in both popular media and academic discourse. This study examined RAE in Swedish tennis players born in 1998–2001. The study was conducted in 2015–2016 and includes all ranked Swedish tennis players (n = 1835) registered in the Swedish Tennis Association database from the year 2014. The results show that when the birth dates of the corresponding Swedish population and all the ranked players are compared, they show a moderate RAE; however, the higher up they are in the ranking system, the greater the RAE becomes. Top 10 players display an average of 64.1% being born in the first half of the year. Some gender differences were also found, with a greater proportion of both higher and lower ranked females being born in the first half of the year. In our discussion of the findings we raise several issues that need to be addressed to provide more equal opportunities for all junior players regardless of birth date. Resolving ongoing problems associated with RAE in competitive sports such as tennis is important both in term of prolonged participation in the sport and increased performance. Suggestions made in this article include recognising RAE when designing the format of competitions/tournaments, not using official rankings until the juniors get older, addressing RAE in a “gender sensitive” way, and conducting further in-depth studies in which RAE is understood/examined as being associated with environmental factors. Although these findings show the RAE effect in Swedish tennis players, thus pointing at the need for further consideration in terms of ranking and selection procedures to ensure equal opportunities for player development, the study also concludes by reasserting an emphasis on a holistic approach to player development in which coaches focus on the developmentally appropriate needs and potential of each individual player regardless of their biological age. View Full-Text   Abstract
The purpose of this study was to examine the effects of a recovery supplement compared with a placebo on muscle morphology in trained weightlifters. Vastus lateralis and muscle fiber cross sectional area of type I and type II fibers were compared between groups using a series of 2 × 2 (group × time) repeated measure ANOVAs. Both groups on average improved cross-sectional area of the vastus lateralis, type I and type II muscle fibers from pre-to-post but individual response varied within both groups. Greater magnitude of changes in type I and type II muscle fibers were observed for the placebo group but not for vastus lateralis cross sectional area. Additionally, subjects were divided into large and small fiber groups based on combined fiber size at the start of the investigation. These findings indicate that the recovery supplement utilized provided no greater effect compared with a placebo in a 12-week block periodization protocol in trained weightlifters. The primary determinate of fiber size changes in the study was determined to be the initial fiber size of muscle fibers with larger practical changes observed in the small fiber group compared with the large fiber group in type I, II, and ultrasound cross-sectional area (CSA). View Full-Text   Abstract
A countermovement jump (CMJ) represents one of the most frequently used performance tests for monitoring neuromuscular function in athletes. An often-overlooked feature that may provide some useful diagnostic information is the actual shape of the force-time curve. The aim of this study was therefore to consider how the shape of the force-time curve influences jump performance. Thirty-three male rugby union players performed two CMJs on a force plate, with discrete variables and continuous curve analysis used. The subjects were dichotomized based on shape of the force-time curve during the propulsion phase and by jump height. The differences between the unimodal and bimodal groups were unclear for jump height (ES = 0.28, ±0.58) and reactive strength index-modified (ES = −0.30, ±0.59). A substantial difference between high (40.2 ± 2.9 cm) and low (31.2 ± 3.2 cm) jumpers only existed in the late propulsion phase by 79.0% to 97.0% of the normalized force-time curve. A bimodal force-time curve is not representative of an optimal pattern of performance and simply reflects an inefficient stretch-shortening cycle. The inter-individual variability that exists in braking COM displacement renders temporal phase analysis impractical in cross-sectional type studies. View Full-Text   change of direction,deceleration,acceleration,accelerometry,fatigue   relative age effect,tennis,Sweden,coaching,gender   protein,carbohydrate,weightlifting,supplementation   movement,attention,neuromuscular function,shape ", Sports 
 A Brave New World of Work through the Lens of Disability   Racial Variation in the Association between Educational Attainment and Self-Rated Health   Supported Decision-Making from Theory to Practice: Implementing the Right to Enjoy Legal Capacity ," Abstract
Work and paid employment has become a central aspect of social identity in our contemporary work societies. The assumed positive aspects of wage labour and employment on individual well-being are hardly questioned. It is instead claimed that work offers the individual a sense of purposefulness, a possibility to contribute to the collective good and a daily structure. Since its late emergence in the 1960s, the disability rights movement has put an emphasis on exclusion from work and employment. Nevertheless, all over the world, people with disabilities still belong to the most marginalised groups in the labour market. Using disability rights monitoring as a method, this paper explores what role the disability rights framework plays in shaping and transforming our present work society. Based on a German context, it is outlined how the international human rights framework has influenced the social policies that support the inclusion of disabled people in work and employment. Including the narratives of disabled people, it is outlined that despite comprehensive anti-discrimination legislation, the German labour market remains exclusionary and discriminatory against people with disabilities. Recently introduced measures, however, point to a new direction and aim to create a more equal and just world of work that acknowledges embodied differences and the needs and capabilities of disabled and non-disabled workers. View Full-Text   Abstract
Background: Minorities’ Diminished Return theory can be defined as the systematically smaller effects of socioeconomic status (SES) indicators on the health and well-being of minority populations compared to Whites. To test whether Minorities’ Diminished Return theory holds for self-rated health (SRH), we investigated Black–White differences in the effects of education and income on SRH. Methods: Data from the Health Information National Trends Survey (HINTS) 2017 was used. HINTS 2017 (n = 3217) is a nationally cross-sectional survey of American adults. The current analysis included 2277 adults who were either Whites (n = 1868; 82%) or Blacks (n = 409; 18%). Education and income were the independent variables. Poor/fair SRH was the dependent variable. Covariates included age, gender, obesity, and health behaviors (smoking and exercise). Race was the focal moderator. We ran logistic regressions in the overall sample, with and without race by SES (education and income) interactions. Results: Higher education was associated with lower risk of poor/fair SRH in the pooled sample. We found an interaction between race and education, but not race and income, in relation to SRH, suggesting a stronger association for Whites than Blacks. Conclusions: Minorities’ Diminished Return theory is also relevant to the effects of educational attainment on SRH. The relative disadvantage of Blacks compared to Whites in gaining SRH from educational attainment may reflect structural racism that systemically hinders Blacks. There is a need for additional research on specific societal barriers that minimize Blacks’ health gain from their SES resources. Policies and programs should help Black individuals leverage their SES resources. View Full-Text   Abstract
The right to equal recognition before the law, protected by Article 12 of the United Nations (UN) Convention on the Rights of Persons with Disabilities (CRPD), mandates the use of supported decision-making practices to enable disabled people, particularly those with intellectual and/or psychosocial disabilities, to enjoy their legal capacity. Finding ways to translate this theoretical mandate into practice poses a number of particularly challenging socio-legal issues, which this research seeks to address. The English Mental Capacity Act 2005 (MCA) sets out a right to support with decision-making (s.1(3)), underpinned by a presumption of capacity (s.1(2)). Qualitative interviews with intellectually disabled people, their supporters, and care and support professionals were undertaken to explore how disabled people make decisions in their everyday lives, the kinds of support they need, and the strategies for supported decision-making used in practice. Analysis of these interviews suggests that a range of supported decision-making techniques have been developed in practice and are effective in supporting everyday preferences and some life choices. Paradoxically, it appears that as decisions become more complex, the support available to disabled people reduces. Specifically, much less support is available for more difficult decisions around finances, healthcare and legal matters. We argue that the reasons for this are due to a web of regulatory, social and policy issues. We conclude that implementing the right to enjoy legal capacity through supported decision-making will require a combination of regulatory reform, social change and policy amendment. View Full-Text "," employment and work,disability,human rights,social participation,Germany   race,social class,education,income,socioeconomic status,social determinants of health,self-rated health   legal capacity,mental capacity,supported decision-making,UN Convention on the Rights of Persons with Disabilities,care,human rights "," A Brave New World of Work through the Lens of Disability   Racial Variation in the Association between Educational Attainment and Self-Rated Health   Supported Decision-Making from Theory to Practice: Implementing the Right to Enjoy Legal Capacity   Abstract
Work and paid employment has become a central aspect of social identity in our contemporary work societies. The assumed positive aspects of wage labour and employment on individual well-being are hardly questioned. It is instead claimed that work offers the individual a sense of purposefulness, a possibility to contribute to the collective good and a daily structure. Since its late emergence in the 1960s, the disability rights movement has put an emphasis on exclusion from work and employment. Nevertheless, all over the world, people with disabilities still belong to the most marginalised groups in the labour market. Using disability rights monitoring as a method, this paper explores what role the disability rights framework plays in shaping and transforming our present work society. Based on a German context, it is outlined how the international human rights framework has influenced the social policies that support the inclusion of disabled people in work and employment. Including the narratives of disabled people, it is outlined that despite comprehensive anti-discrimination legislation, the German labour market remains exclusionary and discriminatory against people with disabilities. Recently introduced measures, however, point to a new direction and aim to create a more equal and just world of work that acknowledges embodied differences and the needs and capabilities of disabled and non-disabled workers. View Full-Text   Abstract
Background: Minorities’ Diminished Return theory can be defined as the systematically smaller effects of socioeconomic status (SES) indicators on the health and well-being of minority populations compared to Whites. To test whether Minorities’ Diminished Return theory holds for self-rated health (SRH), we investigated Black–White differences in the effects of education and income on SRH. Methods: Data from the Health Information National Trends Survey (HINTS) 2017 was used. HINTS 2017 (n = 3217) is a nationally cross-sectional survey of American adults. The current analysis included 2277 adults who were either Whites (n = 1868; 82%) or Blacks (n = 409; 18%). Education and income were the independent variables. Poor/fair SRH was the dependent variable. Covariates included age, gender, obesity, and health behaviors (smoking and exercise). Race was the focal moderator. We ran logistic regressions in the overall sample, with and without race by SES (education and income) interactions. Results: Higher education was associated with lower risk of poor/fair SRH in the pooled sample. We found an interaction between race and education, but not race and income, in relation to SRH, suggesting a stronger association for Whites than Blacks. Conclusions: Minorities’ Diminished Return theory is also relevant to the effects of educational attainment on SRH. The relative disadvantage of Blacks compared to Whites in gaining SRH from educational attainment may reflect structural racism that systemically hinders Blacks. There is a need for additional research on specific societal barriers that minimize Blacks’ health gain from their SES resources. Policies and programs should help Black individuals leverage their SES resources. View Full-Text   Abstract
The right to equal recognition before the law, protected by Article 12 of the United Nations (UN) Convention on the Rights of Persons with Disabilities (CRPD), mandates the use of supported decision-making practices to enable disabled people, particularly those with intellectual and/or psychosocial disabilities, to enjoy their legal capacity. Finding ways to translate this theoretical mandate into practice poses a number of particularly challenging socio-legal issues, which this research seeks to address. The English Mental Capacity Act 2005 (MCA) sets out a right to support with decision-making (s.1(3)), underpinned by a presumption of capacity (s.1(2)). Qualitative interviews with intellectually disabled people, their supporters, and care and support professionals were undertaken to explore how disabled people make decisions in their everyday lives, the kinds of support they need, and the strategies for supported decision-making used in practice. Analysis of these interviews suggests that a range of supported decision-making techniques have been developed in practice and are effective in supporting everyday preferences and some life choices. Paradoxically, it appears that as decisions become more complex, the support available to disabled people reduces. Specifically, much less support is available for more difficult decisions around finances, healthcare and legal matters. We argue that the reasons for this are due to a web of regulatory, social and policy issues. We conclude that implementing the right to enjoy legal capacity through supported decision-making will require a combination of regulatory reform, social change and policy amendment. View Full-Text   employment and work,disability,human rights,social participation,Germany   race,social class,education,income,socioeconomic status,social determinants of health,self-rated health   legal capacity,mental capacity,supported decision-making,UN Convention on the Rights of Persons with Disabilities,care,human rights ", Societies 
" Concerns about Genetic Discrimination after Regulation: A Qualitative Study of the Situation Regarding BRCA and Huntington’s Disease in Belgium   Off to the Courts? Or the Agency? Public Attitudes on Bureaucratic and Legal Approaches to Policy Enforcement   The Administrative Role of the Chief Justice: Law, Politics, and Procedure in the Roberts Court Era   Assessing Judicial Empowerment "," Abstract
Although there is no unequivocal evidence of genetic discrimination (GD), and despite laws that prohibit it, individuals confronted with genetic diseases still seem to be concerned. The aim of this study was to gain in-depth understanding of experiences and concerns in relation to possible genetic discrimination. This article presents an analysis of semi-structured interviews with 42 individuals who had or were at risk of breast and ovarian cancer (BRCA) or Huntington’s disease (HD) in Belgium. Even after regulation, individuals at risk of BRCA and HD express concerns about possible genetic discrimination. These concerns relate to direct forms of GD, for instance those related to insurance and employment. Individuals were often unclear about and wary of legislation. Importantly, concerns were also expressed as to more subtle and indirect forms of GD, e.g., in social relations, where individuals fear being treated ‘differently’ and unfairly. Our study demonstrates how these concerns emerge at particular moments in life and how levels and forms of concern are influenced by the specific genetic disorder. Worries concerning these more subtle forms of genetic discrimination are more difficult to protect by law. Current legislative efforts do not appear to be effective in alleviating concerns about genetic discrimination. These regulations seem to be unclear, some participants are unsure about their effectiveness and they do not succeed in incorporating all forms of genetic discrimination. Particularly challenging is how to address indirect forms of genetic discrimination. View Full-Text   Abstract
A key curiosity in the operation of the American regulatory state lies with its hybrid structure, defined by centralized, bureaucratic approaches but also more decentralized actions such as lawsuits brought by private citizens in the courts. While current research on these two pathways focuses at the elite level—exploring how and why political actors and institutions opt for legal or administrative strategies for implementing different public policies—there is little research that examines public attitudes toward how policy is enforced in the U.S. Given that the public is a key partner in this process, this paper integrates public attitudes into the discussion, tapping into conceptions of “big government,” privatization, and the tort reform movement. Using original data from a series of vignette-based experiments included in the 2014 Cooperative Congressional Election Survey, we examine public preferences about how policy is regulated—by private citizens in the courts or by government officials in agencies—across a broad number of policy areas. We offer one of the first studies that adjudicates the boundaries of public attitudes on litigation and bureaucratic regulation in the U.S., offering implications for how elites might approach the design of policy implementation for different issue areas. View Full-Text   Abstract
The Chief Justice of the Supreme Court plays a critical role in shaping national politics and public policy. While political scientists tend to focus on the ways in which the chief affects the Court’s jurisprudence, relatively little attention has been devoted to the unique administrative aspects of the position that allow for strategic influence over political and legal outcomes. This article examines the role of the chief justice as the head of the Judicial Conference, which is the primary policy making body for federal courts in the United States. Specifically, I examine the degree to which Chief Justice Roberts has appointed members to the Conference’s rulemaking committees with a long-standing conservative legal goal in mind: constricting access to courts. By focusing on the 2015 amendments to the Federal Rules of Civil Procedure in particular, I show that Chief Justice Roberts’ sole discretion to appoint members to these committees constitutes a “purely procedural” role through which he has exercised extensive political power, blurring the line between “law” and “politics” to great effect. View Full-Text   Abstract
Drawing on an ongoing international data collection effort, this paper examines the free expression jurisprudence of the Supreme Court of Canada and the European Court of Human Rights in an effort to assess the political beneficiaries of judicial empowerment. Free expression is a universally recognized fundamental right, and it is a right that is regularly invoked in court by a rich diversity of political actors. As such, free speech law provides an illuminating window onto how constitutional courts respond to similar claims from differently situated claimants. This paper compares the response by two influential courts to free expression claims filed by for-profit businesses and by labor advocates. View Full-Text "," genetic discrimination,concerns,BRCA,Huntington’s disease,living with genetic risk,stigma,regulation,qualitative research,Europe   policy implementation,bureaucratic,administrative agencies, legal,private litigation,tort reform,public opinion,attitudes,survey experiment,policy substance,American state   Chief Justice of the U.S. Supreme Court,Judicial Conference,discovery rules,civil procedure,federal courts   judicial empowerment,judicialization,free speech,freedom of speech,free expression,freedom of expression,Supreme Court of Canada,European Court of Human Rights "," Concerns about Genetic Discrimination after Regulation: A Qualitative Study of the Situation Regarding BRCA and Huntington’s Disease in Belgium   Off to the Courts? Or the Agency? Public Attitudes on Bureaucratic and Legal Approaches to Policy Enforcement   The Administrative Role of the Chief Justice: Law, Politics, and Procedure in the Roberts Court Era   Assessing Judicial Empowerment   Abstract
Although there is no unequivocal evidence of genetic discrimination (GD), and despite laws that prohibit it, individuals confronted with genetic diseases still seem to be concerned. The aim of this study was to gain in-depth understanding of experiences and concerns in relation to possible genetic discrimination. This article presents an analysis of semi-structured interviews with 42 individuals who had or were at risk of breast and ovarian cancer (BRCA) or Huntington’s disease (HD) in Belgium. Even after regulation, individuals at risk of BRCA and HD express concerns about possible genetic discrimination. These concerns relate to direct forms of GD, for instance those related to insurance and employment. Individuals were often unclear about and wary of legislation. Importantly, concerns were also expressed as to more subtle and indirect forms of GD, e.g., in social relations, where individuals fear being treated ‘differently’ and unfairly. Our study demonstrates how these concerns emerge at particular moments in life and how levels and forms of concern are influenced by the specific genetic disorder. Worries concerning these more subtle forms of genetic discrimination are more difficult to protect by law. Current legislative efforts do not appear to be effective in alleviating concerns about genetic discrimination. These regulations seem to be unclear, some participants are unsure about their effectiveness and they do not succeed in incorporating all forms of genetic discrimination. Particularly challenging is how to address indirect forms of genetic discrimination. View Full-Text   Abstract
A key curiosity in the operation of the American regulatory state lies with its hybrid structure, defined by centralized, bureaucratic approaches but also more decentralized actions such as lawsuits brought by private citizens in the courts. While current research on these two pathways focuses at the elite level—exploring how and why political actors and institutions opt for legal or administrative strategies for implementing different public policies—there is little research that examines public attitudes toward how policy is enforced in the U.S. Given that the public is a key partner in this process, this paper integrates public attitudes into the discussion, tapping into conceptions of “big government,” privatization, and the tort reform movement. Using original data from a series of vignette-based experiments included in the 2014 Cooperative Congressional Election Survey, we examine public preferences about how policy is regulated—by private citizens in the courts or by government officials in agencies—across a broad number of policy areas. We offer one of the first studies that adjudicates the boundaries of public attitudes on litigation and bureaucratic regulation in the U.S., offering implications for how elites might approach the design of policy implementation for different issue areas. View Full-Text   Abstract
The Chief Justice of the Supreme Court plays a critical role in shaping national politics and public policy. While political scientists tend to focus on the ways in which the chief affects the Court’s jurisprudence, relatively little attention has been devoted to the unique administrative aspects of the position that allow for strategic influence over political and legal outcomes. This article examines the role of the chief justice as the head of the Judicial Conference, which is the primary policy making body for federal courts in the United States. Specifically, I examine the degree to which Chief Justice Roberts has appointed members to the Conference’s rulemaking committees with a long-standing conservative legal goal in mind: constricting access to courts. By focusing on the 2015 amendments to the Federal Rules of Civil Procedure in particular, I show that Chief Justice Roberts’ sole discretion to appoint members to these committees constitutes a “purely procedural” role through which he has exercised extensive political power, blurring the line between “law” and “politics” to great effect. View Full-Text   Abstract
Drawing on an ongoing international data collection effort, this paper examines the free expression jurisprudence of the Supreme Court of Canada and the European Court of Human Rights in an effort to assess the political beneficiaries of judicial empowerment. Free expression is a universally recognized fundamental right, and it is a right that is regularly invoked in court by a rich diversity of political actors. As such, free speech law provides an illuminating window onto how constitutional courts respond to similar claims from differently situated claimants. This paper compares the response by two influential courts to free expression claims filed by for-profit businesses and by labor advocates. View Full-Text   genetic discrimination,concerns,BRCA,Huntington’s disease,living with genetic risk,stigma,regulation,qualitative research,Europe   policy implementation,bureaucratic,administrative agencies, legal,private litigation,tort reform,public opinion,attitudes,survey experiment,policy substance,American state   Chief Justice of the U.S. Supreme Court,Judicial Conference,discovery rules,civil procedure,federal courts   judicial empowerment,judicialization,free speech,freedom of speech,free expression,freedom of expression,Supreme Court of Canada,European Court of Human Rights ", Laws 
 Design Lessons from Three Australian Dementia Support Facilities   Preventing Dampness Related Health Risks at the Design Stage of Buildings in Mediterranean Climates: A Cyprus Case Study   Autonomous Building Detection Using Edge Properties and Image Color Invariants ," Abstract
There is a significant increase in the number of people with dementia, and the demand for residential support facilities is expected to increase. Providing an appropriate living environment for residents with dementia, which can cater for their specific needs is crucial. Residential aged care design can impact the quality of life and wellbeing of the residents. In this investigation, three recently constructed dementia support facilities in Victoria, Australia are selected for evaluation. Through fieldwork observation, design evaluation and space syntax analysis, the aim of this investigation is to consider the design of these three facilities in the context of current evidence on how the built environment can best accommodate residents with dementia. View Full-Text   Abstract
Dampness is a major building challenge that poses a health risk by aiding the growth of mold and other related microorganisms in very humid areas. Thus, the correction of these post-effects results in high maintenance costs via energy consumption, due to the prolonged heating of damp rooms and post-treatment, especially during the winter. A survey of 2000 valid respondents living in apartment-style buildings was conducted and analyzed using SPSS software. In this study, the AutoDesk Computational Fluid Dynamics (ACFD) software was used to perform a simulation for building materials analysis, to evaluate them for suitability in high humidity areas and to select the best building orientation for adequate and natural ventilation. The analysis aimed to observe the indoor air conditions due to environmental air flow conditions. The relationships of the airflow conditions to the material properties were measured. The methodology involves a Failure Modes and Effects Analysis to determine the level and nature of the dampness sources. The Design-Expert Statistical-Software 10 confirmed the simulation results. The simulation revealed a lower percentage of relative humidity and temperature in Adobe walls than in brick walls. View Full-Text   Abstract
Automated building extraction from high-resolution satellite imagery is a challenging research problem, and several issues remain with respect to the variety of variables to be accounted for. In this paper we present an approach for building detection using multiple cues. We use the shadow, shape, and color features of buildings to propose our approach, known as Building Detection with Shadow Verification (BDSV). BDSV has three main pillars, which are: (1) tile building detection (TBD) to detect roof tile buildings; (2) flat building detection (FBD) to detect non-tile flat buildings according to shape features; and (3) results fusion used to fuse and aggregate results from previous blocks. Analyses performed over different study areas reveal high quality percentage and precision metrics, exceeding 95%. Performance analysis over the SztaKi–Inria and Istanbul datasets shows that BDSV outperforms benchmark algorithms. View Full-Text "," design for dementia,dementia-friendly,design evaluation,dementia support facilities,residential aged care,built environment,space syntax,wayfinding,behavior cues,orientation cues   Computational Fluid Dynamics (CFD),dampness,design stage,materials,mold   building extraction,remote sensing,shadow detection,hypothesis and validation,object identification "," Design Lessons from Three Australian Dementia Support Facilities   Preventing Dampness Related Health Risks at the Design Stage of Buildings in Mediterranean Climates: A Cyprus Case Study   Autonomous Building Detection Using Edge Properties and Image Color Invariants   Abstract
There is a significant increase in the number of people with dementia, and the demand for residential support facilities is expected to increase. Providing an appropriate living environment for residents with dementia, which can cater for their specific needs is crucial. Residential aged care design can impact the quality of life and wellbeing of the residents. In this investigation, three recently constructed dementia support facilities in Victoria, Australia are selected for evaluation. Through fieldwork observation, design evaluation and space syntax analysis, the aim of this investigation is to consider the design of these three facilities in the context of current evidence on how the built environment can best accommodate residents with dementia. View Full-Text   Abstract
Dampness is a major building challenge that poses a health risk by aiding the growth of mold and other related microorganisms in very humid areas. Thus, the correction of these post-effects results in high maintenance costs via energy consumption, due to the prolonged heating of damp rooms and post-treatment, especially during the winter. A survey of 2000 valid respondents living in apartment-style buildings was conducted and analyzed using SPSS software. In this study, the AutoDesk Computational Fluid Dynamics (ACFD) software was used to perform a simulation for building materials analysis, to evaluate them for suitability in high humidity areas and to select the best building orientation for adequate and natural ventilation. The analysis aimed to observe the indoor air conditions due to environmental air flow conditions. The relationships of the airflow conditions to the material properties were measured. The methodology involves a Failure Modes and Effects Analysis to determine the level and nature of the dampness sources. The Design-Expert Statistical-Software 10 confirmed the simulation results. The simulation revealed a lower percentage of relative humidity and temperature in Adobe walls than in brick walls. View Full-Text   Abstract
Automated building extraction from high-resolution satellite imagery is a challenging research problem, and several issues remain with respect to the variety of variables to be accounted for. In this paper we present an approach for building detection using multiple cues. We use the shadow, shape, and color features of buildings to propose our approach, known as Building Detection with Shadow Verification (BDSV). BDSV has three main pillars, which are: (1) tile building detection (TBD) to detect roof tile buildings; (2) flat building detection (FBD) to detect non-tile flat buildings according to shape features; and (3) results fusion used to fuse and aggregate results from previous blocks. Analyses performed over different study areas reveal high quality percentage and precision metrics, exceeding 95%. Performance analysis over the SztaKi–Inria and Istanbul datasets shows that BDSV outperforms benchmark algorithms. View Full-Text   design for dementia,dementia-friendly,design evaluation,dementia support facilities,residential aged care,built environment,space syntax,wayfinding,behavior cues,orientation cues   Computational Fluid Dynamics (CFD),dampness,design stage,materials,mold   building extraction,remote sensing,shadow detection,hypothesis and validation,object identification ", Buildings 
 Anime Landscapes as a Tool for Analyzing the Human–Environment Relationship: Hayao Miyazaki Films   Re: Sex-Bots—Let Us Look before We Leap   Paleolithic Rock Art: A Worldwide Literature Survey Extracted from the Rock Art Studies Bibliographic Database for the Years 1864–2017†   The Original “Cybernetic Serendipity” Special Issue of Studio International to Be Reprinted ," Abstract
Common dualistic thinking in environmental design education adopts humans and the environment as separate entities, with the environment as raw material stock. This approach affects the intellectual development of landscape architects and limits their ability to create meaningful landscapes. Therefore, it is necessary to explore and highlight new ideas about the more integrated human–environment relationship. Through the films of Hayao Miyazaki, many audiences around the world have encountered a different worldview. By contrast with Western thinking, which adopts human superiority to nature, the worldview that Miyazaki reflects in his films depicts human as an inseparable part of nature. Being inspired by different communities and their relationship to nature in Miyazaki’s films, we propose using anime as a means of analyzing the human–environment relationship. We classified landscapes based on power relations between humans and nature. We explored how communities shape their physical environment based on how they socially construct nature and the resulting landscapes. Thus, through apocalyptic landscapes, the bitter results of exploiting nature were depicted. Wilderness landscapes reflect the bias humanity has about nature as wild and hostile. Responsible landscapes were introduced asway of understanding the unbreakable bond between humans and the environment. Through these animated landscape types, the ways landscape architecture should approach nature in professional practices was discussed, and the importance of creating responsible landscapes was emphasized. View Full-Text   Abstract
With the understanding that a substantial commerce in sexually-enabled robots represents a plunge into the unknown for humankind, and at the “deep end of the pool”—i.e., involving one of the most important, complex, and problem-ridden aspects of human existence—it is the goal of this brief opinion piece to help ensure that we remain aware as a society of some of the potential pitfalls—these, as is quite appropriate for an opinion piece of this kind, illustrated via negative but plausible scenarios—and presented as well in the light of the multi-dimensional aspect of human sexuality; and with the reality of a certain level of risk associated with sex-bots having been established, there are presented in conclusion some potentially strategic considerations for those professionals who find themselves involved with their design, production, and/or marketing. View Full-Text   Abstract
The Rock Art Studies Bibliographic Database is an open access; online resource that fulfills the need for a searchable portal into the world’s rock art literature. Geared to the broadest interests of rock art researchers; students; cultural resource managers; and the general public; the RAS database makes rock art literature accessible through a simple search interface that facilitates inquiries into multiple data fields; including authors’ names; title and publication; place-name keyword; subject keyword; ISBN/ISSN number and abstract. The results of a data search can further be sorted by any of the data fields; including: authors’ names; date; title; and so forth. An ever increasing number of citations within the database include web links to online versions of the reference cited; and many citations include full author’s abstracts. The data compilation has been undertaken by Leigh Marymor with the year 2018 marking the 25th year of continuous revision and expansion of the data. Over 37,000 citations are currently contained in the database. The RAS database first launched online as a joint project of the Bay Area Rock Art Research Association and University of California’s Bancroft Library. After thirteen years of collaboration; the project found a new home and collaborator at the Anthropology Department at the Museum of Northern Arizona. The Paleolithic Rock Art bibliography results from an export of data from the RAS database and captures a freeze-frame in the state of the rock art literature for the world’s Paleolithic rock art as compiled here in the year 2018. The online version of the RAS Bibliographic Database at the Museum of Northern Arizona is updated annually; and we refer the reader to that resource for up-to-date bibliographic data revisions and additions. Researchers who consult the online database in concert with their reference to the Paleolithic Rock Art bibliography will discover a powerful ally in further refining geographic and thematic inquiries. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Studio International (Studio International 2018), the now on-line successor to print art magazine The Studio, is planning a late April 2018 50th anniversary reprinting of its Special Issue dedicated to the historic 1968 “Cybernetic Serendipity” techno-art exhibition (Benavides 2018a)[...] View Full-Text "," human–environment relationship,Hayao Miyazaki,anime,landscape type,wilderness,apocalyptic,responsible,deep ecology   sexually-enabled robot,sex-bot,sex,sexuality,inherited disease resistance,DNA repair,bastard muses,robotic caregiver,open source AI,open source robotics   Paleolithic,bibliography,rock art studies,world    "," Anime Landscapes as a Tool for Analyzing the Human–Environment Relationship: Hayao Miyazaki Films   Re: Sex-Bots—Let Us Look before We Leap   Paleolithic Rock Art: A Worldwide Literature Survey Extracted from the Rock Art Studies Bibliographic Database for the Years 1864–2017†   The Original “Cybernetic Serendipity” Special Issue of Studio International to Be Reprinted   Abstract
Common dualistic thinking in environmental design education adopts humans and the environment as separate entities, with the environment as raw material stock. This approach affects the intellectual development of landscape architects and limits their ability to create meaningful landscapes. Therefore, it is necessary to explore and highlight new ideas about the more integrated human–environment relationship. Through the films of Hayao Miyazaki, many audiences around the world have encountered a different worldview. By contrast with Western thinking, which adopts human superiority to nature, the worldview that Miyazaki reflects in his films depicts human as an inseparable part of nature. Being inspired by different communities and their relationship to nature in Miyazaki’s films, we propose using anime as a means of analyzing the human–environment relationship. We classified landscapes based on power relations between humans and nature. We explored how communities shape their physical environment based on how they socially construct nature and the resulting landscapes. Thus, through apocalyptic landscapes, the bitter results of exploiting nature were depicted. Wilderness landscapes reflect the bias humanity has about nature as wild and hostile. Responsible landscapes were introduced asway of understanding the unbreakable bond between humans and the environment. Through these animated landscape types, the ways landscape architecture should approach nature in professional practices was discussed, and the importance of creating responsible landscapes was emphasized. View Full-Text   Abstract
With the understanding that a substantial commerce in sexually-enabled robots represents a plunge into the unknown for humankind, and at the “deep end of the pool”—i.e., involving one of the most important, complex, and problem-ridden aspects of human existence—it is the goal of this brief opinion piece to help ensure that we remain aware as a society of some of the potential pitfalls—these, as is quite appropriate for an opinion piece of this kind, illustrated via negative but plausible scenarios—and presented as well in the light of the multi-dimensional aspect of human sexuality; and with the reality of a certain level of risk associated with sex-bots having been established, there are presented in conclusion some potentially strategic considerations for those professionals who find themselves involved with their design, production, and/or marketing. View Full-Text   Abstract
The Rock Art Studies Bibliographic Database is an open access; online resource that fulfills the need for a searchable portal into the world’s rock art literature. Geared to the broadest interests of rock art researchers; students; cultural resource managers; and the general public; the RAS database makes rock art literature accessible through a simple search interface that facilitates inquiries into multiple data fields; including authors’ names; title and publication; place-name keyword; subject keyword; ISBN/ISSN number and abstract. The results of a data search can further be sorted by any of the data fields; including: authors’ names; date; title; and so forth. An ever increasing number of citations within the database include web links to online versions of the reference cited; and many citations include full author’s abstracts. The data compilation has been undertaken by Leigh Marymor with the year 2018 marking the 25th year of continuous revision and expansion of the data. Over 37,000 citations are currently contained in the database. The RAS database first launched online as a joint project of the Bay Area Rock Art Research Association and University of California’s Bancroft Library. After thirteen years of collaboration; the project found a new home and collaborator at the Anthropology Department at the Museum of Northern Arizona. The Paleolithic Rock Art bibliography results from an export of data from the RAS database and captures a freeze-frame in the state of the rock art literature for the world’s Paleolithic rock art as compiled here in the year 2018. The online version of the RAS Bibliographic Database at the Museum of Northern Arizona is updated annually; and we refer the reader to that resource for up-to-date bibliographic data revisions and additions. Researchers who consult the online database in concert with their reference to the Paleolithic Rock Art bibliography will discover a powerful ally in further refining geographic and thematic inquiries. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Studio International (Studio International 2018), the now on-line successor to print art magazine The Studio, is planning a late April 2018 50th anniversary reprinting of its Special Issue dedicated to the historic 1968 “Cybernetic Serendipity” techno-art exhibition (Benavides 2018a)[...] View Full-Text   human–environment relationship,Hayao Miyazaki,anime,landscape type,wilderness,apocalyptic,responsible,deep ecology   sexually-enabled robot,sex-bot,sex,sexuality,inherited disease resistance,DNA repair,bastard muses,robotic caregiver,open source AI,open source robotics   Paleolithic,bibliography,rock art studies,world    ", Arts 
 Dynamics in the Field of Museums: Contemporary Challenges for Polish Museologists   Settlement and Integration Needs of Skilled Immigrants in Canada   Running in Someone Else’s Shoes: The Electoral Consequences of Running as an Appointed Senator   Diminished Economic Return of Socioeconomic Status for Black Families ," Abstract
The aim of this text is to present and analyze the attitudes of Polish museologists towards the changes currently taking place in the field of museums. More specifically, it will focus on their opinions regarding the evolution of museums—from the traditional model, based on symbolic violence, to the contemporary model, which accents the subjectivity of the audience. Its conclusions, based on analyses of 26 qualitative interviews with employees of Polish museums, are as follows: the organizational changes taking place in Polish museums do not relieve museologists from bureaucratic work; the collections in museums distinguish them from other institutions of culture; there is a struggle for symbolic advantage among actors in the field of museology; museologists do not know their audience well. The interviews also revealed that the assumptions of the New Museology have less impact on practice than is suggested in literature, and that everyday museology combines elements of the ‘old’ and ‘new’ philosophies. View Full-Text   Abstract
It is often believed that the settlement and integration of skilled immigrants is moderately easy in Canada, and that skilled immigrants do well in Canada after a brief adjustment period. However, numerous barriers prevent the effective integration of skilled immigrants in the mainstream society. Despite being famous for its Federal Skilled Worker Program, which includes the immigration of skilled workers through Express Entry, Canada shows disappointing results in the economic and social outcomes of the integration of skilled immigrants. This has socioeconomic implications for the immigrants and affects their health and wellbeing. Therefore, there is a need for all those who are involved with immigrant integration to explore and be conversant about the contexts and issues faced by skilled newcomers in Canada. In reviewing the academic and grey literature on the settlement and integration of skilled immigrants in Canada, this paper highlights the challenges faced by skilled immigrants in Canada and the needs experienced by them in facing these challenges. It provides an overview of the experiences and expectations of skilled immigrants related to their settlement and integration in Canada. This paper indicates a need to evaluate the availability of immigrant services focused on skilled immigrants and the effectiveness of the existing support offered to them by various government and non-government agencies. View Full-Text   Abstract
Over the past century, nearly two hundred times a governor has appointed an individual to fill a vacant Senate seat. This research seeks to understand the electoral fates of these appointed senators. First, I address the question of when and under what conditions an appointed senator will choose to run for reelection to the seat. Then, should they choose to run for that office in the next election, they are in the rare position of being an incumbent who has not previously won an election to that particular office. Although these appointed senators are not on equal footing as other first-term senators, they still provide a unique circumstance worthy of further examination. I find that those appointed senators who had previously held an elected office were more likely to run to maintain the Senate seat. I also find that appointed senators fare slightly worse than other first-term senators did when campaigning for reelection. View Full-Text   Abstract
Background: According to the Minorities’ Diminished Return theory, socioeconomic status (SES) systemically generates larger gains for Whites compared to Blacks. It is, however, unknown whether the effects of baseline SES on future family income also varies between Blacks and Whites. Aims: Using a national sample, this study investigated racial variation in the effects of family SES (i.e., family structure, maternal education, and income) at birth on subsequent household income at age 15. Methods: This 15-year longitudinal study used data from the Fragile Families and Child Wellbeing Study (FFCWS), which followed 1471 non-Hispanic Black or White families from the time of birth of their child for 15 years. Two family SES indicators (maternal education and income) at birth were the independent variables. Family income 15 years later was the outcome. Maternal age, child gender, and family structure at baseline were covariates. Race was the focal moderator. Linear regression models were used for data analysis. Results: In the pooled sample, maternal education (b = 11.62, p < 0.001) and household income (b = 0.73, p < 0.001) at baseline were predictive of family income 15 years later. Race, however, interacted with maternal education (b = −12,073.89, p < 0.001) and household income (b = −312.47, p < 0.001) at birth on household income 15 years later, indicating smaller effects for Black compared to White families. These differential gains were independent of family structure, mother age, and child gender. Conclusions: The economic return of family SES is smaller for Black compared to White families, regardless of the SES indicator. Policies should specifically address structural barriers in the lives of racial and ethnic minorities to minimize the diminished return of SES resources across racial minority groups. Policies should also reduce extra costs of upward social mobility for racial minorities. As the likely causes are multi-level, solutions should also be also multi-level. Without such interventions, it may be very difficult if not impossible to eliminate the existing Black–White economic gap. View Full-Text "," museum,New Museology,field of museums,cultural institution   skilled immigrants,immigrant integration,barriers to integration,settlement and integration needs   senate elections,appointments,incumbency advantage   socioeconomic status,income,education,ethnic groups,Blacks,ethnicity,families,parents "," Dynamics in the Field of Museums: Contemporary Challenges for Polish Museologists   Settlement and Integration Needs of Skilled Immigrants in Canada   Running in Someone Else’s Shoes: The Electoral Consequences of Running as an Appointed Senator   Diminished Economic Return of Socioeconomic Status for Black Families   Abstract
The aim of this text is to present and analyze the attitudes of Polish museologists towards the changes currently taking place in the field of museums. More specifically, it will focus on their opinions regarding the evolution of museums—from the traditional model, based on symbolic violence, to the contemporary model, which accents the subjectivity of the audience. Its conclusions, based on analyses of 26 qualitative interviews with employees of Polish museums, are as follows: the organizational changes taking place in Polish museums do not relieve museologists from bureaucratic work; the collections in museums distinguish them from other institutions of culture; there is a struggle for symbolic advantage among actors in the field of museology; museologists do not know their audience well. The interviews also revealed that the assumptions of the New Museology have less impact on practice than is suggested in literature, and that everyday museology combines elements of the ‘old’ and ‘new’ philosophies. View Full-Text   Abstract
It is often believed that the settlement and integration of skilled immigrants is moderately easy in Canada, and that skilled immigrants do well in Canada after a brief adjustment period. However, numerous barriers prevent the effective integration of skilled immigrants in the mainstream society. Despite being famous for its Federal Skilled Worker Program, which includes the immigration of skilled workers through Express Entry, Canada shows disappointing results in the economic and social outcomes of the integration of skilled immigrants. This has socioeconomic implications for the immigrants and affects their health and wellbeing. Therefore, there is a need for all those who are involved with immigrant integration to explore and be conversant about the contexts and issues faced by skilled newcomers in Canada. In reviewing the academic and grey literature on the settlement and integration of skilled immigrants in Canada, this paper highlights the challenges faced by skilled immigrants in Canada and the needs experienced by them in facing these challenges. It provides an overview of the experiences and expectations of skilled immigrants related to their settlement and integration in Canada. This paper indicates a need to evaluate the availability of immigrant services focused on skilled immigrants and the effectiveness of the existing support offered to them by various government and non-government agencies. View Full-Text   Abstract
Over the past century, nearly two hundred times a governor has appointed an individual to fill a vacant Senate seat. This research seeks to understand the electoral fates of these appointed senators. First, I address the question of when and under what conditions an appointed senator will choose to run for reelection to the seat. Then, should they choose to run for that office in the next election, they are in the rare position of being an incumbent who has not previously won an election to that particular office. Although these appointed senators are not on equal footing as other first-term senators, they still provide a unique circumstance worthy of further examination. I find that those appointed senators who had previously held an elected office were more likely to run to maintain the Senate seat. I also find that appointed senators fare slightly worse than other first-term senators did when campaigning for reelection. View Full-Text   Abstract
Background: According to the Minorities’ Diminished Return theory, socioeconomic status (SES) systemically generates larger gains for Whites compared to Blacks. It is, however, unknown whether the effects of baseline SES on future family income also varies between Blacks and Whites. Aims: Using a national sample, this study investigated racial variation in the effects of family SES (i.e., family structure, maternal education, and income) at birth on subsequent household income at age 15. Methods: This 15-year longitudinal study used data from the Fragile Families and Child Wellbeing Study (FFCWS), which followed 1471 non-Hispanic Black or White families from the time of birth of their child for 15 years. Two family SES indicators (maternal education and income) at birth were the independent variables. Family income 15 years later was the outcome. Maternal age, child gender, and family structure at baseline were covariates. Race was the focal moderator. Linear regression models were used for data analysis. Results: In the pooled sample, maternal education (b = 11.62, p < 0.001) and household income (b = 0.73, p < 0.001) at baseline were predictive of family income 15 years later. Race, however, interacted with maternal education (b = −12,073.89, p < 0.001) and household income (b = −312.47, p < 0.001) at birth on household income 15 years later, indicating smaller effects for Black compared to White families. These differential gains were independent of family structure, mother age, and child gender. Conclusions: The economic return of family SES is smaller for Black compared to White families, regardless of the SES indicator. Policies should specifically address structural barriers in the lives of racial and ethnic minorities to minimize the diminished return of SES resources across racial minority groups. Policies should also reduce extra costs of upward social mobility for racial minorities. As the likely causes are multi-level, solutions should also be also multi-level. Without such interventions, it may be very difficult if not impossible to eliminate the existing Black–White economic gap. View Full-Text   museum,New Museology,field of museums,cultural institution   skilled immigrants,immigrant integration,barriers to integration,settlement and integration needs   senate elections,appointments,incumbency advantage   socioeconomic status,income,education,ethnic groups,Blacks,ethnicity,families,parents ", Social Sciences 
 The Question of Space: A Review Essay   A Preliminary Discussion of Some Important Discoveries Regarding Seaport Sites for Porcelain Shipping in the Jin Dynasty   Staging Encounters with Estranged Pasts: Radu Jude’s The Dead Nation (2017) and the Cinematic Face of Public Memory of the Holocaust in Present-Day Romania   Were Neanderthals Rational? A Stoic Approach ," Abstract
This article is a review essay which discusses the inter-disciplinary collection of essays edited by Marijn Nieuwenhuis and David Crouch, titled The Question of Space: Interrogating the Spatial Turn between Disciplines (London: Rowman & Littlefield 2017). The book was published as part of the Place, Memory, Affect series, edited by Neil Campbell and Christine Berberich. As well as providing a detailed critical overview of The Question of Space, the article responds to some of the broader questions that the book poses in terms of the radical inter-disciplinary of space and spatiality, relating these firstly to ideas drawn from Henri Lefebvre’s discussion of ‘blind fields’. The review essay then goes on to question what we might understand by the so-called ‘spatial turn’ and whether this itself requires some rethinking in order to better take stock of the developments in and around the inter-disciplinary scholarship on space and spatiality. Following this, the essay engages more directly with the individual chapter contributions in The Question of Space, before drawing together some concluding remarks that speak to the concept of ‘atmosphere’ as an affective and phenomenological quality of space as experiential and embodied ‘spacing’. View Full-Text   Abstract
The seaports of the Jin dynasty have not been given enough attention for a long time. In recent years, some important seaport sites of the Jin dynasty have been discovered or reported, for example the Haifengzhen (海丰镇) site in Hebei Province, and the Haibei (海北) and Banqiaozhen (板桥镇) sites in Shandong Province. Based on these discoveries and other related information, we can try to analyze and infer the function and system of these seaports in the Jin dynasty. Firstly, Banqiaozhen Shi Bo Si (市舶司), the Northern Song Dynasty’s only foreign trade administration in the north of China, suffered a great deal of damage during the war at the end of the Northern Song dynasty. As a consequence, the porcelains produced in Northern China during the Jin Dynasty, such as Cizhou Ware (磁州窑), Cicun Ware (磁村窑), and Ding Ware (定窑) needed new seaports for access to the Korean Peninsula and Japan. It has been reported that many of these porcelains were discovered at Korean and Japanese sites, which correspond to the years of the Jin dynasty. Furthermore, a large number of these porcelains were discovered at the Haifengzhen and Haibei sites. There is thus a very strong possibility that these two sites were departure ports to East Asia of the Maritime Silk Road during the Jin Dynasty. Secondly, many porcelains produced in Southern China, especially Jingdezhen Ware (景德镇窑), have been discovered at the Haifengzhen, Haibei, and Banqiaozhen sites. Some Ding Ware products were also discovered in the lower reaches of the Yangtze River during the Southern Song Dynasty, and also many Cizhou Ware and Ding Ware products were discovered in Northeastern China during the Jin Dynasty. Furthermore, in the coastal waters on the northern side of the Haifengzhen site, archaeologists have found some traces of shipwrecks dating from the same time. Based on the above information, we infer that the Haifengzhen, Haibei, and Banqiaozhen sites might also have played an important role in the seaway transshipment between Southern and Northern China during this period. In conclusion, we can determine that the recently discovered seaports of the Jin dynasty had two functions and systems, both internal and external:the Haifengzhen and Haibei sites opened China up to the Korean Peninsula and Japan, while the Haifengzhen, Haibei, and Banqiaozhen sites might also have been used for domestic coastal shipping. View Full-Text   Abstract
This article provides a close analysis of Radu Jude’s The Dead Nation (2017), a documentary essay that brings together authentic archival sources documenting the persecution and murder of Jews in World War II. The sources include a little-known diary of Emil Dorian, a Jewish medical doctor and writer from Bucharest, a collection of photographs depicting scenes from Romanian daily life in the 1930s and 1940s, and recordings of political speeches and propaganda songs of a Fascist nature. Through a careful framing of this film in relation to Romanian public memory of World War II, and in connection to the popular new wave cinema, I will contend that Jude’s work acts, perhaps unwittingly, to intervene in public memory and invites the Romanian public to face up to and acknowledge the nation’s perpetrator past. This filmic intervention further offers an important platform for public debate on Romania’s Holocaust memory and is of significance for European public memory, as it proposes the film happening as a distinct and innovative practice of public engagement with history. View Full-Text   Abstract
This paper adopts the philosophical approach of Stoicism as the basis for re-examining the cognitive and ethical relationship between Homo sapiens and Neanderthals. Stoicism sets out a clear criterion for the special moral status of human beings, namely rationality. We explore to what extent Neanderthals were sufficiently rational to be considered “human”. Recent findings in the fields of palaeoanthropology and palaeogenetics show that Neanderthals possessed high-level cognitive abilities and produced viable offspring with anatomically modern humans. Our discussion offers insights for reflecting on the relationship between humans and other forms of natural life and any moral obligations that result. View Full-Text "," spatial turn,affect,phenomenology,interdisciplinary,non-representational,autoethnography,performance,deep mapping,experience   seaport,porcelain shipping,Jin dynasty,maritime silk road,domestic transshipment   public memory,post-1989 Romania,Radu Jude,Emil Dorian,cinematic intervention,dialectical montage,public reception   circles of concern,eudaimonia,human evolution,speciesism,stoicism and science "," The Question of Space: A Review Essay   A Preliminary Discussion of Some Important Discoveries Regarding Seaport Sites for Porcelain Shipping in the Jin Dynasty   Staging Encounters with Estranged Pasts: Radu Jude’s The Dead Nation (2017) and the Cinematic Face of Public Memory of the Holocaust in Present-Day Romania   Were Neanderthals Rational? A Stoic Approach   Abstract
This article is a review essay which discusses the inter-disciplinary collection of essays edited by Marijn Nieuwenhuis and David Crouch, titled The Question of Space: Interrogating the Spatial Turn between Disciplines (London: Rowman & Littlefield 2017). The book was published as part of the Place, Memory, Affect series, edited by Neil Campbell and Christine Berberich. As well as providing a detailed critical overview of The Question of Space, the article responds to some of the broader questions that the book poses in terms of the radical inter-disciplinary of space and spatiality, relating these firstly to ideas drawn from Henri Lefebvre’s discussion of ‘blind fields’. The review essay then goes on to question what we might understand by the so-called ‘spatial turn’ and whether this itself requires some rethinking in order to better take stock of the developments in and around the inter-disciplinary scholarship on space and spatiality. Following this, the essay engages more directly with the individual chapter contributions in The Question of Space, before drawing together some concluding remarks that speak to the concept of ‘atmosphere’ as an affective and phenomenological quality of space as experiential and embodied ‘spacing’. View Full-Text   Abstract
The seaports of the Jin dynasty have not been given enough attention for a long time. In recent years, some important seaport sites of the Jin dynasty have been discovered or reported, for example the Haifengzhen (海丰镇) site in Hebei Province, and the Haibei (海北) and Banqiaozhen (板桥镇) sites in Shandong Province. Based on these discoveries and other related information, we can try to analyze and infer the function and system of these seaports in the Jin dynasty. Firstly, Banqiaozhen Shi Bo Si (市舶司), the Northern Song Dynasty’s only foreign trade administration in the north of China, suffered a great deal of damage during the war at the end of the Northern Song dynasty. As a consequence, the porcelains produced in Northern China during the Jin Dynasty, such as Cizhou Ware (磁州窑), Cicun Ware (磁村窑), and Ding Ware (定窑) needed new seaports for access to the Korean Peninsula and Japan. It has been reported that many of these porcelains were discovered at Korean and Japanese sites, which correspond to the years of the Jin dynasty. Furthermore, a large number of these porcelains were discovered at the Haifengzhen and Haibei sites. There is thus a very strong possibility that these two sites were departure ports to East Asia of the Maritime Silk Road during the Jin Dynasty. Secondly, many porcelains produced in Southern China, especially Jingdezhen Ware (景德镇窑), have been discovered at the Haifengzhen, Haibei, and Banqiaozhen sites. Some Ding Ware products were also discovered in the lower reaches of the Yangtze River during the Southern Song Dynasty, and also many Cizhou Ware and Ding Ware products were discovered in Northeastern China during the Jin Dynasty. Furthermore, in the coastal waters on the northern side of the Haifengzhen site, archaeologists have found some traces of shipwrecks dating from the same time. Based on the above information, we infer that the Haifengzhen, Haibei, and Banqiaozhen sites might also have played an important role in the seaway transshipment between Southern and Northern China during this period. In conclusion, we can determine that the recently discovered seaports of the Jin dynasty had two functions and systems, both internal and external:the Haifengzhen and Haibei sites opened China up to the Korean Peninsula and Japan, while the Haifengzhen, Haibei, and Banqiaozhen sites might also have been used for domestic coastal shipping. View Full-Text   Abstract
This article provides a close analysis of Radu Jude’s The Dead Nation (2017), a documentary essay that brings together authentic archival sources documenting the persecution and murder of Jews in World War II. The sources include a little-known diary of Emil Dorian, a Jewish medical doctor and writer from Bucharest, a collection of photographs depicting scenes from Romanian daily life in the 1930s and 1940s, and recordings of political speeches and propaganda songs of a Fascist nature. Through a careful framing of this film in relation to Romanian public memory of World War II, and in connection to the popular new wave cinema, I will contend that Jude’s work acts, perhaps unwittingly, to intervene in public memory and invites the Romanian public to face up to and acknowledge the nation’s perpetrator past. This filmic intervention further offers an important platform for public debate on Romania’s Holocaust memory and is of significance for European public memory, as it proposes the film happening as a distinct and innovative practice of public engagement with history. View Full-Text   Abstract
This paper adopts the philosophical approach of Stoicism as the basis for re-examining the cognitive and ethical relationship between Homo sapiens and Neanderthals. Stoicism sets out a clear criterion for the special moral status of human beings, namely rationality. We explore to what extent Neanderthals were sufficiently rational to be considered “human”. Recent findings in the fields of palaeoanthropology and palaeogenetics show that Neanderthals possessed high-level cognitive abilities and produced viable offspring with anatomically modern humans. Our discussion offers insights for reflecting on the relationship between humans and other forms of natural life and any moral obligations that result. View Full-Text   spatial turn,affect,phenomenology,interdisciplinary,non-representational,autoethnography,performance,deep mapping,experience   seaport,porcelain shipping,Jin dynasty,maritime silk road,domestic transshipment   public memory,post-1989 Romania,Radu Jude,Emil Dorian,cinematic intervention,dialectical montage,public reception   circles of concern,eudaimonia,human evolution,speciesism,stoicism and science ", Humanities 
" Molecular Responses to the Zika Virus in Mosquitoes   Adenylate Cyclases of Trypanosoma brucei, Environmental Sensors and Controllers of Host Innate Immune Response   Genome Characterization of a Pathogenic Porcine Rotavirus B Strain Identified in Buryat Republic, Russia in 2015 "," Abstract
The Zika virus (ZIKV), originally discovered in 1947, did not become a major concern until the virus swept across the Pacific and into the Americas in the last decade, bringing with it news of neurological complications and birth defects in ZIKV affected areas. This prompted researchers to dissect the molecular interactions between ZIKV and the mosquito vector in an attempt to better understand not only the changes that occur upon infection, but to also identify molecules that may potentially enhance or suppress a mosquito’s ability to become infected and/or transmit the virus. Here, we review what is currently known regarding ZIKV-mosquito molecular interactions, focusing on ZIKV infection of Aedes aegypti and Aedes albopictus, the primary species implicated in transmitting ZIKV during the recent outbreaks. View Full-Text   Abstract
Trypanosoma brucei, etiological agent of Sleeping Sickness in Africa, is the prototype of African trypanosomes, protozoan extracellular flagellate parasites transmitted by saliva (Salivaria). In these parasites the molecular controls of the cell cycle and environmental sensing are elaborate and concentrated at the flagellum. Genomic analyses suggest that these parasites appear to differ considerably from the host in signaling mechanisms, with the exception of receptor-type adenylate cyclases (AC) that are topologically similar to receptor-type guanylate cyclase (GC) of higher eukaryotes but control a new class of cAMP targets of unknown function, the cAMP response proteins (CARPs), rather than the classical protein kinase A cAMP effector (PKA). T. brucei possesses a large polymorphic family of ACs, mainly associated with the flagellar membrane, and these are involved in inhibition of the innate immune response of the host prior to the massive release of immunomodulatory factors at the first peak of parasitemia. Recent evidence suggests that in T. brucei several insect-specific AC isoforms are involved in social motility, whereas only a few AC isoforms are involved in cytokinesis control of bloodstream forms, attesting that a complex signaling pathway is required for environmental sensing. In this review, after a general update on cAMP signaling pathway and the multiple roles of cAMP, I summarize the existing knowledge of the mechanisms by which pathogenic microorganisms modulate cAMP levels to escape immune defense. View Full-Text   Abstract
An outbreak of enteric disease of unknown etiology with 60% morbidity and 8% mortality in weaning piglets occurred in November 2015 on a farm in Buryat Republic, Russia. Metagenomic sequencing revealed the presence of rotavirus B in feces from diseased piglets while no other pathogens were identified. Clinical disease was reproduced in experimentally infected piglets, yielding the 11 RVB gene segments for strain Buryat15, with an RVB genotype constellation of G12-P[4]-I13-R4-C4-M4-A8-N10-T4-E4-H7. This genotype constellation has also been identified in the United States. While the Buryat15 VP7 protein lacked unique amino acid differences in the predicted neutralizing epitopes compared to the previously published swine RVB G12 strains, this report of RVB in Russian swine increases our epidemiological knowledge on the global prevalence and genetic diversity of RVB. View Full-Text "," Flavivirus,ZIKV,Aedes aegypti,Aedes albopictus   Trypanosoma brucei,adenylate cyclase,cAMP signaling,innate immunity,inflammation,TNF-α   porcine group B rotavirus,RVB,gastrointestinal disease,porcine enteric disease,phylogenetic analysis "," Molecular Responses to the Zika Virus in Mosquitoes   Adenylate Cyclases of Trypanosoma brucei, Environmental Sensors and Controllers of Host Innate Immune Response   Genome Characterization of a Pathogenic Porcine Rotavirus B Strain Identified in Buryat Republic, Russia in 2015   Abstract
The Zika virus (ZIKV), originally discovered in 1947, did not become a major concern until the virus swept across the Pacific and into the Americas in the last decade, bringing with it news of neurological complications and birth defects in ZIKV affected areas. This prompted researchers to dissect the molecular interactions between ZIKV and the mosquito vector in an attempt to better understand not only the changes that occur upon infection, but to also identify molecules that may potentially enhance or suppress a mosquito’s ability to become infected and/or transmit the virus. Here, we review what is currently known regarding ZIKV-mosquito molecular interactions, focusing on ZIKV infection of Aedes aegypti and Aedes albopictus, the primary species implicated in transmitting ZIKV during the recent outbreaks. View Full-Text   Abstract
Trypanosoma brucei, etiological agent of Sleeping Sickness in Africa, is the prototype of African trypanosomes, protozoan extracellular flagellate parasites transmitted by saliva (Salivaria). In these parasites the molecular controls of the cell cycle and environmental sensing are elaborate and concentrated at the flagellum. Genomic analyses suggest that these parasites appear to differ considerably from the host in signaling mechanisms, with the exception of receptor-type adenylate cyclases (AC) that are topologically similar to receptor-type guanylate cyclase (GC) of higher eukaryotes but control a new class of cAMP targets of unknown function, the cAMP response proteins (CARPs), rather than the classical protein kinase A cAMP effector (PKA). T. brucei possesses a large polymorphic family of ACs, mainly associated with the flagellar membrane, and these are involved in inhibition of the innate immune response of the host prior to the massive release of immunomodulatory factors at the first peak of parasitemia. Recent evidence suggests that in T. brucei several insect-specific AC isoforms are involved in social motility, whereas only a few AC isoforms are involved in cytokinesis control of bloodstream forms, attesting that a complex signaling pathway is required for environmental sensing. In this review, after a general update on cAMP signaling pathway and the multiple roles of cAMP, I summarize the existing knowledge of the mechanisms by which pathogenic microorganisms modulate cAMP levels to escape immune defense. View Full-Text   Abstract
An outbreak of enteric disease of unknown etiology with 60% morbidity and 8% mortality in weaning piglets occurred in November 2015 on a farm in Buryat Republic, Russia. Metagenomic sequencing revealed the presence of rotavirus B in feces from diseased piglets while no other pathogens were identified. Clinical disease was reproduced in experimentally infected piglets, yielding the 11 RVB gene segments for strain Buryat15, with an RVB genotype constellation of G12-P[4]-I13-R4-C4-M4-A8-N10-T4-E4-H7. This genotype constellation has also been identified in the United States. While the Buryat15 VP7 protein lacked unique amino acid differences in the predicted neutralizing epitopes compared to the previously published swine RVB G12 strains, this report of RVB in Russian swine increases our epidemiological knowledge on the global prevalence and genetic diversity of RVB. View Full-Text   Flavivirus,ZIKV,Aedes aegypti,Aedes albopictus   Trypanosoma brucei,adenylate cyclase,cAMP signaling,innate immunity,inflammation,TNF-α   porcine group B rotavirus,RVB,gastrointestinal disease,porcine enteric disease,phylogenetic analysis ", Pathogens 
 The Role of Glycans in Bacterial Adhesion to Mucosal Surfaces: How Can Single-Molecule Techniques Advance Our Understanding?   Comparison of Yeasts as Hosts for Recombinant Protein Production   Recombinant Inga Laurina Trypsin Inhibitor (ILTI) Production in Komagataella Phaffii Confirms Its Potential Anti-Biofilm Effect and Reveals an Anti-Tumoral Activity ," Abstract
Bacterial adhesion is currently the subject of increased interest from the research community, leading to fast progress in our understanding of this complex phenomenon. Resent research within this field has documented the important roles played by glycans for bacterial surface adhesion, either through interaction with lectins or with other glycans. In parallel with this increased interest for and understanding of bacterial adhesion, there has been a growth in the sophistication and use of sensitive force probes for single-molecule and single cell studies. In this review, we highlight how the sensitive force probes atomic force microscopy (AFM) and optical tweezers (OT) have contributed to clarifying the mechanisms underlying bacterial adhesion to glycosylated surfaces in general and mucosal surfaces in particular. We also describe research areas where these techniques have not yet been applied, but where their capabilities appear appropriate to advance our understanding. View Full-Text   Abstract
Recombinant protein production emerged in the early 1980s with the development of genetic engineering tools, which represented a compelling alternative to protein extraction from natural sources. Over the years, a high level of heterologous protein was made possible in a variety of hosts ranging from the bacteria Escherichia coli to mammalian cells. Recombinant protein importance is represented by its market size, which reached $1654 million in 2016 and is expected to reach $2850.5 million by 2022. Among the available hosts, yeasts have been used for producing a great variety of proteins applied to chemicals, fuels, food, and pharmaceuticals, being one of the most used hosts for recombinant production nowadays. Historically, Saccharomyces cerevisiae was the dominant yeast host for heterologous protein production. Lately, other yeasts such as Komagataella sp., Kluyveromyces lactis, and Yarrowia lipolytica have emerged as advantageous hosts. In this review, a comparative analysis is done listing the advantages and disadvantages of using each host regarding the availability of genetic tools, strategies for cultivation in bioreactors, and the main techniques utilized for protein purification. Finally, examples of each host will be discussed regarding the total amount of protein recovered and its bioactivity due to correct folding and glycosylation patterns. View Full-Text   Abstract
Protease inhibitors have a broad biotechnological application ranging from medical drugs to anti-microbial agents. The Inga laurina trypsin inhibitor (ILTI) previously showed a great in vitro inhibitory effect under the adherence of Staphylococcus species, being a strong candidate for use as an anti-biofilm agent. Nevertheless, this is found in small quantities in its sources, which impairs its utilization at an industrial scale. Within this context, heterologous production using recombinant microorganisms is one of the best options to scale up the recombinant protein production. Thus, this work aimed at utilizing Komagataella phaffii to produce recombinant ILTI. For this, the vector pPIC9K+ILTI was constructed and inserted into the genome of the yeast K. phaffii, strain GS115. The protein expression was highest after 48 h using methanol 1%. A matrix-assisted laser desorption ionization–time-of-flight (MALDI–TOF) analysis was performed to confirm the production of the recombinant ILTI and its activity was investigated trough inhibitory assays using the synthetic substrate Nα-Benzoyl-D,L-arginine p-nitroanilide hydrochloride (BAPNA). Finally, recombinant ILTI (rILTI) was used in assays, showing that there was no significant difference between native and recombinant ILTI in its inhibitory activity in biofilm formation. Anti-tumor assay against Ehrlich ascites tumor (EAT) cells showed that rILTI has a potential anti-tumoral effect, showing the same effect as Melittin when incubated for 48 h in concentrations above 25 µg/mL. All together the results suggests broad applications for rILTI. View Full-Text "," carbohydrate recognition,mucus,adhesins,lectins,mucus adhesion,glycan interactions,AFM,optical tweezers   recombinant protein,yeast,Saccharomyces cerevisiae,Kluyveromyces lactis,Yarrowia lipolytica,Komagataella phaffii   Komagataella phaffii,heterologous expression,Inga laurina trypsin inhibitor (ILTI),biofilm assay,anti-tumor effect "," The Role of Glycans in Bacterial Adhesion to Mucosal Surfaces: How Can Single-Molecule Techniques Advance Our Understanding?   Comparison of Yeasts as Hosts for Recombinant Protein Production   Recombinant Inga Laurina Trypsin Inhibitor (ILTI) Production in Komagataella Phaffii Confirms Its Potential Anti-Biofilm Effect and Reveals an Anti-Tumoral Activity   Abstract
Bacterial adhesion is currently the subject of increased interest from the research community, leading to fast progress in our understanding of this complex phenomenon. Resent research within this field has documented the important roles played by glycans for bacterial surface adhesion, either through interaction with lectins or with other glycans. In parallel with this increased interest for and understanding of bacterial adhesion, there has been a growth in the sophistication and use of sensitive force probes for single-molecule and single cell studies. In this review, we highlight how the sensitive force probes atomic force microscopy (AFM) and optical tweezers (OT) have contributed to clarifying the mechanisms underlying bacterial adhesion to glycosylated surfaces in general and mucosal surfaces in particular. We also describe research areas where these techniques have not yet been applied, but where their capabilities appear appropriate to advance our understanding. View Full-Text   Abstract
Recombinant protein production emerged in the early 1980s with the development of genetic engineering tools, which represented a compelling alternative to protein extraction from natural sources. Over the years, a high level of heterologous protein was made possible in a variety of hosts ranging from the bacteria Escherichia coli to mammalian cells. Recombinant protein importance is represented by its market size, which reached $1654 million in 2016 and is expected to reach $2850.5 million by 2022. Among the available hosts, yeasts have been used for producing a great variety of proteins applied to chemicals, fuels, food, and pharmaceuticals, being one of the most used hosts for recombinant production nowadays. Historically, Saccharomyces cerevisiae was the dominant yeast host for heterologous protein production. Lately, other yeasts such as Komagataella sp., Kluyveromyces lactis, and Yarrowia lipolytica have emerged as advantageous hosts. In this review, a comparative analysis is done listing the advantages and disadvantages of using each host regarding the availability of genetic tools, strategies for cultivation in bioreactors, and the main techniques utilized for protein purification. Finally, examples of each host will be discussed regarding the total amount of protein recovered and its bioactivity due to correct folding and glycosylation patterns. View Full-Text   Abstract
Protease inhibitors have a broad biotechnological application ranging from medical drugs to anti-microbial agents. The Inga laurina trypsin inhibitor (ILTI) previously showed a great in vitro inhibitory effect under the adherence of Staphylococcus species, being a strong candidate for use as an anti-biofilm agent. Nevertheless, this is found in small quantities in its sources, which impairs its utilization at an industrial scale. Within this context, heterologous production using recombinant microorganisms is one of the best options to scale up the recombinant protein production. Thus, this work aimed at utilizing Komagataella phaffii to produce recombinant ILTI. For this, the vector pPIC9K+ILTI was constructed and inserted into the genome of the yeast K. phaffii, strain GS115. The protein expression was highest after 48 h using methanol 1%. A matrix-assisted laser desorption ionization–time-of-flight (MALDI–TOF) analysis was performed to confirm the production of the recombinant ILTI and its activity was investigated trough inhibitory assays using the synthetic substrate Nα-Benzoyl-D,L-arginine p-nitroanilide hydrochloride (BAPNA). Finally, recombinant ILTI (rILTI) was used in assays, showing that there was no significant difference between native and recombinant ILTI in its inhibitory activity in biofilm formation. Anti-tumor assay against Ehrlich ascites tumor (EAT) cells showed that rILTI has a potential anti-tumoral effect, showing the same effect as Melittin when incubated for 48 h in concentrations above 25 µg/mL. All together the results suggests broad applications for rILTI. View Full-Text   carbohydrate recognition,mucus,adhesins,lectins,mucus adhesion,glycan interactions,AFM,optical tweezers   recombinant protein,yeast,Saccharomyces cerevisiae,Kluyveromyces lactis,Yarrowia lipolytica,Komagataella phaffii   Komagataella phaffii,heterologous expression,Inga laurina trypsin inhibitor (ILTI),biofilm assay,anti-tumor effect ", Microorganisms 
" Effect of Different Flooring Designs on the Performance and Foot Pad Health in Broilers and Turkeys   Should the Endangered Status of the Giant Panda Really Be Reduced? The Case of Giant Panda Conservation in Sichuan, China   Dog Population & Dog Sheltering Trends in the United States of America "," Abstract
Litter quality has a significant influence on the performance and foot pad health in poultry. The objective of this study was to evaluate the effects of different types of flooring designs on the performance and foot pad health in fattening broilers and turkeys. Three trials were conducted for each species using a total of 720 Ross 308 broilers and 720 Big 6 turkeys. After day seven, animals were randomly assigned to four groups with three subgroups each: G1—floor pens with litter, G2—floor pens with litter and floor heating, G3—partially-slatted flooring, including a littered area, and G4—fully-slatted flooring with a sand bath (900 cm2). Animals of both species had a significantly higher final body weight at dissection (day 36) after being reared on fully-slatted floors compared to common littered floors. In turkeys, the feed conversion ratio was worse in G4 (1.53 ± 0.04) than in G1 (1.47 ± 0.02) and G2 (1.48 ± 0.03). Water to feed ratio was significantly higher in G2 than other groups. Turkeys’ foot pad health was significantly better in G4 than in other groups beginning at day 21. In turkeys, platforms with slatted floors that allow for temporary separation of the feet from the litter could lead to improvements in foot pad health which could better enable the realization of species-specific behaviours and activities in littered areas. View Full-Text   Abstract
The International Union for Conservation of Nature (IUCN) reduced the threat status of the giant panda from “endangered” to “vulnerable” in September 2016. In this study, we analyzed current practices for giant panda conservation at regional and local environmental scales, based on recent reports of giant panda protection efforts in Sichuan Province, China, combined with the survey results from 927 households within and adjacent to the giant panda reserves in this area. The results showed that household attitudes were very positive regarding giant panda protection efforts. Over the last 10 years, farmers’ dependence on the natural resources provided by giant panda reserves significantly decreased. However, socio-economic development increased resource consumption, and led to climate change, habitat fragmentation, environmental pollution, and other issues that placed increased pressure on giant panda populations. This difference between local and regional scales must be considered when evaluating the IUCN status of giant pandas. While the status of this species has improved in the short-term due to positive local attitudes, large-scale socio-economic development pressure could have long-term negative impacts. Consequently, the IUCN assessment leading to the classification of giant panda as “vulnerable” instead of “endangered”, should not affect its conservation intensity and effort, as such actions could negatively impact population recovery efforts, leading to the extinction of this charismatic species. View Full-Text   Simple Summary
The pet overpopulation problem in the United States has changed significantly since the 1970s. The purpose of this review is to document these changes and propose factors that have been and are currently driving the dog population dynamics in the US. In the 1960s, about one quarter of the dog population was still roaming the streets (whether owned or not) and 10 to 20-fold more dogs were euthanized in shelters compared to the present. We present data from across the United States which support the idea that, along with increased responsible pet ownership behaviors, sterilization efforts in shelters and private veterinary hospitals have played a role driving and sustaining the decline in unwanted animals entering shelters (and being euthanized). Additionally, data shows that adoption numbers are rising slowly across the US and have become an additional driver of declining euthanasia numbers in the last decade. We conclude that the cultural shift in how society and pet owners relate to dogs has produced positive shelter trends beyond the decline in intake. The increased level of control and care dog owners provide to their dogs, as well as the increasing perception of dogs as family members, are all indicators of the changing human-dog relationship in the US. "," broiler,turkey,flooring design,slatted flooring,floor heating,performance,foot pad dermatitis   giant panda,endangered status,community,economic development    "," Effect of Different Flooring Designs on the Performance and Foot Pad Health in Broilers and Turkeys   Should the Endangered Status of the Giant Panda Really Be Reduced? The Case of Giant Panda Conservation in Sichuan, China   Dog Population & Dog Sheltering Trends in the United States of America   Abstract
Litter quality has a significant influence on the performance and foot pad health in poultry. The objective of this study was to evaluate the effects of different types of flooring designs on the performance and foot pad health in fattening broilers and turkeys. Three trials were conducted for each species using a total of 720 Ross 308 broilers and 720 Big 6 turkeys. After day seven, animals were randomly assigned to four groups with three subgroups each: G1—floor pens with litter, G2—floor pens with litter and floor heating, G3—partially-slatted flooring, including a littered area, and G4—fully-slatted flooring with a sand bath (900 cm2). Animals of both species had a significantly higher final body weight at dissection (day 36) after being reared on fully-slatted floors compared to common littered floors. In turkeys, the feed conversion ratio was worse in G4 (1.53 ± 0.04) than in G1 (1.47 ± 0.02) and G2 (1.48 ± 0.03). Water to feed ratio was significantly higher in G2 than other groups. Turkeys’ foot pad health was significantly better in G4 than in other groups beginning at day 21. In turkeys, platforms with slatted floors that allow for temporary separation of the feet from the litter could lead to improvements in foot pad health which could better enable the realization of species-specific behaviours and activities in littered areas. View Full-Text   Abstract
The International Union for Conservation of Nature (IUCN) reduced the threat status of the giant panda from “endangered” to “vulnerable” in September 2016. In this study, we analyzed current practices for giant panda conservation at regional and local environmental scales, based on recent reports of giant panda protection efforts in Sichuan Province, China, combined with the survey results from 927 households within and adjacent to the giant panda reserves in this area. The results showed that household attitudes were very positive regarding giant panda protection efforts. Over the last 10 years, farmers’ dependence on the natural resources provided by giant panda reserves significantly decreased. However, socio-economic development increased resource consumption, and led to climate change, habitat fragmentation, environmental pollution, and other issues that placed increased pressure on giant panda populations. This difference between local and regional scales must be considered when evaluating the IUCN status of giant pandas. While the status of this species has improved in the short-term due to positive local attitudes, large-scale socio-economic development pressure could have long-term negative impacts. Consequently, the IUCN assessment leading to the classification of giant panda as “vulnerable” instead of “endangered”, should not affect its conservation intensity and effort, as such actions could negatively impact population recovery efforts, leading to the extinction of this charismatic species. View Full-Text   Simple Summary
The pet overpopulation problem in the United States has changed significantly since the 1970s. The purpose of this review is to document these changes and propose factors that have been and are currently driving the dog population dynamics in the US. In the 1960s, about one quarter of the dog population was still roaming the streets (whether owned or not) and 10 to 20-fold more dogs were euthanized in shelters compared to the present. We present data from across the United States which support the idea that, along with increased responsible pet ownership behaviors, sterilization efforts in shelters and private veterinary hospitals have played a role driving and sustaining the decline in unwanted animals entering shelters (and being euthanized). Additionally, data shows that adoption numbers are rising slowly across the US and have become an additional driver of declining euthanasia numbers in the last decade. We conclude that the cultural shift in how society and pet owners relate to dogs has produced positive shelter trends beyond the decline in intake. The increased level of control and care dog owners provide to their dogs, as well as the increasing perception of dogs as family members, are all indicators of the changing human-dog relationship in the US.   broiler,turkey,flooring design,slatted flooring,floor heating,performance,foot pad dermatitis   giant panda,endangered status,community,economic development    ", Animals 
" Mass Balance of Cenozoic Andes-Amazon Source to Sink System—Marañón Basin, Peru   Soil Erosion Induced by the Introduction of New Pasture Species in a Faxinal Farm of Southern Brazil "," Abstract
We investigate the mass balance of the Cenozoic Andes-Amazon source to sink system using rock uplift proxies and solid sedimentation of the Marañón Basin in Peru. The evolution of sedimentation rates is calibrated with regional structural restored cross-section. The quantification of eroded sediments from reliefs to sedimentary basin is achieved with ×10 Myr resolution and compared to present day proxies from the HYBAM (HYdrologie et Biogéochimie du Bassin Amazonien) Critical Zone Observatory. Erosion of the early Andean landforms started during the Upper Mesozoic period, but sediment rates significantly increase during the Neogene. This is in agreement with the calibrated increase of rock uplift in the Andean orogenic belt. View Full-Text   Abstract
The faxinal management system is an endangered agro-silvopastoral system which forms part of the local traditional management in the Paraná federal state (Brazil). Significant changes in land management since the 1970s caused farmers to look for alternatives to increase the productivity of their farms. The introduction of new pasture species is causing land degradation problems, of which soil erosion is the most important challenge. Therefore, in this study, we assessed the environmental consequences of introducing exotic pasture species, such as Brachiaria decumbens. To achieve this goal, ten erosion plots were installed with exotic and native pastures (Paspalum notatum Flüggé) to quantify soil and water losses in paired plots. Total rainfall per event, soil properties (soil cover, texture, organic matter, bulk density, porosity, and soil penetration resistance), and pasture production were also estimated. Our results showed a decrease in organic matter and porosity and an increase of the bulk density in the exotic pasture plots. Soil erosion monitoring showed higher soil losses for the exotic cultivated plots (359.8 g m−2 or 3.6 mg ha−1) than for the native plots (90.7 g m−2 or 0.91 mg ha−1). The highest percentage of bare soil surfaces and compaction coincided with the highest soil erosion rates measured in the exotic pastures. However, the mean fodder production in the exotic plots was almost five times higher (987 kg DM ha−1) than in the native ones (204 kg DM ha−1). These findings confirm that farmers have an internal conflict. They want to optimize the production of fodder, but this leads to high soil erosion rates and reduces soil fertility in the medium- and long-term. The traditional, less productive pastoral system is more sustainable from an environmental and cultural point of view. However, this system may not be sustainable from an economic point of view. View Full-Text "," source to sink,mass balance,erosion,sedimentation rate,Andes,Peru,Marañón Basin,Cenozoic   traditional farming,Brachiaria decumbens,land degradation,pasture production "," Mass Balance of Cenozoic Andes-Amazon Source to Sink System—Marañón Basin, Peru   Soil Erosion Induced by the Introduction of New Pasture Species in a Faxinal Farm of Southern Brazil   Abstract
We investigate the mass balance of the Cenozoic Andes-Amazon source to sink system using rock uplift proxies and solid sedimentation of the Marañón Basin in Peru. The evolution of sedimentation rates is calibrated with regional structural restored cross-section. The quantification of eroded sediments from reliefs to sedimentary basin is achieved with ×10 Myr resolution and compared to present day proxies from the HYBAM (HYdrologie et Biogéochimie du Bassin Amazonien) Critical Zone Observatory. Erosion of the early Andean landforms started during the Upper Mesozoic period, but sediment rates significantly increase during the Neogene. This is in agreement with the calibrated increase of rock uplift in the Andean orogenic belt. View Full-Text   Abstract
The faxinal management system is an endangered agro-silvopastoral system which forms part of the local traditional management in the Paraná federal state (Brazil). Significant changes in land management since the 1970s caused farmers to look for alternatives to increase the productivity of their farms. The introduction of new pasture species is causing land degradation problems, of which soil erosion is the most important challenge. Therefore, in this study, we assessed the environmental consequences of introducing exotic pasture species, such as Brachiaria decumbens. To achieve this goal, ten erosion plots were installed with exotic and native pastures (Paspalum notatum Flüggé) to quantify soil and water losses in paired plots. Total rainfall per event, soil properties (soil cover, texture, organic matter, bulk density, porosity, and soil penetration resistance), and pasture production were also estimated. Our results showed a decrease in organic matter and porosity and an increase of the bulk density in the exotic pasture plots. Soil erosion monitoring showed higher soil losses for the exotic cultivated plots (359.8 g m−2 or 3.6 mg ha−1) than for the native plots (90.7 g m−2 or 0.91 mg ha−1). The highest percentage of bare soil surfaces and compaction coincided with the highest soil erosion rates measured in the exotic pastures. However, the mean fodder production in the exotic plots was almost five times higher (987 kg DM ha−1) than in the native ones (204 kg DM ha−1). These findings confirm that farmers have an internal conflict. They want to optimize the production of fodder, but this leads to high soil erosion rates and reduces soil fertility in the medium- and long-term. The traditional, less productive pastoral system is more sustainable from an environmental and cultural point of view. However, this system may not be sustainable from an economic point of view. View Full-Text   source to sink,mass balance,erosion,sedimentation rate,Andes,Peru,Marañón Basin,Cenozoic   traditional farming,Brachiaria decumbens,land degradation,pasture production ", Geosciences 
" The Role of Adipokines in Intervertebral Disc Degeneration   Myeloperoxidase as an Active Disease Biomarker: Recent Biochemical and Pathological Perspectives   The Role of Gut Microbiota in Obesity and Type 2 and Type 1 Diabetes Mellitus: New Insights into “Old” Diseases   Colorectal Cancer: Genetic Abnormalities, Tumor Progression, Tumor Heterogeneity, Clonal Evolution and Tumor-Initiating Cells "," Abstract
Intervertebral disc degeneration (IDD) is an important cause of low back pain. Recent evidence suggests that in addition to abnormal and excessive mechanical loading, inflammation may be a key driver for both IDD and low back pain. Obesity, a known mechanical risk factor of IDD, is now increasingly being recognized as a systemic inflammatory state with adipokines being postulated as likely inflammatory mediators. The aim of this review was to summarize the current literature regarding the inflammatory role of adipokines in the pathophysiology of IDD. A systematic literature search was performed using the OVID Medline, EMBASE and PubMed databases to identify all studies assessing IDD and adipokines. Fifteen studies were included in the present review. Leptin was the most commonly assessed adipokine. Ten of 15 studies were conducted in humans; three in rats and two in both humans and rats. Studies focused on a variety of topics ranging from receptor identification, pathway analysis, genetic associations, and proteonomics. Currently, data from both human and animal experiments demonstrate significant effects of leptin and adiponectin on the internal milieu of intervertebral discs. However, future studies are needed to determine the molecular pathway relationships between adipokines in the pathophysiology of IDD as avenues for future therapeutic targets. View Full-Text   Abstract
Myeloperoxidase (MPO) belongs to the family of heme-containing peroxidases, produced mostly from polymorphonuclear neutrophils. The active enzyme (150 kDa) is the product of the MPO gene located on long arm of chromosome 17. The primary gene product undergoes several modifications, such as the removal of introns and signal peptides, and leads to the formation of enzymatically inactive glycosylated apoproMPO which complexes with chaperons, producing inactive proMPO by the insertion of a heme moiety. The active enzyme is a homodimer of heavy and light chain protomers. This enzyme is released into the extracellular fluid after oxidative stress and different inflammatory responses. Myeloperoxidase is the only type of peroxidase that uses H2O2 to oxidize several halides and pseudohalides to form different hypohalous acids. So, the antibacterial activities of MPO involve the production of reactive oxygen and reactive nitrogen species. Controlled MPO release at the site of infection is of prime importance for its efficient activities. Any uncontrolled degranulation exaggerates the inflammation and can also lead to tissue damage even in absence of inflammation. Several types of tissue injuries and the pathogenesis of several other major chronic diseases such as rheumatoid arthritis, cardiovascular diseases, liver diseases, diabetes, and cancer have been reported to be linked with MPO-derived oxidants. Thus, the enhanced level of MPO activity is one of the best diagnostic tools of inflammatory and oxidative stress biomarkers among these commonly-occurring diseases. View Full-Text   Abstract
The investigation of the human microbiome is the most rapidly expanding field in biomedicine. Early studies were undertaken to better understand the role of microbiota in carbohydrate digestion and utilization. These processes include polysaccharide degradation, glycan transport, glycolysis, and short-chain fatty acid production. Recent research has demonstrated that the intricate axis between gut microbiota and the host metabolism is much more complex. Gut microbiota—depending on their composition—have disease-promoting effects but can also possess protective properties. This review focuses on disorders of metabolic syndrome, with special regard to obesity as a prequel to type 2 diabetes, type 2 diabetes itself, and type 1 diabetes. In all these conditions, differences in the composition of the gut microbiota in comparison to healthy people have been reported. Mechanisms of the interaction between microbiota and host that have been characterized thus far include an increase in energy harvest, modulation of free fatty acids—especially butyrate—of bile acids, lipopolysaccharides, gamma-aminobutyric acid (GABA), an impact on toll-like receptors, the endocannabinoid system and “metabolic endotoxinemia” as well as “metabolic infection.” This review will also address the influence of already established therapies for metabolic syndrome and diabetes on the microbiota and the present state of attempts to alter the gut microbiota as a therapeutic strategy. View Full-Text   Abstract
Colon cancer is the third most common cancer worldwide. Most colorectal cancer occurrences are sporadic, not related to genetic predisposition or family history; however, 20–30% of patients with colorectal cancer have a family history of colorectal cancer and 5% of these tumors arise in the setting of a Mendelian inheritance syndrome. In many patients, the development of a colorectal cancer is preceded by a benign neoplastic lesion: either an adenomatous polyp or a serrated polyp. Studies carried out in the last years have characterized the main molecular alterations occurring in colorectal cancers, showing that the tumor of each patient displays from two to eight driver mutations. The ensemble of molecular studies, including gene expression studies, has led to two proposed classifications of colorectal cancers, with the identification of four/five non-overlapping groups. The homeostasis of the rapidly renewing intestinal epithelium is ensured by few stem cells present at the level of the base of intestinal crypts. Various experimental evidence suggests that colorectal cancers may derive from the malignant transformation of intestinal stem cells or of intestinal cells that acquire stem cell properties following malignant transformation. Colon cancer stem cells seem to be involved in tumor chemoresistance, radioresistance and relapse. View Full-Text "," disc degeneration,adipokines,leptin,adiponectin,resistin,spine,obesity   myeloperoxidase,leukocytes,inflammation,oxidative stress,chronic diseases,disease biomarker   gut microbiome,obesity,metabolic syndrome,type 2 diabetes mellitus,type 1 diabetes mellitus,butyrate,probiotics,lipopolysaccharides,faecal microbiota transfer,metformin   colorectal cancer,adenomatous polyp,serrated polyp,cancer stem cells,tumor xenotrasplantation assay,gene sequencing,gene expression profiling "," The Role of Adipokines in Intervertebral Disc Degeneration   Myeloperoxidase as an Active Disease Biomarker: Recent Biochemical and Pathological Perspectives   The Role of Gut Microbiota in Obesity and Type 2 and Type 1 Diabetes Mellitus: New Insights into “Old” Diseases   Colorectal Cancer: Genetic Abnormalities, Tumor Progression, Tumor Heterogeneity, Clonal Evolution and Tumor-Initiating Cells   Abstract
Intervertebral disc degeneration (IDD) is an important cause of low back pain. Recent evidence suggests that in addition to abnormal and excessive mechanical loading, inflammation may be a key driver for both IDD and low back pain. Obesity, a known mechanical risk factor of IDD, is now increasingly being recognized as a systemic inflammatory state with adipokines being postulated as likely inflammatory mediators. The aim of this review was to summarize the current literature regarding the inflammatory role of adipokines in the pathophysiology of IDD. A systematic literature search was performed using the OVID Medline, EMBASE and PubMed databases to identify all studies assessing IDD and adipokines. Fifteen studies were included in the present review. Leptin was the most commonly assessed adipokine. Ten of 15 studies were conducted in humans; three in rats and two in both humans and rats. Studies focused on a variety of topics ranging from receptor identification, pathway analysis, genetic associations, and proteonomics. Currently, data from both human and animal experiments demonstrate significant effects of leptin and adiponectin on the internal milieu of intervertebral discs. However, future studies are needed to determine the molecular pathway relationships between adipokines in the pathophysiology of IDD as avenues for future therapeutic targets. View Full-Text   Abstract
Myeloperoxidase (MPO) belongs to the family of heme-containing peroxidases, produced mostly from polymorphonuclear neutrophils. The active enzyme (150 kDa) is the product of the MPO gene located on long arm of chromosome 17. The primary gene product undergoes several modifications, such as the removal of introns and signal peptides, and leads to the formation of enzymatically inactive glycosylated apoproMPO which complexes with chaperons, producing inactive proMPO by the insertion of a heme moiety. The active enzyme is a homodimer of heavy and light chain protomers. This enzyme is released into the extracellular fluid after oxidative stress and different inflammatory responses. Myeloperoxidase is the only type of peroxidase that uses H2O2 to oxidize several halides and pseudohalides to form different hypohalous acids. So, the antibacterial activities of MPO involve the production of reactive oxygen and reactive nitrogen species. Controlled MPO release at the site of infection is of prime importance for its efficient activities. Any uncontrolled degranulation exaggerates the inflammation and can also lead to tissue damage even in absence of inflammation. Several types of tissue injuries and the pathogenesis of several other major chronic diseases such as rheumatoid arthritis, cardiovascular diseases, liver diseases, diabetes, and cancer have been reported to be linked with MPO-derived oxidants. Thus, the enhanced level of MPO activity is one of the best diagnostic tools of inflammatory and oxidative stress biomarkers among these commonly-occurring diseases. View Full-Text   Abstract
The investigation of the human microbiome is the most rapidly expanding field in biomedicine. Early studies were undertaken to better understand the role of microbiota in carbohydrate digestion and utilization. These processes include polysaccharide degradation, glycan transport, glycolysis, and short-chain fatty acid production. Recent research has demonstrated that the intricate axis between gut microbiota and the host metabolism is much more complex. Gut microbiota—depending on their composition—have disease-promoting effects but can also possess protective properties. This review focuses on disorders of metabolic syndrome, with special regard to obesity as a prequel to type 2 diabetes, type 2 diabetes itself, and type 1 diabetes. In all these conditions, differences in the composition of the gut microbiota in comparison to healthy people have been reported. Mechanisms of the interaction between microbiota and host that have been characterized thus far include an increase in energy harvest, modulation of free fatty acids—especially butyrate—of bile acids, lipopolysaccharides, gamma-aminobutyric acid (GABA), an impact on toll-like receptors, the endocannabinoid system and “metabolic endotoxinemia” as well as “metabolic infection.” This review will also address the influence of already established therapies for metabolic syndrome and diabetes on the microbiota and the present state of attempts to alter the gut microbiota as a therapeutic strategy. View Full-Text   Abstract
Colon cancer is the third most common cancer worldwide. Most colorectal cancer occurrences are sporadic, not related to genetic predisposition or family history; however, 20–30% of patients with colorectal cancer have a family history of colorectal cancer and 5% of these tumors arise in the setting of a Mendelian inheritance syndrome. In many patients, the development of a colorectal cancer is preceded by a benign neoplastic lesion: either an adenomatous polyp or a serrated polyp. Studies carried out in the last years have characterized the main molecular alterations occurring in colorectal cancers, showing that the tumor of each patient displays from two to eight driver mutations. The ensemble of molecular studies, including gene expression studies, has led to two proposed classifications of colorectal cancers, with the identification of four/five non-overlapping groups. The homeostasis of the rapidly renewing intestinal epithelium is ensured by few stem cells present at the level of the base of intestinal crypts. Various experimental evidence suggests that colorectal cancers may derive from the malignant transformation of intestinal stem cells or of intestinal cells that acquire stem cell properties following malignant transformation. Colon cancer stem cells seem to be involved in tumor chemoresistance, radioresistance and relapse. View Full-Text   disc degeneration,adipokines,leptin,adiponectin,resistin,spine,obesity   myeloperoxidase,leukocytes,inflammation,oxidative stress,chronic diseases,disease biomarker   gut microbiome,obesity,metabolic syndrome,type 2 diabetes mellitus,type 1 diabetes mellitus,butyrate,probiotics,lipopolysaccharides,faecal microbiota transfer,metformin   colorectal cancer,adenomatous polyp,serrated polyp,cancer stem cells,tumor xenotrasplantation assay,gene sequencing,gene expression profiling ", Medical Sciences 
 Secular and Religious Social Support Better Protect Blacks than Whites against Depressive Symptoms   Perceived Discrimination among Black Youth: An 18-Year Longitudinal Study   The Effect of Pet Therapy and Artist Interactions on Quality of Life in Brain Tumor Patients: A Cross-Section of Art and Medicine in Dialog ," Abstract
Purpose: Although the protective effect of social support against depression is well known, limited information exists on racial differences in this association. The current study examined Black-White differences in the effects of religious and secular emotional social support on depressive symptoms in a national sample of older adults in the United States. Methods: With a longitudinal prospective design, the Religion, Aging and Health Survey, 2001–2004, followed 1493 Black (n = 734) and White (n = 759) elderly individuals (age 66 and older) for three years. Race, demographics (age and gender), socio-economics (education and marital status) and frequency of church attendance were measured at baseline in 2001. Secular social support, religious social support, chronic medical conditions and depressive symptoms [8- item Center for Epidemiological Studies-Depression scale (CES-D)] were measured in 2004. Multiple linear regression models were used for data analysis. Results: In the pooled sample, secular and religious social support were both protective against depressive symptoms, net of all covariates. Race interacted with secular (β = −0.62 for interaction) and religious (β = −0.21 for interaction) social support on baseline depressive symptoms (p < 0.05 for both interactions), suggesting larger protections for Blacks compared to Whites. In race-specific models, the regression weight for the effect of secular social support on depressive symptoms was larger for Blacks (β = −0.64) than Whites (β = −0.16). Conclusion: We found Black—White differences in the protective effects of secular and religious social support against depressive symptoms. Blacks seem to benefit more from the same level of emotional social support, regardless of its source, compared to Whites. View Full-Text   Abstract
Background: Recent research has suggested vulnerability to perceived racial discrimination (PRD) as a mechanism behind high levels of depression seen in high socioeconomic status (SES) Black males. To better understand the effects of gender and SES on shaping experiences of PRD among Black youth in the United States, we used data from the Family and Community Health Study (FACHS) to explore the trajectory of PRD in Black youth by gender, SES, and place. Methods: Data came from FACHS, 1997–2017, which followed 889 children aged 10–12 years old at Wave 1 (n = 478; 53.8% females and n = 411; 46.2% males) for up to 18 years. Data were collected in seven waves. The main predictors of interest were gender, SES (parent education and annual family income), age, and place of residence. Main outcomes of interest were baseline and slope of PRD. Latent growth curve modeling (LGCM) was used for data analysis. Results: Gender, SES, place, and age were correlated with baseline and change in PRD over time. Male, high family income, and younger Black youth reported lower PRD at baseline but a larger increase in PRD over time. Youth who lived in Iowa (in a predominantly White area) reported higher PRD at baseline and also an increase in PRD over time. High parental education was not associated with baseline or change in PRD. Conclusion: In the United States, Black youth who are male, high income, and live in predominantly White areas experience an increase in PRD over time. Future research is needed on the interactions between gender, SES, and place on exposure and vulnerability of Black youth to PRD. Such research may explain the increased risk of depression in high SES Black males. View Full-Text   Abstract
With the evolution of modern medical treatment strategies, there also comes the realization that many times we reach a point where traditional goals of medical care, such as overall survival or disease-free survival, are not realistic goals for many patients facing devastating illnesses. One such disease is malignant primary brain tumors, known as malignant glioma (MG). With median survival of only 20.9 months following best available standard of care treatment strategies, including surgery, chemotherapy, radiation, and tumor treating fields, MG is one of the deadliest malignancies of the modern era. Along the course of treating patients with MG, clinicians often realize that traditional treatment therapies can at best provide incremental benefit of symptom management without any survival benefit. However, even in these difficult situations, it is possible to make significant positive changes in patients’ health-related quality of life (HRQoL) using creative, non-traditional interventions. In this paper, we describe the initial findings from our project that takes a unique approach to studying the intersections of clinical care and art by using pet therapy and art-making as interventions for patients diagnosed with brain tumors. Our preliminary findings suggest that pet therapy and the ability to reflect as well as speak about their journey through a life-altering disease significantly increases patients’ overall feeling of wellbeing and reduces anxiety about future uncertainty. View Full-Text "," population groups,ethnic groups,African Americans,social support,religion,depressive symptoms,depression   Blacks,African Americans,socioeconomic status (SES), education,discrimination,racism,place   brain tumor,malignant glioma,pet therapy,video art,photography,quality of life,cancer,artist,artistic engagement,art "," Secular and Religious Social Support Better Protect Blacks than Whites against Depressive Symptoms   Perceived Discrimination among Black Youth: An 18-Year Longitudinal Study   The Effect of Pet Therapy and Artist Interactions on Quality of Life in Brain Tumor Patients: A Cross-Section of Art and Medicine in Dialog   Abstract
Purpose: Although the protective effect of social support against depression is well known, limited information exists on racial differences in this association. The current study examined Black-White differences in the effects of religious and secular emotional social support on depressive symptoms in a national sample of older adults in the United States. Methods: With a longitudinal prospective design, the Religion, Aging and Health Survey, 2001–2004, followed 1493 Black (n = 734) and White (n = 759) elderly individuals (age 66 and older) for three years. Race, demographics (age and gender), socio-economics (education and marital status) and frequency of church attendance were measured at baseline in 2001. Secular social support, religious social support, chronic medical conditions and depressive symptoms [8- item Center for Epidemiological Studies-Depression scale (CES-D)] were measured in 2004. Multiple linear regression models were used for data analysis. Results: In the pooled sample, secular and religious social support were both protective against depressive symptoms, net of all covariates. Race interacted with secular (β = −0.62 for interaction) and religious (β = −0.21 for interaction) social support on baseline depressive symptoms (p < 0.05 for both interactions), suggesting larger protections for Blacks compared to Whites. In race-specific models, the regression weight for the effect of secular social support on depressive symptoms was larger for Blacks (β = −0.64) than Whites (β = −0.16). Conclusion: We found Black—White differences in the protective effects of secular and religious social support against depressive symptoms. Blacks seem to benefit more from the same level of emotional social support, regardless of its source, compared to Whites. View Full-Text   Abstract
Background: Recent research has suggested vulnerability to perceived racial discrimination (PRD) as a mechanism behind high levels of depression seen in high socioeconomic status (SES) Black males. To better understand the effects of gender and SES on shaping experiences of PRD among Black youth in the United States, we used data from the Family and Community Health Study (FACHS) to explore the trajectory of PRD in Black youth by gender, SES, and place. Methods: Data came from FACHS, 1997–2017, which followed 889 children aged 10–12 years old at Wave 1 (n = 478; 53.8% females and n = 411; 46.2% males) for up to 18 years. Data were collected in seven waves. The main predictors of interest were gender, SES (parent education and annual family income), age, and place of residence. Main outcomes of interest were baseline and slope of PRD. Latent growth curve modeling (LGCM) was used for data analysis. Results: Gender, SES, place, and age were correlated with baseline and change in PRD over time. Male, high family income, and younger Black youth reported lower PRD at baseline but a larger increase in PRD over time. Youth who lived in Iowa (in a predominantly White area) reported higher PRD at baseline and also an increase in PRD over time. High parental education was not associated with baseline or change in PRD. Conclusion: In the United States, Black youth who are male, high income, and live in predominantly White areas experience an increase in PRD over time. Future research is needed on the interactions between gender, SES, and place on exposure and vulnerability of Black youth to PRD. Such research may explain the increased risk of depression in high SES Black males. View Full-Text   Abstract
With the evolution of modern medical treatment strategies, there also comes the realization that many times we reach a point where traditional goals of medical care, such as overall survival or disease-free survival, are not realistic goals for many patients facing devastating illnesses. One such disease is malignant primary brain tumors, known as malignant glioma (MG). With median survival of only 20.9 months following best available standard of care treatment strategies, including surgery, chemotherapy, radiation, and tumor treating fields, MG is one of the deadliest malignancies of the modern era. Along the course of treating patients with MG, clinicians often realize that traditional treatment therapies can at best provide incremental benefit of symptom management without any survival benefit. However, even in these difficult situations, it is possible to make significant positive changes in patients’ health-related quality of life (HRQoL) using creative, non-traditional interventions. In this paper, we describe the initial findings from our project that takes a unique approach to studying the intersections of clinical care and art by using pet therapy and art-making as interventions for patients diagnosed with brain tumors. Our preliminary findings suggest that pet therapy and the ability to reflect as well as speak about their journey through a life-altering disease significantly increases patients’ overall feeling of wellbeing and reduces anxiety about future uncertainty. View Full-Text   population groups,ethnic groups,African Americans,social support,religion,depressive symptoms,depression   Blacks,African Americans,socioeconomic status (SES), education,discrimination,racism,place   brain tumor,malignant glioma,pet therapy,video art,photography,quality of life,cancer,artist,artistic engagement,art ", Behavioral Sciences 
 Speech Identification and Comprehension in the Urban Soundscape   Use of Water Balance and Tracer-Based Approaches to Monitor Groundwater Recharge in the Hyper-Arid Gobi Desert of Northwestern China   Governing Forest Ecosystem Services for Sustainable Environmental Governance: A Review ," Abstract
Urban environments are characterised by the presence of copious and unstructured noise. This noise continuously challenges speech intelligibility both in normal-hearing and hearing-impaired individuals. In this paper, we investigate the impact of urban noise, such as traffic, on speech identification and, more generally, speech understanding. With this purpose, we perform listening experiments to evaluate the ability of individuals with normal hearing to detect words and interpret conversational speech in the presence of urban noise (e.g., street drilling, traffic jams). Our experiments confirm previous findings in different acoustic environments and demonstrate that speech identification is influenced by the similarity between the target speech and the masking noise also in urban scenarios. More specifically, we propose the use of the structural similarity index to quantify this similarity. Our analysis confirms that speech identification is more successful in presence of noise with tempo-spectral characteristics different from speech. Moreover, our results show that speech comprehension is not as challenging as word identification in urban sound environments that are characterised by the presence of severe noise. Indeed, our experiments demonstrate that speech comprehension can be fairly successful even in acoustic scenes where the ability to identify speech is highly reduced. View Full-Text   Abstract
The groundwater recharge mechanism in the hyper-arid Gobi Desert of Northwestern China was analyzed using water balance and tracer-based approaches. Investigations of evaporation, soil water content, and their relationships with individual rainfall events were conducted from April to August of 2004. Water sampling of rainwater, groundwater, and surface water was also conducted. During this period, 10 precipitation events with a total amount of 41.5 mm, including a maximum of 28.9 mm, were observed. Evaporation during the period was estimated to be 33.1 mm. Only the soil water, which was derived from the heaviest precipitation, remained in the vadose zone. This is because a dry surface layer, which was formed several days after the heaviest precipitation event, prevented evaporation. Prior to that, the heaviest precipitation rapidly infiltrated without being affected by evaporation. This is corroborated by the isotopic evidence that both the heaviest precipitation and the groundwater retained no trace of significant kinetic evaporation. Estimated δ-values of the remaining soil water based on isotopic fractionation and its mass balance theories also demonstrated no trace of kinetic fractionation in the infiltration process. Moreover, stable isotopic compositions of the heaviest precipitation and the groundwater were very similar. Therefore, we concluded that the high-intensity precipitation, which rapidly infiltrated without any trace of evaporation, was the main source of the groundwater. View Full-Text   Abstract
Governing forest ecosystem services as a forest socio-ecological system is an evolving concept in the face of different environmental and social challenges. Therefore, different modes of ecosystem governance such as hierarchical, scientific–technical, and adaptive–collaborative governance have been developed. Although each form of governance offers important features, no one form on its own is sufficient to attain sustainable environmental governance (SEG). Thus, the blending of important features of each mode of governance could contribute to SEG, through a combination of both hierarchical and collaborative governance systems supported by scientifically and technically aided knowledge. This should be further reinforced by the broad engagement of stakeholders to ensure the improved well-being of both ecosystems and humans. Some form of governance and forest management measures, including sustainable forest management, forest certification, and payment for ecosystem services mechanisms, are also contributing to that end. While issues around commodification and putting a price on nature are still contested due to the complex relationship between different services, if these limitations are taken into account, the governance of forest ecosystem services will serve as a means of effective environmental governance and the sustainable management of forest resources. Therefore, forest ecosystem services governance has a promising future for SEG, provided limitations are tackled with due care in future governance endeavors. View Full-Text "," speech identification,speech comprehension,speech intelligibility,urban soundscape,urban environments,masking,auditory perception   groundwater recharge,evaporation,water balance,stable isotopes,hyper-arid environment,Gobi Desert,Northwestern China   forest,ecosystem services,governance,management "," Speech Identification and Comprehension in the Urban Soundscape   Use of Water Balance and Tracer-Based Approaches to Monitor Groundwater Recharge in the Hyper-Arid Gobi Desert of Northwestern China   Governing Forest Ecosystem Services for Sustainable Environmental Governance: A Review   Abstract
Urban environments are characterised by the presence of copious and unstructured noise. This noise continuously challenges speech intelligibility both in normal-hearing and hearing-impaired individuals. In this paper, we investigate the impact of urban noise, such as traffic, on speech identification and, more generally, speech understanding. With this purpose, we perform listening experiments to evaluate the ability of individuals with normal hearing to detect words and interpret conversational speech in the presence of urban noise (e.g., street drilling, traffic jams). Our experiments confirm previous findings in different acoustic environments and demonstrate that speech identification is influenced by the similarity between the target speech and the masking noise also in urban scenarios. More specifically, we propose the use of the structural similarity index to quantify this similarity. Our analysis confirms that speech identification is more successful in presence of noise with tempo-spectral characteristics different from speech. Moreover, our results show that speech comprehension is not as challenging as word identification in urban sound environments that are characterised by the presence of severe noise. Indeed, our experiments demonstrate that speech comprehension can be fairly successful even in acoustic scenes where the ability to identify speech is highly reduced. View Full-Text   Abstract
The groundwater recharge mechanism in the hyper-arid Gobi Desert of Northwestern China was analyzed using water balance and tracer-based approaches. Investigations of evaporation, soil water content, and their relationships with individual rainfall events were conducted from April to August of 2004. Water sampling of rainwater, groundwater, and surface water was also conducted. During this period, 10 precipitation events with a total amount of 41.5 mm, including a maximum of 28.9 mm, were observed. Evaporation during the period was estimated to be 33.1 mm. Only the soil water, which was derived from the heaviest precipitation, remained in the vadose zone. This is because a dry surface layer, which was formed several days after the heaviest precipitation event, prevented evaporation. Prior to that, the heaviest precipitation rapidly infiltrated without being affected by evaporation. This is corroborated by the isotopic evidence that both the heaviest precipitation and the groundwater retained no trace of significant kinetic evaporation. Estimated δ-values of the remaining soil water based on isotopic fractionation and its mass balance theories also demonstrated no trace of kinetic fractionation in the infiltration process. Moreover, stable isotopic compositions of the heaviest precipitation and the groundwater were very similar. Therefore, we concluded that the high-intensity precipitation, which rapidly infiltrated without any trace of evaporation, was the main source of the groundwater. View Full-Text   Abstract
Governing forest ecosystem services as a forest socio-ecological system is an evolving concept in the face of different environmental and social challenges. Therefore, different modes of ecosystem governance such as hierarchical, scientific–technical, and adaptive–collaborative governance have been developed. Although each form of governance offers important features, no one form on its own is sufficient to attain sustainable environmental governance (SEG). Thus, the blending of important features of each mode of governance could contribute to SEG, through a combination of both hierarchical and collaborative governance systems supported by scientifically and technically aided knowledge. This should be further reinforced by the broad engagement of stakeholders to ensure the improved well-being of both ecosystems and humans. Some form of governance and forest management measures, including sustainable forest management, forest certification, and payment for ecosystem services mechanisms, are also contributing to that end. While issues around commodification and putting a price on nature are still contested due to the complex relationship between different services, if these limitations are taken into account, the governance of forest ecosystem services will serve as a means of effective environmental governance and the sustainable management of forest resources. Therefore, forest ecosystem services governance has a promising future for SEG, provided limitations are tackled with due care in future governance endeavors. View Full-Text   speech identification,speech comprehension,speech intelligibility,urban soundscape,urban environments,masking,auditory perception   groundwater recharge,evaporation,water balance,stable isotopes,hyper-arid environment,Gobi Desert,Northwestern China   forest,ecosystem services,governance,management ", Environments 
" Prevalence of Developmental Dyslexia in Spanish University Students   Transcranial Direct Current Stimulation (tDCS): A Promising Treatment for Major Depressive Disorder?   Depression, Olfaction, and Quality of Life: A Mutual Relationship "," Abstract
A recent concern in the field of dyslexia studies is the lack of awareness and attention to university students suffering from this condition. If this problem is serious in countries where the relative opacity of the writing system allows for an early detection and, therefore, effective interventions, it is most critical in countries where transparent spelling makes such detection difficult, except in the most severe cases. In Spain, the diagnosis of dyslexia is rare among university-level adults. The present study pursues three aims: (a) to put forward a screening instrument for the detection of university students at risk of dyslexia, (b) to determine the ratio of university students that could be at risk of dyslexia by means of two different procedures, and (c) to create awareness for a disorder that causes hitherto unrecognized difficulties for an important subgroup of the college population. Six hundred and eighty-six university students in four different fields of study within the general area of Social Sciences from a public University in Madrid completed a Spanish-adapted version of a protocol including stress assignment, spelling words and nonwords, and timed phonological working memory of reading and writing task. Results showed that between 1.6% and 6.4% of this population could be at risk of suffering dyslexia. Such risk is not evenly distributed across the four fields of study. As for gender, the first criterion used yields 1.8 males at risk for every female, but the second criterion has as many males as females at risk. Women were significantly better than men in word spelling. Spelling was best predicted by the timed phonological working memory task of reading and writing. View Full-Text   Abstract
Background: Transcranial direct current stimulation (tDCS) opens new perspectives in the treatment of major depressive disorder (MDD), because of its ability to modulate cortical excitability and induce long-lasting effects. The aim of this review is to summarize the current status of knowledge regarding tDCS application in MDD. Methods: In this review, we searched for articles published in PubMed/MEDLINE from the earliest available date to February 2018 that explored clinical and cognitive effects of tDCS in MDD. Results: Despite differences in design and stimulation parameters, the examined studies indicated beneficial effects of tDCS for MDD. These preliminary results, the non-invasiveness of tDCS, and its good tolerability support the need for further research on this technique. Conclusions: tDCS constitutes a promising therapeutic alternative for patients with MDD, but its place in the therapeutic armamentarium remains to be determined. View Full-Text   Abstract
Olfactory dysfunction has been well studied in depression. Common brain areas are involved in depression and in the olfactory process, suggesting that olfactory impairments may constitute potential markers of this disorder. Olfactory markers of depression can be either state (present only in symptomatic phases) or trait (persistent after symptomatic remission) markers. This study presents the etiology of depression, the anatomical links between olfaction and depression, and a literature review of different olfactory markers of depression. Several studies have also shown that olfactory impairment affects the quality of life and that olfactory disorders can affect daily life and may be lead to depression. Thus, this study discusses the links between olfactory processing, depression, and quality of life. Finally, olfaction is an innovative research field that may constitute a new therapeutic tool for the treatment of depression. View Full-Text "," dyslexia,reading,spelling,working memory,stress assignment,Spanish,university students   transcranial direct current stimulation,depression,cognition   depression,olfaction,markers,quality of life,therapeutic tool "," Prevalence of Developmental Dyslexia in Spanish University Students   Transcranial Direct Current Stimulation (tDCS): A Promising Treatment for Major Depressive Disorder?   Depression, Olfaction, and Quality of Life: A Mutual Relationship   Abstract
A recent concern in the field of dyslexia studies is the lack of awareness and attention to university students suffering from this condition. If this problem is serious in countries where the relative opacity of the writing system allows for an early detection and, therefore, effective interventions, it is most critical in countries where transparent spelling makes such detection difficult, except in the most severe cases. In Spain, the diagnosis of dyslexia is rare among university-level adults. The present study pursues three aims: (a) to put forward a screening instrument for the detection of university students at risk of dyslexia, (b) to determine the ratio of university students that could be at risk of dyslexia by means of two different procedures, and (c) to create awareness for a disorder that causes hitherto unrecognized difficulties for an important subgroup of the college population. Six hundred and eighty-six university students in four different fields of study within the general area of Social Sciences from a public University in Madrid completed a Spanish-adapted version of a protocol including stress assignment, spelling words and nonwords, and timed phonological working memory of reading and writing task. Results showed that between 1.6% and 6.4% of this population could be at risk of suffering dyslexia. Such risk is not evenly distributed across the four fields of study. As for gender, the first criterion used yields 1.8 males at risk for every female, but the second criterion has as many males as females at risk. Women were significantly better than men in word spelling. Spelling was best predicted by the timed phonological working memory task of reading and writing. View Full-Text   Abstract
Background: Transcranial direct current stimulation (tDCS) opens new perspectives in the treatment of major depressive disorder (MDD), because of its ability to modulate cortical excitability and induce long-lasting effects. The aim of this review is to summarize the current status of knowledge regarding tDCS application in MDD. Methods: In this review, we searched for articles published in PubMed/MEDLINE from the earliest available date to February 2018 that explored clinical and cognitive effects of tDCS in MDD. Results: Despite differences in design and stimulation parameters, the examined studies indicated beneficial effects of tDCS for MDD. These preliminary results, the non-invasiveness of tDCS, and its good tolerability support the need for further research on this technique. Conclusions: tDCS constitutes a promising therapeutic alternative for patients with MDD, but its place in the therapeutic armamentarium remains to be determined. View Full-Text   Abstract
Olfactory dysfunction has been well studied in depression. Common brain areas are involved in depression and in the olfactory process, suggesting that olfactory impairments may constitute potential markers of this disorder. Olfactory markers of depression can be either state (present only in symptomatic phases) or trait (persistent after symptomatic remission) markers. This study presents the etiology of depression, the anatomical links between olfaction and depression, and a literature review of different olfactory markers of depression. Several studies have also shown that olfactory impairment affects the quality of life and that olfactory disorders can affect daily life and may be lead to depression. Thus, this study discusses the links between olfactory processing, depression, and quality of life. Finally, olfaction is an innovative research field that may constitute a new therapeutic tool for the treatment of depression. View Full-Text   dyslexia,reading,spelling,working memory,stress assignment,Spanish,university students   transcranial direct current stimulation,depression,cognition   depression,olfaction,markers,quality of life,therapeutic tool ", Brain Sciences 
 Glutathione: Antioxidant Properties Dedicated to Nanotechnologies   Fruit and Vegetable By-Products to Fortify Spreadable Cheese   Milling the Mistletoe: Nanotechnological Conversion of African Mistletoe (Loranthus micranthus) Intoantimicrobial Materials ," Abstract
Which scientist has never heard of glutathione (GSH)? This well-known low-molecular-weight tripeptide is perhaps the most famous natural antioxidant. However, the interest in GSH should not be restricted to its redox properties. This multidisciplinary review aims to bring out some lesser-known aspects of GSH, for example, as an emerging tool in nanotechnologies to achieve targeted drug delivery. After recalling the biochemistry of GSH, including its metabolism pathways and redox properties, its involvement in cellular redox homeostasis and signaling is described. Analytical methods for the dosage and localization of GSH or glutathiolated proteins are also covered. Finally, the various therapeutic strategies to replenish GSH stocks are discussed, in parallel with its use as an addressing molecule in drug delivery. View Full-Text   Abstract
In this work, spreadable cheese was enriched with flours from by-products (red and white grape pomace, tomato peel, broccoli, corn bran, and artichokes) as sources of fibres and antioxidant compounds. The physicochemical and the sensory properties of all the cheese samples were analysed. Results revealed that total phenolic content, flavonoids, and antioxidant activity of samples containing grape pomace significantly increased, followed by broccoli, artichoke, corn bran, and tomato peel by-products, compared to the control cheese. Specifically, cheeses containing white and red grape pomace recorded high phenolic content (2.74 ± 0.04 and 2.34 ± 0.15 mg GAEs/g dw, respectively) compared to the control (0.66 mg GAEs/g dw). View Full-Text   Abstract
Nanosizing represents a straight forward technique to unlock the biological activity of complex plant materials. The aim of this study was to develop herbal nanoparticles with medicinal value from dried leaves and stems of Loranthus micranthus with the aid of ball-milling, high speed stirring, and high-pressure homogenization techniques. The milled nanoparticles were characterized using laser diffraction analysis, photon correlation spectroscopy analysis, and light microscopy. The average size of leaf nanoparticles was around 245 nm and that of stem nanoparticles was around 180 nm. The nanoparticles were tested for their antimicrobial and nematicidal properties against a Gram-negative bacterium Escherichia coli, a Gram-positive bacterium Staphylococcus carnosus, fungi Candida albicans and Saccharomyces cerevisiae, and a nematode Steinernemafeltiae. The results show significant activities for both leaf and (particularly) stem nanoparticles of Loranthus micranthus on all organisms tested, even at a particle concentration as low as 0.01% (w/w). The results observed indicate that nanoparticles (especially of the stem) of Loranthus micranthus could serve as novel antimicrobial agents with wide-ranging biomedical applications. View Full-Text "," glutathione,antioxidant,redox signaling,nanotechnologies,repletion,targeted drug delivery   by-products,bioactive compounds,spreadable cheese,functional food,waste reduction   antimicrobial activity,mistletoe nanoparticle,Loranthus micranthus,nanosizing,nematicidal activity "," Glutathione: Antioxidant Properties Dedicated to Nanotechnologies   Fruit and Vegetable By-Products to Fortify Spreadable Cheese   Milling the Mistletoe: Nanotechnological Conversion of African Mistletoe (Loranthus micranthus) Intoantimicrobial Materials   Abstract
Which scientist has never heard of glutathione (GSH)? This well-known low-molecular-weight tripeptide is perhaps the most famous natural antioxidant. However, the interest in GSH should not be restricted to its redox properties. This multidisciplinary review aims to bring out some lesser-known aspects of GSH, for example, as an emerging tool in nanotechnologies to achieve targeted drug delivery. After recalling the biochemistry of GSH, including its metabolism pathways and redox properties, its involvement in cellular redox homeostasis and signaling is described. Analytical methods for the dosage and localization of GSH or glutathiolated proteins are also covered. Finally, the various therapeutic strategies to replenish GSH stocks are discussed, in parallel with its use as an addressing molecule in drug delivery. View Full-Text   Abstract
In this work, spreadable cheese was enriched with flours from by-products (red and white grape pomace, tomato peel, broccoli, corn bran, and artichokes) as sources of fibres and antioxidant compounds. The physicochemical and the sensory properties of all the cheese samples were analysed. Results revealed that total phenolic content, flavonoids, and antioxidant activity of samples containing grape pomace significantly increased, followed by broccoli, artichoke, corn bran, and tomato peel by-products, compared to the control cheese. Specifically, cheeses containing white and red grape pomace recorded high phenolic content (2.74 ± 0.04 and 2.34 ± 0.15 mg GAEs/g dw, respectively) compared to the control (0.66 mg GAEs/g dw). View Full-Text   Abstract
Nanosizing represents a straight forward technique to unlock the biological activity of complex plant materials. The aim of this study was to develop herbal nanoparticles with medicinal value from dried leaves and stems of Loranthus micranthus with the aid of ball-milling, high speed stirring, and high-pressure homogenization techniques. The milled nanoparticles were characterized using laser diffraction analysis, photon correlation spectroscopy analysis, and light microscopy. The average size of leaf nanoparticles was around 245 nm and that of stem nanoparticles was around 180 nm. The nanoparticles were tested for their antimicrobial and nematicidal properties against a Gram-negative bacterium Escherichia coli, a Gram-positive bacterium Staphylococcus carnosus, fungi Candida albicans and Saccharomyces cerevisiae, and a nematode Steinernemafeltiae. The results show significant activities for both leaf and (particularly) stem nanoparticles of Loranthus micranthus on all organisms tested, even at a particle concentration as low as 0.01% (w/w). The results observed indicate that nanoparticles (especially of the stem) of Loranthus micranthus could serve as novel antimicrobial agents with wide-ranging biomedical applications. View Full-Text   glutathione,antioxidant,redox signaling,nanotechnologies,repletion,targeted drug delivery   by-products,bioactive compounds,spreadable cheese,functional food,waste reduction   antimicrobial activity,mistletoe nanoparticle,Loranthus micranthus,nanosizing,nematicidal activity ", Antioxidants 
" Development and Regulation of Novel Influenza Virus Vaccines: A United States Young Scientist Perspective   “Gnothi Seauton”: Leveraging the Host Response to Improve Influenza Virus Vaccine Efficacy   Predictors and Barriers to Full Vaccination among Children in Ethiopia   Linkage of Infection to Adverse Systemic Complications: Periodontal Disease, Toll-Like Receptors, and Other Pattern Recognition Systems "," Abstract
Vaccination against influenza is the most effective approach for reducing influenza morbidity and mortality. However, influenza vaccines are unique among all licensed vaccines as they are updated and administered annually to antigenically match the vaccine strains and currently circulating influenza strains. Vaccine efficacy of each selected influenza virus vaccine varies depending on the antigenic match between circulating strains and vaccine strains, as well as the age and health status of the vaccine recipient. Low vaccine effectiveness of seasonal influenza vaccines in recent years provides an impetus to improve current seasonal influenza vaccines, and for development of next-generation influenza vaccines that can provide broader, long-lasting protection against both matching and antigenically diverse influenza strains. This review discusses a perspective on some of the issues and formidable challenges facing the development and regulation of the next-generation influenza vaccines. View Full-Text   Abstract
Vaccination against the seasonal influenza virus is the best way to prevent infection. Nevertheless, vaccine efficacy remains far from optimal especially in high-risk populations such as the elderly. Recent technological advancements have facilitated rapid and precise identification of the B and T cell epitopes that are targets for protective responses. While these discoveries have undoubtedly brought the field closer to “universal” influenza virus vaccines, choosing the correct antigen is only one piece of the equation. Achieving efficacy and durability requires a detailed understanding of the diverse host factors and pathways that are required for attaining optimal responses. Sequencing technologies, systems biology, and immunological studies have recently advanced our understanding of the diverse aspects of the host response required for vaccine efficacy. In this paper, we review the critical role of the host response in determining efficacious responses and discuss the gaps in knowledge that will need to be addressed if the field is to be successful in developing new and more effective influenza virus vaccines. View Full-Text   Abstract
Predictors of immunization status outside of large cities in Ethiopia are not well known, and Muslims have lower vaccination coverage. The aim of this study is to assess factors associated with full immunization among children 12–23 months in Worabe, Ethiopia, a Muslim-majority community. A cross-sectional study is conducted in summer 2016. Multivariable logistic regression was used to assess the significance of predictors of full immunization. Among 484 children, 61% are fully vaccinated. Children whose mothers had fewer antenatal care (ANC) visits have decreased odds of full vaccination (zero visits: odds ratio (OR) = 0.09; one visit: OR = 0.15; two visits: OR = 0.46; three visits: OR = 0.89). The most common reasons that the mother gave for not vaccinating the child are fear of side reactions (36%), being too busy (31%), or hearing rumors about vaccines (28%). Local interventions incorporating interventions with religious authorities could raise awareness in the community of the importance of childhood immunizations and ANC visits. View Full-Text   Abstract
Toll-like receptors (TLRs) are a group of pattern recognition receptors (PRRs) that provide innate immune sensing of conserved pathogen-associated molecular patterns (PAMPs) to engage early immune recognition of bacteria, viruses, and protozoa. Furthermore, TLRs provide a conduit for initiation of non-infectious inflammation following the sensing of danger-associated molecular patterns (DAMPs) generated as a consequence of cellular injury. Due to their essential role as DAMP and PAMP sensors, TLR signaling also contributes importantly to several systemic diseases including cardiovascular disease, diabetes, and others. The overlapping participation of TLRs in the control of infection, and pathogenesis of systemic diseases, has served as a starting point for research delving into the poorly defined area of infection leading to increased risk of various systemic diseases. Although conflicting studies exist, cardiovascular disease, diabetes, cancer, rheumatoid arthritis, and obesity/metabolic dysfunction have been associated with differing degrees of strength to infectious diseases. Here we will discuss elements of these connections focusing on the contributions of TLR signaling as a consequence of bacterial exposure in the context of the oral infections leading to periodontal disease, and associations with metabolic diseases including atherosclerosis and type 2 diabetes. View Full-Text "," influenza,vaccine,correlates,universal,next-generation,animal model,human challenge,adjuvants,vaccine safety,regulatory pathway   influenza virus,vaccines,host factors,systems biology,polymorphisms,dendritic cells,adjuvants,innate immunity,adaptive immunity   Ethiopia,vaccination coverage,religion,vaccine hesitancy,perinatal care   toll-like receptors,periodontal disease,infection,immunity,systemic disease,adipocytes,insulin resistance,lipolysis,review "," Development and Regulation of Novel Influenza Virus Vaccines: A United States Young Scientist Perspective   “Gnothi Seauton”: Leveraging the Host Response to Improve Influenza Virus Vaccine Efficacy   Predictors and Barriers to Full Vaccination among Children in Ethiopia   Linkage of Infection to Adverse Systemic Complications: Periodontal Disease, Toll-Like Receptors, and Other Pattern Recognition Systems   Abstract
Vaccination against influenza is the most effective approach for reducing influenza morbidity and mortality. However, influenza vaccines are unique among all licensed vaccines as they are updated and administered annually to antigenically match the vaccine strains and currently circulating influenza strains. Vaccine efficacy of each selected influenza virus vaccine varies depending on the antigenic match between circulating strains and vaccine strains, as well as the age and health status of the vaccine recipient. Low vaccine effectiveness of seasonal influenza vaccines in recent years provides an impetus to improve current seasonal influenza vaccines, and for development of next-generation influenza vaccines that can provide broader, long-lasting protection against both matching and antigenically diverse influenza strains. This review discusses a perspective on some of the issues and formidable challenges facing the development and regulation of the next-generation influenza vaccines. View Full-Text   Abstract
Vaccination against the seasonal influenza virus is the best way to prevent infection. Nevertheless, vaccine efficacy remains far from optimal especially in high-risk populations such as the elderly. Recent technological advancements have facilitated rapid and precise identification of the B and T cell epitopes that are targets for protective responses. While these discoveries have undoubtedly brought the field closer to “universal” influenza virus vaccines, choosing the correct antigen is only one piece of the equation. Achieving efficacy and durability requires a detailed understanding of the diverse host factors and pathways that are required for attaining optimal responses. Sequencing technologies, systems biology, and immunological studies have recently advanced our understanding of the diverse aspects of the host response required for vaccine efficacy. In this paper, we review the critical role of the host response in determining efficacious responses and discuss the gaps in knowledge that will need to be addressed if the field is to be successful in developing new and more effective influenza virus vaccines. View Full-Text   Abstract
Predictors of immunization status outside of large cities in Ethiopia are not well known, and Muslims have lower vaccination coverage. The aim of this study is to assess factors associated with full immunization among children 12–23 months in Worabe, Ethiopia, a Muslim-majority community. A cross-sectional study is conducted in summer 2016. Multivariable logistic regression was used to assess the significance of predictors of full immunization. Among 484 children, 61% are fully vaccinated. Children whose mothers had fewer antenatal care (ANC) visits have decreased odds of full vaccination (zero visits: odds ratio (OR) = 0.09; one visit: OR = 0.15; two visits: OR = 0.46; three visits: OR = 0.89). The most common reasons that the mother gave for not vaccinating the child are fear of side reactions (36%), being too busy (31%), or hearing rumors about vaccines (28%). Local interventions incorporating interventions with religious authorities could raise awareness in the community of the importance of childhood immunizations and ANC visits. View Full-Text   Abstract
Toll-like receptors (TLRs) are a group of pattern recognition receptors (PRRs) that provide innate immune sensing of conserved pathogen-associated molecular patterns (PAMPs) to engage early immune recognition of bacteria, viruses, and protozoa. Furthermore, TLRs provide a conduit for initiation of non-infectious inflammation following the sensing of danger-associated molecular patterns (DAMPs) generated as a consequence of cellular injury. Due to their essential role as DAMP and PAMP sensors, TLR signaling also contributes importantly to several systemic diseases including cardiovascular disease, diabetes, and others. The overlapping participation of TLRs in the control of infection, and pathogenesis of systemic diseases, has served as a starting point for research delving into the poorly defined area of infection leading to increased risk of various systemic diseases. Although conflicting studies exist, cardiovascular disease, diabetes, cancer, rheumatoid arthritis, and obesity/metabolic dysfunction have been associated with differing degrees of strength to infectious diseases. Here we will discuss elements of these connections focusing on the contributions of TLR signaling as a consequence of bacterial exposure in the context of the oral infections leading to periodontal disease, and associations with metabolic diseases including atherosclerosis and type 2 diabetes. View Full-Text   influenza,vaccine,correlates,universal,next-generation,animal model,human challenge,adjuvants,vaccine safety,regulatory pathway   influenza virus,vaccines,host factors,systems biology,polymorphisms,dendritic cells,adjuvants,innate immunity,adaptive immunity   Ethiopia,vaccination coverage,religion,vaccine hesitancy,perinatal care   toll-like receptors,periodontal disease,infection,immunity,systemic disease,adipocytes,insulin resistance,lipolysis,review ", Vaccines 
 Effect of DS Concentration on the PRO Performance Using a 5-Inch Scale Cellulose Triacetate-Based Hollow Fiber Membrane Module   Applicability of a Supported Liquid Membrane in the Enrichment and Determination of Cadmium from Complex Aqueous Samples   Effective Conversion of Amide to Carboxylic Acid on Polymers of Intrinsic Microporosity (PIM-1) with Nitrous Acid   Liquid Membranes as a Tool for Chemical Speciation of Metals in Natural Waters: Organic and Inorganic Complexes of Nickel ," Abstract
In this study, pressure-retarded osmosis (PRO) performance of a 5-inch scale cellulose triacetate (CTA)-based hollow fiber (HF) membrane module was evaluated under a wide range of operating conditions (0.0–6.0 MPa of applied pressure, 0.5–2.0 L/min feed solution (FS) inlet flow rate, 1.0–6.0 L/min DS inlet flow rate and 0.1–0.9 M draw solution (DS) concentration) by using a PRO/reverse osmosis (RO) hybrid system. The subsequent RO system for DS regeneration enabled the evaluation of the steady-stated module performance. In the case of pilot-scale module operation, since the DS dilution and the feed solution (FS) up-concentration had occurred and was not negligible, unlike the lab-scale experiment, PRO performance strongly depended on operating conditions such as inlet flow rates of both the DS and FS concentration. To compare the module performance with different configurations, we proposed a converted parameter in which a difference of the packing density between the spiral wound (SW) and the HF module was fairly considered. In the case of HF configuration, because of high packing density, volumetric-based performance was higher than that of SW module, that is, the required number of the module would be less than that of SW module in a full-scale PRO plant. View Full-Text   Abstract
A supported liquid membrane is developed for the separation of Cd from either high in salinity or acidity aqueous media. The membrane consisted of a durapore (polyvinylidene difluoride) polymeric support impregnated with a 0.5 M Aliquat 336 solution in decaline. The effect of carrier concentration, organic solvent and feed and receiving solutions on the metal permeability is studied. This system allows the effective transport of trace levels of Cd through the formation of CdCl42−, which is the predominant species responsible for the extraction process, in both NaCl and HCl solutions. The supported liquid membrane system in a hollow fibre configuration allows the enrichment and separation of trace levels of Cd from spiked seawater samples, facilitating the analytical determination of this toxic metal. View Full-Text   Abstract
Carboxylate-functionalised polymers of intrinsic microporosity (C-PIMs) are highly desirable materials for membrane separation applications. The recently reported method to afford C-PIMs was via an extensive base hydrolysis process requiring 360 h. Herein, a novel and effective method to convert PIM-CONH2 to C-PIM using nitrous acid was studied. The chemical structure of C-PIM was characterised by 1H NMR, 13C NMR, FTIR, elemental analysis, UV-Vis, TGA and TGA-MS. Complete conversion from amide to carboxylic acid groups was confirmed. Decarboxylation of C-PIM was also successfully studied by TGA-MS for the first time, with a loss of m/z 44 amu (CO2) observed at the first degradation stage. TGA also revealed decreased thermal stability of C-PIM relative to PIM-CONH2 under both N2 and air atmosphere. Gel permeation chromatography (GPC) analysis showed continuous molecular weight degradation of C-PIM with extended reaction time. Aromatic nitration was also observed as a side reaction in some cases. View Full-Text   Abstract
The different species of nickel present in natural waters exhibit different transport behaviour through bulk liquid membranes (BLMs). This fact has been used to design and optimise a separation/pre-concentration system applicable to separate labile and non-labile nickel fractions. A hydrazone derivative—1,2-cyclohexanedione bis-benzoyl-hydrazone (1,2-CHBBH) dissolved in toluene/dimethyl formamide (2% DMF)—was used as a chemical carrier of nickel species, from an aqueous source solution (sample) to a receiving acidic solution. Both chemical and hydrodynamic conditions controlling the transport system were studied and optimised. Under optimum conditions, variations in the transport of nickel ions as a function of organic (humic acids) and inorganic (chloride ions) ligands were studied. Relationships between the permeability coefficient (P) or recovery efficiency (%R) and the concentrations of ligands and nickel species were analysed using Winhumic V software. A negative correlation between P and the concentration of organic nickel complexes was found, suggesting that only labile nickel species are transported through the liquid membrane, with non-labile complexes remaining in the water sample; allowing for their separation and subsequent quantification in natural waters. View Full-Text "," pressure-retarded osmosis,hollow fiber membrane,pilot-scale   solid supported liquid membrane,hollow fibre,Aliquat 336,cadmium,seawater   polymers of intrinsic microporosity,gas separation membrane,carboxylated PIM-1   natural water,trace metal,nickel,pre-concentration,speciation,liquid membranes "," Effect of DS Concentration on the PRO Performance Using a 5-Inch Scale Cellulose Triacetate-Based Hollow Fiber Membrane Module   Applicability of a Supported Liquid Membrane in the Enrichment and Determination of Cadmium from Complex Aqueous Samples   Effective Conversion of Amide to Carboxylic Acid on Polymers of Intrinsic Microporosity (PIM-1) with Nitrous Acid   Liquid Membranes as a Tool for Chemical Speciation of Metals in Natural Waters: Organic and Inorganic Complexes of Nickel   Abstract
In this study, pressure-retarded osmosis (PRO) performance of a 5-inch scale cellulose triacetate (CTA)-based hollow fiber (HF) membrane module was evaluated under a wide range of operating conditions (0.0–6.0 MPa of applied pressure, 0.5–2.0 L/min feed solution (FS) inlet flow rate, 1.0–6.0 L/min DS inlet flow rate and 0.1–0.9 M draw solution (DS) concentration) by using a PRO/reverse osmosis (RO) hybrid system. The subsequent RO system for DS regeneration enabled the evaluation of the steady-stated module performance. In the case of pilot-scale module operation, since the DS dilution and the feed solution (FS) up-concentration had occurred and was not negligible, unlike the lab-scale experiment, PRO performance strongly depended on operating conditions such as inlet flow rates of both the DS and FS concentration. To compare the module performance with different configurations, we proposed a converted parameter in which a difference of the packing density between the spiral wound (SW) and the HF module was fairly considered. In the case of HF configuration, because of high packing density, volumetric-based performance was higher than that of SW module, that is, the required number of the module would be less than that of SW module in a full-scale PRO plant. View Full-Text   Abstract
A supported liquid membrane is developed for the separation of Cd from either high in salinity or acidity aqueous media. The membrane consisted of a durapore (polyvinylidene difluoride) polymeric support impregnated with a 0.5 M Aliquat 336 solution in decaline. The effect of carrier concentration, organic solvent and feed and receiving solutions on the metal permeability is studied. This system allows the effective transport of trace levels of Cd through the formation of CdCl42−, which is the predominant species responsible for the extraction process, in both NaCl and HCl solutions. The supported liquid membrane system in a hollow fibre configuration allows the enrichment and separation of trace levels of Cd from spiked seawater samples, facilitating the analytical determination of this toxic metal. View Full-Text   Abstract
Carboxylate-functionalised polymers of intrinsic microporosity (C-PIMs) are highly desirable materials for membrane separation applications. The recently reported method to afford C-PIMs was via an extensive base hydrolysis process requiring 360 h. Herein, a novel and effective method to convert PIM-CONH2 to C-PIM using nitrous acid was studied. The chemical structure of C-PIM was characterised by 1H NMR, 13C NMR, FTIR, elemental analysis, UV-Vis, TGA and TGA-MS. Complete conversion from amide to carboxylic acid groups was confirmed. Decarboxylation of C-PIM was also successfully studied by TGA-MS for the first time, with a loss of m/z 44 amu (CO2) observed at the first degradation stage. TGA also revealed decreased thermal stability of C-PIM relative to PIM-CONH2 under both N2 and air atmosphere. Gel permeation chromatography (GPC) analysis showed continuous molecular weight degradation of C-PIM with extended reaction time. Aromatic nitration was also observed as a side reaction in some cases. View Full-Text   Abstract
The different species of nickel present in natural waters exhibit different transport behaviour through bulk liquid membranes (BLMs). This fact has been used to design and optimise a separation/pre-concentration system applicable to separate labile and non-labile nickel fractions. A hydrazone derivative—1,2-cyclohexanedione bis-benzoyl-hydrazone (1,2-CHBBH) dissolved in toluene/dimethyl formamide (2% DMF)—was used as a chemical carrier of nickel species, from an aqueous source solution (sample) to a receiving acidic solution. Both chemical and hydrodynamic conditions controlling the transport system were studied and optimised. Under optimum conditions, variations in the transport of nickel ions as a function of organic (humic acids) and inorganic (chloride ions) ligands were studied. Relationships between the permeability coefficient (P) or recovery efficiency (%R) and the concentrations of ligands and nickel species were analysed using Winhumic V software. A negative correlation between P and the concentration of organic nickel complexes was found, suggesting that only labile nickel species are transported through the liquid membrane, with non-labile complexes remaining in the water sample; allowing for their separation and subsequent quantification in natural waters. View Full-Text   pressure-retarded osmosis,hollow fiber membrane,pilot-scale   solid supported liquid membrane,hollow fibre,Aliquat 336,cadmium,seawater   polymers of intrinsic microporosity,gas separation membrane,carboxylated PIM-1   natural water,trace metal,nickel,pre-concentration,speciation,liquid membranes ", Membranes 
" Degree of Left Renal Vein Compression Predicts Nutcracker Syndrome   Influence of the Self-Perception of Old Age on the Effect of a Healthy Aging Program   The Frequency of MEFV Gene Mutations and Genotypes in Sanliurfa Province, South-Eastern Region of Turkey, after the Syrian Civil War by Using Next Generation Sequencing and Report of a Novel Exon 4 Mutation (I423T) "," Abstract
Nutcracker syndrome (NS) refers to symptomatic compression of the left renal vein (LRV) between the abdominal aorta and superior mesenteric artery with potential symptoms including hematuria, proteinuria, left flank pain, and renal venous hypertension. No consensus diagnostic criteria exist to guide endovascular treatment. We aimed to evaluate the specificity of LRV compression to NS symptoms through a retrospective study including 33 NS and 103 control patients. The size of the patent lumen at point of compression and normal portions of the LRV were measured for all patients. Multiple logistic regression analyses (MLR) assessing impact of compression, body mass index (BMI), age, and gender on the likelihood of each symptom with NS were obtained. NS patients presented most commonly with abdominal pain (72.7%), followed by hematuria (57.6%), proteinuria (39.4%), and left flank pain (30.3%). These symptoms were more commonly seen than in the control group at 10.6, 11.7, 6.8, and 1.9%, respectively. The degree of LRV compression for NS was 74.5% and 25.2% for controls (p < 0.0001). Higher compression led to more hematuria (p < 0.0013), abdominal pain (p < 0.006), and more proteinuria (p < 0.002). Furthermore, the average BMI of NS patients was 21.4 and 27.2 for controls (p < 0.001) and a low BMI led to more abdominal pain (p < 0.005). These results demonstrate a strong correlation between the degree of LRV compression on imaging in diagnosing NS. View Full-Text   Abstract
It has been shown that health programs are useful for the prevention and control of chronic diseases in community-dwelling older people; however, a negative self-perception of old age could have an effect on the results. Therefore, our aim was to evaluate the effect of a healthy aging program linked to self-perception of old age in Mexican community-dwelling older people. A pre-test/post-test single-group design study was conducted in a convenience sample of 64 older people who undertook the entire healthy aging program workshop (five months’ duration). We measured self-perception of old age, efficacy of self-care, blood glucose concentration, anthropometric measures, and blood pressure before and after the workshop. A statistically significant decrease in blood glucose concentration was observed (baseline 136 ± 50 vs. post-intervention, 124 ± 45 ± 29 mg/dL, p < 0.01), LDL (baseline 153 ± 47 vs. post-intervention, 130 ± 36 mg/dL, p < 0.01), systolic blood pressure (130 ± 20 vs. 119 ± 11 mm/Hg, p < 0.001), and diastolic blood pressure (75 ± 9 vs. 72 ± 7 mm/Hg, p < 0.05) after community intervention. However, when we analyzed the data regarding self-perception, we found that this difference was only maintained in the subgroup of older adults with a positive self-perception of old age. Our findings suggest that the self-perception of old age influences the effect of healthy aging programs on the health of community-dwelling older people. View Full-Text   Abstract
Background: Familial Mediterranean Fever (FMF) is a genetic disorder characterized by recurrent episodes of fever and abdominal pain. Mutations in the Mediterranean fever (MEFV) gene are localized on the p arm of chromosome 16. Over 333 MEFV sequence variants have been identified so far in FMF patients, which occur mostly in the 2nd and 10th exons of the gene. Methods: In this study, 296 unrelated patients with clinical suspicion of FMF, which were admitted during January–December 2017, were retrospectively reviewed to identify the frequency of MEFV gene mutations by using next generation sequencing. Results: Eighteen different mutations, 45 different genotypes and a novel exon 4 (I423T) mutation were identified in this study. This mutation is the fourth mutation identified in exon 4.The most frequent mutation was R202Q, followed by M694V, E148Q, M680I, R761H, V726A and R354W. Conclusions: One of the most important aims of this study is to investigate the MEFV mutation type and genotype of migrants coming to Sanliurfa after the civil war of Syria. This study also examines the effect of the condition on the region’s gene pool and the distribution of different types of mutations. Our results indicated that MEFV mutations are highly heterogeneous in our patient population, which is consistent with the findings of other studies in our region. Previously used methods, such as Restriction Fragment Length Polymorphism (RFLP), do not define uncommon or especially novel mutations. Therefore, Next Generation Sequencing (NGS) analysis of the MEFV gene could be useful for finding novel mutations, except for those located on exon 2 and 10. View Full-Text "," nutcracker syndrome,left renal vein,compression   self-perception of old age,self-care,healthy aging,Mexican community-dwelling older people   MEFV mutations,genetics,rheumatology,FMF,next generation sequencing "," Degree of Left Renal Vein Compression Predicts Nutcracker Syndrome   Influence of the Self-Perception of Old Age on the Effect of a Healthy Aging Program   The Frequency of MEFV Gene Mutations and Genotypes in Sanliurfa Province, South-Eastern Region of Turkey, after the Syrian Civil War by Using Next Generation Sequencing and Report of a Novel Exon 4 Mutation (I423T)   Abstract
Nutcracker syndrome (NS) refers to symptomatic compression of the left renal vein (LRV) between the abdominal aorta and superior mesenteric artery with potential symptoms including hematuria, proteinuria, left flank pain, and renal venous hypertension. No consensus diagnostic criteria exist to guide endovascular treatment. We aimed to evaluate the specificity of LRV compression to NS symptoms through a retrospective study including 33 NS and 103 control patients. The size of the patent lumen at point of compression and normal portions of the LRV were measured for all patients. Multiple logistic regression analyses (MLR) assessing impact of compression, body mass index (BMI), age, and gender on the likelihood of each symptom with NS were obtained. NS patients presented most commonly with abdominal pain (72.7%), followed by hematuria (57.6%), proteinuria (39.4%), and left flank pain (30.3%). These symptoms were more commonly seen than in the control group at 10.6, 11.7, 6.8, and 1.9%, respectively. The degree of LRV compression for NS was 74.5% and 25.2% for controls (p < 0.0001). Higher compression led to more hematuria (p < 0.0013), abdominal pain (p < 0.006), and more proteinuria (p < 0.002). Furthermore, the average BMI of NS patients was 21.4 and 27.2 for controls (p < 0.001) and a low BMI led to more abdominal pain (p < 0.005). These results demonstrate a strong correlation between the degree of LRV compression on imaging in diagnosing NS. View Full-Text   Abstract
It has been shown that health programs are useful for the prevention and control of chronic diseases in community-dwelling older people; however, a negative self-perception of old age could have an effect on the results. Therefore, our aim was to evaluate the effect of a healthy aging program linked to self-perception of old age in Mexican community-dwelling older people. A pre-test/post-test single-group design study was conducted in a convenience sample of 64 older people who undertook the entire healthy aging program workshop (five months’ duration). We measured self-perception of old age, efficacy of self-care, blood glucose concentration, anthropometric measures, and blood pressure before and after the workshop. A statistically significant decrease in blood glucose concentration was observed (baseline 136 ± 50 vs. post-intervention, 124 ± 45 ± 29 mg/dL, p < 0.01), LDL (baseline 153 ± 47 vs. post-intervention, 130 ± 36 mg/dL, p < 0.01), systolic blood pressure (130 ± 20 vs. 119 ± 11 mm/Hg, p < 0.001), and diastolic blood pressure (75 ± 9 vs. 72 ± 7 mm/Hg, p < 0.05) after community intervention. However, when we analyzed the data regarding self-perception, we found that this difference was only maintained in the subgroup of older adults with a positive self-perception of old age. Our findings suggest that the self-perception of old age influences the effect of healthy aging programs on the health of community-dwelling older people. View Full-Text   Abstract
Background: Familial Mediterranean Fever (FMF) is a genetic disorder characterized by recurrent episodes of fever and abdominal pain. Mutations in the Mediterranean fever (MEFV) gene are localized on the p arm of chromosome 16. Over 333 MEFV sequence variants have been identified so far in FMF patients, which occur mostly in the 2nd and 10th exons of the gene. Methods: In this study, 296 unrelated patients with clinical suspicion of FMF, which were admitted during January–December 2017, were retrospectively reviewed to identify the frequency of MEFV gene mutations by using next generation sequencing. Results: Eighteen different mutations, 45 different genotypes and a novel exon 4 (I423T) mutation were identified in this study. This mutation is the fourth mutation identified in exon 4.The most frequent mutation was R202Q, followed by M694V, E148Q, M680I, R761H, V726A and R354W. Conclusions: One of the most important aims of this study is to investigate the MEFV mutation type and genotype of migrants coming to Sanliurfa after the civil war of Syria. This study also examines the effect of the condition on the region’s gene pool and the distribution of different types of mutations. Our results indicated that MEFV mutations are highly heterogeneous in our patient population, which is consistent with the findings of other studies in our region. Previously used methods, such as Restriction Fragment Length Polymorphism (RFLP), do not define uncommon or especially novel mutations. Therefore, Next Generation Sequencing (NGS) analysis of the MEFV gene could be useful for finding novel mutations, except for those located on exon 2 and 10. View Full-Text   nutcracker syndrome,left renal vein,compression   self-perception of old age,self-care,healthy aging,Mexican community-dwelling older people   MEFV mutations,genetics,rheumatology,FMF,next generation sequencing ", Journal of Clinical Medicine 
 Salt Tolerance of Six Switchgrass Cultivars   Multi-Temporal Site-Specific Weed Control of Cirsium arvense (L.) Scop. and Rumex crispus L. in Maize and Sugar Beet Using Unmanned Aerial Vehicle Based Mapping   Relationship of Date Palm Tree Density to Dubas Bug Ommatissus lybicus Infestation in Omani Orchards   Sustainable Intensification in Dryland Cropping Systems—Perspectives for Adaptions across the Western Siberian Grain Belt ," Abstract
Panicum virgatum L. (switchgrass) cultivars (‘Alamo’, ‘Cimarron’, ‘Kanlow’, ‘NL 94C2-3’, ‘NSL 2009-1’, and ‘NSL 2009-2’) were evaluated for salt tolerance in two separate greenhouse experiments. In experiment (Expt.) 1, switchgrass seedlings were irrigated with a nutrient solution at an electrical conductivity (EC) of 1.2 dS·m−1 (control) or a saline solution (spiked with salts) at an EC of 5.0 dS·m−1 (EC 5) or 10.0 dS·m−1 (EC 10) for four weeks, once a week. Treatment EC 10 reduced the tiller number by 32% to 37% for all switchgrass cultivars except ‘Kanlow’. All switchgrass cultivars under EC 10 had a significant reduction of 50% to 63% in dry weight. In Expt. 2, switchgrass was seeded in substrates moistened with either a nutrient solution of EC 1.2 dS·m−1 (control) or a saline solution of EC of 5.0, 10.0, or 20.0 dS·m−1 (EC 5, EC 10, or EC 20). Treatment EC 5 did not affect the seedling emergence, regardless of cultivar. Compared to the control, EC 10 reduced the seedling emergence of switchgrass ‘Alamo’, ‘Cimarron’, and ‘NL 94C2-3’ by 44%, 33%, and 82%, respectively. All switchgrass cultivars under EC 10 had a 46% to 88% reduction in the seedling emergence index except ‘NSL 2009-2’. No switchgrass seedlings emerged under EC 20. In summary, high salinity negatively affected switchgrass seedling emergence and growth. Dendrogram and cluster of six switchgrass cultivars indicated that ‘Alamo’ was the most tolerant cultivar, while ‘NSL 2009-2’ was the least tolerant cultivar at both seedling emergence and growth stages. A growth-stage dependent response to salinity was observed for the remaining switchgrass cultivars. ‘NSL 2009-1’ and ‘NL 94C2-3’ were more tolerant to salinity than ‘Cimarron’ and ‘Kanlow’ at the seedling emergence stage; however, ‘Kanlow’ and ‘Cimarron’ were more tolerant to salinity than ‘NSL 2009-1’ and ‘NL 94C2-3’ at the seedling growth stage. View Full-Text   Abstract
Sensor-based weed mapping in arable fields is a key element for site-specific herbicide management strategies. In this study, we investigated the generation of application maps based on Unmanned Aerial Vehicle imagery and present a site-specific herbicide application using those maps. Field trials for site-specific herbicide applications and multi-temporal image flights were carried out in maize (Zea mays L.) and sugar beet (Beta vulgaris L.) in southern Germany. Real-time kinematic Global Positioning System precision planting information provided the input for determining plant rows in the geocoded aerial images. Vegetation indices combined with generated plant height data were used to detect the patches containing creeping thistle (Cirsium arvense (L.) Scop.) and curled dock (Rumex crispus L.). The computed weed maps showed the presence or absence of the aforementioned weeds on the fields, clustered to 9 m × 9 m grid cells. The precision of the correct classification varied from 96% in maize to 80% in the last sugar beet treatment. The computational underestimation of manual mapped C. arvense and R. cripus patches varied from 1% to 10% respectively. Overall, the developed algorithm performed well, identifying tall perennial weeds for the computation of large-scale herbicide application maps. View Full-Text   Abstract
Date palm trees, Phoenix dactylifera, are the primary crop in Oman. Most date palm cultivation is under the traditional agricultural system. The plants are usually under dense planting, which makes them prone to pest infestation. The main pest attacking date palm crops in Oman is the Dubas bug Ommatissus lybicus. This study integrated modern technology, remote sensing and geographic information systems to determine the number of date palm trees in traditional agriculture locations to find the relationship between date palm tree density and O. lybicus infestation. A local maxima method for tree identification was used to determine the number of date palm trees from high spatial resolution satellite imagery captured by WorldView-3 satellite. Window scale sizes of 3, 5 and 7 m were tested and the results showed that the best window size for date palm trees number detection was 7 m, with an overall estimation accuracy 88.2%. Global regression ordinary least square (OLS) and local geographic weighted regression (GWR) were used to test the relationship between infestation intensity and tree density. The GWR model showed a good positive significant relationship between infestation and tree density in the spring season with R2 = 0.59 and medium positive significant relationship in the autumn season with R2 = 0.30. In contrast, the OLS model results showed a weak positive significant relationship in the spring season with R2 = 0.02, p < 0.05 and insignificant relationship in the autumn season with R2 = 0.01, p > 0.05. The results indicated that there was a geographic effect on the infestation of O. lybicus, which had a greater impact on infestation severity, and that the impact of tree density was higher in the spring season than in autumn season. View Full-Text   Abstract
The Western Siberian grain belt is of global significance in terms of agricultural production as well as carbon sequestration and biodiversity preservation. Regional downscaling of general circulation models predict increasing drought risks and water scarcity for this area. Additionally, significant land-use changes took place in this region after the dissolution of the USSR and collapse of the state farm system: Land-use intensity in Western Siberia (Russian Federation) continuously decreased on grassland, whilst on cropland the intensity increased through recultivation of abandoned cropland and rising fertilizer inputs since 2003. Together, these changing conditions have led to challenges for sustainable agriculture in this semi-arid environment. For sustainable land management, strategies for adapted crop production systems are needed. In agronomic field trials, the potential of enhanced water use efficiency as contribution to a resilient agricultural system under changing climate conditions was evaluated and related to the common practice and regional research. In participatory on-farm trials, higher average soil water content (+40%) in the top soil layer led to higher grain yield (+0.4 t ha−1) and protein yield (+0.05 t ha−1) under no-till compared to the common practice of conventional tillage. Despite this, regional research still promotes bare fallowing with beneficial effects only in the first harvest after fallow, whereas the potential of no-till was visible each year, even under above-average wet and cool growing conditions. In this case study from the Western Siberian grain belt, we depict a possible pathway to make cereal production in Western Siberia more sustainable. However, the approach of applied sustainable intensification by promoting no-till is related to the negative concomitant effect of increased herbicide applications. Due to the strict rejection of GMOs in Russian agriculture by the federal government, this is a great opportunity to maintain a large, pristine area of over 17 million km2 with a lower risk of glyphosate-dependent cropping systems. View Full-Text "," Panicum virgatum,salinity,mineral nutrition,cluster analysis   digital elevation model,excessive green red vegetation index,patch spraying,site-specific weed control,UAV weed detection,weed mapping   Dubas bug Ommatissus lybicus,date palm Phoenix dactylifera,remote sensing,multispectral image,local maxima   bare fallow,no-till,conservation agriculture,crop rotation,spring wheat,water use efficiency "," Salt Tolerance of Six Switchgrass Cultivars   Multi-Temporal Site-Specific Weed Control of Cirsium arvense (L.) Scop. and Rumex crispus L. in Maize and Sugar Beet Using Unmanned Aerial Vehicle Based Mapping   Relationship of Date Palm Tree Density to Dubas Bug Ommatissus lybicus Infestation in Omani Orchards   Sustainable Intensification in Dryland Cropping Systems—Perspectives for Adaptions across the Western Siberian Grain Belt   Abstract
Panicum virgatum L. (switchgrass) cultivars (‘Alamo’, ‘Cimarron’, ‘Kanlow’, ‘NL 94C2-3’, ‘NSL 2009-1’, and ‘NSL 2009-2’) were evaluated for salt tolerance in two separate greenhouse experiments. In experiment (Expt.) 1, switchgrass seedlings were irrigated with a nutrient solution at an electrical conductivity (EC) of 1.2 dS·m−1 (control) or a saline solution (spiked with salts) at an EC of 5.0 dS·m−1 (EC 5) or 10.0 dS·m−1 (EC 10) for four weeks, once a week. Treatment EC 10 reduced the tiller number by 32% to 37% for all switchgrass cultivars except ‘Kanlow’. All switchgrass cultivars under EC 10 had a significant reduction of 50% to 63% in dry weight. In Expt. 2, switchgrass was seeded in substrates moistened with either a nutrient solution of EC 1.2 dS·m−1 (control) or a saline solution of EC of 5.0, 10.0, or 20.0 dS·m−1 (EC 5, EC 10, or EC 20). Treatment EC 5 did not affect the seedling emergence, regardless of cultivar. Compared to the control, EC 10 reduced the seedling emergence of switchgrass ‘Alamo’, ‘Cimarron’, and ‘NL 94C2-3’ by 44%, 33%, and 82%, respectively. All switchgrass cultivars under EC 10 had a 46% to 88% reduction in the seedling emergence index except ‘NSL 2009-2’. No switchgrass seedlings emerged under EC 20. In summary, high salinity negatively affected switchgrass seedling emergence and growth. Dendrogram and cluster of six switchgrass cultivars indicated that ‘Alamo’ was the most tolerant cultivar, while ‘NSL 2009-2’ was the least tolerant cultivar at both seedling emergence and growth stages. A growth-stage dependent response to salinity was observed for the remaining switchgrass cultivars. ‘NSL 2009-1’ and ‘NL 94C2-3’ were more tolerant to salinity than ‘Cimarron’ and ‘Kanlow’ at the seedling emergence stage; however, ‘Kanlow’ and ‘Cimarron’ were more tolerant to salinity than ‘NSL 2009-1’ and ‘NL 94C2-3’ at the seedling growth stage. View Full-Text   Abstract
Sensor-based weed mapping in arable fields is a key element for site-specific herbicide management strategies. In this study, we investigated the generation of application maps based on Unmanned Aerial Vehicle imagery and present a site-specific herbicide application using those maps. Field trials for site-specific herbicide applications and multi-temporal image flights were carried out in maize (Zea mays L.) and sugar beet (Beta vulgaris L.) in southern Germany. Real-time kinematic Global Positioning System precision planting information provided the input for determining plant rows in the geocoded aerial images. Vegetation indices combined with generated plant height data were used to detect the patches containing creeping thistle (Cirsium arvense (L.) Scop.) and curled dock (Rumex crispus L.). The computed weed maps showed the presence or absence of the aforementioned weeds on the fields, clustered to 9 m × 9 m grid cells. The precision of the correct classification varied from 96% in maize to 80% in the last sugar beet treatment. The computational underestimation of manual mapped C. arvense and R. cripus patches varied from 1% to 10% respectively. Overall, the developed algorithm performed well, identifying tall perennial weeds for the computation of large-scale herbicide application maps. View Full-Text   Abstract
Date palm trees, Phoenix dactylifera, are the primary crop in Oman. Most date palm cultivation is under the traditional agricultural system. The plants are usually under dense planting, which makes them prone to pest infestation. The main pest attacking date palm crops in Oman is the Dubas bug Ommatissus lybicus. This study integrated modern technology, remote sensing and geographic information systems to determine the number of date palm trees in traditional agriculture locations to find the relationship between date palm tree density and O. lybicus infestation. A local maxima method for tree identification was used to determine the number of date palm trees from high spatial resolution satellite imagery captured by WorldView-3 satellite. Window scale sizes of 3, 5 and 7 m were tested and the results showed that the best window size for date palm trees number detection was 7 m, with an overall estimation accuracy 88.2%. Global regression ordinary least square (OLS) and local geographic weighted regression (GWR) were used to test the relationship between infestation intensity and tree density. The GWR model showed a good positive significant relationship between infestation and tree density in the spring season with R2 = 0.59 and medium positive significant relationship in the autumn season with R2 = 0.30. In contrast, the OLS model results showed a weak positive significant relationship in the spring season with R2 = 0.02, p < 0.05 and insignificant relationship in the autumn season with R2 = 0.01, p > 0.05. The results indicated that there was a geographic effect on the infestation of O. lybicus, which had a greater impact on infestation severity, and that the impact of tree density was higher in the spring season than in autumn season. View Full-Text   Abstract
The Western Siberian grain belt is of global significance in terms of agricultural production as well as carbon sequestration and biodiversity preservation. Regional downscaling of general circulation models predict increasing drought risks and water scarcity for this area. Additionally, significant land-use changes took place in this region after the dissolution of the USSR and collapse of the state farm system: Land-use intensity in Western Siberia (Russian Federation) continuously decreased on grassland, whilst on cropland the intensity increased through recultivation of abandoned cropland and rising fertilizer inputs since 2003. Together, these changing conditions have led to challenges for sustainable agriculture in this semi-arid environment. For sustainable land management, strategies for adapted crop production systems are needed. In agronomic field trials, the potential of enhanced water use efficiency as contribution to a resilient agricultural system under changing climate conditions was evaluated and related to the common practice and regional research. In participatory on-farm trials, higher average soil water content (+40%) in the top soil layer led to higher grain yield (+0.4 t ha−1) and protein yield (+0.05 t ha−1) under no-till compared to the common practice of conventional tillage. Despite this, regional research still promotes bare fallowing with beneficial effects only in the first harvest after fallow, whereas the potential of no-till was visible each year, even under above-average wet and cool growing conditions. In this case study from the Western Siberian grain belt, we depict a possible pathway to make cereal production in Western Siberia more sustainable. However, the approach of applied sustainable intensification by promoting no-till is related to the negative concomitant effect of increased herbicide applications. Due to the strict rejection of GMOs in Russian agriculture by the federal government, this is a great opportunity to maintain a large, pristine area of over 17 million km2 with a lower risk of glyphosate-dependent cropping systems. View Full-Text   Panicum virgatum,salinity,mineral nutrition,cluster analysis   digital elevation model,excessive green red vegetation index,patch spraying,site-specific weed control,UAV weed detection,weed mapping   Dubas bug Ommatissus lybicus,date palm Phoenix dactylifera,remote sensing,multispectral image,local maxima   bare fallow,no-till,conservation agriculture,crop rotation,spring wheat,water use efficiency ", Agriculture 
 Prediction of Propeller-Induced Hull Pressure Fluctuations via a Potential-Based Method: Study of the Effects of Different Wake Alignment Methods and of the Rudder   Experimental Validation of Fluid–Structure Interaction Computations of Flexible Composite Propellers in Open Water Conditions Using BEM-FEM and RANS-FEM Methods   Experimental Investigation of Propeller Wake Velocity Field to Determine the Major Factors Affecting Propeller Wake Wash   A Semi-Empirical Prediction Method for Broadband Hull-Pressure Fluctuations and Underwater Radiated Noise by Propeller Tip Vortex Cavitation † ," Abstract
In order to predict ship hull pressure fluctuations induced by marine propellers, a combination of several numerical schemes is used. The propeller perturbation flow is solved by the boundary element method (BEM), while the coupling between a BEM solver and a Reynolds-averaged Navier-Stokes (RANS) solver can efficiently predict the effective wake. Based on the BEM solution under the predicted effective wake, the propeller-induced potential on the ship hull can be evaluated. Then, a pressure-BEM solver is used to solve the diffraction pressure on the hull in order to obtain the solid boundary factor which leads to the total hull pressure. This paper briefly introduces the schemes and numerical models. To avoid numerical instability, several simplifications need to be made. The effects of these simplifications are studied, including the rudder effect and the wake alignment model effect. View Full-Text   Abstract
In the past several decades, many papers have been published on fluid–structure coupled calculations to analyse the hydro-elastic response of flexible (composite) propellers. The flow is usually modelled either by the Navier–Stokes equations or as a potential flow, by assuming an irrotational flow. Phenomena as separation of the flow, flow transition, boundary layer build-up and vorticity dynamics are not captured in a non-viscous potential flow. Nevertheless, potential flow based methods have been shown to be powerful methods to resolve the hydrodynamics of propellers. With the upcoming interest in flexible (composite) propellers, a valid question is what the consequences of the potential flow simplifications are with regard to the coupled fluid–structure analyses of these types of propellers. This question has been addressed in the following way: calculations and experiments were conducted for uniform flows only, with a propeller geometry that challenges the potential flow model due to its sensitivity to leading edge vortex separation. Calculations were performed on the undeformed propeller geometry with a Reynolds-averaged-Navier–Stokes (RANS) solver and a boundary element method (BEM). These calculations show some typical differences between the RANS and BEM results. The flexible propeller responses were predicted by coupled calculations between BEM and finite element method (FEM) and RANS and FEM. The applied methodologies are briefly described. Results obtained from both calculation methods have been compared to experimental results obtained from blade deformation measurements in a cavitation tunnel. The results show that, even for the extreme cases, promising results have been obtained with the BEM-FEM coupling. The BEM-FEM calculated responses are consistent with the RANS-FEM results.   Abstract
The propeller jet from a ship has a significant component directed upwards towards the free surface of the water, which can be used for ice management. This paper describes a comprehensive laboratory experiment where the operational factors affecting a propeller wake velocity field were investigated. The experiment was conducted using a steady wake field to investigate the characteristics of the axial velocity of the fluid in the wake and the corresponding variability downstream of the propeller. The axial velocities and the variability recorded were time-averaged. Propeller rotational speed was found to be the most significant factor, followed by propeller inclination. The experimental results also provide some idea about the change of the patterns of the mean axial velocity distribution against the factors considered for the test throughout the effective wake field, as well as the relationships to predict the axial velocity for known factors. View Full-Text   Abstract
A semi-empirical method is presented that predicts broadband hull-pressure fluctuations and underwater radiated noise due to propeller tip vortex cavitation. The method uses a hump-shaped pattern for the spectrum and predicts the centre frequency and level of this hump. The principal parameter is the vortex cavity size, which is predicted by a combination of a boundary element method and a semi-empirical vortex model. It is shown that such a model is capable of representing the variation of cavity size with cavitation number well. Using a database of model- and full-scale measured hull-pressure data, an empirical formulation for the maximum level and centre frequency has been developed that is a function of, among other parameters, the cavity size. Acceptable results are obtained when comparing predicted and measured hull-pressure and radiated noise spectra for various cases. The comparison also shows differences that require adjustments of parameters that need to be further investigated. View Full-Text "," hull pressure,pressure fluctuation,diffraction potential,wake alignment scheme,boundary element method,cavitation   flexible composite propellers,BEM-FEM coupling,RANS-FEM coupling,propeller deformation measurements   ship’s propeller jet,mean axial velocity of flow,prediction equations   propeller,cavitation,tip vortex,hull pressures,underwater radiated noise "," Prediction of Propeller-Induced Hull Pressure Fluctuations via a Potential-Based Method: Study of the Effects of Different Wake Alignment Methods and of the Rudder   Experimental Validation of Fluid–Structure Interaction Computations of Flexible Composite Propellers in Open Water Conditions Using BEM-FEM and RANS-FEM Methods   Experimental Investigation of Propeller Wake Velocity Field to Determine the Major Factors Affecting Propeller Wake Wash   A Semi-Empirical Prediction Method for Broadband Hull-Pressure Fluctuations and Underwater Radiated Noise by Propeller Tip Vortex Cavitation †   Abstract
In order to predict ship hull pressure fluctuations induced by marine propellers, a combination of several numerical schemes is used. The propeller perturbation flow is solved by the boundary element method (BEM), while the coupling between a BEM solver and a Reynolds-averaged Navier-Stokes (RANS) solver can efficiently predict the effective wake. Based on the BEM solution under the predicted effective wake, the propeller-induced potential on the ship hull can be evaluated. Then, a pressure-BEM solver is used to solve the diffraction pressure on the hull in order to obtain the solid boundary factor which leads to the total hull pressure. This paper briefly introduces the schemes and numerical models. To avoid numerical instability, several simplifications need to be made. The effects of these simplifications are studied, including the rudder effect and the wake alignment model effect. View Full-Text   Abstract
In the past several decades, many papers have been published on fluid–structure coupled calculations to analyse the hydro-elastic response of flexible (composite) propellers. The flow is usually modelled either by the Navier–Stokes equations or as a potential flow, by assuming an irrotational flow. Phenomena as separation of the flow, flow transition, boundary layer build-up and vorticity dynamics are not captured in a non-viscous potential flow. Nevertheless, potential flow based methods have been shown to be powerful methods to resolve the hydrodynamics of propellers. With the upcoming interest in flexible (composite) propellers, a valid question is what the consequences of the potential flow simplifications are with regard to the coupled fluid–structure analyses of these types of propellers. This question has been addressed in the following way: calculations and experiments were conducted for uniform flows only, with a propeller geometry that challenges the potential flow model due to its sensitivity to leading edge vortex separation. Calculations were performed on the undeformed propeller geometry with a Reynolds-averaged-Navier–Stokes (RANS) solver and a boundary element method (BEM). These calculations show some typical differences between the RANS and BEM results. The flexible propeller responses were predicted by coupled calculations between BEM and finite element method (FEM) and RANS and FEM. The applied methodologies are briefly described. Results obtained from both calculation methods have been compared to experimental results obtained from blade deformation measurements in a cavitation tunnel. The results show that, even for the extreme cases, promising results have been obtained with the BEM-FEM coupling. The BEM-FEM calculated responses are consistent with the RANS-FEM results.   Abstract
The propeller jet from a ship has a significant component directed upwards towards the free surface of the water, which can be used for ice management. This paper describes a comprehensive laboratory experiment where the operational factors affecting a propeller wake velocity field were investigated. The experiment was conducted using a steady wake field to investigate the characteristics of the axial velocity of the fluid in the wake and the corresponding variability downstream of the propeller. The axial velocities and the variability recorded were time-averaged. Propeller rotational speed was found to be the most significant factor, followed by propeller inclination. The experimental results also provide some idea about the change of the patterns of the mean axial velocity distribution against the factors considered for the test throughout the effective wake field, as well as the relationships to predict the axial velocity for known factors. View Full-Text   Abstract
A semi-empirical method is presented that predicts broadband hull-pressure fluctuations and underwater radiated noise due to propeller tip vortex cavitation. The method uses a hump-shaped pattern for the spectrum and predicts the centre frequency and level of this hump. The principal parameter is the vortex cavity size, which is predicted by a combination of a boundary element method and a semi-empirical vortex model. It is shown that such a model is capable of representing the variation of cavity size with cavitation number well. Using a database of model- and full-scale measured hull-pressure data, an empirical formulation for the maximum level and centre frequency has been developed that is a function of, among other parameters, the cavity size. Acceptable results are obtained when comparing predicted and measured hull-pressure and radiated noise spectra for various cases. The comparison also shows differences that require adjustments of parameters that need to be further investigated. View Full-Text   hull pressure,pressure fluctuation,diffraction potential,wake alignment scheme,boundary element method,cavitation   flexible composite propellers,BEM-FEM coupling,RANS-FEM coupling,propeller deformation measurements   ship’s propeller jet,mean axial velocity of flow,prediction equations   propeller,cavitation,tip vortex,hull pressures,underwater radiated noise ", Journal of Marine Science and Engineering 
" Cybernetics and the 4D Smart City: Smartness as Awareness   Value Engineering and Function Analysis: Frameworks for Innovation in Antenna Systems   Myalgic Encephalomyelitis, Chronic Fatigue Syndrome, and Systemic Exertion Intolerance Disease: Three Distinct Clinical Entities   Analogies between Heavy Metal Music and the Symptoms of Mental Illness "," Abstract
The complexity of urban challenges obliges us to seek smarter paths for urban development and increase our awareness of urban dynamics in a more holistic manner. Stemming from the discipline of architecture and urban planning, this concept paper outlines an idea of a cybernetic urban management for anticipatory governance of smart cities. A cybernetic system absorbs information from different sources, such as buildings that are aware of their energy efficiency, a city aware of its traffic flows, and citizens who are aware of the affordances of urban life. Defined as context-aware cyber-physical social systems, smart cities of the future are planned and managed with increasing awareness of the manifoldness of physical, experiential, and virtual life. The benefits of a cybernetic urban management could, for instance, be related to dynamic service network planning with a real-time view to service network efficiency. This in turn could lead to better services for citizens, resource efficiency, and better allocation of financial resources. Cybernetic management and smart city production necessitates a shared view of urban processes that is not dedicated only for the eyes of a few experts but is widely accessible and supports information exchange and dialogue among city authorities, decision-makers, and citizens. View Full-Text   Abstract
Value engineering (VE) and function analysis (FA) are technological tools for the functional enhancement and cost reduction of engineering projects. They also help to overcome mental inertia by acknowledging the voice of the customer in complicated systems. Antenna engineering, providing electromagnetic remote links, is an important area in engineering science, with a large number of innovative concepts. However, managing innovative ideas to improve performance, reliability, quality, safety, and reduce life cycle costs, is still a work in progress. This research was designed to apply VE and FA as frameworks for innovative ideas in antenna systems, especially with regard to imaging and radar systems. FA diagrams free a designers’ mind from tools to instead focus on purpose, which can help them to obtain better ideas for solutions to problems. It was identified that there were several options available for functionality enhancement and cost reduction. The required functionalities of the components of antenna systems, and their advantages and limitations were indicated. In addition, it was identified that some of the advantages and limitations appeared for combinations of the components. Alternative methods for applications, such as polarization conversion and the separation of outgoing and incoming electromagnetic waves, were studied. Circular polarization (CP) is important for two-way communication, since left-handed circularly polarized waves usually return with right-handed CP from targets. Therefore, various methods for producing CP were discussed, such as metamaterial-based linear to circular polarization converters and waveguide polarizers. Also, potential extra applications for these systems were explained. Two examples were: (1) merging multiple systems with different operating frequencies using multiband components; and (2) applying a feeding system for multiple reflectors using surfaces that reflect half of the wave and transmit the other half. Consequently, it was identified that the clearance of existing functions, prioritization of customers, identification of system bottlenecks requiring innovative methods, and better communication between users and designers, were the key benefits of VE and FA. View Full-Text   Abstract
Many researchers consider chronic fatigue syndrome (CFS) to be a synonym of Myalgic Encephalomyelitis (ME). However, the case criteria of ME and CFS define two distinct clinical entities. Although some patients will meet both case criteria, other patients can meet the diagnosis of ME and not fulfil the case criteria for CFS, while the diagnosis of CFS is largely insufficient to be qualified as a ME patient. ME is a neuromuscular disease with distinctive muscular symptoms, including prolonged muscle weakness after exertion, and neurological signs implicating cerebral dysfunction, including cognitive impairment and sensory symptoms. The only mandatory symptom of CFS is chronic fatigue. Chronic fatigue must be accompanied by at least four out of eight nonspecific symptoms: substantial impairment in short-term memory or concentration, a sore throat, tender lymph nodes, muscle pain, multijoint pain, a new type of headaches, unrefreshing sleep, and postexertional “malaise” lasting more than 24 h. So, regardless whether the name ME is appropriate or not, ME is not synonymous to CFS. That is not a matter of opinion, but a matter of definition. Due to the definitions of ME and CFS, “ME/CFS” does not exist and cannot be replaced by a new clinical entity (SEID: Systemic Exertion Intolerance Disease), as recently suggested.
View Full-Text   Abstract
This paper builds a link between isolated domains within the arts and sciences, specifically between music and psychiatry. An analogous model is presented that associates heavy metal music with bipolar disorder, a form of mental illness. Metal music consists of a variety of subgenres with distinct manifestations of song, rhythm, instrumentation, and vocal structure. These manifestations are analogous to the symptomatology of bipolar disorder, specifically the recurrent episodes of (hypo)mania and depression. Examples of songs are given which show these analogies. Besides creating a subjective link between apparently unconnected knowledge domains, these analogies could play a heuristic role in clinical applications and education about the disorder and mental illnesses at large. View Full-Text "," smart cities,urban planning and design,cybernetics,urban experiences,north   function analysis,value engineering,inventive design,antenna systems,antenna design   myalgic encephalomyelitis,chronic fatigue syndrome,systemic exertion intolerance disease,diagnosis,nosology,neurology,muscular disease   auditory arts,music,psychiatry,heavy metal music,mental illness,bipolar disorder,analogous model,heuristic,creative thinking "," Cybernetics and the 4D Smart City: Smartness as Awareness   Value Engineering and Function Analysis: Frameworks for Innovation in Antenna Systems   Myalgic Encephalomyelitis, Chronic Fatigue Syndrome, and Systemic Exertion Intolerance Disease: Three Distinct Clinical Entities   Analogies between Heavy Metal Music and the Symptoms of Mental Illness   Abstract
The complexity of urban challenges obliges us to seek smarter paths for urban development and increase our awareness of urban dynamics in a more holistic manner. Stemming from the discipline of architecture and urban planning, this concept paper outlines an idea of a cybernetic urban management for anticipatory governance of smart cities. A cybernetic system absorbs information from different sources, such as buildings that are aware of their energy efficiency, a city aware of its traffic flows, and citizens who are aware of the affordances of urban life. Defined as context-aware cyber-physical social systems, smart cities of the future are planned and managed with increasing awareness of the manifoldness of physical, experiential, and virtual life. The benefits of a cybernetic urban management could, for instance, be related to dynamic service network planning with a real-time view to service network efficiency. This in turn could lead to better services for citizens, resource efficiency, and better allocation of financial resources. Cybernetic management and smart city production necessitates a shared view of urban processes that is not dedicated only for the eyes of a few experts but is widely accessible and supports information exchange and dialogue among city authorities, decision-makers, and citizens. View Full-Text   Abstract
Value engineering (VE) and function analysis (FA) are technological tools for the functional enhancement and cost reduction of engineering projects. They also help to overcome mental inertia by acknowledging the voice of the customer in complicated systems. Antenna engineering, providing electromagnetic remote links, is an important area in engineering science, with a large number of innovative concepts. However, managing innovative ideas to improve performance, reliability, quality, safety, and reduce life cycle costs, is still a work in progress. This research was designed to apply VE and FA as frameworks for innovative ideas in antenna systems, especially with regard to imaging and radar systems. FA diagrams free a designers’ mind from tools to instead focus on purpose, which can help them to obtain better ideas for solutions to problems. It was identified that there were several options available for functionality enhancement and cost reduction. The required functionalities of the components of antenna systems, and their advantages and limitations were indicated. In addition, it was identified that some of the advantages and limitations appeared for combinations of the components. Alternative methods for applications, such as polarization conversion and the separation of outgoing and incoming electromagnetic waves, were studied. Circular polarization (CP) is important for two-way communication, since left-handed circularly polarized waves usually return with right-handed CP from targets. Therefore, various methods for producing CP were discussed, such as metamaterial-based linear to circular polarization converters and waveguide polarizers. Also, potential extra applications for these systems were explained. Two examples were: (1) merging multiple systems with different operating frequencies using multiband components; and (2) applying a feeding system for multiple reflectors using surfaces that reflect half of the wave and transmit the other half. Consequently, it was identified that the clearance of existing functions, prioritization of customers, identification of system bottlenecks requiring innovative methods, and better communication between users and designers, were the key benefits of VE and FA. View Full-Text   Abstract
Many researchers consider chronic fatigue syndrome (CFS) to be a synonym of Myalgic Encephalomyelitis (ME). However, the case criteria of ME and CFS define two distinct clinical entities. Although some patients will meet both case criteria, other patients can meet the diagnosis of ME and not fulfil the case criteria for CFS, while the diagnosis of CFS is largely insufficient to be qualified as a ME patient. ME is a neuromuscular disease with distinctive muscular symptoms, including prolonged muscle weakness after exertion, and neurological signs implicating cerebral dysfunction, including cognitive impairment and sensory symptoms. The only mandatory symptom of CFS is chronic fatigue. Chronic fatigue must be accompanied by at least four out of eight nonspecific symptoms: substantial impairment in short-term memory or concentration, a sore throat, tender lymph nodes, muscle pain, multijoint pain, a new type of headaches, unrefreshing sleep, and postexertional “malaise” lasting more than 24 h. So, regardless whether the name ME is appropriate or not, ME is not synonymous to CFS. That is not a matter of opinion, but a matter of definition. Due to the definitions of ME and CFS, “ME/CFS” does not exist and cannot be replaced by a new clinical entity (SEID: Systemic Exertion Intolerance Disease), as recently suggested.
View Full-Text   Abstract
This paper builds a link between isolated domains within the arts and sciences, specifically between music and psychiatry. An analogous model is presented that associates heavy metal music with bipolar disorder, a form of mental illness. Metal music consists of a variety of subgenres with distinct manifestations of song, rhythm, instrumentation, and vocal structure. These manifestations are analogous to the symptomatology of bipolar disorder, specifically the recurrent episodes of (hypo)mania and depression. Examples of songs are given which show these analogies. Besides creating a subjective link between apparently unconnected knowledge domains, these analogies could play a heuristic role in clinical applications and education about the disorder and mental illnesses at large. View Full-Text   smart cities,urban planning and design,cybernetics,urban experiences,north   function analysis,value engineering,inventive design,antenna systems,antenna design   myalgic encephalomyelitis,chronic fatigue syndrome,systemic exertion intolerance disease,diagnosis,nosology,neurology,muscular disease   auditory arts,music,psychiatry,heavy metal music,mental illness,bipolar disorder,analogous model,heuristic,creative thinking ", Challenges 
 Hardware Support for Security in the Internet of Things: From Lightweight Countermeasures to Accelerated Homomorphic Encryption   The Human Takeover: A Call for a Venture into an Existential Opportunity   Developing an Ontology-Based Rollover Monitoring and Decision Support System for Engineering Vehicles ," Abstract
In the Internet of Things (IoT), many strong constraints have to be considered when designing the connected objects, including low cost and low power, thus limited resources. The confidentiality and integrity of sensitive data must however be ensured even when they have to be processed in the cloud. Security is therefore one of the design constraints but must be achieved without the usual level of resources. In this paper, we address two very different examples showing how embedded hardware/software co-design can help in improving security in the IoT context. The first example targets so-called “hardware attacks” and we show how some simple attacks can be made much more difficult at very low cost. This is demonstrated on a crypto-processor designed for Elliptic Curve Cryptography (ECC). A very lightweight countermeasure is implemented against Simple Power Analysis (SPA), taking advantage of the general processor usually available in the system. The second example shows how confidentiality in the cloud can be guaranteed by homomorphic encryption at a lower computational cost by taking advantage of a hardware accelerator. The proposed accelerator is very easy to implement and can easily be tuned to several encryption schemes and several trade-offs between hardware costs and computation speed. View Full-Text   Abstract
We propose a venture into an existential opportunity for establishing a world ‘good enough’ for humans to live in. Defining an existential opportunity as the converse of an existential risk—that is, a development that promises to dramatically improve the future of humanity—we argue that one such opportunity is available and should be explored now. The opportunity resides in the moment of transition of the Internet—from mediating information to mediating distributed direct governance in the sense of self-organization. The Internet of tomorrow will mediate the execution of contracts, transactions, public interventions and all other change-establishing events more reliably and more synergistically than any other technology or institution. It will become a distributed, synthetically intelligent agent in itself. This transition must not be just observed, or exploited instrumentally: it must be ventured into and seized on behalf of entire humanity. We envision a configuration of three kinds of cognitive system—the human mind, social systems and the emerging synthetic intelligence—serving to augment the autonomy of the first from the ‘programming’ imposed by the second. Our proposition is grounded in a detailed analysis of the manner in which the socio-econo-political system has evolved into a powerful control mechanism that subsumes human minds, steers their will and automates their thinking. We see the venture into the existential opportunity described here as aiming at the global dissolution of the core reason of that programming’s effectiveness—the critical dependence of the continuity of human lives on the coherence of the socially constructed personas they ‘wear.’ Thus, we oppose the popular prediction of the upcoming, ‘dreadful AI takeover’ with a call for action: instead of worrying that Artificial Intelligence will soon come to dominate and govern the human world, let us think of how it could help the human being to finally be able to do it. View Full-Text   Abstract
The increasing number of rollover accidents of engineering vehicles has attracted close attention; however, most researchers focus on the analysis and monitoring of rollover stability indexes and seldom the assessment and decision support for the rollover risk of engineering vehicles. In this context, an ontology-based rollover monitoring and decision support system for engineering vehicles is proposed. The ontology model is built for representing monitored rollover stability data with semantic properties and for constructing semantic relevance among the various concepts involved in the rollover domain. On the basis of this, ontology querying and reasoning methods based on the Simple Protocol and RDF Query Language (SPARQL) and Semantic Web Rule Language (SWRL) rules are utilized to realize the rollover risk assessment and to obtain suggested measures. PC and mobile applications (APPs) have also been developed to implement the above methods. In addition, five sets of rollover stability data for an articulated off-road engineering vehicle under different working conditions were analyzed to verify the accuracy and effectiveness of the proposed system. View Full-Text "," IoT security,integrated circuits,hardware accelerators,crypto-processors,ECC encryption,homomorphic encryption,lightweight,SPA,countermeasure   governance,social systems,personware,communication,cognition,cognitive dissonance,symbolic order,human emancipation,Artificial Intelligence,good enough world,existential opportunity   ontology,engineering vehicles’ rollover,monitoring,decision support,assessment "," Hardware Support for Security in the Internet of Things: From Lightweight Countermeasures to Accelerated Homomorphic Encryption   The Human Takeover: A Call for a Venture into an Existential Opportunity   Developing an Ontology-Based Rollover Monitoring and Decision Support System for Engineering Vehicles   Abstract
In the Internet of Things (IoT), many strong constraints have to be considered when designing the connected objects, including low cost and low power, thus limited resources. The confidentiality and integrity of sensitive data must however be ensured even when they have to be processed in the cloud. Security is therefore one of the design constraints but must be achieved without the usual level of resources. In this paper, we address two very different examples showing how embedded hardware/software co-design can help in improving security in the IoT context. The first example targets so-called “hardware attacks” and we show how some simple attacks can be made much more difficult at very low cost. This is demonstrated on a crypto-processor designed for Elliptic Curve Cryptography (ECC). A very lightweight countermeasure is implemented against Simple Power Analysis (SPA), taking advantage of the general processor usually available in the system. The second example shows how confidentiality in the cloud can be guaranteed by homomorphic encryption at a lower computational cost by taking advantage of a hardware accelerator. The proposed accelerator is very easy to implement and can easily be tuned to several encryption schemes and several trade-offs between hardware costs and computation speed. View Full-Text   Abstract
We propose a venture into an existential opportunity for establishing a world ‘good enough’ for humans to live in. Defining an existential opportunity as the converse of an existential risk—that is, a development that promises to dramatically improve the future of humanity—we argue that one such opportunity is available and should be explored now. The opportunity resides in the moment of transition of the Internet—from mediating information to mediating distributed direct governance in the sense of self-organization. The Internet of tomorrow will mediate the execution of contracts, transactions, public interventions and all other change-establishing events more reliably and more synergistically than any other technology or institution. It will become a distributed, synthetically intelligent agent in itself. This transition must not be just observed, or exploited instrumentally: it must be ventured into and seized on behalf of entire humanity. We envision a configuration of three kinds of cognitive system—the human mind, social systems and the emerging synthetic intelligence—serving to augment the autonomy of the first from the ‘programming’ imposed by the second. Our proposition is grounded in a detailed analysis of the manner in which the socio-econo-political system has evolved into a powerful control mechanism that subsumes human minds, steers their will and automates their thinking. We see the venture into the existential opportunity described here as aiming at the global dissolution of the core reason of that programming’s effectiveness—the critical dependence of the continuity of human lives on the coherence of the socially constructed personas they ‘wear.’ Thus, we oppose the popular prediction of the upcoming, ‘dreadful AI takeover’ with a call for action: instead of worrying that Artificial Intelligence will soon come to dominate and govern the human world, let us think of how it could help the human being to finally be able to do it. View Full-Text   Abstract
The increasing number of rollover accidents of engineering vehicles has attracted close attention; however, most researchers focus on the analysis and monitoring of rollover stability indexes and seldom the assessment and decision support for the rollover risk of engineering vehicles. In this context, an ontology-based rollover monitoring and decision support system for engineering vehicles is proposed. The ontology model is built for representing monitored rollover stability data with semantic properties and for constructing semantic relevance among the various concepts involved in the rollover domain. On the basis of this, ontology querying and reasoning methods based on the Simple Protocol and RDF Query Language (SPARQL) and Semantic Web Rule Language (SWRL) rules are utilized to realize the rollover risk assessment and to obtain suggested measures. PC and mobile applications (APPs) have also been developed to implement the above methods. In addition, five sets of rollover stability data for an articulated off-road engineering vehicle under different working conditions were analyzed to verify the accuracy and effectiveness of the proposed system. View Full-Text   IoT security,integrated circuits,hardware accelerators,crypto-processors,ECC encryption,homomorphic encryption,lightweight,SPA,countermeasure   governance,social systems,personware,communication,cognition,cognitive dissonance,symbolic order,human emancipation,Artificial Intelligence,good enough world,existential opportunity   ontology,engineering vehicles’ rollover,monitoring,decision support,assessment ", Information 
 Shannon Entropy in Atoms: A Test for the Assessment of Density Functionals in Kohn-Sham Theory   Asymptotic Behavior of Exact Exchange for Slabs: Beyond the Leading Order   Aerodynamic Optimization of Airfoil Profiles for Small Horizontal Axis Wind Turbines   Modeling Confined Cell Migration Mediated by Cytoskeleton Dynamics ," Abstract
Electron density is used to compute Shannon entropy. The deviation from the Hartree–Fock (HF) of this quantity has been observed to be related to correlation energy. Thus, Shannon entropy is here proposed as a valid quantity to assess the quality of an energy density functional developed within Kohn–Sham theory. To this purpose, results from eight different functionals, representative of Jacob’s ladder, are compared with accurate results obtained from diffusion quantum Monte Carlo (DMC) computations. For three series of atomic ions, our results show that the revTPSS and the PBE0 functionals are the best, whereas those based on local density approximation give the largest discrepancy from DMC Shannon entropy. View Full-Text   Abstract
Far outside the surface of slabs, the exact exchange (EXX) potential
v
x
falls off as
−1/z
, if z denotes the direction perpendicular to the surface and the slab is localized around
z=0
. Similarly, the EXX energy density
e
x
behaves as
−n/(2z)
, where n is the electron density. Here, an alternative proof of these relations is given, in which the Coulomb singularity in the EXX energy is treated in a particularly careful fashion. This new approach allows the derivation of the next-to-leading order contributions to the asymptotic
v
x
and
e
x
. It turns out that in both cases, the corrections are proportional to
1/
z
2
in general. View Full-Text   Abstract
The purpose of this study is the development of an automated two-dimensional airfoil shape optimization procedure for small horizontal axis wind turbines (HAWT), with an emphasis on high thrust and aerodynamically stable performance. The procedure combines the Computational Fluid Dynamics (CFD) analysis with the Response Surface Methodology (RSM), the Biobjective Mesh Adaptive Direct Search (BiMADS) optimization algorithm and an automatic geometry and mesh generation tool. In CFD analysis, a Reynolds Averaged Numerical Simulation (RANS) is applied in combination with a two-equation turbulence model. For describing the system behaviour under alternating wind conditions, a number of CFD 2D-RANS-Simulations with varying Reynolds numbers and wind angles are performed. The number of cases is reduced by the use of RSM. In the analysis, an emphasis is placed upon the role of the blade-to-blade interaction. The average and the standard deviation of the thrust are optimized by a derivative-free optimization algorithm to define a Pareto optimal set, using the BiMADS algorithm. The results show that improvements in the performance can be achieved by modifications of the blade shape and the present procedure can be used as an effective tool for blade shape optimization. View Full-Text   Abstract
Cell migration is an important biological process that has generated increasing interest during the last several years. This process is based on three phases: protrusion at the front end of the cell, de-adhesion at the rear end and contraction of the cell body, all of them coordinated due to the polymerization/depolymerization of certain cytoskeletal proteins. The aim of this work is to present a mathematical model to simulate the actin polymerization/depolymerization process that regulates the final outcome of cell migration process, considering all the above phases, in a particular case: when the cell is confined in a microfluidic channel. Under these specific conditions, cell migration can be approximated by using one-dimensional simulations. We will propose a system of reaction–diffusion equations to simulate the behavior of the cytoskeletal proteins responsible for protrusion and contraction in the cell, coupled with the mechanical response of the cell, computing its deformations and stresses. Furthermore, a numerical procedure is presented in order to simulate the whole process in a moving and deformable domain corresponding to the cell body. View Full-Text "," Shannon entropy,density functional theory,Quantum Monte Carlo,electronic structure of atoms   density functional theory,exact exchange,slabs,asymptotic behavior   CFD,RSM,RANS,BiMADS,HAWT,wind turbine,airfoil,aerodynamics,optimization   cell migration,actin–myosin dynamics,reaction–diffusion equations,numerical simulation "," Shannon Entropy in Atoms: A Test for the Assessment of Density Functionals in Kohn-Sham Theory   Asymptotic Behavior of Exact Exchange for Slabs: Beyond the Leading Order   Aerodynamic Optimization of Airfoil Profiles for Small Horizontal Axis Wind Turbines   Modeling Confined Cell Migration Mediated by Cytoskeleton Dynamics   Abstract
Electron density is used to compute Shannon entropy. The deviation from the Hartree–Fock (HF) of this quantity has been observed to be related to correlation energy. Thus, Shannon entropy is here proposed as a valid quantity to assess the quality of an energy density functional developed within Kohn–Sham theory. To this purpose, results from eight different functionals, representative of Jacob’s ladder, are compared with accurate results obtained from diffusion quantum Monte Carlo (DMC) computations. For three series of atomic ions, our results show that the revTPSS and the PBE0 functionals are the best, whereas those based on local density approximation give the largest discrepancy from DMC Shannon entropy. View Full-Text   Abstract
Far outside the surface of slabs, the exact exchange (EXX) potential
v
x
falls off as
−1/z
, if z denotes the direction perpendicular to the surface and the slab is localized around
z=0
. Similarly, the EXX energy density
e
x
behaves as
−n/(2z)
, where n is the electron density. Here, an alternative proof of these relations is given, in which the Coulomb singularity in the EXX energy is treated in a particularly careful fashion. This new approach allows the derivation of the next-to-leading order contributions to the asymptotic
v
x
and
e
x
. It turns out that in both cases, the corrections are proportional to
1/
z
2
in general. View Full-Text   Abstract
The purpose of this study is the development of an automated two-dimensional airfoil shape optimization procedure for small horizontal axis wind turbines (HAWT), with an emphasis on high thrust and aerodynamically stable performance. The procedure combines the Computational Fluid Dynamics (CFD) analysis with the Response Surface Methodology (RSM), the Biobjective Mesh Adaptive Direct Search (BiMADS) optimization algorithm and an automatic geometry and mesh generation tool. In CFD analysis, a Reynolds Averaged Numerical Simulation (RANS) is applied in combination with a two-equation turbulence model. For describing the system behaviour under alternating wind conditions, a number of CFD 2D-RANS-Simulations with varying Reynolds numbers and wind angles are performed. The number of cases is reduced by the use of RSM. In the analysis, an emphasis is placed upon the role of the blade-to-blade interaction. The average and the standard deviation of the thrust are optimized by a derivative-free optimization algorithm to define a Pareto optimal set, using the BiMADS algorithm. The results show that improvements in the performance can be achieved by modifications of the blade shape and the present procedure can be used as an effective tool for blade shape optimization. View Full-Text   Abstract
Cell migration is an important biological process that has generated increasing interest during the last several years. This process is based on three phases: protrusion at the front end of the cell, de-adhesion at the rear end and contraction of the cell body, all of them coordinated due to the polymerization/depolymerization of certain cytoskeletal proteins. The aim of this work is to present a mathematical model to simulate the actin polymerization/depolymerization process that regulates the final outcome of cell migration process, considering all the above phases, in a particular case: when the cell is confined in a microfluidic channel. Under these specific conditions, cell migration can be approximated by using one-dimensional simulations. We will propose a system of reaction–diffusion equations to simulate the behavior of the cytoskeletal proteins responsible for protrusion and contraction in the cell, coupled with the mechanical response of the cell, computing its deformations and stresses. Furthermore, a numerical procedure is presented in order to simulate the whole process in a moving and deformable domain corresponding to the cell body. View Full-Text   Shannon entropy,density functional theory,Quantum Monte Carlo,electronic structure of atoms   density functional theory,exact exchange,slabs,asymptotic behavior   CFD,RSM,RANS,BiMADS,HAWT,wind turbine,airfoil,aerodynamics,optimization   cell migration,actin–myosin dynamics,reaction–diffusion equations,numerical simulation ", Computation 
" How to Think Rationally about World Problems   A Tempest in A Ladle: The Debate about the Roles of General and Specific Abilities in Predicting Important Outcomes   Individual Mental Abiities vs. the World’s Problems   The Strengths of Wisdom Provide Unique Contributions to Improved Leadership, Sustainability, Inequality, Gross National Happiness, and Civic Discourse in the Face of Contemporary World Problems "," Abstract
I agree with the target essay that psychology has something to offer in helping to address societal problems. Intelligence has helped meliorate some social problems throughout history, including the period of time that is covered by the Flynn effect, but I agree with Sternberg that other psychological characteristics may be contributing as well, particularly increases in rationality. I also believe that increasing human rationality could have a variety of positive societal affects at levels somewhat smaller in grain size than the societal problems that Sternberg focuses on. Some of the societal problems that Sternberg lists, however, I do not think would be remedied by increases in rationality, intelligence, or wisdom, because remedy might be the wrong word in the context of these issues. Issues such as how much inequality of income to tolerate, how much pollution to tolerate, and how much we should sacrifice economic growth for potential future changes in global temperature represent issues of clashing values, not the inability to process information, nor the lack of information, nor the failure to show wisdom. View Full-Text   Abstract
The debate about the roles of general and specific abilities in predicting important outcomes is a tempest in a ladle because we cannot measure abilities without also measuring skills. Skills always develop through exposure, are specific rather than general, and are executed using different strategies by different people, thus tapping into varied specific abilities. Relative predictive validities of measurement formats depend on the purpose: the more general and long-term the purpose, the better the more general measure. The more specific and immediate the purpose, the better the closely related specific measure. View Full-Text   Abstract
The major problems in the world today are problems of government or the lack of it. Thus, the relevant parts of intelligence are those that make for good citizenship, such as supporting the best candidates and policies. I argue that dispositions, as well as capacities, are part of intelligence, and that some dispositions are the ones most crucial for citizenship, particularly the disposition to engage in actively open-minded thinking (AOT) and to apply it as a standard for the evaluation of the qualifications of authorities and leaders. AOT is a general prescriptive theory that applies to all thinking. It affects the aptness of conclusions and the accuracy of confidence judgments, and it reduces overconfidence when extreme confidence is not warranted. AOT may be affected by different factors from those that affect other components of intelligence and thus may undergo different changes over time. Whatever has happened in the past, we need more of it now. View Full-Text   Abstract
We present evidence for the strengths of the intellectual virtues that philosophers and behavioral scientists characterize as key cognitive elements of wisdom. Wisdom has been of centuries-long interest for philosophical scholarship, but relative to intelligence largely neglected in public discourse on educational science, public policy, and societal well-being. Wise reasoning characteristics include intellectual humility, recognition of uncertainty, consideration of diverse viewpoints, and an attempt to integrate these viewpoints. Emerging scholarship on these features of wisdom suggest that they uniquely contribute to societal well-being, improve leadership, shed light on societal inequality, promote cooperation in Public Goods Games and reduce political polarization and intergroup-hostility. We review empirical evidence about macro-cultural, ecological, situational, and person-level processes facilitating and inhibiting wisdom in daily life. Based on this evidence, we speculate about ways to foster wisdom in education, organizations, and institutions. View Full-Text "," rationality,intelligence,world problems,meliorism   general cognitive ability,specific cognitive abilities,academic achievement,job performance,occupational attainment,health,longevity,situational specificity   Flynn effect,actively open-minded thinking,cognitive style,political judgment   wisdom,reasoning,virtues,well-being,political polarization,culture,social class,egocentrism,leadership "," How to Think Rationally about World Problems   A Tempest in A Ladle: The Debate about the Roles of General and Specific Abilities in Predicting Important Outcomes   Individual Mental Abiities vs. the World’s Problems   The Strengths of Wisdom Provide Unique Contributions to Improved Leadership, Sustainability, Inequality, Gross National Happiness, and Civic Discourse in the Face of Contemporary World Problems   Abstract
I agree with the target essay that psychology has something to offer in helping to address societal problems. Intelligence has helped meliorate some social problems throughout history, including the period of time that is covered by the Flynn effect, but I agree with Sternberg that other psychological characteristics may be contributing as well, particularly increases in rationality. I also believe that increasing human rationality could have a variety of positive societal affects at levels somewhat smaller in grain size than the societal problems that Sternberg focuses on. Some of the societal problems that Sternberg lists, however, I do not think would be remedied by increases in rationality, intelligence, or wisdom, because remedy might be the wrong word in the context of these issues. Issues such as how much inequality of income to tolerate, how much pollution to tolerate, and how much we should sacrifice economic growth for potential future changes in global temperature represent issues of clashing values, not the inability to process information, nor the lack of information, nor the failure to show wisdom. View Full-Text   Abstract
The debate about the roles of general and specific abilities in predicting important outcomes is a tempest in a ladle because we cannot measure abilities without also measuring skills. Skills always develop through exposure, are specific rather than general, and are executed using different strategies by different people, thus tapping into varied specific abilities. Relative predictive validities of measurement formats depend on the purpose: the more general and long-term the purpose, the better the more general measure. The more specific and immediate the purpose, the better the closely related specific measure. View Full-Text   Abstract
The major problems in the world today are problems of government or the lack of it. Thus, the relevant parts of intelligence are those that make for good citizenship, such as supporting the best candidates and policies. I argue that dispositions, as well as capacities, are part of intelligence, and that some dispositions are the ones most crucial for citizenship, particularly the disposition to engage in actively open-minded thinking (AOT) and to apply it as a standard for the evaluation of the qualifications of authorities and leaders. AOT is a general prescriptive theory that applies to all thinking. It affects the aptness of conclusions and the accuracy of confidence judgments, and it reduces overconfidence when extreme confidence is not warranted. AOT may be affected by different factors from those that affect other components of intelligence and thus may undergo different changes over time. Whatever has happened in the past, we need more of it now. View Full-Text   Abstract
We present evidence for the strengths of the intellectual virtues that philosophers and behavioral scientists characterize as key cognitive elements of wisdom. Wisdom has been of centuries-long interest for philosophical scholarship, but relative to intelligence largely neglected in public discourse on educational science, public policy, and societal well-being. Wise reasoning characteristics include intellectual humility, recognition of uncertainty, consideration of diverse viewpoints, and an attempt to integrate these viewpoints. Emerging scholarship on these features of wisdom suggest that they uniquely contribute to societal well-being, improve leadership, shed light on societal inequality, promote cooperation in Public Goods Games and reduce political polarization and intergroup-hostility. We review empirical evidence about macro-cultural, ecological, situational, and person-level processes facilitating and inhibiting wisdom in daily life. Based on this evidence, we speculate about ways to foster wisdom in education, organizations, and institutions. View Full-Text   rationality,intelligence,world problems,meliorism   general cognitive ability,specific cognitive abilities,academic achievement,job performance,occupational attainment,health,longevity,situational specificity   Flynn effect,actively open-minded thinking,cognitive style,political judgment   wisdom,reasoning,virtues,well-being,political polarization,culture,social class,egocentrism,leadership ", Journal of Intelligence 
 Synthesis and Characterization of Injectable Hydrogels with Varying Collagen–Chitosan–Thymosin β4 Composition for Myocardial Infarction Therapy   Poly-L-lactic Acid (PLLA)-Chitosan-Collagen Electrospun Tube for Vascular Graft Application   Nail Properties and Bone Health: A Review   Growing Neural PC-12 Cell on Crosslinked Silica Aerogels Increases Neurite Extension in the Presence of an Electric Field ," Abstract
Thirty percent of global mortalities are caused by cardiovascular disease, and 54% of the aforementioned amount is instigated by ischemic heart disease that triggered myocardial infarction. Myocardial infarction is due to blood flow cessation in certain coronary arteries that causes lack of oxygen (ischemia) and stimulates myocardial necrosis. One of the methods to treat myocardial infarction consists in injecting cells or active biomolecules and biomaterials into heart infarction locations. This study aimed to investigate the characteristics of a collagen–chitosan-based hydrogel with variations in its chitosan composition. The prepared hydrogels contained thymosin β4 (Tβ4), a 43-amino acid peptide with angiogenic and cardioprotective properties which can act as a bioactive molecule for the treatment of myocardial infarction. A morphological structure analysis showed that the hydrogels lacked interconnecting pores. All samples were not toxic on the basis of a cytotoxicity test. A histopathological anatomy test showed that the collagen–chitosan–thymosin β4 hydrogels could stimulate angiogenesis and epicardial heart cell migration, as demonstrated by the evaluation of the number of blood vessels and the infiltration extent of myofibroblasts. View Full-Text   Abstract
Poly-L-Lactic acid (PLLA) blended with chitosan and collagen was used to fabricate a conduit for blood vessel engineering through an electrospinning process. Various concentrations of chitosan were used in the blend in order to study its effect on the morphology, chemical bond, tensile strength, burst pressure, hemocompatibility, and cell viability (cytotoxicity) of the tube.In vitro assessments indicated that addition of chitosan-collagen could improve cell viability and hemocompatibility. Best results were demonstrated by the conduit with 10% PLLA, 0.5% chitosan, and 1% collagen. Tensile strength reached 2.13 MPa and burst pressure reached 2593 mmHg, both values that are within the range value of native blood vessel. A hemolysis percentage of 1.04% and a cell viability of 86.2% were obtained, meeting the standards of high hemocompatibility and low cytotoxicity for vascular graft material. The results are promising for further development toward vascular graft application. View Full-Text   Abstract
Physicochemical properties of nail may offer valuable insight into the health of bone. Currently, dual-energy X-ray absorptiometry (DXA) is the gold standard technique for evaluating bone health through bone mineral density (BMD). However, only 70% of fractures are explained by low BMD according to DXA. Therefore, the World Health Organisation recommended the need for the development of alternative methods of assessing bone health. Keratin and collagen type I are major proteins in nail and bone, respectively. Both of these proteins undergo post-translational modifications, with a possible correlation between the degree of post-translational modifications in keratin and collagen. Raman spectroscopy is a technique used to detect changes in protein composition and structure. As changes in protein function and structure may be associated with the development of osteoporosis, Raman spectroscopy may be a valuable adjunct to assess bone health and fracture risk. This review critically evaluates various methods and techniques to identify the link between nail properties and bone health. The strengths and limitations of various studies and the potential use of nail protein and minerals to evaluate bone health have been also presented. View Full-Text   Abstract
Externally applied electrical stimulation (ES) has been shown to enhance the nerve regeneration process and to influence the directionality of neurite outgrowth. In addition, the physical and chemical properties of the substrate used for nerve-cell regeneration is critical in fostering regeneration. Previously, we have shown that polyurea-crosslinked silica aerogels (PCSA) exert a positive influence on the extension of neurites by PC-12 cells, a cell-line model widely used to study neurite extension and electrical excitability. In this work, we have examined how an externally applied electric field (EF) influences the extension of neurites in PC-12 cells grown on two substrates: collagen-coated dishes versus collagen-coated crosslinked silica aerogels. The externally applied direct current (DC) bias was applied in vitro using a custom-designed chamber containing polydimethysiloxane (PDMS) embedded copper electrodes to create an electric field across the substrate for the cultured PC-12 cells. Results suggest orientation preference towards the anode, and, on average, longer neurites in the presence of the applied DC bias than with 0 V DC bias. In addition, neurite length was increased in cells grown on silica-crosslinked aerogel when compared to cells grown on regular petri-dishes. These results further support the notion that PCSA is a promising material for nerve regeneration. View Full-Text "," myocardial infarction,hydrogel,collagen,chitosan,thymosin β4   poly L-lactic acid,collagen,chitosan,electrospinning,tube,vascular graft   nail plate protein,collagen,nail mineral composition,bone mineral density,Raman spectroscopy   aerogel,porous,scaffold,substrate,PC-12,neuron,electrical stimulation,electric field,guidance "," Synthesis and Characterization of Injectable Hydrogels with Varying Collagen–Chitosan–Thymosin β4 Composition for Myocardial Infarction Therapy   Poly-L-lactic Acid (PLLA)-Chitosan-Collagen Electrospun Tube for Vascular Graft Application   Nail Properties and Bone Health: A Review   Growing Neural PC-12 Cell on Crosslinked Silica Aerogels Increases Neurite Extension in the Presence of an Electric Field   Abstract
Thirty percent of global mortalities are caused by cardiovascular disease, and 54% of the aforementioned amount is instigated by ischemic heart disease that triggered myocardial infarction. Myocardial infarction is due to blood flow cessation in certain coronary arteries that causes lack of oxygen (ischemia) and stimulates myocardial necrosis. One of the methods to treat myocardial infarction consists in injecting cells or active biomolecules and biomaterials into heart infarction locations. This study aimed to investigate the characteristics of a collagen–chitosan-based hydrogel with variations in its chitosan composition. The prepared hydrogels contained thymosin β4 (Tβ4), a 43-amino acid peptide with angiogenic and cardioprotective properties which can act as a bioactive molecule for the treatment of myocardial infarction. A morphological structure analysis showed that the hydrogels lacked interconnecting pores. All samples were not toxic on the basis of a cytotoxicity test. A histopathological anatomy test showed that the collagen–chitosan–thymosin β4 hydrogels could stimulate angiogenesis and epicardial heart cell migration, as demonstrated by the evaluation of the number of blood vessels and the infiltration extent of myofibroblasts. View Full-Text   Abstract
Poly-L-Lactic acid (PLLA) blended with chitosan and collagen was used to fabricate a conduit for blood vessel engineering through an electrospinning process. Various concentrations of chitosan were used in the blend in order to study its effect on the morphology, chemical bond, tensile strength, burst pressure, hemocompatibility, and cell viability (cytotoxicity) of the tube.In vitro assessments indicated that addition of chitosan-collagen could improve cell viability and hemocompatibility. Best results were demonstrated by the conduit with 10% PLLA, 0.5% chitosan, and 1% collagen. Tensile strength reached 2.13 MPa and burst pressure reached 2593 mmHg, both values that are within the range value of native blood vessel. A hemolysis percentage of 1.04% and a cell viability of 86.2% were obtained, meeting the standards of high hemocompatibility and low cytotoxicity for vascular graft material. The results are promising for further development toward vascular graft application. View Full-Text   Abstract
Physicochemical properties of nail may offer valuable insight into the health of bone. Currently, dual-energy X-ray absorptiometry (DXA) is the gold standard technique for evaluating bone health through bone mineral density (BMD). However, only 70% of fractures are explained by low BMD according to DXA. Therefore, the World Health Organisation recommended the need for the development of alternative methods of assessing bone health. Keratin and collagen type I are major proteins in nail and bone, respectively. Both of these proteins undergo post-translational modifications, with a possible correlation between the degree of post-translational modifications in keratin and collagen. Raman spectroscopy is a technique used to detect changes in protein composition and structure. As changes in protein function and structure may be associated with the development of osteoporosis, Raman spectroscopy may be a valuable adjunct to assess bone health and fracture risk. This review critically evaluates various methods and techniques to identify the link between nail properties and bone health. The strengths and limitations of various studies and the potential use of nail protein and minerals to evaluate bone health have been also presented. View Full-Text   Abstract
Externally applied electrical stimulation (ES) has been shown to enhance the nerve regeneration process and to influence the directionality of neurite outgrowth. In addition, the physical and chemical properties of the substrate used for nerve-cell regeneration is critical in fostering regeneration. Previously, we have shown that polyurea-crosslinked silica aerogels (PCSA) exert a positive influence on the extension of neurites by PC-12 cells, a cell-line model widely used to study neurite extension and electrical excitability. In this work, we have examined how an externally applied electric field (EF) influences the extension of neurites in PC-12 cells grown on two substrates: collagen-coated dishes versus collagen-coated crosslinked silica aerogels. The externally applied direct current (DC) bias was applied in vitro using a custom-designed chamber containing polydimethysiloxane (PDMS) embedded copper electrodes to create an electric field across the substrate for the cultured PC-12 cells. Results suggest orientation preference towards the anode, and, on average, longer neurites in the presence of the applied DC bias than with 0 V DC bias. In addition, neurite length was increased in cells grown on silica-crosslinked aerogel when compared to cells grown on regular petri-dishes. These results further support the notion that PCSA is a promising material for nerve regeneration. View Full-Text   myocardial infarction,hydrogel,collagen,chitosan,thymosin β4   poly L-lactic acid,collagen,chitosan,electrospinning,tube,vascular graft   nail plate protein,collagen,nail mineral composition,bone mineral density,Raman spectroscopy   aerogel,porous,scaffold,substrate,PC-12,neuron,electrical stimulation,electric field,guidance ", Journal of Functional Biomaterials 
 Sensor Access to the Cellular Microenvironment Using the Sensing Cell Culture Flask   Continuous Glucose Monitoring in Resource-Constrained Settings for Hypoglycaemia Detection: Looking at the Problem from the Other Side of the Coin   Laser Scribed Graphene Biosensor for Detection of Biogenic Amines in Food Samples Using Locally Sourced Materials   Olfactory Dysfunction as a Global Biomarker for Sniffing out Alzheimer’s Disease: A Meta-Analysis ," Abstract
The Sensing Cell Culture Flask (SCCF) is a cell culture monitoring system accessing the cellular microenvironment in 2D cell culture using electrochemical microsensors. The system is based on microfabricated sensor chips embedded in standard cell culture flasks. Ideally, the sensor chips could be equipped with any electrochemical sensor. Its transparency allows optical inspection of the cells during measurement. The surface of the sensor chip is in-plane with the flask surface allowing undisturbed cell growth on the sensor chip. A custom developed rack system allows easy usage of multiple flasks in parallel within an incubator. The presented data demonstrates the application of the SCCF with brain tumor (T98G) and breast cancer (T-47D) cells. Amperometric oxygen sensors were used to monitor cellular respiration with different incubation conditions. Cellular acidification was accessed with potentiometric pH sensors using electrodeposited iridium oxide films. The system itself provides the foundation for electrochemical monitoring systems in 3D cell culture. View Full-Text   Abstract
The appearance, over a decade ago, of continuous glucose monitoring (CGM) devices has triggered a patient-centred revolution in the control and management of diabetes mellitus and other metabolic conditions, improving the patient’s glycaemic control and quality of life. Such devices, the use of which remains typically restricted to high-income countries on account of their elevated costs, at present show very limited implantation in resource-constrained settings, where many other urgent health priorities beyond diabetes prevention and management still need to be resolved. In this commentary, we argue that such devices could have an additional utility in low-income settings, whereby they could be selectively used among severely ill children admitted to hospital for closer monitoring of paediatric hypoglycaemia, a life-threatening condition often complicating severe cases of malaria, malnutrition, and other common paediatric conditions. View Full-Text   Abstract
In foods, high levels of biogenic amines (BA) are the result of microbial metabolism that could be affected by temperatures and storage conditions. Thus, the level of BA is commonly used as an indicator of food safety and quality. This manuscript outlines the development of laser scribed graphene electrodes, with locally sourced materials, for reagent-free food safety biosensing. To fabricate the biosensors, the graphene surface was functionalized with copper microparticles and diamine oxidase, purchased from a local supermarket; and then compared to biosensors fabricated with analytical grade materials. The amperometric biosensor exhibits good electrochemical performance, with an average histamine sensitivity of 23.3 µA/mM, a lower detection limit of 11.6 µM, and a response time of 7.3 s, showing similar performance to biosensors constructed from analytical grade materials. We demonstrated the application of the biosensor by testing total BA concentration in fish paste samples subjected to fermentation with lactic acid bacteria. Biogenic amines concentrations prior to lactic acid fermentation were below the detection limit of the biosensor, while concentration after fermentation was 19.24 ± 8.21 mg histamine/kg, confirming that the sensor was selective in a complex food matrix. The low-cost, rapid, and accurate device is a promising tool for biogenic amine estimation in food samples, particularly in situations where standard laboratory techniques are unavailable, or are cost prohibitive. This biosensor can be used for screening food samples, potentially limiting food waste, while reducing chances of foodborne outbreaks. View Full-Text   Abstract
Cases of Alzheimer’s disease (AD) are rising exponentially due to increasing global life expectancy. There are approximately 50 million sufferers worldwide, with prevalence rising most rapidly in low-income countries such as Africa and Asia. There is currently no definite diagnosis of AD until after death, thus an early biomarker for AD is urgently required in order to administer timelier and more effective interventions. Olfactory dysfunction (problems with the sense of smell) is one of the earliest, preclinical symptoms observed in AD. Olfaction is a promising early biomarker for use worldwide as it is easy, cheap to measure, and not reliant on specialist clinicians or laboratory analysis. We carried out a meta-analysis to determine the credibility of olfaction in diagnosing AD in the preclinical stages, by comparing olfaction in healthy controls against AD patients and patients with mild cognitive impairment (MCI). Data from 10 articles were subjected to two comparative meta-analyses. In the case of AD, the results illustrated that the overall magnitude of effect size was more apparent, d = −1.63, 95% CI [−1.95, −1.31], in comparison to that of MCI, d = −0.81, 95% CI [−1.08, −0.55]. This shows that olfaction worsens progressively as patients progress from MCI to AD, highlighting the potential for olfactory dysfunction to identify AD in the preclinical stages prior to MCI. View Full-Text "," cell culture monitoring,microsensor,oxygen,pH,hypoxia   continuous glucose monitoring,hypoglycaemia,low-income countries   biogenic amines,laser scribed graphene,diamine oxidase,disposable sensor,food quality,risk assessment,planetary health   Alzheimer’s disease (AD),mild cognitive impairment (MCI),biomarker,dementia,olfactory dysfunction,olfaction,smell "," Sensor Access to the Cellular Microenvironment Using the Sensing Cell Culture Flask   Continuous Glucose Monitoring in Resource-Constrained Settings for Hypoglycaemia Detection: Looking at the Problem from the Other Side of the Coin   Laser Scribed Graphene Biosensor for Detection of Biogenic Amines in Food Samples Using Locally Sourced Materials   Olfactory Dysfunction as a Global Biomarker for Sniffing out Alzheimer’s Disease: A Meta-Analysis   Abstract
The Sensing Cell Culture Flask (SCCF) is a cell culture monitoring system accessing the cellular microenvironment in 2D cell culture using electrochemical microsensors. The system is based on microfabricated sensor chips embedded in standard cell culture flasks. Ideally, the sensor chips could be equipped with any electrochemical sensor. Its transparency allows optical inspection of the cells during measurement. The surface of the sensor chip is in-plane with the flask surface allowing undisturbed cell growth on the sensor chip. A custom developed rack system allows easy usage of multiple flasks in parallel within an incubator. The presented data demonstrates the application of the SCCF with brain tumor (T98G) and breast cancer (T-47D) cells. Amperometric oxygen sensors were used to monitor cellular respiration with different incubation conditions. Cellular acidification was accessed with potentiometric pH sensors using electrodeposited iridium oxide films. The system itself provides the foundation for electrochemical monitoring systems in 3D cell culture. View Full-Text   Abstract
The appearance, over a decade ago, of continuous glucose monitoring (CGM) devices has triggered a patient-centred revolution in the control and management of diabetes mellitus and other metabolic conditions, improving the patient’s glycaemic control and quality of life. Such devices, the use of which remains typically restricted to high-income countries on account of their elevated costs, at present show very limited implantation in resource-constrained settings, where many other urgent health priorities beyond diabetes prevention and management still need to be resolved. In this commentary, we argue that such devices could have an additional utility in low-income settings, whereby they could be selectively used among severely ill children admitted to hospital for closer monitoring of paediatric hypoglycaemia, a life-threatening condition often complicating severe cases of malaria, malnutrition, and other common paediatric conditions. View Full-Text   Abstract
In foods, high levels of biogenic amines (BA) are the result of microbial metabolism that could be affected by temperatures and storage conditions. Thus, the level of BA is commonly used as an indicator of food safety and quality. This manuscript outlines the development of laser scribed graphene electrodes, with locally sourced materials, for reagent-free food safety biosensing. To fabricate the biosensors, the graphene surface was functionalized with copper microparticles and diamine oxidase, purchased from a local supermarket; and then compared to biosensors fabricated with analytical grade materials. The amperometric biosensor exhibits good electrochemical performance, with an average histamine sensitivity of 23.3 µA/mM, a lower detection limit of 11.6 µM, and a response time of 7.3 s, showing similar performance to biosensors constructed from analytical grade materials. We demonstrated the application of the biosensor by testing total BA concentration in fish paste samples subjected to fermentation with lactic acid bacteria. Biogenic amines concentrations prior to lactic acid fermentation were below the detection limit of the biosensor, while concentration after fermentation was 19.24 ± 8.21 mg histamine/kg, confirming that the sensor was selective in a complex food matrix. The low-cost, rapid, and accurate device is a promising tool for biogenic amine estimation in food samples, particularly in situations where standard laboratory techniques are unavailable, or are cost prohibitive. This biosensor can be used for screening food samples, potentially limiting food waste, while reducing chances of foodborne outbreaks. View Full-Text   Abstract
Cases of Alzheimer’s disease (AD) are rising exponentially due to increasing global life expectancy. There are approximately 50 million sufferers worldwide, with prevalence rising most rapidly in low-income countries such as Africa and Asia. There is currently no definite diagnosis of AD until after death, thus an early biomarker for AD is urgently required in order to administer timelier and more effective interventions. Olfactory dysfunction (problems with the sense of smell) is one of the earliest, preclinical symptoms observed in AD. Olfaction is a promising early biomarker for use worldwide as it is easy, cheap to measure, and not reliant on specialist clinicians or laboratory analysis. We carried out a meta-analysis to determine the credibility of olfaction in diagnosing AD in the preclinical stages, by comparing olfaction in healthy controls against AD patients and patients with mild cognitive impairment (MCI). Data from 10 articles were subjected to two comparative meta-analyses. In the case of AD, the results illustrated that the overall magnitude of effect size was more apparent, d = −1.63, 95% CI [−1.95, −1.31], in comparison to that of MCI, d = −0.81, 95% CI [−1.08, −0.55]. This shows that olfaction worsens progressively as patients progress from MCI to AD, highlighting the potential for olfactory dysfunction to identify AD in the preclinical stages prior to MCI. View Full-Text   cell culture monitoring,microsensor,oxygen,pH,hypoxia   continuous glucose monitoring,hypoglycaemia,low-income countries   biogenic amines,laser scribed graphene,diamine oxidase,disposable sensor,food quality,risk assessment,planetary health   Alzheimer’s disease (AD),mild cognitive impairment (MCI),biomarker,dementia,olfactory dysfunction,olfaction,smell ", Biosensors 
 Unraveling Nutritional Regulation of Tacrolimus Biosynthesis in Streptomyces tsukubaensis through omic Approaches   Antibiotic Prescribing for Oro-Facial Infections in the Paediatric Outpatient: A Review   Comparison of Staphylococcus Phage K with Close Phage Relatives Commonly Employed in Phage Therapeutics   Specificity of Induction of Glycopeptide Antibiotic Resistance in the Producing Actinomycetes ," Abstract
Streptomyces tsukubaensis stands out among actinomycetes by its ability to produce the immunosuppressant tacrolimus. Discovered about 30 years ago, this macrolide is widely used as immunosuppressant in current clinics. Other potential applications for the treatment of cancer and as neuroprotective agent have been proposed in the last years. In this review we introduce the discovery of S. tsukubaensis and tacrolimus, its biosynthetic pathway and gene cluster (fkb) regulation. We have focused this work on the omic studies performed in this species in order to understand tacrolimus production. Transcriptomics, proteomics and metabolomics have improved our knowledge about the fkb transcriptional regulation and have given important clues about nutritional regulation of tacrolimus production that can be applied to improve production yields. Finally, we address some points of S. tsukubaensis biology that deserve more attention. View Full-Text   Abstract
There are many reports on the complications associated with antibiotics abuse during the treatment of paediatric patients, particularly those related to antimicrobial resistance. The dental profession is no exception; there is growing evidence that dental practitioners are misusing antibiotics in the treatment of their paediatric patients. This review is directed to dental practitioners who provide oral healthcare to children. It is also directed to medical practitioners, particularly those working in emergency departments and encountering children with acute orofacial infections. A systematic search of literature was conducted to explore the clinical indications and recommended antibiotic regimens for orofacial infections in paediatric outpatients. The main indications included cellulitis, aggressive periodontitis, necrotizing ulcerative gingivitis, and pericoronitis. Amoxicillin was found to be the most commonly recommended antibiotic for short durations of 3–5 days, with metronidazole or azithromycin being the alternative antibiotics in penicillin-sensitive patients. View Full-Text   Abstract
The increase in antibiotic resistance in pathogenic bacteria is a public health danger requiring alternative treatment options, and this has led to renewed interest in phage therapy. In this respect, we describe the distinct host ranges of Staphylococcus phage K, and two other K-like phages against 23 isolates, including 21 methicillin-resistant S. aureus (MRSA) representative sequence types representing the Irish National MRSA Reference Laboratory collection. The two K-like phages were isolated from the Fersisi therapeutic phage mix from the Tbilisi Eliava Institute, and were designated B1 (vB_SauM_B1) and JA1 (vB_SauM_JA1). The sequence relatedness of B1 and JA1 to phage K was observed to be 95% and 94% respectively. In terms of host range on the 23 Staphylococcus isolates, B1 and JA1 infected 73.9% and 78.2% respectively, whereas K infected only 43.5%. Eleven open reading frames (ORFs) present in both phages B1 and JA1 but absent in phage K were identified by comparative genomic analysis. These ORFs were also found to be present in the genomes of phages (Team 1, vB_SauM-fRuSau02, Sb_1 and ISP) that are components of several commercial phage mixtures with reported wide host ranges. This is the first comparative study of therapeutic staphylococcal phages within the recently described genus Kayvirus. View Full-Text   Abstract
Glycopeptide antibiotics are drugs of last resort for treating severe infections caused by Gram-positive pathogens. It is widely believed that glycopeptide-resistance determinants (van genes) are ultimately derived from the producing actinomycetes. We hereby investigated the relationship between the antimicrobial activity of vancomycin and teicoplanins and their differential ability to induce van gene expression in Actinoplanes teichomyceticus—the producer of teicoplanin—and Nonomuraea gerenzanensis—the producer of the teicoplanin-like A40926. As a control, we used the well-characterized resistance model Streptomyces coelicolor. The enzyme activities of a cytoplasmic-soluble d,d-dipeptidase and of a membrane-associated d,d-carboxypeptidase (corresponding to VanX and VanY respectively) involved in resistant cell wall remodeling were measured in the actinomycetes grown in the presence or absence of subinhibitory concentrations of vancomycin, teicoplanin, and A40926. Results indicated that actinomycetes possess diverse self-resistance mechanisms, and that each of them responds differently to glycopeptide induction. Gene swapping among teicoplanins-producing actinomycetes indicated that cross-talking is possible and provides useful information for predicting the evolution of future resistance gene combinations emerging in pathogens. View Full-Text "," Streptomyces tsukubaensis,tacrolimus,FK506,omics   antibiotics,prescribing,paediatric,orofacial infections,antimicrobial resistance   phage isolation,bacteriophage,phage resistance,MRSA,Staphylococcus,Kayvirus   actinomycetes,glycopeptide antibiotics,teicoplanin,A40926,van resistance genes "," Unraveling Nutritional Regulation of Tacrolimus Biosynthesis in Streptomyces tsukubaensis through omic Approaches   Antibiotic Prescribing for Oro-Facial Infections in the Paediatric Outpatient: A Review   Comparison of Staphylococcus Phage K with Close Phage Relatives Commonly Employed in Phage Therapeutics   Specificity of Induction of Glycopeptide Antibiotic Resistance in the Producing Actinomycetes   Abstract
Streptomyces tsukubaensis stands out among actinomycetes by its ability to produce the immunosuppressant tacrolimus. Discovered about 30 years ago, this macrolide is widely used as immunosuppressant in current clinics. Other potential applications for the treatment of cancer and as neuroprotective agent have been proposed in the last years. In this review we introduce the discovery of S. tsukubaensis and tacrolimus, its biosynthetic pathway and gene cluster (fkb) regulation. We have focused this work on the omic studies performed in this species in order to understand tacrolimus production. Transcriptomics, proteomics and metabolomics have improved our knowledge about the fkb transcriptional regulation and have given important clues about nutritional regulation of tacrolimus production that can be applied to improve production yields. Finally, we address some points of S. tsukubaensis biology that deserve more attention. View Full-Text   Abstract
There are many reports on the complications associated with antibiotics abuse during the treatment of paediatric patients, particularly those related to antimicrobial resistance. The dental profession is no exception; there is growing evidence that dental practitioners are misusing antibiotics in the treatment of their paediatric patients. This review is directed to dental practitioners who provide oral healthcare to children. It is also directed to medical practitioners, particularly those working in emergency departments and encountering children with acute orofacial infections. A systematic search of literature was conducted to explore the clinical indications and recommended antibiotic regimens for orofacial infections in paediatric outpatients. The main indications included cellulitis, aggressive periodontitis, necrotizing ulcerative gingivitis, and pericoronitis. Amoxicillin was found to be the most commonly recommended antibiotic for short durations of 3–5 days, with metronidazole or azithromycin being the alternative antibiotics in penicillin-sensitive patients. View Full-Text   Abstract
The increase in antibiotic resistance in pathogenic bacteria is a public health danger requiring alternative treatment options, and this has led to renewed interest in phage therapy. In this respect, we describe the distinct host ranges of Staphylococcus phage K, and two other K-like phages against 23 isolates, including 21 methicillin-resistant S. aureus (MRSA) representative sequence types representing the Irish National MRSA Reference Laboratory collection. The two K-like phages were isolated from the Fersisi therapeutic phage mix from the Tbilisi Eliava Institute, and were designated B1 (vB_SauM_B1) and JA1 (vB_SauM_JA1). The sequence relatedness of B1 and JA1 to phage K was observed to be 95% and 94% respectively. In terms of host range on the 23 Staphylococcus isolates, B1 and JA1 infected 73.9% and 78.2% respectively, whereas K infected only 43.5%. Eleven open reading frames (ORFs) present in both phages B1 and JA1 but absent in phage K were identified by comparative genomic analysis. These ORFs were also found to be present in the genomes of phages (Team 1, vB_SauM-fRuSau02, Sb_1 and ISP) that are components of several commercial phage mixtures with reported wide host ranges. This is the first comparative study of therapeutic staphylococcal phages within the recently described genus Kayvirus. View Full-Text   Abstract
Glycopeptide antibiotics are drugs of last resort for treating severe infections caused by Gram-positive pathogens. It is widely believed that glycopeptide-resistance determinants (van genes) are ultimately derived from the producing actinomycetes. We hereby investigated the relationship between the antimicrobial activity of vancomycin and teicoplanins and their differential ability to induce van gene expression in Actinoplanes teichomyceticus—the producer of teicoplanin—and Nonomuraea gerenzanensis—the producer of the teicoplanin-like A40926. As a control, we used the well-characterized resistance model Streptomyces coelicolor. The enzyme activities of a cytoplasmic-soluble d,d-dipeptidase and of a membrane-associated d,d-carboxypeptidase (corresponding to VanX and VanY respectively) involved in resistant cell wall remodeling were measured in the actinomycetes grown in the presence or absence of subinhibitory concentrations of vancomycin, teicoplanin, and A40926. Results indicated that actinomycetes possess diverse self-resistance mechanisms, and that each of them responds differently to glycopeptide induction. Gene swapping among teicoplanins-producing actinomycetes indicated that cross-talking is possible and provides useful information for predicting the evolution of future resistance gene combinations emerging in pathogens. View Full-Text   Streptomyces tsukubaensis,tacrolimus,FK506,omics   antibiotics,prescribing,paediatric,orofacial infections,antimicrobial resistance   phage isolation,bacteriophage,phage resistance,MRSA,Staphylococcus,Kayvirus   actinomycetes,glycopeptide antibiotics,teicoplanin,A40926,van resistance genes ", Antibiotics 
" The Double-Aspect of Life   Sediment Carbon Accumulation in Southern Latitude Saltmarsh Communities of Tasmania, Australia   Electrochemical Characterisation of Bio-Bottle-Voltaic (BBV) Systems Operated with Algae and Built with Recycled Materials   Characterization of Chlorella sorokiniana, UTEX 1230 "," Abstract
Life is based on two aspects: matter and a non-material, electrical component. In a dynamic system of reciprocal causality, matter and the so-called bioelectricity interact with one another, forming a functional unity. The aim of this essay is to summarize evidence for bioelectricity, for the sensitivity of biosystems to external physical factors and for the interactions of internal bioelectricity with internal biochemical structures. I propose non-material information of bioelectrical states to be just as inheritable from generation to generation as is the material genetic code. View Full-Text   Abstract
Carbon sequestration values of wetlands are greatest in their sediments. Northern hemisphere research dominates the earlier saltmarsh carbon sequestration literature, recently augmented by analyses across mainland Australia where species assemblages, catchment histories and environmental settings differ. No previous assessment has been made for Tasmania. Carbon stores and accumulation rates in saltmarsh sediments of the Rubicon estuary, Tasmania, were investigated. Carbon was determined from sediment cores by Elemental Analyser, combined with analysis of organic content and bulk density. Carbon accumulation was determined using short-term and long-term sediment accretion indicators. Results showed carbon densities to be lower than global averages, with variation found between carbon stores of native and introduced species zones. Cores from introduced Spartina anglica indicated a trend of higher sediment carbon percentages relative to cores from native saltmarsh Juncus kraussii and Sarcocornia quinqueflora, and in finer grain sizes. Sediment carbon stock of 30 cm depths was 49.5 Mg C ha−1 for native saltmarsh and 55.5 Mg C ha−1 for Spartina. Carbon percentages were low owing to high catchment inorganic sediment yields, however carbon accumulation rates were similar to global averages, particularly under Spartina. Covering 85% of saltmarsh area in the estuary, Spartina contributes the majority to carbon stores, potentially indicating a previously unrecognized value for this invasive species in Australia. View Full-Text   Abstract
Photobioelectrochemical systems are an emerging possibility for renewable energy. By exploiting photosynthesis, they transform the energy of light into electricity. This study evaluates a simple, scalable bioelectrochemical system built from recycled plastic bottles, equipped with an anode made from recycled aluminum, and operated with the green alga Chlorella sorokiniana. We tested whether such a system, referred to as a bio-bottle-voltaic (BBV) device, could operate outdoors for a prolonged time period of 35 days. Electrochemical characterisation was conducted by measuring the drop in potential between the anode and the cathode, and this value was used to calculate the rate of charge accumulation. The BBV systems were initially able to deliver ~500 mC·bottle−1·day−1, which increased throughout the experimental run to a maximum of ~2000 mC·bottle−1·day−1. The electrical output was consistently and significantly higher than that of the abiotic BBV system operated without algal cells (~100 mC·bottle−1·day−1). The analysis of the rate of algal biomass accumulation supported the hypothesis that harvesting a proportion of electrons from the algal cells does not significantly perturb the rate of algal growth. Our finding demonstrates that bioelectrochemical systems can be built using recycled components. Prototypes of these systems have been displayed in public events; they could serve as educational toolkits in schools and could also offer a solution for powering low-energy devices off-grid. View Full-Text   Abstract
This paper characterizes the strain Chlorella sorokiniana UTEX 1230 within a laboratory setting using a 1 L bubble column. The findings show that productivity can be trebled under mixotrophic conditions (from 0.2 g·L−1·d−1 to 0.66 g·L−1·d−1) with the addition of sodium acetate. The results also indicate that both the growth rate and final yield increase with the cultivation temperature, with most parameters showing an optimum in the range of 30–35 °C. The maximum specific growth rate was found to be in the region of 0.12 h−1 at a surface irradiance between 100–500 µE·m−2·s−1. This high growth rate makes the strain particularly suited to the rapid production of biomass, suitable for either whole cell bioprocessing or bioremediation. However, the relatively low lipid productivity (9.2 mg·L−1·d−1) confirms previous findings which would indicate poor applicability for biodiesel production. The strain shows greater promise in wastewater treatment applications with removal rates of nitrogen and phosphorus in the region of 37 and 30 mg·L−1·d−1 respectively. Furthermore, the findings show that a fed-batch strategy to inorganic nutrient loading can increase the final yield by around 50% compared to a conventional batch run. This is particularly interesting as fed-batch production techniques are rarely used within microalgal cultivation, so provide an interesting avenue for further investigation. Overall, the findings show that C. sorokiniana UTEX 1230 is a robust and fast-growing microalgal strain suitable both for the laboratory and scale-up. View Full-Text "," electrostatic fields,electrodynamic fields,bioelectricity,ecology,evolution   saltmarsh,sediment carbon,wetland,accumulation rates,Spartina,pollen analysis   algae,bioelectrochemistry,renewable energy,recycled materials   Chlorella sorokiniana,UTEX1230,productivity,yield,characterization "," The Double-Aspect of Life   Sediment Carbon Accumulation in Southern Latitude Saltmarsh Communities of Tasmania, Australia   Electrochemical Characterisation of Bio-Bottle-Voltaic (BBV) Systems Operated with Algae and Built with Recycled Materials   Characterization of Chlorella sorokiniana, UTEX 1230   Abstract
Life is based on two aspects: matter and a non-material, electrical component. In a dynamic system of reciprocal causality, matter and the so-called bioelectricity interact with one another, forming a functional unity. The aim of this essay is to summarize evidence for bioelectricity, for the sensitivity of biosystems to external physical factors and for the interactions of internal bioelectricity with internal biochemical structures. I propose non-material information of bioelectrical states to be just as inheritable from generation to generation as is the material genetic code. View Full-Text   Abstract
Carbon sequestration values of wetlands are greatest in their sediments. Northern hemisphere research dominates the earlier saltmarsh carbon sequestration literature, recently augmented by analyses across mainland Australia where species assemblages, catchment histories and environmental settings differ. No previous assessment has been made for Tasmania. Carbon stores and accumulation rates in saltmarsh sediments of the Rubicon estuary, Tasmania, were investigated. Carbon was determined from sediment cores by Elemental Analyser, combined with analysis of organic content and bulk density. Carbon accumulation was determined using short-term and long-term sediment accretion indicators. Results showed carbon densities to be lower than global averages, with variation found between carbon stores of native and introduced species zones. Cores from introduced Spartina anglica indicated a trend of higher sediment carbon percentages relative to cores from native saltmarsh Juncus kraussii and Sarcocornia quinqueflora, and in finer grain sizes. Sediment carbon stock of 30 cm depths was 49.5 Mg C ha−1 for native saltmarsh and 55.5 Mg C ha−1 for Spartina. Carbon percentages were low owing to high catchment inorganic sediment yields, however carbon accumulation rates were similar to global averages, particularly under Spartina. Covering 85% of saltmarsh area in the estuary, Spartina contributes the majority to carbon stores, potentially indicating a previously unrecognized value for this invasive species in Australia. View Full-Text   Abstract
Photobioelectrochemical systems are an emerging possibility for renewable energy. By exploiting photosynthesis, they transform the energy of light into electricity. This study evaluates a simple, scalable bioelectrochemical system built from recycled plastic bottles, equipped with an anode made from recycled aluminum, and operated with the green alga Chlorella sorokiniana. We tested whether such a system, referred to as a bio-bottle-voltaic (BBV) device, could operate outdoors for a prolonged time period of 35 days. Electrochemical characterisation was conducted by measuring the drop in potential between the anode and the cathode, and this value was used to calculate the rate of charge accumulation. The BBV systems were initially able to deliver ~500 mC·bottle−1·day−1, which increased throughout the experimental run to a maximum of ~2000 mC·bottle−1·day−1. The electrical output was consistently and significantly higher than that of the abiotic BBV system operated without algal cells (~100 mC·bottle−1·day−1). The analysis of the rate of algal biomass accumulation supported the hypothesis that harvesting a proportion of electrons from the algal cells does not significantly perturb the rate of algal growth. Our finding demonstrates that bioelectrochemical systems can be built using recycled components. Prototypes of these systems have been displayed in public events; they could serve as educational toolkits in schools and could also offer a solution for powering low-energy devices off-grid. View Full-Text   Abstract
This paper characterizes the strain Chlorella sorokiniana UTEX 1230 within a laboratory setting using a 1 L bubble column. The findings show that productivity can be trebled under mixotrophic conditions (from 0.2 g·L−1·d−1 to 0.66 g·L−1·d−1) with the addition of sodium acetate. The results also indicate that both the growth rate and final yield increase with the cultivation temperature, with most parameters showing an optimum in the range of 30–35 °C. The maximum specific growth rate was found to be in the region of 0.12 h−1 at a surface irradiance between 100–500 µE·m−2·s−1. This high growth rate makes the strain particularly suited to the rapid production of biomass, suitable for either whole cell bioprocessing or bioremediation. However, the relatively low lipid productivity (9.2 mg·L−1·d−1) confirms previous findings which would indicate poor applicability for biodiesel production. The strain shows greater promise in wastewater treatment applications with removal rates of nitrogen and phosphorus in the region of 37 and 30 mg·L−1·d−1 respectively. Furthermore, the findings show that a fed-batch strategy to inorganic nutrient loading can increase the final yield by around 50% compared to a conventional batch run. This is particularly interesting as fed-batch production techniques are rarely used within microalgal cultivation, so provide an interesting avenue for further investigation. Overall, the findings show that C. sorokiniana UTEX 1230 is a robust and fast-growing microalgal strain suitable both for the laboratory and scale-up. View Full-Text   electrostatic fields,electrodynamic fields,bioelectricity,ecology,evolution   saltmarsh,sediment carbon,wetland,accumulation rates,Spartina,pollen analysis   algae,bioelectrochemistry,renewable energy,recycled materials   Chlorella sorokiniana,UTEX1230,productivity,yield,characterization ", Biology 
 Mapping Digital Co-Creation for Urban Communities and Public Places   Innovation Emergence: Public Policies versus Actors’ Free Interaction   Reflections on Teaching System Dynamics Modeling to Secondary School Students for over 20 Years   Online Academic Networks as Knowledge Brokers: The Mediating Role of Organizational Support ," Abstract
Increasingly digital communication, social media and computing networks put the end-users at the center of innovation processes, thus shifting the emphasis from technologies to people. In the private sector, this shift to user-centricity has been conceptualized under such approaches as Service-Dominant Logic and Open Innovation 2.0. Public sector conceptualizes the change through the New Public Governance and Open Government paradigms and suggest that the public value is no longer created by the governments alone but in collaboration between the public entities, private sector, civil society organizations and citizens. While traditional approaches to public engagement and governmental transformations remain relevant, this article focuses on the growing potential of networked urban communities to solve the social problems. It expands the co-creation research field and suggests a typology discerning co-creation patterns when enhancing the public spaces with a community-wide participation with the use of creative, innovative and cooperative Information and Communication Technologies’ applications. The sample for web-based monitoring consists of 10 digital applications linked with design and improvement of public spaces in Vilnius, Lithuania. The proposed typology framework gives an overview of the state-of-art in the interaction between people, places and technology. The research helps to discern how different technological, organizational and other social factors influence and shape the patterns of co-creative initiatives. View Full-Text   Abstract
The main argument of this work is that innovation flourishes and emerges in a creative environment where the actors interact freely, to the extent that this environment is a complex adaptive system. Public or institutional policies, trying to induce innovation, must be careful to not stifle or interrupt the emergence of novelties in the path from creation and conception to market involvement. Our proposed model argues that innovation emerges wherever evolution, learning, mutation, and competition between individuals and firms are permitted, without restrictions or pre-defined paths to the market. We describe two cases of innovation by way of example: the first case shows how several—and sometimes anonymous—elements interact and compete in a typical environment of innovation, while the second case shows how continuous policies to foment innovation may create results to the contrary. In addition, we show technology clusters as cases where the emergence of innovation can be fostered by policies that observe the complex adaptive system characteristics. View Full-Text   Abstract
This paper contains the description of a successful system dynamics (SD) modeling approach used for almost a quarter-century in secondary schools, both in algebra classes and in a year-long SD modeling course. Secondary school students have demonstrated an ability to build original models from the news, write technical papers explaining their models, and present a newfound understanding of dynamic feedback behavior to an audience. The educational learning theory and instructional methods used for both the algebra and modeling courses are detailed, with examples. Successful student SD modeling experiences suggest the SD approach can expand the sophistication of topics that secondary school students can understand. View Full-Text   Abstract
Placing online academic networks in the framework of social, cultural and institutional “deterritorialization,” the current paper aims at investigating the functionality of these new forms of transnational and trans-organizational aggregations as knowledge brokers. The emphasis is laid on the influence of human collective intelligence and consistent knowledge flows on research innovation, considering the role of organizational support within higher education systems. In this respect, the research relied on a questionnaire-based survey with 140 academics from European emerging countries, the data collected being processed via a partial least squares structural equation modelling technique. Evidence was brought that, as knowledge brokers, online academic networks are systems aimed to support the access to human collective intelligence and consistent knowledge flows which exert a positive influence on research innovation, both directly and indirectly, by means of formal and informal organizational support. As facilitators of collaborative environments for individuals with specialized knowledge, competence, expertise and experience, online academic networks have set themselves up as an agora for academics worldwide and as an outlet for their acumen and literacy. View Full-Text "," co-creation,public spaces,communities,social technologies   Innovation,emergence,complex system,complex adaptive system,Global Innovation Index,cluster,technology cluster   pre-college systems modeling,system dynamics,deeper learning,complex systems,student-centered learning.   knowledge brokers,brokerage,online academic networks,organizational support,deterritorialization "," Mapping Digital Co-Creation for Urban Communities and Public Places   Innovation Emergence: Public Policies versus Actors’ Free Interaction   Reflections on Teaching System Dynamics Modeling to Secondary School Students for over 20 Years   Online Academic Networks as Knowledge Brokers: The Mediating Role of Organizational Support   Abstract
Increasingly digital communication, social media and computing networks put the end-users at the center of innovation processes, thus shifting the emphasis from technologies to people. In the private sector, this shift to user-centricity has been conceptualized under such approaches as Service-Dominant Logic and Open Innovation 2.0. Public sector conceptualizes the change through the New Public Governance and Open Government paradigms and suggest that the public value is no longer created by the governments alone but in collaboration between the public entities, private sector, civil society organizations and citizens. While traditional approaches to public engagement and governmental transformations remain relevant, this article focuses on the growing potential of networked urban communities to solve the social problems. It expands the co-creation research field and suggests a typology discerning co-creation patterns when enhancing the public spaces with a community-wide participation with the use of creative, innovative and cooperative Information and Communication Technologies’ applications. The sample for web-based monitoring consists of 10 digital applications linked with design and improvement of public spaces in Vilnius, Lithuania. The proposed typology framework gives an overview of the state-of-art in the interaction between people, places and technology. The research helps to discern how different technological, organizational and other social factors influence and shape the patterns of co-creative initiatives. View Full-Text   Abstract
The main argument of this work is that innovation flourishes and emerges in a creative environment where the actors interact freely, to the extent that this environment is a complex adaptive system. Public or institutional policies, trying to induce innovation, must be careful to not stifle or interrupt the emergence of novelties in the path from creation and conception to market involvement. Our proposed model argues that innovation emerges wherever evolution, learning, mutation, and competition between individuals and firms are permitted, without restrictions or pre-defined paths to the market. We describe two cases of innovation by way of example: the first case shows how several—and sometimes anonymous—elements interact and compete in a typical environment of innovation, while the second case shows how continuous policies to foment innovation may create results to the contrary. In addition, we show technology clusters as cases where the emergence of innovation can be fostered by policies that observe the complex adaptive system characteristics. View Full-Text   Abstract
This paper contains the description of a successful system dynamics (SD) modeling approach used for almost a quarter-century in secondary schools, both in algebra classes and in a year-long SD modeling course. Secondary school students have demonstrated an ability to build original models from the news, write technical papers explaining their models, and present a newfound understanding of dynamic feedback behavior to an audience. The educational learning theory and instructional methods used for both the algebra and modeling courses are detailed, with examples. Successful student SD modeling experiences suggest the SD approach can expand the sophistication of topics that secondary school students can understand. View Full-Text   Abstract
Placing online academic networks in the framework of social, cultural and institutional “deterritorialization,” the current paper aims at investigating the functionality of these new forms of transnational and trans-organizational aggregations as knowledge brokers. The emphasis is laid on the influence of human collective intelligence and consistent knowledge flows on research innovation, considering the role of organizational support within higher education systems. In this respect, the research relied on a questionnaire-based survey with 140 academics from European emerging countries, the data collected being processed via a partial least squares structural equation modelling technique. Evidence was brought that, as knowledge brokers, online academic networks are systems aimed to support the access to human collective intelligence and consistent knowledge flows which exert a positive influence on research innovation, both directly and indirectly, by means of formal and informal organizational support. As facilitators of collaborative environments for individuals with specialized knowledge, competence, expertise and experience, online academic networks have set themselves up as an agora for academics worldwide and as an outlet for their acumen and literacy. View Full-Text   co-creation,public spaces,communities,social technologies   Innovation,emergence,complex system,complex adaptive system,Global Innovation Index,cluster,technology cluster   pre-college systems modeling,system dynamics,deeper learning,complex systems,student-centered learning.   knowledge brokers,brokerage,online academic networks,organizational support,deterritorialization ", Systems 
 Review of Analog-To-Digital Conversion Characteristics and Design Considerations for the Creation of Power-Efficient Hybrid Data Converters   An Ultra-Low Power 28 nm FD-SOI Low Noise Amplifier Based on Channel Aware Receiver System Analysis ," Abstract
This article reviews design challenges for low-power CMOS high-speed analog-to-digital converters (ADCs). Basic ADC converter architectures (flash ADCs, interpolating and folding ADCs, subranging and two-step ADCs, pipelined ADCs, successive approximation ADCs) are described with particular focus on their suitability for the construction of power-efficient hybrid ADCs. The overview includes discussions of channel offsets and gain mismatches, timing skews, channel bandwidth mismatches, and other considerations for low-power hybrid ADC design. As an example, a hybrid ADC architecture is introduced for applications requiring 1 GS/s with 6–8 bit resolution and power consumption below 11 mW. The hybrid ADC was fabricated in 130-nm CMOS technology, and has a subranging architecture with a 3-bit flash ADC as a first stage, and a 5-bit four-channel time-interleaved comparator-based asynchronous binary search (CABS) ADC as a second stage. Testing considerations and chip measurements results are summarized to demonstrate its low-power characteristics. View Full-Text   Abstract
This study investigates the benefit of an optimal and energy-efficient reconfiguration technique for the design of channel-aware receiver aiming Internet of Things (IoT) applications. First, it demonstrates the interest for adaptive receivers based on an estimation of the received power and compares the proposed channel-aware receiver with the State Of the Art. It is shown that the lifetime of the Wireless Sensor (WS) battery can be extended by a factor of five with the optimization of operating points of the tunable receiver while maintaining similar performances than industrial modules. The design of an Ultra-Low Power (ULP) inductorless Low Noise Amplifier (LNA), which fits the low power mode of the tunable receiver, is then optimized and described. The back-gate biasing of Fully Depleted Silicon-On-Insulator (FD-SOI) technology to lower the power consumption by more than 25% still maintaining performances is evaluated. The proposed LNA has been implemented in ST-Microelectronics 28 nm FD-SOI Technology, its active area is only 0.0015 mm2. The measured performances at 2.4 GHz exhibit more than 16 dB of voltage Gain (Gv), 7.3 dB of Noise Figure (NF), and a −16 dBm Input referred third-order Intercept Point (IIP3). The LNA consumes 300 µW from a 0.6 V supply. View Full-Text "," analog-to-digital converter (ADC),comparator-based asynchronous binary search (CABS) ADC,subranging,successive approximation register (SAR),time-interleaved (TI),hybrid ADC   Front-End Receiver,Internet of Things,Fully Depleted Silicon-On-Insulator,Low Noise Amplifier,Ultra Low Power,Wireless Sensor Network "," Review of Analog-To-Digital Conversion Characteristics and Design Considerations for the Creation of Power-Efficient Hybrid Data Converters   An Ultra-Low Power 28 nm FD-SOI Low Noise Amplifier Based on Channel Aware Receiver System Analysis   Abstract
This article reviews design challenges for low-power CMOS high-speed analog-to-digital converters (ADCs). Basic ADC converter architectures (flash ADCs, interpolating and folding ADCs, subranging and two-step ADCs, pipelined ADCs, successive approximation ADCs) are described with particular focus on their suitability for the construction of power-efficient hybrid ADCs. The overview includes discussions of channel offsets and gain mismatches, timing skews, channel bandwidth mismatches, and other considerations for low-power hybrid ADC design. As an example, a hybrid ADC architecture is introduced for applications requiring 1 GS/s with 6–8 bit resolution and power consumption below 11 mW. The hybrid ADC was fabricated in 130-nm CMOS technology, and has a subranging architecture with a 3-bit flash ADC as a first stage, and a 5-bit four-channel time-interleaved comparator-based asynchronous binary search (CABS) ADC as a second stage. Testing considerations and chip measurements results are summarized to demonstrate its low-power characteristics. View Full-Text   Abstract
This study investigates the benefit of an optimal and energy-efficient reconfiguration technique for the design of channel-aware receiver aiming Internet of Things (IoT) applications. First, it demonstrates the interest for adaptive receivers based on an estimation of the received power and compares the proposed channel-aware receiver with the State Of the Art. It is shown that the lifetime of the Wireless Sensor (WS) battery can be extended by a factor of five with the optimization of operating points of the tunable receiver while maintaining similar performances than industrial modules. The design of an Ultra-Low Power (ULP) inductorless Low Noise Amplifier (LNA), which fits the low power mode of the tunable receiver, is then optimized and described. The back-gate biasing of Fully Depleted Silicon-On-Insulator (FD-SOI) technology to lower the power consumption by more than 25% still maintaining performances is evaluated. The proposed LNA has been implemented in ST-Microelectronics 28 nm FD-SOI Technology, its active area is only 0.0015 mm2. The measured performances at 2.4 GHz exhibit more than 16 dB of voltage Gain (Gv), 7.3 dB of Noise Figure (NF), and a −16 dBm Input referred third-order Intercept Point (IIP3). The LNA consumes 300 µW from a 0.6 V supply. View Full-Text   analog-to-digital converter (ADC),comparator-based asynchronous binary search (CABS) ADC,subranging,successive approximation register (SAR),time-interleaved (TI),hybrid ADC   Front-End Receiver,Internet of Things,Fully Depleted Silicon-On-Insulator,Low Noise Amplifier,Ultra Low Power,Wireless Sensor Network ", Journal of Low Power Electronics and Applications 
 Scenario Modelling of the “Green” Economy in an Economic Space   Microwave-Assisted Extraction and Physicochemical Evaluation of Oil from Hevea brasiliensis Seeds   Development of an Innovative and Sustainable Model for Integrating River Maintenance with Energy Production from Residual Biomass   Ecological Impact of Forest Fires and Subsequent Restoration in Chile ," Abstract
The article utilizes the main elements of system analysis and the bases of cognitive science to analyze the concept of the “ecological and economic system”. The characteristics of the conceptual elements of the “green” economy dynamic model used in the application of cognitive analysis are given and their mutual influence is considered. A dynamic model of the “green” economy is developed, a general extended map and a reduced-parametric cognitive map of the development of the “green” economy in the economic space of the region are constructed. Scenario modelling of the development of the region’s “green” economy based on the intensification of the influence of one of the cognitive vertices of the model on the curve of the development of the “green” economy is carried out and described. Scenario modelling and development of cognitive maps are carried out using the software package Vensim Personal Learning Edition (PLE), which is widely applied in system analysis. View Full-Text   Abstract
The rubber tree (Hevea brasiliensis) is exploited mainly for latex in view of its economic importance. However, one of its auxiliary products, the rubber seed, does not find any major applications, and hence, even the natural production of seeds itself remains underutilized. In this study, microwave-assisted Soxhlet extraction is used as a green alternative to extract the oil from seeds at a reaction time of 90 min and microwave power of 300 W. The objective of the study is to evaluate the effects of the processing conditions, including drying time, temperature, solid–solvent ratio, and extraction solvent, on the yield of rubber seed oil. Moreover, the microwave-assisted aqueous extraction (MAAE) under acidic conditions is also investigated. Based on the results, n-hexane gave the best yield at an optimized 1:20 seed–hexane ratio at 72 °C compared with the conventional Soxhlet method and the acidic MAAE. Furthermore, the chemical characteristics of the oil showed a high value of free fatty acids (% FFA) (1.15–7.61%) and an iodine value (IV) that ranges from 100–150. As a semi-drying oil, rubber seed oil (RSO) can be used as an ingredient for surface coating and in the formulation of products where the presence of unsaturation is important. View Full-Text   Abstract
This study aims to develop an innovative model for managing territory maintenance in which the productive function is linked with the protective one and that integrates environmental and economic development aspects, combining the energetic valorization with an effective territory maintenance program. The strong innovation consists in the creation of an agro-energy environment chain based on the maintenance of river basins and small waterways made by single farmers or associations that will use residual biomass to produce electrical and thermal bio-energy. The maintenance activities include the control of aquatic weeds, grass cutting on river banks, and tree/bush management. If left unmanaged, they can block the flow of watercourses and increase the risk of flooding. The implementation of this virtuous model to the rivers maintenance aims to provide management and conservation means based on the territory characteristics. In fact, the new model has been applied to an existing site in the Marche region (Italy) located near a river characterized by a poor state of maintenance. A real commercial system for residual biomass exploitation was chosen, and both the technical and economic feasibility of the model implementation have been demonstrated. View Full-Text   Abstract
This note analyzes the effects forest fires in Chile have on vegetation and subsequent ecological restoration. We analyze why forest fires have been a main factor that affects the environment and causes the ecosystem to deteriorate, leading to loss of native forests, species extinction, damage to the urban population, and others. The data examined are derived from fire hotspots in Chile’s central and central-south zones (
33
∘
00
′
S–
41
∘
57
′
S) between 1985 and 2017. We also analyze some key aspects for restoration priorities such as studying affected areas and posterior consequences. Finally, we evaluate actions the country has already taken, and propose further appropriate preventive and restoration measures. View Full-Text "," “green” economy,cognitive modeling,cognitive maps,system dynamics,system dynamic model,development of the “green” economy,economic space of the region   rubber seed oil,microwave-assisted extraction,Soxhlet extraction,microwave-assisted aqueous extraction   bio-energy,agro-energy,biomass,floods prevention,gasification,river maintenance,sustainability   forest fires,native woods,ecological restoration,forest resources,Chile "," Scenario Modelling of the “Green” Economy in an Economic Space   Microwave-Assisted Extraction and Physicochemical Evaluation of Oil from Hevea brasiliensis Seeds   Development of an Innovative and Sustainable Model for Integrating River Maintenance with Energy Production from Residual Biomass   Ecological Impact of Forest Fires and Subsequent Restoration in Chile   Abstract
The article utilizes the main elements of system analysis and the bases of cognitive science to analyze the concept of the “ecological and economic system”. The characteristics of the conceptual elements of the “green” economy dynamic model used in the application of cognitive analysis are given and their mutual influence is considered. A dynamic model of the “green” economy is developed, a general extended map and a reduced-parametric cognitive map of the development of the “green” economy in the economic space of the region are constructed. Scenario modelling of the development of the region’s “green” economy based on the intensification of the influence of one of the cognitive vertices of the model on the curve of the development of the “green” economy is carried out and described. Scenario modelling and development of cognitive maps are carried out using the software package Vensim Personal Learning Edition (PLE), which is widely applied in system analysis. View Full-Text   Abstract
The rubber tree (Hevea brasiliensis) is exploited mainly for latex in view of its economic importance. However, one of its auxiliary products, the rubber seed, does not find any major applications, and hence, even the natural production of seeds itself remains underutilized. In this study, microwave-assisted Soxhlet extraction is used as a green alternative to extract the oil from seeds at a reaction time of 90 min and microwave power of 300 W. The objective of the study is to evaluate the effects of the processing conditions, including drying time, temperature, solid–solvent ratio, and extraction solvent, on the yield of rubber seed oil. Moreover, the microwave-assisted aqueous extraction (MAAE) under acidic conditions is also investigated. Based on the results, n-hexane gave the best yield at an optimized 1:20 seed–hexane ratio at 72 °C compared with the conventional Soxhlet method and the acidic MAAE. Furthermore, the chemical characteristics of the oil showed a high value of free fatty acids (% FFA) (1.15–7.61%) and an iodine value (IV) that ranges from 100–150. As a semi-drying oil, rubber seed oil (RSO) can be used as an ingredient for surface coating and in the formulation of products where the presence of unsaturation is important. View Full-Text   Abstract
This study aims to develop an innovative model for managing territory maintenance in which the productive function is linked with the protective one and that integrates environmental and economic development aspects, combining the energetic valorization with an effective territory maintenance program. The strong innovation consists in the creation of an agro-energy environment chain based on the maintenance of river basins and small waterways made by single farmers or associations that will use residual biomass to produce electrical and thermal bio-energy. The maintenance activities include the control of aquatic weeds, grass cutting on river banks, and tree/bush management. If left unmanaged, they can block the flow of watercourses and increase the risk of flooding. The implementation of this virtuous model to the rivers maintenance aims to provide management and conservation means based on the territory characteristics. In fact, the new model has been applied to an existing site in the Marche region (Italy) located near a river characterized by a poor state of maintenance. A real commercial system for residual biomass exploitation was chosen, and both the technical and economic feasibility of the model implementation have been demonstrated. View Full-Text   Abstract
This note analyzes the effects forest fires in Chile have on vegetation and subsequent ecological restoration. We analyze why forest fires have been a main factor that affects the environment and causes the ecosystem to deteriorate, leading to loss of native forests, species extinction, damage to the urban population, and others. The data examined are derived from fire hotspots in Chile’s central and central-south zones (
33
∘
00
′
S–
41
∘
57
′
S) between 1985 and 2017. We also analyze some key aspects for restoration priorities such as studying affected areas and posterior consequences. Finally, we evaluate actions the country has already taken, and propose further appropriate preventive and restoration measures. View Full-Text   “green” economy,cognitive modeling,cognitive maps,system dynamics,system dynamic model,development of the “green” economy,economic space of the region   rubber seed oil,microwave-assisted extraction,Soxhlet extraction,microwave-assisted aqueous extraction   bio-energy,agro-energy,biomass,floods prevention,gasification,river maintenance,sustainability   forest fires,native woods,ecological restoration,forest resources,Chile ", Resources 
" Herbal Cosmetics Knowledge of Arab-Choa and Kotoko Ethnic Groups in the Semi-Arid Areas of Far North Cameroon: Ethnobotanical Assessment and Phytochemical Review   A Critical View of Different Botanical, Molecular, and Chemical Techniques Used in Authentication of Plant Materials for Cosmetic Applications   Skin Regenerative and Anti-Cancer Actions of Copper Peptides   Quantitative Analysis Using the Phototrichogram Technique of an Italian Population Suffering from Androgenic Alopecia "," Abstract
The plant-based traditional knowledge of many Cameroonian populations concerning beauty and skin care is still poorly documented, yet they are real resources of innovation and economic development. The aim of this study is to document the indigenous knowledge of Choa Arab and Kotoko ethnic group in Kousséri (Far North Region of Cameroon) about plants used for cosmetics. Ethnobotanical data collected among key informants revealed a total of 13 plants species belonging to 12 families used by local people. Canarium schweinfurthii Engl and Santalum album L. obtained the highest frequency of citation. Trees are the most abundant life forms, while barks and seeds are the most frequently used parts. More than 40% of recorded plants are used for skin care. The cosmetic allegations of recorded plants include: dermatology, anti-cancers, antioxidant agent, perfume, anti-inflammatory, antimicrobial, wounds healing activity, skin lightening, dental caries, astringent and hair care. They all contain various phytochemicals that are of interest in cosmetics. Despite the strong relationship between the Choa Arab and Kotoko people and herbal cosmetic ingredients, these plants are still less investigated for their cosmetic application. The authors urge for the development of sustainable supply chain for plants with potentials as cosmetics, involving local communities in the planning, implementation and monitoring process, following principles of Nagoya protocol on Access and Benefit Sharing. View Full-Text   Abstract
A number of approaches can be implemented to ensure plant-based material authentication for cosmetic applications. Doing this requires knowledge and data dealing with botany, molecular biology, and analytical chemistry, the main techniques of which are described here. A comprehensive and critical view of the methods is provided with comments as well as examples of their application domains. View Full-Text   Abstract
Topical remedies capable of protecting skin from damage and supporting its regeneration can improve skin’s health as well as its appearance. Small copper peptides have an excellent safety record and are widely used in cosmetic products. The most studied copper peptide is GHK-Cu (glycyl-L-histidyl-L-lysine), a small copper-binding peptide, naturally present in human plasma. Since its discovery in 1973, in vivo and in vitro studies have shown that GHK-Cu possesses a wealth of health-positive actions including improving wound contraction and epithelization, and increasing the production of growth factors and activity of antioxidant enzymes. Recently, gene expression profiling shed new light on diverse biological actions of GHK-Cu. The present paper discusses evidence of GHK-Cu and other small copper peptides possessing potent anti-cancer properties. View Full-Text   Abstract
In this study, the values of some scalp basal parameters, collected during several clinical studies involving a total of 254 subjects with androgenic alopecia, were analyzed. Subjects’ values were grouped by age and gender, and the differences between groups were examined. The density values (n° of hair/cm2) and the percentages of anagen and telogen hair were considered. Furthermore, the variations recorded at the end of cosmetic treatments (ranging from 12 to 16 weeks) aiming to reduce excessive hair loss were analyzed. The basal values regarding the percentage of hair in the anagen phase evidenced a linear decrease with increasing age, with a corresponding increase of the percentage of hair in the telogen phase. As far as the hair density differences between males and females are concerned, females had a mean value significantly higher than males. Moreover, at the end of the intended anti-hair loss treatments, females were more susceptible to improvements of their hair density values. View Full-Text "," Choa Arab,Kotoko,indigenous knowledge,phytochemicals,cosmetics   authentication,botany,cosmetic,molecular markers,phytochemical analysis,plant material   GHK-Cu,copper peptides,skin cancer,gene profiling,gene expression,regeneration   hair density,anagen phase,telogen phase,age groups,gender "," Herbal Cosmetics Knowledge of Arab-Choa and Kotoko Ethnic Groups in the Semi-Arid Areas of Far North Cameroon: Ethnobotanical Assessment and Phytochemical Review   A Critical View of Different Botanical, Molecular, and Chemical Techniques Used in Authentication of Plant Materials for Cosmetic Applications   Skin Regenerative and Anti-Cancer Actions of Copper Peptides   Quantitative Analysis Using the Phototrichogram Technique of an Italian Population Suffering from Androgenic Alopecia   Abstract
The plant-based traditional knowledge of many Cameroonian populations concerning beauty and skin care is still poorly documented, yet they are real resources of innovation and economic development. The aim of this study is to document the indigenous knowledge of Choa Arab and Kotoko ethnic group in Kousséri (Far North Region of Cameroon) about plants used for cosmetics. Ethnobotanical data collected among key informants revealed a total of 13 plants species belonging to 12 families used by local people. Canarium schweinfurthii Engl and Santalum album L. obtained the highest frequency of citation. Trees are the most abundant life forms, while barks and seeds are the most frequently used parts. More than 40% of recorded plants are used for skin care. The cosmetic allegations of recorded plants include: dermatology, anti-cancers, antioxidant agent, perfume, anti-inflammatory, antimicrobial, wounds healing activity, skin lightening, dental caries, astringent and hair care. They all contain various phytochemicals that are of interest in cosmetics. Despite the strong relationship between the Choa Arab and Kotoko people and herbal cosmetic ingredients, these plants are still less investigated for their cosmetic application. The authors urge for the development of sustainable supply chain for plants with potentials as cosmetics, involving local communities in the planning, implementation and monitoring process, following principles of Nagoya protocol on Access and Benefit Sharing. View Full-Text   Abstract
A number of approaches can be implemented to ensure plant-based material authentication for cosmetic applications. Doing this requires knowledge and data dealing with botany, molecular biology, and analytical chemistry, the main techniques of which are described here. A comprehensive and critical view of the methods is provided with comments as well as examples of their application domains. View Full-Text   Abstract
Topical remedies capable of protecting skin from damage and supporting its regeneration can improve skin’s health as well as its appearance. Small copper peptides have an excellent safety record and are widely used in cosmetic products. The most studied copper peptide is GHK-Cu (glycyl-L-histidyl-L-lysine), a small copper-binding peptide, naturally present in human plasma. Since its discovery in 1973, in vivo and in vitro studies have shown that GHK-Cu possesses a wealth of health-positive actions including improving wound contraction and epithelization, and increasing the production of growth factors and activity of antioxidant enzymes. Recently, gene expression profiling shed new light on diverse biological actions of GHK-Cu. The present paper discusses evidence of GHK-Cu and other small copper peptides possessing potent anti-cancer properties. View Full-Text   Abstract
In this study, the values of some scalp basal parameters, collected during several clinical studies involving a total of 254 subjects with androgenic alopecia, were analyzed. Subjects’ values were grouped by age and gender, and the differences between groups were examined. The density values (n° of hair/cm2) and the percentages of anagen and telogen hair were considered. Furthermore, the variations recorded at the end of cosmetic treatments (ranging from 12 to 16 weeks) aiming to reduce excessive hair loss were analyzed. The basal values regarding the percentage of hair in the anagen phase evidenced a linear decrease with increasing age, with a corresponding increase of the percentage of hair in the telogen phase. As far as the hair density differences between males and females are concerned, females had a mean value significantly higher than males. Moreover, at the end of the intended anti-hair loss treatments, females were more susceptible to improvements of their hair density values. View Full-Text   Choa Arab,Kotoko,indigenous knowledge,phytochemicals,cosmetics   authentication,botany,cosmetic,molecular markers,phytochemical analysis,plant material   GHK-Cu,copper peptides,skin cancer,gene profiling,gene expression,regeneration   hair density,anagen phase,telogen phase,age groups,gender ", Cosmetics 
 PrECast: An Efficient Crypto-Free Solution for Broadcast-Based Attacks in IPv4 Networks   Two-Dimensional (2D) Slices Encryption-Based Security Solution for Three-Dimensional (3D) Printing Industry   A Novel Supercapacitor/Lithium-Ion Hybrid Energy System with a Fuzzy Logic-Controlled Fast Charging and Intelligent Energy Management System ," Abstract
Broadcasting is one of the essential features in the Internet Protocol Ver 4 (IPv4). Attackers often exploit this feature of the IP protocol to launch several attacks against a network or an individual host. Attackers may either be a part of a Local Area Network (LAN) or outside a LAN to launch these attacks. There are numerous papers available in the literature to solve problems resulting from IP broadcasting. However, all these solutions target a specific problem that results from IP broadcasting. Furthermore, these solutions use either a computationally-intensive cryptographic scheme, the a priori relation between the host and the network or a modified protocol stack at every host. In this paper, we provide a seamless and transparent solution to eliminate IP broadcasting and thus eliminate all problems related to IP broadcasting. Our proposed solution is crypto-free and does not need any modification to the protocol stack. View Full-Text   Abstract
Nowadays, three-dimensional (3D) printing technology is applied to many areas of life and changes the world based on the creation of complex structures and shapes that were not feasible in the past. But, the data of 3D printing is often attacked in the storage and transmission processes. Therefore, 3D printing must be ensured security in the manufacturing process, especially the data of 3D printing to prevent attacks from hackers. This paper presents a security solution for 3D printing based on two-dimensional (2D) slices encryption. The 2D slices of 3D printing data is encrypted in the frequency domain or in the spatial domain by the secret key to generate the encrypted data of 3D printing. We implemented the proposed solution in both the frequency domain based on the Discrete Cosine Transform and the spatial domain based on geometric transform. The entire 2D slices of 3D printing data is altered and secured after the encryption process. The proposed solution is responsive to the security requirements for the secured storage and transmission. Experimental results also verified that the proposed solution is effective to 3D printing data and is independent on the format of 3D printing models. When compared to the conventional works, the security and performance of the proposed solution is also better. View Full-Text   Abstract
The electric powered wheelchair (EPW) is an essential assistive tool for people with serious injuries or disability. This manuscript describes the validation of applied research for reducing the charging time of an electric wheelchair using a hybrid electric system (HES) composed of a supercapacitor (SC) bank and a lithium-ion battery with a fuzzy logic controller (FLC)-based fast charging system for Li-ion batteries and a fuzzy logic-based intelligent energy management system (FLIEMS) for controlling the power flow within the HES. The fast charging FLC was designed to drive the voltage difference (Vd) among the different cells of a multi-cell battery and the cell voltage (Vc) of an individual cell. These parameters (voltage difference and cell voltage) were used as input voltages to reduce the charge time and activate a bypass equalization (BPE) scheme. BPE was introduced in this paper so that the battery operates within the safe voltage range. For SC/Li-ion HES, the FLIEMS presented in this paper controls the bi-directional power flow to smooth the power extracted from Li-ion batteries. Moreover, a dual active bridge isolated bidirectional DC converter (DAB-IBDC) was used for power conversion. The DAB-IBDC presented in this paper has the characteristics of galvanic isolation, and high power conversion efficiency compared to the conventional converter circuits due to the reduced reverse power flow and current stresses. View Full-Text "," IPv4,ARP-poison,IP-broadcasting,DDoS,DHCP-hijacking   3D printing,3D printing data,3D printing security,discrete cosine transform,geometric transformation   fuzzy logic controller (FLC),supercapacitor,Li-ion,hybrid electric system (HES),energy management system (EMS),dual active bridge (DAB) converter "," PrECast: An Efficient Crypto-Free Solution for Broadcast-Based Attacks in IPv4 Networks   Two-Dimensional (2D) Slices Encryption-Based Security Solution for Three-Dimensional (3D) Printing Industry   A Novel Supercapacitor/Lithium-Ion Hybrid Energy System with a Fuzzy Logic-Controlled Fast Charging and Intelligent Energy Management System   Abstract
Broadcasting is one of the essential features in the Internet Protocol Ver 4 (IPv4). Attackers often exploit this feature of the IP protocol to launch several attacks against a network or an individual host. Attackers may either be a part of a Local Area Network (LAN) or outside a LAN to launch these attacks. There are numerous papers available in the literature to solve problems resulting from IP broadcasting. However, all these solutions target a specific problem that results from IP broadcasting. Furthermore, these solutions use either a computationally-intensive cryptographic scheme, the a priori relation between the host and the network or a modified protocol stack at every host. In this paper, we provide a seamless and transparent solution to eliminate IP broadcasting and thus eliminate all problems related to IP broadcasting. Our proposed solution is crypto-free and does not need any modification to the protocol stack. View Full-Text   Abstract
Nowadays, three-dimensional (3D) printing technology is applied to many areas of life and changes the world based on the creation of complex structures and shapes that were not feasible in the past. But, the data of 3D printing is often attacked in the storage and transmission processes. Therefore, 3D printing must be ensured security in the manufacturing process, especially the data of 3D printing to prevent attacks from hackers. This paper presents a security solution for 3D printing based on two-dimensional (2D) slices encryption. The 2D slices of 3D printing data is encrypted in the frequency domain or in the spatial domain by the secret key to generate the encrypted data of 3D printing. We implemented the proposed solution in both the frequency domain based on the Discrete Cosine Transform and the spatial domain based on geometric transform. The entire 2D slices of 3D printing data is altered and secured after the encryption process. The proposed solution is responsive to the security requirements for the secured storage and transmission. Experimental results also verified that the proposed solution is effective to 3D printing data and is independent on the format of 3D printing models. When compared to the conventional works, the security and performance of the proposed solution is also better. View Full-Text   Abstract
The electric powered wheelchair (EPW) is an essential assistive tool for people with serious injuries or disability. This manuscript describes the validation of applied research for reducing the charging time of an electric wheelchair using a hybrid electric system (HES) composed of a supercapacitor (SC) bank and a lithium-ion battery with a fuzzy logic controller (FLC)-based fast charging system for Li-ion batteries and a fuzzy logic-based intelligent energy management system (FLIEMS) for controlling the power flow within the HES. The fast charging FLC was designed to drive the voltage difference (Vd) among the different cells of a multi-cell battery and the cell voltage (Vc) of an individual cell. These parameters (voltage difference and cell voltage) were used as input voltages to reduce the charge time and activate a bypass equalization (BPE) scheme. BPE was introduced in this paper so that the battery operates within the safe voltage range. For SC/Li-ion HES, the FLIEMS presented in this paper controls the bi-directional power flow to smooth the power extracted from Li-ion batteries. Moreover, a dual active bridge isolated bidirectional DC converter (DAB-IBDC) was used for power conversion. The DAB-IBDC presented in this paper has the characteristics of galvanic isolation, and high power conversion efficiency compared to the conventional converter circuits due to the reduced reverse power flow and current stresses. View Full-Text   IPv4,ARP-poison,IP-broadcasting,DDoS,DHCP-hijacking   3D printing,3D printing data,3D printing security,discrete cosine transform,geometric transformation   fuzzy logic controller (FLC),supercapacitor,Li-ion,hybrid electric system (HES),energy management system (EMS),dual active bridge (DAB) converter ", Electronics 
" Survival and Prognostic Factors in Mixed Cryoglobulinemia: Data from 246 Cases   Epigenetic Regulation of ATP-Binding Cassette Protein A1 (ABCA1) Gene Expression: A New Era to Alleviate Atherosclerotic Cardiovascular Disease   Comparison of Brain Natriuretic Peptide Levels to Simultaneously Obtained Right Heart Hemodynamics in Stable Outpatients with Pulmonary Arterial Hypertension   Self-Medication with Antibiotics, Attitude and Knowledge of Antibiotic Resistance among Community Residents and Undergraduate Students in Northwest Nigeria "," Abstract
Introduction: The clinical and therapeutic management of mixed cryoglobulinemia (MC) remains a subject of controversy. In addition, most studies have not recorded the long-term follow-up and the outcome of these cases. Material and Methods: We enrolled 246 patients affected by MC who were consecutively admitted to our Department from January 1993 to February 2013. Clinical and biological data had been recorded until June 2014. Results: The median age (at diagnosis) was 60 years (range 26–83). The aetiology was HCV in 95% of patients, HBV in 3% and “essential” in 2%. HCV genotype was 1b in 57%, genotypes 2–3 in 43%. MC was Type II in 203 of the cases (87%) and Type III in 52 (13%). The most frequent clinical manifestations were purpura (72%), chronic liver disease (70%), glomerulonephritis (35%), arthralgias (58%), peripheral neuropathy (21%), non-Hodgkin lymphoma (15%) and cutaneous ulcers (3%). Purpura, arthralgias, peripheral neuropathy, glomerulonephritis and non-Hodgkin lymphoma were more frequently observed in Type II than in Type III MC (p < 0.05). Treatments were interferon (IFN) or Pegilated-IFN (PEG-IFN) alone or plus Ribavirin (RIBA) in 101 cases, steroids with or without alkylating agents in 33 cases, Rituximab in 8 patients. The complete clinical, virological and immunological responses were associated with PEG-IFN plus RIBA. Severe infections were associated with renal failure. At 10 years, the overall survival rate was 71% in Type II MC and 84% in Type III (p < 0.053). Conclusions: From our data, antiviral therapy is the first-line therapy in HCV-related MC, whereas steroids, alkylating agents and Rituximab should be considered as a second-line therapy. Given the heterogeneity of the disease, the role of these different therapeutic strategies should be checked in randomized controlled trials. View Full-Text   Abstract
The most important function of high density lipoprotein (HDL) is its ability to remove cholesterol from cells and tissues involved in the early stages of atherosclerosis back to the liver for excretion. The ATP-binding cassette transporters ABCA1 and ABCG1 are responsible for the major part of cholesterol efflux to HDL in macrophage foam cells. Thus, promoting the process of reverse cholesterol transport (RCT) by upregulating mainly ABCA1 remains one of the potential targets for the development of new therapeutic agents against atherosclerosis. Growing evidence suggests that posttranscriptional regulation of HDL biogenesis as well as modulation of ABCA1 expression are under the control of several genetic and epigenetic factors such as transcription factor (TFs), microRNAs (miRNAs) and RNA-binding proteins (RBPs).These factors may act either individually or in combination to orchestrate ABCA1 expression. Complementary to our recent work, we propose an exploratory model for the potential molecular mechanism(s) underlying epigenetic signature of ABCA1 gene regulation. Such a model may hopefully provide the basic framework for understanding the epigenetic regulation of RCT and contribute to the development of novel therapeutic strategies to alleviate the burden of cardiovascular diseases (CVD). View Full-Text   Abstract
Pulmonary arterial hypertension (PAH) is a progressive disease that requires validated biomarkers of disease severity. While PAH is defined hemodynamically by right heart catheterization (RHC), brain natriuretic peptide (BNP) is recommended by guidelines to assess disease status. Retrospectively collected data in 138 group 1 PAH patients were examined for the correlation of BNP levels to simultaneously obtained right heart catheterization (RHC). Patients were mostly Caucasian women, with functional class III symptoms, mean BNP of 406 ± 443 pg/mL, and an average right atrial pressure (RAP) of 9.9 ± 5.7 mm Hg and mean pulmonary artery pressure (mPAP) of 47.3 ± 14.7 mm Hg. Significant correlation was demonstrated between BNP and RAP (p = 0.021) and mPAP (p = 0.003). Additional correlation was seen with right heart size on echocardiography: right atrial (RAE; p = 0.04) and right ventricular enlargement (p = 0.03). An increased BNP level was an independent predictor of mortality (p < 0.0001), along with RAP (p = 0.039) and RAE (p = 0.018). Simultaneous collection of BNP at the time of RHC confirmed the correlation of BNP with right heart hemodynamics. The current results reinforce the use of BNP level as a continuous variable to assess disease severity in group 1 PAH. View Full-Text   Abstract
This study set out to evaluate self-medicated antibiotics and knowledge of antibiotic resistance among undergraduate students and community members in northern Nigeria. Antibiotic consumption pattern, source of prescription, illnesses commonly treated, attitude towards antibiotics, and knowledge of antibiotic resistance were explored using a structured questionnaire. Responses were analyzed and summarized using descriptive statistics. Of the 1230 respondents from undergraduate students and community members, prescription of antibiotics by a physician was 33% and 57%, respectively, amongst undergraduate students and community members. We tested the respondents’ knowledge of antibiotic resistance (ABR) and found that undergraduate students displayed less knowledge that self-medication could lead to ABR (32.6% and 42.2% respectively). Self-medication with antibiotics is highly prevalent in Northwest Nigeria, with most medicines being purchased from un-licensed stores without prescription from a physician. We also observed a significant gap in respondents’ knowledge of ABR. There is an urgent need for public health authorities in Nigeria to enforce existing laws on antibiotics sales and enlighten the people on the dangers of ABR. View Full-Text "," hepatitis C virus,mixed cryoglobulinemia,interferon alpha,steroids,rituximab   ABCA1,HDL,miRNA,circular RNA,gene expression,RNA-binding proteins,reverse cholesterol transport,cardiovascular diseases   pulmonary arterial hypertension,brain natriuretic peptide,biomarkers,right heart catheterization,transthoracic echocardiogram   self-medication,antibiotic resistance,community,undergraduates "," Survival and Prognostic Factors in Mixed Cryoglobulinemia: Data from 246 Cases   Epigenetic Regulation of ATP-Binding Cassette Protein A1 (ABCA1) Gene Expression: A New Era to Alleviate Atherosclerotic Cardiovascular Disease   Comparison of Brain Natriuretic Peptide Levels to Simultaneously Obtained Right Heart Hemodynamics in Stable Outpatients with Pulmonary Arterial Hypertension   Self-Medication with Antibiotics, Attitude and Knowledge of Antibiotic Resistance among Community Residents and Undergraduate Students in Northwest Nigeria   Abstract
Introduction: The clinical and therapeutic management of mixed cryoglobulinemia (MC) remains a subject of controversy. In addition, most studies have not recorded the long-term follow-up and the outcome of these cases. Material and Methods: We enrolled 246 patients affected by MC who were consecutively admitted to our Department from January 1993 to February 2013. Clinical and biological data had been recorded until June 2014. Results: The median age (at diagnosis) was 60 years (range 26–83). The aetiology was HCV in 95% of patients, HBV in 3% and “essential” in 2%. HCV genotype was 1b in 57%, genotypes 2–3 in 43%. MC was Type II in 203 of the cases (87%) and Type III in 52 (13%). The most frequent clinical manifestations were purpura (72%), chronic liver disease (70%), glomerulonephritis (35%), arthralgias (58%), peripheral neuropathy (21%), non-Hodgkin lymphoma (15%) and cutaneous ulcers (3%). Purpura, arthralgias, peripheral neuropathy, glomerulonephritis and non-Hodgkin lymphoma were more frequently observed in Type II than in Type III MC (p < 0.05). Treatments were interferon (IFN) or Pegilated-IFN (PEG-IFN) alone or plus Ribavirin (RIBA) in 101 cases, steroids with or without alkylating agents in 33 cases, Rituximab in 8 patients. The complete clinical, virological and immunological responses were associated with PEG-IFN plus RIBA. Severe infections were associated with renal failure. At 10 years, the overall survival rate was 71% in Type II MC and 84% in Type III (p < 0.053). Conclusions: From our data, antiviral therapy is the first-line therapy in HCV-related MC, whereas steroids, alkylating agents and Rituximab should be considered as a second-line therapy. Given the heterogeneity of the disease, the role of these different therapeutic strategies should be checked in randomized controlled trials. View Full-Text   Abstract
The most important function of high density lipoprotein (HDL) is its ability to remove cholesterol from cells and tissues involved in the early stages of atherosclerosis back to the liver for excretion. The ATP-binding cassette transporters ABCA1 and ABCG1 are responsible for the major part of cholesterol efflux to HDL in macrophage foam cells. Thus, promoting the process of reverse cholesterol transport (RCT) by upregulating mainly ABCA1 remains one of the potential targets for the development of new therapeutic agents against atherosclerosis. Growing evidence suggests that posttranscriptional regulation of HDL biogenesis as well as modulation of ABCA1 expression are under the control of several genetic and epigenetic factors such as transcription factor (TFs), microRNAs (miRNAs) and RNA-binding proteins (RBPs).These factors may act either individually or in combination to orchestrate ABCA1 expression. Complementary to our recent work, we propose an exploratory model for the potential molecular mechanism(s) underlying epigenetic signature of ABCA1 gene regulation. Such a model may hopefully provide the basic framework for understanding the epigenetic regulation of RCT and contribute to the development of novel therapeutic strategies to alleviate the burden of cardiovascular diseases (CVD). View Full-Text   Abstract
Pulmonary arterial hypertension (PAH) is a progressive disease that requires validated biomarkers of disease severity. While PAH is defined hemodynamically by right heart catheterization (RHC), brain natriuretic peptide (BNP) is recommended by guidelines to assess disease status. Retrospectively collected data in 138 group 1 PAH patients were examined for the correlation of BNP levels to simultaneously obtained right heart catheterization (RHC). Patients were mostly Caucasian women, with functional class III symptoms, mean BNP of 406 ± 443 pg/mL, and an average right atrial pressure (RAP) of 9.9 ± 5.7 mm Hg and mean pulmonary artery pressure (mPAP) of 47.3 ± 14.7 mm Hg. Significant correlation was demonstrated between BNP and RAP (p = 0.021) and mPAP (p = 0.003). Additional correlation was seen with right heart size on echocardiography: right atrial (RAE; p = 0.04) and right ventricular enlargement (p = 0.03). An increased BNP level was an independent predictor of mortality (p < 0.0001), along with RAP (p = 0.039) and RAE (p = 0.018). Simultaneous collection of BNP at the time of RHC confirmed the correlation of BNP with right heart hemodynamics. The current results reinforce the use of BNP level as a continuous variable to assess disease severity in group 1 PAH. View Full-Text   Abstract
This study set out to evaluate self-medicated antibiotics and knowledge of antibiotic resistance among undergraduate students and community members in northern Nigeria. Antibiotic consumption pattern, source of prescription, illnesses commonly treated, attitude towards antibiotics, and knowledge of antibiotic resistance were explored using a structured questionnaire. Responses were analyzed and summarized using descriptive statistics. Of the 1230 respondents from undergraduate students and community members, prescription of antibiotics by a physician was 33% and 57%, respectively, amongst undergraduate students and community members. We tested the respondents’ knowledge of antibiotic resistance (ABR) and found that undergraduate students displayed less knowledge that self-medication could lead to ABR (32.6% and 42.2% respectively). Self-medication with antibiotics is highly prevalent in Northwest Nigeria, with most medicines being purchased from un-licensed stores without prescription from a physician. We also observed a significant gap in respondents’ knowledge of ABR. There is an urgent need for public health authorities in Nigeria to enforce existing laws on antibiotics sales and enlighten the people on the dangers of ABR. View Full-Text   hepatitis C virus,mixed cryoglobulinemia,interferon alpha,steroids,rituximab   ABCA1,HDL,miRNA,circular RNA,gene expression,RNA-binding proteins,reverse cholesterol transport,cardiovascular diseases   pulmonary arterial hypertension,brain natriuretic peptide,biomarkers,right heart catheterization,transthoracic echocardiogram   self-medication,antibiotic resistance,community,undergraduates ", Diseases 
,,,  ," Journal of Open Innovation: Technology, Market, and Complexity "
" Betulin-3,28-diphosphate as a Component of Combination Cytostatic Drugs for the Treatment of Ehrlich Ascites Carcinoma In Vitro and In Vivo Experiments   Ocular Delivery System for Propranolol Hydrochloride Based on Nanostructured Lipid Carrier   Novel Mutations in pncA Gene of Pyrazinamide Resistant Clinical Isolates of Mycobacterium tuberculosis   Honey Bee as Alternative Medicine to Treat Eleven Multidrug-Resistant Bacteria Causing Urinary Tract Infection during Pregnancy "," Abstract
The activity of betulin-3,28-diphosphate (BDP) in combination with the cytostatics such as 5-fluorouracil (5-FU) and hydrazine sulfate (HS) was demonstrated by using the transplanted Ehrlich ascites carcinoma (EAC) in mice. The dose-dependent effect of combination drugs BDP + HS and BDP + 5-FU was revealed by in vitro experiments on rats. The synergetic effect of HS and BDP on oxidative stress and energy metabolism was established. The malonic dialdehyde (MDA) level both in plasma and erythrocytes decreased by 87 ± 2%, and the superoxide dismutase (SOD) activity increased by 105 ± 7% in comparison with the control. The combination of BDP + HS promoted the increase of lactate dehydrogenase (LDH) activity in the reverse reaction by 195 ± 21% compared to the control. The combination drug of 5-FU with BDP caused the synergetic decrease of the lipid peroxidation (LPO) intensity estimated by the MDA level decrease up to 14 ± 4% compared to pure compounds. Betulin-3,28-diphosphate in combination with cytostatics for EAC treatment improved the animal health status, as well as decreased the cytostatics dose that can be used in palliative therapy. View Full-Text   Abstract
One drawback of traditional forms of medical ocular dosage is drug dilution by tear; moreover, drugs are rapidly drained away from pre-corneal cavity by tear flow and lacrimo-nasal drainage. Prolonging contact time with different strategies and mucoadhesive vehicles will help to continuously deliver drugs to the eyes. For this study, we prepared and evaluated the effects of a nanostructure lipid carrier (NLC) on propranolol hydrochloride as a hydrophilic drug model for rabbit corneal permeation. Propranolol hydrochloride NLC was prepared using cold homogenization. The lipid was melted, then the drug and surfactant were dispersed and stirred into the melted lipid. This fused lipid phase was scattered in aqueous solution containing the cosurfactant at 4 °C and then homogenized. We evaluated particle size, drug loading, drug release, and NLC permeability through rabbit cornea as well as the formula’s effect on the cornea. Our results show that drug loading efficiency depended on the surfactant/lipid ratio (S/L) and the percentages of liquid lipid and Transcutol (Gattefosse, Saint-Priest, France) (as solubilizer). Drug release data were evaluated with the Higuchi model and a significant correlation was shown between the S/L ratio and the amount of drug released after 4 and 48 h. NLC formulations improved propranolol hydrochloride permeation. We conclude that the effect of the NLC formulations was due to mucoadhesive and film forming properties. View Full-Text   Abstract
In clinical isolates of Mycobacterium tuberculosis (MTB), resistance to pyrazinamide occurs by mutations in any positions of the pncA gene (NC_000962.3) especially in nucleotides 359 and 374. In this study we examined the pncA gene sequence in clinical isolates of MTB. Genomic DNA of 33 clinical isolates of MTB was extracted by the Chelex100 method. The polymerase chain reactions (PCR) were performed using specific primers for amplification of 744 bp amplicon comprising the coding sequences (CDS) of the pncA gene. PCR products were sequenced by an automated sequencing Bioscience system. Additionally, semi Nested-allele specific (sNASP) and polymerase chain reaction-restriction fragment length polymorphism (PCR-RFLP) methods were carried out for verification of probable mutations in nucleotides 359 and 374. Sequencing results showed that from 33 MTB clinical isolates, nine pyrazinamide-resistant isolates have mutations. Furthermore, no mutation was detected in 24 susceptible strains in the entire 561 bp of the pncA gene. Moreover, new mutations of G→A at position 3 of the pncA gene were identified in some of the resistant isolates. Results showed that the sNASP method could detect mutations in nucleotide 359 and 374 of the pncA gene, but the PCR-RFLP method by the SacII enzyme could not detect these mutations. In conclusion, the identification of new mutations in the pncA gene confirmed the probable occurrence of mutations in any nucleotides of the pncA gene sequence in resistant isolates of MTB. View Full-Text   Abstract
Medicinal benefits of honey bee have been recognized in the medical community since ancient times as a remedy for many diseases and infections. This study aimed to investigate the in vitro susceptibility of 11 multidrug-resistant bacterial strains, isolated from urinary tract infections of pregnant women, to six honey samples collected from different localities in the east of Algeria. The evaluation of the antibacterial activity was performed by the well method followed by the broth dilution method using two-fold dilutions of each honey sample ranging from 2.5 to 80% (w/v). The results obtained in this study revealed that all tested honeys exhibited potent antibacterial activity against the tested strains. The diameters of inhibition ranged from 19.67 to 53.33 mm, with minimum inhibitory concentrations (MICs) ranging from 2.5 to 40% (w/v) and minimum bactericidal concentration (MBCs) varied between 2.5 and 80% (w/v). Gram-positive bacteria were found to be more susceptible than Gram-negative bacteria with diameters ranging from 43.33 to 53.33 mm; MIC and MBC values ranged from 2.5 to 5% (w/v). The P. aeruginosa strain was found to be less susceptible than other strains with inhibitory diameters ranging from 19.67 to 27.33 mm; MICs ranged from 20 to 40% and MBCs ranged from 20 to 80% (w/v). This contribution has provided a broad overview of the antibacterial activity of Algerian honey and shown that honey bee has great potential for therapeutic use as an alternative therapy for urinary tract infection treatment which is safe and efficient during pregnancy. View Full-Text "," Ehrlich carcinoma,betulin-3,28-diphosphate,5-fluorouracil,hydrazine sulfate,antioxidant activity   ocular,drug delivery,permeability,propranolol hydrochloride,nanostructured lipid carrier   Mycobacterium tuberculosis,pyrazinamide,mutation,polymerase chain reaction,sequencing   honey bee,urinary tract infections,pregnant women,antibacterial activity,alternative medicine "," Betulin-3,28-diphosphate as a Component of Combination Cytostatic Drugs for the Treatment of Ehrlich Ascites Carcinoma In Vitro and In Vivo Experiments   Ocular Delivery System for Propranolol Hydrochloride Based on Nanostructured Lipid Carrier   Novel Mutations in pncA Gene of Pyrazinamide Resistant Clinical Isolates of Mycobacterium tuberculosis   Honey Bee as Alternative Medicine to Treat Eleven Multidrug-Resistant Bacteria Causing Urinary Tract Infection during Pregnancy   Abstract
The activity of betulin-3,28-diphosphate (BDP) in combination with the cytostatics such as 5-fluorouracil (5-FU) and hydrazine sulfate (HS) was demonstrated by using the transplanted Ehrlich ascites carcinoma (EAC) in mice. The dose-dependent effect of combination drugs BDP + HS and BDP + 5-FU was revealed by in vitro experiments on rats. The synergetic effect of HS and BDP on oxidative stress and energy metabolism was established. The malonic dialdehyde (MDA) level both in plasma and erythrocytes decreased by 87 ± 2%, and the superoxide dismutase (SOD) activity increased by 105 ± 7% in comparison with the control. The combination of BDP + HS promoted the increase of lactate dehydrogenase (LDH) activity in the reverse reaction by 195 ± 21% compared to the control. The combination drug of 5-FU with BDP caused the synergetic decrease of the lipid peroxidation (LPO) intensity estimated by the MDA level decrease up to 14 ± 4% compared to pure compounds. Betulin-3,28-diphosphate in combination with cytostatics for EAC treatment improved the animal health status, as well as decreased the cytostatics dose that can be used in palliative therapy. View Full-Text   Abstract
One drawback of traditional forms of medical ocular dosage is drug dilution by tear; moreover, drugs are rapidly drained away from pre-corneal cavity by tear flow and lacrimo-nasal drainage. Prolonging contact time with different strategies and mucoadhesive vehicles will help to continuously deliver drugs to the eyes. For this study, we prepared and evaluated the effects of a nanostructure lipid carrier (NLC) on propranolol hydrochloride as a hydrophilic drug model for rabbit corneal permeation. Propranolol hydrochloride NLC was prepared using cold homogenization. The lipid was melted, then the drug and surfactant were dispersed and stirred into the melted lipid. This fused lipid phase was scattered in aqueous solution containing the cosurfactant at 4 °C and then homogenized. We evaluated particle size, drug loading, drug release, and NLC permeability through rabbit cornea as well as the formula’s effect on the cornea. Our results show that drug loading efficiency depended on the surfactant/lipid ratio (S/L) and the percentages of liquid lipid and Transcutol (Gattefosse, Saint-Priest, France) (as solubilizer). Drug release data were evaluated with the Higuchi model and a significant correlation was shown between the S/L ratio and the amount of drug released after 4 and 48 h. NLC formulations improved propranolol hydrochloride permeation. We conclude that the effect of the NLC formulations was due to mucoadhesive and film forming properties. View Full-Text   Abstract
In clinical isolates of Mycobacterium tuberculosis (MTB), resistance to pyrazinamide occurs by mutations in any positions of the pncA gene (NC_000962.3) especially in nucleotides 359 and 374. In this study we examined the pncA gene sequence in clinical isolates of MTB. Genomic DNA of 33 clinical isolates of MTB was extracted by the Chelex100 method. The polymerase chain reactions (PCR) were performed using specific primers for amplification of 744 bp amplicon comprising the coding sequences (CDS) of the pncA gene. PCR products were sequenced by an automated sequencing Bioscience system. Additionally, semi Nested-allele specific (sNASP) and polymerase chain reaction-restriction fragment length polymorphism (PCR-RFLP) methods were carried out for verification of probable mutations in nucleotides 359 and 374. Sequencing results showed that from 33 MTB clinical isolates, nine pyrazinamide-resistant isolates have mutations. Furthermore, no mutation was detected in 24 susceptible strains in the entire 561 bp of the pncA gene. Moreover, new mutations of G→A at position 3 of the pncA gene were identified in some of the resistant isolates. Results showed that the sNASP method could detect mutations in nucleotide 359 and 374 of the pncA gene, but the PCR-RFLP method by the SacII enzyme could not detect these mutations. In conclusion, the identification of new mutations in the pncA gene confirmed the probable occurrence of mutations in any nucleotides of the pncA gene sequence in resistant isolates of MTB. View Full-Text   Abstract
Medicinal benefits of honey bee have been recognized in the medical community since ancient times as a remedy for many diseases and infections. This study aimed to investigate the in vitro susceptibility of 11 multidrug-resistant bacterial strains, isolated from urinary tract infections of pregnant women, to six honey samples collected from different localities in the east of Algeria. The evaluation of the antibacterial activity was performed by the well method followed by the broth dilution method using two-fold dilutions of each honey sample ranging from 2.5 to 80% (w/v). The results obtained in this study revealed that all tested honeys exhibited potent antibacterial activity against the tested strains. The diameters of inhibition ranged from 19.67 to 53.33 mm, with minimum inhibitory concentrations (MICs) ranging from 2.5 to 40% (w/v) and minimum bactericidal concentration (MBCs) varied between 2.5 and 80% (w/v). Gram-positive bacteria were found to be more susceptible than Gram-negative bacteria with diameters ranging from 43.33 to 53.33 mm; MIC and MBC values ranged from 2.5 to 5% (w/v). The P. aeruginosa strain was found to be less susceptible than other strains with inhibitory diameters ranging from 19.67 to 27.33 mm; MICs ranged from 20 to 40% and MBCs ranged from 20 to 80% (w/v). This contribution has provided a broad overview of the antibacterial activity of Algerian honey and shown that honey bee has great potential for therapeutic use as an alternative therapy for urinary tract infection treatment which is safe and efficient during pregnancy. View Full-Text   Ehrlich carcinoma,betulin-3,28-diphosphate,5-fluorouracil,hydrazine sulfate,antioxidant activity   ocular,drug delivery,permeability,propranolol hydrochloride,nanostructured lipid carrier   Mycobacterium tuberculosis,pyrazinamide,mutation,polymerase chain reaction,sequencing   honey bee,urinary tract infections,pregnant women,antibacterial activity,alternative medicine ", Scientia Pharmaceutica 
 Lipidomic Profiling of Murine Macrophages Treated with Fatty Acids of Varying Chain Length and Saturation Status   Adipose Tissue Lactate Clearance but Not Blood Lactate Clearance Is Associated with Clinical Outcome in Sepsis or Septic Shock during the Post-Resuscitation Period   Pasture Feeding Changes the Bovine Rumen and Milk Metabolome   GC-MS Based Metabolomics and NMR Spectroscopy Investigation of Food Intake Biomarkers for Milk and Cheese in Serum of Healthy Humans ," Abstract
Macrophages are abundant within adipose tissue depots where they are exposed to fatty acids, leading to lipid accumulation. Herein, we have determined the effects of various fatty acids on the macrophage lipidome. Using targeted mass-spectrometry, we were able to detect 641 individual lipid species in primary murine macrophages treated with a variety of saturated fatty acids and an un-saturated fatty acid, either alone or in combination. The most pronounced effects were observed for the long-chain saturated fatty acid palmitate, which increased the total abundance of numerous classes of lipids. While other medium- and long-chain saturated fatty acids, as well as the long-chain unsaturated fatty acid, had less pronounced effects on the total abundance of specific lipid classes, all fatty acids induced marked alterations in the abundance of numerous lipid species within given lipid classes. Fatty acid treatment markedly altered overall phospholipid saturation status; these effects were most pronounced for phosphatidylcholine and ether-phosphatidylcholine lipid species. Finally, treatment of macrophages with either palmitate or stearate in combination with oleate prevented many of the changes that were observed in macrophages treated with palmitate or stearate alone. Collectively, our results reveal substantial and specific remodelling of the macrophage lipidome following treatment with fatty acids. View Full-Text   Abstract
No study has directly measured tissue lactate clearance in patients with sepsis during the post-resuscitation period. In this study we aimed to assess in ICU patients with sepsis (n = 32) or septic shock (n = 79)—during the post-resuscitation phase—the relative kinetics of blood/tissue lactate clearances and to examine whether these are associated with outcome. We measured serially—over a 48-h period—blood and adipose tissue interstitial fluid lactate levels (with microdialysis) and we calculated lactate clearance. Statistics included mixed model analysis, Friedman’s analysis of variance, Wilcoxon’s test, Mann-Whitney’s test, receiver operating characteristics curves and logistic regression. Forty patients died (28-day mortality rate = 28%). Tissue lactate clearance was higher compared to blood lactate clearance at 0–8, 0–12, 0–16, 0–20 and 0–24 h (all p < 0.05). Tissue lactate clearance was higher in survivors compared to non-survivors at 0–12, 0–20 and 0–24 h (all p = 0.02). APACHE II along with tissue lactate clearance <30% at 0–12, 0–20 and 0–24 h were independent outcome predictors. We did not find blood lactate clearance to be related to survival. Thus, in critically ill septic patients, elevated tissue (but not blood) lactate clearance, was associated with a favorable clinical outcome. View Full-Text   Abstract
The purpose of this study was to examine the effects of two pasture feeding systems—perennial ryegrass (GRS) and perennial ryegrass and white clover (CLV)—and an indoor total mixed ration (TMR) system on the (a) rumen microbiome; (b) rumen fluid and milk metabolome; and (c) to assess the potential to distinguish milk from different feeding systems by their respective metabolomes. Rumen fluid was collected from nine rumen cannulated cows under the different feeding systems in early, mid and late lactation, and raw milk samples were collected from ten non-cannulated cows in mid-lactation from each of the feeding systems. The microbiota present in rumen liquid and solid portions were analysed using 16S rRNA gene sequencing, while 1H-NMR untargeted metabolomic analysis was performed on rumen fluid and raw milk samples. The rumen microbiota composition was not found to be significantly altered by any feeding system in this study, likely as a result of a shortened adaptation period (two weeks’ exposure time). In contrast, feeding system had a significant effect on both the rumen and milk metabolome. Increased concentrations of volatile fatty acids including acetic acid, an important source of energy for the cow, were detected in the rumen of TMR and CLV-fed cows. Pasture feeding resulted in significantly higher concentrations of isoacids in the rumen. The ruminal fluids of both CLV and GRS-fed cows were found to have increased concentrations of p-cresol, a product of microbiome metabolism. CLV feeding resulted in increased rumen concentrations of formate, a substrate compound for methanogenesis. The TMR feeding resulted in significantly higher rumen choline content, which contributes to animal health and milk production, and succinate, a product of carbohydrate metabolism. Milk and rumen-fluids were shown to have varying levels of dimethyl sulfone in each feeding system, which was found to be an important compound for distinguishing between the diets. CLV feeding resulted in increased concentrations of milk urea. Milk from pasture-based feeding systems was shown to have significantly higher concentrations of hippuric acid, a potential biomarker of pasture-derived milk. This study has demonstrated that 1H-NMR metabolomics coupled with multivariate analysis is capable of distinguishing both rumen-fluid and milk derived from cows on different feeding systems, specifically between indoor TMR and pasture-based diets used in this study. View Full-Text   Abstract
The identification and validation of food intake biomarkers (FIBs) in human biofluids is a key objective for the evaluation of dietary intake. We report here the analysis of the GC-MS and 1H-NMR metabolomes of serum samples from a randomized cross-over study in 11 healthy volunteers having consumed isocaloric amounts of milk, cheese, and a soy drink as non-dairy alternative. Serum was collected at baseline, postprandially up to 6 h, and 24 h after consumption. A multivariate analysis of the untargeted serum metabolomes, combined with a targeted analysis of candidate FIBs previously reported in urine samples from the same study, identified galactitol, galactonate, and galactono-1,5-lactone (milk), 3-phenyllactic acid (cheese), and pinitol (soy drink) as candidate FIBs for these products. Serum metabolites not previously identified in the urine samples, e.g., 3-hydroxyisobutyrate after cheese intake, were detected. Finally, an analysis of the postprandial behavior of candidate FIBs, in particular the dairy fatty acids pentadecanoic acid and heptadecanoic acid, revealed specific kinetic patterns of relevance to their detection in future validation studies. Taken together, promising candidate FIBs for dairy intake appear to be lactose and metabolites thereof, for lactose-containing products, and microbial metabolites derived from amino acids, for fermented dairy products such as cheese. View Full-Text "," lipidomics,macrophages,fatty acids,obesity   microdialysis,intensive care unit,sepsis,lactate clearance,tissue hypoxia,outcome   cows diet,rumen,milk,metabolome,pasture,total mixed ration   biomarker,metabolomics,nutrition,serum metabolome,milk,cheese,soy drink "," Lipidomic Profiling of Murine Macrophages Treated with Fatty Acids of Varying Chain Length and Saturation Status   Adipose Tissue Lactate Clearance but Not Blood Lactate Clearance Is Associated with Clinical Outcome in Sepsis or Septic Shock during the Post-Resuscitation Period   Pasture Feeding Changes the Bovine Rumen and Milk Metabolome   GC-MS Based Metabolomics and NMR Spectroscopy Investigation of Food Intake Biomarkers for Milk and Cheese in Serum of Healthy Humans   Abstract
Macrophages are abundant within adipose tissue depots where they are exposed to fatty acids, leading to lipid accumulation. Herein, we have determined the effects of various fatty acids on the macrophage lipidome. Using targeted mass-spectrometry, we were able to detect 641 individual lipid species in primary murine macrophages treated with a variety of saturated fatty acids and an un-saturated fatty acid, either alone or in combination. The most pronounced effects were observed for the long-chain saturated fatty acid palmitate, which increased the total abundance of numerous classes of lipids. While other medium- and long-chain saturated fatty acids, as well as the long-chain unsaturated fatty acid, had less pronounced effects on the total abundance of specific lipid classes, all fatty acids induced marked alterations in the abundance of numerous lipid species within given lipid classes. Fatty acid treatment markedly altered overall phospholipid saturation status; these effects were most pronounced for phosphatidylcholine and ether-phosphatidylcholine lipid species. Finally, treatment of macrophages with either palmitate or stearate in combination with oleate prevented many of the changes that were observed in macrophages treated with palmitate or stearate alone. Collectively, our results reveal substantial and specific remodelling of the macrophage lipidome following treatment with fatty acids. View Full-Text   Abstract
No study has directly measured tissue lactate clearance in patients with sepsis during the post-resuscitation period. In this study we aimed to assess in ICU patients with sepsis (n = 32) or septic shock (n = 79)—during the post-resuscitation phase—the relative kinetics of blood/tissue lactate clearances and to examine whether these are associated with outcome. We measured serially—over a 48-h period—blood and adipose tissue interstitial fluid lactate levels (with microdialysis) and we calculated lactate clearance. Statistics included mixed model analysis, Friedman’s analysis of variance, Wilcoxon’s test, Mann-Whitney’s test, receiver operating characteristics curves and logistic regression. Forty patients died (28-day mortality rate = 28%). Tissue lactate clearance was higher compared to blood lactate clearance at 0–8, 0–12, 0–16, 0–20 and 0–24 h (all p < 0.05). Tissue lactate clearance was higher in survivors compared to non-survivors at 0–12, 0–20 and 0–24 h (all p = 0.02). APACHE II along with tissue lactate clearance <30% at 0–12, 0–20 and 0–24 h were independent outcome predictors. We did not find blood lactate clearance to be related to survival. Thus, in critically ill septic patients, elevated tissue (but not blood) lactate clearance, was associated with a favorable clinical outcome. View Full-Text   Abstract
The purpose of this study was to examine the effects of two pasture feeding systems—perennial ryegrass (GRS) and perennial ryegrass and white clover (CLV)—and an indoor total mixed ration (TMR) system on the (a) rumen microbiome; (b) rumen fluid and milk metabolome; and (c) to assess the potential to distinguish milk from different feeding systems by their respective metabolomes. Rumen fluid was collected from nine rumen cannulated cows under the different feeding systems in early, mid and late lactation, and raw milk samples were collected from ten non-cannulated cows in mid-lactation from each of the feeding systems. The microbiota present in rumen liquid and solid portions were analysed using 16S rRNA gene sequencing, while 1H-NMR untargeted metabolomic analysis was performed on rumen fluid and raw milk samples. The rumen microbiota composition was not found to be significantly altered by any feeding system in this study, likely as a result of a shortened adaptation period (two weeks’ exposure time). In contrast, feeding system had a significant effect on both the rumen and milk metabolome. Increased concentrations of volatile fatty acids including acetic acid, an important source of energy for the cow, were detected in the rumen of TMR and CLV-fed cows. Pasture feeding resulted in significantly higher concentrations of isoacids in the rumen. The ruminal fluids of both CLV and GRS-fed cows were found to have increased concentrations of p-cresol, a product of microbiome metabolism. CLV feeding resulted in increased rumen concentrations of formate, a substrate compound for methanogenesis. The TMR feeding resulted in significantly higher rumen choline content, which contributes to animal health and milk production, and succinate, a product of carbohydrate metabolism. Milk and rumen-fluids were shown to have varying levels of dimethyl sulfone in each feeding system, which was found to be an important compound for distinguishing between the diets. CLV feeding resulted in increased concentrations of milk urea. Milk from pasture-based feeding systems was shown to have significantly higher concentrations of hippuric acid, a potential biomarker of pasture-derived milk. This study has demonstrated that 1H-NMR metabolomics coupled with multivariate analysis is capable of distinguishing both rumen-fluid and milk derived from cows on different feeding systems, specifically between indoor TMR and pasture-based diets used in this study. View Full-Text   Abstract
The identification and validation of food intake biomarkers (FIBs) in human biofluids is a key objective for the evaluation of dietary intake. We report here the analysis of the GC-MS and 1H-NMR metabolomes of serum samples from a randomized cross-over study in 11 healthy volunteers having consumed isocaloric amounts of milk, cheese, and a soy drink as non-dairy alternative. Serum was collected at baseline, postprandially up to 6 h, and 24 h after consumption. A multivariate analysis of the untargeted serum metabolomes, combined with a targeted analysis of candidate FIBs previously reported in urine samples from the same study, identified galactitol, galactonate, and galactono-1,5-lactone (milk), 3-phenyllactic acid (cheese), and pinitol (soy drink) as candidate FIBs for these products. Serum metabolites not previously identified in the urine samples, e.g., 3-hydroxyisobutyrate after cheese intake, were detected. Finally, an analysis of the postprandial behavior of candidate FIBs, in particular the dairy fatty acids pentadecanoic acid and heptadecanoic acid, revealed specific kinetic patterns of relevance to their detection in future validation studies. Taken together, promising candidate FIBs for dairy intake appear to be lactose and metabolites thereof, for lactose-containing products, and microbial metabolites derived from amino acids, for fermented dairy products such as cheese. View Full-Text   lipidomics,macrophages,fatty acids,obesity   microdialysis,intensive care unit,sepsis,lactate clearance,tissue hypoxia,outcome   cows diet,rumen,milk,metabolome,pasture,total mixed ration   biomarker,metabolomics,nutrition,serum metabolome,milk,cheese,soy drink ", Metabolites 
" Accurate Mass Measurements for Planetary Microlensing Events Using High Angular Resolution Observations   String Sigma Models on Curved Supermanifolds   Perspectives on Constraining a Cosmological Constant-Type Parameter with Pulsar Timing in the Galactic Center   Scaling Properties of Spectra in New Exact Solutions of Rotating, Multi-Component Fireball Hydrodynamics "," Abstract
The microlensing technique is a unique method to hunt for cold planets over a range of mass and separation, orbiting all varieties of host stars in the disk of our galaxy. It provides precise mass-ratio and projected separations in units of the Einstein ring radius. In order to obtain the physical parameters (mass, distance, orbital separation) of the system, it is necessary to combine the result of light curve modeling with lens mass-distance relations and/or perform a Bayesian analysis with a galactic model. A first mass-distance relation could be obtained from a constraint on the Einstein ring radius if the crossing time of the source over the caustic is measured. It could then be supplemented by secondary constraints such as parallax measurements, ideally by using coinciding ground and space-born observations. These are still subject to degeneracies, like the orbital motion of the lens. A third mass-distance relation can be obtained thanks to constraints on the lens luminosity using high angular resolution observations with 8 m class telescopes or the Hubble Space Telescope. The latter route, although quite inexpensive in telescope time is very effective. If we have to rely heavily on Bayesian analysis and limited constraints on mass-distance relations, the physical parameters are determined to 30–40% typically. In a handful of cases, ground-space parallax is a powerful route to get stronger constraint on masses. High angular resolution observations will be able to constrain the luminosity of the lenses in the majority of the cases, and in favorable circumstances it is possible to derive physical parameters to 10% or better. Moreover, these constraints will be obtained in most of the planets to be discovered by the Euclid and WFIRST satellites. We describe here the state-of-the-art approaches to measure lens masses and distances with an emphasis on high angular resolution observations. We will discuss the challenges, recent results and perspectives. View Full-Text   Abstract
We use the techniques of integral forms to analyze the easiest example of two-dimensional sigma models on a supermanifold. We write the action as an integral of a top integral form over a
D=2
supermanifold, and we show how to interpolate between different superspace actions. Then, we consider curved supermanifolds, and we show that the definitions used for flat supermanifolds can also be used for curved supermanifolds. We prove it by first considering the case of a curved rigid supermanifold and then the case of a generic curved supermanifold described by a single superfield E. View Full-Text   Abstract
Independent tests aiming to constrain the value of the cosmological constant
Λ
are usually difficult because of its extreme smallness
(Λ≃1×
10
−52
m
−2
,or2.89×
10
−122
inPlanckunits)
. Bounds on it from Solar System orbital motions determined with spacecraft tracking are currently at the
≃
10
−43
–
10
−44
m
−2
(5
–
1×
10
−113
inPlanckunits)
level, but they may turn out to be optimistic since
Λ
has not yet been explicitly modeled in the planetary data reductions. Accurate
(
σ
τ
p
≃1
–
10μs)
timing of expected pulsars orbiting the Black Hole at the Galactic Center, preferably along highly eccentric and wide orbits, might, at least in principle, improve the planetary constraints by several orders of magnitude. By looking at the average time shift per orbit
Δδτ
¯
¯
¯
¯
¯
¯
Λ
p
, an S2-like orbital configuration with
e=0.8839,
P
b
=16yr
would permit a preliminarily upper bound of the order of
|Λ|≲9×
10
−47
m
−2
(≲2×
10
−116
inPlanckunits)
if only
σ
τ
p
were to be considered. Our results can be easily extended to modified models of gravity using
Λ
-type parameters. View Full-Text   Abstract
We describe fireballs that rehadronize from a perfect fluid of quark matter, characterized by the lattice QCD equation of state, to a chemically frozen, multi-component mixture, that contains various kinds of observable hadrons. For simplicity and clarity, we apply a non-relativistic approximation to describe the kinematics of this expansion. Unexpectedly, we identify a secondary explosion that may characterize fireball hydrodynamics at the QCD critical point. After rehadronization, the multi-component mixture of hadrons keeps on rotating and expanding together, similarly to a single component fluid. After kinetic freeze-out, the effective temperature
T
i
of the single-particle spectra of hadron type
h
i
is found to be a sum of the kinetic freeze-out temperature
T
f
(that is independent of the hadron type
h
i
) and a term proportional to the mass
m
i
of hadron type
h
i
. The coefficient of proportionality to
m
i
is found to be independent of the hadron type
h
i
but to be dependent on the radial flow and vorticity of collective dynamics. View Full-Text "," exoplanets,planetary systems,microlensing,adaptive optics   supermanifolds,sigma models,string models   astrophysical studies of gravity,general relativity,cosmological constant,neutron stars & pulsars,classical black holes   hydrodynamics,exact solution,quark-gluon plasma,hadronization,vorticity,radial flow "," Accurate Mass Measurements for Planetary Microlensing Events Using High Angular Resolution Observations   String Sigma Models on Curved Supermanifolds   Perspectives on Constraining a Cosmological Constant-Type Parameter with Pulsar Timing in the Galactic Center   Scaling Properties of Spectra in New Exact Solutions of Rotating, Multi-Component Fireball Hydrodynamics   Abstract
The microlensing technique is a unique method to hunt for cold planets over a range of mass and separation, orbiting all varieties of host stars in the disk of our galaxy. It provides precise mass-ratio and projected separations in units of the Einstein ring radius. In order to obtain the physical parameters (mass, distance, orbital separation) of the system, it is necessary to combine the result of light curve modeling with lens mass-distance relations and/or perform a Bayesian analysis with a galactic model. A first mass-distance relation could be obtained from a constraint on the Einstein ring radius if the crossing time of the source over the caustic is measured. It could then be supplemented by secondary constraints such as parallax measurements, ideally by using coinciding ground and space-born observations. These are still subject to degeneracies, like the orbital motion of the lens. A third mass-distance relation can be obtained thanks to constraints on the lens luminosity using high angular resolution observations with 8 m class telescopes or the Hubble Space Telescope. The latter route, although quite inexpensive in telescope time is very effective. If we have to rely heavily on Bayesian analysis and limited constraints on mass-distance relations, the physical parameters are determined to 30–40% typically. In a handful of cases, ground-space parallax is a powerful route to get stronger constraint on masses. High angular resolution observations will be able to constrain the luminosity of the lenses in the majority of the cases, and in favorable circumstances it is possible to derive physical parameters to 10% or better. Moreover, these constraints will be obtained in most of the planets to be discovered by the Euclid and WFIRST satellites. We describe here the state-of-the-art approaches to measure lens masses and distances with an emphasis on high angular resolution observations. We will discuss the challenges, recent results and perspectives. View Full-Text   Abstract
We use the techniques of integral forms to analyze the easiest example of two-dimensional sigma models on a supermanifold. We write the action as an integral of a top integral form over a
D=2
supermanifold, and we show how to interpolate between different superspace actions. Then, we consider curved supermanifolds, and we show that the definitions used for flat supermanifolds can also be used for curved supermanifolds. We prove it by first considering the case of a curved rigid supermanifold and then the case of a generic curved supermanifold described by a single superfield E. View Full-Text   Abstract
Independent tests aiming to constrain the value of the cosmological constant
Λ
are usually difficult because of its extreme smallness
(Λ≃1×
10
−52
m
−2
,or2.89×
10
−122
inPlanckunits)
. Bounds on it from Solar System orbital motions determined with spacecraft tracking are currently at the
≃
10
−43
–
10
−44
m
−2
(5
–
1×
10
−113
inPlanckunits)
level, but they may turn out to be optimistic since
Λ
has not yet been explicitly modeled in the planetary data reductions. Accurate
(
σ
τ
p
≃1
–
10μs)
timing of expected pulsars orbiting the Black Hole at the Galactic Center, preferably along highly eccentric and wide orbits, might, at least in principle, improve the planetary constraints by several orders of magnitude. By looking at the average time shift per orbit
Δδτ
¯
¯
¯
¯
¯
¯
Λ
p
, an S2-like orbital configuration with
e=0.8839,
P
b
=16yr
would permit a preliminarily upper bound of the order of
|Λ|≲9×
10
−47
m
−2
(≲2×
10
−116
inPlanckunits)
if only
σ
τ
p
were to be considered. Our results can be easily extended to modified models of gravity using
Λ
-type parameters. View Full-Text   Abstract
We describe fireballs that rehadronize from a perfect fluid of quark matter, characterized by the lattice QCD equation of state, to a chemically frozen, multi-component mixture, that contains various kinds of observable hadrons. For simplicity and clarity, we apply a non-relativistic approximation to describe the kinematics of this expansion. Unexpectedly, we identify a secondary explosion that may characterize fireball hydrodynamics at the QCD critical point. After rehadronization, the multi-component mixture of hadrons keeps on rotating and expanding together, similarly to a single component fluid. After kinetic freeze-out, the effective temperature
T
i
of the single-particle spectra of hadron type
h
i
is found to be a sum of the kinetic freeze-out temperature
T
f
(that is independent of the hadron type
h
i
) and a term proportional to the mass
m
i
of hadron type
h
i
. The coefficient of proportionality to
m
i
is found to be independent of the hadron type
h
i
but to be dependent on the radial flow and vorticity of collective dynamics. View Full-Text   exoplanets,planetary systems,microlensing,adaptive optics   supermanifolds,sigma models,string models   astrophysical studies of gravity,general relativity,cosmological constant,neutron stars & pulsars,classical black holes   hydrodynamics,exact solution,quark-gluon plasma,hadronization,vorticity,radial flow ", Universe 
,,,  , Fibers 
 Capture of Pb2+ and Cu2+ Metal Cations by Neisseria meningitidis-type Capsular Polysaccharides   11th IUBMB Focused Meeting on the Aminoacyl-tRNA Synthetases: Sailing a New Sea of Complex Functions in Human Biology and Disease   Circulating MicroRNA Biomarkers in Melanoma: Tools and Challenges in Personalised Medicine   Protein–Phospholipid Interaction Motifs: A Focus on Phosphatidic Acid ," Abstract
Heavy metal pollution of water is a significant environmental and public health concern. Current biological strategies for heavy metal removal from water are performed using microbial biopolymers, including polysaccharides, that are already fully formed. This creates limitations in adapting polysaccharides to increase binding affinity for specific metals. We propose that altering the specificity of polysaccharide-producing enzymes could be beneficial to improving metal capture by modified polysaccharides. We assess binding of Cu2+ and Pb2+ metal cations to Neisseria meningitidis-type polysaccharides. All concentrations of metal cations tested were able to completely bind to colominic acid. This polymer is equivalent to the capsular polysaccharide of N. meningitidis serogroup B comprised of a homopolymer of negatively charged sialic acid. There was slightly less binding observed with N. meningitidis serogroup W, which contains repeating units of the neutral sugar galactose and sialic acid. Our work represents the first assessment of the metal-binding properties of these capsular polysaccharides. Future work will seek to optimize metal-binding with Neisseria meningitidis serogroup W polysaccharide. View Full-Text   Abstract
The 11th IUBMB Focused Meeting on Aminoacyl-tRNA Synthetases was held in Clearwater Beach, Florida from 29 October–2 November 2017, with the aim of presenting the latest research on these enzymes and promoting interchange among aminoacyl-tRNA synthetase (ARS) researchers. Topics covered in the meeting included many areas of investigation, including ARS evolution, mechanism, editing functions, biology in prokaryotic and eukaryotic cells and their organelles, their roles in human diseases, and their application to problems in emerging areas of synthetic biology. In this report, we provide a summary of the major themes of the meeting, citing contributions from the oral presentations in the meeting. View Full-Text   Abstract
Effective management of melanoma depends heavily on early diagnosis. When detected in early non-metastatic stages, melanoma is almost 100% curable by surgical resection, however when detected in late metastatic stages III and IV, 5-year survival rates drop to ~50% and 10–25%, respectively, due to limited efficacy of current treatment options. This presents a pressing need to identify biomarkers that can detect patients at high risk of recurrence and progression to metastatic disease, which will allow for early intervention and survival benefit. Accumulating evidence over the past few decades has highlighted the potential use of circulating molecular biomarkers for melanoma diagnosis and prognosis, including lactate dehydrogenase (LDH), S100 calcium-binding protein B (S100B) and circulating tumor DNA (ctDNA) fragments. Since 2010, circulating microRNAs (miRNAs) have been increasingly recognised as more robust non-invasive biomarkers for melanoma due to their structural stability under the harsh conditions of the blood and different conditions of sample processing and isolation. Several pre-analytical and analytical variables challenge the accurate quantification of relative miRNA levels between serum samples or plasma samples, leading to conflicting findings between studies on circulating miRNA biomarkers for melanoma. In this review, we provide a critical summary of the circulating miRNA biomarkers for melanoma published to date. View Full-Text   Abstract
Cellular membranes are composed of thousands of different lipids usually maintained within a narrow range of concentrations. In addition to their well-known structural and metabolic roles, signaling functions for many lipids have also emerged over the last two decades. The latter largely depend on the ability of particular classes of lipids to interact specifically with a great variety of proteins and to regulate their localization and activity. Among these lipids, phosphatidic acid (PA) plays a unique role in a large repertoire of cellular activities, most likely in relation to its unique biophysical properties. However, until recently, only incomplete information was available to model the interaction between PA and its protein partners. The development of new liposome-based assays as well as molecular dynamic simulation are now providing novel information. We will review the different factors that have shown to modulate the capacity of PA to interact with specific domains in target proteins. View Full-Text "," capsular polysaccharide,Neisseria meningitidis,bioremediation,heavy metals   aminoacyl-tRNA synthetases,genetic code,translation,protein synthesis   melanoma,microRNAs,circulating biomarkers,diagnostic biomarkers,prognostic biomarkers,exosomes   interaction motif,lipid binding,membrane,phospholipase D,phosphatidic acid "," Capture of Pb2+ and Cu2+ Metal Cations by Neisseria meningitidis-type Capsular Polysaccharides   11th IUBMB Focused Meeting on the Aminoacyl-tRNA Synthetases: Sailing a New Sea of Complex Functions in Human Biology and Disease   Circulating MicroRNA Biomarkers in Melanoma: Tools and Challenges in Personalised Medicine   Protein–Phospholipid Interaction Motifs: A Focus on Phosphatidic Acid   Abstract
Heavy metal pollution of water is a significant environmental and public health concern. Current biological strategies for heavy metal removal from water are performed using microbial biopolymers, including polysaccharides, that are already fully formed. This creates limitations in adapting polysaccharides to increase binding affinity for specific metals. We propose that altering the specificity of polysaccharide-producing enzymes could be beneficial to improving metal capture by modified polysaccharides. We assess binding of Cu2+ and Pb2+ metal cations to Neisseria meningitidis-type polysaccharides. All concentrations of metal cations tested were able to completely bind to colominic acid. This polymer is equivalent to the capsular polysaccharide of N. meningitidis serogroup B comprised of a homopolymer of negatively charged sialic acid. There was slightly less binding observed with N. meningitidis serogroup W, which contains repeating units of the neutral sugar galactose and sialic acid. Our work represents the first assessment of the metal-binding properties of these capsular polysaccharides. Future work will seek to optimize metal-binding with Neisseria meningitidis serogroup W polysaccharide. View Full-Text   Abstract
The 11th IUBMB Focused Meeting on Aminoacyl-tRNA Synthetases was held in Clearwater Beach, Florida from 29 October–2 November 2017, with the aim of presenting the latest research on these enzymes and promoting interchange among aminoacyl-tRNA synthetase (ARS) researchers. Topics covered in the meeting included many areas of investigation, including ARS evolution, mechanism, editing functions, biology in prokaryotic and eukaryotic cells and their organelles, their roles in human diseases, and their application to problems in emerging areas of synthetic biology. In this report, we provide a summary of the major themes of the meeting, citing contributions from the oral presentations in the meeting. View Full-Text   Abstract
Effective management of melanoma depends heavily on early diagnosis. When detected in early non-metastatic stages, melanoma is almost 100% curable by surgical resection, however when detected in late metastatic stages III and IV, 5-year survival rates drop to ~50% and 10–25%, respectively, due to limited efficacy of current treatment options. This presents a pressing need to identify biomarkers that can detect patients at high risk of recurrence and progression to metastatic disease, which will allow for early intervention and survival benefit. Accumulating evidence over the past few decades has highlighted the potential use of circulating molecular biomarkers for melanoma diagnosis and prognosis, including lactate dehydrogenase (LDH), S100 calcium-binding protein B (S100B) and circulating tumor DNA (ctDNA) fragments. Since 2010, circulating microRNAs (miRNAs) have been increasingly recognised as more robust non-invasive biomarkers for melanoma due to their structural stability under the harsh conditions of the blood and different conditions of sample processing and isolation. Several pre-analytical and analytical variables challenge the accurate quantification of relative miRNA levels between serum samples or plasma samples, leading to conflicting findings between studies on circulating miRNA biomarkers for melanoma. In this review, we provide a critical summary of the circulating miRNA biomarkers for melanoma published to date. View Full-Text   Abstract
Cellular membranes are composed of thousands of different lipids usually maintained within a narrow range of concentrations. In addition to their well-known structural and metabolic roles, signaling functions for many lipids have also emerged over the last two decades. The latter largely depend on the ability of particular classes of lipids to interact specifically with a great variety of proteins and to regulate their localization and activity. Among these lipids, phosphatidic acid (PA) plays a unique role in a large repertoire of cellular activities, most likely in relation to its unique biophysical properties. However, until recently, only incomplete information was available to model the interaction between PA and its protein partners. The development of new liposome-based assays as well as molecular dynamic simulation are now providing novel information. We will review the different factors that have shown to modulate the capacity of PA to interact with specific domains in target proteins. View Full-Text   capsular polysaccharide,Neisseria meningitidis,bioremediation,heavy metals   aminoacyl-tRNA synthetases,genetic code,translation,protein synthesis   melanoma,microRNAs,circulating biomarkers,diagnostic biomarkers,prognostic biomarkers,exosomes   interaction motif,lipid binding,membrane,phospholipase D,phosphatidic acid ", Biomolecules 
 Robot Learning from Demonstration in Robotic Assembly: A Survey   Prediction Governors for Input-Affine Nonlinear Systems and Application to Automatic Driving Control   Cable Robot Performance Evaluation by Wrench Exertion Capability   An Underwater Image Enhancement Algorithm for Environment Recognition and Robot Navigation ," Abstract
Learning from demonstration (LfD) has been used to help robots to implement manipulation tasks autonomously, in particular, to learn manipulation behaviors from observing the motion executed by human demonstrators. This paper reviews recent research and development in the field of LfD. The main focus is placed on how to demonstrate the example behaviors to the robot in assembly operations, and how to extract the manipulation features for robot learning and generating imitative behaviors. Diverse metrics are analyzed to evaluate the performance of robot imitation learning. Specifically, the application of LfD in robotic assembly is a focal point in this paper. View Full-Text   Abstract
In recent years, automatic driving control has attracted attention. To achieve a satisfactory driving control performance, the prediction accuracy of the traveling route is important. If a highly accurate prediction method can be used, an accurate traveling route can be obtained. Despite the considerable efforts that have been invested in improving prediction methods, prediction errors do occur in general. Thus, a method to minimize the influence of prediction errors on automatic driving control systems is required. This need motivated us to focus on the design of a mechanism for shaping prediction signals, which is called a prediction governor. In this study, we first extended our previous study to the input-affine nonlinear system case. Then, we analytically derived a solution to an optimal design problem of prediction governors. Finally, we applied the solution to an automatic driving control system, and demonstrated its usefulness through a numerical example and an experiment using a radio controlled car. View Full-Text   Abstract
Although cable driven robots are a type of parallel manipulators, the evaluation of their performances cannot be carried out using the performance indices already developed for parallel robots with rigid links. This is an obvious consequence of the peculiar features of flexible cables—a cable can only exert a tensile and limited force in the direction of the cable itself. A comprehensive performance evaluation can certainly be attained by computing the maximum force (or torque) that can be exerted by the cables on the moving platform along a specific (or any) direction within the whole workspace. This is the idea behind the index—called the Wrench Exertion Capability (WEC)—which can be employed to evaluate the performance of any cable robot topology and is characterized by an efficient and simple formulation based on linear programming. By significantly improving a preliminary computation method for the WEC, this paper proposes an ultimate formulation suitable for any cable robot topology. Several numerical investigations on planar and spatial cable robots are presented to give evidence of the WEC usefulness, comparisons with popular performance indices are also provided. View Full-Text   Abstract
There are many tasks that require clear and easily recognizable images in the field of underwater robotics and marine science, such as underwater target detection and identification of robot navigation and obstacle avoidance. However, water turbidity makes the underwater image quality too low to recognize. This paper proposes the use of the dark channel prior model for underwater environment recognition, in which underwater reflection models are used to obtain enhanced images. The proposed approach achieves very good performance and multi-scene robustness by combining the dark channel prior model with the underwater diffuse model. The experimental results are given to show the effectiveness of the dark channel prior model in underwater scenarios. View Full-Text "," learning from demonstration,imitation learning,robotic assembly,machine learning   prediction,signal shaping,automatic driving control   cable driven robot,performance index,Wrench Exertion Capability   dark channel prior,underwater reflection models,underwater environment recognition,Image enhancement "," Robot Learning from Demonstration in Robotic Assembly: A Survey   Prediction Governors for Input-Affine Nonlinear Systems and Application to Automatic Driving Control   Cable Robot Performance Evaluation by Wrench Exertion Capability   An Underwater Image Enhancement Algorithm for Environment Recognition and Robot Navigation   Abstract
Learning from demonstration (LfD) has been used to help robots to implement manipulation tasks autonomously, in particular, to learn manipulation behaviors from observing the motion executed by human demonstrators. This paper reviews recent research and development in the field of LfD. The main focus is placed on how to demonstrate the example behaviors to the robot in assembly operations, and how to extract the manipulation features for robot learning and generating imitative behaviors. Diverse metrics are analyzed to evaluate the performance of robot imitation learning. Specifically, the application of LfD in robotic assembly is a focal point in this paper. View Full-Text   Abstract
In recent years, automatic driving control has attracted attention. To achieve a satisfactory driving control performance, the prediction accuracy of the traveling route is important. If a highly accurate prediction method can be used, an accurate traveling route can be obtained. Despite the considerable efforts that have been invested in improving prediction methods, prediction errors do occur in general. Thus, a method to minimize the influence of prediction errors on automatic driving control systems is required. This need motivated us to focus on the design of a mechanism for shaping prediction signals, which is called a prediction governor. In this study, we first extended our previous study to the input-affine nonlinear system case. Then, we analytically derived a solution to an optimal design problem of prediction governors. Finally, we applied the solution to an automatic driving control system, and demonstrated its usefulness through a numerical example and an experiment using a radio controlled car. View Full-Text   Abstract
Although cable driven robots are a type of parallel manipulators, the evaluation of their performances cannot be carried out using the performance indices already developed for parallel robots with rigid links. This is an obvious consequence of the peculiar features of flexible cables—a cable can only exert a tensile and limited force in the direction of the cable itself. A comprehensive performance evaluation can certainly be attained by computing the maximum force (or torque) that can be exerted by the cables on the moving platform along a specific (or any) direction within the whole workspace. This is the idea behind the index—called the Wrench Exertion Capability (WEC)—which can be employed to evaluate the performance of any cable robot topology and is characterized by an efficient and simple formulation based on linear programming. By significantly improving a preliminary computation method for the WEC, this paper proposes an ultimate formulation suitable for any cable robot topology. Several numerical investigations on planar and spatial cable robots are presented to give evidence of the WEC usefulness, comparisons with popular performance indices are also provided. View Full-Text   Abstract
There are many tasks that require clear and easily recognizable images in the field of underwater robotics and marine science, such as underwater target detection and identification of robot navigation and obstacle avoidance. However, water turbidity makes the underwater image quality too low to recognize. This paper proposes the use of the dark channel prior model for underwater environment recognition, in which underwater reflection models are used to obtain enhanced images. The proposed approach achieves very good performance and multi-scene robustness by combining the dark channel prior model with the underwater diffuse model. The experimental results are given to show the effectiveness of the dark channel prior model in underwater scenarios. View Full-Text   learning from demonstration,imitation learning,robotic assembly,machine learning   prediction,signal shaping,automatic driving control   cable driven robot,performance index,Wrench Exertion Capability   dark channel prior,underwater reflection models,underwater environment recognition,Image enhancement ", Robotics 
" Requirement of the Dynein-Adaptor Spindly for Mitotic and Post-Mitotic Functions in Drosophila   Wingless/Wnt Signaling in Intestinal Development, Homeostasis, Regeneration and Tumorigenesis: A Drosophila Perspective   Ethanol Exposure Causes Muscle Degeneration in Zebrafish   Imaging Neuronal Activity in the Optic Tectum of Late Stage Larval Zebrafish "," Abstract
Spindly was originally identified as a specific regulator of Dynein activity at the kinetochore. In early prometaphase, Spindly recruits the Dynein/Dynactin complex, promoting the establishment of stable kinetochore-microtubule interactions and progression into anaphase. While details of Spindly function in mitosis have been worked out in cultured human cells and in the C. elegans zygote, the function of Spindly within the context of an organism has not yet been addressed. Here, we present loss- and gain-of-function studies of Spindly using transgenic RNAi in Drosophila. Knock-down of Spindly in the female germ line results in mitotic arrest during embryonic cleavage divisions. We investigated the requirements of Spindly protein domains for its localisation and function, and found that the carboxy-terminal region controls Spindly localisation in a cell-type specific manner. Overexpression of Spindly in the female germ line is embryonic lethal and results in altered egg morphology. To determine whether Spindly plays a role in post-mitotic cells, we altered Spindly protein levels in migrating cells and found that ovarian border cell migration is sensitive to the levels of Spindly protein. Our study uncovers novel functions of Spindly and a differential, functional requirement for its carboxy-terminal region in Drosophila. View Full-Text   Abstract
In mammals, the Wnt/β-catenin signal transduction pathway regulates intestinal stem cell maintenance and proliferation, whereas Wnt pathway hyperactivation, resulting primarily from the inactivation of the tumor suppressor Adenomatous polyposis coli (APC), triggers the development of the vast majority of colorectal cancers. The Drosophila adult gut has recently emerged as a powerful model to elucidate the mechanisms by which Wingless/Wnt signaling regulates intestinal development, homeostasis, regeneration, and tumorigenesis. Herein, we review recent insights on the roles of Wnt signaling in Drosophila intestinal physiology and pathology. View Full-Text   Abstract
Alcoholic myopathies are characterized by neuromusculoskeletal symptoms such as compromised movement and weakness. Although these symptoms have been attributed to neurological damage, EtOH may also target skeletal muscle. EtOH exposure during zebrafish primary muscle development or adulthood results in smaller muscle fibers. However, the effects of EtOH exposure on skeletal muscle during the growth period that follows primary muscle development are not well understood. We determined the effects of EtOH exposure on muscle during this phase of development. Strikingly, muscle fibers at this stage are acutely sensitive to EtOH treatment: EtOH induces muscle degeneration. The severity of EtOH-induced muscle damage varies but muscle becomes more refractory to EtOH as muscle develops. NF-kB induction in muscle indicates that EtOH triggers a pro-inflammatory response. EtOH-induced muscle damage is p53-independent. Uptake of Evans blue dye shows that EtOH treatment causes sarcolemmal instability before muscle fiber detachment. Dystrophin-null sapje mutant zebrafish also exhibit sarcolemmal instability. We tested whether Trichostatin A (TSA), which reduces muscle degeneration in sapje mutants, would affect EtOH-treated zebrafish. We found that TSA and EtOH are a lethal combination. EtOH does, however, exacerbate muscle degeneration in sapje mutants. EtOH also disrupts adhesion of muscle fibers to their extracellular matrix at the myotendinous junction: some detached muscle fibers retain beta-Dystroglycan indicating failure of muscle end attachments. Overexpression of Paxillin, which reduces muscle degeneration in zebrafish deficient for beta-Dystroglycan, is not sufficient to rescue degeneration. Taken together, our results suggest that EtOH exposure has pleiotropic deleterious effects on skeletal muscle. View Full-Text   Abstract
The zebrafish is an established model to study the development and function of visual neuronal circuits in vivo, largely due to their optical accessibility at embryonic and larval stages. In the past decade multiple experimental paradigms have been developed to study visually-driven behaviours, particularly those regulated by the optic tectum, the main visual centre in lower vertebrates. With few exceptions these techniques are limited to young larvae (7–9 days post-fertilisation, dpf). However, many forms of visually-driven behaviour, such as shoaling, emerge at later developmental stages. Consequently, there is a need for an experimental paradigm to image the visual system in zebrafish larvae beyond 9 dpf. Here, we show that using NBT:GCaMP3 line allows for imaging neuronal activity in the optic tectum in late stage larvae until at least 21 dpf. Utilising this line, we have characterised the receptive field properties of tectal neurons of the 2–3 weeks old fish in the cell bodies and the neuropil. The NBT:GCaMP3 line provides a complementary approach and additional opportunities to study neuronal activity in late stage zebrafish larvae. View Full-Text "," Drosophila,mitosis,cell migration,mitotic spindle,Dynein   Wnt/Wingless signaling,Drosophila gut,animal model,intestinal physiology and pathology,Adenomatous polyposis coli (APC),colorectal cancer   zebrafish,muscle,ethanol,alcohol,myopathy,fetal alcohol spectrum disorder,muscular dystrophy,Paxillin   zebrafish,calcium imaging,neuronal activity "," Requirement of the Dynein-Adaptor Spindly for Mitotic and Post-Mitotic Functions in Drosophila   Wingless/Wnt Signaling in Intestinal Development, Homeostasis, Regeneration and Tumorigenesis: A Drosophila Perspective   Ethanol Exposure Causes Muscle Degeneration in Zebrafish   Imaging Neuronal Activity in the Optic Tectum of Late Stage Larval Zebrafish   Abstract
Spindly was originally identified as a specific regulator of Dynein activity at the kinetochore. In early prometaphase, Spindly recruits the Dynein/Dynactin complex, promoting the establishment of stable kinetochore-microtubule interactions and progression into anaphase. While details of Spindly function in mitosis have been worked out in cultured human cells and in the C. elegans zygote, the function of Spindly within the context of an organism has not yet been addressed. Here, we present loss- and gain-of-function studies of Spindly using transgenic RNAi in Drosophila. Knock-down of Spindly in the female germ line results in mitotic arrest during embryonic cleavage divisions. We investigated the requirements of Spindly protein domains for its localisation and function, and found that the carboxy-terminal region controls Spindly localisation in a cell-type specific manner. Overexpression of Spindly in the female germ line is embryonic lethal and results in altered egg morphology. To determine whether Spindly plays a role in post-mitotic cells, we altered Spindly protein levels in migrating cells and found that ovarian border cell migration is sensitive to the levels of Spindly protein. Our study uncovers novel functions of Spindly and a differential, functional requirement for its carboxy-terminal region in Drosophila. View Full-Text   Abstract
In mammals, the Wnt/β-catenin signal transduction pathway regulates intestinal stem cell maintenance and proliferation, whereas Wnt pathway hyperactivation, resulting primarily from the inactivation of the tumor suppressor Adenomatous polyposis coli (APC), triggers the development of the vast majority of colorectal cancers. The Drosophila adult gut has recently emerged as a powerful model to elucidate the mechanisms by which Wingless/Wnt signaling regulates intestinal development, homeostasis, regeneration, and tumorigenesis. Herein, we review recent insights on the roles of Wnt signaling in Drosophila intestinal physiology and pathology. View Full-Text   Abstract
Alcoholic myopathies are characterized by neuromusculoskeletal symptoms such as compromised movement and weakness. Although these symptoms have been attributed to neurological damage, EtOH may also target skeletal muscle. EtOH exposure during zebrafish primary muscle development or adulthood results in smaller muscle fibers. However, the effects of EtOH exposure on skeletal muscle during the growth period that follows primary muscle development are not well understood. We determined the effects of EtOH exposure on muscle during this phase of development. Strikingly, muscle fibers at this stage are acutely sensitive to EtOH treatment: EtOH induces muscle degeneration. The severity of EtOH-induced muscle damage varies but muscle becomes more refractory to EtOH as muscle develops. NF-kB induction in muscle indicates that EtOH triggers a pro-inflammatory response. EtOH-induced muscle damage is p53-independent. Uptake of Evans blue dye shows that EtOH treatment causes sarcolemmal instability before muscle fiber detachment. Dystrophin-null sapje mutant zebrafish also exhibit sarcolemmal instability. We tested whether Trichostatin A (TSA), which reduces muscle degeneration in sapje mutants, would affect EtOH-treated zebrafish. We found that TSA and EtOH are a lethal combination. EtOH does, however, exacerbate muscle degeneration in sapje mutants. EtOH also disrupts adhesion of muscle fibers to their extracellular matrix at the myotendinous junction: some detached muscle fibers retain beta-Dystroglycan indicating failure of muscle end attachments. Overexpression of Paxillin, which reduces muscle degeneration in zebrafish deficient for beta-Dystroglycan, is not sufficient to rescue degeneration. Taken together, our results suggest that EtOH exposure has pleiotropic deleterious effects on skeletal muscle. View Full-Text   Abstract
The zebrafish is an established model to study the development and function of visual neuronal circuits in vivo, largely due to their optical accessibility at embryonic and larval stages. In the past decade multiple experimental paradigms have been developed to study visually-driven behaviours, particularly those regulated by the optic tectum, the main visual centre in lower vertebrates. With few exceptions these techniques are limited to young larvae (7–9 days post-fertilisation, dpf). However, many forms of visually-driven behaviour, such as shoaling, emerge at later developmental stages. Consequently, there is a need for an experimental paradigm to image the visual system in zebrafish larvae beyond 9 dpf. Here, we show that using NBT:GCaMP3 line allows for imaging neuronal activity in the optic tectum in late stage larvae until at least 21 dpf. Utilising this line, we have characterised the receptive field properties of tectal neurons of the 2–3 weeks old fish in the cell bodies and the neuropil. The NBT:GCaMP3 line provides a complementary approach and additional opportunities to study neuronal activity in late stage zebrafish larvae. View Full-Text   Drosophila,mitosis,cell migration,mitotic spindle,Dynein   Wnt/Wingless signaling,Drosophila gut,animal model,intestinal physiology and pathology,Adenomatous polyposis coli (APC),colorectal cancer   zebrafish,muscle,ethanol,alcohol,myopathy,fetal alcohol spectrum disorder,muscular dystrophy,Paxillin   zebrafish,calcium imaging,neuronal activity ", Journal of Developmental Biology 
" Phenotypic and Physiological Evaluation of Two and Six Rows Barley under Different Environmental Conditions   Examination of S-Locus Regulated Differential Expression in Primula vulgaris Floral Development   Assessment of Sulfur Deficiency under Field Conditions by Single Measurements of Sulfur, Chloride and Phosphorus in Mature Leaves   Treatment of Anaerobic Digester Effluent Using Acorus calamus: Effects on Plant Growth and Tissue Composition "," Abstract
In recent years, barley has attracted more interest as a food and feed source because of its high soluble dietary fiber and β-glucan content compared with other small grains. Twenty-five barley genotypes (20 imported genotypes and five check cultivars) were grown in three environments for two successive seasons: 2015/2016 and 2016/2017. The first environment was in El-Nubaria, Alexandria, Egypt during 2015/2016, while the second and third environments were in El-Bostan, Elbhera, Egypt during 2015/2016 and 2016/2017. The experiments were conducted in a randomized complete block design with the three replicates. The primary objectives of the current study were to evaluate the performance of 20 imported barley genotypes under several environmental conditions. The imported materials were superior to the local commercial cultivars for several traits, including grain yield. Therefore, the superior genotypes will be further evaluated and used in barley breeding programs. Our future work will focus on creating several crosses among the selected superior genotypes to improve yield and other important traits, while applying marker-assisted selection. View Full-Text   Abstract
Recent findings on the molecular basis of heteromorphic self-incompatibility in Primula have shown that the controlling self-incompatibility (S)-locus is not allelic, but is instead a small hemizygous region of only a few genes in the thrum genotype. How these genes alter the development of floral morphology and the specificity of self-incompatibility is still not completely clear. In order to start to identify genes regulated by the S-locus and elucidate the large-scale biological processes affected, we used RNA-seq data from floral buds of heteromorphic P. vulgaris pin (long style, short anthers) and thrum (short style, long anthers) morphs at early and late developmental time points. Differential expression between the two morphs was assessed at both time points and Gene Ontology term analyses of these gene sets were conducted. Our findings suggest that the S-locus regulates a large number of genes outside its physical bounds and likely sets up a cascade of expression changes. Additionally, we found evidence to suggest that there may be a timing difference in pollen development between the morphs, with pin pollen development proceeding earlier than thrum pollen development. This finding provides insight into how morphological differences in pollen between the morphs may be established, but intriguingly, could also be related to the self-incompatibility phenotype. View Full-Text   Abstract
Determination of S status is very important to detect S deficiency and prevent losses of yield and seed quality. The aim of this study was to investigate the possibility of using the ([Cl−]+[NO3−]+[PO43−]):[SO42−] ratio as an indicator of S nutrition under field conditions in Brassica napus and whether this could be applied to other species. Different S and nitrogen (N) fertilizations were applied on a S deficient field of oilseed rape to harvest mature leaves and analyze their anion and element contents in order to evaluate a new S nutrition indicator and useful threshold values. Large sets of commercial varieties were then used to test S deficiency scenarios. As main results, this study shown that, under field conditions, leaf ([Cl−]+[NO3−]+[PO43−]):[SO42−] ratio was increased by lowering S fertilization, indicating S deficiency. The usefulness of this ratio was also found for other species grown under controlled conditions and it could be simplified by using the elemental ([Cl]+[P]):[S] ratio. Threshold values were determined and used for the clustering of commercial varieties within three groups: S deficient, at risk of S deficiency and S sufficient. The ([Cl]+[P]):[S] ratio quantified under field conditions, can be used as an early and accurate diagnostic tool to manage S fertilization. View Full-Text   Abstract
The responses of Acorus calamus under greenhouse conditions for 56 days when exposed to three dilutions (25%, 50%, and undiluted) of anaerobic digester effluent from a swine farm were determined. Plant growth, morphology, pigments, and minerals in plant tissues as well as water quality were investigated. The plants grew well in all concentrations of anaerobic digester effluent with no statistically significant effects on plant growth and morphology, and without any toxicity symptoms. The NH4+ concentrations in leaves and roots and the NO3− concentrations in leaves as well as the nitrogen, phosphorus, and potassium concentrations in the plant tissues increased with increasing effluent concentration. The nutrients in the anaerobic digester effluent were removed effectively (NH4-N > 99% removal; PO4-P > 80% removal), with highest removal rates in the undiluted digester effluent. The removal of total suspended solids (>80% in 42 days) and chemical oxygen demand (37–53%) were lower. The dissolved oxygen concentration in the anaerobic digester effluent increased overtime, probably because of root oxygen release. It is concluded that Acorus calamus could be a promising species for treating high-strength wastewater with high nutrient concentrations, such as effluents from anaerobic digesters as well as other types of agricultural wastewaters. View Full-Text "," imported barley,evaluation,genotypes,biotic stress,pre-breeding   Primula,heteromorphic self-incompatibility,RNA-seq,S-locus,flower development   Brassica napus,diagnostic tools,indicator of S nutrition,S fertilization,Triticum aestivum,Zea mays   Acorus calamus,nutrient removal,sweet flag,swine wastewater "," Phenotypic and Physiological Evaluation of Two and Six Rows Barley under Different Environmental Conditions   Examination of S-Locus Regulated Differential Expression in Primula vulgaris Floral Development   Assessment of Sulfur Deficiency under Field Conditions by Single Measurements of Sulfur, Chloride and Phosphorus in Mature Leaves   Treatment of Anaerobic Digester Effluent Using Acorus calamus: Effects on Plant Growth and Tissue Composition   Abstract
In recent years, barley has attracted more interest as a food and feed source because of its high soluble dietary fiber and β-glucan content compared with other small grains. Twenty-five barley genotypes (20 imported genotypes and five check cultivars) were grown in three environments for two successive seasons: 2015/2016 and 2016/2017. The first environment was in El-Nubaria, Alexandria, Egypt during 2015/2016, while the second and third environments were in El-Bostan, Elbhera, Egypt during 2015/2016 and 2016/2017. The experiments were conducted in a randomized complete block design with the three replicates. The primary objectives of the current study were to evaluate the performance of 20 imported barley genotypes under several environmental conditions. The imported materials were superior to the local commercial cultivars for several traits, including grain yield. Therefore, the superior genotypes will be further evaluated and used in barley breeding programs. Our future work will focus on creating several crosses among the selected superior genotypes to improve yield and other important traits, while applying marker-assisted selection. View Full-Text   Abstract
Recent findings on the molecular basis of heteromorphic self-incompatibility in Primula have shown that the controlling self-incompatibility (S)-locus is not allelic, but is instead a small hemizygous region of only a few genes in the thrum genotype. How these genes alter the development of floral morphology and the specificity of self-incompatibility is still not completely clear. In order to start to identify genes regulated by the S-locus and elucidate the large-scale biological processes affected, we used RNA-seq data from floral buds of heteromorphic P. vulgaris pin (long style, short anthers) and thrum (short style, long anthers) morphs at early and late developmental time points. Differential expression between the two morphs was assessed at both time points and Gene Ontology term analyses of these gene sets were conducted. Our findings suggest that the S-locus regulates a large number of genes outside its physical bounds and likely sets up a cascade of expression changes. Additionally, we found evidence to suggest that there may be a timing difference in pollen development between the morphs, with pin pollen development proceeding earlier than thrum pollen development. This finding provides insight into how morphological differences in pollen between the morphs may be established, but intriguingly, could also be related to the self-incompatibility phenotype. View Full-Text   Abstract
Determination of S status is very important to detect S deficiency and prevent losses of yield and seed quality. The aim of this study was to investigate the possibility of using the ([Cl−]+[NO3−]+[PO43−]):[SO42−] ratio as an indicator of S nutrition under field conditions in Brassica napus and whether this could be applied to other species. Different S and nitrogen (N) fertilizations were applied on a S deficient field of oilseed rape to harvest mature leaves and analyze their anion and element contents in order to evaluate a new S nutrition indicator and useful threshold values. Large sets of commercial varieties were then used to test S deficiency scenarios. As main results, this study shown that, under field conditions, leaf ([Cl−]+[NO3−]+[PO43−]):[SO42−] ratio was increased by lowering S fertilization, indicating S deficiency. The usefulness of this ratio was also found for other species grown under controlled conditions and it could be simplified by using the elemental ([Cl]+[P]):[S] ratio. Threshold values were determined and used for the clustering of commercial varieties within three groups: S deficient, at risk of S deficiency and S sufficient. The ([Cl]+[P]):[S] ratio quantified under field conditions, can be used as an early and accurate diagnostic tool to manage S fertilization. View Full-Text   Abstract
The responses of Acorus calamus under greenhouse conditions for 56 days when exposed to three dilutions (25%, 50%, and undiluted) of anaerobic digester effluent from a swine farm were determined. Plant growth, morphology, pigments, and minerals in plant tissues as well as water quality were investigated. The plants grew well in all concentrations of anaerobic digester effluent with no statistically significant effects on plant growth and morphology, and without any toxicity symptoms. The NH4+ concentrations in leaves and roots and the NO3− concentrations in leaves as well as the nitrogen, phosphorus, and potassium concentrations in the plant tissues increased with increasing effluent concentration. The nutrients in the anaerobic digester effluent were removed effectively (NH4-N > 99% removal; PO4-P > 80% removal), with highest removal rates in the undiluted digester effluent. The removal of total suspended solids (>80% in 42 days) and chemical oxygen demand (37–53%) were lower. The dissolved oxygen concentration in the anaerobic digester effluent increased overtime, probably because of root oxygen release. It is concluded that Acorus calamus could be a promising species for treating high-strength wastewater with high nutrient concentrations, such as effluents from anaerobic digesters as well as other types of agricultural wastewaters. View Full-Text   imported barley,evaluation,genotypes,biotic stress,pre-breeding   Primula,heteromorphic self-incompatibility,RNA-seq,S-locus,flower development   Brassica napus,diagnostic tools,indicator of S nutrition,S fertilization,Triticum aestivum,Zea mays   Acorus calamus,nutrient removal,sweet flag,swine wastewater ", Plants 
 Performance Analysis of a 3D Wireless Massively Parallel Computer   Reduced Complexity Detection in MIMO Systems with SC-FDE Modulations and Iterative DFE Receivers   Virtual Replication of IoT Hubs in the Cloud: A Flexible Approach to Smart Object Management ," Abstract
In previous work, the authors presented a 3D hexagonal wireless direct-interconnect network for a massively parallel computer, with a focus on analysing processor utilisation. In this study, we consider the characteristics of such an architecture in terms of link utilisation and power consumption. We have applied a store-and-forward packet-switching algorithm to both our proposed architecture and a traditional wired 5D direct network (the same as IBM’s Blue Gene). Simulations show that for small and medium-size networks the link utility of the proposed architecture is comparable with (and in some cases even better than) traditional 5D networks. This work demonstrates that there is a potential for wireless processing array concepts to address High-Performance Computing (HPC) challenges whilst alleviating some significant physical construction drawbacks of traditional systems. View Full-Text   Abstract
This paper considers a Multiple-Input Multiple-Output (MIMO) system with P transmitting and R receiving antennas and different overall noise characteristics on the different receiver antennas (e.g., due to nonlinear effects at the receiver side). Each communication link employs a Single-Carrier with Frequency-Domain Equalization (SC-FDE) modulation scheme, and the receiver is based on robust iterative frequency-domain multi-user detectors based on the Iterative Block Decision Feedback Equalization (IB-DFE) concept. We present low complexity efficient receivers that can employ low resolution Analog-to-Digital Converters (ADCs) and require the inversion of matrices with reduced dimension when the number of receive antennas is larger than the number of independent data streams. The advantages of the proposed techniques are particularly high for highly unbalanced MIMO systems, such as in the uplink of Base Station (BS) cooperation systems that aim for Single-Frequency Network (SFN) operation or massive MIMO systems with much more antennas at the receiver side. View Full-Text   Abstract
In future years, the Internet of Things is expected to interconnect billions of highly heterogeneous devices, denoted as “smart objects”, enabling the development of innovative distributed applications. Smart objects are constrained sensor/actuator-equipped devices, in terms of computational power and available memory. In order to cope with the diverse physical connectivity technologies of smart objects, the Internet Protocol is foreseen as the common “language” for full interoperability and as a unifying factor for integration with the Internet. Large-scale platforms for interconnected devices are required to effectively manage resources provided by smart objects. In this work, we present a novel architecture for the management of large numbers of resources in a scalable, seamless, and secure way. The proposed architecture is based on a network element, denoted as IoT Hub, placed at the border of the constrained network, which implements the following functions: service discovery; border router; HTTP/Constrained Application Protocol (CoAP) and CoAP/CoAP proxy; cache; and resource directory. In order to protect smart objects (which cannot, because of their constrained nature, serve a large number of concurrent requests) and the IoT Hub (which serves as a gateway to the constrained network), we introduce the concept of virtual IoT Hub replica: a Cloud-based “entity” replicating all the functions of a physical IoT Hub, which external clients will query to access resources. IoT Hub replicas are constantly synchronized with the physical IoT Hub through a low-overhead protocol based on Message Queue Telemetry Transport (MQTT). An experimental evaluation, proving the feasibility and advantages of the proposed architecture, is presented. View Full-Text "," wireless networks,packet-switching,buffer management,on-chip radio communication,parallel computing,interconnect network,link utility,power consumption   MIMO,nonlinear effects,SC-FDE,IB-DFE   Internet of Things,edge computing,cloud computing "," Performance Analysis of a 3D Wireless Massively Parallel Computer   Reduced Complexity Detection in MIMO Systems with SC-FDE Modulations and Iterative DFE Receivers   Virtual Replication of IoT Hubs in the Cloud: A Flexible Approach to Smart Object Management   Abstract
In previous work, the authors presented a 3D hexagonal wireless direct-interconnect network for a massively parallel computer, with a focus on analysing processor utilisation. In this study, we consider the characteristics of such an architecture in terms of link utilisation and power consumption. We have applied a store-and-forward packet-switching algorithm to both our proposed architecture and a traditional wired 5D direct network (the same as IBM’s Blue Gene). Simulations show that for small and medium-size networks the link utility of the proposed architecture is comparable with (and in some cases even better than) traditional 5D networks. This work demonstrates that there is a potential for wireless processing array concepts to address High-Performance Computing (HPC) challenges whilst alleviating some significant physical construction drawbacks of traditional systems. View Full-Text   Abstract
This paper considers a Multiple-Input Multiple-Output (MIMO) system with P transmitting and R receiving antennas and different overall noise characteristics on the different receiver antennas (e.g., due to nonlinear effects at the receiver side). Each communication link employs a Single-Carrier with Frequency-Domain Equalization (SC-FDE) modulation scheme, and the receiver is based on robust iterative frequency-domain multi-user detectors based on the Iterative Block Decision Feedback Equalization (IB-DFE) concept. We present low complexity efficient receivers that can employ low resolution Analog-to-Digital Converters (ADCs) and require the inversion of matrices with reduced dimension when the number of receive antennas is larger than the number of independent data streams. The advantages of the proposed techniques are particularly high for highly unbalanced MIMO systems, such as in the uplink of Base Station (BS) cooperation systems that aim for Single-Frequency Network (SFN) operation or massive MIMO systems with much more antennas at the receiver side. View Full-Text   Abstract
In future years, the Internet of Things is expected to interconnect billions of highly heterogeneous devices, denoted as “smart objects”, enabling the development of innovative distributed applications. Smart objects are constrained sensor/actuator-equipped devices, in terms of computational power and available memory. In order to cope with the diverse physical connectivity technologies of smart objects, the Internet Protocol is foreseen as the common “language” for full interoperability and as a unifying factor for integration with the Internet. Large-scale platforms for interconnected devices are required to effectively manage resources provided by smart objects. In this work, we present a novel architecture for the management of large numbers of resources in a scalable, seamless, and secure way. The proposed architecture is based on a network element, denoted as IoT Hub, placed at the border of the constrained network, which implements the following functions: service discovery; border router; HTTP/Constrained Application Protocol (CoAP) and CoAP/CoAP proxy; cache; and resource directory. In order to protect smart objects (which cannot, because of their constrained nature, serve a large number of concurrent requests) and the IoT Hub (which serves as a gateway to the constrained network), we introduce the concept of virtual IoT Hub replica: a Cloud-based “entity” replicating all the functions of a physical IoT Hub, which external clients will query to access resources. IoT Hub replicas are constantly synchronized with the physical IoT Hub through a low-overhead protocol based on Message Queue Telemetry Transport (MQTT). An experimental evaluation, proving the feasibility and advantages of the proposed architecture, is presented. View Full-Text   wireless networks,packet-switching,buffer management,on-chip radio communication,parallel computing,interconnect network,link utility,power consumption   MIMO,nonlinear effects,SC-FDE,IB-DFE   Internet of Things,edge computing,cloud computing ", Journal of Sensor and Actuator Networks 
 Forecasting Inflation Uncertainty in the G7 Countries   Parametric Inference for Index Functionals   Using the GB2 Income Distribution   Polarization and Rising Wage Inequality: Comparing the U.S. and Germany ," Abstract
There is substantial evidence that inflation rates are characterized by long memory and nonlinearities. In this paper, we introduce a long-memory Smooth Transition AutoRegressive Fractionally Integrated Moving Average-Markov Switching Multifractal specification [
STARFIMA(p,d,q)
-
MSM(k)
] for modeling and forecasting inflation uncertainty. We first provide the statistical properties of the process and investigate the finite sample properties of the maximum likelihood estimators through simulation. Second, we evaluate the out-of-sample forecast performance of the model in forecasting inflation uncertainty in the G7 countries. Our empirical analysis demonstrates the superiority of the new model over the alternative
STARFIMA(p,d,q)
-
GARCH
-type models in forecasting inflation uncertainty. View Full-Text   Abstract
In this paper, we study the finite sample accuracy of confidence intervals for index functional built via parametric bootstrap, in the case of inequality indices. To estimate the parameters of the assumed parametric data generating distribution, we propose a Generalized Method of Moment estimator that targets the quantity of interest, namely the considered inequality index. Its primary advantage is that the scale parameter does not need to be estimated to perform parametric bootstrap, since inequality measures are scale invariant. The very good finite sample coverages that are found in a simulation study suggest that this feature provides an advantage over the parametric bootstrap using the maximum likelihood estimator. We also find that overall, a parametric bootstrap provides more accurate inference than its non or semi-parametric counterparts, especially for heavy tailed income distributions. View Full-Text   Abstract
To use the generalized beta distribution of the second kind (GB2) for the analysis of income and other positively skewed distributions, knowledge of estimation methods and the ability to compute quantities of interest from the estimated parameters are required. We review estimation methodology that has appeared in the literature, and summarize expressions for inequality, poverty, and pro-poor growth that can be used to compute these measures from GB2 parameter estimates. An application to data from China and Indonesia is provided. View Full-Text   Abstract
Since the late 1970s, wage inequality has increased strongly both in the U.S. and Germany but the trends have been different. Wage inequality increased along the entire wage distribution during the 1980s in the U.S. and since the mid 1990s in Germany. There is evidence for wage polarization in the U.S. in the 1990s, and the increase in wage inequality in Germany was restricted to the top of the distribution before the 1990s. Using an approach developed by MaCurdy and Mroz (1995) to separate age, time, and cohort effects, we find a large role played by cohort effects in Germany, while we find only small cohort effects in the U.S. Employment trends in both countries are consistent with polarization since the 1990s. The evidence is consistent with a technology-driven polarization of the labor market, but this cannot explain the country specific differences. View Full-Text "," inflation uncertainty,smooth transition,multifractal processes,GARCH processes   parametric bootstrap,generalized method of moments,income distribution,inequality measurement,heavy tail   inequality,poverty,pro-poor growth,GMM estimation   wage inequality,polarization,international comparison,cohort study,quantile regression "," Forecasting Inflation Uncertainty in the G7 Countries   Parametric Inference for Index Functionals   Using the GB2 Income Distribution   Polarization and Rising Wage Inequality: Comparing the U.S. and Germany   Abstract
There is substantial evidence that inflation rates are characterized by long memory and nonlinearities. In this paper, we introduce a long-memory Smooth Transition AutoRegressive Fractionally Integrated Moving Average-Markov Switching Multifractal specification [
STARFIMA(p,d,q)
-
MSM(k)
] for modeling and forecasting inflation uncertainty. We first provide the statistical properties of the process and investigate the finite sample properties of the maximum likelihood estimators through simulation. Second, we evaluate the out-of-sample forecast performance of the model in forecasting inflation uncertainty in the G7 countries. Our empirical analysis demonstrates the superiority of the new model over the alternative
STARFIMA(p,d,q)
-
GARCH
-type models in forecasting inflation uncertainty. View Full-Text   Abstract
In this paper, we study the finite sample accuracy of confidence intervals for index functional built via parametric bootstrap, in the case of inequality indices. To estimate the parameters of the assumed parametric data generating distribution, we propose a Generalized Method of Moment estimator that targets the quantity of interest, namely the considered inequality index. Its primary advantage is that the scale parameter does not need to be estimated to perform parametric bootstrap, since inequality measures are scale invariant. The very good finite sample coverages that are found in a simulation study suggest that this feature provides an advantage over the parametric bootstrap using the maximum likelihood estimator. We also find that overall, a parametric bootstrap provides more accurate inference than its non or semi-parametric counterparts, especially for heavy tailed income distributions. View Full-Text   Abstract
To use the generalized beta distribution of the second kind (GB2) for the analysis of income and other positively skewed distributions, knowledge of estimation methods and the ability to compute quantities of interest from the estimated parameters are required. We review estimation methodology that has appeared in the literature, and summarize expressions for inequality, poverty, and pro-poor growth that can be used to compute these measures from GB2 parameter estimates. An application to data from China and Indonesia is provided. View Full-Text   Abstract
Since the late 1970s, wage inequality has increased strongly both in the U.S. and Germany but the trends have been different. Wage inequality increased along the entire wage distribution during the 1980s in the U.S. and since the mid 1990s in Germany. There is evidence for wage polarization in the U.S. in the 1990s, and the increase in wage inequality in Germany was restricted to the top of the distribution before the 1990s. Using an approach developed by MaCurdy and Mroz (1995) to separate age, time, and cohort effects, we find a large role played by cohort effects in Germany, while we find only small cohort effects in the U.S. Employment trends in both countries are consistent with polarization since the 1990s. The evidence is consistent with a technology-driven polarization of the labor market, but this cannot explain the country specific differences. View Full-Text   inflation uncertainty,smooth transition,multifractal processes,GARCH processes   parametric bootstrap,generalized method of moments,income distribution,inequality measurement,heavy tail   inequality,poverty,pro-poor growth,GMM estimation   wage inequality,polarization,international comparison,cohort study,quantile regression ", Econometrics 
" On-Farm Evaluation of the Potential Use of Greenhouse Gas Mitigation Techniques for Rice Cultivation: A Case Study in Thailand   Simulating the Impacts of Tree, C3, and C4 Plant Functional Types on the Future Climate of West Africa   Evaluation of Small-Scale Fishers’ Perceptions on Climate Change and Their Coping Strategies: Insights from Lake Malawi   Intercomparison of Univariate and Joint Bias Correction Methods in Changing Climate From a Hydrological Perspective "," Abstract
Environmental and socio-economic evaluations that imply techniques for mitigating greenhouse gas (GHG) emissions from rice cultivation are a challenging and controversial issue. This study was designed to investigate the potential use of mitigation techniques for rice cultivation. Mid-season drainage (MD), using ammonium sulfate instead of urea (AS), and site-specific nutrient management (SSNM) were chosen as mitigation techniques. Data were collected using field surveys and structured questionnaires at the same 156 farms, covering four crop years. The GHG emissions were evaluated based on the concept of the life cycle assessment of the GHG emissions of products. The farmers’ assessments of mitigation techniques, with multiple criteria evaluation, were obtained by face-to-face interviews. Opinions on all mitigation techniques were requested two times covering four years with the same 156 farm owners. The multinomial logistic regression model was used to examine the factors influencing the farmers’ decisions. The results show that SSNM was evaluated as the highest abatement potential (363.52 kgCO2eq ha−1), the negative value of abatement cost (−2565 THB ha−1), and the negative value of the average abatement cost (−14 THB kgCO2eq−1). Among the different techniques, SSNM was perceived as the most suitable one, followed by MD and AS. Highly significant factors influencing decision making consisted of planted area, land size, farmer liability, farmer perception of yield, and GHG emissions. Subsidies or cost-sharing measures to convince farmers to adopt new techniques can enhance their practices, and more support for the development of water systems can increase their availability. View Full-Text   Abstract
This study investigates the future climatic impacts of different percentages of trees/shrubs, C4 and C3 plant functional types (PFTs) over the West Africa region. The ratio of co-existence among the different PFTs was done as a representation of agri-silviculture practices over the region. Nine sensitivity experiments of different percentages of trees/shrubs, and C4 and C3 PFTs were carried out with a regional climate model (RegCM4) driven by Global Climate Model (HADGEM2-ES) outputs. These experiments were carried out along the Guinea Savana zone of West Africa using both prescribed and dynamic vegetation options of the model. The model simulated the seasonal evolution of precipitation and temperature fields quite well, with correlations greater than 0.8, but exhibited cold and wet biases of about 1–2 °C and 1–4 mm/day, respectively. Widespread warming (1–3 °C) and drying (1–2 mm/day) is projected in the near future across most parts of West Africa all year round. The West African future climate change associated with the different percentages of trees/shrubs, and C4 and C3 PFTs varied with the vegetation state (prescribed or dynamic) and model domain sizes. The prescribed vegetation experiments induced cooling of about 0.5–2 °C in most areas along the designated agri-silviculture zone, except Liberia and Sierra Leone. Similarly, enhanced precipitation occurred over most parts of Ghana and coastal parts of Nigeria (0.5–3 mm/day). On the other hand, the dynamic vegetation option did not exhibit pronounced changes in temperature and precipitation, except with a larger domain size. This study suggests the implementation of agri-silviculture as a mitigation and adaptation land-use practice across West Africa if drought-tolerant crops and the deciduous trees are adopted. View Full-Text   Abstract
The effects of climate change have negatively affected Malawi’s agricultural production. In this context, fisheries have been providing alternative livelihoods. However, there is a knowledge gap around the responses of small-scale fishers to climate-related changes. Therefore, a study was conducted on the Western shores of Lake Malawi between August 2015 and April 2016. The study evaluated the perceived effects of climate change on small-scale fishers and their coping strategies by employing a wide range of methods for data collection and analysis. The study used explorative surveys, household surveys, focus group discussions and key informant interviews to collect data. The study randomly sampled 112 household heads who owned either fishing gear or a fishing vessel or both. Content analysis for themes was used to analyse the qualitative data. The Mann–Kendal Test was used to analyse trends in meteorological data, and binary logistic regression was used to determine factors that influence coping with low fish catches. Despite the respondents noticing an increased incidence of extreme weather events and low fish catches, their perceptions could not be validated using time series meteorological data. However, such perceptions were influenced by experience from long-time exposure to extreme weather events and to low fish catches. The majority of the fishers had adjusted to these changes by increasing their fishing time, using highly efficient illegal fishing nets, expanding farming land, operating small businesses and undertaking casual labour in agriculture and fishing activities. The fishers’ propensity to adjust to these changes increased due to the presence of the following factors: older age of household head, higher education level, being married and having an annual income. In contrast, being a member of fish conservation club decreased the probability of adjusting. This study emphasizes the need to be cautious when defining and framing perceptions of local communities on extreme weather events as data obtained could be misleading. Furthermore, a multi-sectoral approach to balance sustainable livelihoods and management of fisheries is needed. These findings provide theoretical and practical lessons that can inform design, planning and implementation of policies that enhance adaptive capacity in fisheries and promote sustainable livelihoods in sub-Saharan Africa. View Full-Text   Abstract
In this paper, the ability of two joint bias correction algorithms to adjust biases in daily mean temperature and precipitation is compared against two univariate quantile mapping methods when constructing projections from years 1981–2010 to early (2011–2040) and late (2061–2090) 21st century periods. Using both climate model simulations and the corresponding hydrological model simulations as proxies for the future in a pseudo-reality framework, these methods are inter-compared in a cross-validation manner in order to assess to what extent the more sophisticated methods have added value, particularly from the hydrological modeling perspective. By design, bi-variate bias correction methods improve the inter-variable relationships in the baseline period. Cross-validation results show, however, that both in the early and late 21st century conditions the additional benefit of using bi-variate bias correction methods is not obvious, as univariate methods have a comparable performance. From the evaluated hydrological variables, the added value is most clearly seen in the simulated snow water equivalent. Although not having the best performance in adjusting the temperature and precipitation distributions, quantile mapping applied as a delta change method performs well from the hydrological modeling point of view, particularly in the early 21st century conditions. This suggests that retaining the observed correlation structures of temperature and precipitation might in some cases be sufficient for simulating future hydrological climate change impacts. View Full-Text "," rice field,mitigation techniques,greenhouse gas emissions,life cycle assessment,farmer acceptance,incentive measures   agri-silviculture,mitigation and adaptation,future climate,regional climate model,West Africa,plant functional types   perceptions,Lake Malawi,climate change,coping strategies,logistic regression,vulnerability,adaptive capacity   regional climate modeling,hydrological modeling,bias correction,multivariate,pseudo reality "," On-Farm Evaluation of the Potential Use of Greenhouse Gas Mitigation Techniques for Rice Cultivation: A Case Study in Thailand   Simulating the Impacts of Tree, C3, and C4 Plant Functional Types on the Future Climate of West Africa   Evaluation of Small-Scale Fishers’ Perceptions on Climate Change and Their Coping Strategies: Insights from Lake Malawi   Intercomparison of Univariate and Joint Bias Correction Methods in Changing Climate From a Hydrological Perspective   Abstract
Environmental and socio-economic evaluations that imply techniques for mitigating greenhouse gas (GHG) emissions from rice cultivation are a challenging and controversial issue. This study was designed to investigate the potential use of mitigation techniques for rice cultivation. Mid-season drainage (MD), using ammonium sulfate instead of urea (AS), and site-specific nutrient management (SSNM) were chosen as mitigation techniques. Data were collected using field surveys and structured questionnaires at the same 156 farms, covering four crop years. The GHG emissions were evaluated based on the concept of the life cycle assessment of the GHG emissions of products. The farmers’ assessments of mitigation techniques, with multiple criteria evaluation, were obtained by face-to-face interviews. Opinions on all mitigation techniques were requested two times covering four years with the same 156 farm owners. The multinomial logistic regression model was used to examine the factors influencing the farmers’ decisions. The results show that SSNM was evaluated as the highest abatement potential (363.52 kgCO2eq ha−1), the negative value of abatement cost (−2565 THB ha−1), and the negative value of the average abatement cost (−14 THB kgCO2eq−1). Among the different techniques, SSNM was perceived as the most suitable one, followed by MD and AS. Highly significant factors influencing decision making consisted of planted area, land size, farmer liability, farmer perception of yield, and GHG emissions. Subsidies or cost-sharing measures to convince farmers to adopt new techniques can enhance their practices, and more support for the development of water systems can increase their availability. View Full-Text   Abstract
This study investigates the future climatic impacts of different percentages of trees/shrubs, C4 and C3 plant functional types (PFTs) over the West Africa region. The ratio of co-existence among the different PFTs was done as a representation of agri-silviculture practices over the region. Nine sensitivity experiments of different percentages of trees/shrubs, and C4 and C3 PFTs were carried out with a regional climate model (RegCM4) driven by Global Climate Model (HADGEM2-ES) outputs. These experiments were carried out along the Guinea Savana zone of West Africa using both prescribed and dynamic vegetation options of the model. The model simulated the seasonal evolution of precipitation and temperature fields quite well, with correlations greater than 0.8, but exhibited cold and wet biases of about 1–2 °C and 1–4 mm/day, respectively. Widespread warming (1–3 °C) and drying (1–2 mm/day) is projected in the near future across most parts of West Africa all year round. The West African future climate change associated with the different percentages of trees/shrubs, and C4 and C3 PFTs varied with the vegetation state (prescribed or dynamic) and model domain sizes. The prescribed vegetation experiments induced cooling of about 0.5–2 °C in most areas along the designated agri-silviculture zone, except Liberia and Sierra Leone. Similarly, enhanced precipitation occurred over most parts of Ghana and coastal parts of Nigeria (0.5–3 mm/day). On the other hand, the dynamic vegetation option did not exhibit pronounced changes in temperature and precipitation, except with a larger domain size. This study suggests the implementation of agri-silviculture as a mitigation and adaptation land-use practice across West Africa if drought-tolerant crops and the deciduous trees are adopted. View Full-Text   Abstract
The effects of climate change have negatively affected Malawi’s agricultural production. In this context, fisheries have been providing alternative livelihoods. However, there is a knowledge gap around the responses of small-scale fishers to climate-related changes. Therefore, a study was conducted on the Western shores of Lake Malawi between August 2015 and April 2016. The study evaluated the perceived effects of climate change on small-scale fishers and their coping strategies by employing a wide range of methods for data collection and analysis. The study used explorative surveys, household surveys, focus group discussions and key informant interviews to collect data. The study randomly sampled 112 household heads who owned either fishing gear or a fishing vessel or both. Content analysis for themes was used to analyse the qualitative data. The Mann–Kendal Test was used to analyse trends in meteorological data, and binary logistic regression was used to determine factors that influence coping with low fish catches. Despite the respondents noticing an increased incidence of extreme weather events and low fish catches, their perceptions could not be validated using time series meteorological data. However, such perceptions were influenced by experience from long-time exposure to extreme weather events and to low fish catches. The majority of the fishers had adjusted to these changes by increasing their fishing time, using highly efficient illegal fishing nets, expanding farming land, operating small businesses and undertaking casual labour in agriculture and fishing activities. The fishers’ propensity to adjust to these changes increased due to the presence of the following factors: older age of household head, higher education level, being married and having an annual income. In contrast, being a member of fish conservation club decreased the probability of adjusting. This study emphasizes the need to be cautious when defining and framing perceptions of local communities on extreme weather events as data obtained could be misleading. Furthermore, a multi-sectoral approach to balance sustainable livelihoods and management of fisheries is needed. These findings provide theoretical and practical lessons that can inform design, planning and implementation of policies that enhance adaptive capacity in fisheries and promote sustainable livelihoods in sub-Saharan Africa. View Full-Text   Abstract
In this paper, the ability of two joint bias correction algorithms to adjust biases in daily mean temperature and precipitation is compared against two univariate quantile mapping methods when constructing projections from years 1981–2010 to early (2011–2040) and late (2061–2090) 21st century periods. Using both climate model simulations and the corresponding hydrological model simulations as proxies for the future in a pseudo-reality framework, these methods are inter-compared in a cross-validation manner in order to assess to what extent the more sophisticated methods have added value, particularly from the hydrological modeling perspective. By design, bi-variate bias correction methods improve the inter-variable relationships in the baseline period. Cross-validation results show, however, that both in the early and late 21st century conditions the additional benefit of using bi-variate bias correction methods is not obvious, as univariate methods have a comparable performance. From the evaluated hydrological variables, the added value is most clearly seen in the simulated snow water equivalent. Although not having the best performance in adjusting the temperature and precipitation distributions, quantile mapping applied as a delta change method performs well from the hydrological modeling point of view, particularly in the early 21st century conditions. This suggests that retaining the observed correlation structures of temperature and precipitation might in some cases be sufficient for simulating future hydrological climate change impacts. View Full-Text   rice field,mitigation techniques,greenhouse gas emissions,life cycle assessment,farmer acceptance,incentive measures   agri-silviculture,mitigation and adaptation,future climate,regional climate model,West Africa,plant functional types   perceptions,Lake Malawi,climate change,coping strategies,logistic regression,vulnerability,adaptive capacity   regional climate modeling,hydrological modeling,bias correction,multivariate,pseudo reality ", Climate 
 Simulation of Random Events for Air Traffic Applications   A Dual Mode Propulsion System for Small Satellite Applications†   Prediction of Heat Transfer in a Jet Cooled Aircraft Engine Compressor Cone Based on Statistical Methods ," Abstract
Resilience to uncertainties must be ensured in air traffic management. Unexpected events can either be disruptive, like thunderstorms or the famous volcano ash cloud resulting from the Eyjafjallajökull eruption in Iceland, or simply due to imprecise measurements or incomplete knowledge of the environment. While human operators are able to cope with such situations, it is generally not the case for automated decision support tools. Important examples originate from the numerous attempts made to design algorithms able to solve conflicts between aircraft occurring during flights. The STARGATE (STochastic AppRoach for naviGATion functions in uncertain Environment) project was initiated in order to study the feasibility of inherently robust automated planning algorithms that will not fail when submitted to random perturbations. A mandatory first step is the ability to simulate the usual stochastic phenomenons impairing the system: delays due to airport platforms or air traffic control (ATC) and uncertainties on the wind velocity. The work presented here will detail algorithms suitable for the simulation task. View Full-Text   Abstract
This study focused on the development of a chemical micropropulsion system suitable for primary propulsion and/or attitude control for a nanosatellite. Due to the limitations and expense of current micropropulsion technologies, few nanosatellites with propulsion have been launched to date; however, the availability of such a propulsion system would allow for new nanosatellite mission concepts, such as deep space exploration, maneuvering in low gravity environments and formation flying. This work describes the design of “dual mode” monopropellant/bipropellant microthruster prototype that employs a novel homogeneous catalysis scheme. Results from prototype testing are reported that validate the concept. The micropropulsion system is designed to be fabricated using a combination of additively-manufactured and commercial off the shelf (COTS) parts along with non-toxic fuels, thus making it a low-cost and environmentally-friendly option for future nanosatellite missions. View Full-Text   Abstract
The paper presents the setup and analysis of an experimental study on heat transfer of a jet cooled compressor rear cone with adjacent conical housing. The main goal of the paper is to describe the systematic derivation of empirical correlations for global Nusselt numbers to be used in the design process of a jet engine secondary air system. Based on the relevant similarity parameters obtained from literature, operating points are deduced leading to a full factorial design experiment to identify all effects and interactions. The varied similarity parameters are the circumferential Reynolds number, the non-dimensional mass flow, the non-dimensional spacing between rotor and stator, and the jet incidence angle. The range of the varied similarity parameters covers engine oriented operating conditions and is therefore suitable to predict Nusselt numbers in the actual engine component. In order to estimate measurement uncertainties, a simplified model of the test specimen, consisting of a convectively cooled flat plate, has been derived. Uncertainties of the measured quantities and derived properties are discussed by means of a linear propagation of uncertainties. A sensitivity study shows the effects of the input parameters and their interactions on the global Nusselt number. Subsequently, an empirical correlation for the global Nusselt numbers is derived using a multivariate non-linear regression. The quality of the empirical correlation is assessed by means of statistical hypotheses and by a comparison between measured and predicted data. The predicted values show excellent agreement with experimental data. In a wide range, accuracies of 15% can be reached when predicting global Nusselt numbers. Furthermore, the results of the sensitivity study show that pre-swirled cooling air does not have a positive effect on heat transfer. View Full-Text "," fast time traffic simulator,Gaussian field simulation,air traffic management   micropropulsion,microthruster,small satellites,additive manufacturing,hydrogen peroxide,monopropellant   jet engines,rotor-stator systems,heat transfer,nusselt number correlation,multivariate regression,statistical modeling "," Simulation of Random Events for Air Traffic Applications   A Dual Mode Propulsion System for Small Satellite Applications†   Prediction of Heat Transfer in a Jet Cooled Aircraft Engine Compressor Cone Based on Statistical Methods   Abstract
Resilience to uncertainties must be ensured in air traffic management. Unexpected events can either be disruptive, like thunderstorms or the famous volcano ash cloud resulting from the Eyjafjallajökull eruption in Iceland, or simply due to imprecise measurements or incomplete knowledge of the environment. While human operators are able to cope with such situations, it is generally not the case for automated decision support tools. Important examples originate from the numerous attempts made to design algorithms able to solve conflicts between aircraft occurring during flights. The STARGATE (STochastic AppRoach for naviGATion functions in uncertain Environment) project was initiated in order to study the feasibility of inherently robust automated planning algorithms that will not fail when submitted to random perturbations. A mandatory first step is the ability to simulate the usual stochastic phenomenons impairing the system: delays due to airport platforms or air traffic control (ATC) and uncertainties on the wind velocity. The work presented here will detail algorithms suitable for the simulation task. View Full-Text   Abstract
This study focused on the development of a chemical micropropulsion system suitable for primary propulsion and/or attitude control for a nanosatellite. Due to the limitations and expense of current micropropulsion technologies, few nanosatellites with propulsion have been launched to date; however, the availability of such a propulsion system would allow for new nanosatellite mission concepts, such as deep space exploration, maneuvering in low gravity environments and formation flying. This work describes the design of “dual mode” monopropellant/bipropellant microthruster prototype that employs a novel homogeneous catalysis scheme. Results from prototype testing are reported that validate the concept. The micropropulsion system is designed to be fabricated using a combination of additively-manufactured and commercial off the shelf (COTS) parts along with non-toxic fuels, thus making it a low-cost and environmentally-friendly option for future nanosatellite missions. View Full-Text   Abstract
The paper presents the setup and analysis of an experimental study on heat transfer of a jet cooled compressor rear cone with adjacent conical housing. The main goal of the paper is to describe the systematic derivation of empirical correlations for global Nusselt numbers to be used in the design process of a jet engine secondary air system. Based on the relevant similarity parameters obtained from literature, operating points are deduced leading to a full factorial design experiment to identify all effects and interactions. The varied similarity parameters are the circumferential Reynolds number, the non-dimensional mass flow, the non-dimensional spacing between rotor and stator, and the jet incidence angle. The range of the varied similarity parameters covers engine oriented operating conditions and is therefore suitable to predict Nusselt numbers in the actual engine component. In order to estimate measurement uncertainties, a simplified model of the test specimen, consisting of a convectively cooled flat plate, has been derived. Uncertainties of the measured quantities and derived properties are discussed by means of a linear propagation of uncertainties. A sensitivity study shows the effects of the input parameters and their interactions on the global Nusselt number. Subsequently, an empirical correlation for the global Nusselt numbers is derived using a multivariate non-linear regression. The quality of the empirical correlation is assessed by means of statistical hypotheses and by a comparison between measured and predicted data. The predicted values show excellent agreement with experimental data. In a wide range, accuracies of 15% can be reached when predicting global Nusselt numbers. Furthermore, the results of the sensitivity study show that pre-swirled cooling air does not have a positive effect on heat transfer. View Full-Text   fast time traffic simulator,Gaussian field simulation,air traffic management   micropropulsion,microthruster,small satellites,additive manufacturing,hydrogen peroxide,monopropellant   jet engines,rotor-stator systems,heat transfer,nusselt number correlation,multivariate regression,statistical modeling ", Aerospace 
" Acquisition of L2 French Object Pronouns by Advanced Anglophone Learners   On Convergence, Ongoing Language Change, and Crosslinguistic Influence in Direct Object Expression in Catalan–Spanish Bilingualism   Does Typological Proximity Really Matter? Evidence from Mandarin and Brazilian Portuguese-Speaking Learners of Spanish   The Mixed Effects of Phonetic Input Variability on Relative Ease of L2 Learning: Evidence from English Learners’ Production of French and Spanish Stop-Rhotic Clusters "," Abstract
The role native language transfer plays in L2 acquisition raises the question of whether L1 constitutes a permanent representational deficit to mastery of the L2 morphosyntax and prosody or if it can eventually be overcome. Earlier research has shown that beginning and low intermediate Anglophone L2 French learners are insensitive to French morphosyntactic and prosodic constraints in using in situ pronouns transferred from the L1. The prosodic transfer hypothesis (PTH) proposes that native prosodic structures may be adapted to facilitate acquisition of L2 prosodic structure. Our study presents new evidence from three Anglophone advanced learners of L2 French that indicates ceiling performance for pronoun production (99% accuracy in 300 tokens over nine interviews) and grammaticality judgment (98% accuracy). This native-like performance demonstrates target French morphosyntax and prosody, built—as predicted by the PTH—by licensing pronominal free clitics in a new pre-verbal L2 position distinct from post-verbal L1. Furthermore, the learners’ data confirms accurate prosody by way of appropriate prominence patterns in clitic + host sequences, correct use of clitics with prefixed verbs, use of stacked pronouns, as well as correct prosodic alternations involving liaison and elision. These results counter impaired representation approaches and suggest early missing inflection may be overcome. View Full-Text   Abstract
The present study explores two morphological differences in direct object expression between Spanish and Catalan: Differential Object Marking (DOM), and the accusative clitics el /l/ vs. ho /u/. Both phenomena are regulated by semantic features, such as animacy and specificity/definiteness. The study experimentally tested 57 Catalan–Spanish bilinguals with different degrees of language dominance in their comprehension and production of these Catalan constructions in order to explore the degree of structural convergence. The results show that with respect to DOM, bilinguals systematically accept ample optionality, creating a new language variety, the bilingual variety, with properties similar and different from both Spanish and Catalan. With respect to the accusative clitics, a certain degree of functional interference in the grammar of Spanish-dominant bilinguals is found. These results illustrate, on the one hand, structural convergence in DOM, culminating in an internal language change accelerated by language contact, and, on the other hand, incipient language transfer from the dominant language in the expression of accusative clitics. View Full-Text   Abstract
The present study examines the role of typological proximity in the acquisition of Differential Object Marking (DOM) in Spanish among eighteen (n = 18) Mandarin-speaking second language (L2) learners and sixteen (n = 16) Spanish heritage speakers (HSs) with Brazilian Portuguese (BP) as their dominant language. Specifically, we investigate the extent to which language proximity (languages are members of the same family) plays a role in the complete specification of the relevant features constraining DOM marking in Spanish. Results from an elicited production task and an acceptability judgment task (AJT) showed no support for the typological proximity model (Rothman 2010). There were also no age of onset of acquisition effects, in contrast to what was expected. The post-puberty Mandarin L2 learners outperformed the BP HSs in most of the conditions examined, suggesting a role for language instruction. Results are discussed along the lines of Liceras and Alba de la Fuente’s (2015) proposal whereby the locus of transfer is more related to the typological similarity between the languages at the microparametric level than to language proximity itself. View Full-Text   Abstract
We examined the consequences of within-category phonetic variability in the input on non-native learners’ production accuracy. Following previous empirical research on the L2 acquisition of phonetics and the lexicon, we tested the hypothesis that phonetic variability facilitates learning by analyzing English-speaking learners’ production of French and Spanish word-medial stop-rhotic clusters, which differ from their English counterparts in terms of stop and rhotic voicing and manner. Crucially, for both the stops and rhotics, there are differences in within-language variability. Twenty native speakers per language and 39 L1 English-learners of French (N = 20) and Spanish (N = 19) of intermediate and advanced proficiency performed a carrier-sentence reading task. A given parameter was deemed to have been acquired when the learners’ production fell within the range of attested native speaker values. An acoustic analysis of the data partially supports the facilitative effect of phonetic variability. To account for the unsupported hypotheses, we discuss a number of issues, including the difficulty of measuring variability, the need to determine the extent to which learners’ perception shapes intake, and the challenge of teasing apart the effects of input variability from those of transferred L1 articulatory patterns. View Full-Text "," second language acquisition,native language transfer,French object pronouns,advanced learners,prosodic transfer hypothesis,French object clitics,strong pronouns   accusative clitics,DOM,language convergence,Catalan,Spanish,definiteness,bilingualism,language change,crosslinguistic influence   Spanish Differential Object Marking,Chinese learners of Spanish,typological proximity model,Spanish heritage speakers   input,variability,relative difficulty,second language production,consonant clusters,stops,rhotics,phonetic parameters,voicing,manner "," Acquisition of L2 French Object Pronouns by Advanced Anglophone Learners   On Convergence, Ongoing Language Change, and Crosslinguistic Influence in Direct Object Expression in Catalan–Spanish Bilingualism   Does Typological Proximity Really Matter? Evidence from Mandarin and Brazilian Portuguese-Speaking Learners of Spanish   The Mixed Effects of Phonetic Input Variability on Relative Ease of L2 Learning: Evidence from English Learners’ Production of French and Spanish Stop-Rhotic Clusters   Abstract
The role native language transfer plays in L2 acquisition raises the question of whether L1 constitutes a permanent representational deficit to mastery of the L2 morphosyntax and prosody or if it can eventually be overcome. Earlier research has shown that beginning and low intermediate Anglophone L2 French learners are insensitive to French morphosyntactic and prosodic constraints in using in situ pronouns transferred from the L1. The prosodic transfer hypothesis (PTH) proposes that native prosodic structures may be adapted to facilitate acquisition of L2 prosodic structure. Our study presents new evidence from three Anglophone advanced learners of L2 French that indicates ceiling performance for pronoun production (99% accuracy in 300 tokens over nine interviews) and grammaticality judgment (98% accuracy). This native-like performance demonstrates target French morphosyntax and prosody, built—as predicted by the PTH—by licensing pronominal free clitics in a new pre-verbal L2 position distinct from post-verbal L1. Furthermore, the learners’ data confirms accurate prosody by way of appropriate prominence patterns in clitic + host sequences, correct use of clitics with prefixed verbs, use of stacked pronouns, as well as correct prosodic alternations involving liaison and elision. These results counter impaired representation approaches and suggest early missing inflection may be overcome. View Full-Text   Abstract
The present study explores two morphological differences in direct object expression between Spanish and Catalan: Differential Object Marking (DOM), and the accusative clitics el /l/ vs. ho /u/. Both phenomena are regulated by semantic features, such as animacy and specificity/definiteness. The study experimentally tested 57 Catalan–Spanish bilinguals with different degrees of language dominance in their comprehension and production of these Catalan constructions in order to explore the degree of structural convergence. The results show that with respect to DOM, bilinguals systematically accept ample optionality, creating a new language variety, the bilingual variety, with properties similar and different from both Spanish and Catalan. With respect to the accusative clitics, a certain degree of functional interference in the grammar of Spanish-dominant bilinguals is found. These results illustrate, on the one hand, structural convergence in DOM, culminating in an internal language change accelerated by language contact, and, on the other hand, incipient language transfer from the dominant language in the expression of accusative clitics. View Full-Text   Abstract
The present study examines the role of typological proximity in the acquisition of Differential Object Marking (DOM) in Spanish among eighteen (n = 18) Mandarin-speaking second language (L2) learners and sixteen (n = 16) Spanish heritage speakers (HSs) with Brazilian Portuguese (BP) as their dominant language. Specifically, we investigate the extent to which language proximity (languages are members of the same family) plays a role in the complete specification of the relevant features constraining DOM marking in Spanish. Results from an elicited production task and an acceptability judgment task (AJT) showed no support for the typological proximity model (Rothman 2010). There were also no age of onset of acquisition effects, in contrast to what was expected. The post-puberty Mandarin L2 learners outperformed the BP HSs in most of the conditions examined, suggesting a role for language instruction. Results are discussed along the lines of Liceras and Alba de la Fuente’s (2015) proposal whereby the locus of transfer is more related to the typological similarity between the languages at the microparametric level than to language proximity itself. View Full-Text   Abstract
We examined the consequences of within-category phonetic variability in the input on non-native learners’ production accuracy. Following previous empirical research on the L2 acquisition of phonetics and the lexicon, we tested the hypothesis that phonetic variability facilitates learning by analyzing English-speaking learners’ production of French and Spanish word-medial stop-rhotic clusters, which differ from their English counterparts in terms of stop and rhotic voicing and manner. Crucially, for both the stops and rhotics, there are differences in within-language variability. Twenty native speakers per language and 39 L1 English-learners of French (N = 20) and Spanish (N = 19) of intermediate and advanced proficiency performed a carrier-sentence reading task. A given parameter was deemed to have been acquired when the learners’ production fell within the range of attested native speaker values. An acoustic analysis of the data partially supports the facilitative effect of phonetic variability. To account for the unsupported hypotheses, we discuss a number of issues, including the difficulty of measuring variability, the need to determine the extent to which learners’ perception shapes intake, and the challenge of teasing apart the effects of input variability from those of transferred L1 articulatory patterns. View Full-Text   second language acquisition,native language transfer,French object pronouns,advanced learners,prosodic transfer hypothesis,French object clitics,strong pronouns   accusative clitics,DOM,language convergence,Catalan,Spanish,definiteness,bilingualism,language change,crosslinguistic influence   Spanish Differential Object Marking,Chinese learners of Spanish,typological proximity model,Spanish heritage speakers   input,variability,relative difficulty,second language production,consonant clusters,stops,rhotics,phonetic parameters,voicing,manner ", Languages 
 Simulation and Feedback in Health Education: A Mixed Methods Study Comparing Three Simulation Modalities   Simulation as a Central Feature of an Elective Course: Does Simulated Bedside Care Impact Learning?   The Development of a Community Pharmacy-Based Intervention to Optimize Patients’ Use of and Experience with Antidepressants: A Step-by-Step Demonstration of the Intervention Mapping Process   Older Peoples’ Adherence and Awareness of Changes in Drug Therapy after Discharge from Hospital ," Abstract
Background. There are numerous approaches to simulating a patient encounter in pharmacy education. However, little direct comparison between these approaches has been undertaken. Our objective was to investigate student experiences, satisfaction, and feedback preferences between three scenario simulation modalities (paper-, actor-, and computer-based). Methods. We conducted a mixed methods study with randomized cross-over of simulation modalities on final-year Australian graduate-entry Master of Pharmacy students. Participants completed case-based scenarios within each of three simulation modalities, with feedback provided at the completion of each scenario in a format corresponding to each simulation modality. A post-simulation questionnaire collected qualitative and quantitative responses pertaining to participant satisfaction, experiences, and feedback preferences. Results. Participants reported similar levels satisfaction across all three modalities. However, each modality resulted in unique positive and negative experiences, such as student disengagement with paper-based scenarios. Conclusion. Importantly, the themes of guidance and opportunity for peer discussion underlie the best forms of feedback for students. The provision of feedback following simulation should be carefully considered and delivered, with all three simulation modalities producing both positive and negative experiences in regard to their feedback format. View Full-Text   Abstract
A three-credit, simulation-based, emergency medicine elective course was designed and offered to doctor of pharmacy students for two years. The primary objective was to determine if there was a difference in exam performance stratified by student simulation experience, namely either as an active observer or as part of bedside clinical care. The secondary objective was to report student satisfaction. Examination performance for simulation-based questions was compared based on the student role (evaluator versus clinical) using the Student’s t-test. Summary responses from Likert scale-based student satisfaction responses were collected. A total of 24 students took the course: 12 in each offering. Performance was similar whether the student was assigned to the evaluation team or the clinical team for all of the comparisons (mid-term and final 2015 and 2016, all p-values > 0.05). Students were very satisfied with the course. Of the 19 questions assessing the qualitative aspects of the course, all of the students agreed or strongly agreed to 17 statements, and all of the students were neutral, agreed, or strongly agreed to the remaining two statements. Direct participation and active observation in simulation-based experiences appear to be equally valuable in the learning process, as evidenced by examination performance. View Full-Text   Abstract
Objective: To describe the development of a community pharmacy-based intervention aimed at optimizing experience and use of antidepressants (ADs) for patients with mood and anxiety disorders. Methods: Intervention Mapping (IM) was used for conducting needs assessment, formulating intervention objectives, selecting change methods and practical applications, designing the intervention, and planning intervention implementation. IM is based on a qualitative participatory approach and each step of the intervention development process was conducted through consultations with a pharmacists’ committee. Results: A needs assessment was informed by qualitative and quantitative studies conducted with leaders, pharmacists, and patients. Intervention objectives and change methods were selected to target factors influencing patients’ experience with and use of ADs. The intervention includes four brief consultations between the pharmacist and the patient: (1) provision of information (first AD claim); (2) management of side effects (15 days after first claim); (3) monitoring treatment efficacy (30-day renewal); (4) assessment of treatment persistence (2-month renewal, repeated every 6 months). A detailed implementation plan was also developed. Conclusion: IM provided a systematic and rigorous approach to the development of an intervention directly tied to empirical data on patients’ and pharmacists’ experiences and recommendations. The thorough description of this intervention may facilitate the development of new pharmacy-based interventions or the adaptation of this intervention to other illnesses and settings. View Full-Text   Abstract
Non-adherence is important to address because it might affect the effectiveness of therapy and lead to adverse effects. The objectives of this interview study were to investigate old peoples’ general adherence to drugs and their awareness of and adherence to changes in drug therapy after their hospital stay. Following ethical approval, 42 patients admitted to the medical ward were invited to participate in this study. Of these, 36 persons, with a mean age of 82.5 years, who were discharged to their home, were interviewed by telephone using the Medical Adherence Report Scale (MARS) to assess their general adherence to prescribed drugs. Questions regarding awareness and adherence to drug changes during their hospital stay were asked. Different factors related to adherence and non-adherence were investigated using the Pearson chi-square test and the independent sample t-test. The average MARS score was 23.9 ± 1.4, with 31 persons (86%) assessed as adherent to their drug therapy and 5 persons (14%) as non-adherent. Of the 36 people, 30 had at least one change in their drug therapy during their hospital stay, and 23 (77%) of these people were aware of all changes and 23 (77%) were adherent to all of the changes. No significant differences between adherence and age, gender, living situation, or number of drugs were found. This small study found that some older people who were discharged from hospital were generally non-adherent, and some were not aware of or adherent to changes made in the drug therapy during their hospital stay. This is an important problem to address with further interventions. View Full-Text "," pharmacy education,simulation,scenarios,computer,virtual,virtual patient,standardized patient,actor,paper-based   simulation,emergency medicine,pharmacy practice   Intervention Mapping,program development,antidepressant drugs,anxiety disorder,mood disorder,community pharmacy services,patient education,patient satisfaction,medication adherence   adherence to medications,older people "," Simulation and Feedback in Health Education: A Mixed Methods Study Comparing Three Simulation Modalities   Simulation as a Central Feature of an Elective Course: Does Simulated Bedside Care Impact Learning?   The Development of a Community Pharmacy-Based Intervention to Optimize Patients’ Use of and Experience with Antidepressants: A Step-by-Step Demonstration of the Intervention Mapping Process   Older Peoples’ Adherence and Awareness of Changes in Drug Therapy after Discharge from Hospital   Abstract
Background. There are numerous approaches to simulating a patient encounter in pharmacy education. However, little direct comparison between these approaches has been undertaken. Our objective was to investigate student experiences, satisfaction, and feedback preferences between three scenario simulation modalities (paper-, actor-, and computer-based). Methods. We conducted a mixed methods study with randomized cross-over of simulation modalities on final-year Australian graduate-entry Master of Pharmacy students. Participants completed case-based scenarios within each of three simulation modalities, with feedback provided at the completion of each scenario in a format corresponding to each simulation modality. A post-simulation questionnaire collected qualitative and quantitative responses pertaining to participant satisfaction, experiences, and feedback preferences. Results. Participants reported similar levels satisfaction across all three modalities. However, each modality resulted in unique positive and negative experiences, such as student disengagement with paper-based scenarios. Conclusion. Importantly, the themes of guidance and opportunity for peer discussion underlie the best forms of feedback for students. The provision of feedback following simulation should be carefully considered and delivered, with all three simulation modalities producing both positive and negative experiences in regard to their feedback format. View Full-Text   Abstract
A three-credit, simulation-based, emergency medicine elective course was designed and offered to doctor of pharmacy students for two years. The primary objective was to determine if there was a difference in exam performance stratified by student simulation experience, namely either as an active observer or as part of bedside clinical care. The secondary objective was to report student satisfaction. Examination performance for simulation-based questions was compared based on the student role (evaluator versus clinical) using the Student’s t-test. Summary responses from Likert scale-based student satisfaction responses were collected. A total of 24 students took the course: 12 in each offering. Performance was similar whether the student was assigned to the evaluation team or the clinical team for all of the comparisons (mid-term and final 2015 and 2016, all p-values > 0.05). Students were very satisfied with the course. Of the 19 questions assessing the qualitative aspects of the course, all of the students agreed or strongly agreed to 17 statements, and all of the students were neutral, agreed, or strongly agreed to the remaining two statements. Direct participation and active observation in simulation-based experiences appear to be equally valuable in the learning process, as evidenced by examination performance. View Full-Text   Abstract
Objective: To describe the development of a community pharmacy-based intervention aimed at optimizing experience and use of antidepressants (ADs) for patients with mood and anxiety disorders. Methods: Intervention Mapping (IM) was used for conducting needs assessment, formulating intervention objectives, selecting change methods and practical applications, designing the intervention, and planning intervention implementation. IM is based on a qualitative participatory approach and each step of the intervention development process was conducted through consultations with a pharmacists’ committee. Results: A needs assessment was informed by qualitative and quantitative studies conducted with leaders, pharmacists, and patients. Intervention objectives and change methods were selected to target factors influencing patients’ experience with and use of ADs. The intervention includes four brief consultations between the pharmacist and the patient: (1) provision of information (first AD claim); (2) management of side effects (15 days after first claim); (3) monitoring treatment efficacy (30-day renewal); (4) assessment of treatment persistence (2-month renewal, repeated every 6 months). A detailed implementation plan was also developed. Conclusion: IM provided a systematic and rigorous approach to the development of an intervention directly tied to empirical data on patients’ and pharmacists’ experiences and recommendations. The thorough description of this intervention may facilitate the development of new pharmacy-based interventions or the adaptation of this intervention to other illnesses and settings. View Full-Text   Abstract
Non-adherence is important to address because it might affect the effectiveness of therapy and lead to adverse effects. The objectives of this interview study were to investigate old peoples’ general adherence to drugs and their awareness of and adherence to changes in drug therapy after their hospital stay. Following ethical approval, 42 patients admitted to the medical ward were invited to participate in this study. Of these, 36 persons, with a mean age of 82.5 years, who were discharged to their home, were interviewed by telephone using the Medical Adherence Report Scale (MARS) to assess their general adherence to prescribed drugs. Questions regarding awareness and adherence to drug changes during their hospital stay were asked. Different factors related to adherence and non-adherence were investigated using the Pearson chi-square test and the independent sample t-test. The average MARS score was 23.9 ± 1.4, with 31 persons (86%) assessed as adherent to their drug therapy and 5 persons (14%) as non-adherent. Of the 36 people, 30 had at least one change in their drug therapy during their hospital stay, and 23 (77%) of these people were aware of all changes and 23 (77%) were adherent to all of the changes. No significant differences between adherence and age, gender, living situation, or number of drugs were found. This small study found that some older people who were discharged from hospital were generally non-adherent, and some were not aware of or adherent to changes made in the drug therapy during their hospital stay. This is an important problem to address with further interventions. View Full-Text   pharmacy education,simulation,scenarios,computer,virtual,virtual patient,standardized patient,actor,paper-based   simulation,emergency medicine,pharmacy practice   Intervention Mapping,program development,antidepressant drugs,anxiety disorder,mood disorder,community pharmacy services,patient education,patient satisfaction,medication adherence   adherence to medications,older people ", Pharmacy 
 Sovereign Adaptive Risk Modeling and Implications for the Eurozone GREXIT Case   Topological Network Analysis Based on Dissimilarity Measure of Multivariate Time Series Evolution in the Subprime Crisis   BREXIT and Foreign Direct Investment: Key Issues and New Empirical Findings ," Abstract
In the wake of the 2008 financial crisis, the Financial Stability Board (FSB) and the Basel Committee on Banking Supervision (BCBS) created a list of systemically important financial institutions (SIFIs) with the intention of determining which financial institutions were important enough to the global market that their failure would result in systemic collapse. In this work, we create a model that modifies the BCBS’s five indicators of size, interconnectedness, cross-jurisdictional activities, complexity, and substitutability and apply these measures of systemic stress to governments. Although the cross-jurisdictional activities and size were almost identical to the SIFI calculations, the others had to be adapted to mirror the intent of the BCBS. Interconnectedness is calculated by simulation of what would happen to nearby countries if a country defaulted. Substitutability is estimated by the number of services that would no longer be provided if the government ceased to exist. Complexity is market-based and is derived from credit default swap (CDS) spreads. The original application of the model was to track the systemic interdependence of the Eurozone, with particular emphasis on the case of Greece. We anticipate that this model can be used in regional fiscal situations beyond the Eurozone. View Full-Text   Abstract
Correlation network based on similarity is the common approach in financial network analyses where the Minimal Spanning Tree (MST) is used to filter the important information contained in the network. In this paper, by considering a distance matrix based on dissimilarities among multivariate time series of currency, a topological network was analyzed. A topological network can explain to what extent two or more multi-dimensional currency structures are different from each other. For this purpose, we examined the topological network of currency market from 2005 to 2011 in terms of the subprime crisis. After that, the multivariate time series evolution of MSTs were analyzed in terms of the structural changes for three periods (before, during, and after the crisis). Moreover, since the clusters of currencies in network analysis are due to regional factors, by considering each region, which is composed of a number of currencies, as an element on the financial system, we attempted to determine how a region interacts with the other regions in crisis periods. This motivated us to introduce a region-based network analysis of currencies. Since each region consisted of a different number of currencies compared to the others, the appropriate network analysis was in multivariate setting. Finally, the applications of the method were presented with the situation of a currencies crisis behavior. The results indicate significant changes in the topological structures of MSTs when their properties are compared to each other. View Full-Text   Abstract
This contribution takes a new look at the gravity equation model in relation to foreign direct investment (FDI) of leading industrialized countries which presents a useful basis for assessing certain potential impacts arising from BREXIT—the envisaged leaving of the EU by the United Kingdom. The gravity equation estimated subsequently allows one to consider the case of BREXIT and the broader role of EU membership and other variables. Looking at the period from 1985 to 2012 for a dataset which contains 34 OECD (Organisation for Economic Co-operation and Development) countries, Pseudo Poisson Maximum Likelihood (PPML) dyadic fixed estimations take into account a broad set of approaches and variables. Besides the traditional variables of the EU/EU single-market membership of the source country and of the host country, we further consider the role of trade openness as well as corporate tax rates and the ratio of inward FDI stock to total capital stock. The analysis shows that trade openness is a variable which can be largely replaced by the inward FDI stock/capital stock ratio so that gravity FDI modeling with a strong emphasis on trade openness is likely to overstate the role of trade and to understate the role of relative FDI accumulation effects. The implication for BREXIT analysis is that the UK will face three impulses for FDI inflows: (1) leaving the EU single market will strongly reduce FDI inflows; (2) if foreign ownership in UK capital stock should strongly increase in the run-up to the BREXIT year 2019, part of the dampening effects of leaving the EU will be mitigated by the increase of the FDI stock/capital stock ratio, which in turn is likely to reflect a Froot–Stein effect related to real pound depreciation for 2016–2018; (3) to the extent that the UK government will want to reinforce output growth through higher FDI inflows, a reduction of corporate taxation could generate high effects but could also stimulate a downward international corporate tax reduction game. View Full-Text "," systemic risk,sovereign default,GREXIT   similarity and sissimilarity measure,multivariate vector correlation,minimal spanning tree,regional currencies,subprime crisis,n-dimensional currencies   foreign direct investment,BREXIT,gravity equation,corporate taxation,EU single market "," Sovereign Adaptive Risk Modeling and Implications for the Eurozone GREXIT Case   Topological Network Analysis Based on Dissimilarity Measure of Multivariate Time Series Evolution in the Subprime Crisis   BREXIT and Foreign Direct Investment: Key Issues and New Empirical Findings   Abstract
In the wake of the 2008 financial crisis, the Financial Stability Board (FSB) and the Basel Committee on Banking Supervision (BCBS) created a list of systemically important financial institutions (SIFIs) with the intention of determining which financial institutions were important enough to the global market that their failure would result in systemic collapse. In this work, we create a model that modifies the BCBS’s five indicators of size, interconnectedness, cross-jurisdictional activities, complexity, and substitutability and apply these measures of systemic stress to governments. Although the cross-jurisdictional activities and size were almost identical to the SIFI calculations, the others had to be adapted to mirror the intent of the BCBS. Interconnectedness is calculated by simulation of what would happen to nearby countries if a country defaulted. Substitutability is estimated by the number of services that would no longer be provided if the government ceased to exist. Complexity is market-based and is derived from credit default swap (CDS) spreads. The original application of the model was to track the systemic interdependence of the Eurozone, with particular emphasis on the case of Greece. We anticipate that this model can be used in regional fiscal situations beyond the Eurozone. View Full-Text   Abstract
Correlation network based on similarity is the common approach in financial network analyses where the Minimal Spanning Tree (MST) is used to filter the important information contained in the network. In this paper, by considering a distance matrix based on dissimilarities among multivariate time series of currency, a topological network was analyzed. A topological network can explain to what extent two or more multi-dimensional currency structures are different from each other. For this purpose, we examined the topological network of currency market from 2005 to 2011 in terms of the subprime crisis. After that, the multivariate time series evolution of MSTs were analyzed in terms of the structural changes for three periods (before, during, and after the crisis). Moreover, since the clusters of currencies in network analysis are due to regional factors, by considering each region, which is composed of a number of currencies, as an element on the financial system, we attempted to determine how a region interacts with the other regions in crisis periods. This motivated us to introduce a region-based network analysis of currencies. Since each region consisted of a different number of currencies compared to the others, the appropriate network analysis was in multivariate setting. Finally, the applications of the method were presented with the situation of a currencies crisis behavior. The results indicate significant changes in the topological structures of MSTs when their properties are compared to each other. View Full-Text   Abstract
This contribution takes a new look at the gravity equation model in relation to foreign direct investment (FDI) of leading industrialized countries which presents a useful basis for assessing certain potential impacts arising from BREXIT—the envisaged leaving of the EU by the United Kingdom. The gravity equation estimated subsequently allows one to consider the case of BREXIT and the broader role of EU membership and other variables. Looking at the period from 1985 to 2012 for a dataset which contains 34 OECD (Organisation for Economic Co-operation and Development) countries, Pseudo Poisson Maximum Likelihood (PPML) dyadic fixed estimations take into account a broad set of approaches and variables. Besides the traditional variables of the EU/EU single-market membership of the source country and of the host country, we further consider the role of trade openness as well as corporate tax rates and the ratio of inward FDI stock to total capital stock. The analysis shows that trade openness is a variable which can be largely replaced by the inward FDI stock/capital stock ratio so that gravity FDI modeling with a strong emphasis on trade openness is likely to overstate the role of trade and to understate the role of relative FDI accumulation effects. The implication for BREXIT analysis is that the UK will face three impulses for FDI inflows: (1) leaving the EU single market will strongly reduce FDI inflows; (2) if foreign ownership in UK capital stock should strongly increase in the run-up to the BREXIT year 2019, part of the dampening effects of leaving the EU will be mitigated by the increase of the FDI stock/capital stock ratio, which in turn is likely to reflect a Froot–Stein effect related to real pound depreciation for 2016–2018; (3) to the extent that the UK government will want to reinforce output growth through higher FDI inflows, a reduction of corporate taxation could generate high effects but could also stimulate a downward international corporate tax reduction game. View Full-Text   systemic risk,sovereign default,GREXIT   similarity and sissimilarity measure,multivariate vector correlation,minimal spanning tree,regional currencies,subprime crisis,n-dimensional currencies   foreign direct investment,BREXIT,gravity equation,corporate taxation,EU single market ", International Journal of Financial Studies 
" In-Situ Contact Surface Characterization in a MEMS Ohmic Switch under Low Current Switching   Experimental Validation of External Load Effects for Micro-Contacts under Low Frequency, Low Amplitude Alternating Current (AC) Test Conditions   High Density Interconnect Microstrip Patch Antenna for 5G Base Stations with Integrated Filtering Performance   Antepartum Fetal Monitoring through a Wearable System and a Mobile Application "," Abstract
To develop robust microelectromechanical systems (MEMS) switching technology for low voltage direct current (DC) applications (1–12 V) there is a requirement for the investigation of wear caused by hot switching (contact operated while carrying a current load). Previous investigation of contact wear in the ohmic MEMS switch has been limited to either the completion of the contact switching cycles, where the device is destructively opened, or by low switching rates, making lifetime testing impractical. A novel MEMS testing platform is described that is capable of both resolving microscale changes on the contact surface between switching events and sustained high frequency switch cycling, enabling practical lifetime testing. The platform is used to investigate early surface changes in a thin-film Au contact pair on a cycle-by-cycle basis. The contact is closed at forces representative of a practical MEMS contact (<1 mN). The apparatus reveals the microscopic surface change between individual switching events. Hot switched contact wear is dominated by the molten metal bridge (MMB) phenomenon, linked to a characteristic voltage transient at contact opening and the gradual process of contact material transfer; however, during hot switching delamination phenomena are also observed, and associated with a step change in contact voltage and a greater level of surface damage. View Full-Text   Abstract
The use of micro-contacts has been demonstrated in various radio frequency (RF) applications. However, the premature failure of such devices under alternating current (AC) operations is still a hurdle to further development. In this work, modified gray scale lithography is performed to fabricate two types of gold–gold (Au–Au) micro-contacts: hemispherical-planar and hemispherical-2D pyramid. The performance of these devices was investigated under low frequency, low amplitude AC conditions with external circuit loads. A custom-made experimental setup which uses various load configurations, controls the frequency of the applied voltage and modifies the cycle rate of switch operation to obtain the contact resistance as a function of number of cycles (up to 107 cycles). Nearly 87% of the tested devices (13 out of 15 hemispherical-planar micro-contacts) were found to be in good operational condition and passed the 10 million cycle mark successfully. A steady gain and large swing in the value of contact resistance was also observed near the end of all, but one, tests. Such changes in contact resistance were found to be permanent as none of the devices recovered completely. On the other hand, the hemispherical-2D pyramid micro-contact performed better than the planar one as it also passed 107 cycle mark with low and remarkably stable contact resistance throughout the testing span. This study suggests that micro-contacts with ‘engineered’ surface structures with external loads applied are a viable solution to premature failure and high contact resistance in micro-contacts under low frequency AC operations. View Full-Text   Abstract
The elementary radiator of a planar array for next generation millimeter-wave (mm-wave) 5G base stations is described. The antenna is designed for high density interconnect (HDI) manufacturing for yielding a compact, densely-interconnected, and highly-integrable stacked structure. The layout of the single element is determined by directly optimizing key radiation features of the whole planar arrangement according to specific application-driven requirements. In addition, thanks to the exploitation of a spline-shaped modelling of the radiator, suitable performance in terms of impedance matching, realized gain, half-power beamwidth (HPBW), polarization purity, and inter-element isolation are achieved within the 28-GHz pass-band. Moreover, integrated out-of-band filtering capabilities are obtained in selected and wide non-contiguous stop-bands without additional circuitry. View Full-Text   Abstract
Prenatal monitoring of Fetal Heart Rate (FHR) is crucial for the prevention of fetal pathologies and unfavorable deliveries. However, the most commonly used Cardiotocographic exam can be performed only in hospital-like structures and requires the supervision of expert personnel. For this reason, a wearable system able to continuously monitor FHR would be a noticeable step towards a personalized and remote pregnancy care. Thanks to textile electrodes, miniaturized electronics, and smart devices like smartphones and tablets, we developed a wearable integrated system for everyday fetal monitoring during the last weeks of pregnancy. Pregnant women at home can use it without the need for any external support by clinicians. The transmission of FHR to a specialized medical center allows its remote analysis, exploiting advanced algorithms running on high-performance hardware able to obtain the best classification of the fetal condition. The system has been tested on a limited set of pregnant women whose fetal electrocardiogram recordings were acquired and classified, yielding an overall score for both accuracy and sensitivity over 90%. This novel approach can open a new perspective on the continuous monitoring of fetus development by enhancing the performance of regular examinations, making treatments really personalized, and reducing hospitalization or ambulatory visits. View Full-Text "," microelectromechanical systems (MEMS) switching,contact wear,surface wear,direct current (DC) switching,hot switching,low current switching   microcontact,gray scale lithography,hemispherical-planar,hemispherical-2D pyramid,external loads effects   5G base station,mm-wave antenna design,high density interconnect (HDI),filtering antenna,spline shape,embedded element analysis   tele-monitoring,wearable devices,fetal heart rate,telemedicine "," In-Situ Contact Surface Characterization in a MEMS Ohmic Switch under Low Current Switching   Experimental Validation of External Load Effects for Micro-Contacts under Low Frequency, Low Amplitude Alternating Current (AC) Test Conditions   High Density Interconnect Microstrip Patch Antenna for 5G Base Stations with Integrated Filtering Performance   Antepartum Fetal Monitoring through a Wearable System and a Mobile Application   Abstract
To develop robust microelectromechanical systems (MEMS) switching technology for low voltage direct current (DC) applications (1–12 V) there is a requirement for the investigation of wear caused by hot switching (contact operated while carrying a current load). Previous investigation of contact wear in the ohmic MEMS switch has been limited to either the completion of the contact switching cycles, where the device is destructively opened, or by low switching rates, making lifetime testing impractical. A novel MEMS testing platform is described that is capable of both resolving microscale changes on the contact surface between switching events and sustained high frequency switch cycling, enabling practical lifetime testing. The platform is used to investigate early surface changes in a thin-film Au contact pair on a cycle-by-cycle basis. The contact is closed at forces representative of a practical MEMS contact (<1 mN). The apparatus reveals the microscopic surface change between individual switching events. Hot switched contact wear is dominated by the molten metal bridge (MMB) phenomenon, linked to a characteristic voltage transient at contact opening and the gradual process of contact material transfer; however, during hot switching delamination phenomena are also observed, and associated with a step change in contact voltage and a greater level of surface damage. View Full-Text   Abstract
The use of micro-contacts has been demonstrated in various radio frequency (RF) applications. However, the premature failure of such devices under alternating current (AC) operations is still a hurdle to further development. In this work, modified gray scale lithography is performed to fabricate two types of gold–gold (Au–Au) micro-contacts: hemispherical-planar and hemispherical-2D pyramid. The performance of these devices was investigated under low frequency, low amplitude AC conditions with external circuit loads. A custom-made experimental setup which uses various load configurations, controls the frequency of the applied voltage and modifies the cycle rate of switch operation to obtain the contact resistance as a function of number of cycles (up to 107 cycles). Nearly 87% of the tested devices (13 out of 15 hemispherical-planar micro-contacts) were found to be in good operational condition and passed the 10 million cycle mark successfully. A steady gain and large swing in the value of contact resistance was also observed near the end of all, but one, tests. Such changes in contact resistance were found to be permanent as none of the devices recovered completely. On the other hand, the hemispherical-2D pyramid micro-contact performed better than the planar one as it also passed 107 cycle mark with low and remarkably stable contact resistance throughout the testing span. This study suggests that micro-contacts with ‘engineered’ surface structures with external loads applied are a viable solution to premature failure and high contact resistance in micro-contacts under low frequency AC operations. View Full-Text   Abstract
The elementary radiator of a planar array for next generation millimeter-wave (mm-wave) 5G base stations is described. The antenna is designed for high density interconnect (HDI) manufacturing for yielding a compact, densely-interconnected, and highly-integrable stacked structure. The layout of the single element is determined by directly optimizing key radiation features of the whole planar arrangement according to specific application-driven requirements. In addition, thanks to the exploitation of a spline-shaped modelling of the radiator, suitable performance in terms of impedance matching, realized gain, half-power beamwidth (HPBW), polarization purity, and inter-element isolation are achieved within the 28-GHz pass-band. Moreover, integrated out-of-band filtering capabilities are obtained in selected and wide non-contiguous stop-bands without additional circuitry. View Full-Text   Abstract
Prenatal monitoring of Fetal Heart Rate (FHR) is crucial for the prevention of fetal pathologies and unfavorable deliveries. However, the most commonly used Cardiotocographic exam can be performed only in hospital-like structures and requires the supervision of expert personnel. For this reason, a wearable system able to continuously monitor FHR would be a noticeable step towards a personalized and remote pregnancy care. Thanks to textile electrodes, miniaturized electronics, and smart devices like smartphones and tablets, we developed a wearable integrated system for everyday fetal monitoring during the last weeks of pregnancy. Pregnant women at home can use it without the need for any external support by clinicians. The transmission of FHR to a specialized medical center allows its remote analysis, exploiting advanced algorithms running on high-performance hardware able to obtain the best classification of the fetal condition. The system has been tested on a limited set of pregnant women whose fetal electrocardiogram recordings were acquired and classified, yielding an overall score for both accuracy and sensitivity over 90%. This novel approach can open a new perspective on the continuous monitoring of fetus development by enhancing the performance of regular examinations, making treatments really personalized, and reducing hospitalization or ambulatory visits. View Full-Text   microelectromechanical systems (MEMS) switching,contact wear,surface wear,direct current (DC) switching,hot switching,low current switching   microcontact,gray scale lithography,hemispherical-planar,hemispherical-2D pyramid,external loads effects   5G base station,mm-wave antenna design,high density interconnect (HDI),filtering antenna,spline shape,embedded element analysis   tele-monitoring,wearable devices,fetal heart rate,telemedicine ", Technologies 
 Effects of Conditional Cash Transfers (CCT) in Anti-Poverty Programs. An Empirical Approach with Panel Data for the Mexican Case of PROSPERA-Oportunidades (2002–2012)   Private Sector Credit and Inflation Volatility   The Effects of Fiscal Policy on Non-Oil Economic Growth   Shaking up the Firm Survival: Evidence from Yogyakarta (Indonesia) ," Abstract
Conditional Cash Transfer Programs (CCT) have been implemented in México and Latin America since the late 1990’s. This type of program focuses on providing social government services by way of direct cash transfers to poor families that are often conditioned to the use of public education and health services. Despite the apparent short-term success of these CCT programs in the Latin American context, there still is much debate about whether CCT programs are effective in alleviating poverty. This paper analyzes the effectiveness of conditional cash transfer programs as a long-term incentive in the use of public services—health and education—among beneficiary families of PROSPERA-Oportunidades in Mexico. The Average Effect of Treatment on the Treated (ATT) for the time period 2002–2012 is estimated based on data from the Mexican Family Life Survey (MxFLS) using Propensity Score Matching (PSM). The results show that the program’s impact on the use of preventive health and education services by poor families cannot be sustained in the long-term, which puts in doubt the effectiveness of this social protection intervention program in combating poverty in Mexico. View Full-Text   Abstract
This paper investigates the effect of inflation volatility on private sector credit growth. The results indicate that private sector credit growth is positively linked to the one period lagged inflation volatility. Given that past monetary policy actions continue to affect the targeted variables due to the substantial lags in the transmission mechanism, the positive response of private sector credit growth to past inflation volatility suggests a credible monetary policy regime in Uganda, which has led to a reduction in the level of macroeconomic uncertainty and the restoration of favorable economic conditions and prospects, thus increasing the demand for credit. Further, the study finds that the lagged private sector credit growth, nominal exchange rate, and inflation have a statistically significant effect on private sector credit growth while financial innovation, interest rates, and GDP growth appear not to be important determinants of private sector credit growth. The robustness of our findings is confirmed by sensitivity checks. View Full-Text   Abstract
We investigate non-oil sector effects of fiscal policy in Azerbaijan over a long time period in which a recent low oil prices sample is incorporated. To obtain robust empirical findings, we use different test and estimation methods as well as address small-sample bias issues in the extended production function framework. Results show that fiscal policy has a statistically significant positive impact on the non-oil sector both in the long and short run. However, the size of the impact is small compared to the findings of earlier studies due to, we believe, the low oil-price environment and different specifications used. Azerbaijani policymakers should take measures to compensate for the declining share of oil revenues in government revenues. They may consider increasing tax rates, import and export fees, energy and other tariffs as rapid remedies to fill the budget but these measures might hurt economic development. Alternative and less harmful remedies would be optimizing government spending, strongly monitoring ongoing projects, and phasing out social and infrastructure projects, which make lower contributions to growth. Our research opens the way for further investigation of this topic for the oil exporting economies in the future. View Full-Text   Abstract
The survival of firms under changes in the business environment caused by exogenous shocks can be explained using economic Darwinism. Exogenous shocks can cause ‘cleansing effects’. Shocks clean out unproductive firms so that available resources are allocated to the remaining more productive firms. However, shocks may also force out young firms that have the potential to be highly productive in the future, which will lower the average productivity of industries. This is known as the ‘scarring effect’ of shocks. Therefore, the overall impact of exogenous shocks on the allocation of resources depends on the relative magnitude of cleansing and scarring effects. This paper investigates this natural selection mechanism after the Yogyakarta earthquake in 2006. The study uses data on medium-sized and large manufacturing firms in the Yogyakarta province collected by the Indonesian Statistical Agency. The main finding of this paper is that firms that had higher productivity prior to the earthquake in 2006 were more likely to survive after the earthquake, which suggests the existence of a natural selection mechanism, specifically cleansing effects. There is no evidence of the scarring effects of the earthquake on the new entrants. View Full-Text "," poverty,conditionality,social protection,panel data analysis,Sustainable Development Goals (SDGs)   private sector credit,inflation volatility,exchange rates   Azerbaijan economy,fiscal policy,non-oil sector,cointegration,error-correction modeling,Johansen approach,autoregressive distributed lags bounds testing approach   firm’s survival,exogenous shock,Yogyakarta earthquake,Indonesia "," Effects of Conditional Cash Transfers (CCT) in Anti-Poverty Programs. An Empirical Approach with Panel Data for the Mexican Case of PROSPERA-Oportunidades (2002–2012)   Private Sector Credit and Inflation Volatility   The Effects of Fiscal Policy on Non-Oil Economic Growth   Shaking up the Firm Survival: Evidence from Yogyakarta (Indonesia)   Abstract
Conditional Cash Transfer Programs (CCT) have been implemented in México and Latin America since the late 1990’s. This type of program focuses on providing social government services by way of direct cash transfers to poor families that are often conditioned to the use of public education and health services. Despite the apparent short-term success of these CCT programs in the Latin American context, there still is much debate about whether CCT programs are effective in alleviating poverty. This paper analyzes the effectiveness of conditional cash transfer programs as a long-term incentive in the use of public services—health and education—among beneficiary families of PROSPERA-Oportunidades in Mexico. The Average Effect of Treatment on the Treated (ATT) for the time period 2002–2012 is estimated based on data from the Mexican Family Life Survey (MxFLS) using Propensity Score Matching (PSM). The results show that the program’s impact on the use of preventive health and education services by poor families cannot be sustained in the long-term, which puts in doubt the effectiveness of this social protection intervention program in combating poverty in Mexico. View Full-Text   Abstract
This paper investigates the effect of inflation volatility on private sector credit growth. The results indicate that private sector credit growth is positively linked to the one period lagged inflation volatility. Given that past monetary policy actions continue to affect the targeted variables due to the substantial lags in the transmission mechanism, the positive response of private sector credit growth to past inflation volatility suggests a credible monetary policy regime in Uganda, which has led to a reduction in the level of macroeconomic uncertainty and the restoration of favorable economic conditions and prospects, thus increasing the demand for credit. Further, the study finds that the lagged private sector credit growth, nominal exchange rate, and inflation have a statistically significant effect on private sector credit growth while financial innovation, interest rates, and GDP growth appear not to be important determinants of private sector credit growth. The robustness of our findings is confirmed by sensitivity checks. View Full-Text   Abstract
We investigate non-oil sector effects of fiscal policy in Azerbaijan over a long time period in which a recent low oil prices sample is incorporated. To obtain robust empirical findings, we use different test and estimation methods as well as address small-sample bias issues in the extended production function framework. Results show that fiscal policy has a statistically significant positive impact on the non-oil sector both in the long and short run. However, the size of the impact is small compared to the findings of earlier studies due to, we believe, the low oil-price environment and different specifications used. Azerbaijani policymakers should take measures to compensate for the declining share of oil revenues in government revenues. They may consider increasing tax rates, import and export fees, energy and other tariffs as rapid remedies to fill the budget but these measures might hurt economic development. Alternative and less harmful remedies would be optimizing government spending, strongly monitoring ongoing projects, and phasing out social and infrastructure projects, which make lower contributions to growth. Our research opens the way for further investigation of this topic for the oil exporting economies in the future. View Full-Text   Abstract
The survival of firms under changes in the business environment caused by exogenous shocks can be explained using economic Darwinism. Exogenous shocks can cause ‘cleansing effects’. Shocks clean out unproductive firms so that available resources are allocated to the remaining more productive firms. However, shocks may also force out young firms that have the potential to be highly productive in the future, which will lower the average productivity of industries. This is known as the ‘scarring effect’ of shocks. Therefore, the overall impact of exogenous shocks on the allocation of resources depends on the relative magnitude of cleansing and scarring effects. This paper investigates this natural selection mechanism after the Yogyakarta earthquake in 2006. The study uses data on medium-sized and large manufacturing firms in the Yogyakarta province collected by the Indonesian Statistical Agency. The main finding of this paper is that firms that had higher productivity prior to the earthquake in 2006 were more likely to survive after the earthquake, which suggests the existence of a natural selection mechanism, specifically cleansing effects. There is no evidence of the scarring effects of the earthquake on the new entrants. View Full-Text   poverty,conditionality,social protection,panel data analysis,Sustainable Development Goals (SDGs)   private sector credit,inflation volatility,exchange rates   Azerbaijan economy,fiscal policy,non-oil sector,cointegration,error-correction modeling,Johansen approach,autoregressive distributed lags bounds testing approach   firm’s survival,exogenous shock,Yogyakarta earthquake,Indonesia ", Economies 
" Solving Power Balance Problems in Single-Traction Tractors Using PTractor Plus 1.1, a Possible Learning Aid for Students of Agricultural Engineering   The StarT Project Competition from the Perspective of Mathematics and Academic Literacy   Music Education for All: The raison d’être of Music Schools   The Myth That Only Brilliant People Are Good at Math and Its Implications for Diversity "," Abstract
Tractors are used to perform jobs that require different types of agricultural tools to be attached to their rear, to their front, or both. These tools may need to be dragged, towed, or suspended above ground, and sometimes require a power supply; this is usually obtained via a hydraulic system or from the tractor’s power take-off system. When tractors have to work with such tools on different types of soils and on different slopes, the need arises to calculate the power the tractor engine will have to produce. In the classroom, this is normally calculated manually with the help of a calculator. This work, however, describes a computer program (written in Delphi and operating under Windows) that rapidly solves the most common types of power balance problems associated with single-traction tractors. The value of this software as a learning aid for students of agricultural engineering is discussed. View Full-Text   Abstract
This article concerns mathematical project work in the context of Finnish StarT project competition. The focus is on how well pupils achieve the learning objective of their project work: learning mathematics and practicing 21st century skills. Development of the learning objectives is considered from the viewpoint of Finnish national core curriculum and evaluated using the framework of academic literacy. The research material consists of teams’ project reports, observation, and questionnaires. Project work in the StarT competition seems to develop the learning objectives of project-based learning: pupils practice 21st century skills while studying mathematical contents. View Full-Text   Abstract
Music schools, centres of non-formal music education, bring music to people of all ages as they work to achieve their main objective of offering practical musical training, for both instruments and voice. Their activities are centred in the town or city in which they are located, and their impact extends beyond the educational sphere: music schools are also a social force whose activities stimulate the local cultural scene. This study explores the work carried out by these schools in the Basque Country (Spain), where they have been operating for over 20 years. The analysis focuses on the range of music education they offer, their ability to respond to different demands and needs and how they relate to their social and educational environment. Furthermore, the paper examines whether music schools see other potential areas for growth and development and explores the factors that could positively or negatively impact their ability to achieve their objectives. The study adopts a description-oriented empirical-analytical methodology and applies the SWOT system. A total of 67 schools were included in the study. The results reveal the relevance of this ever-evolving model of education and confirm music schools as a key force in both music education and the sociocultural sphere in this country. View Full-Text   Abstract
A common misconception about math is that it requires raw intellectual talent or “brilliance.” Only students who possess this sort of brilliance are assumed to be capable of success in math-related subjects. This harmful myth has far-reaching consequences for the success of girls and children from ethnic-minority backgrounds in these subjects. Because women and minorities are stereotyped as lacking brilliance, the myth that success in math requires this trait is a barrier that students from these groups have to overcome. In the first part of this paper, we detail the pervasiveness of this myth and explore its relation to gender and race gaps in math and beyond. In the second part, we highlight some potential sources of this myth in children’s everyday experiences and offer some strategies for debunking it. View Full-Text "," improving classroom teaching,simulations,teaching/learning strategies   project-based learning,academic literacy,mathematics,education   music schools,education and society,lifelong learning,non-formal education   brilliance,giftedness,stereotypes,gender gaps,race gaps,mindsets "," Solving Power Balance Problems in Single-Traction Tractors Using PTractor Plus 1.1, a Possible Learning Aid for Students of Agricultural Engineering   The StarT Project Competition from the Perspective of Mathematics and Academic Literacy   Music Education for All: The raison d’être of Music Schools   The Myth That Only Brilliant People Are Good at Math and Its Implications for Diversity   Abstract
Tractors are used to perform jobs that require different types of agricultural tools to be attached to their rear, to their front, or both. These tools may need to be dragged, towed, or suspended above ground, and sometimes require a power supply; this is usually obtained via a hydraulic system or from the tractor’s power take-off system. When tractors have to work with such tools on different types of soils and on different slopes, the need arises to calculate the power the tractor engine will have to produce. In the classroom, this is normally calculated manually with the help of a calculator. This work, however, describes a computer program (written in Delphi and operating under Windows) that rapidly solves the most common types of power balance problems associated with single-traction tractors. The value of this software as a learning aid for students of agricultural engineering is discussed. View Full-Text   Abstract
This article concerns mathematical project work in the context of Finnish StarT project competition. The focus is on how well pupils achieve the learning objective of their project work: learning mathematics and practicing 21st century skills. Development of the learning objectives is considered from the viewpoint of Finnish national core curriculum and evaluated using the framework of academic literacy. The research material consists of teams’ project reports, observation, and questionnaires. Project work in the StarT competition seems to develop the learning objectives of project-based learning: pupils practice 21st century skills while studying mathematical contents. View Full-Text   Abstract
Music schools, centres of non-formal music education, bring music to people of all ages as they work to achieve their main objective of offering practical musical training, for both instruments and voice. Their activities are centred in the town or city in which they are located, and their impact extends beyond the educational sphere: music schools are also a social force whose activities stimulate the local cultural scene. This study explores the work carried out by these schools in the Basque Country (Spain), where they have been operating for over 20 years. The analysis focuses on the range of music education they offer, their ability to respond to different demands and needs and how they relate to their social and educational environment. Furthermore, the paper examines whether music schools see other potential areas for growth and development and explores the factors that could positively or negatively impact their ability to achieve their objectives. The study adopts a description-oriented empirical-analytical methodology and applies the SWOT system. A total of 67 schools were included in the study. The results reveal the relevance of this ever-evolving model of education and confirm music schools as a key force in both music education and the sociocultural sphere in this country. View Full-Text   Abstract
A common misconception about math is that it requires raw intellectual talent or “brilliance.” Only students who possess this sort of brilliance are assumed to be capable of success in math-related subjects. This harmful myth has far-reaching consequences for the success of girls and children from ethnic-minority backgrounds in these subjects. Because women and minorities are stereotyped as lacking brilliance, the myth that success in math requires this trait is a barrier that students from these groups have to overcome. In the first part of this paper, we detail the pervasiveness of this myth and explore its relation to gender and race gaps in math and beyond. In the second part, we highlight some potential sources of this myth in children’s everyday experiences and offer some strategies for debunking it. View Full-Text   improving classroom teaching,simulations,teaching/learning strategies   project-based learning,academic literacy,mathematics,education   music schools,education and society,lifelong learning,non-formal education   brilliance,giftedness,stereotypes,gender gaps,race gaps,mindsets ", Education Sciences 
 Integrated Chemometrics and Statistics to Drive Successful Proteomics Biomarker Discovery   A Proteomic View of Salmonella Typhimurium in Response to Phosphate Limitation   Surface and Extracellular Proteome of the Emerging Pathogen Corynebacterium ulcerans   Molecular Pathophysiology of Epithelial Barrier Dysfunction in Inflammatory Bowel Diseases ," Abstract
Protein biomarkers are of great benefit for clinical research and applications, as they are powerful means for diagnosing, monitoring and treatment prediction of different diseases. Even though numerous biomarkers have been reported, the translation to clinical practice is still limited. This mainly due to: (i) incorrect biomarker selection, (ii) insufficient validation of potential biomarkers, and (iii) insufficient clinical use. In this review, we focus on the biomarker selection process and critically discuss the chemometrical and statistical decisions made in proteomics biomarker discovery to increase to selection of high value biomarkers. The characteristics of the data, the computational resources, the type of biomarker that is searched for and the validation strategy influence the decision making of the chemometrical and statistical methods and a decision made for one component directly influences the choice for another. Incorrect decisions could increase the false positive and negative rate of biomarkers which requires independent confirmation of outcome by other techniques and for comparison between different related studies. There are few guidelines for authors regarding data analysis documentation in peer reviewed journals, making it hard to reproduce successful data analysis strategies. Here we review multiple chemometrical and statistical methods for their value in proteomics-based biomarker discovery and propose to include key components in scientific documentation.   Abstract
Salmonella enterica serovar Typhimurium (S. Typhimurium), an important foodborne pathogen, often encounters phosphate (Pi) shortage both in the environment and inside host cells. To gain a global view on its physiological responses to Pi starvation, we performed proteomic profiling of S. Typhimurium upon the shift from Pi-rich to Pi-low conditions. In addition to the Pho regulon, many metabolic processes were up-regulated, such as glycolysis, pentose phosphate pathway, pyrimidine degradation, glycogen, and trehalose metabolism, allowing us to chart an overview of S. Typhimurium carbon metabolism under Pi starvation. Furthermore, proteomic analysis of a mutant lacking phoB (that encodes a key regulator of Pi shortage response) suggested that only a small subset of the altered proteins upon Pi limitation was PhoB-dependent. Importantly, we present evidence that S. Typhimurium N-acetylglucosamine catabolism was induced under Pi-limiting conditions in a PhoB-dependent manner. Immunoblotting and β-galactosidase assays demonstrated that PhoB was required for the full activation of NagB, a key enzyme of this pathway, in response to low Pi. Thus, our study reveals that N-acetylglucosamine catabolism may represent an additional PhoB-regulated pathway to tackle bacterial Pi shortage. View Full-Text   Abstract
Corynebacterium ulcerans is an emerging pathogen, which is increasingly recognized as an etiological agent of diphtheria, but can also evoke ulcers of the skin and systemic infections in humans. Besides man, the bacteria can colonize a wide variety of different animals, including cattle and pet animals, which might serve as a reservoir for human infections. In this study, surface-located proteins and the exoproteome of two Corynebacterium ulcerans strains were analyzed, since these may have key roles in the interaction of the pathogen with host cells. Strain 809 was isolated from a fatal case of human respiratory tract infection, while strain BR-AD22 was isolated from a nasal swap of an asymptomatic dog. While a very similar pattern of virulence factors was observed in the culture supernatant and surface protein fractions of the two strains, proteome analyses revealed a higher stability of 809 cells compared to strain BR-AD22. During exponential growth, 17% of encoded proteins of strain 809 were detectable in the medium, while 38% of the predicted proteins encoded by the BR-AD22 chromosome were found. Furthermore, the data indicate differential expression of phospholipase D and a cell wall-associated hydrolase, since these were only detected in strain BR-AD22. View Full-Text   Abstract
Over the years, the scientific community has explored myriads of theories in search of the etiology and a cure for inflammatory bowel disease (IBD). The cumulative evidence has pointed to the key role of the intestinal barrier and the breakdown of these mechanisms in IBD. More and more scientists and clinicians are embracing the concept of the impaired intestinal epithelial barrier and its role in the pathogenesis and natural history of IBD. However, we are missing a key tool that bridges these scientific insights to clinical practice. Our goal is to overcome the limitations in understanding the molecular physiology of intestinal barrier function and develop a clinical tool to assess and quantify it. This review article explores the proteins in the intestinal tissue that are pivotal in regulating intestinal permeability. Understanding the molecular pathophysiology of impaired intestinal barrier function in IBD may lead to the development of a biochemical method of assessing intestinal tissue integrity which will have a significant impact on the development of novel therapies targeting the intestinal mucosa. View Full-Text "," biomarker,clinical proteomics,chemometrics,statistics,preprocessing,classification models,feature reduction,review   Salmonella Typhimurium,phosphate starvation,the PhoR-PhoB two-component system,the nag operon   diphtheria,exoproteome,genomics,host-pathogen interaction,surface proteome,virulence factors   intestinal barrier function,inflammatory bowel disease "," Integrated Chemometrics and Statistics to Drive Successful Proteomics Biomarker Discovery   A Proteomic View of Salmonella Typhimurium in Response to Phosphate Limitation   Surface and Extracellular Proteome of the Emerging Pathogen Corynebacterium ulcerans   Molecular Pathophysiology of Epithelial Barrier Dysfunction in Inflammatory Bowel Diseases   Abstract
Protein biomarkers are of great benefit for clinical research and applications, as they are powerful means for diagnosing, monitoring and treatment prediction of different diseases. Even though numerous biomarkers have been reported, the translation to clinical practice is still limited. This mainly due to: (i) incorrect biomarker selection, (ii) insufficient validation of potential biomarkers, and (iii) insufficient clinical use. In this review, we focus on the biomarker selection process and critically discuss the chemometrical and statistical decisions made in proteomics biomarker discovery to increase to selection of high value biomarkers. The characteristics of the data, the computational resources, the type of biomarker that is searched for and the validation strategy influence the decision making of the chemometrical and statistical methods and a decision made for one component directly influences the choice for another. Incorrect decisions could increase the false positive and negative rate of biomarkers which requires independent confirmation of outcome by other techniques and for comparison between different related studies. There are few guidelines for authors regarding data analysis documentation in peer reviewed journals, making it hard to reproduce successful data analysis strategies. Here we review multiple chemometrical and statistical methods for their value in proteomics-based biomarker discovery and propose to include key components in scientific documentation.   Abstract
Salmonella enterica serovar Typhimurium (S. Typhimurium), an important foodborne pathogen, often encounters phosphate (Pi) shortage both in the environment and inside host cells. To gain a global view on its physiological responses to Pi starvation, we performed proteomic profiling of S. Typhimurium upon the shift from Pi-rich to Pi-low conditions. In addition to the Pho regulon, many metabolic processes were up-regulated, such as glycolysis, pentose phosphate pathway, pyrimidine degradation, glycogen, and trehalose metabolism, allowing us to chart an overview of S. Typhimurium carbon metabolism under Pi starvation. Furthermore, proteomic analysis of a mutant lacking phoB (that encodes a key regulator of Pi shortage response) suggested that only a small subset of the altered proteins upon Pi limitation was PhoB-dependent. Importantly, we present evidence that S. Typhimurium N-acetylglucosamine catabolism was induced under Pi-limiting conditions in a PhoB-dependent manner. Immunoblotting and β-galactosidase assays demonstrated that PhoB was required for the full activation of NagB, a key enzyme of this pathway, in response to low Pi. Thus, our study reveals that N-acetylglucosamine catabolism may represent an additional PhoB-regulated pathway to tackle bacterial Pi shortage. View Full-Text   Abstract
Corynebacterium ulcerans is an emerging pathogen, which is increasingly recognized as an etiological agent of diphtheria, but can also evoke ulcers of the skin and systemic infections in humans. Besides man, the bacteria can colonize a wide variety of different animals, including cattle and pet animals, which might serve as a reservoir for human infections. In this study, surface-located proteins and the exoproteome of two Corynebacterium ulcerans strains were analyzed, since these may have key roles in the interaction of the pathogen with host cells. Strain 809 was isolated from a fatal case of human respiratory tract infection, while strain BR-AD22 was isolated from a nasal swap of an asymptomatic dog. While a very similar pattern of virulence factors was observed in the culture supernatant and surface protein fractions of the two strains, proteome analyses revealed a higher stability of 809 cells compared to strain BR-AD22. During exponential growth, 17% of encoded proteins of strain 809 were detectable in the medium, while 38% of the predicted proteins encoded by the BR-AD22 chromosome were found. Furthermore, the data indicate differential expression of phospholipase D and a cell wall-associated hydrolase, since these were only detected in strain BR-AD22. View Full-Text   Abstract
Over the years, the scientific community has explored myriads of theories in search of the etiology and a cure for inflammatory bowel disease (IBD). The cumulative evidence has pointed to the key role of the intestinal barrier and the breakdown of these mechanisms in IBD. More and more scientists and clinicians are embracing the concept of the impaired intestinal epithelial barrier and its role in the pathogenesis and natural history of IBD. However, we are missing a key tool that bridges these scientific insights to clinical practice. Our goal is to overcome the limitations in understanding the molecular physiology of intestinal barrier function and develop a clinical tool to assess and quantify it. This review article explores the proteins in the intestinal tissue that are pivotal in regulating intestinal permeability. Understanding the molecular pathophysiology of impaired intestinal barrier function in IBD may lead to the development of a biochemical method of assessing intestinal tissue integrity which will have a significant impact on the development of novel therapies targeting the intestinal mucosa. View Full-Text   biomarker,clinical proteomics,chemometrics,statistics,preprocessing,classification models,feature reduction,review   Salmonella Typhimurium,phosphate starvation,the PhoR-PhoB two-component system,the nag operon   diphtheria,exoproteome,genomics,host-pathogen interaction,surface proteome,virulence factors   intestinal barrier function,inflammatory bowel disease ", Proteomes 
 The Role of Adult Day Services in Supporting the Occupational Participation of People with Dementia and Their Carers: An Integrative Review   The Delivery of Health Promotion and Environmental Health Services; Public Health or Primary Care Settings?   Assessing the Effectiveness of the Aging Mastery Program   Skin Protective Nutraceuticals: The Current Evidence in Brief ," Abstract
The increasing numbers of people with dementia places considerable stress on health and aged care services and has resulted in the development of community adult day services. Aim: The aim of this integrative review is to determine the extent to which these services support the occupational participation of people with dementia, and how they impact their primary carers. Method: The mixed-methods appraisal tool (MMAT) was used to identify relevant studies in the period 2011–2016. Results: Nine databases were searched and yielded 16 articles with a variety of research designs for inclusion in the review. Conclusions: Findings indicate that adult day services use a range of approaches to support attendees and their carers. In spite of these efforts, there appears to be a lack of interest in utilizing these services while a person is in the early stages of dementia. This suggests that policies in aged care, such as aging-in-place, need to consider the pressure and stress they exert on carer’s quality of life. Another consideration is to better promote the benefits of participating in adult day services in the early stages of dementia for both the attendees and their carers, thereby delaying the tendency towards early institutionalization. View Full-Text   Abstract
The WHO Regional Office for Europe developed a set of public health functions resulting in the ten Essential Public Health Operations (EPHO). Public health or primary care settings seem to be favorable to embrace all actions included into EPHOs. The presented paper aims to guide readers on how to assign individual health promotion and environmental health services to public health or primary care settings. Survey tools were developed based on EPHO 2, 3 and 4; there were six key informant surveys out of 18 contacted completed via e-mails by informants working in Denmark on health promotion and five face-to-face interviews were conducted in Australia (Melbourne and Victoria state) with experts from environmental health, public health and a physician. Based on interviews, we developed a set of indicators to support the assignment process. Population or individual focus, a system approach or one-to-one approach, dealing with hazards or dealing with effects, being proactive or reactive were identified as main element of the decision tool. Assignment of public health services to one of two settings proved to be possible in some cases, whereas in many there is no clear distinction between the two settings. National context might be the one which guides delivery of public health services. View Full-Text   Abstract
Background: Successful aging is best determined by active management and self-determination of one’s aging roadmap. Some individuals are ready to respond to these challenges, others may benefit from assistance that might be offered through an evidence-based intervention. The Aging Mastery Program® (AMP) has been developed to meet these needs. Method: In a cross over design the intervention was tested in ten senior centers and aging network agencies looking at impacts upon general health and quality of life, patient activation, physical activity and advanced care planning. Results: There was a statistically significant (tested at a 0.05 level) level of improvement found in physical activity and advanced care planning. Conclusion: Findings support the program’s effectiveness and its value as an evidence-based intervention for older adult programming. View Full-Text   Abstract
Nutraceuticals are important for healthy skin maintenance. Probiotics, phenolics, and vitamins are just a few of the nutraceuticals meant to potentially prevent and assist medical management of dermatologic conditions. Among these, probiotics, vitamin E, and green tea catechins may offer the broadest array of skin protective mechanisms with probiotics having the greatest clinical range. Probiotics’ amelioration of atopic dermatitis and opportunistic infections of skin burns has been targeted in recent research efforts. This includes the improvement of Scoring Atopic Dermatitis index scores, p = 0.02, with intact Lactobacillus rhamnosus Goldin and Gorbach (LGG) in comparison to heat inactivated LGG or placebo. Lactobacillus reuteri used prior to or concurrently with Staphylococcus aureus infection can increase epidermal keratinocyte survival, p < 0.01. Phenolics may not have been extensively studied for atopic dermatitis or skin burns. However, phenolics do have a role in photoprotection. The phenolic rutin increases ultraviolet B radiation filter reactive oxygen species scavenging at 75%, p < 0.002, and peak wavelength absorption, p < 0.001. While oral and topical probiotics have untapped potential for atopic dermatitis amelioration and skin infection prevention, phenolics will be increasingly used for photoprotection. With optimized bioavailability, dosage, and formulation, nutraceuticals will become crucial for healthy skin maintenance. View Full-Text "," adult day services,adult day care center,community-based services,dementia,occupation,primary carers   public health operations,settings,decision tools,primary care   physical activity,advanced planning,aging,evidence-based   atopic dermatitis,green tea,human skin,keratinocyte,moisturizer,nutraceuticals,photoprotection,polyphenols,probiotics,vitamin E "," The Role of Adult Day Services in Supporting the Occupational Participation of People with Dementia and Their Carers: An Integrative Review   The Delivery of Health Promotion and Environmental Health Services; Public Health or Primary Care Settings?   Assessing the Effectiveness of the Aging Mastery Program   Skin Protective Nutraceuticals: The Current Evidence in Brief   Abstract
The increasing numbers of people with dementia places considerable stress on health and aged care services and has resulted in the development of community adult day services. Aim: The aim of this integrative review is to determine the extent to which these services support the occupational participation of people with dementia, and how they impact their primary carers. Method: The mixed-methods appraisal tool (MMAT) was used to identify relevant studies in the period 2011–2016. Results: Nine databases were searched and yielded 16 articles with a variety of research designs for inclusion in the review. Conclusions: Findings indicate that adult day services use a range of approaches to support attendees and their carers. In spite of these efforts, there appears to be a lack of interest in utilizing these services while a person is in the early stages of dementia. This suggests that policies in aged care, such as aging-in-place, need to consider the pressure and stress they exert on carer’s quality of life. Another consideration is to better promote the benefits of participating in adult day services in the early stages of dementia for both the attendees and their carers, thereby delaying the tendency towards early institutionalization. View Full-Text   Abstract
The WHO Regional Office for Europe developed a set of public health functions resulting in the ten Essential Public Health Operations (EPHO). Public health or primary care settings seem to be favorable to embrace all actions included into EPHOs. The presented paper aims to guide readers on how to assign individual health promotion and environmental health services to public health or primary care settings. Survey tools were developed based on EPHO 2, 3 and 4; there were six key informant surveys out of 18 contacted completed via e-mails by informants working in Denmark on health promotion and five face-to-face interviews were conducted in Australia (Melbourne and Victoria state) with experts from environmental health, public health and a physician. Based on interviews, we developed a set of indicators to support the assignment process. Population or individual focus, a system approach or one-to-one approach, dealing with hazards or dealing with effects, being proactive or reactive were identified as main element of the decision tool. Assignment of public health services to one of two settings proved to be possible in some cases, whereas in many there is no clear distinction between the two settings. National context might be the one which guides delivery of public health services. View Full-Text   Abstract
Background: Successful aging is best determined by active management and self-determination of one’s aging roadmap. Some individuals are ready to respond to these challenges, others may benefit from assistance that might be offered through an evidence-based intervention. The Aging Mastery Program® (AMP) has been developed to meet these needs. Method: In a cross over design the intervention was tested in ten senior centers and aging network agencies looking at impacts upon general health and quality of life, patient activation, physical activity and advanced care planning. Results: There was a statistically significant (tested at a 0.05 level) level of improvement found in physical activity and advanced care planning. Conclusion: Findings support the program’s effectiveness and its value as an evidence-based intervention for older adult programming. View Full-Text   Abstract
Nutraceuticals are important for healthy skin maintenance. Probiotics, phenolics, and vitamins are just a few of the nutraceuticals meant to potentially prevent and assist medical management of dermatologic conditions. Among these, probiotics, vitamin E, and green tea catechins may offer the broadest array of skin protective mechanisms with probiotics having the greatest clinical range. Probiotics’ amelioration of atopic dermatitis and opportunistic infections of skin burns has been targeted in recent research efforts. This includes the improvement of Scoring Atopic Dermatitis index scores, p = 0.02, with intact Lactobacillus rhamnosus Goldin and Gorbach (LGG) in comparison to heat inactivated LGG or placebo. Lactobacillus reuteri used prior to or concurrently with Staphylococcus aureus infection can increase epidermal keratinocyte survival, p < 0.01. Phenolics may not have been extensively studied for atopic dermatitis or skin burns. However, phenolics do have a role in photoprotection. The phenolic rutin increases ultraviolet B radiation filter reactive oxygen species scavenging at 75%, p < 0.002, and peak wavelength absorption, p < 0.001. While oral and topical probiotics have untapped potential for atopic dermatitis amelioration and skin infection prevention, phenolics will be increasingly used for photoprotection. With optimized bioavailability, dosage, and formulation, nutraceuticals will become crucial for healthy skin maintenance. View Full-Text   adult day services,adult day care center,community-based services,dementia,occupation,primary carers   public health operations,settings,decision tools,primary care   physical activity,advanced planning,aging,evidence-based   atopic dermatitis,green tea,human skin,keratinocyte,moisturizer,nutraceuticals,photoprotection,polyphenols,probiotics,vitamin E ", Healthcare 
" Modelling and Development of Electrical Aptasensors: A Short Review   Dissection of Protein Kinase Pathways in Live Cells Using Photoluminescent Probes: Surveillance or Interrogation?   The Use of Hoechst Dyes for DNA Staining and Beyond   A Rationally Designed, Spiropyran-Based Chemosensor for Magnesium "," Abstract
Aptamers are strands of DNA or RNA molecules, chemically synthetized and able to bind a wide range of targets, from small molecules to live cells, and even tissues, with high affinity and specificity. Due to their efficient targeting ability, they have many different kinds of applications. Particularly attractive is their use in biotechnology and disease therapy, in substitution of antibodies. They represent a promising way for early diagnosis (aptasensors), but also for delivering imaging agents and drugs and for inhibiting specific proteins (therapeutic aptamers). Starting by briefly reviewing the most recent literature concerning advances in biomedical applications of aptamers and aptasensors, the focus is on the issues of a theoretical/computational framework (proteotronics) for modelling the electrical properties of biomolecules. Some recent results of proteotronics concerning the electrical, topological and affinity properties of aptamers are reviewed. View Full-Text   Abstract
Protein kinases catalyze phosphorylation, a small yet crucial modification that affects participation of the substrate proteins in the intracellular signaling pathways. The activity of 538 protein kinases encoded in human genome relies upon spatiotemporally controlled mechanisms, ensuring correct progression of virtually all physiological processes on the cellular level—from cell division to cell death. The aberrant functioning of protein kinases is linked to a wide spectrum of major health issues including cancer, cardiovascular diseases, neurodegenerative diseases, inflammatory diseases, etc. Hence, significant effort of scientific community has been dedicated to the dissection of protein kinase pathways in their natural milieu. The combination of recent advances in the field of light microscopy, the wide variety of genetically encoded or synthetic photoluminescent scaffolds, and the techniques for intracellular delivery of cargoes has enabled design of a plethora of probes that can report activation of target protein kinases in human live cells. The question remains: how much do we bias intracellular signaling of protein kinases by monitoring it? This review seeks answers to this question by analyzing different classes of probes according to their general structure, mechanism of recognition of biological target, and optical properties necessary for the reporting of intracellular events. View Full-Text   Abstract
Hoechst dyes are among the most popular fluorophores used to stain DNA in living and fixed cells. Moreover, their high affinity and specificity towards DNA make Hoechst dyes excellent targeting moieties, which can be conjugated to various other molecules in order to tether them to DNA. The recent developments in the fields of microscopy and flow cytometry have sparked interest in such composite molecules, whose applications range from investigating nucleus microenvironment to drug delivery into tumours. Here we provide an overview of the properties of Hoechst dyes and discuss recent developments in Hoechst-based composite probes. View Full-Text   Abstract
Magnesium ions (Mg2+) play an important role in mammalian cell function; however, relatively little is known about the mechanisms of Mg2+ regulation in disease states. An advance in this field would come from the development of selective, reversible fluorescent chemosensors, capable of repeated measurements. To this end, the rational design and fluorescence-based photophysical characterisation of two spiropyran-based chemosensors for Mg2+ are presented. The most promising analogue, chemosensor 1, exhibits 2-fold fluorescence enhancement factor and 3-fold higher binding affinity for Mg2+ (Kd 6.0 µM) over Ca2+ (Kd 18.7 µM). Incorporation of spiropyran-based sensors into optical fibre sensing platforms has been shown to yield significant signal-to-background changes with minimal sample volumes, a real advance in biological sensing that enables measurement on subcellular-scale samples. In order to demonstrate chemosensor compatibility within the light intense microenvironment of an optical fibre, photoswitching and photostability of 1 within a suspended core optical fibre (SCF) was subsequently explored, revealing reversible Mg2+ binding with improved photostability compared to the non-photoswitchable Rhodamine B fluorophore. The spiropyran-based chemosensors reported here highlight untapped opportunities for a new class of photoswitchable Mg2+ probe and present a first step in the development of a light-controlled, reversible dip-sensor for Mg2+. View Full-Text "," aptamer,aptasensor,electrical properties,networks,proteotronics   protein kinase,phosphorylation,photoluminescence,fluorescence,FRET,probe,sensor,reporter   fluorescent probes,biosensors,fluorescent indicators,DNA staining,protein labelling,optical microscopy,proteomics,living cells   magnesium chemosensor,photoswitchable,spiropyran,merocyanine,fluorescent chemosensor,microstructured optical fibre,suspended core fibre "," Modelling and Development of Electrical Aptasensors: A Short Review   Dissection of Protein Kinase Pathways in Live Cells Using Photoluminescent Probes: Surveillance or Interrogation?   The Use of Hoechst Dyes for DNA Staining and Beyond   A Rationally Designed, Spiropyran-Based Chemosensor for Magnesium   Abstract
Aptamers are strands of DNA or RNA molecules, chemically synthetized and able to bind a wide range of targets, from small molecules to live cells, and even tissues, with high affinity and specificity. Due to their efficient targeting ability, they have many different kinds of applications. Particularly attractive is their use in biotechnology and disease therapy, in substitution of antibodies. They represent a promising way for early diagnosis (aptasensors), but also for delivering imaging agents and drugs and for inhibiting specific proteins (therapeutic aptamers). Starting by briefly reviewing the most recent literature concerning advances in biomedical applications of aptamers and aptasensors, the focus is on the issues of a theoretical/computational framework (proteotronics) for modelling the electrical properties of biomolecules. Some recent results of proteotronics concerning the electrical, topological and affinity properties of aptamers are reviewed. View Full-Text   Abstract
Protein kinases catalyze phosphorylation, a small yet crucial modification that affects participation of the substrate proteins in the intracellular signaling pathways. The activity of 538 protein kinases encoded in human genome relies upon spatiotemporally controlled mechanisms, ensuring correct progression of virtually all physiological processes on the cellular level—from cell division to cell death. The aberrant functioning of protein kinases is linked to a wide spectrum of major health issues including cancer, cardiovascular diseases, neurodegenerative diseases, inflammatory diseases, etc. Hence, significant effort of scientific community has been dedicated to the dissection of protein kinase pathways in their natural milieu. The combination of recent advances in the field of light microscopy, the wide variety of genetically encoded or synthetic photoluminescent scaffolds, and the techniques for intracellular delivery of cargoes has enabled design of a plethora of probes that can report activation of target protein kinases in human live cells. The question remains: how much do we bias intracellular signaling of protein kinases by monitoring it? This review seeks answers to this question by analyzing different classes of probes according to their general structure, mechanism of recognition of biological target, and optical properties necessary for the reporting of intracellular events. View Full-Text   Abstract
Hoechst dyes are among the most popular fluorophores used to stain DNA in living and fixed cells. Moreover, their high affinity and specificity towards DNA make Hoechst dyes excellent targeting moieties, which can be conjugated to various other molecules in order to tether them to DNA. The recent developments in the fields of microscopy and flow cytometry have sparked interest in such composite molecules, whose applications range from investigating nucleus microenvironment to drug delivery into tumours. Here we provide an overview of the properties of Hoechst dyes and discuss recent developments in Hoechst-based composite probes. View Full-Text   Abstract
Magnesium ions (Mg2+) play an important role in mammalian cell function; however, relatively little is known about the mechanisms of Mg2+ regulation in disease states. An advance in this field would come from the development of selective, reversible fluorescent chemosensors, capable of repeated measurements. To this end, the rational design and fluorescence-based photophysical characterisation of two spiropyran-based chemosensors for Mg2+ are presented. The most promising analogue, chemosensor 1, exhibits 2-fold fluorescence enhancement factor and 3-fold higher binding affinity for Mg2+ (Kd 6.0 µM) over Ca2+ (Kd 18.7 µM). Incorporation of spiropyran-based sensors into optical fibre sensing platforms has been shown to yield significant signal-to-background changes with minimal sample volumes, a real advance in biological sensing that enables measurement on subcellular-scale samples. In order to demonstrate chemosensor compatibility within the light intense microenvironment of an optical fibre, photoswitching and photostability of 1 within a suspended core optical fibre (SCF) was subsequently explored, revealing reversible Mg2+ binding with improved photostability compared to the non-photoswitchable Rhodamine B fluorophore. The spiropyran-based chemosensors reported here highlight untapped opportunities for a new class of photoswitchable Mg2+ probe and present a first step in the development of a light-controlled, reversible dip-sensor for Mg2+. View Full-Text   aptamer,aptasensor,electrical properties,networks,proteotronics   protein kinase,phosphorylation,photoluminescence,fluorescence,FRET,probe,sensor,reporter   fluorescent probes,biosensors,fluorescent indicators,DNA staining,protein labelling,optical microscopy,proteomics,living cells   magnesium chemosensor,photoswitchable,spiropyran,merocyanine,fluorescent chemosensor,microstructured optical fibre,suspended core fibre ", Chemosensors 
 Cell-Penetrating Peptides to Enhance Delivery of Oligonucleotide-Based Therapeutics   Mammary Stem Cells and Breast Cancer Stem Cells: Molecular Connections and Clinical Implications   Neural Oscillatory Correlates for Conditioning and Extinction of Fear ," Abstract
The promise of nucleic acid based oligonucleotides as effective genetic therapies has been held back by their low bioavailability and poor cellular uptake to target tissues upon systemic administration. One such strategy to improve upon delivery is the use of short cell-penetrating peptides (CPPs) that can be either directly attached to their cargo through covalent linkages or through the formation of noncovalent nanoparticle complexes that can facilitate cellular uptake. In this review, we will highlight recent proof-of-principle studies that have utilized both of these strategies to improve nucleic acid delivery and discuss the prospects for translation of this approach for clinical application. View Full-Text   Abstract
Cancer arises from subpopulations of transformed cells with high tumor initiation and repopulation ability, known as cancer stem cells (CSCs), which share many similarities with their normal counterparts. In the mammary gland, several studies have shown common molecular regulators between adult mammary stem cells (MaSCs) and breast cancer stem cells (bCSCs). Cell plasticity and self-renewal are essential abilities for MaSCs to maintain tissue homeostasis and regenerate the gland after pregnancy. Intriguingly, these properties are similarly executed in breast cancer stem cells to drive tumor initiation, tumor heterogeneity and recurrence after chemotherapy. In addition, both stem cell phenotypes are strongly influenced by external signals from the microenvironment, immune cells and supportive specific niches. This review focuses on the intrinsic and extrinsic connections of MaSC and bCSCs with clinical implications for breast cancer progression and their possible therapeutic applications. View Full-Text   Abstract
The extinction of conditioned-fear represents a hallmark of current exposure therapies as it has been found to be impaired in people suffering from post-traumatic stress disorder (PTSD) and anxiety. A large body of knowledge focusing on psychophysiological animal and human studies suggests the involvement of key brain structures that interact via neural oscillations during the acquisition and extinction of fear. Consequently, neural oscillatory correlates of such mechanisms appear relevant regarding the development of novel therapeutic approaches to counterbalance abnormal activity in fear-related brain circuits, which, in turn, could alleviate fear and anxiety symptoms. Here, we provide an account of state-of-the-art neural oscillatory correlates for the conditioning and extinction of fear, and also deal with recent translational efforts aimed at fear extinction by neural oscillatory modulation. View Full-Text "," cell-penetrating peptides,antisense oligonucleotides,delivery   mammary stem cells,cancer stem cells,cell plasticity,immune interplay,tumor microenvironment,targeting CSCs   oscillations,extinction learning,fear conditioning,fear extinction,translational "," Cell-Penetrating Peptides to Enhance Delivery of Oligonucleotide-Based Therapeutics   Mammary Stem Cells and Breast Cancer Stem Cells: Molecular Connections and Clinical Implications   Neural Oscillatory Correlates for Conditioning and Extinction of Fear   Abstract
The promise of nucleic acid based oligonucleotides as effective genetic therapies has been held back by their low bioavailability and poor cellular uptake to target tissues upon systemic administration. One such strategy to improve upon delivery is the use of short cell-penetrating peptides (CPPs) that can be either directly attached to their cargo through covalent linkages or through the formation of noncovalent nanoparticle complexes that can facilitate cellular uptake. In this review, we will highlight recent proof-of-principle studies that have utilized both of these strategies to improve nucleic acid delivery and discuss the prospects for translation of this approach for clinical application. View Full-Text   Abstract
Cancer arises from subpopulations of transformed cells with high tumor initiation and repopulation ability, known as cancer stem cells (CSCs), which share many similarities with their normal counterparts. In the mammary gland, several studies have shown common molecular regulators between adult mammary stem cells (MaSCs) and breast cancer stem cells (bCSCs). Cell plasticity and self-renewal are essential abilities for MaSCs to maintain tissue homeostasis and regenerate the gland after pregnancy. Intriguingly, these properties are similarly executed in breast cancer stem cells to drive tumor initiation, tumor heterogeneity and recurrence after chemotherapy. In addition, both stem cell phenotypes are strongly influenced by external signals from the microenvironment, immune cells and supportive specific niches. This review focuses on the intrinsic and extrinsic connections of MaSC and bCSCs with clinical implications for breast cancer progression and their possible therapeutic applications. View Full-Text   Abstract
The extinction of conditioned-fear represents a hallmark of current exposure therapies as it has been found to be impaired in people suffering from post-traumatic stress disorder (PTSD) and anxiety. A large body of knowledge focusing on psychophysiological animal and human studies suggests the involvement of key brain structures that interact via neural oscillations during the acquisition and extinction of fear. Consequently, neural oscillatory correlates of such mechanisms appear relevant regarding the development of novel therapeutic approaches to counterbalance abnormal activity in fear-related brain circuits, which, in turn, could alleviate fear and anxiety symptoms. Here, we provide an account of state-of-the-art neural oscillatory correlates for the conditioning and extinction of fear, and also deal with recent translational efforts aimed at fear extinction by neural oscillatory modulation. View Full-Text   cell-penetrating peptides,antisense oligonucleotides,delivery   mammary stem cells,cancer stem cells,cell plasticity,immune interplay,tumor microenvironment,targeting CSCs   oscillations,extinction learning,fear conditioning,fear extinction,translational ", Biomedicines 
" Hearing Loss in Adult Survivors of Childhood Cancer Treated with Radiotherapy   Family Socioeconomic Status at Birth and Youth Impulsivity at Age 15; Blacks’ Diminished Return   Anti-Epileptic Drug Toxicity in Children   Development and Validation of a Questionnaire on Breastfeeding Intentions, Attitudes and Knowledge of a Sample of Croatian Secondary-School Students "," Abstract
The ototoxic effects of radiotherapy have been poorly characterized. We examined adult survivors of childhood cancer who were treated with radiotherapy, which included the head, before the age of 22 years and between 1952 and 2016. Those who received platinum chemotherapy were excluded. Demographic, diagnosis, and treatment outcomes were captured. Audiograms were graded using the Chang and International Society of Paediatric Oncology ototoxicity (SIOP) scales. Among 276 patients with a history of radiation to sites that included the brain, orbit, nasopharynx, and total body irradiation, the median age at treatment was 10.1 years and 59% were male. Of 51 survivors who had post-treatment audiograms, 19 demonstrated severe hearing impairment according to both the Chang and SIOP scales after a median follow-up of 16.6 years. Of those with severe impairment, 10 were using hearing aids. Among the 23 patients with more than one audiogram, five had normal hearing on the first audiogram but hearing loss upon subsequent study. Ototoxic effects of radiotherapy are present in a significant portion of survivors, but impairment may present over time, and our results suggest that many are not being screened. Further, among patients with severe hearing loss, use of hearing aids is not universal. Expansion of access to audiology testing and hearing interventions may be warranted. View Full-Text   Abstract
Minorities’ Diminished Return theory suggests that health effects of socioeconomic status (SES) are systemically smaller for racial and ethnic minorities compared to Whites. To test the relevance of Minorities’ Diminished Return theory for youth impulsivity, we investigated Black–White differences in the effects of family SES at birth on subsequent youth impulsivity at age 15. Data came from the Fragile Families and Child Wellbeing Study (FFCWS), 1998–2016, a 15-year longitudinal study of urban families from the birth of their children to age 15. This analysis included 1931 families who were either White (n = 495) or Black (n = 1436). The independent variables of this study were family income, maternal education, and family structure at birth. Youth impulsivity at age 15 was the dependent variable. Gender was the covariate and race was the focal moderator. We ran linear regressions in the overall sample and specific to each race. In the overall sample, higher household income (b = −0.01, 95% CI = −0.01 to 0.00) and maternal education (b = −0.24, 95% CI = −0.44 to −0.04) at birth were associated with lower youth impulsivity at age 15, independent of race, gender, and family structure. A significant interaction was found between race and household income at birth (b = 0.01, 95% CI = 0.00 to 0.02) on subsequent youth impulsivity, which was indicative of a stronger protective effect for Whites compared to Blacks. Blacks’ diminished return exists for the long-term protective effects of family income at birth against subsequent youth impulsivity. The relative disadvantage of Blacks in comparison to Whites is in line with a growing literature showing that Black families gain less from high SES, which is possibly due to the existing structural racism in the US. View Full-Text   Abstract
Anti-epileptic drugs (AEDs) have had a major impact on children, improving their quality of life and significantly reducing both morbidity and mortality. They are, however, associated with significant toxicity. Behavioural problems and somnolence are the most frequent adverse drug reactions for many AEDs. Unfortunately, the comparative risk of drug toxicity for different AEDs has been inadequately studied. Drug toxicity is poorly reported in randomised controlled trials. Prospective cohort studies are the best way to study drug toxicity. There have been a few prospective cohort studies of children with epilepsy, but the numbers of children have been small. Systemic reviews of the toxicity of individual AEDs have been helpful in identifying the risk of drug toxicity. Parents of children with epilepsy and the children and young people who are due to receive AED treatment have the right to know the likelihood of them experiencing drug toxicity. Unfortunately, the evidence base on which health professionals can provide such information is limited. View Full-Text   Abstract
Background: Validating a questionnaire/instrument before proceeding to the field for data collection is important. Methods: An 18-item breastfeeding intention, 39-item attitude and 44-item knowledge questionnaire was validated in a Croatian sample of secondary-school students (N = 277). Results: For the intentions, principal component analysis (PCA) yielded a four-factor solution with 8 items explaining 68.3% of the total variance. Cronbach’s alpha (0.71) indicated satisfactory internal consistency. For the attitudes, PCA showed a seven-factor structure with 33 items explaining 58.41% of total variance. Cronbach’s alpha (0.87) indicated good internal consistency. There were 13 knowledge questions that were retained after item analysis, showing good internal consistency (KR20 = 0.83). In terms of criterion validity, the questionnaire differentiated between students who received breastfeeding education compared to students who were not educated in breastfeeding. Correlations between intentions and attitudes (r = 0.49), intentions and knowledge (r = 0.29), and attitudes and knowledge (r = 0.38) confirmed concurrent validity. Conclusions: The final instrument is reliable and valid for data collection on breastfeeding. Therefore, the instrument is recommended for evaluation of breastfeeding education programs aimed at upper-grade elementary and secondary school students. View Full-Text "," radiotherapy,ototoxicity,survivorship,hearing aids,pediatric cancer   race,ethnicity,social class,education,socioeconomic status,income,social determinants of health,impulsivity   drug toxicity,antiepileptic drug,behavioural problems,valproate,lamotrigine,levetiracetam   questionnaire,breastfeeding,students "," Hearing Loss in Adult Survivors of Childhood Cancer Treated with Radiotherapy   Family Socioeconomic Status at Birth and Youth Impulsivity at Age 15; Blacks’ Diminished Return   Anti-Epileptic Drug Toxicity in Children   Development and Validation of a Questionnaire on Breastfeeding Intentions, Attitudes and Knowledge of a Sample of Croatian Secondary-School Students   Abstract
The ototoxic effects of radiotherapy have been poorly characterized. We examined adult survivors of childhood cancer who were treated with radiotherapy, which included the head, before the age of 22 years and between 1952 and 2016. Those who received platinum chemotherapy were excluded. Demographic, diagnosis, and treatment outcomes were captured. Audiograms were graded using the Chang and International Society of Paediatric Oncology ototoxicity (SIOP) scales. Among 276 patients with a history of radiation to sites that included the brain, orbit, nasopharynx, and total body irradiation, the median age at treatment was 10.1 years and 59% were male. Of 51 survivors who had post-treatment audiograms, 19 demonstrated severe hearing impairment according to both the Chang and SIOP scales after a median follow-up of 16.6 years. Of those with severe impairment, 10 were using hearing aids. Among the 23 patients with more than one audiogram, five had normal hearing on the first audiogram but hearing loss upon subsequent study. Ototoxic effects of radiotherapy are present in a significant portion of survivors, but impairment may present over time, and our results suggest that many are not being screened. Further, among patients with severe hearing loss, use of hearing aids is not universal. Expansion of access to audiology testing and hearing interventions may be warranted. View Full-Text   Abstract
Minorities’ Diminished Return theory suggests that health effects of socioeconomic status (SES) are systemically smaller for racial and ethnic minorities compared to Whites. To test the relevance of Minorities’ Diminished Return theory for youth impulsivity, we investigated Black–White differences in the effects of family SES at birth on subsequent youth impulsivity at age 15. Data came from the Fragile Families and Child Wellbeing Study (FFCWS), 1998–2016, a 15-year longitudinal study of urban families from the birth of their children to age 15. This analysis included 1931 families who were either White (n = 495) or Black (n = 1436). The independent variables of this study were family income, maternal education, and family structure at birth. Youth impulsivity at age 15 was the dependent variable. Gender was the covariate and race was the focal moderator. We ran linear regressions in the overall sample and specific to each race. In the overall sample, higher household income (b = −0.01, 95% CI = −0.01 to 0.00) and maternal education (b = −0.24, 95% CI = −0.44 to −0.04) at birth were associated with lower youth impulsivity at age 15, independent of race, gender, and family structure. A significant interaction was found between race and household income at birth (b = 0.01, 95% CI = 0.00 to 0.02) on subsequent youth impulsivity, which was indicative of a stronger protective effect for Whites compared to Blacks. Blacks’ diminished return exists for the long-term protective effects of family income at birth against subsequent youth impulsivity. The relative disadvantage of Blacks in comparison to Whites is in line with a growing literature showing that Black families gain less from high SES, which is possibly due to the existing structural racism in the US. View Full-Text   Abstract
Anti-epileptic drugs (AEDs) have had a major impact on children, improving their quality of life and significantly reducing both morbidity and mortality. They are, however, associated with significant toxicity. Behavioural problems and somnolence are the most frequent adverse drug reactions for many AEDs. Unfortunately, the comparative risk of drug toxicity for different AEDs has been inadequately studied. Drug toxicity is poorly reported in randomised controlled trials. Prospective cohort studies are the best way to study drug toxicity. There have been a few prospective cohort studies of children with epilepsy, but the numbers of children have been small. Systemic reviews of the toxicity of individual AEDs have been helpful in identifying the risk of drug toxicity. Parents of children with epilepsy and the children and young people who are due to receive AED treatment have the right to know the likelihood of them experiencing drug toxicity. Unfortunately, the evidence base on which health professionals can provide such information is limited. View Full-Text   Abstract
Background: Validating a questionnaire/instrument before proceeding to the field for data collection is important. Methods: An 18-item breastfeeding intention, 39-item attitude and 44-item knowledge questionnaire was validated in a Croatian sample of secondary-school students (N = 277). Results: For the intentions, principal component analysis (PCA) yielded a four-factor solution with 8 items explaining 68.3% of the total variance. Cronbach’s alpha (0.71) indicated satisfactory internal consistency. For the attitudes, PCA showed a seven-factor structure with 33 items explaining 58.41% of total variance. Cronbach’s alpha (0.87) indicated good internal consistency. There were 13 knowledge questions that were retained after item analysis, showing good internal consistency (KR20 = 0.83). In terms of criterion validity, the questionnaire differentiated between students who received breastfeeding education compared to students who were not educated in breastfeeding. Correlations between intentions and attitudes (r = 0.49), intentions and knowledge (r = 0.29), and attitudes and knowledge (r = 0.38) confirmed concurrent validity. Conclusions: The final instrument is reliable and valid for data collection on breastfeeding. Therefore, the instrument is recommended for evaluation of breastfeeding education programs aimed at upper-grade elementary and secondary school students. View Full-Text   radiotherapy,ototoxicity,survivorship,hearing aids,pediatric cancer   race,ethnicity,social class,education,socioeconomic status,income,social determinants of health,impulsivity   drug toxicity,antiepileptic drug,behavioural problems,valproate,lamotrigine,levetiracetam   questionnaire,breastfeeding,students ", Children 
" Modelling and Forecasting Stock Price Movements with Serially Dependent Determinants   Real-Option Valuation in a Finite-Time, Incomplete Market with Jump Diffusion and Investor-Utility Inflation   The Effect of Non-Proportional Reinsurance: A Revision of Solvency II Standard Formula   Properties of Stochastic Arrangement Increasing and Their Applications in Allocation Problems "," Abstract
The direction of price movements are analysed under an ordered probit framework, recognising the importance of accounting for discreteness in price changes. By extending the work of Hausman et al. (1972) and Yang and Parwada (2012),This paper focuses on improving the forecast performance of the model while infusing a more practical perspective by enhancing flexibility. This is achieved by extending the existing framework to generate short term multi period ahead forecasts for better decision making, whilst considering the serial dependence structure. This approach enhances the flexibility and adaptability of the model to future price changes, particularly targeting risk minimisation. Empirical evidence is provided, based on seven stocks listed on the Australian Securities Exchange (ASX). The prediction success varies between 78 and 91 per cent for in-sample and out-of-sample forecasts for both the short term and long term. View Full-Text   Abstract
We extend an existing numerical model (Grasselli (2011)) for valuing a real option to invest in a capital project in an incomplete market with a finite time horizon. In doing so, we include two separate effects: the possibility that the project value is partly describable according to a jump-diffusion process, and incorporation of a time-dependent investor utility function, taking into account the effect of inflation. We adopt a discrete approximation to the jump process, whose parameters are restricted in order to preserve the drift and the volatility of the project-value process that it modifies. By controlling for these low-order effects, the higher-order effects may be considered in isolation. Our simulated results demonstrate that the inclusion of the jump process tends to decrease the value of the option, and expand the circumstances under which it should be exercised. Our results also demonstrate that an appropriate selection of the time-dependent investor utility function yields more reasonable investor-behaviour predictions regarding the decision to exercise the option, than would occur otherwise. View Full-Text   Abstract
Solvency II Standard Formula provides a methodology to recognise the risk-mitigating impact of excess of loss reinsurance treaties in premium risk modelling. We analyse the proposals of both Quantitative Impact Study 5 and Commission Delegated Regulation highlighting some inconsistencies. This paper tries to bridge main pitfalls of both versions. To this aim, we propose a revision of non-proportional adjustment factor in order to measure the effect of excess of loss treaties on premium risk volatility. In this way, capital requirement can be easily assessed. As numerical results show, this proposal appears to be a feasible and much more consistent approach to describe the effect of non-proportional reinsurance on premium risk. View Full-Text   Abstract
There are extensive studies on the allocation problems in the field of insurance and finance. We observe that these studies, although involving different methodologies, share some inherent commonalities. In this paper, we develop a new framework for these studies with the tool of arrangement increasing functions. This framework unifies many existing studies and provides shortcuts to developing new results. View Full-Text "," ordered probit,stock prices,auto-regressive,multi-step ahead forecasts   real option,incomplete market,jump diffusion,time-dependent risk preferences   Solvency II,premium risk capital requirement,non-proportional reinsurance,collective risk models   arrangement increasing function,majorization,stochastic arrangement increasing,stochastic orders,optimal allocations "," Modelling and Forecasting Stock Price Movements with Serially Dependent Determinants   Real-Option Valuation in a Finite-Time, Incomplete Market with Jump Diffusion and Investor-Utility Inflation   The Effect of Non-Proportional Reinsurance: A Revision of Solvency II Standard Formula   Properties of Stochastic Arrangement Increasing and Their Applications in Allocation Problems   Abstract
The direction of price movements are analysed under an ordered probit framework, recognising the importance of accounting for discreteness in price changes. By extending the work of Hausman et al. (1972) and Yang and Parwada (2012),This paper focuses on improving the forecast performance of the model while infusing a more practical perspective by enhancing flexibility. This is achieved by extending the existing framework to generate short term multi period ahead forecasts for better decision making, whilst considering the serial dependence structure. This approach enhances the flexibility and adaptability of the model to future price changes, particularly targeting risk minimisation. Empirical evidence is provided, based on seven stocks listed on the Australian Securities Exchange (ASX). The prediction success varies between 78 and 91 per cent for in-sample and out-of-sample forecasts for both the short term and long term. View Full-Text   Abstract
We extend an existing numerical model (Grasselli (2011)) for valuing a real option to invest in a capital project in an incomplete market with a finite time horizon. In doing so, we include two separate effects: the possibility that the project value is partly describable according to a jump-diffusion process, and incorporation of a time-dependent investor utility function, taking into account the effect of inflation. We adopt a discrete approximation to the jump process, whose parameters are restricted in order to preserve the drift and the volatility of the project-value process that it modifies. By controlling for these low-order effects, the higher-order effects may be considered in isolation. Our simulated results demonstrate that the inclusion of the jump process tends to decrease the value of the option, and expand the circumstances under which it should be exercised. Our results also demonstrate that an appropriate selection of the time-dependent investor utility function yields more reasonable investor-behaviour predictions regarding the decision to exercise the option, than would occur otherwise. View Full-Text   Abstract
Solvency II Standard Formula provides a methodology to recognise the risk-mitigating impact of excess of loss reinsurance treaties in premium risk modelling. We analyse the proposals of both Quantitative Impact Study 5 and Commission Delegated Regulation highlighting some inconsistencies. This paper tries to bridge main pitfalls of both versions. To this aim, we propose a revision of non-proportional adjustment factor in order to measure the effect of excess of loss treaties on premium risk volatility. In this way, capital requirement can be easily assessed. As numerical results show, this proposal appears to be a feasible and much more consistent approach to describe the effect of non-proportional reinsurance on premium risk. View Full-Text   Abstract
There are extensive studies on the allocation problems in the field of insurance and finance. We observe that these studies, although involving different methodologies, share some inherent commonalities. In this paper, we develop a new framework for these studies with the tool of arrangement increasing functions. This framework unifies many existing studies and provides shortcuts to developing new results. View Full-Text   ordered probit,stock prices,auto-regressive,multi-step ahead forecasts   real option,incomplete market,jump diffusion,time-dependent risk preferences   Solvency II,premium risk capital requirement,non-proportional reinsurance,collective risk models   arrangement increasing function,majorization,stochastic arrangement increasing,stochastic orders,optimal allocations ", Risks 
 An Internet of Things Based Multi-Level Privacy-Preserving Access Control for Smart Living   Building Realistic Mobility Models for Mobile Ad Hoc Networks   Exploiting Rating Abstention Intervals for Addressing Concept Drift in Social Network Recommender Systems ," Abstract
The presence of the Internet of Things (IoT) in healthcare through the use of mobile medical applications and wearable devices allows patients to capture their healthcare data and enables healthcare professionals to be up-to-date with a patient’s status. Ambient Assisted Living (AAL), which is considered as one of the major applications of IoT, is a home environment augmented with embedded ambient sensors to help improve an individual’s quality of life. This domain faces major challenges in providing safety and security when accessing sensitive health data. This paper presents an access control framework for AAL which considers multi-level access and privacy preservation. We focus on two major points: (1) how to use the data collected from ambient sensors and biometric sensors to perform the high-level task of activity recognition; and (2) how to secure the collected private healthcare data via effective access control. We achieve multi-level access control by extending Public Key Infrastructure (PKI) for secure authentication and utilizing Attribute-Based Access Control (ABAC) for authorization. The proposed access control system regulates access to healthcare data by defining policy attributes over healthcare professional groups and data classes classifications. We provide guidelines to classify the data classes and healthcare professional groups and describe security policies to control access to the data classes. View Full-Text   Abstract
A mobile ad hoc network (MANET) is a self-configuring wireless network in which each node could act as a router, as well as a data source or sink. Its application areas include battlefields and vehicular and disaster areas. Many techniques applied to infrastructure-based networks are less effective in MANETs, with routing being a particular challenge. This paper presents a rigorous study into simulation techniques for evaluating routing solutions for MANETs with the aim of producing more realistic simulation models and thereby, more accurate protocol evaluations. MANET simulations require models that reflect the world in which the MANET is to operate. Much of the published research uses movement models, such as the random waypoint (RWP) model, with arbitrary world sizes and node counts. This paper presents a technique for developing more realistic simulation models to test and evaluate MANET protocols. The technique is animation, which is applied to a realistic scenario to produce a model that accurately reflects the size and shape of the world, node count, movement patterns, and time period over which the MANET may operate. The animation technique has been used to develop a battlefield model based on established military tactics. Trace data has been used to build a model of maritime movements in the Irish Sea. Similar world models have been built using the random waypoint movement model for comparison. All models have been built using the ns-2 simulator. These models have been used to compare the performance of three routing protocols: dynamic source routing (DSR), destination-sequenced distance-vector routing (DSDV), and ad hoc n-demand distance vector routing (AODV). The findings reveal that protocol performance is dependent on the model used. In particular, it is shown that RWP models do not reflect the performance of these protocols under realistic circumstances, and protocol selection is subject to the scenario to which it is applied. To conclude, it is possible to develop a range of techniques for modelling scenarios applicable to MANETs, and these simulation models could be utilised for the evaluation of routing protocols. View Full-Text   Abstract
One of the major problems that social networks face is the continuous production of successful, user-targeted information in the form of recommendations, which are produced exploiting technology from the field of recommender systems. Recommender systems are based on information about users’ past behavior to formulate recommendations about their future actions. However, as time goes by, social network users may change preferences and likings: they may like different types of clothes, listen to different singers or even different genres of music and so on. This phenomenon has been termed as concept drift. In this paper: (1) we establish that when a social network user abstains from rating submission for a long time, it is a strong indication that concept drift has occurred and (2) we present a technique that exploits the abstention interval concept, to drop from the database ratings that do not reflect the current social network user’s interests, thus improving prediction quality. View Full-Text "," access control,ambient assisted living,authentication,Internet of Things,IoT   MANET,RWP,battlefield,realistic model,performance evaluation,network simulation,mobility modelling   social networks,recommender systems,collaborative filtering,shift of interest,concept drift,evaluation "," An Internet of Things Based Multi-Level Privacy-Preserving Access Control for Smart Living   Building Realistic Mobility Models for Mobile Ad Hoc Networks   Exploiting Rating Abstention Intervals for Addressing Concept Drift in Social Network Recommender Systems   Abstract
The presence of the Internet of Things (IoT) in healthcare through the use of mobile medical applications and wearable devices allows patients to capture their healthcare data and enables healthcare professionals to be up-to-date with a patient’s status. Ambient Assisted Living (AAL), which is considered as one of the major applications of IoT, is a home environment augmented with embedded ambient sensors to help improve an individual’s quality of life. This domain faces major challenges in providing safety and security when accessing sensitive health data. This paper presents an access control framework for AAL which considers multi-level access and privacy preservation. We focus on two major points: (1) how to use the data collected from ambient sensors and biometric sensors to perform the high-level task of activity recognition; and (2) how to secure the collected private healthcare data via effective access control. We achieve multi-level access control by extending Public Key Infrastructure (PKI) for secure authentication and utilizing Attribute-Based Access Control (ABAC) for authorization. The proposed access control system regulates access to healthcare data by defining policy attributes over healthcare professional groups and data classes classifications. We provide guidelines to classify the data classes and healthcare professional groups and describe security policies to control access to the data classes. View Full-Text   Abstract
A mobile ad hoc network (MANET) is a self-configuring wireless network in which each node could act as a router, as well as a data source or sink. Its application areas include battlefields and vehicular and disaster areas. Many techniques applied to infrastructure-based networks are less effective in MANETs, with routing being a particular challenge. This paper presents a rigorous study into simulation techniques for evaluating routing solutions for MANETs with the aim of producing more realistic simulation models and thereby, more accurate protocol evaluations. MANET simulations require models that reflect the world in which the MANET is to operate. Much of the published research uses movement models, such as the random waypoint (RWP) model, with arbitrary world sizes and node counts. This paper presents a technique for developing more realistic simulation models to test and evaluate MANET protocols. The technique is animation, which is applied to a realistic scenario to produce a model that accurately reflects the size and shape of the world, node count, movement patterns, and time period over which the MANET may operate. The animation technique has been used to develop a battlefield model based on established military tactics. Trace data has been used to build a model of maritime movements in the Irish Sea. Similar world models have been built using the random waypoint movement model for comparison. All models have been built using the ns-2 simulator. These models have been used to compare the performance of three routing protocols: dynamic source routing (DSR), destination-sequenced distance-vector routing (DSDV), and ad hoc n-demand distance vector routing (AODV). The findings reveal that protocol performance is dependent on the model used. In particular, it is shown that RWP models do not reflect the performance of these protocols under realistic circumstances, and protocol selection is subject to the scenario to which it is applied. To conclude, it is possible to develop a range of techniques for modelling scenarios applicable to MANETs, and these simulation models could be utilised for the evaluation of routing protocols. View Full-Text   Abstract
One of the major problems that social networks face is the continuous production of successful, user-targeted information in the form of recommendations, which are produced exploiting technology from the field of recommender systems. Recommender systems are based on information about users’ past behavior to formulate recommendations about their future actions. However, as time goes by, social network users may change preferences and likings: they may like different types of clothes, listen to different singers or even different genres of music and so on. This phenomenon has been termed as concept drift. In this paper: (1) we establish that when a social network user abstains from rating submission for a long time, it is a strong indication that concept drift has occurred and (2) we present a technique that exploits the abstention interval concept, to drop from the database ratings that do not reflect the current social network user’s interests, thus improving prediction quality. View Full-Text   access control,ambient assisted living,authentication,Internet of Things,IoT   MANET,RWP,battlefield,realistic model,performance evaluation,network simulation,mobility modelling   social networks,recommender systems,collaborative filtering,shift of interest,concept drift,evaluation ", Informatics 
 Key Parameters of Gob-Side Entry Retaining in A Gassy and Thin Coal Seam with Hard Roof   Membrane Fouling Characteristics of a Side-Stream Tubular Anaerobic Membrane Bioreactor (AnMBR) Treating Domestic Wastewater   The Effect of Joint Dip Angle on the Mechanical Behavior of Infilled Jointed Rock Masses under Uniaxial and Biaxial Compressions   Optimal Control Strategy for TB-HIV/AIDS Co-Infection Model in the Presence of Behaviour Modification ," Abstract
Gob-side entry retaining (GER) employed in a thin coal seam (TCS) can increase economic benefits and coal recovery, as well as mitigate gas concentration in the gob. In accordance with the caving style of a limestone roof, the gas concentration and air pressure in the gob were analyzed, and a roof-cutting mechanical model of GER with a roadside backfill body (RBB) was proposed, to determine the key parameters of the GER-TCS, including the roof-cutting resistance and the width of the RBB. The results show that if the immediate roof height is greater than the seam height, the roof-cutting resistance and width of the RBB should meet the requirement of the immediate roof being totally cut along the gob, for which the optimal roof-cutting resistance and width of RBB were determined by analytical and numerical methods. The greater the RBB width, the greater its roof-cutting resistance. The relationship between the supporting strength of the RBB and the width of the RBB can be derived as a composite curve. The floor heave of GER increases with increasing RBB width. When the width of the RBB increased from 0.8 m to 1.2 m, the floor heave increased two-fold to 146.2 mm. GER was applied in a TCS with a limestone roof of 5 m thickness; the field-measured data verified the conclusions of the numerical model. View Full-Text   Abstract
A lab-scale of a side stream anaerobic membrane bioreactor (AnMBR) equipped with a tubular membrane operated at the mesophilic temperature of 37.0 ± 1.2 °C for treating domestic wastewater was tested to investigate its performance and fouling characteristics at two organic loading rates (OLR) of 0.25 kg COD m−3d−1, and 0.70 kg COD m−3d−1, respectively. The AnMBR was operated for 600 days at sludge retention time (SRT) of 100 days. This AnMBR exhibits excellent chemical oxygen demand (COD) removal of 91% at 0.25 kg COD m−3d−1, and 94% at 0.7 kg COD m−3d−1 respectively, with effluent-soluble COD below 50 mg/L. Chemically-enhanced cleaning method using NaOH, NaOCl, and citric acid solution were introduced for fouling investigation at these two stages. The results showed that sequential chemical cleaning of alkaline and acid were most effective to recover the membrane flux. The alkaline cleaning was effective at removing organic foulants, while citric acid cleaning was effective at removing the scalants. The analyses of the excitation emission matrix, gel permeation chromatography, and extracellular polymeric substances indicated that major components of membrane foulants were proteins, carbohydrates, humic, and fulvic acids. At 0.25 kg COD m−3d−1, organic fouling was more prone to be trapped in the cake layers and responsible for membrane pore blockage, inorganic fouling exhibited marginal contribution to the membrane fouling behavior. However, at 0.70 kg COD m−3d−1, high concentrations of organic and inorganic foulants supported an essential role of organic and inorganic fouling on membrane fouling behavior. View Full-Text   Abstract
Due to the complex formation process of a rock mass, a large number of fissures, joints, faults, other defects exist and the defects commonly contain infilled materials. The jointed rock masses are in a complex geological environment, in which the geometric distribution and the boundary condition can greatly affect the mechanical behavior of the infilled jointed rock mass. In this study, the infilled jointed rock mass specimens with different dip angles are prepared using similar materials, and the uniaxial and biaxial compression tests on the specimens are conducted. The effect of the joint dip angle on the mechanical behavior of the infilled jointed rock mass under uniaxial and biaxial compressions is investigated. The results show that the uniaxial compressive strength shows a W-shaped variation, and the biaxial compressive strength shows a V-shaped variation with an increase in the dip angle. Most of the cracks appear in pairs around the joint and occur symmetrically in a bilateral distribution, and the existence of the infilled joints induces a nonlinear mechanical behavior in the specimen. In addition, the specimens exhibit three failure modes under uniaxial compression: splitting failure, step-path failure and planar failure. The specimens present two failure modes under biaxial compression: splitting failure and planar failure. View Full-Text   Abstract
A mathematical model for a transmission of TB-HIV/AIDS co-infection that incorporates prevalence dependent behaviour change in the population and treatment for the infected (and infectious) class is formulated and analyzed. The two sub-models, when each of the two diseases are considered separately are mathematically analyzed. The theory of optimal control analysis is applied to the full model with the objective of minimizing the aggregate cost of the infections and the control efforts. In the numerical simulation section, various combinations of the controls are also presented and it has been shown in this part that the optimal combination of both prevention and treatment controls will suppress the prevalence of both HIV and TB to below 3% within 10 years. Moreover, it is found that the treatment control is more effective than the preventive controls. View Full-Text "," gas concentration,gob-side entry retaining (GER),limestone roof,roof-cutting resistance,roadside backfill body (RBB)   tubular membrane,membrane fouling,organic matter,synthetic wastewater,excitation-emission matrix (EEM),inorganic element   jointed rock mass,filled cracks,mechanical behavior,crack coalescence,failure mode   TB-HIV co-infection,behaviour change,dynamical systems,optimal control,equilibrium,treatment,stability,Human Immunodeficiency Virus (HIV),tuberculosis (TB) "," Key Parameters of Gob-Side Entry Retaining in A Gassy and Thin Coal Seam with Hard Roof   Membrane Fouling Characteristics of a Side-Stream Tubular Anaerobic Membrane Bioreactor (AnMBR) Treating Domestic Wastewater   The Effect of Joint Dip Angle on the Mechanical Behavior of Infilled Jointed Rock Masses under Uniaxial and Biaxial Compressions   Optimal Control Strategy for TB-HIV/AIDS Co-Infection Model in the Presence of Behaviour Modification   Abstract
Gob-side entry retaining (GER) employed in a thin coal seam (TCS) can increase economic benefits and coal recovery, as well as mitigate gas concentration in the gob. In accordance with the caving style of a limestone roof, the gas concentration and air pressure in the gob were analyzed, and a roof-cutting mechanical model of GER with a roadside backfill body (RBB) was proposed, to determine the key parameters of the GER-TCS, including the roof-cutting resistance and the width of the RBB. The results show that if the immediate roof height is greater than the seam height, the roof-cutting resistance and width of the RBB should meet the requirement of the immediate roof being totally cut along the gob, for which the optimal roof-cutting resistance and width of RBB were determined by analytical and numerical methods. The greater the RBB width, the greater its roof-cutting resistance. The relationship between the supporting strength of the RBB and the width of the RBB can be derived as a composite curve. The floor heave of GER increases with increasing RBB width. When the width of the RBB increased from 0.8 m to 1.2 m, the floor heave increased two-fold to 146.2 mm. GER was applied in a TCS with a limestone roof of 5 m thickness; the field-measured data verified the conclusions of the numerical model. View Full-Text   Abstract
A lab-scale of a side stream anaerobic membrane bioreactor (AnMBR) equipped with a tubular membrane operated at the mesophilic temperature of 37.0 ± 1.2 °C for treating domestic wastewater was tested to investigate its performance and fouling characteristics at two organic loading rates (OLR) of 0.25 kg COD m−3d−1, and 0.70 kg COD m−3d−1, respectively. The AnMBR was operated for 600 days at sludge retention time (SRT) of 100 days. This AnMBR exhibits excellent chemical oxygen demand (COD) removal of 91% at 0.25 kg COD m−3d−1, and 94% at 0.7 kg COD m−3d−1 respectively, with effluent-soluble COD below 50 mg/L. Chemically-enhanced cleaning method using NaOH, NaOCl, and citric acid solution were introduced for fouling investigation at these two stages. The results showed that sequential chemical cleaning of alkaline and acid were most effective to recover the membrane flux. The alkaline cleaning was effective at removing organic foulants, while citric acid cleaning was effective at removing the scalants. The analyses of the excitation emission matrix, gel permeation chromatography, and extracellular polymeric substances indicated that major components of membrane foulants were proteins, carbohydrates, humic, and fulvic acids. At 0.25 kg COD m−3d−1, organic fouling was more prone to be trapped in the cake layers and responsible for membrane pore blockage, inorganic fouling exhibited marginal contribution to the membrane fouling behavior. However, at 0.70 kg COD m−3d−1, high concentrations of organic and inorganic foulants supported an essential role of organic and inorganic fouling on membrane fouling behavior. View Full-Text   Abstract
Due to the complex formation process of a rock mass, a large number of fissures, joints, faults, other defects exist and the defects commonly contain infilled materials. The jointed rock masses are in a complex geological environment, in which the geometric distribution and the boundary condition can greatly affect the mechanical behavior of the infilled jointed rock mass. In this study, the infilled jointed rock mass specimens with different dip angles are prepared using similar materials, and the uniaxial and biaxial compression tests on the specimens are conducted. The effect of the joint dip angle on the mechanical behavior of the infilled jointed rock mass under uniaxial and biaxial compressions is investigated. The results show that the uniaxial compressive strength shows a W-shaped variation, and the biaxial compressive strength shows a V-shaped variation with an increase in the dip angle. Most of the cracks appear in pairs around the joint and occur symmetrically in a bilateral distribution, and the existence of the infilled joints induces a nonlinear mechanical behavior in the specimen. In addition, the specimens exhibit three failure modes under uniaxial compression: splitting failure, step-path failure and planar failure. The specimens present two failure modes under biaxial compression: splitting failure and planar failure. View Full-Text   Abstract
A mathematical model for a transmission of TB-HIV/AIDS co-infection that incorporates prevalence dependent behaviour change in the population and treatment for the infected (and infectious) class is formulated and analyzed. The two sub-models, when each of the two diseases are considered separately are mathematically analyzed. The theory of optimal control analysis is applied to the full model with the objective of minimizing the aggregate cost of the infections and the control efforts. In the numerical simulation section, various combinations of the controls are also presented and it has been shown in this part that the optimal combination of both prevention and treatment controls will suppress the prevalence of both HIV and TB to below 3% within 10 years. Moreover, it is found that the treatment control is more effective than the preventive controls. View Full-Text   gas concentration,gob-side entry retaining (GER),limestone roof,roof-cutting resistance,roadside backfill body (RBB)   tubular membrane,membrane fouling,organic matter,synthetic wastewater,excitation-emission matrix (EEM),inorganic element   jointed rock mass,filled cracks,mechanical behavior,crack coalescence,failure mode   TB-HIV co-infection,behaviour change,dynamical systems,optimal control,equilibrium,treatment,stability,Human Immunodeficiency Virus (HIV),tuberculosis (TB) ", Processes 
" Experimental Investigation of the Productivity of a Wet Separation Process of Traditional and Bio-Plastics   Silk Fibroin Nanoparticles for Drug Delivery: Effect of Bovine Serum Albumin and Magnetic Nanoparticles Addition on Drug Encapsulation and Release   Natural Variation of Volatile Compounds in Virgin Olive Oil Analyzed by HS-SPME/GC-MS-FID   Assessment, Validation and Application to Real Samples of an RP-HPLC Method for the Determination of Guayulins A, B, C and D in Guayule Shrub "," Abstract
The separation process within a mechanical recycling plant plays a major role in the context of the production of high-quality secondary raw materials and the reduction of extensive waste disposal in landfills. Traditional plants for plastic separation employ dry or wet processes that rely on the different physical properties among the polymers. The hydraulic separator is a device employing a wet technology for particle separation. It allows the separation of two-polymer mixtures into two products, one collected within the instrument and the other one expelled through its outlet ducts. Apparatus performance were analyzed as a function of fluid and solid flow rates, flow patterns developing within the apparatus, in addition to the density, shape, and size of the polymers. For the hydraulic configurations tested, a two-way coupling takes place where the fluid exerts an influence on the plastic particles and the opposite occurs too. The interaction between the solid and liquid phases determines whether a certain polymer settles within the device or is expelled from the apparatus. Tests carried out with samples of increasing volumes of solid particles demonstrate that there are no significant differences in the apparatus effectiveness as far as a two-way interaction takes place. Almost pure concentrates of Polyethylene Terephthalate (PET), Polyvinyl Chloride (PVC), and Polycarbonate (PC) can be obtained from a mixture of traditional polymers. Tests conducted on Polylactic Acid (PLA) and Mater-Bi® samples showed that the hydraulic separator can be effectively employed to separate bio-plastics from conventional plastics with remarkable grade and recovery. View Full-Text   Abstract
Silk fibroin nanoparticles were prepared in the present study based on phase separation between silk fibroin and polyvinyl alcohol. The drug encapsulation efficiency of the prepared nanoparticles was examined at a range of concentrations from 10 ppm to 500 ppm for pramipexole, curcumin, and propranolol hydrochloride. Silk fibroin nanoparticles encapsulated with propranolol presented the highest drug release profile. In order to improve the drug encapsulation efficiency and drug release performance, a modification of silk fibroin nanoparticles with bovine serum albumin and magnetic nanoparticles was tried. The modification was found to improve the drug encapsulation and release of the modified nanoparticles. Bovine-serum-modified nanoparticles presented the best improvement. View Full-Text   Abstract
Virgin olive oil is unique among plant oils for its high levels of oleic acid, and the presence of a wide range of minor components, which are responsible for both its health-promoting properties and characteristic aroma, and only produced when olives are crushed during the industrial process used for oil production. The genetic variability of the major volatile compounds comprising the oil aroma was studied in a representative sample of olive cultivars from the World Olive Germplasm Collection (IFAPA, Cordoba, Spain), by means of the headspace solid-phase microextraction/gas chromatography–mass spectrometry–flame ionization detection (HS-SPME/GC-MS-FID). The analytical data demonstrated that a high variability is found for the content of volatile compounds in olive species, and that most of the volatile compounds found in the oils were synthesized by the enzymes included in the so-called lipoxygenase pathway. Multivariate analysis allowed the identification of cultivars that are particularly interesting, in terms of volatile composition and presumed organoleptic quality, which can be used both to identify old olive cultivars that give rise to oils with a high organoleptic quality, and in parent selection for olive breeding programs. View Full-Text   Abstract
Guayule (Parthenium argentatum Gray) is a shrub native to the arid regions of Mexico. In the last decades, significant attention to its cultivation has arisen because it is the raw material for the production of hypoallergenic natural rubber. Guayule biomass also contains high amounts of resin, which is not normally exploited in any way. Among other sesquiterpenic esters, guayulins (i.e., the parteniol esters of cinnamic acid, guayulin A, or of anisic acid, guayulin B) are contained in resin. In addition, minor amounts of guayulin C and guayulin D are formed by degradation/oxidation of guayulins A and B, respectively. Guayulins likely act as cinnamate and p-anisate reservoirs for the Guayule shrub; in addition, it has been postulated that they might have a key role in the chemical defense system of Guayule. Furthermore, it seems reasonable that guayulins may possess significant biological properties (e.g., antibacterial and anticancer activities), in close analogy with those shown by sesquiterpene lactones contained in many other species of Parthenum genus. As a matter of fact, guayulins A and B play an important role in the synthesis of antineoplastics used in breast cancer treatment. In this contribution we propose an original and validated RP-HPLC approach to the simultaneous quantification of guayulins A, B, C and D. The procedure of resin extraction from Guayule biomass has been optimized in terms of both extraction method and solvent. RP-HPLC separation has been accomplished by an Ascentis® C18 column under isocratic elution with a 80:20 (v:v) acetonitrile:water mixture. Validation was carried out in terms of limits of detection and quantification, linearity, precision, and trueness. Finally, the method was tested with a number of fresh and seasoned samples of spontaneous Guayule shrub from Mexico. View Full-Text "," plastic separation,two-phase flows,coupling regimes,wet technology,mono- and multi-material separation tests,traditional plastics,bio-plastics   silk fibroin,drug delivery,magnetic silk fibroin,bovine serum albumin   Olea europaea L.,virgin olive oil,volatile compounds,variability,quality   guayule,Parthenium argentatum Gray,resin,guayulins,RP-HPLC "," Experimental Investigation of the Productivity of a Wet Separation Process of Traditional and Bio-Plastics   Silk Fibroin Nanoparticles for Drug Delivery: Effect of Bovine Serum Albumin and Magnetic Nanoparticles Addition on Drug Encapsulation and Release   Natural Variation of Volatile Compounds in Virgin Olive Oil Analyzed by HS-SPME/GC-MS-FID   Assessment, Validation and Application to Real Samples of an RP-HPLC Method for the Determination of Guayulins A, B, C and D in Guayule Shrub   Abstract
The separation process within a mechanical recycling plant plays a major role in the context of the production of high-quality secondary raw materials and the reduction of extensive waste disposal in landfills. Traditional plants for plastic separation employ dry or wet processes that rely on the different physical properties among the polymers. The hydraulic separator is a device employing a wet technology for particle separation. It allows the separation of two-polymer mixtures into two products, one collected within the instrument and the other one expelled through its outlet ducts. Apparatus performance were analyzed as a function of fluid and solid flow rates, flow patterns developing within the apparatus, in addition to the density, shape, and size of the polymers. For the hydraulic configurations tested, a two-way coupling takes place where the fluid exerts an influence on the plastic particles and the opposite occurs too. The interaction between the solid and liquid phases determines whether a certain polymer settles within the device or is expelled from the apparatus. Tests carried out with samples of increasing volumes of solid particles demonstrate that there are no significant differences in the apparatus effectiveness as far as a two-way interaction takes place. Almost pure concentrates of Polyethylene Terephthalate (PET), Polyvinyl Chloride (PVC), and Polycarbonate (PC) can be obtained from a mixture of traditional polymers. Tests conducted on Polylactic Acid (PLA) and Mater-Bi® samples showed that the hydraulic separator can be effectively employed to separate bio-plastics from conventional plastics with remarkable grade and recovery. View Full-Text   Abstract
Silk fibroin nanoparticles were prepared in the present study based on phase separation between silk fibroin and polyvinyl alcohol. The drug encapsulation efficiency of the prepared nanoparticles was examined at a range of concentrations from 10 ppm to 500 ppm for pramipexole, curcumin, and propranolol hydrochloride. Silk fibroin nanoparticles encapsulated with propranolol presented the highest drug release profile. In order to improve the drug encapsulation efficiency and drug release performance, a modification of silk fibroin nanoparticles with bovine serum albumin and magnetic nanoparticles was tried. The modification was found to improve the drug encapsulation and release of the modified nanoparticles. Bovine-serum-modified nanoparticles presented the best improvement. View Full-Text   Abstract
Virgin olive oil is unique among plant oils for its high levels of oleic acid, and the presence of a wide range of minor components, which are responsible for both its health-promoting properties and characteristic aroma, and only produced when olives are crushed during the industrial process used for oil production. The genetic variability of the major volatile compounds comprising the oil aroma was studied in a representative sample of olive cultivars from the World Olive Germplasm Collection (IFAPA, Cordoba, Spain), by means of the headspace solid-phase microextraction/gas chromatography–mass spectrometry–flame ionization detection (HS-SPME/GC-MS-FID). The analytical data demonstrated that a high variability is found for the content of volatile compounds in olive species, and that most of the volatile compounds found in the oils were synthesized by the enzymes included in the so-called lipoxygenase pathway. Multivariate analysis allowed the identification of cultivars that are particularly interesting, in terms of volatile composition and presumed organoleptic quality, which can be used both to identify old olive cultivars that give rise to oils with a high organoleptic quality, and in parent selection for olive breeding programs. View Full-Text   Abstract
Guayule (Parthenium argentatum Gray) is a shrub native to the arid regions of Mexico. In the last decades, significant attention to its cultivation has arisen because it is the raw material for the production of hypoallergenic natural rubber. Guayule biomass also contains high amounts of resin, which is not normally exploited in any way. Among other sesquiterpenic esters, guayulins (i.e., the parteniol esters of cinnamic acid, guayulin A, or of anisic acid, guayulin B) are contained in resin. In addition, minor amounts of guayulin C and guayulin D are formed by degradation/oxidation of guayulins A and B, respectively. Guayulins likely act as cinnamate and p-anisate reservoirs for the Guayule shrub; in addition, it has been postulated that they might have a key role in the chemical defense system of Guayule. Furthermore, it seems reasonable that guayulins may possess significant biological properties (e.g., antibacterial and anticancer activities), in close analogy with those shown by sesquiterpene lactones contained in many other species of Parthenum genus. As a matter of fact, guayulins A and B play an important role in the synthesis of antineoplastics used in breast cancer treatment. In this contribution we propose an original and validated RP-HPLC approach to the simultaneous quantification of guayulins A, B, C and D. The procedure of resin extraction from Guayule biomass has been optimized in terms of both extraction method and solvent. RP-HPLC separation has been accomplished by an Ascentis® C18 column under isocratic elution with a 80:20 (v:v) acetonitrile:water mixture. Validation was carried out in terms of limits of detection and quantification, linearity, precision, and trueness. Finally, the method was tested with a number of fresh and seasoned samples of spontaneous Guayule shrub from Mexico. View Full-Text   plastic separation,two-phase flows,coupling regimes,wet technology,mono- and multi-material separation tests,traditional plastics,bio-plastics   silk fibroin,drug delivery,magnetic silk fibroin,bovine serum albumin   Olea europaea L.,virgin olive oil,volatile compounds,variability,quality   guayule,Parthenium argentatum Gray,resin,guayulins,RP-HPLC ", Separations 
 A Simple Spectral Observer   Solution of Optimal Harvesting Problem by Finite Difference Approximations of Size-Structured Population Model   Optimal Control Analysis of a Mathematical Model for Breast Cancer   Impact of Thermal Radiation and Heat Source/Sink on Eyring–Powell Fluid Flow over an Unsteady Oscillatory Porous Stretching Surface ," Abstract
The principal aim of a spectral observer is twofold: the reconstruction of a signal of time via state estimation and the decomposition of such a signal into the frequencies that make it up. A spectral observer can be catalogued as an online algorithm for time-frequency analysis because is a method that can compute on the fly the Fourier Transform (FT) of a signal, without having the entire signal available from the start. In this regard, this paper presents a novel spectral observer with an adjustable constant gain for reconstructing a given signal by means of the recursive identification of the coefficients of a Fourier series. The reconstruction or estimation of a signal in the context of this work means to find the coefficients of a linear combination of sines a cosines that fits a signal such that it can be reproduced. The design procedure of the spectral observer is presented along with the following applications: (1) the reconstruction of a simple periodical signal, (2) the approximation of both a square and a triangular signal, (3) the edge detection in signals by using the Fourier coefficients, (4) the fitting of the historical Bitcoin market data from 1 December 2014 to 8 January 2018 and (5) the estimation of a input force acting upon a Duffing oscillator. To round out this paper, we present a detailed discussion about the results of the applications as well as a comparative analysis of the proposed spectral observer vis-à-vis the Short Time Fourier Transform (STFT), which is a well-known method for time-frequency analysis. View Full-Text   Abstract
We solve numerically a forest management optimization problem governed by a nonlinear partial differential equation (PDE), which is a size-structured population model. The formulated problem is supplemented with a natural constraint for a solution to be non-negative. PDE is approximated by an explicit or implicit in time finite difference scheme, whereas the cost function is taken from the very beginning in the finite-dimensional form used in practice. We prove the stability of the constructed nonlinear finite difference schemes on the set of non-negative vectors and the solvability of the formulated discrete optimal control problems. The gradient information is derived by constructing discrete adjoint state equations. The projected gradient method is used for finding the extremal points. The results of numerical testing for several real problems show good agreement with the known results and confirm the theoretical statements. View Full-Text   Abstract
In this paper, a mathematical model of breast cancer governed by a system of ordinary differential equations in the presence of chemotherapy treatment and ketogenic diet is discussed. Several comprehensive mathematical analyses were carried out using a variety of analytical methods to study the stability of the breast cancer model. Also, sufficient conditions on parameter values to ensure cancer persistence in the absence of anti-cancer drugs, ketogenic diet, and cancer emission when anti-cancer drugs, immune-booster, and ketogenic diet are included were established. Furthermore, optimal control theory is applied to discover the optimal drug adjustment as an input control of the system therapies in order to minimize the number of cancerous cells by considering different controlled combinations of administering the chemotherapy agent and ketogenic diet using the popular Pontryagin’s maximum principle. Numerical simulations are presented to validate our theoretical results. View Full-Text   Abstract
The main intention of this article is to examine the heat transmission of the flow of Eyring–Powell fluid over an unstable oscillatory porous stretching surface. The effect of thermal radiation on the fluid flow is investigated, where the flow is actuated by the unbounded flexible surface which is extended occasionally to and fro on its plane. The rudimentary leading equations are changed to differential equations through the use of applicable similarity variables. An optimal and numerical approach was used to find the solution to the modeled problems. The convergence of the homotopy analysis method (HAM) is shown numerically. The homotopy analysis method predictions of the structures formed are in close agreement with the obtained results from the numerical method. Comparisons between HAM and numerical methods are shown graphically as well as numerically. The convergence of this method is shown numerically. The impacts of the skin friction and heat flux are shown through a table. The influence of the porosity, oscillation, thermal radiation, and heat absorption/generation are the main focus of this work. The consequences of emerging parameters are demonstrated through graphs. View Full-Text "," signal processing,Fourier series,state observer,Short Time Fourier Transform,time-frequency analysis   size-structured population model,nonlinear partial differential equation,finite difference approximation,optimization,gradient method   breast cancer,optimal control,ketogenic diet,chemotherapy   Eyring–Powell fluid,thermal radiation,porosity,oscillatory stretched sheet,HAM "," A Simple Spectral Observer   Solution of Optimal Harvesting Problem by Finite Difference Approximations of Size-Structured Population Model   Optimal Control Analysis of a Mathematical Model for Breast Cancer   Impact of Thermal Radiation and Heat Source/Sink on Eyring–Powell Fluid Flow over an Unsteady Oscillatory Porous Stretching Surface   Abstract
The principal aim of a spectral observer is twofold: the reconstruction of a signal of time via state estimation and the decomposition of such a signal into the frequencies that make it up. A spectral observer can be catalogued as an online algorithm for time-frequency analysis because is a method that can compute on the fly the Fourier Transform (FT) of a signal, without having the entire signal available from the start. In this regard, this paper presents a novel spectral observer with an adjustable constant gain for reconstructing a given signal by means of the recursive identification of the coefficients of a Fourier series. The reconstruction or estimation of a signal in the context of this work means to find the coefficients of a linear combination of sines a cosines that fits a signal such that it can be reproduced. The design procedure of the spectral observer is presented along with the following applications: (1) the reconstruction of a simple periodical signal, (2) the approximation of both a square and a triangular signal, (3) the edge detection in signals by using the Fourier coefficients, (4) the fitting of the historical Bitcoin market data from 1 December 2014 to 8 January 2018 and (5) the estimation of a input force acting upon a Duffing oscillator. To round out this paper, we present a detailed discussion about the results of the applications as well as a comparative analysis of the proposed spectral observer vis-à-vis the Short Time Fourier Transform (STFT), which is a well-known method for time-frequency analysis. View Full-Text   Abstract
We solve numerically a forest management optimization problem governed by a nonlinear partial differential equation (PDE), which is a size-structured population model. The formulated problem is supplemented with a natural constraint for a solution to be non-negative. PDE is approximated by an explicit or implicit in time finite difference scheme, whereas the cost function is taken from the very beginning in the finite-dimensional form used in practice. We prove the stability of the constructed nonlinear finite difference schemes on the set of non-negative vectors and the solvability of the formulated discrete optimal control problems. The gradient information is derived by constructing discrete adjoint state equations. The projected gradient method is used for finding the extremal points. The results of numerical testing for several real problems show good agreement with the known results and confirm the theoretical statements. View Full-Text   Abstract
In this paper, a mathematical model of breast cancer governed by a system of ordinary differential equations in the presence of chemotherapy treatment and ketogenic diet is discussed. Several comprehensive mathematical analyses were carried out using a variety of analytical methods to study the stability of the breast cancer model. Also, sufficient conditions on parameter values to ensure cancer persistence in the absence of anti-cancer drugs, ketogenic diet, and cancer emission when anti-cancer drugs, immune-booster, and ketogenic diet are included were established. Furthermore, optimal control theory is applied to discover the optimal drug adjustment as an input control of the system therapies in order to minimize the number of cancerous cells by considering different controlled combinations of administering the chemotherapy agent and ketogenic diet using the popular Pontryagin’s maximum principle. Numerical simulations are presented to validate our theoretical results. View Full-Text   Abstract
The main intention of this article is to examine the heat transmission of the flow of Eyring–Powell fluid over an unstable oscillatory porous stretching surface. The effect of thermal radiation on the fluid flow is investigated, where the flow is actuated by the unbounded flexible surface which is extended occasionally to and fro on its plane. The rudimentary leading equations are changed to differential equations through the use of applicable similarity variables. An optimal and numerical approach was used to find the solution to the modeled problems. The convergence of the homotopy analysis method (HAM) is shown numerically. The homotopy analysis method predictions of the structures formed are in close agreement with the obtained results from the numerical method. Comparisons between HAM and numerical methods are shown graphically as well as numerically. The convergence of this method is shown numerically. The impacts of the skin friction and heat flux are shown through a table. The influence of the porosity, oscillation, thermal radiation, and heat absorption/generation are the main focus of this work. The consequences of emerging parameters are demonstrated through graphs. View Full-Text   signal processing,Fourier series,state observer,Short Time Fourier Transform,time-frequency analysis   size-structured population model,nonlinear partial differential equation,finite difference approximation,optimization,gradient method   breast cancer,optimal control,ketogenic diet,chemotherapy   Eyring–Powell fluid,thermal radiation,porosity,oscillatory stretched sheet,HAM ", Mathematical and Computational Applications 
 Photonics-Based Microwave Image-Reject Mixer   Design Considerations for Integration of Terahertz Time-Domain Spectroscopy in Microfluidic Platforms ," Abstract
Recent developments in photonics-based microwave image-reject mixers (IRMs) are reviewed with an emphasis on the pre-filtering method, which applies an optical or electrical filter to remove the undesired image, and the phase cancellation method, which is realized by introducing an additional phase to the converted image and cancelling it through coherent combination without phase shift. Applications of photonics-based microwave IRM in electronic warfare, radar systems and satellite payloads are described. The inherent challenges of implementing photonics-based microwave IRM to meet specific requirements of the radio frequency (RF) system are discussed. Developmental trends of the photonics-based microwave IRM are also discussed. View Full-Text   Abstract
Microfluidic platforms have received much attention in recent years. In particular, there is interest in combining spectroscopy with microfluidic platforms. This work investigates the integration of microfluidic platforms and terahertz time-domain spectroscopy (THz-TDS) systems. A semiclassical computational model is used to simulate the emission of THz radiation from a GaAs photoconductive THz emitter. This model incorporates white noise with increasing noise amplitude (corresponding to decreasing dynamic range values). White noise is selected over other noise due to its contributions in THz-TDS systems. The results from this semiclassical computational model, in combination with defined sample thicknesses, can provide the maximum measurable absorption coefficient for a microfluidic-based THz-TDS system. The maximum measurable frequencies for such systems can be extracted through the relationship between the maximum measurable absorption coefficient and the absorption coefficient for representative biofluids. The sample thickness of the microfluidic platform and the dynamic range of the THz-TDS system play a role in defining the maximum measurable frequency for microfluidic-based THz-TDS systems. The results of this work serve as a design tool for the development of such systems. View Full-Text "," microwave photonics,frequency conversion,image reject,photonic signal processing   terahertz,biomedical optics,microfluidics,spectroscopy "," Photonics-Based Microwave Image-Reject Mixer   Design Considerations for Integration of Terahertz Time-Domain Spectroscopy in Microfluidic Platforms   Abstract
Recent developments in photonics-based microwave image-reject mixers (IRMs) are reviewed with an emphasis on the pre-filtering method, which applies an optical or electrical filter to remove the undesired image, and the phase cancellation method, which is realized by introducing an additional phase to the converted image and cancelling it through coherent combination without phase shift. Applications of photonics-based microwave IRM in electronic warfare, radar systems and satellite payloads are described. The inherent challenges of implementing photonics-based microwave IRM to meet specific requirements of the radio frequency (RF) system are discussed. Developmental trends of the photonics-based microwave IRM are also discussed. View Full-Text   Abstract
Microfluidic platforms have received much attention in recent years. In particular, there is interest in combining spectroscopy with microfluidic platforms. This work investigates the integration of microfluidic platforms and terahertz time-domain spectroscopy (THz-TDS) systems. A semiclassical computational model is used to simulate the emission of THz radiation from a GaAs photoconductive THz emitter. This model incorporates white noise with increasing noise amplitude (corresponding to decreasing dynamic range values). White noise is selected over other noise due to its contributions in THz-TDS systems. The results from this semiclassical computational model, in combination with defined sample thicknesses, can provide the maximum measurable absorption coefficient for a microfluidic-based THz-TDS system. The maximum measurable frequencies for such systems can be extracted through the relationship between the maximum measurable absorption coefficient and the absorption coefficient for representative biofluids. The sample thickness of the microfluidic platform and the dynamic range of the THz-TDS system play a role in defining the maximum measurable frequency for microfluidic-based THz-TDS systems. The results of this work serve as a design tool for the development of such systems. View Full-Text   microwave photonics,frequency conversion,image reject,photonic signal processing   terahertz,biomedical optics,microfluidics,spectroscopy ", Photonics 
" Field-Induced Dysprosium Single-Molecule Magnet Involving a Fused o-Semiquinone-Extended-Tetrathiafulvalene-o-Semiquinone Bridging Triad   A M2L2 Redox-Active Metalla-Macrocycle Based on Electron-Rich 9-(1,3-Dithiol-2-ylidene)Fluorene   Metal (Hg, Pt, Ru) Bisalkynyl Bridge between Tetrathiafulvalene Electrophores and Electronic Interplay "," Abstract
The reaction between the 2,2′-benzene-1,4-diylbis(6-hydroxy-4,7-di-tert-butyl-1,3-benzodithiol-2-ylium-5-olate biradical triad (L) and the metallo-precursor [Dy(hfac)3]·2H2O leads to the formation of a one-dimensional coordination polymer with the formula {[Dy(hfac)3(L)]·2C6H14}n (1). The X-ray structure reveals that the polymeric structure is formed by the bridging of the Dy(hfac)3 units with the multi-redox triad L. Single-crystal X-ray diffraction and UltraViolet-visible absorption spectroscopy confirm that the triad L in 1 is bound as a direduced, diprotonated form of o-quinone-extended tetrathiafulvalene-o-quinone (Q-exTTF-Q). Alternate Current (AC) measurements highlight a field-induced single-molecule magnet (SMM) behavior with an energy barrier of 20 K, and thus 1 can be described as a one-dimensional assembly of mononuclear SMMs bridged by the L triad. View Full-Text   Abstract
A redox-active M2L2 metalla-macrocycle is depicted, of which construction has been achieved through coordination driven self-assembly from an electron-rich 9-(1,3-dithiol-2-ylidene)fluorene bis-pyridyl ligand and a cis-blocked square planar palladium complex (Pd(dppf)OTf2, dppf = 1,1′-Bis(diphenylphosphino)ferrocene). The resulting metalla-macrocycle has been fully characterized in solution, as well as in the solid state (X-ray crystal structure). Its electronic properties show that both constitutive ligands can be oxidized independently through a one-electron process. View Full-Text   Abstract
A series of metal (Hg, Pt, Ru) bis(alkynyl-tetrathiafulvalene) complexes have been investigated to study the electronic interplay between the metal and the tetrathiafulvalene (TTF), as well as between the two peripheral TTF electrophores along the organometallic bridge. Cyclic voltammetry experiments, together with spectro-electrochemical investigations, have shown the electronic effect of the metal center through the linker on redox properties of the TTF, as well as the influence of the length of the conjugated organic linker. These data show that the degree of coupling can be modulated from no coupling with mercury to appreciable electronic coupling between different electrophores with ruthenium. View Full-Text "," o-semiquinone,extended-tetrathiafulvalene,triads,lanthanides,single-molecule magnet   supramolecular chemistry,self-assembly,coordination compound,metalla-macrocycle,9-(1,3-dithiol-2-ylidene)Fluorene,redox-active compound   tetrathiafulvalene,alkynyl complexes,ruthenium,platinum,mercury,electrochemistry,electronic interaction "," Field-Induced Dysprosium Single-Molecule Magnet Involving a Fused o-Semiquinone-Extended-Tetrathiafulvalene-o-Semiquinone Bridging Triad   A M2L2 Redox-Active Metalla-Macrocycle Based on Electron-Rich 9-(1,3-Dithiol-2-ylidene)Fluorene   Metal (Hg, Pt, Ru) Bisalkynyl Bridge between Tetrathiafulvalene Electrophores and Electronic Interplay   Abstract
The reaction between the 2,2′-benzene-1,4-diylbis(6-hydroxy-4,7-di-tert-butyl-1,3-benzodithiol-2-ylium-5-olate biradical triad (L) and the metallo-precursor [Dy(hfac)3]·2H2O leads to the formation of a one-dimensional coordination polymer with the formula {[Dy(hfac)3(L)]·2C6H14}n (1). The X-ray structure reveals that the polymeric structure is formed by the bridging of the Dy(hfac)3 units with the multi-redox triad L. Single-crystal X-ray diffraction and UltraViolet-visible absorption spectroscopy confirm that the triad L in 1 is bound as a direduced, diprotonated form of o-quinone-extended tetrathiafulvalene-o-quinone (Q-exTTF-Q). Alternate Current (AC) measurements highlight a field-induced single-molecule magnet (SMM) behavior with an energy barrier of 20 K, and thus 1 can be described as a one-dimensional assembly of mononuclear SMMs bridged by the L triad. View Full-Text   Abstract
A redox-active M2L2 metalla-macrocycle is depicted, of which construction has been achieved through coordination driven self-assembly from an electron-rich 9-(1,3-dithiol-2-ylidene)fluorene bis-pyridyl ligand and a cis-blocked square planar palladium complex (Pd(dppf)OTf2, dppf = 1,1′-Bis(diphenylphosphino)ferrocene). The resulting metalla-macrocycle has been fully characterized in solution, as well as in the solid state (X-ray crystal structure). Its electronic properties show that both constitutive ligands can be oxidized independently through a one-electron process. View Full-Text   Abstract
A series of metal (Hg, Pt, Ru) bis(alkynyl-tetrathiafulvalene) complexes have been investigated to study the electronic interplay between the metal and the tetrathiafulvalene (TTF), as well as between the two peripheral TTF electrophores along the organometallic bridge. Cyclic voltammetry experiments, together with spectro-electrochemical investigations, have shown the electronic effect of the metal center through the linker on redox properties of the TTF, as well as the influence of the length of the conjugated organic linker. These data show that the degree of coupling can be modulated from no coupling with mercury to appreciable electronic coupling between different electrophores with ruthenium. View Full-Text   o-semiquinone,extended-tetrathiafulvalene,triads,lanthanides,single-molecule magnet   supramolecular chemistry,self-assembly,coordination compound,metalla-macrocycle,9-(1,3-dithiol-2-ylidene)Fluorene,redox-active compound   tetrathiafulvalene,alkynyl complexes,ruthenium,platinum,mercury,electrochemistry,electronic interaction ", Inorganics 
 Socioeconomic Status and Self-Rated Oral Health; Diminished Return among Hispanic Whites   Oral Dysbiotic Communities and Their Implications in Systemic Diseases   The Strange Case of Peri-Implantology ," Abstract
Background. An extensive body of knowledge has documented weaker health effects of socio-economic status (SES) for Blacks compared to Whites, a phenomenon also known as Blacks’ diminished return. It is, however, unknown whether the same diminished return also holds for other ethnic minorities such as Hispanics or not. Aim. Using a nationally representative sample, the current study aimed to compare Non-Hispanic and Hispanic Whites for the effects of SES on self-rated oral health. Methods. For the current cross-sectional study, we used data from the Collaborative Psychiatric Epidemiology Surveys (CPES), 2001–2003. With a nationally representative sampling, CPES included 11,207 adults who were either non-Hispanic Whites (n = 7587) or Hispanic Whites (n = 3620. The dependent variable was self-rated oral health, treated as dichotomous measure. Independent variables were education, income, employment, and marital status. Ethnicity was the focal moderator. Age and gender were covariates. Logistic regressions were used for data analysis. Results. Education, income, employment, and marital status were associated with oral health in the pooled sample. Although education, income, employment, and marital status were associated with oral health in non-Hispanic Whites, none of these associations were found for Hispanic Whites. Conclusion. In a similar pattern to Blacks’ diminished return, differential gain of SES indicators exists between Hispanic and non-Hispanic Whites, with a disadvantage for Hispanic Whites. Diminished return of SES should be regarded as a systemically neglected contributing mechanism behind ethnic oral health disparities in the United States. Replication of Blacks’ diminished return for Hispanics suggests that these processes are not specific to ethnic minority groups, and non-White groups gain less because they are not enjoying the privilege and advantage of Whites. View Full-Text   Abstract
The human body supports the growth of a wide array of microbial communities in various niches such as the oral cavity, gastro-intestinal and urogenital tracts, and on the surface of the skin. These host associated microbial communities include yet-un-cultivable bacteria and are influenced by various factors. Together, these communities of bacteria are referred to as the human microbiome. Human oral microbiome consists of both symbionts and pathobionts. Deviation from symbiosis among the bacterial community leads to “dysbiosis”, a state of community disturbance. Dysbiosis occurs due to many confounding factors that predispose a shift in the composition and relative abundance of microbial communities. Dysbiotic communities have been a major cause for many microbiome related systemic infections. Such dysbiosis is directed by certain important pathogens called the “keystone pathogens”, which can modulate community microbiome variations. One such persistent infection is oral infection, mainly periodontitis, where a wide array of causal organisms have been implied to systemic infections such as cardio vascular disease, diabetes mellitus, rheumatoid arthritis, and Alzheimer’s disease. The keystone pathogens co-occur with many yet-cultivable bacteria and their interactions lead to dysbiosis. This has been the focus of recent research. While immune evasion is one of the major modes that leads to dysbiosis, new processes and new virulence factors of bacteria have been shown to be involved in this important process that determines a disease or health state. This review focuses on such dysbiotic communities, their interactions, and their virulence factors that predispose the host to other systemic implications. View Full-Text   No abstract available View Full-Text "," economic inequalities,ethnic health disparities,socioeconomic status,oral health   oral dysbiosis,human oral microbiome,yet-un cultivable organisms,systemic diseases    "," Socioeconomic Status and Self-Rated Oral Health; Diminished Return among Hispanic Whites   Oral Dysbiotic Communities and Their Implications in Systemic Diseases   The Strange Case of Peri-Implantology   Abstract
Background. An extensive body of knowledge has documented weaker health effects of socio-economic status (SES) for Blacks compared to Whites, a phenomenon also known as Blacks’ diminished return. It is, however, unknown whether the same diminished return also holds for other ethnic minorities such as Hispanics or not. Aim. Using a nationally representative sample, the current study aimed to compare Non-Hispanic and Hispanic Whites for the effects of SES on self-rated oral health. Methods. For the current cross-sectional study, we used data from the Collaborative Psychiatric Epidemiology Surveys (CPES), 2001–2003. With a nationally representative sampling, CPES included 11,207 adults who were either non-Hispanic Whites (n = 7587) or Hispanic Whites (n = 3620. The dependent variable was self-rated oral health, treated as dichotomous measure. Independent variables were education, income, employment, and marital status. Ethnicity was the focal moderator. Age and gender were covariates. Logistic regressions were used for data analysis. Results. Education, income, employment, and marital status were associated with oral health in the pooled sample. Although education, income, employment, and marital status were associated with oral health in non-Hispanic Whites, none of these associations were found for Hispanic Whites. Conclusion. In a similar pattern to Blacks’ diminished return, differential gain of SES indicators exists between Hispanic and non-Hispanic Whites, with a disadvantage for Hispanic Whites. Diminished return of SES should be regarded as a systemically neglected contributing mechanism behind ethnic oral health disparities in the United States. Replication of Blacks’ diminished return for Hispanics suggests that these processes are not specific to ethnic minority groups, and non-White groups gain less because they are not enjoying the privilege and advantage of Whites. View Full-Text   Abstract
The human body supports the growth of a wide array of microbial communities in various niches such as the oral cavity, gastro-intestinal and urogenital tracts, and on the surface of the skin. These host associated microbial communities include yet-un-cultivable bacteria and are influenced by various factors. Together, these communities of bacteria are referred to as the human microbiome. Human oral microbiome consists of both symbionts and pathobionts. Deviation from symbiosis among the bacterial community leads to “dysbiosis”, a state of community disturbance. Dysbiosis occurs due to many confounding factors that predispose a shift in the composition and relative abundance of microbial communities. Dysbiotic communities have been a major cause for many microbiome related systemic infections. Such dysbiosis is directed by certain important pathogens called the “keystone pathogens”, which can modulate community microbiome variations. One such persistent infection is oral infection, mainly periodontitis, where a wide array of causal organisms have been implied to systemic infections such as cardio vascular disease, diabetes mellitus, rheumatoid arthritis, and Alzheimer’s disease. The keystone pathogens co-occur with many yet-cultivable bacteria and their interactions lead to dysbiosis. This has been the focus of recent research. While immune evasion is one of the major modes that leads to dysbiosis, new processes and new virulence factors of bacteria have been shown to be involved in this important process that determines a disease or health state. This review focuses on such dysbiotic communities, their interactions, and their virulence factors that predispose the host to other systemic implications. View Full-Text   No abstract available View Full-Text   economic inequalities,ethnic health disparities,socioeconomic status,oral health   oral dysbiosis,human oral microbiome,yet-un cultivable organisms,systemic diseases    ", Dentistry Journal 
 “As-You-Go” Instead of “After-the-Fact”: A Network Approach to Scholarly Communication and Evaluation   Library-Mediated Deposit: A Gift to Researchers or a Curse on Open Access? Reflections from the Case of Surrey   Data-Driven Transition: Joint Reporting of Subscription Expenditure and Publication Costs   Publish and Who Should Perish: You or Science? ," Abstract
Scholarly research faces threats to its sustainability on multiple domains (access, incentives, reproducibility, inclusivity). We argue that “after-the-fact” research papers do not help and actually cause some of these threats because the chronology of the research cycle is lost in a research paper. We propose to give up the academic paper and propose a digitally native “as-you-go” alternative. In this design, modules of research outputs are communicated along the way and are directly linked to each other to form a network of outputs that can facilitate research evaluation. This embeds chronology in the design of scholarly communication and facilitates the recognition of more diverse outputs that go beyond the paper (e.g., code, materials). Moreover, using network analysis to investigate the relations between linked outputs could help align evaluation tools with evaluation questions. We illustrate how such a modular “as-you-go” design of scholarly communication could be structured and how network indicators could be computed to assist in the evaluation process, with specific use cases for funders, universities, and individual researchers. View Full-Text   Abstract
The University of Surrey was one of the first universities to set up an open access repository. The Library was the natural stakeholder to lead this project. Over the years, the service has been influenced by external and internal factors, and consequently the Library’s role in developing the OA agenda has changed. Here, we present the development and implementation of a fully mediated open access service at Surrey. The mediated workflow was introduced following an operational review, to ensure higher compliance and engagement from researchers. The size and responsibilities of the open access team in the Library increased to comply with internal and external policies and to implement the fully mediated workflow. As a result, there has been a growth in deposit rates and overall compliance. We discuss the benefits and shortcomings of Library mediation; its effects on the relationship between the Library, senior management and researchers, and the increasing necessity for the Library to lead towards a culture of openness beyond policy compliance. View Full-Text   Abstract
The transition process from the subscription model to the open access model in the world of scholarly publishing brings a variety of challenges to libraries. Within this evolving landscape, the present article takes a focus on budget control for both subscription and publication expenditure with the opportunity to enable the shift from one to the other. To reach informed decisions with a solid base of data to be used in negotiations with publishers, the diverse already-existing systems for managing publications costs and for managing journal subscriptions have to be adapted to allow comprehensive reporting on publication expenditure and subscription expenditure. In the case presented here, two separate systems are described and the establishment of joint reporting covering both these systems is introduced. Some of the results of joint reporting are presented as an example of how such a comprehensive monitoring can support management decisions and negotiations. On a larger scale, the establishment of the National Open Access Monitor in Germany is introduced, bringing together a diverse range of data from several already-existing systems, including, among others, holdings information, usage data, and data on publication fees. This system will enable libraries to access all relevant data with a single user interface. View Full-Text   Abstract
Something is wrong with science as there is an increasing amount of unreliable, manipulated and outright faked results appearing in the literature. Here I argue that this is a direct consequence of the pay-structure and the assessment system employed in academia and it could be remedied by changing hiring, advancement, and funding criteria. Scientists are paid below average relative to their level of education, unless they are at the top or can secure grants that allow for higher salaries. Positions and grants are mostly awarded based on bibliometric numbers. Consequently, there is a strong competition to accumulate numbers of papers, impact factors, and citations. Those who can increase their value efficiently will be rewarded and the accumulation of higher values will become easier (the Matthew effect). Higher bibliometric numbers can be obtained by unethical or questionable practices, which might tempt some people. If assessments did not employ bibliometric numbers, then these practices would not have a benefit, and would fade out. Throughout the text, data from Hungary, which are similar to data from elsewhere, supplement the argument. View Full-Text "," evaluation,network,communication,paper,metaresearch,decentralization,decentralisation,publishing   open access,repositories,library-mediated deposit,researcher engagement   open access,APC,workflow,journal subscription,offsetting,publication fee,monitoring,transition   publish or perish,inequality,Matthew effect,early stage researchers,Hungary "," “As-You-Go” Instead of “After-the-Fact”: A Network Approach to Scholarly Communication and Evaluation   Library-Mediated Deposit: A Gift to Researchers or a Curse on Open Access? Reflections from the Case of Surrey   Data-Driven Transition: Joint Reporting of Subscription Expenditure and Publication Costs   Publish and Who Should Perish: You or Science?   Abstract
Scholarly research faces threats to its sustainability on multiple domains (access, incentives, reproducibility, inclusivity). We argue that “after-the-fact” research papers do not help and actually cause some of these threats because the chronology of the research cycle is lost in a research paper. We propose to give up the academic paper and propose a digitally native “as-you-go” alternative. In this design, modules of research outputs are communicated along the way and are directly linked to each other to form a network of outputs that can facilitate research evaluation. This embeds chronology in the design of scholarly communication and facilitates the recognition of more diverse outputs that go beyond the paper (e.g., code, materials). Moreover, using network analysis to investigate the relations between linked outputs could help align evaluation tools with evaluation questions. We illustrate how such a modular “as-you-go” design of scholarly communication could be structured and how network indicators could be computed to assist in the evaluation process, with specific use cases for funders, universities, and individual researchers. View Full-Text   Abstract
The University of Surrey was one of the first universities to set up an open access repository. The Library was the natural stakeholder to lead this project. Over the years, the service has been influenced by external and internal factors, and consequently the Library’s role in developing the OA agenda has changed. Here, we present the development and implementation of a fully mediated open access service at Surrey. The mediated workflow was introduced following an operational review, to ensure higher compliance and engagement from researchers. The size and responsibilities of the open access team in the Library increased to comply with internal and external policies and to implement the fully mediated workflow. As a result, there has been a growth in deposit rates and overall compliance. We discuss the benefits and shortcomings of Library mediation; its effects on the relationship between the Library, senior management and researchers, and the increasing necessity for the Library to lead towards a culture of openness beyond policy compliance. View Full-Text   Abstract
The transition process from the subscription model to the open access model in the world of scholarly publishing brings a variety of challenges to libraries. Within this evolving landscape, the present article takes a focus on budget control for both subscription and publication expenditure with the opportunity to enable the shift from one to the other. To reach informed decisions with a solid base of data to be used in negotiations with publishers, the diverse already-existing systems for managing publications costs and for managing journal subscriptions have to be adapted to allow comprehensive reporting on publication expenditure and subscription expenditure. In the case presented here, two separate systems are described and the establishment of joint reporting covering both these systems is introduced. Some of the results of joint reporting are presented as an example of how such a comprehensive monitoring can support management decisions and negotiations. On a larger scale, the establishment of the National Open Access Monitor in Germany is introduced, bringing together a diverse range of data from several already-existing systems, including, among others, holdings information, usage data, and data on publication fees. This system will enable libraries to access all relevant data with a single user interface. View Full-Text   Abstract
Something is wrong with science as there is an increasing amount of unreliable, manipulated and outright faked results appearing in the literature. Here I argue that this is a direct consequence of the pay-structure and the assessment system employed in academia and it could be remedied by changing hiring, advancement, and funding criteria. Scientists are paid below average relative to their level of education, unless they are at the top or can secure grants that allow for higher salaries. Positions and grants are mostly awarded based on bibliometric numbers. Consequently, there is a strong competition to accumulate numbers of papers, impact factors, and citations. Those who can increase their value efficiently will be rewarded and the accumulation of higher values will become easier (the Matthew effect). Higher bibliometric numbers can be obtained by unethical or questionable practices, which might tempt some people. If assessments did not employ bibliometric numbers, then these practices would not have a benefit, and would fade out. Throughout the text, data from Hungary, which are similar to data from elsewhere, supplement the argument. View Full-Text   evaluation,network,communication,paper,metaresearch,decentralization,decentralisation,publishing   open access,repositories,library-mediated deposit,researcher engagement   open access,APC,workflow,journal subscription,offsetting,publication fee,monitoring,transition   publish or perish,inequality,Matthew effect,early stage researchers,Hungary ", Publications 
" Improving Cull Cow Meat Quality Using Vacuum Impregnation   Composition, Protein Profile and Rheological Properties of Pseudocereal-Based Protein-Rich Ingredients   Nanoparticles and Controlled Delivery for Bioactive Compounds: Outlining Challenges for New “Smart-Foods” for Health   Buchanania obovata: Functionality and Phytochemical Profiling of the Australian Native Green Plum "," Abstract
Boneless strip loins from mature cows (50 to 70 months of age) were vacuum impregnated (VI) with an isotonic solution (IS) of sodium chloride. This study sought to determine the vacuum impregnation and microstructural properties of meat from cull cows. The experiments were conducted by varying the pressure,
p
1
(20.3, 71.1 kPa), and time,
t
1
(0.5, 2.0, 4.0 h), of impregnation. After the VI step, the meat was kept for a time,
t
2
(0.0, 0.5, 2.0, 4.0 h), in the IS under atmospheric pressure. The microstructural changes, impregnation, deformation, and porosity of the meat were measured in all the treatments. Impregnation and deformation levels in terms of volume fractions of the initial sample at the end of the vacuum step and the VI processes were calculated according to the mathematical model for deformation-relaxation and hydrodynamic mechanisms. Scanning electron microscopy (SEM) was used to study the microstructure of the vacuum-impregnated meat samples. Results showed that both the vacuum and atmospheric pressures generated a positive impregnation and deformation. The highest values of impregnation
X
(10.5%) and deformation
γ
(9.3%) were obtained at
p
1
of 71.1 kPa and
t
1
of 4.0 h. The sample effective porosity (
ε
e
) exhibited a significant interaction (p < 0.01) between
p
1
×
t
1
. The highest
ε
e
(14.0%) was achieved at
p
1
of 20.3 kPa and
t
1
of 4.0 h, whereas the most extended distension of meat fibers (98 μm) was observed at the highest levels of p1, t1, and t2. These results indicate that meat from mature cows can undergo a vacuum-wetting process successfully, with an IS of sodium chloride to improve its quality. View Full-Text   Abstract
The objectives of this study were to investigate the nutrient composition, protein profile, morphology, and pasting properties of protein-rich pseudocereal ingredients (quinoa, amaranth, and buckwheat) and compare them to the more common rice and maize flours. Literature concerning protein-rich pseudocereal ingredients is very limited, mainly to protein profiling. The concentrations of macronutrients (i.e., ash, fat, and protein, as well as soluble, insoluble and total dietary fibre) were significantly higher for the protein-rich variants of pseudocereal-based flours than their regular protein content variants and the rice and maize flours. On profiling the protein component using sodium dodecyl sulfate–polyacrylamide gel electrophoresis (SDS-PAGE), all samples showed common bands at ~50 kDa and low molecular weight bands corresponding to the globulin fraction (~50 kDa) and albumin fraction (~10 kDa), respectively; except rice, in which the main protein was glutelin. The morphology of the starch granules was studied using scanning electron microscopy with quinoa and amaranth showing the smallest sized granules, while buckwheat, rice, and maize had the largest starch granules. The pasting properties of the ingredients were generally similar, except for buckwheat and amaranth, which showed the highest and lowest final viscosity, respectively. The results obtained in this study can be used to better understand the functionality and food applications of protein-rich pseudocereal ingredients. View Full-Text   Abstract
Nanotechnology is a field of research that has been stressed as a very valuable approach for the prevention and treatment of different human health disorders. This has been stressed as a delivery system for the therapeutic fight against an array of pathophysiological situations. Actually, industry has applied this technology in the search for new oral delivery alternatives obtained upon the modification of the solubility properties of bioactive compounds. Significant works have been made in the last years for testing the input that nanomaterials and nanoparticles provide for an array of pathophysiological situations. In this frame, this review addresses general questions concerning the extent to which nanoparticles offer alternatives that improve therapeutic value, while avoid toxicity, by releasing bioactive compounds specifically to target tissues affected by specific chemical and pathophysiological settings. In this regard, to date, the contribution of nanoparticles to protect encapsulated bioactive compounds from degradation as a result of gastrointestinal digestion and cellular metabolism, to enable their release in a controlled manner, enhancing biodistribution of bioactive compounds, and to allow them to target those tissues affected by biological disturbances has been demonstrated. View Full-Text   Abstract
The green plum is the fruit of Buchanania obovata Engl. and is an Australian Indigenous bush food. Very little study has been done on the green plum, so this is an initial screening study of the functional properties and phytochemical profile found in the flesh and seed. The flesh was shown to have antimicrobial properties effective against gram negative (Escherichia coli 9001—NCTC) and gram positive (Staphylococcus aureus 6571—NCTC) bacteria. Scanning electron microscopy analysis shows that the antimicrobial activity causes cell wall disintegration and cytoplasmic leakage in both bacteria. Antioxidant 2,2-diphenyl-1-picrylhydrazyl (DPPH) testing shows the flesh has high radical scavenging activity (106.3 ± 28.6 μM Trolox equivalant/g Dry Weight in methanol). The flesh and seed contain a range of polyphenols including gallic acid, ellagic acid, p-coumaric acid, kaempferol, quercetin and trans-ferulic acid that may be responsible for this activity. The seed is eaten as a bush food and contains a delphinidin-based anthocyanin. The green plum has potential as a functional ingredient in food products for its antimicrobial and antioxidant activity, and further investigation into its bioactivity, chemical composition and potential applications in different food products is warranted. View Full-Text "," vacuum impregnation,sodium chloride brine,cull cows,meat quality,microstructure,moisture-enhanced meat   pseudocereal,cereal,protein-rich ingredients,macronutrient,protein profile,morphology,rheological properties   phytochemicals,nanoparticles,controlled release,improved functionality,health,smart-formulations   Buchanania obovata,green plum,fruit,polyphenols,antioxidants,Indigenous Australia "," Improving Cull Cow Meat Quality Using Vacuum Impregnation   Composition, Protein Profile and Rheological Properties of Pseudocereal-Based Protein-Rich Ingredients   Nanoparticles and Controlled Delivery for Bioactive Compounds: Outlining Challenges for New “Smart-Foods” for Health   Buchanania obovata: Functionality and Phytochemical Profiling of the Australian Native Green Plum   Abstract
Boneless strip loins from mature cows (50 to 70 months of age) were vacuum impregnated (VI) with an isotonic solution (IS) of sodium chloride. This study sought to determine the vacuum impregnation and microstructural properties of meat from cull cows. The experiments were conducted by varying the pressure,
p
1
(20.3, 71.1 kPa), and time,
t
1
(0.5, 2.0, 4.0 h), of impregnation. After the VI step, the meat was kept for a time,
t
2
(0.0, 0.5, 2.0, 4.0 h), in the IS under atmospheric pressure. The microstructural changes, impregnation, deformation, and porosity of the meat were measured in all the treatments. Impregnation and deformation levels in terms of volume fractions of the initial sample at the end of the vacuum step and the VI processes were calculated according to the mathematical model for deformation-relaxation and hydrodynamic mechanisms. Scanning electron microscopy (SEM) was used to study the microstructure of the vacuum-impregnated meat samples. Results showed that both the vacuum and atmospheric pressures generated a positive impregnation and deformation. The highest values of impregnation
X
(10.5%) and deformation
γ
(9.3%) were obtained at
p
1
of 71.1 kPa and
t
1
of 4.0 h. The sample effective porosity (
ε
e
) exhibited a significant interaction (p < 0.01) between
p
1
×
t
1
. The highest
ε
e
(14.0%) was achieved at
p
1
of 20.3 kPa and
t
1
of 4.0 h, whereas the most extended distension of meat fibers (98 μm) was observed at the highest levels of p1, t1, and t2. These results indicate that meat from mature cows can undergo a vacuum-wetting process successfully, with an IS of sodium chloride to improve its quality. View Full-Text   Abstract
The objectives of this study were to investigate the nutrient composition, protein profile, morphology, and pasting properties of protein-rich pseudocereal ingredients (quinoa, amaranth, and buckwheat) and compare them to the more common rice and maize flours. Literature concerning protein-rich pseudocereal ingredients is very limited, mainly to protein profiling. The concentrations of macronutrients (i.e., ash, fat, and protein, as well as soluble, insoluble and total dietary fibre) were significantly higher for the protein-rich variants of pseudocereal-based flours than their regular protein content variants and the rice and maize flours. On profiling the protein component using sodium dodecyl sulfate–polyacrylamide gel electrophoresis (SDS-PAGE), all samples showed common bands at ~50 kDa and low molecular weight bands corresponding to the globulin fraction (~50 kDa) and albumin fraction (~10 kDa), respectively; except rice, in which the main protein was glutelin. The morphology of the starch granules was studied using scanning electron microscopy with quinoa and amaranth showing the smallest sized granules, while buckwheat, rice, and maize had the largest starch granules. The pasting properties of the ingredients were generally similar, except for buckwheat and amaranth, which showed the highest and lowest final viscosity, respectively. The results obtained in this study can be used to better understand the functionality and food applications of protein-rich pseudocereal ingredients. View Full-Text   Abstract
Nanotechnology is a field of research that has been stressed as a very valuable approach for the prevention and treatment of different human health disorders. This has been stressed as a delivery system for the therapeutic fight against an array of pathophysiological situations. Actually, industry has applied this technology in the search for new oral delivery alternatives obtained upon the modification of the solubility properties of bioactive compounds. Significant works have been made in the last years for testing the input that nanomaterials and nanoparticles provide for an array of pathophysiological situations. In this frame, this review addresses general questions concerning the extent to which nanoparticles offer alternatives that improve therapeutic value, while avoid toxicity, by releasing bioactive compounds specifically to target tissues affected by specific chemical and pathophysiological settings. In this regard, to date, the contribution of nanoparticles to protect encapsulated bioactive compounds from degradation as a result of gastrointestinal digestion and cellular metabolism, to enable their release in a controlled manner, enhancing biodistribution of bioactive compounds, and to allow them to target those tissues affected by biological disturbances has been demonstrated. View Full-Text   Abstract
The green plum is the fruit of Buchanania obovata Engl. and is an Australian Indigenous bush food. Very little study has been done on the green plum, so this is an initial screening study of the functional properties and phytochemical profile found in the flesh and seed. The flesh was shown to have antimicrobial properties effective against gram negative (Escherichia coli 9001—NCTC) and gram positive (Staphylococcus aureus 6571—NCTC) bacteria. Scanning electron microscopy analysis shows that the antimicrobial activity causes cell wall disintegration and cytoplasmic leakage in both bacteria. Antioxidant 2,2-diphenyl-1-picrylhydrazyl (DPPH) testing shows the flesh has high radical scavenging activity (106.3 ± 28.6 μM Trolox equivalant/g Dry Weight in methanol). The flesh and seed contain a range of polyphenols including gallic acid, ellagic acid, p-coumaric acid, kaempferol, quercetin and trans-ferulic acid that may be responsible for this activity. The seed is eaten as a bush food and contains a delphinidin-based anthocyanin. The green plum has potential as a functional ingredient in food products for its antimicrobial and antioxidant activity, and further investigation into its bioactivity, chemical composition and potential applications in different food products is warranted. View Full-Text   vacuum impregnation,sodium chloride brine,cull cows,meat quality,microstructure,moisture-enhanced meat   pseudocereal,cereal,protein-rich ingredients,macronutrient,protein profile,morphology,rheological properties   phytochemicals,nanoparticles,controlled release,improved functionality,health,smart-formulations   Buchanania obovata,green plum,fruit,polyphenols,antioxidants,Indigenous Australia ", Foods 
" A Risk-Based Location-Allocation Approach for Weapon Logistics   The Integration of Extended Supply Chain with Sales and Operation Planning: A Conceptual Framework   Considering Materials Management in Construction: An Exploratory Study   Assessing Port Governance, Devolution and Terminal Performance in Nigeria "," Abstract
Governments have vital missions, such as securing their nation from many internal or external risks/threats. Thus, they prepare themselves against different scenarios. The most common scenario for all countries is “facing attacks from other countries”. However, training for these scenarios is not possible because military exercises are too expensive. The contribution of this paper is a scientific approach proposed for such a scenario. A mathematical model is developed to allocate different weapon types to a set of candidate locations (demand nodes, the military installations that need weapons) while minimizing total transportation costs, setup costs, and allocation risk. The risk arises from allocating the weapons to other military units as backups during a conflict. The risk increases when one military unit allocates their weapons to another unit during attacks. The mathematical model is tested on a case study problem of Turkish Land Forces. This case study is solved in 14 min, and the optimal total transportation and setup costs are determined. Since it is very important to make quick decisions during an attack, this scientific approach and computational time can be useful for military decision makers. Additionally, the results of this study can guarantee that any attack can be handled with the minimum cost and risk. View Full-Text   Abstract
This research is an effort to present the emergence of ways to enable marketers to attain high sensitivity and visibility in the supply chain network. It also aims to facilitate better multi-criteria decisions throughout the extended supply chain. It is a qualitative study considering 31 published research articles related to supply chain integration, sales and operation planning, and the use of information systems. With a focus on narrative data, a purposive sampling technique was used to select the papers for review and to produce the results of this study. The findings of this research indicate that the sales and operation planning (S&OP) processes and the key operations in the supply chain network need to be fully integrated. The findings also indicate that information system resources are the key enabler of S&OP and supply chain integration. To be specific, this research is an exercise in theorizing a conceptual framework for optimally confronting the emerging challenges and opportunities regarding an extended supply chain and is intended to bring the proficiency of multi-criteria decisions and actions in the entire supply chain network. View Full-Text   Abstract
While materials count for a considerable amount of construction costs, the way materials are managed seems to be improvised rather than approached methodically. This study investigates the practice of novel techniques used to manage materials in the construction industry. Techniques that have already proven themselves to be efficient ways to manage the production pace within the industry include the pull system, Just-In-Time, Kitting and off-site fabrication. These are explained and assessed in the context of the French construction industry through an exploratory study, supported by a questionnaire completed by contractors. The results reveal that a clear plan to manage materials on-site is lacking among the respondents, creating common inventory problems. This research provides evidence to support the central role played by an efficient management of material flow on-site. It also highlights the obstacles that hinder the adoption of innovative techniques, such as sub-contractor coordination. View Full-Text   Abstract
Concerns about performance and efficiency in port terminals led many national governments to embark on port reforms. The Federal government of Nigeria, for example, adopted the Landlord port model which brought about concessioning of port terminals to private operators. Despite high investments in terminal facilities by the private terminal operators, there are still complaints about level of service offered to port users. This paper applied key performance indicator metrics and parameters of queuing model in assessing performance of Nigeria’s concessioned port terminals. Data for the study were obtained from terminal level records of cargo and ship handling activities for years 2000 to 2015. Major findings indicate that cargo and vessel throughputs improved after the reforms in the six ports examined. However, much variability was observed in trends in ships’ turnround times across all ports after the concession policy implementation. Additional results from the queuing model analysis suggest that the high ships turnround times observed in some ports are associated to delays in ship operation at the berths. The paper recommends that policy interventions be focused on ship operations at the berths as a step in improving service level in the port terminals. View Full-Text "," location-allocation,risk,weapon logistics,homeland defense   supply chain integration,sales and operation planning,information systems,multi-criteria decisions,information flow   materials management,construction,kitting,pull planning,supplier,inventory   port governance,devolution,concession,terminal performance,queuing analysis "," A Risk-Based Location-Allocation Approach for Weapon Logistics   The Integration of Extended Supply Chain with Sales and Operation Planning: A Conceptual Framework   Considering Materials Management in Construction: An Exploratory Study   Assessing Port Governance, Devolution and Terminal Performance in Nigeria   Abstract
Governments have vital missions, such as securing their nation from many internal or external risks/threats. Thus, they prepare themselves against different scenarios. The most common scenario for all countries is “facing attacks from other countries”. However, training for these scenarios is not possible because military exercises are too expensive. The contribution of this paper is a scientific approach proposed for such a scenario. A mathematical model is developed to allocate different weapon types to a set of candidate locations (demand nodes, the military installations that need weapons) while minimizing total transportation costs, setup costs, and allocation risk. The risk arises from allocating the weapons to other military units as backups during a conflict. The risk increases when one military unit allocates their weapons to another unit during attacks. The mathematical model is tested on a case study problem of Turkish Land Forces. This case study is solved in 14 min, and the optimal total transportation and setup costs are determined. Since it is very important to make quick decisions during an attack, this scientific approach and computational time can be useful for military decision makers. Additionally, the results of this study can guarantee that any attack can be handled with the minimum cost and risk. View Full-Text   Abstract
This research is an effort to present the emergence of ways to enable marketers to attain high sensitivity and visibility in the supply chain network. It also aims to facilitate better multi-criteria decisions throughout the extended supply chain. It is a qualitative study considering 31 published research articles related to supply chain integration, sales and operation planning, and the use of information systems. With a focus on narrative data, a purposive sampling technique was used to select the papers for review and to produce the results of this study. The findings of this research indicate that the sales and operation planning (S&OP) processes and the key operations in the supply chain network need to be fully integrated. The findings also indicate that information system resources are the key enabler of S&OP and supply chain integration. To be specific, this research is an exercise in theorizing a conceptual framework for optimally confronting the emerging challenges and opportunities regarding an extended supply chain and is intended to bring the proficiency of multi-criteria decisions and actions in the entire supply chain network. View Full-Text   Abstract
While materials count for a considerable amount of construction costs, the way materials are managed seems to be improvised rather than approached methodically. This study investigates the practice of novel techniques used to manage materials in the construction industry. Techniques that have already proven themselves to be efficient ways to manage the production pace within the industry include the pull system, Just-In-Time, Kitting and off-site fabrication. These are explained and assessed in the context of the French construction industry through an exploratory study, supported by a questionnaire completed by contractors. The results reveal that a clear plan to manage materials on-site is lacking among the respondents, creating common inventory problems. This research provides evidence to support the central role played by an efficient management of material flow on-site. It also highlights the obstacles that hinder the adoption of innovative techniques, such as sub-contractor coordination. View Full-Text   Abstract
Concerns about performance and efficiency in port terminals led many national governments to embark on port reforms. The Federal government of Nigeria, for example, adopted the Landlord port model which brought about concessioning of port terminals to private operators. Despite high investments in terminal facilities by the private terminal operators, there are still complaints about level of service offered to port users. This paper applied key performance indicator metrics and parameters of queuing model in assessing performance of Nigeria’s concessioned port terminals. Data for the study were obtained from terminal level records of cargo and ship handling activities for years 2000 to 2015. Major findings indicate that cargo and vessel throughputs improved after the reforms in the six ports examined. However, much variability was observed in trends in ships’ turnround times across all ports after the concession policy implementation. Additional results from the queuing model analysis suggest that the high ships turnround times observed in some ports are associated to delays in ship operation at the berths. The paper recommends that policy interventions be focused on ship operations at the berths as a step in improving service level in the port terminals. View Full-Text   location-allocation,risk,weapon logistics,homeland defense   supply chain integration,sales and operation planning,information systems,multi-criteria decisions,information flow   materials management,construction,kitting,pull planning,supplier,inventory   port governance,devolution,concession,terminal performance,queuing analysis ", Logistics 
" Liver Injury by Carbon Tetrachloride Intoxication in 16 Patients Treated with Forced Ventilation to Accelerate Toxin Removal via the Lungs: A Clinical Report   Herb-Induced Liver Injuries in Developing Nations: An Update   Cancer Mortality in Residents of the Cadmium-Polluted Jinzu River Basin in Toyama, Japan "," Abstract
Carbon tetrachloride (CCl4) is an efficient but highly toxic solvent, used in households and commercially in the industry under regulatory surveillance to ensure safety at the working place and to protect the workers’ health. However, acute unintentional or intentional intoxications by CCl4 may rarely occur and are potentially life-threatening. In this review article, therapy options are discussed that are based on a literature review of traditional poisoning cases and the clinical experience with 16 patients with acute poisoning by CCl4. Among various therapy options, the CO2-induced hyperventilation therapy will be considered in detail as the most promising approach. This special therapy was developed because only around 1% of the intoxicating CCl4 is responsible for the liver injury after conversion to toxic radicals via microsomal cytochrome P450 2E1 whereas 99% of the solvent will leave the body unchanged by exhalation. Therefore, to enhance CCl4 elimination through the lungs, CO2 is added to the inspiration air at a flow rate of 2–3 L min−1 in order to achieve hyperventilation with a respiratory volume of 25–30 L min−1. Under this therapy, the clinical course was favorable in 15/16 patients, corresponding to 93.8%. In essence, patients with acute CCl4 intoxication should be treated by forced ventilation. View Full-Text   Abstract
The last few decades have seen a rise in the use of herbal supplements, natural products, and traditional medicines. However, there are growing concerns related to the safety and toxicities of these medicines. These herbal medicines are associated with complications such as liver damage with a high incidence of mortalities and morbidities. Clinical manifestations range from asymptomatic cases with abnormal liver functions tests to sudden and severe liver failure necessitating liver transplantation. This work aimed to review the etiology, risk factors, diagnosis, clinical manifestations and selected clinical case reports of herbal hepatotoxicity in developing nations. PubMed and Google Scholar searches were undertaken to identify relevant literature. Furthermore, we scanned the reference lists of the primary and review articles to identify publications not retrieved by electronic searches. Little data exists on clinical cases of herb-induced liver injury in some developing countries such as Nigeria, as most incidences are either not reported to health care providers or reports from hospitals go unpublished. Studies in Nigeria have highlighted a possible correlation between use of herbs and liver disease. In Uganda, and association between the use of traditional herbal medicine with liver fibrosis in HIV-infected and non-HIV patients was demonstrated. Reports from China have revealed incidences of acute liver failure as a result of herbal medicine use. The actual incidence and prevalence of HILI in developing nations remain largely unknown due to both poor pharmacovigilance programs and non-application of emerging technologies. Improving education and public awareness of the potential risks of herbals and herbal products is desirable to ensure that suspected adverse effects are formally reported. There is need for stricter regulations and pre-clinical studies necessary for efficacy and safety. View Full-Text   Abstract
After 26 years, we followed up 7348 participants in a 1979–1984 health screening survey in the Jinzu River basin, the heaviest cadmium-polluted area in Japan. We assessed the associations of cadmium exposure levels and mortality from cancer and renal damage, indicated by records of proteinuria and glucosuria in the original survey. Mortality risks (hazard ratios) were analyzed using the Cox proportional hazards model, stratified by sex, after adjusting for age, smoking status, and hypertension, as indicated in the original survey records. In men, the adjusted hazard ratio for mortality from lung cancer was significantly lower in individuals residing in an area of historically high cadmium exposure and in subjects with a historical record of proteinuria, glucosuria, and glucoproteinuria. The risk of mortality from prostate cancer was borderline higher in cadmium-exposed men. In women, historical cadmium exposure was not associated with an increased risk of mortality from malignant neoplasms, but the adjusted hazard ratios for death from total malignant neoplasms or from renal and uterine cancers were significantly higher in exposed subjects with a historical record of proteinuria, glucosuria, and glucoproteinuria. These findings suggest that women residing in cadmium-polluted areas who exhibit markers of renal damage may be at risk of dying of cancer. View Full-Text "," carbon tetrachloride,aliphatic halogenated hydrocarbons,cytochrome P450 2E1,CO2-induced forced ventilation,hyperbaric oxygen treatment   liver disease,risk assessment,public health,herbal,herbs and dietary supplements   cadmium,follow-up study,cause of death,mortality,environmental pollution,cancer "," Liver Injury by Carbon Tetrachloride Intoxication in 16 Patients Treated with Forced Ventilation to Accelerate Toxin Removal via the Lungs: A Clinical Report   Herb-Induced Liver Injuries in Developing Nations: An Update   Cancer Mortality in Residents of the Cadmium-Polluted Jinzu River Basin in Toyama, Japan   Abstract
Carbon tetrachloride (CCl4) is an efficient but highly toxic solvent, used in households and commercially in the industry under regulatory surveillance to ensure safety at the working place and to protect the workers’ health. However, acute unintentional or intentional intoxications by CCl4 may rarely occur and are potentially life-threatening. In this review article, therapy options are discussed that are based on a literature review of traditional poisoning cases and the clinical experience with 16 patients with acute poisoning by CCl4. Among various therapy options, the CO2-induced hyperventilation therapy will be considered in detail as the most promising approach. This special therapy was developed because only around 1% of the intoxicating CCl4 is responsible for the liver injury after conversion to toxic radicals via microsomal cytochrome P450 2E1 whereas 99% of the solvent will leave the body unchanged by exhalation. Therefore, to enhance CCl4 elimination through the lungs, CO2 is added to the inspiration air at a flow rate of 2–3 L min−1 in order to achieve hyperventilation with a respiratory volume of 25–30 L min−1. Under this therapy, the clinical course was favorable in 15/16 patients, corresponding to 93.8%. In essence, patients with acute CCl4 intoxication should be treated by forced ventilation. View Full-Text   Abstract
The last few decades have seen a rise in the use of herbal supplements, natural products, and traditional medicines. However, there are growing concerns related to the safety and toxicities of these medicines. These herbal medicines are associated with complications such as liver damage with a high incidence of mortalities and morbidities. Clinical manifestations range from asymptomatic cases with abnormal liver functions tests to sudden and severe liver failure necessitating liver transplantation. This work aimed to review the etiology, risk factors, diagnosis, clinical manifestations and selected clinical case reports of herbal hepatotoxicity in developing nations. PubMed and Google Scholar searches were undertaken to identify relevant literature. Furthermore, we scanned the reference lists of the primary and review articles to identify publications not retrieved by electronic searches. Little data exists on clinical cases of herb-induced liver injury in some developing countries such as Nigeria, as most incidences are either not reported to health care providers or reports from hospitals go unpublished. Studies in Nigeria have highlighted a possible correlation between use of herbs and liver disease. In Uganda, and association between the use of traditional herbal medicine with liver fibrosis in HIV-infected and non-HIV patients was demonstrated. Reports from China have revealed incidences of acute liver failure as a result of herbal medicine use. The actual incidence and prevalence of HILI in developing nations remain largely unknown due to both poor pharmacovigilance programs and non-application of emerging technologies. Improving education and public awareness of the potential risks of herbals and herbal products is desirable to ensure that suspected adverse effects are formally reported. There is need for stricter regulations and pre-clinical studies necessary for efficacy and safety. View Full-Text   Abstract
After 26 years, we followed up 7348 participants in a 1979–1984 health screening survey in the Jinzu River basin, the heaviest cadmium-polluted area in Japan. We assessed the associations of cadmium exposure levels and mortality from cancer and renal damage, indicated by records of proteinuria and glucosuria in the original survey. Mortality risks (hazard ratios) were analyzed using the Cox proportional hazards model, stratified by sex, after adjusting for age, smoking status, and hypertension, as indicated in the original survey records. In men, the adjusted hazard ratio for mortality from lung cancer was significantly lower in individuals residing in an area of historically high cadmium exposure and in subjects with a historical record of proteinuria, glucosuria, and glucoproteinuria. The risk of mortality from prostate cancer was borderline higher in cadmium-exposed men. In women, historical cadmium exposure was not associated with an increased risk of mortality from malignant neoplasms, but the adjusted hazard ratios for death from total malignant neoplasms or from renal and uterine cancers were significantly higher in exposed subjects with a historical record of proteinuria, glucosuria, and glucoproteinuria. These findings suggest that women residing in cadmium-polluted areas who exhibit markers of renal damage may be at risk of dying of cancer. View Full-Text   carbon tetrachloride,aliphatic halogenated hydrocarbons,cytochrome P450 2E1,CO2-induced forced ventilation,hyperbaric oxygen treatment   liver disease,risk assessment,public health,herbal,herbs and dietary supplements   cadmium,follow-up study,cause of death,mortality,environmental pollution,cancer ", Toxics 
" Phytochemistry, Antioxidant, and Hepatoprotective Potential of Acanthospermum hispidum DC Extracts against Diethylnitrosamine-Induced Hepatotoxicity in Rats   Bibliometric Analysis of Traditional Chinese Medicine Scientific Production between 1982 and 2016 Indexed in PubMed   Rationalism, Empiricism, and Evidence-Based Medicine: A Call for a New Galenic Synthesis   Does the World Need Plant Medicines? "," Abstract
Background: Burkina Faso is classified among the countries with a high prevalence (˃12%) of hepatitis. Hepatic diseases, such as cirrhosis—related to alcoholism—and hepatitis B and C, are the cause of the increase in cases of liver cancer. They promote the development of cancer by decreasing the natural cell death, causing problems with DNA repair, or by increasing the production of free radical toxins to the cell. According to the World Health Organization (WHO), there were nearly 639,000 deaths from liver cancer worldwide in 2014, hence the need to search for natural hepatoprotective molecules. Objective: To evaluate the hepatoprotective potential of Acanthospermum hispidum extracts on rats and the antioxidant capacity of extracts in vitro and in vivo, and to perform phytochemistry. Methods: The ethanolic and aqueous extracts of the whole Acanthospermum hispidum plant were used to evaluate hepatoprotection. The hepatotoxin used in our case was diethylenitrosamine. The animals were divided into groups of six. The sera of the treated animals were used for the determination of transaminases, and the liver homogenates were used for the determination of antioxidant. The total phenol and flavonoid contents, and the antioxidant properties of the extracts, were evaluated in vitro. Results: The results of the in vitro antioxidant tests showed good antioxidant activity of the ethanolic extract, using the 2,2-diphenyl-1-picrylhydrazyl (DPPH) test (0.08 ± 0.0018 μg/mL) and 2,2′-azinobis (3-ethylbenzolin-6-sulphonate) (ABTS) (246.05 ± 1.55 mmol TE/g). The in vivo tests showed, through the evaluation of the antioxidant in vivo and the biochemical parameters, that the ethanolic extract with the highest phenolic content had a good hepatoprotective capacity. Conclusions: The antioxidant activity of Acanthopermum hispidum extracts would justify the observed hepatoprotective activity. These results confirmed that the plant is used in the treatment of liver diseases in traditional medicine in Burkina Faso. View Full-Text   Abstract
Background: Traditional Chinese medicine (TCM) may be understood as a system of sensations and findings designed to establish the functional vegetative state of the body. This state may be treated by several therapeutic methods such as acupuncture, Chinese pharmacotherapy, dietetics, Tuina, and Qigong. Nowadays, as a result of several evidence-based reported beneficial effects over specific pathological conditions, there is an increasing tendency to integrate some of these practices in Western medicine. The main goal of this study was to perform a bibliometric analysis of TCM scientific production between 1982 and 2016 indexed in PubMed, by analyzing several parameters including time and location distribution, publication quality, experimental design, and treatment methods. Methods: The methodology was based on the quantitative inventory of published scientific research indexed in PubMed medical subject headings (MeSH), sorted within the broad term “Traditional Chinese Medicine” and integrating the following criteria as limit filters: “Species: Humans”, “Article Type: Clinical Trial”. In addition, the articles’ triage was ruled by temporal limitations set between 1945 and 2016. Results: The overall analysis of data allowed observation of an average annual growth of approximately 33%, with a productive peak of 122 articles in 2007. The scientific production was distributed in 27 countries, led by China (76.1%), followed by the United States of America (3.0%) and South Korea (2.1%). A significant amount of references were published in Chinese journals: more than 50%; however, these journals had a low impact factor. The most cited treatments in the keywords section of the articles were phytotherapy (55%) and acupuncture (40%). Conclusion: The increasing demand for TCM seems to be due to factors such as lower side effects and greater efficacy in some patients not responding well to conventional therapy. As a result, a considerable amount of TCM science-based literature has been produced, supporting the rational integration of these practices in Western healthcare systems and research. Our results show that the quality of TCM research and inherent publications have been increasing over the last decades, with a higher incidence of studies published in well-ranked journals. View Full-Text   Abstract
Thirty years after the rise of the evidence-based medicine (EBM) movement, formal training in philosophy remains poorly represented among medical students and their educators. In this paper, I argue that EBM’s reception in this context has resulted in a privileging of empiricism over rationalism in clinical reasoning with unintended consequences for medical practice. After a limited review of the history of medical epistemology, I argue that a solution to this problem can be found in the method of the 2nd-century Roman physician Galen, who brought empiricism and rationalism together in a synthesis anticipating the scientific method. Next, I review several of the problems that have been identified as resulting from a staunch commitment to empiricism in medical practice. Finally, I conclude that greater epistemological awareness in the medical community would precipitate a Galenic shift toward a more epistemically balanced, scientific approach to clinical research. View Full-Text   No abstract available View Full-Text "," Acanthospermum hispidum,diethylenitrosamine,hepatotoxicity,antioxidative enzyme,phenolics,antioxidant activities   acupuncture,traditional Chinese medicine,bibliometric analysis,PubMed   epistemology,evidence-based medicine,medical education,rationalism,empiricism,Galen    "," Phytochemistry, Antioxidant, and Hepatoprotective Potential of Acanthospermum hispidum DC Extracts against Diethylnitrosamine-Induced Hepatotoxicity in Rats   Bibliometric Analysis of Traditional Chinese Medicine Scientific Production between 1982 and 2016 Indexed in PubMed   Rationalism, Empiricism, and Evidence-Based Medicine: A Call for a New Galenic Synthesis   Does the World Need Plant Medicines?   Abstract
Background: Burkina Faso is classified among the countries with a high prevalence (˃12%) of hepatitis. Hepatic diseases, such as cirrhosis—related to alcoholism—and hepatitis B and C, are the cause of the increase in cases of liver cancer. They promote the development of cancer by decreasing the natural cell death, causing problems with DNA repair, or by increasing the production of free radical toxins to the cell. According to the World Health Organization (WHO), there were nearly 639,000 deaths from liver cancer worldwide in 2014, hence the need to search for natural hepatoprotective molecules. Objective: To evaluate the hepatoprotective potential of Acanthospermum hispidum extracts on rats and the antioxidant capacity of extracts in vitro and in vivo, and to perform phytochemistry. Methods: The ethanolic and aqueous extracts of the whole Acanthospermum hispidum plant were used to evaluate hepatoprotection. The hepatotoxin used in our case was diethylenitrosamine. The animals were divided into groups of six. The sera of the treated animals were used for the determination of transaminases, and the liver homogenates were used for the determination of antioxidant. The total phenol and flavonoid contents, and the antioxidant properties of the extracts, were evaluated in vitro. Results: The results of the in vitro antioxidant tests showed good antioxidant activity of the ethanolic extract, using the 2,2-diphenyl-1-picrylhydrazyl (DPPH) test (0.08 ± 0.0018 μg/mL) and 2,2′-azinobis (3-ethylbenzolin-6-sulphonate) (ABTS) (246.05 ± 1.55 mmol TE/g). The in vivo tests showed, through the evaluation of the antioxidant in vivo and the biochemical parameters, that the ethanolic extract with the highest phenolic content had a good hepatoprotective capacity. Conclusions: The antioxidant activity of Acanthopermum hispidum extracts would justify the observed hepatoprotective activity. These results confirmed that the plant is used in the treatment of liver diseases in traditional medicine in Burkina Faso. View Full-Text   Abstract
Background: Traditional Chinese medicine (TCM) may be understood as a system of sensations and findings designed to establish the functional vegetative state of the body. This state may be treated by several therapeutic methods such as acupuncture, Chinese pharmacotherapy, dietetics, Tuina, and Qigong. Nowadays, as a result of several evidence-based reported beneficial effects over specific pathological conditions, there is an increasing tendency to integrate some of these practices in Western medicine. The main goal of this study was to perform a bibliometric analysis of TCM scientific production between 1982 and 2016 indexed in PubMed, by analyzing several parameters including time and location distribution, publication quality, experimental design, and treatment methods. Methods: The methodology was based on the quantitative inventory of published scientific research indexed in PubMed medical subject headings (MeSH), sorted within the broad term “Traditional Chinese Medicine” and integrating the following criteria as limit filters: “Species: Humans”, “Article Type: Clinical Trial”. In addition, the articles’ triage was ruled by temporal limitations set between 1945 and 2016. Results: The overall analysis of data allowed observation of an average annual growth of approximately 33%, with a productive peak of 122 articles in 2007. The scientific production was distributed in 27 countries, led by China (76.1%), followed by the United States of America (3.0%) and South Korea (2.1%). A significant amount of references were published in Chinese journals: more than 50%; however, these journals had a low impact factor. The most cited treatments in the keywords section of the articles were phytotherapy (55%) and acupuncture (40%). Conclusion: The increasing demand for TCM seems to be due to factors such as lower side effects and greater efficacy in some patients not responding well to conventional therapy. As a result, a considerable amount of TCM science-based literature has been produced, supporting the rational integration of these practices in Western healthcare systems and research. Our results show that the quality of TCM research and inherent publications have been increasing over the last decades, with a higher incidence of studies published in well-ranked journals. View Full-Text   Abstract
Thirty years after the rise of the evidence-based medicine (EBM) movement, formal training in philosophy remains poorly represented among medical students and their educators. In this paper, I argue that EBM’s reception in this context has resulted in a privileging of empiricism over rationalism in clinical reasoning with unintended consequences for medical practice. After a limited review of the history of medical epistemology, I argue that a solution to this problem can be found in the method of the 2nd-century Roman physician Galen, who brought empiricism and rationalism together in a synthesis anticipating the scientific method. Next, I review several of the problems that have been identified as resulting from a staunch commitment to empiricism in medical practice. Finally, I conclude that greater epistemological awareness in the medical community would precipitate a Galenic shift toward a more epistemically balanced, scientific approach to clinical research. View Full-Text   No abstract available View Full-Text   Acanthospermum hispidum,diethylenitrosamine,hepatotoxicity,antioxidative enzyme,phenolics,antioxidant activities   acupuncture,traditional Chinese medicine,bibliometric analysis,PubMed   epistemology,evidence-based medicine,medical education,rationalism,empiricism,Galen    ", Medicines 
" Measurement of Volumetric Mass Transfer Coefficient in Bubble Columns   The Bubble Shape in Contaminated Bubbly Flows: Results for Different NaCl Concentrations in Purified Water   Glycine Oligomerization by Pulsed Discharge Plasma over Aqueous Solution under Atmospheric Pressure   Study of Bubble Size, Void Fraction, and Mass Transport in a Bubble Column under High Amplitude Vibration "," Abstract
The paper presents a brief overview of experiments on volumetric mass transfer coefficient in bubble columns. The available experimental data published are often incomparable due to the different type of gas distributor and different operating conditions used by various authors. Moreover, the value of the coefficient obtained experimentally is very sensitive to the particular method and to the physical models used in its evaluation. It follows that the Dynamic Pressure Method (DPM) is able to provide physically correct values not only in lab-scale contactors but also in pilot-scale reactors. However, the method was not correctly proven in bubble columns. In present experiments, DPM was employed in a laboratory-scale bubble column with a coalescent phase and tested in the pure heterogeneous flow regime. The method was successfully validated by the measurements under two different conditions relevant to the mass transfer. First, the ideal pressure step was compared with the non-ideal pressure step. Second, the pure oxygen absorption was compared with the simultaneous oxygen-and-nitrogen absorption. The obtained results proved that DPM is suitable for measuring the mass transport in bubble columns and to provide reliable data of volumetric mass transfer coefficient. View Full-Text   Abstract
The bubble shape influences the transfer of momentum and heat/mass between the bubble and the surrounding fluid as well as the flow field around the bubble. The shape is determined by the interaction of the fluid field in the bubble, the physics on the surface, and the surrounding flow field. It is well known that contaminations can disturb the surface physics so that the bubble shape can be influenced. Indeed, an influence of sodium chloride (NaCl) on the hydrodynamics of bubbly flows was shown for air/water systems in previous studies. The aim of the present work is to investigate if, and to what extent, the NaCl concentration affects the bubble shape in bubble columns. For this purpose, several experiments at the Helmholtz-Zentrum Dresden-Rossendorf and at the pilot-scale bubble column at the Politecnico di Milano are evaluated. The experiments were executed independently from each other and were evaluated with different methods. All experiments show that the bubble shape is not distinctly affected in the examined concentration range from 0 to 1 M NaCl, which is in contrast to a previous study on single bubbles. Therefore, the effect of NaCl on the hydrodynamics of bubbly flows is not induced by the bubble shape. View Full-Text   Abstract
Chemical reactions of amino acids induced by discharge plasma are important for understanding the mechanism of biological effects of discharge plasma in biomedical applications. In this study, we generated a nano-second pulsed discharge plasma under atmospheric pressure over an aqueous solution containing glycine. The reaction products after the pulsed discharge plasma treatments were analyzed by high-performance liquid chromatography and matrix-assisted laser desorption/ionization time-of-flight mass spectroscopy. The oligomerization reaction of glycine was induced in aqueous solution and produced glycine oligomers at the beginning of the discharge plasma. However, the glycine oligomers were decomposed into products with low molecular weight by excessive pulsed discharge plasma. According to comparative experiments, physical force of the plasma is believed to induce the glycine reaction. Moreover, the reactions depended on the pH, but not the conductivity, of the glycine solution. Glycine in aqueous solution was reacted by the discharge plasma only at neutral pH because the reaction proceeded only when glycine ions were in the zwitterionic state. Anions and cations of glycine reacted very little under the discharge plasma. View Full-Text   Abstract
Vertical vibration is known to cause bubble breakup, clustering and retardation in gas-liquid systems. In a bubble column, vibration increases the mass transfer ratio by increasing the residence time and phase interfacial area through introducing kinetic buoyancy force (Bjerknes effect) and bubble breakup. Previous studies have explored the effect of vibration frequency (f), but minimal effort has focused on the effect of amplitude (A) on mass transfer intensification. Thus, the current work experimentally examines bubble size, void fraction, and mass transfer in a bubble column under relatively high amplitude vibration (1.5 mm < A <9.5 mm) over a frequency range of 7.5–22.5 Hz. Results of the present work were compared with past studies. The maximum stable bubble size under vibration was scaled using Hinze theory for breakage. Results of this work indicate that vibration frequency exhibits local maxima in both mass transfer and void fraction. Moreover, an optimum amplitude that is independent of vibration frequency was found for mass transfer enhancements. Finally, this work suggests physics-based models to predict void fraction and mass transfer in a vibrating bubble column. View Full-Text "," bubble column,mass transfer,dynamic pressure method   bubble column,contaminations,surfactants,optical measurement,pilot-plant scale,nuclear safety engineering,sodium chloride   amino acids,pulsed discharge plasma,oligomerization,glycine,protein   bubble column,vibration,bubble size,void fraction,mass transfer "," Measurement of Volumetric Mass Transfer Coefficient in Bubble Columns   The Bubble Shape in Contaminated Bubbly Flows: Results for Different NaCl Concentrations in Purified Water   Glycine Oligomerization by Pulsed Discharge Plasma over Aqueous Solution under Atmospheric Pressure   Study of Bubble Size, Void Fraction, and Mass Transport in a Bubble Column under High Amplitude Vibration   Abstract
The paper presents a brief overview of experiments on volumetric mass transfer coefficient in bubble columns. The available experimental data published are often incomparable due to the different type of gas distributor and different operating conditions used by various authors. Moreover, the value of the coefficient obtained experimentally is very sensitive to the particular method and to the physical models used in its evaluation. It follows that the Dynamic Pressure Method (DPM) is able to provide physically correct values not only in lab-scale contactors but also in pilot-scale reactors. However, the method was not correctly proven in bubble columns. In present experiments, DPM was employed in a laboratory-scale bubble column with a coalescent phase and tested in the pure heterogeneous flow regime. The method was successfully validated by the measurements under two different conditions relevant to the mass transfer. First, the ideal pressure step was compared with the non-ideal pressure step. Second, the pure oxygen absorption was compared with the simultaneous oxygen-and-nitrogen absorption. The obtained results proved that DPM is suitable for measuring the mass transport in bubble columns and to provide reliable data of volumetric mass transfer coefficient. View Full-Text   Abstract
The bubble shape influences the transfer of momentum and heat/mass between the bubble and the surrounding fluid as well as the flow field around the bubble. The shape is determined by the interaction of the fluid field in the bubble, the physics on the surface, and the surrounding flow field. It is well known that contaminations can disturb the surface physics so that the bubble shape can be influenced. Indeed, an influence of sodium chloride (NaCl) on the hydrodynamics of bubbly flows was shown for air/water systems in previous studies. The aim of the present work is to investigate if, and to what extent, the NaCl concentration affects the bubble shape in bubble columns. For this purpose, several experiments at the Helmholtz-Zentrum Dresden-Rossendorf and at the pilot-scale bubble column at the Politecnico di Milano are evaluated. The experiments were executed independently from each other and were evaluated with different methods. All experiments show that the bubble shape is not distinctly affected in the examined concentration range from 0 to 1 M NaCl, which is in contrast to a previous study on single bubbles. Therefore, the effect of NaCl on the hydrodynamics of bubbly flows is not induced by the bubble shape. View Full-Text   Abstract
Chemical reactions of amino acids induced by discharge plasma are important for understanding the mechanism of biological effects of discharge plasma in biomedical applications. In this study, we generated a nano-second pulsed discharge plasma under atmospheric pressure over an aqueous solution containing glycine. The reaction products after the pulsed discharge plasma treatments were analyzed by high-performance liquid chromatography and matrix-assisted laser desorption/ionization time-of-flight mass spectroscopy. The oligomerization reaction of glycine was induced in aqueous solution and produced glycine oligomers at the beginning of the discharge plasma. However, the glycine oligomers were decomposed into products with low molecular weight by excessive pulsed discharge plasma. According to comparative experiments, physical force of the plasma is believed to induce the glycine reaction. Moreover, the reactions depended on the pH, but not the conductivity, of the glycine solution. Glycine in aqueous solution was reacted by the discharge plasma only at neutral pH because the reaction proceeded only when glycine ions were in the zwitterionic state. Anions and cations of glycine reacted very little under the discharge plasma. View Full-Text   Abstract
Vertical vibration is known to cause bubble breakup, clustering and retardation in gas-liquid systems. In a bubble column, vibration increases the mass transfer ratio by increasing the residence time and phase interfacial area through introducing kinetic buoyancy force (Bjerknes effect) and bubble breakup. Previous studies have explored the effect of vibration frequency (f), but minimal effort has focused on the effect of amplitude (A) on mass transfer intensification. Thus, the current work experimentally examines bubble size, void fraction, and mass transfer in a bubble column under relatively high amplitude vibration (1.5 mm < A <9.5 mm) over a frequency range of 7.5–22.5 Hz. Results of the present work were compared with past studies. The maximum stable bubble size under vibration was scaled using Hinze theory for breakage. Results of this work indicate that vibration frequency exhibits local maxima in both mass transfer and void fraction. Moreover, an optimum amplitude that is independent of vibration frequency was found for mass transfer enhancements. Finally, this work suggests physics-based models to predict void fraction and mass transfer in a vibrating bubble column. View Full-Text   bubble column,mass transfer,dynamic pressure method   bubble column,contaminations,surfactants,optical measurement,pilot-plant scale,nuclear safety engineering,sodium chloride   amino acids,pulsed discharge plasma,oligomerization,glycine,protein   bubble column,vibration,bubble size,void fraction,mass transfer ", ChemEngineering 
" Socioeconomic Impact Evaluation for Near Real-Time Flood Detection in the Lower Mekong River Basin   Impact of Land Use Change on Flow and Sediment Yields in the Khokana Outlet of the Bagmati River, Kathmandu, Nepal   Future Climate Change Impacts on Streamflows of Two Main West Africa River Basins: Senegal and Gambia   Estimation of Stream Health Using Flow-Based Indices "," Abstract
Flood events pose a severe threat to communities in the Lower Mekong River Basin. The combination of population growth, urbanization, and economic development exacerbate the impacts of these events. Flood damage assessments, critical for understanding the effects of flooding on the local population and informing decision-makers about future risks, are frequently used to quantify the economic losses due to storms. Remote sensing systems provide a valuable tool for monitoring flood conditions and assessing their severity more rapidly than traditional post-event evaluations. The frequency and severity of extreme flood events are projected to increase, further highlighting the need for improved flood monitoring and impact analysis. In this study we integrate a socioeconomic damage assessment model with a near real-time flood remote sensing and decision support tool (NASA’s Project Mekong). Direct damages to populations, infrastructure, and land cover are assessed using the 2011 Southeast Asian flood as a case study. Improved land use/land cover and flood depth assessments result in rapid loss estimates throughout the Mekong River Basin. Results suggest that rapid initial estimates of flood impacts can provide valuable information to governments, international agencies, and disaster responders in the wake of extreme flood events. View Full-Text   Abstract
Land use changes are a key factor for altering hydrological response, and understanding its impacts can help to develop a sustainable and pragmatic strategy in order to preserve a watershed. The objective of this research is to estimate the impact of land use changes on Bagmati river discharge and sediment yield at the Khokana gauging station of the Kathmandu valley outlet. This study analyzes the impact of land use changes from the year 2000 to 2010 using a semi-distributed hydrological, Soil Water Assessment Tool (SWAT) model. The Load Estimator (LOADEST) simulates sediment loads on limited available sediment data. Sensitivity analysis is performed using the ParaSole (Parameter Solution) method within SWAT Calibration and Uncertainty Procedure (SWAT-CUP), which shows that Linear parameters for calculating the maximum amount of sediment that can be re-entrained during channel sediment routing is a most sensitive parameter that affect the hydrological response of the watershed. Monthly discharge and sediment data from 1995 to 2002 are used for calibration and remaining monthly discharge and sediment data from 2003 to 2010 are used for validation. Four statistical parameters including the Coefficient of Determination (R2), Nash–Sutcliffe Efficiency (NSE), RMSE-observations’ standard deviation ratio (RSR), and Percentage Bias (PBIAS) are estimated in order to evaluate the model performance. The results show a very good agreement between monthly measured and simulated discharge data as indicated by R2 = 0.88, NSE = 0.90, RSR = 0.34, and PBIAS = 0.03. The model shows nearly the same performance also with sediment data. The land use change data shows about a 6% increase in built-up areas from the years 2000 to 2010, whereas the remaining areas such as Forest, Shrub, Grass, Agriculture, Open Field, and Rivers/Lakes are decreased. The surface runoff contribution to stream flow and sediment yields are increased by 27% and 5% respectively. In the contrary, lateral flow contribution to stream flow and groundwater contribution to stream flow are decreased by 25% and 21%, respectively. View Full-Text   Abstract
This research investigated the effect of climate change on the two main river basins of Senegal in West Africa: the Senegal and Gambia River Basins. We used downscaled projected future rainfall and potential evapotranspiration based on projected temperature from six General Circulation Models (CanESM2, CNRM, CSIRO, HadGEM2-CC, HadGEM2-ES, and MIROC5) and two scenarios (RCP4.5 and RCP8.5) to force the GR4J model. The GR4J model was calibrated and validated using observed daily rainfall, potential evapotranspiration from observed daily temperature, and streamflow data. For the cross-validation, two periods for each river basin were considered: 1961–1982 and 1983–2004 for the Senegal River Basin at Bafing Makana, and 1969–1985 and 1986–2000 for the Gambia River Basin at Mako. Model efficiency is evaluated using a multi-criteria function (Fagg) which aggregates Nash and Sutcliffe criteria, cumulative volume error, and mean volume error. Alternating periods of simulation for calibration and validation were used. This process allows us to choose the parameters that best reflect the rainfall-runoff relationship. Once the model was calibrated and validated, we simulated streamflow at Bafing Makana and Mako stations in the near future at a daily scale. The characteristic flow rates were calculated to evaluate their possible evolution under the projected climate scenarios at the 2050 horizon. For the near future (2050 horizon), compared to the 1971–2000 reference period, results showed that for both river basins, multi-model ensemble predicted a decrease of annual streamflow from 8% (Senegal River Basin) to 22% (Gambia River Basin) under the RCP4.5 scenario. Under the RCP8.5 scenario, the decrease is more pronounced: 16% (Senegal River Basin) and 26% (Gambia River Basin). The Gambia River Basin will be more affected by the climate change. View Full-Text   Abstract
Existing methods to estimate stream health are often location-specific, and do not address all of the components of stream health. In addition, there are very few guidelines to estimate the health of a stream, although the literature and useful tools such as Indicators of Hydrologic Alteration (IHA) are available. This paper describes an approach developed for estimating stream health. The method involves the: (1) collection of flow data; (2) identification of hydrologic change; (3) estimation of some hydrologic indicators for pre-alteration and post-alteration periods; and (4) the use of those hydrologic indicators with the scoring framework of the Dundee Hydrologic Regime Assessment Method (DHRAM). The approach estimates the stream health in aggregate including all of the components, such as riparian vegetation, aquatic species, and benthic organisms. Using the approach, stream health can be estimated at two different levels: (1) the existence or absence of a stream health problem based on the concept of eco-deficit and eco-surplus using flow duration curves; and (2) the estimation of overall stream health using the IHA–DHRAM method. The procedure is demonstrated with a case example of the White Rock Creek watershed in Texas in the United States (US). The approach has great potential to estimate stream health and prescribe flow-based goals for the restoration of impaired streams. View Full-Text "," near real-time,Mekong Basin,hydro-economic,socioeconomic,damage assessment,hydroinformatics   GIS,land use change,SWAT,Bagmati watershed,Khokana,calibration,validation   Senegal River Basin,Gambia River Basin,climate change,GR4J,rainfall-runoff modeling,streamflow   White Rock Creek,eco-deficit,eco-surplus,IHA,DHRAM,hydrologic alteration "," Socioeconomic Impact Evaluation for Near Real-Time Flood Detection in the Lower Mekong River Basin   Impact of Land Use Change on Flow and Sediment Yields in the Khokana Outlet of the Bagmati River, Kathmandu, Nepal   Future Climate Change Impacts on Streamflows of Two Main West Africa River Basins: Senegal and Gambia   Estimation of Stream Health Using Flow-Based Indices   Abstract
Flood events pose a severe threat to communities in the Lower Mekong River Basin. The combination of population growth, urbanization, and economic development exacerbate the impacts of these events. Flood damage assessments, critical for understanding the effects of flooding on the local population and informing decision-makers about future risks, are frequently used to quantify the economic losses due to storms. Remote sensing systems provide a valuable tool for monitoring flood conditions and assessing their severity more rapidly than traditional post-event evaluations. The frequency and severity of extreme flood events are projected to increase, further highlighting the need for improved flood monitoring and impact analysis. In this study we integrate a socioeconomic damage assessment model with a near real-time flood remote sensing and decision support tool (NASA’s Project Mekong). Direct damages to populations, infrastructure, and land cover are assessed using the 2011 Southeast Asian flood as a case study. Improved land use/land cover and flood depth assessments result in rapid loss estimates throughout the Mekong River Basin. Results suggest that rapid initial estimates of flood impacts can provide valuable information to governments, international agencies, and disaster responders in the wake of extreme flood events. View Full-Text   Abstract
Land use changes are a key factor for altering hydrological response, and understanding its impacts can help to develop a sustainable and pragmatic strategy in order to preserve a watershed. The objective of this research is to estimate the impact of land use changes on Bagmati river discharge and sediment yield at the Khokana gauging station of the Kathmandu valley outlet. This study analyzes the impact of land use changes from the year 2000 to 2010 using a semi-distributed hydrological, Soil Water Assessment Tool (SWAT) model. The Load Estimator (LOADEST) simulates sediment loads on limited available sediment data. Sensitivity analysis is performed using the ParaSole (Parameter Solution) method within SWAT Calibration and Uncertainty Procedure (SWAT-CUP), which shows that Linear parameters for calculating the maximum amount of sediment that can be re-entrained during channel sediment routing is a most sensitive parameter that affect the hydrological response of the watershed. Monthly discharge and sediment data from 1995 to 2002 are used for calibration and remaining monthly discharge and sediment data from 2003 to 2010 are used for validation. Four statistical parameters including the Coefficient of Determination (R2), Nash–Sutcliffe Efficiency (NSE), RMSE-observations’ standard deviation ratio (RSR), and Percentage Bias (PBIAS) are estimated in order to evaluate the model performance. The results show a very good agreement between monthly measured and simulated discharge data as indicated by R2 = 0.88, NSE = 0.90, RSR = 0.34, and PBIAS = 0.03. The model shows nearly the same performance also with sediment data. The land use change data shows about a 6% increase in built-up areas from the years 2000 to 2010, whereas the remaining areas such as Forest, Shrub, Grass, Agriculture, Open Field, and Rivers/Lakes are decreased. The surface runoff contribution to stream flow and sediment yields are increased by 27% and 5% respectively. In the contrary, lateral flow contribution to stream flow and groundwater contribution to stream flow are decreased by 25% and 21%, respectively. View Full-Text   Abstract
This research investigated the effect of climate change on the two main river basins of Senegal in West Africa: the Senegal and Gambia River Basins. We used downscaled projected future rainfall and potential evapotranspiration based on projected temperature from six General Circulation Models (CanESM2, CNRM, CSIRO, HadGEM2-CC, HadGEM2-ES, and MIROC5) and two scenarios (RCP4.5 and RCP8.5) to force the GR4J model. The GR4J model was calibrated and validated using observed daily rainfall, potential evapotranspiration from observed daily temperature, and streamflow data. For the cross-validation, two periods for each river basin were considered: 1961–1982 and 1983–2004 for the Senegal River Basin at Bafing Makana, and 1969–1985 and 1986–2000 for the Gambia River Basin at Mako. Model efficiency is evaluated using a multi-criteria function (Fagg) which aggregates Nash and Sutcliffe criteria, cumulative volume error, and mean volume error. Alternating periods of simulation for calibration and validation were used. This process allows us to choose the parameters that best reflect the rainfall-runoff relationship. Once the model was calibrated and validated, we simulated streamflow at Bafing Makana and Mako stations in the near future at a daily scale. The characteristic flow rates were calculated to evaluate their possible evolution under the projected climate scenarios at the 2050 horizon. For the near future (2050 horizon), compared to the 1971–2000 reference period, results showed that for both river basins, multi-model ensemble predicted a decrease of annual streamflow from 8% (Senegal River Basin) to 22% (Gambia River Basin) under the RCP4.5 scenario. Under the RCP8.5 scenario, the decrease is more pronounced: 16% (Senegal River Basin) and 26% (Gambia River Basin). The Gambia River Basin will be more affected by the climate change. View Full-Text   Abstract
Existing methods to estimate stream health are often location-specific, and do not address all of the components of stream health. In addition, there are very few guidelines to estimate the health of a stream, although the literature and useful tools such as Indicators of Hydrologic Alteration (IHA) are available. This paper describes an approach developed for estimating stream health. The method involves the: (1) collection of flow data; (2) identification of hydrologic change; (3) estimation of some hydrologic indicators for pre-alteration and post-alteration periods; and (4) the use of those hydrologic indicators with the scoring framework of the Dundee Hydrologic Regime Assessment Method (DHRAM). The approach estimates the stream health in aggregate including all of the components, such as riparian vegetation, aquatic species, and benthic organisms. Using the approach, stream health can be estimated at two different levels: (1) the existence or absence of a stream health problem based on the concept of eco-deficit and eco-surplus using flow duration curves; and (2) the estimation of overall stream health using the IHA–DHRAM method. The procedure is demonstrated with a case example of the White Rock Creek watershed in Texas in the United States (US). The approach has great potential to estimate stream health and prescribe flow-based goals for the restoration of impaired streams. View Full-Text   near real-time,Mekong Basin,hydro-economic,socioeconomic,damage assessment,hydroinformatics   GIS,land use change,SWAT,Bagmati watershed,Khokana,calibration,validation   Senegal River Basin,Gambia River Basin,climate change,GR4J,rainfall-runoff modeling,streamflow   White Rock Creek,eco-deficit,eco-surplus,IHA,DHRAM,hydrologic alteration ", Hydrology 
 Cardiac Arrhythmia Classification by Multi-Layer Perceptron and Convolution Neural Networks   Kinetic Modeling of Corn Fermentation with S. cerevisiae Using a Variable Temperature Strategy   Efficient Computational Design of a Scaffold for Cartilage Cell Regeneration ," Abstract
The electrocardiogram (ECG) plays an imperative role in the medical field, as it records heart signal over time and is used to discover numerous cardiovascular diseases. If a documented ECG signal has a certain irregularity in its predefined features, this is called arrhythmia, the types of which include tachycardia, bradycardia, supraventricular arrhythmias, and ventricular, etc. This has encouraged us to do research that consists of distinguishing between several arrhythmias by using deep neural network algorithms such as multi-layer perceptron (MLP) and convolution neural network (CNN). The TensorFlow library that was established by Google for deep learning and machine learning is used in python to acquire the algorithms proposed here. The ECG databases accessible at PhysioBank.com and kaggle.com were used for training, testing, and validation of the MLP and CNN algorithms. The proposed algorithm consists of four hidden layers with weights, biases in MLP, and four-layer convolution neural networks which map ECG samples to the different classes of arrhythmia. The accuracy of the algorithm surpasses the performance of the current algorithms that have been developed by other cardiologists in both sensitivity and precision. View Full-Text   Abstract
While fermentation is usually done at a fixed temperature, in this study, the effect of having a controlled variable temperature was analyzed. A nonlinear system was used to model batch ethanol fermentation, using corn as substrate and the yeast Saccharomyces cerevisiae, at five different fixed and controlled variable temperatures. The lower temperatures presented higher ethanol yields but took a longer time to reach equilibrium. Higher temperatures had higher initial growth rates, but the decay of yeast cells was faster compared to the lower temperatures. However, in a controlled variable temperature model, the temperature decreased with time with the initial value of 40
∘
C. When analyzing a time window of 60 h, the ethanol production increased 20% compared to the batch with the highest temperature; however, the yield was still 12% lower compared to the 20
∘
C batch. When the 24 h’ simulation was analyzed, the controlled model had a higher ethanol concentration compared to both fixed temperature batches. View Full-Text   Abstract
Due to the sensitivity of mammalian cell cultures, understanding the influence of operating conditions during a tissue generation procedure is crucial. In this regard, a detailed study of scaffold based cell culture under a perfusion flow is presented with the aid of mathematical modelling and computational fluid dynamics (CFD). With respect to the complexity of the case study, this work focuses solely on the effect of nutrient and metabolite concentrations, and the possible influence of fluid-induced shear stress on a targeted cell (cartilage) culture. The simulation set up gives the possibility of predicting the cell culture behavior under various operating conditions and scaffold designs. Thereby, the exploitation of the predictive simulation into a newly developed stochastic routine provides the opportunity of exploring improved scaffold geometry designs. This approach was applied on a common type of fibrous structure in order to increase the process efficiencies compared with the regular used formats. The suggested topology supplies a larger effective surface for cell attachment compared to the reference design while the level of shear stress is kept at the positive range of effect. Moreover, significant improvement of mass transfer is predicted for the suggested topology. View Full-Text "," electrocardiogram (ECG),arrhythmia,deep neural network,machine learning,deep learning,PhysioBank,kaggle,python,TensorFlow   fermentation,Saccharomyces cerevisiae,kinetic modeling   tissue engineering,CFD simulation,scaffold geometry optimization,micro-bioreactor operating conditions "," Cardiac Arrhythmia Classification by Multi-Layer Perceptron and Convolution Neural Networks   Kinetic Modeling of Corn Fermentation with S. cerevisiae Using a Variable Temperature Strategy   Efficient Computational Design of a Scaffold for Cartilage Cell Regeneration   Abstract
The electrocardiogram (ECG) plays an imperative role in the medical field, as it records heart signal over time and is used to discover numerous cardiovascular diseases. If a documented ECG signal has a certain irregularity in its predefined features, this is called arrhythmia, the types of which include tachycardia, bradycardia, supraventricular arrhythmias, and ventricular, etc. This has encouraged us to do research that consists of distinguishing between several arrhythmias by using deep neural network algorithms such as multi-layer perceptron (MLP) and convolution neural network (CNN). The TensorFlow library that was established by Google for deep learning and machine learning is used in python to acquire the algorithms proposed here. The ECG databases accessible at PhysioBank.com and kaggle.com were used for training, testing, and validation of the MLP and CNN algorithms. The proposed algorithm consists of four hidden layers with weights, biases in MLP, and four-layer convolution neural networks which map ECG samples to the different classes of arrhythmia. The accuracy of the algorithm surpasses the performance of the current algorithms that have been developed by other cardiologists in both sensitivity and precision. View Full-Text   Abstract
While fermentation is usually done at a fixed temperature, in this study, the effect of having a controlled variable temperature was analyzed. A nonlinear system was used to model batch ethanol fermentation, using corn as substrate and the yeast Saccharomyces cerevisiae, at five different fixed and controlled variable temperatures. The lower temperatures presented higher ethanol yields but took a longer time to reach equilibrium. Higher temperatures had higher initial growth rates, but the decay of yeast cells was faster compared to the lower temperatures. However, in a controlled variable temperature model, the temperature decreased with time with the initial value of 40
∘
C. When analyzing a time window of 60 h, the ethanol production increased 20% compared to the batch with the highest temperature; however, the yield was still 12% lower compared to the 20
∘
C batch. When the 24 h’ simulation was analyzed, the controlled model had a higher ethanol concentration compared to both fixed temperature batches. View Full-Text   Abstract
Due to the sensitivity of mammalian cell cultures, understanding the influence of operating conditions during a tissue generation procedure is crucial. In this regard, a detailed study of scaffold based cell culture under a perfusion flow is presented with the aid of mathematical modelling and computational fluid dynamics (CFD). With respect to the complexity of the case study, this work focuses solely on the effect of nutrient and metabolite concentrations, and the possible influence of fluid-induced shear stress on a targeted cell (cartilage) culture. The simulation set up gives the possibility of predicting the cell culture behavior under various operating conditions and scaffold designs. Thereby, the exploitation of the predictive simulation into a newly developed stochastic routine provides the opportunity of exploring improved scaffold geometry designs. This approach was applied on a common type of fibrous structure in order to increase the process efficiencies compared with the regular used formats. The suggested topology supplies a larger effective surface for cell attachment compared to the reference design while the level of shear stress is kept at the positive range of effect. Moreover, significant improvement of mass transfer is predicted for the suggested topology. View Full-Text   electrocardiogram (ECG),arrhythmia,deep neural network,machine learning,deep learning,PhysioBank,kaggle,python,TensorFlow   fermentation,Saccharomyces cerevisiae,kinetic modeling   tissue engineering,CFD simulation,scaffold geometry optimization,micro-bioreactor operating conditions ", Bioengineering 
 Nutraceutic Characteristics of the Extracts and Juice of Chayote (Sechium edule (Jacq.) Sw.) Fruits   Microbial and Chemical Diversity of Traditional Non-Cereal Based Alcoholic Beverages of Sub-Saharan Africa   Phenolic Compounds in Fruit Beverages   Analysis of Mycotoxins in Peruvian Evaporated Cow Milk ," Abstract
Fruits of chayote [Sechium edule (Jacq.) Swartz] are a non-traditional vegetable widely consumed in Latin America, with the state of Veracruz, México being the world’s main producer, but little is known about the nutraceutical potential. This study aimed to determine the chemical compositions and antioxidant activities from the juice fruits from two commercial varieties of chayote cultivated in Mexico, as well as a proposal for the elaboration of chayote juices with stevia leaves and pineapple juice. The physicochemical properties of juice from virens levis (VL) and nigrum spinosum (NS) varieties were determined using standard methods. The juice of the two varieties differ significantly regarding the concentrations of total soluble solids and total sugars, but not vitamin C. The total concentration of phenolics in NS extracts was slightly higher than in VL (1005 and 856 mg 100 g−1 dry-weight, respectively), but the total flavonoid contents were similar (27 and 26 mg 100 g−1 dry-weight, respectively). Cucurbitacin D was predominant in both varieties. The radical scavenging capacities of VL and NS extracts varied slightly (IC50 = 0.45 to 0.65 mg mL−1), while the antioxidant activities were similar (~80%). The NS variety is particularly promising regarding nutraceutical application. The chayote juice combined with stevia and pineapple maintained the original nutraceutical characteristics of the fruit, but enhanced the organoleptic characteristics like density and sugar/acidity balance. View Full-Text   Abstract
Fermentation remains an important food preparation technique of health, cultural and economic importance throughout the world. In Sub-Saharan Africa, traditional alcoholic fermentation of cereal and non-cereal based substrates into alcoholic beverages is deeply rooted in the society. Although a multitude of traditional alcoholic beverages from cereal substrates are well researched and documented, their non-cereal based counterparts, mostly produced from indigenous, inexpensive substrates, remain less well studied. In addition, reports of health problems associated with non-cereal based alcoholic beverages produced from spontaneous fermentation are a major cause of concern. This review aims to highlight the microbiological and chemical profiles of these non-cereal based alcoholic beverages with a focus on the Sub-Saharan region. Here, we underscore the importance of the microbial repertoire and the substrates thereof in attaining aromatic complexity and a characteristic taste in these beverages. These aspects are an important starting point towards the potential commercialization of these complex aromatic non-cereal based traditional beverages. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
In this current special issue, different aspects related to phenolic compounds in fruit beverages
are presented.[...] View Full-Text   Abstract
Mycotoxins—toxic secondary fungi metabolites—reach humans through food, producing several effects on their health and economic losses. Mycotoxin co-occurrence is common in food due to the co-presence of different fungi species, each of which may produce different toxins. A survey regarding the presence of 22 mycotoxins (aflatoxins M1, B1, B2, G1, G2; ochratoxins A and B; fumonisins B1, B2 and B3; HT-2 and T-2 toxins; nivalenol; deoxynivalenol; deepoxy-deoxynivalenol; 3 and 15 acetyl-deoxynivalenol; diacetoxyscirpenol; fusarenon X; neosolaniol; sterigmatocystin; and zearalenone) in 30 Peruvian evaporated cow milk samples is presented for the first time. Analysis was carried out by liquid chromatography coupled to tandem mass spectrometry, which was based on two previously validated methods for quantification of these toxic compounds in liquid cow milk, and further validated for the new matrix. The only detected mycotoxin was ochratoxin A, which was found in four samples, although at levels below its limit of quantification (0.2 ng/mL). This initial study indicates that the presence of mycotoxins in evaporated milk is low in Peru. However, we recommend the analysis of more samples and more milk types obtained from urban and rural areas, in order to obtain more data that will allow further risk assessments to be carried out. View Full-Text "," fruits,juice,flavonoids,cucurbitacins   non-cereal,fruit,beverage,fermentation,microbes,metabolites      mycotoxins,ochratoxin A,evaporated milk,Peru,LC–MS/MS,validation,food analysis,beverages "," Nutraceutic Characteristics of the Extracts and Juice of Chayote (Sechium edule (Jacq.) Sw.) Fruits   Microbial and Chemical Diversity of Traditional Non-Cereal Based Alcoholic Beverages of Sub-Saharan Africa   Phenolic Compounds in Fruit Beverages   Analysis of Mycotoxins in Peruvian Evaporated Cow Milk   Abstract
Fruits of chayote [Sechium edule (Jacq.) Swartz] are a non-traditional vegetable widely consumed in Latin America, with the state of Veracruz, México being the world’s main producer, but little is known about the nutraceutical potential. This study aimed to determine the chemical compositions and antioxidant activities from the juice fruits from two commercial varieties of chayote cultivated in Mexico, as well as a proposal for the elaboration of chayote juices with stevia leaves and pineapple juice. The physicochemical properties of juice from virens levis (VL) and nigrum spinosum (NS) varieties were determined using standard methods. The juice of the two varieties differ significantly regarding the concentrations of total soluble solids and total sugars, but not vitamin C. The total concentration of phenolics in NS extracts was slightly higher than in VL (1005 and 856 mg 100 g−1 dry-weight, respectively), but the total flavonoid contents were similar (27 and 26 mg 100 g−1 dry-weight, respectively). Cucurbitacin D was predominant in both varieties. The radical scavenging capacities of VL and NS extracts varied slightly (IC50 = 0.45 to 0.65 mg mL−1), while the antioxidant activities were similar (~80%). The NS variety is particularly promising regarding nutraceutical application. The chayote juice combined with stevia and pineapple maintained the original nutraceutical characteristics of the fruit, but enhanced the organoleptic characteristics like density and sugar/acidity balance. View Full-Text   Abstract
Fermentation remains an important food preparation technique of health, cultural and economic importance throughout the world. In Sub-Saharan Africa, traditional alcoholic fermentation of cereal and non-cereal based substrates into alcoholic beverages is deeply rooted in the society. Although a multitude of traditional alcoholic beverages from cereal substrates are well researched and documented, their non-cereal based counterparts, mostly produced from indigenous, inexpensive substrates, remain less well studied. In addition, reports of health problems associated with non-cereal based alcoholic beverages produced from spontaneous fermentation are a major cause of concern. This review aims to highlight the microbiological and chemical profiles of these non-cereal based alcoholic beverages with a focus on the Sub-Saharan region. Here, we underscore the importance of the microbial repertoire and the substrates thereof in attaining aromatic complexity and a characteristic taste in these beverages. These aspects are an important starting point towards the potential commercialization of these complex aromatic non-cereal based traditional beverages. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
In this current special issue, different aspects related to phenolic compounds in fruit beverages
are presented.[...] View Full-Text   Abstract
Mycotoxins—toxic secondary fungi metabolites—reach humans through food, producing several effects on their health and economic losses. Mycotoxin co-occurrence is common in food due to the co-presence of different fungi species, each of which may produce different toxins. A survey regarding the presence of 22 mycotoxins (aflatoxins M1, B1, B2, G1, G2; ochratoxins A and B; fumonisins B1, B2 and B3; HT-2 and T-2 toxins; nivalenol; deoxynivalenol; deepoxy-deoxynivalenol; 3 and 15 acetyl-deoxynivalenol; diacetoxyscirpenol; fusarenon X; neosolaniol; sterigmatocystin; and zearalenone) in 30 Peruvian evaporated cow milk samples is presented for the first time. Analysis was carried out by liquid chromatography coupled to tandem mass spectrometry, which was based on two previously validated methods for quantification of these toxic compounds in liquid cow milk, and further validated for the new matrix. The only detected mycotoxin was ochratoxin A, which was found in four samples, although at levels below its limit of quantification (0.2 ng/mL). This initial study indicates that the presence of mycotoxins in evaporated milk is low in Peru. However, we recommend the analysis of more samples and more milk types obtained from urban and rural areas, in order to obtain more data that will allow further risk assessments to be carried out. View Full-Text   fruits,juice,flavonoids,cucurbitacins   non-cereal,fruit,beverage,fermentation,microbes,metabolites      mycotoxins,ochratoxin A,evaporated milk,Peru,LC–MS/MS,validation,food analysis,beverages ", Beverages 
 Datasets for Aspect-Based Sentiment Analysis in Bangla and Its Baseline Evaluation   RetroTransformDB: A Dataset of Generic Transforms for Retrosynthetic Analysis   Sigfox and LoRaWAN Datasets for Fingerprint Localization in Large Urban and Rural Areas   Comparison between Simulation and Analytical Methods in Reliability Data Analysis: A Case Study on Face Drilling Rigs ," Abstract
With the extensive growth of user interactions through prominent advances of the Web, sentiment analysis has obtained more focus from an academic and a commercial point of view. Recently, sentiment analysis in the Bangla language is progressively being considered as an important task, for which previous approaches have attempted to detect the overall polarity of a Bangla document. To the best of our knowledge, there is no research on the aspect-based sentiment analysis (ABSA) of Bangla text. This can be described as being due to the lack of available datasets for ABSA. In this paper, we provide two publicly available datasets to perform the ABSA task in Bangla. One of the datasets consists of human-annotated user comments on cricket, and the other dataset consists of customer reviews of restaurants. We also describe a baseline approach for the subtask of aspect category extraction to evaluate our datasets. View Full-Text   Abstract
Presently, software tools for retrosynthetic analysis are widely used by organic, medicinal, and computational chemists. Rule-based systems extensively use collections of retro-reactions (transforms). While there are many public datasets with reactions in synthetic direction (usually non-generic reactions), there are no publicly-available databases with generic reactions in computer-readable format which can be used for the purposes of retrosynthetic analysis. Here we present RetroTransformDB—a dataset of transforms, compiled and coded in SMIRKS line notation by us. The collection is comprised of more than 100 records, with each one including the reaction name, SMIRKS linear notation, the functional group to be obtained, and the transform type classification. All SMIRKS transforms were tested syntactically, semantically, and from a chemical point of view in different software platforms. The overall dataset design and the retrosynthetic fitness were analyzed and curated by organic chemistry experts. The RetroTransformDB dataset may be used by open-source and commercial software packages, as well as chemoinformatics tools. View Full-Text   Abstract
Because of the increasing relevance of the Internet of Things and location-based services, researchers are evaluating wireless positioning techniques, such as fingerprinting, on Low Power Wide Area Network (LPWAN) communication. In order to evaluate fingerprinting in large outdoor environments, extensive, time-consuming measurement campaigns need to be conducted to create useful datasets. This paper presents three LPWAN datasets which are collected in large-scale urban and rural areas. The goal is to provide the research community with a tool to evaluate fingerprinting algorithms in large outdoor environments. During a period of three months, numerous mobile devices periodically obtained location data via a GPS receiver which was transmitted via a Sigfox or LoRaWAN message. Together with network information, this location data is stored in the appropriate LPWAN dataset. The first results of our basic fingerprinting implementation, which is also clarified in this paper, indicate a mean location estimation error of 214.58 m for the rural Sigfox dataset, 688.97 m for the urban Sigfox dataset and 398.40 m for the urban LoRaWAN dataset. In the future, we will enlarge our current datasets and use them to evaluate and optimize our fingerprinting methods. Also, we intend to collect additional datasets for Sigfox, LoRaWAN and NB-IoT. View Full-Text   Abstract
Collecting the failure data and reliability analysis in an underground mining operation is challenging due to the harsh environment and high level of production pressure. Therefore, achieving an accurate, fast, and applicable analysis in a fleet of underground equipment is usually difficult and time consuming. This paper aims to discuss the main reliability analysis challenges in mining machinery by comparing three main approaches: two analytical methods (white-box and black-box modeling), and a simulation approach. For this purpose, the maintenance data from a fleet of face drilling rigs in a Swedish underground metal mine were extracted by the MAXIMO system over a period of two years and were applied for analysis. The investigations reveal that the performance of these approaches in ranking and the reliability of the studies of the machines is different. However, all mentioned methods provide similar outputs but, in general, the simulation estimates the reliability of the studied machines at a higher level. The simulation and white-box method sometimes provide exactly the same results, which are caused by their similar structure of analysis. On average, 9% of the data are missed in the white-box analysis due to a lack of sufficient data in some of the subsystems of the studies’ rigs. View Full-Text "," ABSA dataset,Bangla ABSA,aspect extraction from Bangla   transforms,retrosynthesis,SMIRKS   IoT,LPWAN,Sigfox,LoRaWAN,localization,fingerprinting   modeling,simulation,black-box,white-box,Pareto analysis "," Datasets for Aspect-Based Sentiment Analysis in Bangla and Its Baseline Evaluation   RetroTransformDB: A Dataset of Generic Transforms for Retrosynthetic Analysis   Sigfox and LoRaWAN Datasets for Fingerprint Localization in Large Urban and Rural Areas   Comparison between Simulation and Analytical Methods in Reliability Data Analysis: A Case Study on Face Drilling Rigs   Abstract
With the extensive growth of user interactions through prominent advances of the Web, sentiment analysis has obtained more focus from an academic and a commercial point of view. Recently, sentiment analysis in the Bangla language is progressively being considered as an important task, for which previous approaches have attempted to detect the overall polarity of a Bangla document. To the best of our knowledge, there is no research on the aspect-based sentiment analysis (ABSA) of Bangla text. This can be described as being due to the lack of available datasets for ABSA. In this paper, we provide two publicly available datasets to perform the ABSA task in Bangla. One of the datasets consists of human-annotated user comments on cricket, and the other dataset consists of customer reviews of restaurants. We also describe a baseline approach for the subtask of aspect category extraction to evaluate our datasets. View Full-Text   Abstract
Presently, software tools for retrosynthetic analysis are widely used by organic, medicinal, and computational chemists. Rule-based systems extensively use collections of retro-reactions (transforms). While there are many public datasets with reactions in synthetic direction (usually non-generic reactions), there are no publicly-available databases with generic reactions in computer-readable format which can be used for the purposes of retrosynthetic analysis. Here we present RetroTransformDB—a dataset of transforms, compiled and coded in SMIRKS line notation by us. The collection is comprised of more than 100 records, with each one including the reaction name, SMIRKS linear notation, the functional group to be obtained, and the transform type classification. All SMIRKS transforms were tested syntactically, semantically, and from a chemical point of view in different software platforms. The overall dataset design and the retrosynthetic fitness were analyzed and curated by organic chemistry experts. The RetroTransformDB dataset may be used by open-source and commercial software packages, as well as chemoinformatics tools. View Full-Text   Abstract
Because of the increasing relevance of the Internet of Things and location-based services, researchers are evaluating wireless positioning techniques, such as fingerprinting, on Low Power Wide Area Network (LPWAN) communication. In order to evaluate fingerprinting in large outdoor environments, extensive, time-consuming measurement campaigns need to be conducted to create useful datasets. This paper presents three LPWAN datasets which are collected in large-scale urban and rural areas. The goal is to provide the research community with a tool to evaluate fingerprinting algorithms in large outdoor environments. During a period of three months, numerous mobile devices periodically obtained location data via a GPS receiver which was transmitted via a Sigfox or LoRaWAN message. Together with network information, this location data is stored in the appropriate LPWAN dataset. The first results of our basic fingerprinting implementation, which is also clarified in this paper, indicate a mean location estimation error of 214.58 m for the rural Sigfox dataset, 688.97 m for the urban Sigfox dataset and 398.40 m for the urban LoRaWAN dataset. In the future, we will enlarge our current datasets and use them to evaluate and optimize our fingerprinting methods. Also, we intend to collect additional datasets for Sigfox, LoRaWAN and NB-IoT. View Full-Text   Abstract
Collecting the failure data and reliability analysis in an underground mining operation is challenging due to the harsh environment and high level of production pressure. Therefore, achieving an accurate, fast, and applicable analysis in a fleet of underground equipment is usually difficult and time consuming. This paper aims to discuss the main reliability analysis challenges in mining machinery by comparing three main approaches: two analytical methods (white-box and black-box modeling), and a simulation approach. For this purpose, the maintenance data from a fleet of face drilling rigs in a Swedish underground metal mine were extracted by the MAXIMO system over a period of two years and were applied for analysis. The investigations reveal that the performance of these approaches in ranking and the reliability of the studies of the machines is different. However, all mentioned methods provide similar outputs but, in general, the simulation estimates the reliability of the studied machines at a higher level. The simulation and white-box method sometimes provide exactly the same results, which are caused by their similar structure of analysis. On average, 9% of the data are missed in the white-box analysis due to a lack of sufficient data in some of the subsystems of the studies’ rigs. View Full-Text   ABSA dataset,Bangla ABSA,aspect extraction from Bangla   transforms,retrosynthesis,SMIRKS   IoT,LPWAN,Sigfox,LoRaWAN,localization,fingerprinting   modeling,simulation,black-box,white-box,Pareto analysis ", Data 
 Field Studies Evaluating Bait Acceptance and Handling by Free-Roaming Dogs in Thailand   Clinicopathological Diversity of Canine Mammary Gland Tumors in Sri Lanka: A One-Year Survey on Cases Presented to Two Veterinary Practices ," Abstract
(1) Background: As part of the ongoing endeavor to eliminate dog-mediated human rabies in Thailand, renewed interest has been shown in oral vaccination of dogs as a supplementary tool to increase vaccination coverage of the dog population. (2) Methods: Three different bait types were tested using a hand-out model on the campus of the Kasetsart University and the surrounding temples in Thailand during September 2017, consisting of two industrial manufactured baits (fish meal and egg-flavored) and one bait made from local material (boiled pig intestine placed in collagen casing). A PVC-capsule containing dyed water was inserted in the bait. (3) Results: The fishmeal bait was significantly less often accepted and consumed (50.29%) than the other two baits (intestine bait—79.19%; egg bait—78.77%). Delivery and release of the dyed water in the oral cavity was highest in the egg-flavored bait (84.50%), followed by the intestine bait (76.61%) and fishmeal (54.85%) baits. Bait acceptance was influenced by sex, age, and body size of the dog. Also, the origin of the dogs had a significant effect: temple dogs accepted the baits more often than street dogs. (4) Conclusion: A significant portion of the free-roaming dog population in this study can be vaccinated by offering vaccine baits. View Full-Text   Abstract
Mammary gland tumors (MGTs) are one of the most common neoplasms among dogs in Sri Lanka. However, the clinicopathological diversity of MGTs in Sri Lanka is largely unknown, impeding accurate diagnosis and effective treatment of the disease. The present study investigated the clinicopathological features of MGTs in 74 dogs presented to two veterinary practices in Sri Lanka treated surgically, over a one-year period. Information regarding the patient signalment, clinical presentation, and reproductive history were collected, and each neoplasm was examined histologically. Forty-one (54.4%) dogs were primarily presented for mammary neoplasia, while a MGT was an incidental finding in 33 (44.6%) dogs. The majority of tumors were histologically malignant (n = 65, 87.8%), and 18 malignant tumor sub-types were identified. A significantly higher proportion of malignant tumors were large (>3 cm diameter) and observed in inguinal mammary glands. Nulliparous (n = 42, 55.3%) dogs predominated in the group, and the mean age of MGT diagnosis was 8.0 ± 2.41 years. The present study identified tumor location and size to be predictive of malignancy. A high histological diversity of MGTs was observed. Overall, the present findings emphasize the necessity of improving awareness of MGTs among Sri Lankan clinicians as well as dog owners. View Full-Text "," rabies,bait,dog,oral vaccination   canine,mammary gland tumors,malignant tumors,Sri Lanka "," Field Studies Evaluating Bait Acceptance and Handling by Free-Roaming Dogs in Thailand   Clinicopathological Diversity of Canine Mammary Gland Tumors in Sri Lanka: A One-Year Survey on Cases Presented to Two Veterinary Practices   Abstract
(1) Background: As part of the ongoing endeavor to eliminate dog-mediated human rabies in Thailand, renewed interest has been shown in oral vaccination of dogs as a supplementary tool to increase vaccination coverage of the dog population. (2) Methods: Three different bait types were tested using a hand-out model on the campus of the Kasetsart University and the surrounding temples in Thailand during September 2017, consisting of two industrial manufactured baits (fish meal and egg-flavored) and one bait made from local material (boiled pig intestine placed in collagen casing). A PVC-capsule containing dyed water was inserted in the bait. (3) Results: The fishmeal bait was significantly less often accepted and consumed (50.29%) than the other two baits (intestine bait—79.19%; egg bait—78.77%). Delivery and release of the dyed water in the oral cavity was highest in the egg-flavored bait (84.50%), followed by the intestine bait (76.61%) and fishmeal (54.85%) baits. Bait acceptance was influenced by sex, age, and body size of the dog. Also, the origin of the dogs had a significant effect: temple dogs accepted the baits more often than street dogs. (4) Conclusion: A significant portion of the free-roaming dog population in this study can be vaccinated by offering vaccine baits. View Full-Text   Abstract
Mammary gland tumors (MGTs) are one of the most common neoplasms among dogs in Sri Lanka. However, the clinicopathological diversity of MGTs in Sri Lanka is largely unknown, impeding accurate diagnosis and effective treatment of the disease. The present study investigated the clinicopathological features of MGTs in 74 dogs presented to two veterinary practices in Sri Lanka treated surgically, over a one-year period. Information regarding the patient signalment, clinical presentation, and reproductive history were collected, and each neoplasm was examined histologically. Forty-one (54.4%) dogs were primarily presented for mammary neoplasia, while a MGT was an incidental finding in 33 (44.6%) dogs. The majority of tumors were histologically malignant (n = 65, 87.8%), and 18 malignant tumor sub-types were identified. A significantly higher proportion of malignant tumors were large (>3 cm diameter) and observed in inguinal mammary glands. Nulliparous (n = 42, 55.3%) dogs predominated in the group, and the mean age of MGT diagnosis was 8.0 ± 2.41 years. The present study identified tumor location and size to be predictive of malignancy. A high histological diversity of MGTs was observed. Overall, the present findings emphasize the necessity of improving awareness of MGTs among Sri Lankan clinicians as well as dog owners. View Full-Text   rabies,bait,dog,oral vaccination   canine,mammary gland tumors,malignant tumors,Sri Lanka ", Veterinary Sciences 
" The Association of Fasting Glucose, Insulin, and C-Peptide, with 19-Year Incidence of Coronary Heart Disease in Older Japanese-American Men; the Honolulu Heart Program   Effects of Walking on Coronary Heart Disease in Elderly Men with Diabetes   Altered Functional Brain Connectivity in Mild Cognitive Impairment during a Cognitively Complex Car Following Task   Planning for a Nondriving Future: Behaviors and Beliefs among Middle-Aged and Older Drivers "," Abstract
The role of fasting glucose, insulin levels, and C-peptide in coronary heart disease (CHD) in non-diabetic individuals remains uncertain. We examined the association between fasting glucose, insulin and C-peptide with the long-term incidence of CHD in Japanese-American men. In 1980–1982, from a random sample of the Honolulu Heart Program men (n = 1378), aged 61–81 years, data on several CHD and metabolic risk factors were obtained to examine the relation of fasting glucose, insulin and C-peptide to 19-year CHD incidence. Age-adjusted incidence of CHD increased with increasing quintiles of glucose, insulin and C-peptide. Age-adjusted CHD rates in the glucose quintiles were 11.9, 11.6, 14.4, 18.1 and 24.1 per 1000 person-years (trend p < 0.001). In individual Cox models (lowest quintiles of glucose, insulin and C-peptide as reference) the relative risks (95% confidence interval) of CHD incidence for the glucose quintiles adjusting for age, smoking, hypertension, cholesterol, physical activity, and body mass index, were 0.9 (0.6–1.4), 1.2 (0.8–1.8), 1.4 (0.9–2.2), and 1.7 (1.1–2.6), respectively (trend p = 0.004). Insulin and C-peptide were not significantly associated with CHD on multivariate analysis. Fasting glucose remained the only significant predictor of increased CHD risk (p = 0.003) in a model combining all 3 metabolic variables. In this cohort, only fasting glucose independently predicts long-term incidence of CHD. Age-adjusted insulin and C-peptide levels were associated with CHD incidence, but after adjustment for other risk factors, do not independently predict CHD. View Full-Text   Abstract
Previous studies have shown that walking is associated with increased longevity and a reduced risk of cardiovascular and age-related diseases. Whether walking benefits individuals with diabetes who are at high risk of coronary heart disease (CHD) remains to be determined. The objective of this study is to examine the association between walking and risk of CHD among elderly men with and without diabetes. Walking data was assessed in 2732 men aged 71 to 93 years participating in the Honolulu Heart Program from 1991–1993. Study participants were initially without disabilities and free of prevalent CHD. Men were then followed for incident CHD for up to 7 years. For men with diabetes who walked <0.25 miles/day, the age-adjusted incidence of CHD was significantly higher than in men without diabetes (27.1 vs. 12.7/1000 person years, p = 0.026). In contrast when distance walked was >1.5 miles/day, incidence of CHD was similar in men with and without diabetes (12.2 vs. 9.1/1000 person-years, p = 0.46). While risk of CHD declined significantly with increasing walking distance in men with diabetes after age and risk factor adjustment (p = 0.043, p = 0.025), associations in those without diabetes were weaker (p = 0.070, p = 0.10). These findings suggest that among elderly men with diabetes who are capable of physical activity, walking reduces CHD risk to levels similar to when diabetes is absent. Walking is an easy, safe and accessible form of physical activity that may have marked health benefits for elderly men with diabetes. View Full-Text   Abstract
Mild cognitive impairment (MCI) can affect multiple cognitive abilities, leading to difficulty in performing complex, cognitively demanding daily tasks, such as driving. This study combined driving simulation and functional magnetic resonance imaging (fMRI) to investigate brain function in individuals with MCI while they performed a car-following task. The behavioral driving performance of 24 patients with MCI and 20 healthy age-matched controls was compared during a simulated car-following task. Functional brain connectivity during driving was analyzed for a separate cohort of 15 patients with MCI and 15 controls. Individuals with MCI had minor difficulty with lane maintenance, exhibiting significantly increased variability in steering compared to controls. Patients with MCI also exhibited reduced connectivity between fronto-parietal regions, as well as between regions involved in cognitive control (medial frontal cortex) and regions important for visual processing (cuneus, angular gyrus, superior occipital cortex, inferior and superior parietal cortex). Greater difficulty in lane maintenance (i.e., increased steering variability and lane deviations) among individuals with MCI was further associated with increased connectivity between the posterior cingulate cortex (PCC) and inferior frontal gyrus, as well as increased intra-cerebellar connectivity. Thus, compared to cognitively healthy controls, patients with MCI showed reduced connectivity between regions involved in visual attention, visual processing, cognitive control, and performance monitoring. Greater difficulty with lane maintenance among patients with MCI may reflect failure to inhibit components of the default-mode network (PCC), leading to interference with task-relevant networks as well as alterations in cerebellum connectivity. View Full-Text   Abstract
Despite the reality of older adults living many years after driving cessation, few prepare for the eventuality; empirically, planning for a nondriving future has not been directly quantified or explored. The following study quantifies (1) the extent of current drivers’ planning; (2) specific planning behaviors; (3) beliefs about benefits of planning; (4) drivers’ intention to plan more for future transportation needs; and (5) group differences associated with planning. In a predominantly female, black, urban sample of current drivers ages 53–92, fewer than half (42.1%) had planned at all for a nondriving future, with correspondingly low levels of planning behaviors reported. However, over 80% believed planning would help them meet their needs post-cessation and transition emotionally to being a nondriver. Most (85%) intended to plan more in the future as well, indicating further potential openness to the topic. Drivers who planned were older, drove less frequently, limited their driving to nearby places, reported less difficulty believing they would become a nondriver, and expected to continue driving three years less than non-planners. These findings suggest that drivers’ perceived nearness to driving cessation impacts planning for future transportation needs, and existing perceived benefits of planning may provide leverage to motivate action. View Full-Text "," diabetes mellitus,glucose,coronary disease,insulin,follow-up studies   coronary heart disease,diabetes,walking,Honolulu Heart Program,elderly men   mild cognitive impairment,driving,fMRI,functional connectivity   aging drivers,driving cessation,mobility planning "," The Association of Fasting Glucose, Insulin, and C-Peptide, with 19-Year Incidence of Coronary Heart Disease in Older Japanese-American Men; the Honolulu Heart Program   Effects of Walking on Coronary Heart Disease in Elderly Men with Diabetes   Altered Functional Brain Connectivity in Mild Cognitive Impairment during a Cognitively Complex Car Following Task   Planning for a Nondriving Future: Behaviors and Beliefs among Middle-Aged and Older Drivers   Abstract
The role of fasting glucose, insulin levels, and C-peptide in coronary heart disease (CHD) in non-diabetic individuals remains uncertain. We examined the association between fasting glucose, insulin and C-peptide with the long-term incidence of CHD in Japanese-American men. In 1980–1982, from a random sample of the Honolulu Heart Program men (n = 1378), aged 61–81 years, data on several CHD and metabolic risk factors were obtained to examine the relation of fasting glucose, insulin and C-peptide to 19-year CHD incidence. Age-adjusted incidence of CHD increased with increasing quintiles of glucose, insulin and C-peptide. Age-adjusted CHD rates in the glucose quintiles were 11.9, 11.6, 14.4, 18.1 and 24.1 per 1000 person-years (trend p < 0.001). In individual Cox models (lowest quintiles of glucose, insulin and C-peptide as reference) the relative risks (95% confidence interval) of CHD incidence for the glucose quintiles adjusting for age, smoking, hypertension, cholesterol, physical activity, and body mass index, were 0.9 (0.6–1.4), 1.2 (0.8–1.8), 1.4 (0.9–2.2), and 1.7 (1.1–2.6), respectively (trend p = 0.004). Insulin and C-peptide were not significantly associated with CHD on multivariate analysis. Fasting glucose remained the only significant predictor of increased CHD risk (p = 0.003) in a model combining all 3 metabolic variables. In this cohort, only fasting glucose independently predicts long-term incidence of CHD. Age-adjusted insulin and C-peptide levels were associated with CHD incidence, but after adjustment for other risk factors, do not independently predict CHD. View Full-Text   Abstract
Previous studies have shown that walking is associated with increased longevity and a reduced risk of cardiovascular and age-related diseases. Whether walking benefits individuals with diabetes who are at high risk of coronary heart disease (CHD) remains to be determined. The objective of this study is to examine the association between walking and risk of CHD among elderly men with and without diabetes. Walking data was assessed in 2732 men aged 71 to 93 years participating in the Honolulu Heart Program from 1991–1993. Study participants were initially without disabilities and free of prevalent CHD. Men were then followed for incident CHD for up to 7 years. For men with diabetes who walked <0.25 miles/day, the age-adjusted incidence of CHD was significantly higher than in men without diabetes (27.1 vs. 12.7/1000 person years, p = 0.026). In contrast when distance walked was >1.5 miles/day, incidence of CHD was similar in men with and without diabetes (12.2 vs. 9.1/1000 person-years, p = 0.46). While risk of CHD declined significantly with increasing walking distance in men with diabetes after age and risk factor adjustment (p = 0.043, p = 0.025), associations in those without diabetes were weaker (p = 0.070, p = 0.10). These findings suggest that among elderly men with diabetes who are capable of physical activity, walking reduces CHD risk to levels similar to when diabetes is absent. Walking is an easy, safe and accessible form of physical activity that may have marked health benefits for elderly men with diabetes. View Full-Text   Abstract
Mild cognitive impairment (MCI) can affect multiple cognitive abilities, leading to difficulty in performing complex, cognitively demanding daily tasks, such as driving. This study combined driving simulation and functional magnetic resonance imaging (fMRI) to investigate brain function in individuals with MCI while they performed a car-following task. The behavioral driving performance of 24 patients with MCI and 20 healthy age-matched controls was compared during a simulated car-following task. Functional brain connectivity during driving was analyzed for a separate cohort of 15 patients with MCI and 15 controls. Individuals with MCI had minor difficulty with lane maintenance, exhibiting significantly increased variability in steering compared to controls. Patients with MCI also exhibited reduced connectivity between fronto-parietal regions, as well as between regions involved in cognitive control (medial frontal cortex) and regions important for visual processing (cuneus, angular gyrus, superior occipital cortex, inferior and superior parietal cortex). Greater difficulty in lane maintenance (i.e., increased steering variability and lane deviations) among individuals with MCI was further associated with increased connectivity between the posterior cingulate cortex (PCC) and inferior frontal gyrus, as well as increased intra-cerebellar connectivity. Thus, compared to cognitively healthy controls, patients with MCI showed reduced connectivity between regions involved in visual attention, visual processing, cognitive control, and performance monitoring. Greater difficulty with lane maintenance among patients with MCI may reflect failure to inhibit components of the default-mode network (PCC), leading to interference with task-relevant networks as well as alterations in cerebellum connectivity. View Full-Text   Abstract
Despite the reality of older adults living many years after driving cessation, few prepare for the eventuality; empirically, planning for a nondriving future has not been directly quantified or explored. The following study quantifies (1) the extent of current drivers’ planning; (2) specific planning behaviors; (3) beliefs about benefits of planning; (4) drivers’ intention to plan more for future transportation needs; and (5) group differences associated with planning. In a predominantly female, black, urban sample of current drivers ages 53–92, fewer than half (42.1%) had planned at all for a nondriving future, with correspondingly low levels of planning behaviors reported. However, over 80% believed planning would help them meet their needs post-cessation and transition emotionally to being a nondriver. Most (85%) intended to plan more in the future as well, indicating further potential openness to the topic. Drivers who planned were older, drove less frequently, limited their driving to nearby places, reported less difficulty believing they would become a nondriver, and expected to continue driving three years less than non-planners. These findings suggest that drivers’ perceived nearness to driving cessation impacts planning for future transportation needs, and existing perceived benefits of planning may provide leverage to motivate action. View Full-Text   diabetes mellitus,glucose,coronary disease,insulin,follow-up studies   coronary heart disease,diabetes,walking,Honolulu Heart Program,elderly men   mild cognitive impairment,driving,fMRI,functional connectivity   aging drivers,driving cessation,mobility planning ", Geriatrics 
 The Development of Compartmentation of cAMP Signaling in Cardiomyocytes: The Role of T-Tubules and Caveolae Microdomains   Some Isolated Cardiac Malformations Can Be Related to Laterality Defects   Cholesterol Efflux: Does It Contribute to Aortic Stiffening? ," Abstract
3′-5′-cyclic adenosine monophosphate (cAMP) is a signaling messenger produced in response to the stimulation of cellular receptors, and has a myriad of functional applications depending on the cell type. In the heart, cAMP is responsible for regulating the contraction rate and force; however, cAMP is also involved in multiple other functions. Compartmentation of cAMP production may explain the specificity of signaling following a stimulus. In particular, transverse tubules (T-tubules) and caveolae have been found to be critical structural components for the spatial confinement of cAMP in cardiomyocytes, as exemplified by beta-adrenergic receptor (β-ARs) signaling. Pathological alterations in cardiomyocyte microdomain architecture led to a disruption in compartmentation of the cAMP signal. In this review, we discuss the difference between atrial and ventricular cardiomyocytes in respect to microdomain organization, and the pathological changes of atrial and ventricular cAMP signaling in response to myocyte dedifferentiation. In addition, we review the role of localized phosphodiesterase (PDE) activity in constraining the cAMP signal. Finally, we discuss microdomain biogenesis and maturation of cAMP signaling with the help of induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs). Understanding these mechanisms may help to overcome the detrimental effects of pathological structural remodeling. View Full-Text   Abstract
Human beings are characterized by a left–right asymmetric arrangement of their internal organs, and the heart is the first organ to break symmetry in the developing embryo. Aberrations in normal left–right axis determination during embryogenesis lead to a wide spectrum of abnormal internal laterality phenotypes, including situs inversus and heterotaxy. In more than 90% of instances, the latter condition is accompanied by complex and severe cardiovascular malformations. Atrioventricular canal defect and transposition of the great arteries—which are particularly frequent in the setting of heterotaxy—are commonly found in situs solitus with or without genetic syndromes. Here, we review current data on morphogenesis of the heart in human beings and animal models, familial recurrence, and upstream genetic pathways of left–right determination in order to highlight how some isolated congenital heart diseases, very common in heterotaxy, even in the setting of situs solitus, may actually be considered in the pathogenetic field of laterality defects. View Full-Text   Abstract
Aortic stiffness during cardiac contraction is defined by the rigidity of the aorta and the elastic resistance to deformation. Recent studies suggest that aortic stiffness may be associated with changes in cholesterol efflux in endothelial cells. This alteration in cholesterol efflux may directly affect endothelial function, extracellular matrix composition, and vascular smooth muscle cell function and behavior. These pathological changes favor an aortic stiffness phenotype. Among all of the proteins participating in the cholesterol efflux process, ATP binding cassette transporter A1 (ABCA1) appears to be the main contributor to arterial stiffness changes in terms of structural and cellular function. ABCA1 is also associated with vascular inflammation mediators implicated in aortic stiffness. The goal of this mini review is to provide a conceptual hypothesis of the recent advancements in the understanding of ABCA1 in cholesterol efflux and its role and association in the development of aortic stiffness, with a particular emphasis on the potential mechanisms and pathways involved. View Full-Text "," cAMP,phosphodiesterase,FRET,atrial,ventricle,iPSC-CMs,T-tubule,caveolae,development   congenital heart disease,genetics,heterotaxy,atrioventricular canal defect,transposition of the great arteries   aortic stiffness,cholesterol efflux,reverse cholesterol transport,ATP-binding cassette transporters "," The Development of Compartmentation of cAMP Signaling in Cardiomyocytes: The Role of T-Tubules and Caveolae Microdomains   Some Isolated Cardiac Malformations Can Be Related to Laterality Defects   Cholesterol Efflux: Does It Contribute to Aortic Stiffening?   Abstract
3′-5′-cyclic adenosine monophosphate (cAMP) is a signaling messenger produced in response to the stimulation of cellular receptors, and has a myriad of functional applications depending on the cell type. In the heart, cAMP is responsible for regulating the contraction rate and force; however, cAMP is also involved in multiple other functions. Compartmentation of cAMP production may explain the specificity of signaling following a stimulus. In particular, transverse tubules (T-tubules) and caveolae have been found to be critical structural components for the spatial confinement of cAMP in cardiomyocytes, as exemplified by beta-adrenergic receptor (β-ARs) signaling. Pathological alterations in cardiomyocyte microdomain architecture led to a disruption in compartmentation of the cAMP signal. In this review, we discuss the difference between atrial and ventricular cardiomyocytes in respect to microdomain organization, and the pathological changes of atrial and ventricular cAMP signaling in response to myocyte dedifferentiation. In addition, we review the role of localized phosphodiesterase (PDE) activity in constraining the cAMP signal. Finally, we discuss microdomain biogenesis and maturation of cAMP signaling with the help of induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs). Understanding these mechanisms may help to overcome the detrimental effects of pathological structural remodeling. View Full-Text   Abstract
Human beings are characterized by a left–right asymmetric arrangement of their internal organs, and the heart is the first organ to break symmetry in the developing embryo. Aberrations in normal left–right axis determination during embryogenesis lead to a wide spectrum of abnormal internal laterality phenotypes, including situs inversus and heterotaxy. In more than 90% of instances, the latter condition is accompanied by complex and severe cardiovascular malformations. Atrioventricular canal defect and transposition of the great arteries—which are particularly frequent in the setting of heterotaxy—are commonly found in situs solitus with or without genetic syndromes. Here, we review current data on morphogenesis of the heart in human beings and animal models, familial recurrence, and upstream genetic pathways of left–right determination in order to highlight how some isolated congenital heart diseases, very common in heterotaxy, even in the setting of situs solitus, may actually be considered in the pathogenetic field of laterality defects. View Full-Text   Abstract
Aortic stiffness during cardiac contraction is defined by the rigidity of the aorta and the elastic resistance to deformation. Recent studies suggest that aortic stiffness may be associated with changes in cholesterol efflux in endothelial cells. This alteration in cholesterol efflux may directly affect endothelial function, extracellular matrix composition, and vascular smooth muscle cell function and behavior. These pathological changes favor an aortic stiffness phenotype. Among all of the proteins participating in the cholesterol efflux process, ATP binding cassette transporter A1 (ABCA1) appears to be the main contributor to arterial stiffness changes in terms of structural and cellular function. ABCA1 is also associated with vascular inflammation mediators implicated in aortic stiffness. The goal of this mini review is to provide a conceptual hypothesis of the recent advancements in the understanding of ABCA1 in cholesterol efflux and its role and association in the development of aortic stiffness, with a particular emphasis on the potential mechanisms and pathways involved. View Full-Text   cAMP,phosphodiesterase,FRET,atrial,ventricle,iPSC-CMs,T-tubule,caveolae,development   congenital heart disease,genetics,heterotaxy,atrioventricular canal defect,transposition of the great arteries   aortic stiffness,cholesterol efflux,reverse cholesterol transport,ATP-binding cassette transporters ", Journal of Cardiovascular Development and Disease 
" Rhinosinutis and Asthma in Children   Prevalence and Determinants of Sinus Problems in Farm and Non-Farm Populations of Rural Saskatchewan, Canada   State-of-the-Art Adult Chronic Rhinosinusitis Microbiome: Perspective for Future Studies in Pediatrics   Do Adult Forms of Chronic Rhinosinusitis Exist in Children and Adolescents? "," Abstract
Rhinosinusitis and asthma are two comorbid conditions that lead to pathological and clinical diseases affecting the respiratory tract. They are connected by significant anatomical, epidemiological, pathophysiological, and clinical evidence, and also share therapeutic principles. The aim of this review is to provide an updated overview of the existing link between rhinosinusitis and asthma focusing on the pediatric age. View Full-Text   Abstract
Although sinus problems have long been recognized as the most common respiratory symptoms associated with agricultural work, there is a scarcity of recent studies and/or reliable estimates as to the true prevalence or risk factors of sinus problems related to farming. The aim of this study was to determine the prevalence of sinus problems in farming and non-farming rural populations and further investigate the association of individual (for example life-style, occupational), contextual (e.g., environmental), and important covariates (e.g., age, sex) with sinus problems. A large-scale cross-sectional study was conducted in farm and non-farm residents of rural Saskatchewan, Canada. A logistic regression model based on a generalized estimating equations approach were fitted to investigate the risk factors of sinus problems. Sinus problems were reported by 2755 (34.0%) of the 8101 subjects. Farm residents were more likely to spend their first year of life on farm compared with non-farm residents, and indicated a significantly lower risk of sinus problems. Meanwhile, occupational exposure to solvent and mold were associated with an increased risk of sinus problems. Some health conditions such as allergy and stomach acidity/reflux, family history, and female sex were also related to a higher risk of sinus problems. Farm residents had a significantly lower risk of sinus problems than non-farm residents, likely due to the exposure to farm specific environments in their early life. View Full-Text   Abstract
Chronic rhinosinusitis (CRS) is a prevalent disease that causes persistent mucosal inflammation and is associated with bacterial infection, which is thought to play a role in the inflammatory process. Microbiome analysis provides insight to host–microbial interactions. Disturbances in the host and commensal bacteria interaction may lead to CRS. Culture-based methods are useful to isolate some microorganisms but are unable to grow a majority of the bacteria. A review of the literature shows that several recent studies attempted to overcome this issue by using molecular techniques, such as microbial RNA sequencing, to describe the CRS microbiome. All of these studies were performed in adults, with no comparative studies reported in the pediatric population. Similar studies, utilizing molecular techniques, are needed to better understand the mechanism of CRS in children. Because valuable data from these adult studies may help to bridge the gap in our knowledge of the microbiome in pediatric CRS, we present an overview of the methodology and results behind the current microbiomic approach to adult CRS to set the stage for its use in the study of CRS in children. View Full-Text   Abstract
Pediatric chronic sinusitis is currently designated as pediatric chronic rhinosinusitis. In most pediatric cases, sinusitis is considered as infectious. In the adult literature, a wider repertoire of chronic rhinosinusitis conditions is recognized. In this review, the adult forms of chronic rhinosinusitis are used as a framework for identifying and defining the potential spectrum of pediatric chronic rhinosinusitis that exists beyond the most recognized condition, pediatric infectious chronic rhinosinusitis. View Full-Text "," rhinosinusitis,asthma,children   rhinitis,occupational exposure,environmental exposure,farm,rural health,allergy,respiratory,birth weight,gastroesophageal reflux,sinusitis   microbiome,pediatric chronic rhinosinusitis,molecular techniques   pediatric,children,adolescent,chronic sinusitis,chronic rhinosinusitis,nasal polyps,eosinophilic mucin chronic rhinosinusitis,Samter’s triad "," Rhinosinutis and Asthma in Children   Prevalence and Determinants of Sinus Problems in Farm and Non-Farm Populations of Rural Saskatchewan, Canada   State-of-the-Art Adult Chronic Rhinosinusitis Microbiome: Perspective for Future Studies in Pediatrics   Do Adult Forms of Chronic Rhinosinusitis Exist in Children and Adolescents?   Abstract
Rhinosinusitis and asthma are two comorbid conditions that lead to pathological and clinical diseases affecting the respiratory tract. They are connected by significant anatomical, epidemiological, pathophysiological, and clinical evidence, and also share therapeutic principles. The aim of this review is to provide an updated overview of the existing link between rhinosinusitis and asthma focusing on the pediatric age. View Full-Text   Abstract
Although sinus problems have long been recognized as the most common respiratory symptoms associated with agricultural work, there is a scarcity of recent studies and/or reliable estimates as to the true prevalence or risk factors of sinus problems related to farming. The aim of this study was to determine the prevalence of sinus problems in farming and non-farming rural populations and further investigate the association of individual (for example life-style, occupational), contextual (e.g., environmental), and important covariates (e.g., age, sex) with sinus problems. A large-scale cross-sectional study was conducted in farm and non-farm residents of rural Saskatchewan, Canada. A logistic regression model based on a generalized estimating equations approach were fitted to investigate the risk factors of sinus problems. Sinus problems were reported by 2755 (34.0%) of the 8101 subjects. Farm residents were more likely to spend their first year of life on farm compared with non-farm residents, and indicated a significantly lower risk of sinus problems. Meanwhile, occupational exposure to solvent and mold were associated with an increased risk of sinus problems. Some health conditions such as allergy and stomach acidity/reflux, family history, and female sex were also related to a higher risk of sinus problems. Farm residents had a significantly lower risk of sinus problems than non-farm residents, likely due to the exposure to farm specific environments in their early life. View Full-Text   Abstract
Chronic rhinosinusitis (CRS) is a prevalent disease that causes persistent mucosal inflammation and is associated with bacterial infection, which is thought to play a role in the inflammatory process. Microbiome analysis provides insight to host–microbial interactions. Disturbances in the host and commensal bacteria interaction may lead to CRS. Culture-based methods are useful to isolate some microorganisms but are unable to grow a majority of the bacteria. A review of the literature shows that several recent studies attempted to overcome this issue by using molecular techniques, such as microbial RNA sequencing, to describe the CRS microbiome. All of these studies were performed in adults, with no comparative studies reported in the pediatric population. Similar studies, utilizing molecular techniques, are needed to better understand the mechanism of CRS in children. Because valuable data from these adult studies may help to bridge the gap in our knowledge of the microbiome in pediatric CRS, we present an overview of the methodology and results behind the current microbiomic approach to adult CRS to set the stage for its use in the study of CRS in children. View Full-Text   Abstract
Pediatric chronic sinusitis is currently designated as pediatric chronic rhinosinusitis. In most pediatric cases, sinusitis is considered as infectious. In the adult literature, a wider repertoire of chronic rhinosinusitis conditions is recognized. In this review, the adult forms of chronic rhinosinusitis are used as a framework for identifying and defining the potential spectrum of pediatric chronic rhinosinusitis that exists beyond the most recognized condition, pediatric infectious chronic rhinosinusitis. View Full-Text   rhinosinusitis,asthma,children   rhinitis,occupational exposure,environmental exposure,farm,rural health,allergy,respiratory,birth weight,gastroesophageal reflux,sinusitis   microbiome,pediatric chronic rhinosinusitis,molecular techniques   pediatric,children,adolescent,chronic sinusitis,chronic rhinosinusitis,nasal polyps,eosinophilic mucin chronic rhinosinusitis,Samter’s triad ", Sinusitis 
 Endophytic Fungi in Species of Artemisia   Assessment of Genetic Diversity among Pleurotus spp. Isolates from Jordan ," Abstract
The genus Artemisia, a collection of ~400 hardy herbaceous plant and shrub species, is an important resource contributing to chemistry, medicine, agriculture, industry, and ecology. Its communities of endophytic fungi have only recently begun to be explored. Summarized from studies conducted on the fungal endophytes in Artemisia species, both fungal phylogenetic diversity and the associated bioactivity was examined. Isolations from 14 species of Artemisia have led to 51 genera of fungal endophytes, 28 families, and 18 orders. Endophytes belonged mainly to Ascomycota, except for two taxa of Cantharellales and Sporidiobolales, one taxon of Mucoromycota, and one species of Oomycota. The mostly common families were Pleosporaceae, Trichocomaceae, Leptosphaeriaceae, and Botryosphaeriaceae (relative abundance = 14.89, 8.51, 7.14 and 6.38, respectively). In the search for bioactive metabolites, 27 novel compounds were characterized and 22 metabolites were isolated between 2006 and 2017. The first study on endophytic fungi isolated from species of Artemisia was published but 18 years ago. This summary of recently acquired data illustrates the considerable diversity of biological purposes addressed by fungal endophytes of Artemisia spp. View Full-Text   Abstract
Pleurotus is considered an important genus that belongs to the family Pleurotaceae and includes the edible King Oyster mushroom (Pleurotus eryngii). In the present study, 19 Pleurotus isolates were collected from two locations in the north of Jordan (Tell ar-Rumman and Um-Qais). The morphological characteristics among collected isolates revealed that there was a morphological similarity among the collected isolates. Nucleotide sequence analysis of the internal transcribed spacer (ITS1–5.8S rDNA–ITS4 region) and 28S nuclear large subunit (nLSU) in the ribosomal DNA gene of the isolated stains showed that all of them share over 98% sequence similarity with P. eryngii. Genetic diversity among the collected strains was assessed using inter simple sequence repeat (ISSR) analysis using 18 different primer pairs. Using this approach, 141 out of 196 bands obtained were considered polymorphic and the highest percentage of polymorphism was observed using primer UBC827 (92.3%) with an overall Polymorphism Information Content (PIC) value of 70.56%. Cluster analysis showed that the Jordanian Pleurotus isolates fall into two main clades with a coefficient of similarity values ranging from 0.59 to 0.74 with a clear clustering based on collection sites. The results of the present study reveal that molecular techniques of ISSR and rDNA sequencing can greatly aid in classification and identification of Pleurotus spp. in Jordan. View Full-Text "," medicinal plants microbiome,phylogeny,bioactivity,rare fungal species   Pleurotus,mushroom,inter simple sequence repeat (ISSR),internal transcribed spacer region,genetic diversity "," Endophytic Fungi in Species of Artemisia   Assessment of Genetic Diversity among Pleurotus spp. Isolates from Jordan   Abstract
The genus Artemisia, a collection of ~400 hardy herbaceous plant and shrub species, is an important resource contributing to chemistry, medicine, agriculture, industry, and ecology. Its communities of endophytic fungi have only recently begun to be explored. Summarized from studies conducted on the fungal endophytes in Artemisia species, both fungal phylogenetic diversity and the associated bioactivity was examined. Isolations from 14 species of Artemisia have led to 51 genera of fungal endophytes, 28 families, and 18 orders. Endophytes belonged mainly to Ascomycota, except for two taxa of Cantharellales and Sporidiobolales, one taxon of Mucoromycota, and one species of Oomycota. The mostly common families were Pleosporaceae, Trichocomaceae, Leptosphaeriaceae, and Botryosphaeriaceae (relative abundance = 14.89, 8.51, 7.14 and 6.38, respectively). In the search for bioactive metabolites, 27 novel compounds were characterized and 22 metabolites were isolated between 2006 and 2017. The first study on endophytic fungi isolated from species of Artemisia was published but 18 years ago. This summary of recently acquired data illustrates the considerable diversity of biological purposes addressed by fungal endophytes of Artemisia spp. View Full-Text   Abstract
Pleurotus is considered an important genus that belongs to the family Pleurotaceae and includes the edible King Oyster mushroom (Pleurotus eryngii). In the present study, 19 Pleurotus isolates were collected from two locations in the north of Jordan (Tell ar-Rumman and Um-Qais). The morphological characteristics among collected isolates revealed that there was a morphological similarity among the collected isolates. Nucleotide sequence analysis of the internal transcribed spacer (ITS1–5.8S rDNA–ITS4 region) and 28S nuclear large subunit (nLSU) in the ribosomal DNA gene of the isolated stains showed that all of them share over 98% sequence similarity with P. eryngii. Genetic diversity among the collected strains was assessed using inter simple sequence repeat (ISSR) analysis using 18 different primer pairs. Using this approach, 141 out of 196 bands obtained were considered polymorphic and the highest percentage of polymorphism was observed using primer UBC827 (92.3%) with an overall Polymorphism Information Content (PIC) value of 70.56%. Cluster analysis showed that the Jordanian Pleurotus isolates fall into two main clades with a coefficient of similarity values ranging from 0.59 to 0.74 with a clear clustering based on collection sites. The results of the present study reveal that molecular techniques of ISSR and rDNA sequencing can greatly aid in classification and identification of Pleurotus spp. in Jordan. View Full-Text   medicinal plants microbiome,phylogeny,bioactivity,rare fungal species   Pleurotus,mushroom,inter simple sequence repeat (ISSR),internal transcribed spacer region,genetic diversity ", Journal of Fungi 
 Emergence of Wrinkles during the Curing of Coatings   Beyond Covalent Crosslinks: Applications of Supramolecular Gels   Physical Properties of the Extracellular Matrix of Decellularized Porcine Liver   Microfluidic Spun Alginate Hydrogel Microfibers and Their Application in Tissue Engineering ," Abstract
Wrinkles often emerge on a paint layer when a second coat of paint is applied on an already-coated substrate. Wrinkle formation occurs when the first layer absorbs organic solvent from the second layer. We set up experiments to mimic the double-coating process, focusing on the interaction between a paint layer and an organic solvent. In the experiments, we investigated the characteristic wavelengths of the wrinkles and the time of wrinkle emergence. We employed a simple model to explain the wrinkle emergence and performed numerical simulations. The linear stability analysis of the model provides a relation between the wavelengths and the characteristic timescale that agrees reasonably well with our experimental data as well as numerical results. Our results indicate that compression of the layer due to swelling and delamination are both important factors in the formation of wrinkles. View Full-Text   Abstract
Traditionally, gels have been defined by their covalently cross-linked polymer networks. Supramolecular gels challenge this framework by relying on non-covalent interactions for self-organization into hierarchical structures. This class of materials offers a variety of novel and exciting potential applications. This review draws together recent advances in supramolecular gels with an emphasis on their proposed uses as optoelectronic, energy, biomedical, and biological materials. Additional special topics reviewed include environmental remediation, participation in synthesis procedures, and other industrial uses. The examples presented here demonstrate unique benefits of supramolecular gels, including tunability, processability, and self-healing capability, enabling a new approach to solve engineering challenges. View Full-Text   Abstract
The decellularization of organs has attracted attention as a new functional methodology for regenerative medicine based on tissue engineering. In previous work we developed an L-ECM (Extracellular Matrix) as a substrate-solubilized decellularized liver and demonstrated its effectiveness as a substrate for culturing and transplantation. Importantly, the physical properties of the substrate constitute important factors that control cell behavior. In this study, we aimed to quantify the physical properties of L-ECM and L-ECM gels. L-ECM was prepared as a liver-specific matrix substrate from solubilized decellularized porcine liver. In comparison to type I collagen, L-ECM yielded a lower elasticity and exhibited an abrupt decrease in its elastic modulus at 37 °C. Its elastic modulus increased at increased temperatures, and the storage elastic modulus value never fell below the loss modulus value. An increase in the gel concentration of L-ECM resulted in a decrease in the biodegradation rate and in an increase in mechanical strength. The reported properties of L-ECM gel (10 mg/mL) were equivalent to those of collagen gel (3 mg/mL), which is commonly used in regenerative medicine and gel cultures. Based on reported findings, the physical properties of the novel functional substrate for culturing and regenerative medicine L-ECM were quantified. View Full-Text   Abstract
Tissue engineering is focusing on processing tissue micro-structures for a variety of applications in cell biology and the “bottom-up” construction of artificial tissue. Over the last decade, microfluidic devices have provided novel tools for producing alginate hydrogel microfibers with various morphologies, structures, and compositions for cell cultivation. Moreover, microfluidic spun alginate microfibers are long, thin, and flexible, and these features facilitate higher-order assemblies for fabricating macroscopic cellular structures. In this paper, we present an overview of the microfluidic spinning principle of alginate hydrogel microfibers and their application as micro-scaffolds or scaffolding elements for 3D assembly in tissue engineering. View Full-Text "," paint coating,wrinkle,swelling,buckling   supramolecular gel,self-assembly,gels,applied soft matter   liver-specific extracellular matrix,gel,scaffold,tissue engineering,decellularization,solubilized extracellular matrix,physical property,storage modulus,loss modulus,biodegradation   microfluidic spinning,alginate hydrogel microfibers,3D assembly,tissue engineering "," Emergence of Wrinkles during the Curing of Coatings   Beyond Covalent Crosslinks: Applications of Supramolecular Gels   Physical Properties of the Extracellular Matrix of Decellularized Porcine Liver   Microfluidic Spun Alginate Hydrogel Microfibers and Their Application in Tissue Engineering   Abstract
Wrinkles often emerge on a paint layer when a second coat of paint is applied on an already-coated substrate. Wrinkle formation occurs when the first layer absorbs organic solvent from the second layer. We set up experiments to mimic the double-coating process, focusing on the interaction between a paint layer and an organic solvent. In the experiments, we investigated the characteristic wavelengths of the wrinkles and the time of wrinkle emergence. We employed a simple model to explain the wrinkle emergence and performed numerical simulations. The linear stability analysis of the model provides a relation between the wavelengths and the characteristic timescale that agrees reasonably well with our experimental data as well as numerical results. Our results indicate that compression of the layer due to swelling and delamination are both important factors in the formation of wrinkles. View Full-Text   Abstract
Traditionally, gels have been defined by their covalently cross-linked polymer networks. Supramolecular gels challenge this framework by relying on non-covalent interactions for self-organization into hierarchical structures. This class of materials offers a variety of novel and exciting potential applications. This review draws together recent advances in supramolecular gels with an emphasis on their proposed uses as optoelectronic, energy, biomedical, and biological materials. Additional special topics reviewed include environmental remediation, participation in synthesis procedures, and other industrial uses. The examples presented here demonstrate unique benefits of supramolecular gels, including tunability, processability, and self-healing capability, enabling a new approach to solve engineering challenges. View Full-Text   Abstract
The decellularization of organs has attracted attention as a new functional methodology for regenerative medicine based on tissue engineering. In previous work we developed an L-ECM (Extracellular Matrix) as a substrate-solubilized decellularized liver and demonstrated its effectiveness as a substrate for culturing and transplantation. Importantly, the physical properties of the substrate constitute important factors that control cell behavior. In this study, we aimed to quantify the physical properties of L-ECM and L-ECM gels. L-ECM was prepared as a liver-specific matrix substrate from solubilized decellularized porcine liver. In comparison to type I collagen, L-ECM yielded a lower elasticity and exhibited an abrupt decrease in its elastic modulus at 37 °C. Its elastic modulus increased at increased temperatures, and the storage elastic modulus value never fell below the loss modulus value. An increase in the gel concentration of L-ECM resulted in a decrease in the biodegradation rate and in an increase in mechanical strength. The reported properties of L-ECM gel (10 mg/mL) were equivalent to those of collagen gel (3 mg/mL), which is commonly used in regenerative medicine and gel cultures. Based on reported findings, the physical properties of the novel functional substrate for culturing and regenerative medicine L-ECM were quantified. View Full-Text   Abstract
Tissue engineering is focusing on processing tissue micro-structures for a variety of applications in cell biology and the “bottom-up” construction of artificial tissue. Over the last decade, microfluidic devices have provided novel tools for producing alginate hydrogel microfibers with various morphologies, structures, and compositions for cell cultivation. Moreover, microfluidic spun alginate microfibers are long, thin, and flexible, and these features facilitate higher-order assemblies for fabricating macroscopic cellular structures. In this paper, we present an overview of the microfluidic spinning principle of alginate hydrogel microfibers and their application as micro-scaffolds or scaffolding elements for 3D assembly in tissue engineering. View Full-Text   paint coating,wrinkle,swelling,buckling   supramolecular gel,self-assembly,gels,applied soft matter   liver-specific extracellular matrix,gel,scaffold,tissue engineering,decellularization,solubilized extracellular matrix,physical property,storage modulus,loss modulus,biodegradation   microfluidic spinning,alginate hydrogel microfibers,3D assembly,tissue engineering ", Gels 
 Thermal Fluid Analysis of Cold Plasma Methane Reformer   Spontaneous Synchronization of Beating Cilia: An Experimental Proof Using Vision-Based Control   Aerodynamics of a Wing with a Wingtip Flapper†   One Dimensional Model for Droplet Ejection Process in Inkjet Devices ," Abstract
One of the most important methods of methane utilization is the conversion to synthesis gas (syngas). However, conventional ways of reforming methane usually require very high temperature, therefore non-thermal (non-equilibrium) plasma methane reforming is an attractive alternative. In this study, a novel plasma based reformer named 3D Gliding Arc Vortex Reformer (3D-GAVR) was investigated for partial oxidation of methane to produce syngas. The tangential input creates a vortex in the plasma zone and an expanded plasma presides within the entire area between the two electrodes. Using this method, the experimental results show that hydrogen can be produced for as low as
$4.45
per kg with flow rates of around 1 L per minute. The maximum methane conversion percentage which is achieved by this technology is up to 62.38%. In addition, a computational fluid dynamics (CFD) modeling is conducted for a cold plasma reformer chamber named reverse vortex flow gliding arc reactor (RVF-GA) to investigate the effects of geometry and configuration on the reformer performance. In this modified reformer, an axial air input port is added to the top of the reaction vessel while the premixed reactants can enter the cylindrical reaction zone through tangential jets. The CFD results show that a reverse vortex flow (RVF) scheme can be created which has an outer swirling rotation along with a low pressure area at its center with some component of axial flow. The reversed vortex flow utilizes the uniform temperature and heat flux distribution inside the cylinder, and enhances the gas mixtures leading to expedition of the chemical reaction and the rate of hydrogen production. View Full-Text   Abstract
This article investigates the formation of spontaneous coordination in a row of flexible 2D flaps (artificial cilia) in a chamber filled with a high viscous liquid (Re = 0.12). Each flap is driven individually to oscillate by a rotary motor with the root of the flap attached to its spindle axle. A computer-vision control loop tracks the flap tips online and toggles the axle rotation direction when the tips reach a pre-defined maximum excursion. This is a vision-controlled implementation of the so-called “geometric clutch” hypothesis. When running the control loop with the flaps in an inviscid reference situation (air), they remain in their individual phases for a long term. Then, the flaps are studied in the chamber filled with a highly viscous liquid, and the same control loop is started. The flexible flaps now undergo bending due to hydrodynamic coupling and come, after a maximum of 15 beats, into a synchronous metachronal coordination. The study proves in a macroscopic lab experiment that viscous coupling is sufficient to achieve spontaneous synchronization, even for a symmetric cilia shape and beat pattern. View Full-Text   Abstract
In the present study, an oscillating membrane flapper was pivotally attached to the tip of a conventional rigid wing. Stroke-averaged aerodynamic forces were measured for the range of the flapping frequency, showing significant increases in the lift coefficient and lift-to-drag ratio for the wing with a flapper. Major vortex patterns were deduced from observations of smoke-wire visualization and 2D phase-locked particle image velocimetry (PIV). The centerline of the primary vortex wanders in the counterclockwise direction. On the contrary, its core rotates in the same sense of rotation as a wingtip vortex in a conventional wing. The secondary weaker vortex of opposite rotation lasts for a half stroke. The vortex ring sheds from the flapper during the second half of the upstroke and pronation. The outer parts of the vortex system are much stronger than the inner ones. The circulation and size of vortices decrease significantly at the most distant station from the wing. Strong vertical jets were found in smoke-wire visualization and confirmed with velocity and vorticity fields obtained by PIV. These jets are formed between undulating vortices and inside of the vortex ring. The jet airflow moves away from the flapper and downward or upward depending on the flapping direction. View Full-Text   Abstract
In recent years, physics-based computer models have been increasingly applied to design the drop-on-demand (DOD) inkjet devices. The initial design stage for these devices often requires a fast turnaround time of computer models, because it usually involves a massive screening of a large number of design parameters. Thus, in the present study, a 1D model is developed to achieve the fast prediction of droplet ejection process from DOD devices, including the droplet breakup and coalescence. A popular 1D slender-jet method (Egger, 1994) is adopted in this study. The fluid dynamics in the nozzle region is described by a 2D axisymmetric unsteady Poiseuille flow model. Droplet formation and nozzle fluid dynamics are coupled, and hence solved together, to simulate the inkjet droplet ejection. The arbitrary Lagrangian–Eulerian method is employed to solve the governing equations. Numerical methods have been proposed to handle the breakup and coalescence of droplets. The proposed methods are implemented in an in-house developed MATLAB code. A series of validation examples have been carried out to evaluate the accuracy and the robustness of the proposed 1D model. Finally, a case study of the inkjet droplet ejection with different Ohnesorge number (Oh) is presented to demonstrate the capability of the proposed 1D model for DOD inkjet process. Our study has shown that 1D model can significantly reduce the computational time (usually less than one minute) yet with acceptable accuracy, which makes it very useful to explore the large parameter space of inkjet devices in a short amount of time. View Full-Text "," partial oxidation of methane,synthesis gas,cold plasma,gliding arc discharge,computational fluid dynamics modeling   metachronal wave,beating cilia,self-synchronization,geometric clutch hypothesis,viscous coupling,hydrodynamic interaction   wing,flapping,lift,drag,wake,vortex   drop-on-demand inkjet,slender-jet analysis,droplet breakup,droplet coalescence "," Thermal Fluid Analysis of Cold Plasma Methane Reformer   Spontaneous Synchronization of Beating Cilia: An Experimental Proof Using Vision-Based Control   Aerodynamics of a Wing with a Wingtip Flapper†   One Dimensional Model for Droplet Ejection Process in Inkjet Devices   Abstract
One of the most important methods of methane utilization is the conversion to synthesis gas (syngas). However, conventional ways of reforming methane usually require very high temperature, therefore non-thermal (non-equilibrium) plasma methane reforming is an attractive alternative. In this study, a novel plasma based reformer named 3D Gliding Arc Vortex Reformer (3D-GAVR) was investigated for partial oxidation of methane to produce syngas. The tangential input creates a vortex in the plasma zone and an expanded plasma presides within the entire area between the two electrodes. Using this method, the experimental results show that hydrogen can be produced for as low as
$4.45
per kg with flow rates of around 1 L per minute. The maximum methane conversion percentage which is achieved by this technology is up to 62.38%. In addition, a computational fluid dynamics (CFD) modeling is conducted for a cold plasma reformer chamber named reverse vortex flow gliding arc reactor (RVF-GA) to investigate the effects of geometry and configuration on the reformer performance. In this modified reformer, an axial air input port is added to the top of the reaction vessel while the premixed reactants can enter the cylindrical reaction zone through tangential jets. The CFD results show that a reverse vortex flow (RVF) scheme can be created which has an outer swirling rotation along with a low pressure area at its center with some component of axial flow. The reversed vortex flow utilizes the uniform temperature and heat flux distribution inside the cylinder, and enhances the gas mixtures leading to expedition of the chemical reaction and the rate of hydrogen production. View Full-Text   Abstract
This article investigates the formation of spontaneous coordination in a row of flexible 2D flaps (artificial cilia) in a chamber filled with a high viscous liquid (Re = 0.12). Each flap is driven individually to oscillate by a rotary motor with the root of the flap attached to its spindle axle. A computer-vision control loop tracks the flap tips online and toggles the axle rotation direction when the tips reach a pre-defined maximum excursion. This is a vision-controlled implementation of the so-called “geometric clutch” hypothesis. When running the control loop with the flaps in an inviscid reference situation (air), they remain in their individual phases for a long term. Then, the flaps are studied in the chamber filled with a highly viscous liquid, and the same control loop is started. The flexible flaps now undergo bending due to hydrodynamic coupling and come, after a maximum of 15 beats, into a synchronous metachronal coordination. The study proves in a macroscopic lab experiment that viscous coupling is sufficient to achieve spontaneous synchronization, even for a symmetric cilia shape and beat pattern. View Full-Text   Abstract
In the present study, an oscillating membrane flapper was pivotally attached to the tip of a conventional rigid wing. Stroke-averaged aerodynamic forces were measured for the range of the flapping frequency, showing significant increases in the lift coefficient and lift-to-drag ratio for the wing with a flapper. Major vortex patterns were deduced from observations of smoke-wire visualization and 2D phase-locked particle image velocimetry (PIV). The centerline of the primary vortex wanders in the counterclockwise direction. On the contrary, its core rotates in the same sense of rotation as a wingtip vortex in a conventional wing. The secondary weaker vortex of opposite rotation lasts for a half stroke. The vortex ring sheds from the flapper during the second half of the upstroke and pronation. The outer parts of the vortex system are much stronger than the inner ones. The circulation and size of vortices decrease significantly at the most distant station from the wing. Strong vertical jets were found in smoke-wire visualization and confirmed with velocity and vorticity fields obtained by PIV. These jets are formed between undulating vortices and inside of the vortex ring. The jet airflow moves away from the flapper and downward or upward depending on the flapping direction. View Full-Text   Abstract
In recent years, physics-based computer models have been increasingly applied to design the drop-on-demand (DOD) inkjet devices. The initial design stage for these devices often requires a fast turnaround time of computer models, because it usually involves a massive screening of a large number of design parameters. Thus, in the present study, a 1D model is developed to achieve the fast prediction of droplet ejection process from DOD devices, including the droplet breakup and coalescence. A popular 1D slender-jet method (Egger, 1994) is adopted in this study. The fluid dynamics in the nozzle region is described by a 2D axisymmetric unsteady Poiseuille flow model. Droplet formation and nozzle fluid dynamics are coupled, and hence solved together, to simulate the inkjet droplet ejection. The arbitrary Lagrangian–Eulerian method is employed to solve the governing equations. Numerical methods have been proposed to handle the breakup and coalescence of droplets. The proposed methods are implemented in an in-house developed MATLAB code. A series of validation examples have been carried out to evaluate the accuracy and the robustness of the proposed 1D model. Finally, a case study of the inkjet droplet ejection with different Ohnesorge number (Oh) is presented to demonstrate the capability of the proposed 1D model for DOD inkjet process. Our study has shown that 1D model can significantly reduce the computational time (usually less than one minute) yet with acceptable accuracy, which makes it very useful to explore the large parameter space of inkjet devices in a short amount of time. View Full-Text   partial oxidation of methane,synthesis gas,cold plasma,gliding arc discharge,computational fluid dynamics modeling   metachronal wave,beating cilia,self-synchronization,geometric clutch hypothesis,viscous coupling,hydrodynamic interaction   wing,flapping,lift,drag,wake,vortex   drop-on-demand inkjet,slender-jet analysis,droplet breakup,droplet coalescence ", Fluids 
 Non-Coding RNA as Novel Players in the Pathophysiology of Schizophrenia   Hypoxia-Induced MicroRNA-210 Targets Neurodegenerative Pathways   Strengths and Weaknesses of the Current Strategies to Map and Characterize R-Loops   RNA Surveillance by the Nuclear RNA Exosome: Mechanisms and Significance ," Abstract
Schizophrenia is associated with diverse changes in the brain’s transcriptome and proteome. Underlying these changes is the complex dysregulation of gene expression and protein production that varies both spatially across brain regions and temporally with the progression of the illness. The growing body of literature showing changes in non-coding RNA in individuals with schizophrenia offers new insights into the mechanisms causing this dysregulation. A large number of studies have reported that the expression of microRNA (miRNA) is altered in the brains of individuals with schizophrenia. This evidence is complemented by findings that single nucleotide polymorphisms (SNPs) in miRNA host gene sequences can confer an increased risk of developing the disorder. Additionally, recent evidence suggests the expression of other non-coding RNAs, such as small nucleolar RNA and long non-coding RNA, may also be affected in schizophrenia. Understanding how these changes in non-coding RNAs contribute to the development and progression of schizophrenia offers potential avenues for the better treatment and diagnosis of the disorder. This review will focus on the evidence supporting the involvement of non-coding RNA in schizophrenia and its therapeutic potential. View Full-Text   Abstract
Hypoxia-regulated microRNA-210 (miR-210) is a highly conserved microRNA, known to regulate various processes under hypoxic conditions. Previously we found that miR-210 is also involved in honeybee learning and memory, raising the questions of how neural activity may induce hypoxia-regulated genes and how miR-210 may regulate plasticity in more complex mammalian systems. Using a pull-down approach, we identified 620 unique target genes of miR-210 in humans, among which there was a significant enrichment of age-related neurodegenerative pathways, including Huntington’s, Alzheimer’s, and Parkinson’s diseases. We have also validated that miR-210 directly regulates various identified target genes of interest involved with neuronal plasticity, neurodegenerative diseases, and miR-210-associated cancers. This data suggests a potentially novel mechanism for how metabolic changes may couple plasticity to neuronal activity through hypoxia-regulated genes such as miR-210. View Full-Text   Abstract
R-loops are evolutionarily conserved three-stranded structures that result from the formation of stable DNA:RNA hybrids in the genome. R-loops have attracted increasing interest in recent years as potent regulators of gene expression and genome stability. In particular, their strong association with severe replication stress makes them potential oncogenic structures. Despite their importance, the rules that govern their formation and their dynamics are still controversial and an in-depth description of their direct impact on chromatin organization and DNA transactions is still lacking. To better understand the diversity of R-loop functions, reliable, accurate, and quantitative mapping techniques, as well as functional assays are required. Here, I review the different approaches that are currently used to do so and to highlight their individual strengths and weaknesses. In particular, I review the advantages and disadvantages of using the S9.6 antibody to map R-loops in vivo in an attempt to propose guidelines for best practices. View Full-Text   Abstract
The nuclear RNA exosome is an essential and versatile machinery that regulates maturation and degradation of a huge plethora of RNA species. The past two decades have witnessed remarkable progress in understanding the whole picture of its RNA substrates and the structural basis of its functions. In addition to the exosome itself, recent studies focusing on associated co-factors have been elucidating how the exosome is directed towards specific substrates. Moreover, it has been gradually realized that loss-of-function of exosome subunits affect multiple biological processes, such as the DNA damage response, R-loop resolution, maintenance of genome integrity, RNA export, translation, and cell differentiation. In this review, we summarize the current knowledge of the mechanisms of nuclear exosome-mediated RNA metabolism and discuss their physiological significance. View Full-Text "," schizophrenia,central nervous system,microRNA,lncRNA,snoRNA,biomarkers   microRNA,hsa-miR-210,microRNA targeting,SH-SY5Y cells,neurodegeneration   R-loops,S9.6,RNase H1,DRIP,R-ChIP   exosome,RNA surveillance,RNA processing,RNA degradation "," Non-Coding RNA as Novel Players in the Pathophysiology of Schizophrenia   Hypoxia-Induced MicroRNA-210 Targets Neurodegenerative Pathways   Strengths and Weaknesses of the Current Strategies to Map and Characterize R-Loops   RNA Surveillance by the Nuclear RNA Exosome: Mechanisms and Significance   Abstract
Schizophrenia is associated with diverse changes in the brain’s transcriptome and proteome. Underlying these changes is the complex dysregulation of gene expression and protein production that varies both spatially across brain regions and temporally with the progression of the illness. The growing body of literature showing changes in non-coding RNA in individuals with schizophrenia offers new insights into the mechanisms causing this dysregulation. A large number of studies have reported that the expression of microRNA (miRNA) is altered in the brains of individuals with schizophrenia. This evidence is complemented by findings that single nucleotide polymorphisms (SNPs) in miRNA host gene sequences can confer an increased risk of developing the disorder. Additionally, recent evidence suggests the expression of other non-coding RNAs, such as small nucleolar RNA and long non-coding RNA, may also be affected in schizophrenia. Understanding how these changes in non-coding RNAs contribute to the development and progression of schizophrenia offers potential avenues for the better treatment and diagnosis of the disorder. This review will focus on the evidence supporting the involvement of non-coding RNA in schizophrenia and its therapeutic potential. View Full-Text   Abstract
Hypoxia-regulated microRNA-210 (miR-210) is a highly conserved microRNA, known to regulate various processes under hypoxic conditions. Previously we found that miR-210 is also involved in honeybee learning and memory, raising the questions of how neural activity may induce hypoxia-regulated genes and how miR-210 may regulate plasticity in more complex mammalian systems. Using a pull-down approach, we identified 620 unique target genes of miR-210 in humans, among which there was a significant enrichment of age-related neurodegenerative pathways, including Huntington’s, Alzheimer’s, and Parkinson’s diseases. We have also validated that miR-210 directly regulates various identified target genes of interest involved with neuronal plasticity, neurodegenerative diseases, and miR-210-associated cancers. This data suggests a potentially novel mechanism for how metabolic changes may couple plasticity to neuronal activity through hypoxia-regulated genes such as miR-210. View Full-Text   Abstract
R-loops are evolutionarily conserved three-stranded structures that result from the formation of stable DNA:RNA hybrids in the genome. R-loops have attracted increasing interest in recent years as potent regulators of gene expression and genome stability. In particular, their strong association with severe replication stress makes them potential oncogenic structures. Despite their importance, the rules that govern their formation and their dynamics are still controversial and an in-depth description of their direct impact on chromatin organization and DNA transactions is still lacking. To better understand the diversity of R-loop functions, reliable, accurate, and quantitative mapping techniques, as well as functional assays are required. Here, I review the different approaches that are currently used to do so and to highlight their individual strengths and weaknesses. In particular, I review the advantages and disadvantages of using the S9.6 antibody to map R-loops in vivo in an attempt to propose guidelines for best practices. View Full-Text   Abstract
The nuclear RNA exosome is an essential and versatile machinery that regulates maturation and degradation of a huge plethora of RNA species. The past two decades have witnessed remarkable progress in understanding the whole picture of its RNA substrates and the structural basis of its functions. In addition to the exosome itself, recent studies focusing on associated co-factors have been elucidating how the exosome is directed towards specific substrates. Moreover, it has been gradually realized that loss-of-function of exosome subunits affect multiple biological processes, such as the DNA damage response, R-loop resolution, maintenance of genome integrity, RNA export, translation, and cell differentiation. In this review, we summarize the current knowledge of the mechanisms of nuclear exosome-mediated RNA metabolism and discuss their physiological significance. View Full-Text   schizophrenia,central nervous system,microRNA,lncRNA,snoRNA,biomarkers   microRNA,hsa-miR-210,microRNA targeting,SH-SY5Y cells,neurodegeneration   R-loops,S9.6,RNase H1,DRIP,R-ChIP   exosome,RNA surveillance,RNA processing,RNA degradation ", Non-Coding RNA 
 Porous (Swiss-Cheese) Graphite   Investigation of the Catalytic Performance of Pd/CNFs for Hydrogen Evolution from Additive-Free Formic Acid Decomposition   Development and Characterization of Biomimetic Carbonated Calcium-Deficient Hydroxyapatite Deposited on Carbon Fiber Scaffold   Supercapacitor Electrode Based on Activated Carbon Wool Felt ," Abstract
Porous graphite was prepared without the use of template by rapidly heating the carbonization products from mixtures of anthracene, fluorene, and pyrene with a CO2 laser. Rapid CO2 laser heating at a rate of 1.8 × 106 °C/s vaporizes out the fluorene-pyrene derived pitch while annealing the anthracene coke. The resulting structure is that of graphite with 100 nm spherical pores. The graphitizablity of the porous material is the same as pure anthracene coke. Transmission electron microscopy revealed that the interfaces between graphitic layers and the pore walls are unimpeded. Traditional furnace annealing does not result in the porous structure as the heating rates are too slow to vaporize out the pitch, thereby illustrating the advantage of fast thermal processing. The resultant porous graphite was prelithiated and used as an anode in lithium ion capacitors. The porous graphite when lithiated had a specific capacity of 200 mAh/g at 100 mA/g. The assembled lithium ion capacitor demonstrated an energy density as high as 75 Wh/kg when cycled between 2.2 V and 4.2 V. View Full-Text   Abstract
In recent years, research efforts have focused on the development of safe and efficient H2 generation/storage materials toward a fuel-cell-based H2 economy as a long-term solution in the near future. Herein, we report the development of Pd nanoparticles supported on carbon nanofibers (CNFs) via sol-immobilisation and impregnation techniques. Thorough characterisation has been carried out by means of XRD, XPS, SEM-EDX, TEM, and BET. The catalysts have been evaluated for the catalytic decomposition of formic acid (HCOOH), which has been identified as a safe and convenient H2 carrier under mild conditions. The influence of preparation method was investigated and catalysts prepared by the sol-immobilisation method showed higher catalytic performance (PdSI/CNF) than their analogues prepared by the impregnation method (PdIMP/CNF). A high turnover frequency (TOF) of 979 h−1 for PdSI/CNF and high selectivity (>99.99%) was obtained at 30 °C for the additive-free formic acid decomposition. Comparison with a Pd/AC (activated charcoal) catalyst synthesised with sol-immobilisation method using as a support activated charcoal (AC) showed an increase of catalytic activity by a factor of four, demonstrating the improved performance by choosing CNFs as the preferred choice of support for the deposition of preformed colloidal Pd nanoparticles. View Full-Text   Abstract
Calcium phosphate and derivatives have been known for decades as bone compatible biomaterials. In this work, the chemical composition, microtexture, and structure of calcium phosphate deposits on carbon cloths were investigated. Three main types of deposits, obtained through variation of current density in using the sono-electrodeposition technique, were elaborated. At low current densities, the deposit consists in a biomimetic, plate-like, carbonated calcium-deficient hydroxyapatite (CDA), likely resulting from the in situ hydrolysis of plate-like octacalcium phosphate (OCP), while at higher current densities the synthesis leads to a needle-like carbonated CDA. At intermediate current densities, a mixture of plate-like and needle-like carbonated CDA is deposited. This established that sono-electrodeposition is a versatile process that allows the coating of the carbon scaffold with biomimetic calcium phosphate while tuning the morphology and chemical composition of the deposited particles, thereby bringing new insights in the development of new biomaterials for bone repair. View Full-Text   Abstract
An electrical double-layer capacitor (EDLC) is based on the physical adsorption/desorption of electrolyte ions onto the surface of electrodes. Due to its high surface area and other properties, such as electrochemical stability and high electrical conductivity, carbon materials are the most widely used materials for EDLC electrodes. In this work, we study an activated carbon felt obtained from sheep wool felt (ACF’f) as a supercapacitor electrode. The ACF’f was characterized by elemental analysis, scanning electron microscopy (SEM), textural analysis, and X-ray photoelectron spectroscopy (XPS). The electrochemical behaviour of the ACF’f was tested in a two-electrode Swagelok®-type, using acidic and basic aqueous electrolytes. At low current densities, the maximum specific capacitance determined from the charge-discharge curves were 163 F·g−1 and 152 F·g−1, in acidic and basic electrolytes, respectively. The capacitance retention at higher current densities was better in acidic electrolyte while, for both electrolytes, the voltammogram of the sample presents a typical capacitive behaviour, being in accordance with the electrochemical results. View Full-Text "," carbonization,laser annealing,mesophase,graphitization,porous carbon   H2 production,formic acid decomposition,green chemistry,renewable feedstock,Pd nanoparticles,carbon nanofibers   carbon scaffold,electrodeposition,calcium phosphates,carbonated calcium-deficient hydroxyapatite,carbon biomaterial   activated carbon fibres,wool,supercapacitor electrode "," Porous (Swiss-Cheese) Graphite   Investigation of the Catalytic Performance of Pd/CNFs for Hydrogen Evolution from Additive-Free Formic Acid Decomposition   Development and Characterization of Biomimetic Carbonated Calcium-Deficient Hydroxyapatite Deposited on Carbon Fiber Scaffold   Supercapacitor Electrode Based on Activated Carbon Wool Felt   Abstract
Porous graphite was prepared without the use of template by rapidly heating the carbonization products from mixtures of anthracene, fluorene, and pyrene with a CO2 laser. Rapid CO2 laser heating at a rate of 1.8 × 106 °C/s vaporizes out the fluorene-pyrene derived pitch while annealing the anthracene coke. The resulting structure is that of graphite with 100 nm spherical pores. The graphitizablity of the porous material is the same as pure anthracene coke. Transmission electron microscopy revealed that the interfaces between graphitic layers and the pore walls are unimpeded. Traditional furnace annealing does not result in the porous structure as the heating rates are too slow to vaporize out the pitch, thereby illustrating the advantage of fast thermal processing. The resultant porous graphite was prelithiated and used as an anode in lithium ion capacitors. The porous graphite when lithiated had a specific capacity of 200 mAh/g at 100 mA/g. The assembled lithium ion capacitor demonstrated an energy density as high as 75 Wh/kg when cycled between 2.2 V and 4.2 V. View Full-Text   Abstract
In recent years, research efforts have focused on the development of safe and efficient H2 generation/storage materials toward a fuel-cell-based H2 economy as a long-term solution in the near future. Herein, we report the development of Pd nanoparticles supported on carbon nanofibers (CNFs) via sol-immobilisation and impregnation techniques. Thorough characterisation has been carried out by means of XRD, XPS, SEM-EDX, TEM, and BET. The catalysts have been evaluated for the catalytic decomposition of formic acid (HCOOH), which has been identified as a safe and convenient H2 carrier under mild conditions. The influence of preparation method was investigated and catalysts prepared by the sol-immobilisation method showed higher catalytic performance (PdSI/CNF) than their analogues prepared by the impregnation method (PdIMP/CNF). A high turnover frequency (TOF) of 979 h−1 for PdSI/CNF and high selectivity (>99.99%) was obtained at 30 °C for the additive-free formic acid decomposition. Comparison with a Pd/AC (activated charcoal) catalyst synthesised with sol-immobilisation method using as a support activated charcoal (AC) showed an increase of catalytic activity by a factor of four, demonstrating the improved performance by choosing CNFs as the preferred choice of support for the deposition of preformed colloidal Pd nanoparticles. View Full-Text   Abstract
Calcium phosphate and derivatives have been known for decades as bone compatible biomaterials. In this work, the chemical composition, microtexture, and structure of calcium phosphate deposits on carbon cloths were investigated. Three main types of deposits, obtained through variation of current density in using the sono-electrodeposition technique, were elaborated. At low current densities, the deposit consists in a biomimetic, plate-like, carbonated calcium-deficient hydroxyapatite (CDA), likely resulting from the in situ hydrolysis of plate-like octacalcium phosphate (OCP), while at higher current densities the synthesis leads to a needle-like carbonated CDA. At intermediate current densities, a mixture of plate-like and needle-like carbonated CDA is deposited. This established that sono-electrodeposition is a versatile process that allows the coating of the carbon scaffold with biomimetic calcium phosphate while tuning the morphology and chemical composition of the deposited particles, thereby bringing new insights in the development of new biomaterials for bone repair. View Full-Text   Abstract
An electrical double-layer capacitor (EDLC) is based on the physical adsorption/desorption of electrolyte ions onto the surface of electrodes. Due to its high surface area and other properties, such as electrochemical stability and high electrical conductivity, carbon materials are the most widely used materials for EDLC electrodes. In this work, we study an activated carbon felt obtained from sheep wool felt (ACF’f) as a supercapacitor electrode. The ACF’f was characterized by elemental analysis, scanning electron microscopy (SEM), textural analysis, and X-ray photoelectron spectroscopy (XPS). The electrochemical behaviour of the ACF’f was tested in a two-electrode Swagelok®-type, using acidic and basic aqueous electrolytes. At low current densities, the maximum specific capacitance determined from the charge-discharge curves were 163 F·g−1 and 152 F·g−1, in acidic and basic electrolytes, respectively. The capacitance retention at higher current densities was better in acidic electrolyte while, for both electrolytes, the voltammogram of the sample presents a typical capacitive behaviour, being in accordance with the electrochemical results. View Full-Text   carbonization,laser annealing,mesophase,graphitization,porous carbon   H2 production,formic acid decomposition,green chemistry,renewable feedstock,Pd nanoparticles,carbon nanofibers   carbon scaffold,electrodeposition,calcium phosphates,carbonated calcium-deficient hydroxyapatite,carbon biomaterial   activated carbon fibres,wool,supercapacitor electrode ", C 
 Fumaric Acid Production: A Biorefinery Perspective   Biodiversity and Enological Potential of Non-Saccharomyces Yeasts from Nemean Vineyards   Yeasts from Different Habitats and Their Potential as Biocontrol Agents   A Review on Established and Emerging Fermentation Schemes for Microbial Production of Polyhydroxyalkanoate (PHA) Biopolyesters ," Abstract
The increasing scarcity of fossil raw materials, together with the need to develop new processes and technology based on renewable sources, and the need to dispose of an increasing amount of biomass-derived waste, have boosted the concept of biorefineries. Both 1G and 2G biorefineries are focused on the obtention of biofuels, chemicals, materials, food and feed from biomass, a renewable resource. Fumaric acid, and most compounds involved in the Kreb cycle, are considered key platform chemicals, not only for being acidulants and additives in the food industry, but also for their prospective use as monomers. This review is focused on the biotechnological processes based on fungi, mainly of the Rhizopus genus, whose main product is fumaric acid, on the process conditions, the bioreactors and modes of operation and on the purification of the acid once it is produced. View Full-Text   Abstract
Vineyards in Nemea, the most important viticultural zone in Greece, were surveyed for indigenous non-Saccharomyces (NS) yeasts of enological potential. NS populations were isolated from the final stage of alcoholic fermentation and identified by a range of molecular methods. The enological profiles of Hanseniaspora guilliermondii, H. osmophila, Lachancea thermotolerans, Starmerella bacillaris and Torulaspora delbrueckii strains were evaluated. Significant interspecies variation was observed in fermentation kinetics. H. osmophila and T. delbrueckii showed the highest capacity for prompt initiation of fermentation, while S. bacillaris achieved a higher fermentation rate in the second half of the process. Significant differences were also observed in the chemical parameters of NS strains. S. bacillaris SbS42 and T. delbrueckii TdS45 were further evaluated in mixed-culture fermentations with Saccharomyces cerevisiae. NS strains achieved lower population densities than S. cerevisiae. SbS42 exhibited a higher death rate than TdS45. The chemical profiles of different ferments were separated by principal component analysis (PCA). Both NS strains were associated with lower levels of ethanol, when compared to single S. cerevisiae inoculation. TdS45 increased the ethyl acetate levels, while SbS42 caused a different production pattern of higher alcohols. This is the first report to explore the enological potential of NS wine yeast populations from Nemea. Based on prominent enological traits identified, the selected S. bacillaris and T. delbrueckii strains may be further exploited as co-culture starters for improving the quality and enhancing the regional character of local wines. View Full-Text   Abstract
Ever since plant diseases began causing losses in viticulture, the control of phytopathogenic fungi has become of vital interest for winemakers. The occurrence of novel pests, fungicide resistance, and changed consumer expectations have led to an enormous demand for novel plant protection strategies. As part of integrated protection measures, antagonistic microorganisms have been investigated to a large extent. Such microorganisms can be applied not only in conventional, but also in organic farming as biological control agents (BCA). Particularly, yeasts were found to be interesting candidates for the development of BCA. Many of these eukaryotic microorganisms are found as part of the phylloplane microflora. In this study, we assessed a set of 38 yeast isolates from different habitats, including the guts of termites, for inhibitory effects against some phytopathogenic fungi that have received less attention in earlier studies. The majority of yeasts were found to interfere with fungi infecting grapevine (Eutypa lata, Botrytis cinerea, and Roesleria subterranea), stone fruits (Monilinia fructicola), or rice (Magnaporte oryzae), as well in vitro and in model experiment on fruits. Although most yeast strains secreted glycoside hydrolases and proteases, attempts to demonstrate direct antagonistic activities of lytic enzymes failed. However, in culture filtrates of the termite yeast Papiliotrema odontotermitis OO5, a low molecular thermostable antagonistic factor was detected. Iron depletion as a BCA mechanism was confirmed for strains of Metschnikowia pulcherrima but not for other yeasts. View Full-Text   Abstract
Polyhydroxyalkanoates (PHA) are microbial biopolyesters utilized as “green plastics”. Their production under controlled conditions resorts to bioreactors operated in different modes. Because PHA biosynthesis constitutes a multiphase process, both feeding strategy and bioreactor operation mode need smart adaptation. Traditional PHA production setups based on batch, repeated batch, fed-batch or cyclic fed-batch processes are often limited in productivity, or display insufficient controllability of polyester composition. For highly diluted substrate streams like is the case of (agro) industrial waste streams, fed-batch enhanced by cell recycling has recently been reported as a viable tool to increase volumetric productivity. As an emerging trend, continuous fermentation processes in single-, two- and multi-stage setups are reported, which bring the kinetics of both microbial growth and PHA accumulation into agreement with process engineering and allow tailoring PHA’s molecular structure. Moreover, we currently witness an increasing number of CO2-based PHA production processes using cyanobacteria; these light-driven processes resort to photobioreactors similar to those used for microalgae cultivation and can be operated both discontinuously and continuously. This development is parallel to the emerging use of methane and syngas as abundantly available gaseous substrates, which also calls for bioreactor systems with optimized gas transfer. The review sheds light on the challenges of diverse PHA production processes in different bioreactor types and operational regimes using miscellaneous microbial production strains such as extremophilic Archaea, chemoheterotrophic eubacteria and phototrophic cyanobacteria. Particular emphasis is dedicated to the limitations and promises of different bioreactor–strain combinations and to efforts devoted to upscaling these processes to industrially relevant scales. View Full-Text "," biorefinery,fumaric acid,waste valorization,bioprocess,bioreactor   non-Saccharomyces yeasts,mixed-culture fermentations,enological traits,yeast genotyping,wine chemical analysis   biological control agents,yeasts,phytopathogenic fungi,competition,lytic enzymes,pulcherrimin,termite   batch,biopolyesters,bioreactor,cell recycling,continuous,chemostat,fed-batch,fermentation,pH-stat,polyhydroxyalkanoate (PHA) "," Fumaric Acid Production: A Biorefinery Perspective   Biodiversity and Enological Potential of Non-Saccharomyces Yeasts from Nemean Vineyards   Yeasts from Different Habitats and Their Potential as Biocontrol Agents   A Review on Established and Emerging Fermentation Schemes for Microbial Production of Polyhydroxyalkanoate (PHA) Biopolyesters   Abstract
The increasing scarcity of fossil raw materials, together with the need to develop new processes and technology based on renewable sources, and the need to dispose of an increasing amount of biomass-derived waste, have boosted the concept of biorefineries. Both 1G and 2G biorefineries are focused on the obtention of biofuels, chemicals, materials, food and feed from biomass, a renewable resource. Fumaric acid, and most compounds involved in the Kreb cycle, are considered key platform chemicals, not only for being acidulants and additives in the food industry, but also for their prospective use as monomers. This review is focused on the biotechnological processes based on fungi, mainly of the Rhizopus genus, whose main product is fumaric acid, on the process conditions, the bioreactors and modes of operation and on the purification of the acid once it is produced. View Full-Text   Abstract
Vineyards in Nemea, the most important viticultural zone in Greece, were surveyed for indigenous non-Saccharomyces (NS) yeasts of enological potential. NS populations were isolated from the final stage of alcoholic fermentation and identified by a range of molecular methods. The enological profiles of Hanseniaspora guilliermondii, H. osmophila, Lachancea thermotolerans, Starmerella bacillaris and Torulaspora delbrueckii strains were evaluated. Significant interspecies variation was observed in fermentation kinetics. H. osmophila and T. delbrueckii showed the highest capacity for prompt initiation of fermentation, while S. bacillaris achieved a higher fermentation rate in the second half of the process. Significant differences were also observed in the chemical parameters of NS strains. S. bacillaris SbS42 and T. delbrueckii TdS45 were further evaluated in mixed-culture fermentations with Saccharomyces cerevisiae. NS strains achieved lower population densities than S. cerevisiae. SbS42 exhibited a higher death rate than TdS45. The chemical profiles of different ferments were separated by principal component analysis (PCA). Both NS strains were associated with lower levels of ethanol, when compared to single S. cerevisiae inoculation. TdS45 increased the ethyl acetate levels, while SbS42 caused a different production pattern of higher alcohols. This is the first report to explore the enological potential of NS wine yeast populations from Nemea. Based on prominent enological traits identified, the selected S. bacillaris and T. delbrueckii strains may be further exploited as co-culture starters for improving the quality and enhancing the regional character of local wines. View Full-Text   Abstract
Ever since plant diseases began causing losses in viticulture, the control of phytopathogenic fungi has become of vital interest for winemakers. The occurrence of novel pests, fungicide resistance, and changed consumer expectations have led to an enormous demand for novel plant protection strategies. As part of integrated protection measures, antagonistic microorganisms have been investigated to a large extent. Such microorganisms can be applied not only in conventional, but also in organic farming as biological control agents (BCA). Particularly, yeasts were found to be interesting candidates for the development of BCA. Many of these eukaryotic microorganisms are found as part of the phylloplane microflora. In this study, we assessed a set of 38 yeast isolates from different habitats, including the guts of termites, for inhibitory effects against some phytopathogenic fungi that have received less attention in earlier studies. The majority of yeasts were found to interfere with fungi infecting grapevine (Eutypa lata, Botrytis cinerea, and Roesleria subterranea), stone fruits (Monilinia fructicola), or rice (Magnaporte oryzae), as well in vitro and in model experiment on fruits. Although most yeast strains secreted glycoside hydrolases and proteases, attempts to demonstrate direct antagonistic activities of lytic enzymes failed. However, in culture filtrates of the termite yeast Papiliotrema odontotermitis OO5, a low molecular thermostable antagonistic factor was detected. Iron depletion as a BCA mechanism was confirmed for strains of Metschnikowia pulcherrima but not for other yeasts. View Full-Text   Abstract
Polyhydroxyalkanoates (PHA) are microbial biopolyesters utilized as “green plastics”. Their production under controlled conditions resorts to bioreactors operated in different modes. Because PHA biosynthesis constitutes a multiphase process, both feeding strategy and bioreactor operation mode need smart adaptation. Traditional PHA production setups based on batch, repeated batch, fed-batch or cyclic fed-batch processes are often limited in productivity, or display insufficient controllability of polyester composition. For highly diluted substrate streams like is the case of (agro) industrial waste streams, fed-batch enhanced by cell recycling has recently been reported as a viable tool to increase volumetric productivity. As an emerging trend, continuous fermentation processes in single-, two- and multi-stage setups are reported, which bring the kinetics of both microbial growth and PHA accumulation into agreement with process engineering and allow tailoring PHA’s molecular structure. Moreover, we currently witness an increasing number of CO2-based PHA production processes using cyanobacteria; these light-driven processes resort to photobioreactors similar to those used for microalgae cultivation and can be operated both discontinuously and continuously. This development is parallel to the emerging use of methane and syngas as abundantly available gaseous substrates, which also calls for bioreactor systems with optimized gas transfer. The review sheds light on the challenges of diverse PHA production processes in different bioreactor types and operational regimes using miscellaneous microbial production strains such as extremophilic Archaea, chemoheterotrophic eubacteria and phototrophic cyanobacteria. Particular emphasis is dedicated to the limitations and promises of different bioreactor–strain combinations and to efforts devoted to upscaling these processes to industrially relevant scales. View Full-Text   biorefinery,fumaric acid,waste valorization,bioprocess,bioreactor   non-Saccharomyces yeasts,mixed-culture fermentations,enological traits,yeast genotyping,wine chemical analysis   biological control agents,yeasts,phytopathogenic fungi,competition,lytic enzymes,pulcherrimin,termite   batch,biopolyesters,bioreactor,cell recycling,continuous,chemostat,fed-batch,fermentation,pH-stat,polyhydroxyalkanoate (PHA) ", Fermentation 
" Impact of Low and Moderate Salinity Water on Plant Performance of Leafy Vegetables in a Recirculating NFT System   Effect of Paclobutrazol Application on Plant Photosynthetic Performance and Leaf Greenness of Herbaceous Peony   Evaluation of a New Mexico Landrace and Two Commercial Chile (Capsicum annuum) Cultivars under Four Furrow Irrigation Schedules   Effect of Irrigation on Growth, Yield, and Chemical Composition of Two Green Bean Cultivars "," Abstract
Two greenhouse experiments were conducted to examine the growth and mineral nutrition of four leafy vegetables in a nutrient film technique (NFT) system with water with low to moderate salinity. In Expt. 1, a nutrient solution was prepared using reverse osmosis (RO) water and treatments consisted of supplementing with RO water, tap water, or nutrient solution. In Expt. 2, nutrient solution was prepared using three different water sources (treatments), namely, RO water, tap water, or tap water, plus sodium chloride (NaCl), and supplementing solution was prepared using the same three water sources at one third strength. For both of the experiments, seeds of pac choi ‘Tokyo Bekana’, ‘Mei Qing Choi’, and ‘Rosie’ (Brassica rapa var. chinensis) and leaf lettuce ‘Tropicana’ (Lactuca sativa) were sown and were grown in a growth chamber. Two weeks after sowing, seedlings were transplanted to the NFT systems. Expt. 1 was conducted from 19 April to 19 May 2016 and Expt. 2 from 6 September to 12 October 2016. In Expt. 1, nitrate (NO3−) and phosphorus (P) levels in the tanks decreased, and potassium (K+) levels reached almost zero at the end of the experiment when supplemented with RO or tap water. However, calcium (Ca2+), magnesium (Mg2+), and sulfate (SO42−) either did not decrease or increased over time. Supplementing water type did not affect the growth of leaf lettuce and ‘Mei Qing Choi’ pac choi; however, fresh weight of ‘Rosie’ pac choi and both fresh and dry weight of ‘Tokyo Bekana’ pac choi were reduced when supplemented with RO water. Leaf sap NO3− was reduced in ‘Tokyo Bekana’ pac choi, but not in other varieties, when supplemented with RO or tap water. Leaf sap K+ decreased in ‘Tokyo Bekana’, but not in other varieties. The supplementing water type did not impact leaf sap Ca2+, regardless of vegetable varieties. In Expt. 2, NO3− in all of the treatments, P in RO water, and K+ in RO or tap water decreased in the last week of the experiment. Other macronutrients did not change substantially over time. The addition of NaCl significantly reduced the growth of all the vegetables. ‘Tropicana’ leaf lettuce was the least tolerant to NaCl, followed by ‘Rosie’ pac choi. Water source did not affect leaf Ca2+, K+, P, SO42−, and Mg2+ except for ‘Tokyo Bekana’ where NaCl addition decreased Ca2+ and Mg2+. Our results indicated that the tested leafy vegetables differed in response to various types of water used as supplementing or as source water. N, P, and especially K, should be supplemented in the late stage of the experiment, while replacing the whole tank nutrient solution is only necessary when Na+ and/Cl− build up to harmful levels. View Full-Text   Abstract
Paclobutrazol (PBZ) has been associated with effects on the photosynthetic capacity of plants. PBZ affects the growth and development of plants in general. However, little is known about the effects of PBZ on photosynthetic performance and related anatomical features of herbaceous peony (Paeonia lactiflora Pall.) leaves. In the present study, PBZ application resulted in a significant reduction in peony plant height. Furthermore, PBZ application significantly increased photosynthetic rate (Pn), transpiration rate (Tr) and water use efficiency (WUE), but significantly decreased intercellular CO2 concentration (Ci) at some stages from the bolting stage to the bud stage of the plants, compared to controls. Moreover, PBZ application increased the maximum quantum yield of PSII photochemistry (Fv/Fm), coefficient of photochemical quenching (qP) and intrinsic PSII efficiency (ΦPSII), but decreased the coefficient of non-photochemical quenching (qN) and non-photochemical quenching (NPQ). Leaves treated with PBZ had a heavy aggregation of chloroplasts close to the cell wall, with distinct grana lamellae, more and bigger starch grains (on average for a chloroplast), and fewer plastoglobuli, as compared to the control. PBZ increased chlorophyll content (SPAD) and the number of chloroplasts in individual cells in the foliar ultrastructure. PBZ-treated leaves had a darker green color with decreased luminosity (L*) and increased hue angle (h°). The results indicated that plants treated with PBZ were superior in terms of increased photosynthetic characteristics when compared with untreated controls. The direct cause of the increase in Pn and leaf greenness of PBZ-treated P. lactiflora may be the increase in chlorophyll content. View Full-Text   Abstract
Commercial and landrace chile (Capsicum annuum) cultivars are cultivated under furrow irrigation systems in Northern New Mexico. Yield and physiological differences between commercial and landrace chile cultivars under furrow irrigation systems have not been evaluated. In 2011 and 2012 two commercial chiles, ‘Sandia’ and ‘NuMex Big Jim’, with one landrace chile, ‘Chimayo’, were evaluated under four irrigation schedules, with irrigation once every 7, 9, 11, and 13-days. These four schedules represent possible water availability for farmers in Northern New Mexico. In 2011 there were inconsistent yield patterns; fresh red chile yield of ‘Chimayo’ at the seven-day interval was 90% more than at the nine-day interval. ‘Sandia’ had 138% better yields at the seven- than at the nine-day interval. ‘Chimayo’ fresh green chile yields at the nine-day interval were 47% better than the seven-day interval. ‘NuMex Big Jim’ fresh green yields were 40% greater at the seven-day interval than the 13-day interval. In 2012 no yield components were statistically different for cultivars across irrigation intervals. This data shows commercial green and landrace chile cultivars can be furrow irrigated as water becomes available on 7, 9, 11, or 13-day intervals with no yield effect. View Full-Text   Abstract
A study was conducted in an environmentally controlled greenhouse to evaluate two green bean cultivars, ‘Bronco’ and ‘Paulista’, under three application volumes of irrigation water based on replacing 100, 80, and 60% of evapotranspiration (ET). The experiment was in a split-plot design with three replications, recording vegetative growth, yield, pod parameters, water use efficiency (WUE), and chemical content of pods. The results showed that there were no differences between 80% ET and 100% ET for most parameters. In addition, 80% of ET increased the pod yield and improved the pod parameters and chemical composition. Therefore, this irrigation treatment can increase green bean productivity and improve pod quality. Reducing water application from 100 to 60% of ET progressively increased WUE. The ‘Bronco’ cultivar had a higher plant height, pod yield, WUE, pod weight, pod diameter, and total fiber amount than ‘Paulista’, while the ‘Paulista’ cultivar was superior in total chlorophyll, number of pods per plant, pod length, P, Ca, Mg, Fe, Cu, protein, vitamin C, titratable acid, and soluble sugar. View Full-Text "," Asian vegetable,hydroponics,marginal water,mineral nutrition,salt tolerance   paclobutrazol,photosynthesis,leaf greenness,herbaceous peony   acequia,chile,commercial cultivars,ecosystem services,irrigation,landraces   Phaseolus vulgaris,vegetative growth,pod quality,chemical composition "," Impact of Low and Moderate Salinity Water on Plant Performance of Leafy Vegetables in a Recirculating NFT System   Effect of Paclobutrazol Application on Plant Photosynthetic Performance and Leaf Greenness of Herbaceous Peony   Evaluation of a New Mexico Landrace and Two Commercial Chile (Capsicum annuum) Cultivars under Four Furrow Irrigation Schedules   Effect of Irrigation on Growth, Yield, and Chemical Composition of Two Green Bean Cultivars   Abstract
Two greenhouse experiments were conducted to examine the growth and mineral nutrition of four leafy vegetables in a nutrient film technique (NFT) system with water with low to moderate salinity. In Expt. 1, a nutrient solution was prepared using reverse osmosis (RO) water and treatments consisted of supplementing with RO water, tap water, or nutrient solution. In Expt. 2, nutrient solution was prepared using three different water sources (treatments), namely, RO water, tap water, or tap water, plus sodium chloride (NaCl), and supplementing solution was prepared using the same three water sources at one third strength. For both of the experiments, seeds of pac choi ‘Tokyo Bekana’, ‘Mei Qing Choi’, and ‘Rosie’ (Brassica rapa var. chinensis) and leaf lettuce ‘Tropicana’ (Lactuca sativa) were sown and were grown in a growth chamber. Two weeks after sowing, seedlings were transplanted to the NFT systems. Expt. 1 was conducted from 19 April to 19 May 2016 and Expt. 2 from 6 September to 12 October 2016. In Expt. 1, nitrate (NO3−) and phosphorus (P) levels in the tanks decreased, and potassium (K+) levels reached almost zero at the end of the experiment when supplemented with RO or tap water. However, calcium (Ca2+), magnesium (Mg2+), and sulfate (SO42−) either did not decrease or increased over time. Supplementing water type did not affect the growth of leaf lettuce and ‘Mei Qing Choi’ pac choi; however, fresh weight of ‘Rosie’ pac choi and both fresh and dry weight of ‘Tokyo Bekana’ pac choi were reduced when supplemented with RO water. Leaf sap NO3− was reduced in ‘Tokyo Bekana’ pac choi, but not in other varieties, when supplemented with RO or tap water. Leaf sap K+ decreased in ‘Tokyo Bekana’, but not in other varieties. The supplementing water type did not impact leaf sap Ca2+, regardless of vegetable varieties. In Expt. 2, NO3− in all of the treatments, P in RO water, and K+ in RO or tap water decreased in the last week of the experiment. Other macronutrients did not change substantially over time. The addition of NaCl significantly reduced the growth of all the vegetables. ‘Tropicana’ leaf lettuce was the least tolerant to NaCl, followed by ‘Rosie’ pac choi. Water source did not affect leaf Ca2+, K+, P, SO42−, and Mg2+ except for ‘Tokyo Bekana’ where NaCl addition decreased Ca2+ and Mg2+. Our results indicated that the tested leafy vegetables differed in response to various types of water used as supplementing or as source water. N, P, and especially K, should be supplemented in the late stage of the experiment, while replacing the whole tank nutrient solution is only necessary when Na+ and/Cl− build up to harmful levels. View Full-Text   Abstract
Paclobutrazol (PBZ) has been associated with effects on the photosynthetic capacity of plants. PBZ affects the growth and development of plants in general. However, little is known about the effects of PBZ on photosynthetic performance and related anatomical features of herbaceous peony (Paeonia lactiflora Pall.) leaves. In the present study, PBZ application resulted in a significant reduction in peony plant height. Furthermore, PBZ application significantly increased photosynthetic rate (Pn), transpiration rate (Tr) and water use efficiency (WUE), but significantly decreased intercellular CO2 concentration (Ci) at some stages from the bolting stage to the bud stage of the plants, compared to controls. Moreover, PBZ application increased the maximum quantum yield of PSII photochemistry (Fv/Fm), coefficient of photochemical quenching (qP) and intrinsic PSII efficiency (ΦPSII), but decreased the coefficient of non-photochemical quenching (qN) and non-photochemical quenching (NPQ). Leaves treated with PBZ had a heavy aggregation of chloroplasts close to the cell wall, with distinct grana lamellae, more and bigger starch grains (on average for a chloroplast), and fewer plastoglobuli, as compared to the control. PBZ increased chlorophyll content (SPAD) and the number of chloroplasts in individual cells in the foliar ultrastructure. PBZ-treated leaves had a darker green color with decreased luminosity (L*) and increased hue angle (h°). The results indicated that plants treated with PBZ were superior in terms of increased photosynthetic characteristics when compared with untreated controls. The direct cause of the increase in Pn and leaf greenness of PBZ-treated P. lactiflora may be the increase in chlorophyll content. View Full-Text   Abstract
Commercial and landrace chile (Capsicum annuum) cultivars are cultivated under furrow irrigation systems in Northern New Mexico. Yield and physiological differences between commercial and landrace chile cultivars under furrow irrigation systems have not been evaluated. In 2011 and 2012 two commercial chiles, ‘Sandia’ and ‘NuMex Big Jim’, with one landrace chile, ‘Chimayo’, were evaluated under four irrigation schedules, with irrigation once every 7, 9, 11, and 13-days. These four schedules represent possible water availability for farmers in Northern New Mexico. In 2011 there were inconsistent yield patterns; fresh red chile yield of ‘Chimayo’ at the seven-day interval was 90% more than at the nine-day interval. ‘Sandia’ had 138% better yields at the seven- than at the nine-day interval. ‘Chimayo’ fresh green chile yields at the nine-day interval were 47% better than the seven-day interval. ‘NuMex Big Jim’ fresh green yields were 40% greater at the seven-day interval than the 13-day interval. In 2012 no yield components were statistically different for cultivars across irrigation intervals. This data shows commercial green and landrace chile cultivars can be furrow irrigated as water becomes available on 7, 9, 11, or 13-day intervals with no yield effect. View Full-Text   Abstract
A study was conducted in an environmentally controlled greenhouse to evaluate two green bean cultivars, ‘Bronco’ and ‘Paulista’, under three application volumes of irrigation water based on replacing 100, 80, and 60% of evapotranspiration (ET). The experiment was in a split-plot design with three replications, recording vegetative growth, yield, pod parameters, water use efficiency (WUE), and chemical content of pods. The results showed that there were no differences between 80% ET and 100% ET for most parameters. In addition, 80% of ET increased the pod yield and improved the pod parameters and chemical composition. Therefore, this irrigation treatment can increase green bean productivity and improve pod quality. Reducing water application from 100 to 60% of ET progressively increased WUE. The ‘Bronco’ cultivar had a higher plant height, pod yield, WUE, pod weight, pod diameter, and total fiber amount than ‘Paulista’, while the ‘Paulista’ cultivar was superior in total chlorophyll, number of pods per plant, pod length, P, Ca, Mg, Fe, Cu, protein, vitamin C, titratable acid, and soluble sugar. View Full-Text   Asian vegetable,hydroponics,marginal water,mineral nutrition,salt tolerance   paclobutrazol,photosynthesis,leaf greenness,herbaceous peony   acequia,chile,commercial cultivars,ecosystem services,irrigation,landraces   Phaseolus vulgaris,vegetative growth,pod quality,chemical composition ", Horticulturae 
" Nuclear Magnetic Resonance Spectroscopy   Microstructure, Martensitic Transformation, and Inverse Magnetocaloric Effect in Ni48Mn39.5Sn12.5−xAlx Metamagnetic Shape Memory Alloys   Effect of Chemical Reaction and Heat Absorption on MHD Nanoliquid Flow Past a Stretching Sheet in the Presence of a Transverse Magnetic Field   Announcing the 2018 Magnetochemistry Travel Award for Post-Doctoral Fellows "," No abstract available View Full-Text   Abstract
The effect of Al substitution on microstructure, martensitic transformation and magnetocaloric properties in Ni48Mn39.5Sn12.5−xAlx (x = 0, 1, 2, 3) alloys is reported. At room temperature, depending on Al concentration, the alloys have typical Heusler L21 austenite structure and/or orthorhombic martensite structure with Pmma space group. A secondary Ni-Mn-Al phase also appears already for low Al concentrations (x ≥ 1). On cooling, irrespective of Al substitution, all the samples show ferromagnetic type ordering below 303 K in the austenite phase. The martensitic transition temperature varies with Al content. All the alloys undergo magnetic field-induced reverse martensitic transformation giving rise to an inverse magnetocaloric effect. The largest magnetic entropy change (8.5 J·kg−1·K−1) is observed near 280 K for the Ni48Mn39.5Sn12.5 alloy. View Full-Text   Abstract
In this paper, authors investigate homogeneous-heterogeneous chemical reaction and heat absorption effects on a two-dimensional steady hydromagnetic Newtonian nanoliquid flow along a continuously stretching sheet. The flow field is subjected to a uniform magnetic field acting in a direction perpendicular to the direction of nanoliquid flow. A mathematical model of the physical problem is presented involving nonlinear partial differential equations with appropriate boundary conditions. These equations are then transformed into nonlinear ordinary differential equations using a suitable similarity transformation. Finally, approximate solutions of the transformed equations are obtained using the spectral quasi-linearization method. Results of fluid velocity, fluid temperature, and species concentration are depicted graphically, while the values of skin friction and Nusselt number are presented in tabular form. Fluid flow models of this kind find applications in catalytic reactors involving chemical reactions, insulation systems, and in heat exchangers. The applied magnetic field has a retarding influence on the nanofluid velocity and species concentration, while it does not have any significant effect on the nanofluid temperature. The homogeneous and heterogeneous reactions tend to decrease the species concentration. View Full-Text   No abstract available View Full-Text ","    martensitic transformation,Heusler alloys,magnetocaloric effect,microstructure   homogeneous-heterogeneous reactions,heat absorption,hydromagnetic flow,stretching sheet,SQLM    "," Nuclear Magnetic Resonance Spectroscopy   Microstructure, Martensitic Transformation, and Inverse Magnetocaloric Effect in Ni48Mn39.5Sn12.5−xAlx Metamagnetic Shape Memory Alloys   Effect of Chemical Reaction and Heat Absorption on MHD Nanoliquid Flow Past a Stretching Sheet in the Presence of a Transverse Magnetic Field   Announcing the 2018 Magnetochemistry Travel Award for Post-Doctoral Fellows   No abstract available View Full-Text   Abstract
The effect of Al substitution on microstructure, martensitic transformation and magnetocaloric properties in Ni48Mn39.5Sn12.5−xAlx (x = 0, 1, 2, 3) alloys is reported. At room temperature, depending on Al concentration, the alloys have typical Heusler L21 austenite structure and/or orthorhombic martensite structure with Pmma space group. A secondary Ni-Mn-Al phase also appears already for low Al concentrations (x ≥ 1). On cooling, irrespective of Al substitution, all the samples show ferromagnetic type ordering below 303 K in the austenite phase. The martensitic transition temperature varies with Al content. All the alloys undergo magnetic field-induced reverse martensitic transformation giving rise to an inverse magnetocaloric effect. The largest magnetic entropy change (8.5 J·kg−1·K−1) is observed near 280 K for the Ni48Mn39.5Sn12.5 alloy. View Full-Text   Abstract
In this paper, authors investigate homogeneous-heterogeneous chemical reaction and heat absorption effects on a two-dimensional steady hydromagnetic Newtonian nanoliquid flow along a continuously stretching sheet. The flow field is subjected to a uniform magnetic field acting in a direction perpendicular to the direction of nanoliquid flow. A mathematical model of the physical problem is presented involving nonlinear partial differential equations with appropriate boundary conditions. These equations are then transformed into nonlinear ordinary differential equations using a suitable similarity transformation. Finally, approximate solutions of the transformed equations are obtained using the spectral quasi-linearization method. Results of fluid velocity, fluid temperature, and species concentration are depicted graphically, while the values of skin friction and Nusselt number are presented in tabular form. Fluid flow models of this kind find applications in catalytic reactors involving chemical reactions, insulation systems, and in heat exchangers. The applied magnetic field has a retarding influence on the nanofluid velocity and species concentration, while it does not have any significant effect on the nanofluid temperature. The homogeneous and heterogeneous reactions tend to decrease the species concentration. View Full-Text   No abstract available View Full-Text      martensitic transformation,Heusler alloys,magnetocaloric effect,microstructure   homogeneous-heterogeneous reactions,heat absorption,hydromagnetic flow,stretching sheet,SQLM    ", Magnetochemistry 
 Announcing the 2018 Magnetochemistry Travel Award for Post-Doctoral Fellows , No abstract available View Full-Text ,  , Announcing the 2018 Magnetochemistry Travel Award for Post-Doctoral Fellows   No abstract available View Full-Text    , Fibers 
 Manufacturing a Better Planet: Challenges Arising from the Gap between the Best Intentions and Social Realities   Key Drivers for High-Grade Recycling under Constrained Conditions   A Green Extraction Process to Recover Polyphenols from Byproducts of Hemp Oil Processing   The Recycling Potential of Submersible Sewage Pumps in the EU ," Abstract
With rising concerns about the social and environmental impacts of industrial and manufacturing waste, scientists and engineers have sought solutions to the burdens of waste which do not simply involve burying, burning, dumping or diluting. Our purpose here is to sketch how social science perspectives can illuminate aspects of the waste problem which are not routinely grappled with within science and engineering perspectives. We argue that if one is concerned about the burdens of waste, it is crucial to understand the way political and cultural contexts shape what happens (or does not happen) in regards to reuse. We sketch some of the challenges facing green manufacturing; challenges that hinge on the gap between the best laid plans and social realities. Rather than imply green manufacturing is simply a post hoc move to hide the excesses of industrial capitalism in the green cloth of sustainability, we hope our discussion can assist those who hope to use green manufacturing as a pre-emptive move to build sustainability into industrial capitalism. We suggest that a socio-political conception of technology can bring greater depth to understandings of the industrial, political and consumer environments into which green manufacturing researchers hope to insert their efforts. View Full-Text   Abstract
Various authors have analyzed the fundamental barriers that hamper the transition towards a circular economy, e.g., economic and business, regulatory and legal, and social. This analysis questions how, under these constrained conditions, high-grade recycling can still be implemented successfully in the Netherlands. The study compares five Dutch material flows: paper and cardboard, plastics, non-wearable textiles, building and demolition waste and mattresses. It is concluded that the following four key conditions should be in place, but need a tailor-made approach for each material flow: (1) adequate collection system/logistics; (2) guaranteed volumes of material supply; (3) clear market demand for and (4) quality guarantee of recycled materials. Moreover, the following five key drivers help circumvent the fundamental barriers and realize the four key conditions: (1) mobilizing power by change agents; (2) cooperation within the material chain; (3) well-attuned financial arrangement; (4) circular procurement; and (5) technological innovation (including redesign). These drivers follow a certain sequence in implementation and circumvent the fundamental barriers each in their own way. This empirical analysis complements the mostly conceptual or theoretical literature on the transition towards high-grade recycling and the circular economy in general. Based on this analysis a conceptual model is developed, in which the key conditions, the key drivers and fundamental barriers are linked. Whether the results also hold true for other countries than the Netherlands needs additional research. View Full-Text   Abstract
The valorization of solid waste hemp (Cannabis sativa L.) by a non-conventional method is presented in this article. Hemp polyphenols were extracted using aqueous solutions of 2-hydroxypropyl-β-cyclodextrin as an eco-friendly extraction solvent. Cyclodextrins (CD’s) are known to enhance the extraction of polyphenols in water by forming water soluble inclusion complexes. The process was optimized by implementing a response surface methodology (RSM) that took into consideration the following independent variables: CD concentration (CCD), solid-to-liquid ratio (S/L), and temperature (T). The assessment of the extraction model was based on two responses: the total polyphenol yield (YTP) and the antiradical activity (AAR). The optimum operating conditions were found to be: CD concentration, 32.1% (w/v); solid/solvent ratio, 1/15.2 g/mL; and extraction temperature, 28 °C. Different kinetic models were employed to fit with experimental data and the Peleg’s model was successfully developed for describing the mechanism of extraction under different processing parameters. View Full-Text   Abstract
Sewage pumps have been among the main electromechanical equipment of the sewage and wastewater management facilities around Europe for over 30 years. Their operational life ranges between 15 and 20 years. Therefore, a significant proportion of that equipment is currently non-operational, and many of them must be disposed of in the forthcoming years. Although the “Waste electrical and electronic equipment” Directive (2012/19/EU) is the main related legislation, sewage pumps are not directly addressed. EcoDesign Legislation is the main legislation applicable on such cases. This work investigates the possibilities of recycling sewage pumps used in wastewater management facilities after their renovation or upgrade. Evaluation results indicate that there is high potential for material recovery and for significant economic benefit. Therefore, the recovery of materials and safe handling of non-operating industrial and possibly hazardous electrical equipment waste, could contribute to the minimization of their impact on the environment. View Full-Text "," green manufacturing,recycling,policy,social science   high-grade recycling,material flows,fundamental barriers,key conditions,key drivers,Dutch examples   antioxidants,hydroxypropyl-β-cyclodextrin,glycerol,Cannabis sativa,kinetic models   sewage pump recycling,WEEE Directive,materials recovery,industrial waste reduction "," Manufacturing a Better Planet: Challenges Arising from the Gap between the Best Intentions and Social Realities   Key Drivers for High-Grade Recycling under Constrained Conditions   A Green Extraction Process to Recover Polyphenols from Byproducts of Hemp Oil Processing   The Recycling Potential of Submersible Sewage Pumps in the EU   Abstract
With rising concerns about the social and environmental impacts of industrial and manufacturing waste, scientists and engineers have sought solutions to the burdens of waste which do not simply involve burying, burning, dumping or diluting. Our purpose here is to sketch how social science perspectives can illuminate aspects of the waste problem which are not routinely grappled with within science and engineering perspectives. We argue that if one is concerned about the burdens of waste, it is crucial to understand the way political and cultural contexts shape what happens (or does not happen) in regards to reuse. We sketch some of the challenges facing green manufacturing; challenges that hinge on the gap between the best laid plans and social realities. Rather than imply green manufacturing is simply a post hoc move to hide the excesses of industrial capitalism in the green cloth of sustainability, we hope our discussion can assist those who hope to use green manufacturing as a pre-emptive move to build sustainability into industrial capitalism. We suggest that a socio-political conception of technology can bring greater depth to understandings of the industrial, political and consumer environments into which green manufacturing researchers hope to insert their efforts. View Full-Text   Abstract
Various authors have analyzed the fundamental barriers that hamper the transition towards a circular economy, e.g., economic and business, regulatory and legal, and social. This analysis questions how, under these constrained conditions, high-grade recycling can still be implemented successfully in the Netherlands. The study compares five Dutch material flows: paper and cardboard, plastics, non-wearable textiles, building and demolition waste and mattresses. It is concluded that the following four key conditions should be in place, but need a tailor-made approach for each material flow: (1) adequate collection system/logistics; (2) guaranteed volumes of material supply; (3) clear market demand for and (4) quality guarantee of recycled materials. Moreover, the following five key drivers help circumvent the fundamental barriers and realize the four key conditions: (1) mobilizing power by change agents; (2) cooperation within the material chain; (3) well-attuned financial arrangement; (4) circular procurement; and (5) technological innovation (including redesign). These drivers follow a certain sequence in implementation and circumvent the fundamental barriers each in their own way. This empirical analysis complements the mostly conceptual or theoretical literature on the transition towards high-grade recycling and the circular economy in general. Based on this analysis a conceptual model is developed, in which the key conditions, the key drivers and fundamental barriers are linked. Whether the results also hold true for other countries than the Netherlands needs additional research. View Full-Text   Abstract
The valorization of solid waste hemp (Cannabis sativa L.) by a non-conventional method is presented in this article. Hemp polyphenols were extracted using aqueous solutions of 2-hydroxypropyl-β-cyclodextrin as an eco-friendly extraction solvent. Cyclodextrins (CD’s) are known to enhance the extraction of polyphenols in water by forming water soluble inclusion complexes. The process was optimized by implementing a response surface methodology (RSM) that took into consideration the following independent variables: CD concentration (CCD), solid-to-liquid ratio (S/L), and temperature (T). The assessment of the extraction model was based on two responses: the total polyphenol yield (YTP) and the antiradical activity (AAR). The optimum operating conditions were found to be: CD concentration, 32.1% (w/v); solid/solvent ratio, 1/15.2 g/mL; and extraction temperature, 28 °C. Different kinetic models were employed to fit with experimental data and the Peleg’s model was successfully developed for describing the mechanism of extraction under different processing parameters. View Full-Text   Abstract
Sewage pumps have been among the main electromechanical equipment of the sewage and wastewater management facilities around Europe for over 30 years. Their operational life ranges between 15 and 20 years. Therefore, a significant proportion of that equipment is currently non-operational, and many of them must be disposed of in the forthcoming years. Although the “Waste electrical and electronic equipment” Directive (2012/19/EU) is the main related legislation, sewage pumps are not directly addressed. EcoDesign Legislation is the main legislation applicable on such cases. This work investigates the possibilities of recycling sewage pumps used in wastewater management facilities after their renovation or upgrade. Evaluation results indicate that there is high potential for material recovery and for significant economic benefit. Therefore, the recovery of materials and safe handling of non-operating industrial and possibly hazardous electrical equipment waste, could contribute to the minimization of their impact on the environment. View Full-Text   green manufacturing,recycling,policy,social science   high-grade recycling,material flows,fundamental barriers,key conditions,key drivers,Dutch examples   antioxidants,hydroxypropyl-β-cyclodextrin,glycerol,Cannabis sativa,kinetic models   sewage pump recycling,WEEE Directive,materials recovery,industrial waste reduction ", Recycling 
 Intra-MRI Extraction of Diagnostic Electrocardiograms Using Carotidal Magnetohydrodynamic Voltages   Transfer Learning from Synthetic Data Applied to Soil–Root Segmentation in X-Ray Tomography Images   Edge-Based and Prediction-Based Transformations for Lossless Image Compression ," Abstract
The electrocardiogram (ECG) is commonly utilized for patient monitoring during magnetic resonance imaging (MRI) despite known magnetohydrodynamic voltage (VMHD) overlays, which often eclipse the true sinus rhythm and render the signal to be non-diagnostic. This can complicate MRI gating and at-risk patient monitoring, causing alternative low-fidelity signals to become preferred. We aimed to develop a method of isolating the true sinus rhythm from VMHD in order to enable the use of high-fidelity ECGs during MRI procedures. Twelve-lead ECGs were acquired in two healthy volunteers (n = 2) in a 3T MRI scanner, while a secondary single lead monitor was positioned across the left common carotid artery to directly record VMHD while cancelling out the true sinus rhythm. Carotid MHD was used to adaptively train a least mean squares filter to update a 12-lead ECG VMHD template and produce: (1) clean 12-lead ECGs and (2) an accurate stroke volume (SV) estimate. The adaptive filtering method was shown to reduce VMHD in 12-lead ECGs. This was demonstrated by an average cross-correlation of 0.81 across all ECG leads calculated between filtered ECG taken inside the MRI scanner and the ECG taken outside the MRI scanner. Residual noise formed <5% of the R-wave amplitude. Additionally, the method required only a short training phase. A method to extract real sinus rhythm beats from intra-MRI 12-lead ECGs was presented and shown to provide accurate dynamic measurements of induced VMHD using flow in the carotid artery as a source of dynamic feedback. View Full-Text   Abstract
One of the most challenging computer vision problems in the plant sciences is the segmentation of roots and soil in X-ray tomography. So far, this has been addressed using classical image analysis methods. In this paper, we address this soil–root segmentation problem in X-ray tomography using a variant of supervised deep learning-based classification called transfer learning where the learning stage is based on simulated data. The robustness of this technique, tested for the first time with this plant science problem, is established using soil–roots with very low contrast in X-ray tomography. We also demonstrate the possibility of efficiently segmenting the root from the soil while learning using purely synthetic soil and roots. View Full-Text   Abstract
Pixelated images are used to transmit data between computing devices that have cameras and screens. Significant compression of pixelated images has been achieved by an “edge-based transformation and entropy coding” (ETEC) algorithm recently proposed by the authors of this paper. The study of ETEC is extended in this paper with a comprehensive performance evaluation. Furthermore, a novel algorithm termed “prediction-based transformation and entropy coding” (PTEC) is proposed in this paper for pixelated images. In the first stage of the PTEC method, the image is divided hierarchically to predict the current pixel using neighboring pixels. In the second stage, the prediction errors are used to form two matrices, where one matrix contains the absolute error value and the other contains the polarity of the prediction error. Finally, entropy coding is applied to the generated matrices. This paper also compares the novel ETEC and PTEC schemes with the existing lossless compression techniques: “joint photographic experts group lossless” (JPEG-LS), “set partitioning in hierarchical trees” (SPIHT) and “differential pulse code modulation” (DPCM). Our results show that, for pixelated images, the new ETEC and PTEC algorithms provide better compression than other schemes. Results also show that PTEC has a lower compression ratio but better computation time than ETEC. Furthermore, when both compression ratio and computation time are taken into consideration, PTEC is more suitable than ETEC for compressing pixelated as well as non-pixelated images. View Full-Text "," electrocardiogram,magnetohydrodynamic,physiological monitoring,MRI   root systems,segmentation,X-ray tomography,transfer learning   Image compression,edge,SPIHT,computation time,pixelated image,JPEG-LS "," Intra-MRI Extraction of Diagnostic Electrocardiograms Using Carotidal Magnetohydrodynamic Voltages   Transfer Learning from Synthetic Data Applied to Soil–Root Segmentation in X-Ray Tomography Images   Edge-Based and Prediction-Based Transformations for Lossless Image Compression   Abstract
The electrocardiogram (ECG) is commonly utilized for patient monitoring during magnetic resonance imaging (MRI) despite known magnetohydrodynamic voltage (VMHD) overlays, which often eclipse the true sinus rhythm and render the signal to be non-diagnostic. This can complicate MRI gating and at-risk patient monitoring, causing alternative low-fidelity signals to become preferred. We aimed to develop a method of isolating the true sinus rhythm from VMHD in order to enable the use of high-fidelity ECGs during MRI procedures. Twelve-lead ECGs were acquired in two healthy volunteers (n = 2) in a 3T MRI scanner, while a secondary single lead monitor was positioned across the left common carotid artery to directly record VMHD while cancelling out the true sinus rhythm. Carotid MHD was used to adaptively train a least mean squares filter to update a 12-lead ECG VMHD template and produce: (1) clean 12-lead ECGs and (2) an accurate stroke volume (SV) estimate. The adaptive filtering method was shown to reduce VMHD in 12-lead ECGs. This was demonstrated by an average cross-correlation of 0.81 across all ECG leads calculated between filtered ECG taken inside the MRI scanner and the ECG taken outside the MRI scanner. Residual noise formed <5% of the R-wave amplitude. Additionally, the method required only a short training phase. A method to extract real sinus rhythm beats from intra-MRI 12-lead ECGs was presented and shown to provide accurate dynamic measurements of induced VMHD using flow in the carotid artery as a source of dynamic feedback. View Full-Text   Abstract
One of the most challenging computer vision problems in the plant sciences is the segmentation of roots and soil in X-ray tomography. So far, this has been addressed using classical image analysis methods. In this paper, we address this soil–root segmentation problem in X-ray tomography using a variant of supervised deep learning-based classification called transfer learning where the learning stage is based on simulated data. The robustness of this technique, tested for the first time with this plant science problem, is established using soil–roots with very low contrast in X-ray tomography. We also demonstrate the possibility of efficiently segmenting the root from the soil while learning using purely synthetic soil and roots. View Full-Text   Abstract
Pixelated images are used to transmit data between computing devices that have cameras and screens. Significant compression of pixelated images has been achieved by an “edge-based transformation and entropy coding” (ETEC) algorithm recently proposed by the authors of this paper. The study of ETEC is extended in this paper with a comprehensive performance evaluation. Furthermore, a novel algorithm termed “prediction-based transformation and entropy coding” (PTEC) is proposed in this paper for pixelated images. In the first stage of the PTEC method, the image is divided hierarchically to predict the current pixel using neighboring pixels. In the second stage, the prediction errors are used to form two matrices, where one matrix contains the absolute error value and the other contains the polarity of the prediction error. Finally, entropy coding is applied to the generated matrices. This paper also compares the novel ETEC and PTEC schemes with the existing lossless compression techniques: “joint photographic experts group lossless” (JPEG-LS), “set partitioning in hierarchical trees” (SPIHT) and “differential pulse code modulation” (DPCM). Our results show that, for pixelated images, the new ETEC and PTEC algorithms provide better compression than other schemes. Results also show that PTEC has a lower compression ratio but better computation time than ETEC. Furthermore, when both compression ratio and computation time are taken into consideration, PTEC is more suitable than ETEC for compressing pixelated as well as non-pixelated images. View Full-Text   electrocardiogram,magnetohydrodynamic,physiological monitoring,MRI   root systems,segmentation,X-ray tomography,transfer learning   Image compression,edge,SPIHT,computation time,pixelated image,JPEG-LS ", Journal of Imaging 
 A Framework Based on a Systems Approach to Developing Safety Indicators in Fish Farming   Evaluation of the Effectiveness of a Gaze-Based Training Intervention on Latent Hazard Anticipation Skills for Young Drivers: A Driving Simulator Study   A Weibull Approach for Enabling Safety-Oriented Decision-Making for Electronic Railway Signaling Systems ," Abstract
The fish farming industry is one of the industries in Norway with the highest occupational fatality and injury rate. Despite the serious health, safety, and environmental issues in the industry, little is done to measure changes in safety over time beyond the traditional Lost Time Injury (LTI) registrations. In this article the objective is twofold; (i) to propose a framework for developing safety indicators based on Systems-Theoretic Process Analysis (STPA), and (ii) to apply the framework to find indicators relevant for hazards in operations where subcontractors participate. STPA uses a hierarchical portrayal of the system in focus, in contrast to sequential models, and views safety as a control problem. It is believed that a systemic approach to indicator development better captures the complex safety challenges in aquaculture. Thirteen indicators are identified within areas such as maintenance, training, and planning. The indicators identified may function as a basis for decisions and actions that must be undertaken to ensure safe operations. View Full-Text   Abstract
A PC-based training program (Road Awareness and Perception Training or RAPT; Pradhan et al., 2009), proven effective for improving young novice drivers’ hazard anticipation skills, did not fully maximize the hazard anticipation performance of young drivers despite the use of similar anticipation scenarios in both, the training and the evaluation drives. The current driving simulator experiment examined the additive effects of expert eye movement videos following RAPT training on young drivers’ hazard anticipation performance compared to video-only and RAPT-only conditions. The study employed a between-subject design in which 36 young participants (aged 18–21) were equally and randomly assigned to one of three experimental conditions, were outfitted with an eye tracker and drove four unique scenarios on a driving simulator to evaluate the effect of treatment on their anticipation skills. The results indicate that the young participants that viewed the videos of expert eye movements following the completion of RAPT showed significant improvements in their hazard anticipation ability (85%) on the subsequent experimental evaluation drives compared to those young drivers who were only exposed to either the RAPT training (61%) or the Video (43%). The results further imply that videos of expert eye movements shown immediately after RAPT training may improve the drivers’ anticipation skills by helping them map and integrate the spatial and tactical knowledge gained in a training program within dynamic driving environments involving latent hazards. View Full-Text   Abstract
This paper presents the advantages of using Weibull distributions, within the context of railway signaling systems, for enabling safety-oriented decision-making. Failure rates are used to statistically model the basic event of fault-tree analysis, and their value sizes the maximum allowable latency of failures to fulfill the safety target for which the system has been designed. Relying on field-return failure data, Weibull parameters have been calculated for an existing electronic signaling system and a comparison with existing predictive reliability data, based on exponential distribution, is provided. Results are discussed in order to drive considerations on the respect of quantitative targets and on the impact that a wrong hypothesis might have on the choice of a given architecture. Despite the huge amount of information gathered through the after-sales logbook used to build reliability distribution, several key elements for reliable estimation of failure rate values are still missing. This might affect the uncertainty of reliability parameters and the effort required to collect all the information. We then present how to intervene when operational failure rates present higher values compared to the theoretical approach: increasing the redundancies of the system or performing preventive maintenance tasks. Possible consequences of unjustified adoption of constant failure rate are presented. Some recommendations are also shared in order to build reliability-oriented logbooks and avoid data censoring phenomena by enhancing the functions of the electronic boards composing the system. View Full-Text "," safety indicator,safety,aquaculture,fish farming,systems thinking   hazard anticipation,training,driving simulation,eye movement,young driver   safety modeling,maintenance modeling,reliability analysis,railway signaling systems,Weibull distribution "," A Framework Based on a Systems Approach to Developing Safety Indicators in Fish Farming   Evaluation of the Effectiveness of a Gaze-Based Training Intervention on Latent Hazard Anticipation Skills for Young Drivers: A Driving Simulator Study   A Weibull Approach for Enabling Safety-Oriented Decision-Making for Electronic Railway Signaling Systems   Abstract
The fish farming industry is one of the industries in Norway with the highest occupational fatality and injury rate. Despite the serious health, safety, and environmental issues in the industry, little is done to measure changes in safety over time beyond the traditional Lost Time Injury (LTI) registrations. In this article the objective is twofold; (i) to propose a framework for developing safety indicators based on Systems-Theoretic Process Analysis (STPA), and (ii) to apply the framework to find indicators relevant for hazards in operations where subcontractors participate. STPA uses a hierarchical portrayal of the system in focus, in contrast to sequential models, and views safety as a control problem. It is believed that a systemic approach to indicator development better captures the complex safety challenges in aquaculture. Thirteen indicators are identified within areas such as maintenance, training, and planning. The indicators identified may function as a basis for decisions and actions that must be undertaken to ensure safe operations. View Full-Text   Abstract
A PC-based training program (Road Awareness and Perception Training or RAPT; Pradhan et al., 2009), proven effective for improving young novice drivers’ hazard anticipation skills, did not fully maximize the hazard anticipation performance of young drivers despite the use of similar anticipation scenarios in both, the training and the evaluation drives. The current driving simulator experiment examined the additive effects of expert eye movement videos following RAPT training on young drivers’ hazard anticipation performance compared to video-only and RAPT-only conditions. The study employed a between-subject design in which 36 young participants (aged 18–21) were equally and randomly assigned to one of three experimental conditions, were outfitted with an eye tracker and drove four unique scenarios on a driving simulator to evaluate the effect of treatment on their anticipation skills. The results indicate that the young participants that viewed the videos of expert eye movements following the completion of RAPT showed significant improvements in their hazard anticipation ability (85%) on the subsequent experimental evaluation drives compared to those young drivers who were only exposed to either the RAPT training (61%) or the Video (43%). The results further imply that videos of expert eye movements shown immediately after RAPT training may improve the drivers’ anticipation skills by helping them map and integrate the spatial and tactical knowledge gained in a training program within dynamic driving environments involving latent hazards. View Full-Text   Abstract
This paper presents the advantages of using Weibull distributions, within the context of railway signaling systems, for enabling safety-oriented decision-making. Failure rates are used to statistically model the basic event of fault-tree analysis, and their value sizes the maximum allowable latency of failures to fulfill the safety target for which the system has been designed. Relying on field-return failure data, Weibull parameters have been calculated for an existing electronic signaling system and a comparison with existing predictive reliability data, based on exponential distribution, is provided. Results are discussed in order to drive considerations on the respect of quantitative targets and on the impact that a wrong hypothesis might have on the choice of a given architecture. Despite the huge amount of information gathered through the after-sales logbook used to build reliability distribution, several key elements for reliable estimation of failure rate values are still missing. This might affect the uncertainty of reliability parameters and the effort required to collect all the information. We then present how to intervene when operational failure rates present higher values compared to the theoretical approach: increasing the redundancies of the system or performing preventive maintenance tasks. Possible consequences of unjustified adoption of constant failure rate are presented. Some recommendations are also shared in order to build reliability-oriented logbooks and avoid data censoring phenomena by enhancing the functions of the electronic boards composing the system. View Full-Text   safety indicator,safety,aquaculture,fish farming,systems thinking   hazard anticipation,training,driving simulation,eye movement,young driver   safety modeling,maintenance modeling,reliability analysis,railway signaling systems,Weibull distribution ", Safety 
" Time, Kinship, and the Nation   Family Genealogy’s Contributions to the Philosophical Problem of Birth   Heroes and Cowards: Genealogy, Subjectivity and War in the Twenty-First Century   Mythological Recuperation and Performance as Agency for Genealogical Return in Djanet Sears’s Afrika Solo "," Abstract
There remains both a great deal of confusion over the nature of kinship and an inappropriate resistance to understanding the nation as one form of kinship, specifically, territorial kinship. Although one finds the relatively early and occasional analysis of the nation in terms of kinship, for example, by Lloyd Fallers, anthropologists, including paradoxically Ernest Gellner, have avoided understanding nationality in this way. Despite Anthony Smith’s attention to ethnie, those associated with nationalism studies have also generally avoided analyzing the nation in terms of kinship, as can be seen by the ill-informed hostility to the category “primoridal”. This article rectifies this mistake by re-examining the category of kinship, along both its vertical, temporal axis and horizontal, geographical axis, with attention to nationality in general and, in particular, in antiquity. View Full-Text   Abstract
The central philosophical problem of birth concerns the fact that it is an event necessary for all events. As such, it is the nihilated a priori of itself—in short, it is lost in an abyss of consciousness. The article engages with the thoughts of Sartre, Ricoeur, Henry, Romano, Marion, and Husserl to explain some facets of abyssal birth. It argues that family genealogy may contribute to the philosophical dialogue about birth. Family genealogy is usually practiced with a methodology oriented to epistemology. At times, however, genealogical research may bring the historical ancestral past to presence as a lived experience, thus grounding birth in transgenerational intersubjectivity. To explain this more fully, the article compares this presence affect with similar affects in history, art, and psychoanalysis. The article does not make the birth-as-abyssal problem—as framed by philosophers—vanish, but it questions considering one’s birth exclusively as epistemological. Presence, though closer to ontology than epistemology, is more accurately classified as phenomenological, being as event rather than event as being. View Full-Text   Abstract
From the wars of Ancient Greece to the collapsing Islamic State in the present, the same, apparently timeless protagonists appear and their stories told and re-told: the heroes, cowards and other combatants. This article proposes a framework which combines a Foucauldian genealogical approach with his conception of the subject as both constituted in relation to code-oriented moralities, and creatively self-formed in relation to ethics-oriented moralities (Foucault 1992, pp. 5, 25), to understand how it is possible to speak meaningfully of heroes and cowards in the age of the drone and the jihadist. Section one will explore the applicability of Foucauldian genealogy as the methodological basis for understanding present combatants in the context of war. The second section will assess Foucault’s ‘modes of subjectivation’ and ‘practices of the self’ (Foucault 1992, p. 28), as a means of analyzing the emergence of the subject of war over millennia, with emphasis on the ethical dimension of subjectivity that can be applied to heroes and cowards. Then the third section will use insights from Homer and Augustine to begin to illustrate how Foucault’s genealogical approach and his conception of ethical subjectivity combine to enable heroes and cowards to be meaningfully spoken of and better understood in the domain of war today. The purpose of such a study is to set out the basis on which political genealogy after Foucault can provide a nuanced conceptualization of subjectivity in modern war, as those subjects are formed, claimed, valorized and criticized by competing entities in contemporary political discourse. View Full-Text   Abstract
This paper is an examination of Djanet Sears’s Afrika Solo (1990) as a unique example of how Blacks in the global diaspora trace their genealogical roots back to Africa. Drawing from research in anthropology, cultural studies, and performance, the paper purports that Sears’s African-Canadian identity is underlined by her recuperation of a heritage, epistemes and performative aesthetics, and, real or imagined, practices that are not just Afrocentric but specifically Yoruba. Essentially, the paper examines Afrika Solo in the context of Black Aesthetic and more significantly as “text” in a Yoruba sense, which constitutes her own way of “going back to get it.” The paper is divided into two parts: the first part presents a general argument about Sears’s journey back to Africa and the culturally-rooted nature of the performance as opposed to feminist/gender readings of same, while the second part explores ways of understanding the play through the lens of Yoruba ritual and its aesthetics. View Full-Text "," nation,territory,kinship,primordial,time,nationalism,boundaries,tribe,ethnic group   abyss of birth,philosophical problem of birth,family genealogy,historical presence,intersubjectivity,transgenerational   war,genealogy,Foucault,subjectivity,drone,soldier,jihadist   culture,Ifá,ritual,Sankofa,Sears "," Time, Kinship, and the Nation   Family Genealogy’s Contributions to the Philosophical Problem of Birth   Heroes and Cowards: Genealogy, Subjectivity and War in the Twenty-First Century   Mythological Recuperation and Performance as Agency for Genealogical Return in Djanet Sears’s Afrika Solo   Abstract
There remains both a great deal of confusion over the nature of kinship and an inappropriate resistance to understanding the nation as one form of kinship, specifically, territorial kinship. Although one finds the relatively early and occasional analysis of the nation in terms of kinship, for example, by Lloyd Fallers, anthropologists, including paradoxically Ernest Gellner, have avoided understanding nationality in this way. Despite Anthony Smith’s attention to ethnie, those associated with nationalism studies have also generally avoided analyzing the nation in terms of kinship, as can be seen by the ill-informed hostility to the category “primoridal”. This article rectifies this mistake by re-examining the category of kinship, along both its vertical, temporal axis and horizontal, geographical axis, with attention to nationality in general and, in particular, in antiquity. View Full-Text   Abstract
The central philosophical problem of birth concerns the fact that it is an event necessary for all events. As such, it is the nihilated a priori of itself—in short, it is lost in an abyss of consciousness. The article engages with the thoughts of Sartre, Ricoeur, Henry, Romano, Marion, and Husserl to explain some facets of abyssal birth. It argues that family genealogy may contribute to the philosophical dialogue about birth. Family genealogy is usually practiced with a methodology oriented to epistemology. At times, however, genealogical research may bring the historical ancestral past to presence as a lived experience, thus grounding birth in transgenerational intersubjectivity. To explain this more fully, the article compares this presence affect with similar affects in history, art, and psychoanalysis. The article does not make the birth-as-abyssal problem—as framed by philosophers—vanish, but it questions considering one’s birth exclusively as epistemological. Presence, though closer to ontology than epistemology, is more accurately classified as phenomenological, being as event rather than event as being. View Full-Text   Abstract
From the wars of Ancient Greece to the collapsing Islamic State in the present, the same, apparently timeless protagonists appear and their stories told and re-told: the heroes, cowards and other combatants. This article proposes a framework which combines a Foucauldian genealogical approach with his conception of the subject as both constituted in relation to code-oriented moralities, and creatively self-formed in relation to ethics-oriented moralities (Foucault 1992, pp. 5, 25), to understand how it is possible to speak meaningfully of heroes and cowards in the age of the drone and the jihadist. Section one will explore the applicability of Foucauldian genealogy as the methodological basis for understanding present combatants in the context of war. The second section will assess Foucault’s ‘modes of subjectivation’ and ‘practices of the self’ (Foucault 1992, p. 28), as a means of analyzing the emergence of the subject of war over millennia, with emphasis on the ethical dimension of subjectivity that can be applied to heroes and cowards. Then the third section will use insights from Homer and Augustine to begin to illustrate how Foucault’s genealogical approach and his conception of ethical subjectivity combine to enable heroes and cowards to be meaningfully spoken of and better understood in the domain of war today. The purpose of such a study is to set out the basis on which political genealogy after Foucault can provide a nuanced conceptualization of subjectivity in modern war, as those subjects are formed, claimed, valorized and criticized by competing entities in contemporary political discourse. View Full-Text   Abstract
This paper is an examination of Djanet Sears’s Afrika Solo (1990) as a unique example of how Blacks in the global diaspora trace their genealogical roots back to Africa. Drawing from research in anthropology, cultural studies, and performance, the paper purports that Sears’s African-Canadian identity is underlined by her recuperation of a heritage, epistemes and performative aesthetics, and, real or imagined, practices that are not just Afrocentric but specifically Yoruba. Essentially, the paper examines Afrika Solo in the context of Black Aesthetic and more significantly as “text” in a Yoruba sense, which constitutes her own way of “going back to get it.” The paper is divided into two parts: the first part presents a general argument about Sears’s journey back to Africa and the culturally-rooted nature of the performance as opposed to feminist/gender readings of same, while the second part explores ways of understanding the play through the lens of Yoruba ritual and its aesthetics. View Full-Text   nation,territory,kinship,primordial,time,nationalism,boundaries,tribe,ethnic group   abyss of birth,philosophical problem of birth,family genealogy,historical presence,intersubjectivity,transgenerational   war,genealogy,Foucault,subjectivity,drone,soldier,jihadist   culture,Ifá,ritual,Sankofa,Sears ", Genealogy 
" Interview with the Guest Editor—Ille C. Gebeshuber   Fog-Harvesting Properties of Dryopteris marginata: Role of Interscalar Microchannels in Water-Channeling   Variation of Goliathus orientalis (Moser, 1909) Elytra Nanostructurations and Their Impact on Wettability "," Abstract
Ille C. Gebeshuber is Professor of Physics at the Institute of Applied Physics at the Vienna University of Technology, Austria, where she graduated and completed her Ph.D. on technical biophysics of the inner ear in 1998. In 1999, she undertook postdoctoral training in scanning probe microscopy and biomimetics at the University of California, Santa Barbara, CA, USA, and soon after she returned to Austria to her home university to work on ion surface interactions, tribology and (bio-)nanotechnology. From 2009 to 2015, she joined the Institute of Microengineering and Nanoelectronics at the National University of Malaysia. During her expeditions, together with her students from cultural diverse backgrounds and expertise, she learned from the rainforest how nature develops well-adapted structures and materials, inspiring her to apply these principles to solve technological problems for humans to face global challenges in a safe and sustainable way. Her research focuses on nanotechnology and biomimetics, and takes a multidisciplinary approach, from biology and engineering to the fine arts and the social sciences. In 2017, she was elected Austrian of the Year in the “Research” category. We asked Ille about her career, her thoughts about the potential of biomimetic nanotechnology, and her experience during her editorship with Biomimetics. View Full-Text   Abstract
Several flora and fauna species found in arid areas have adapted themselves to collect water by developing unique structures and to intake the collected moisture. Apart from the capture of the moisture and fog on the surface, water transport and collection both play an important part in fog-harvesting systems as it prevents the loss of captured water through evaporation and makes the surface available for the capture of water again. Here, we report the remarkable fog collection and water-channeling properties of Dryopteris marginata. The surface of D. marginata has developed an integrated system of multiscale channels so that the water spreads quickly and is transported via these channels very efficiently. These integrated multiscale channels have also been replicated using a facile soft lithography technique to prepare biomimetic surfaces and it has been proved that it is the surface architecture that plays a role in the water transport rather than the material’s properties (waxes present on the surface of the leaves). Based on our studies, we infer that the microlevel hierarchy of the structures make the surface hydrophilic and the multiscale channels allow the efficient passage and transport of water. The understanding of the efficient and well-directed water transport and collection in D. marginata is expected to provide valuable insights to design efficient surfaces for fog-harvesting applications. View Full-Text   Abstract
Among the different species of flower beetles, there is one of particular notoriety: the Goliath beetle. This large insect can grow up to 11 cm long and is well-known for its distinctive black and white shield. In this paper, we focus on a particular Goliathus species: G. orientalis (Moser, 1909). We investigated the variations in properties of both the black and white parts of the upper face of G. orientalis; more precisely, the variation in surface properties with respect to the wettability of these two parts. This work reveals that the white parts of the shield have a higher hydrophobic character when compared to the black regions. While the black parts are slightly hydrophobic (θ = 91 ± 5°) and relatively smooth, the white parts are highly hydrophobic (θ = 130 ± 3°) with strong water adhesion (parahydrophobic); similar to the behavior observed for rose petals. Roughness and morphology analyses revealed significant differences between the two parts, and, hence, may explain the change in wettability. The white surfaces are covered with horizontally aligned nanohairs. Interestingly, vertically aligned microhairs are also present on the white surface. Furthermore, the surfaces of the microhairs are not smooth, they contain nanogrooves that are qualitatively similar to those observed in cactus spines. The nanogrooves may have an extremely important function regarding water harvesting, as they preferentially direct the migration of water droplets; this process could be mimicked in the future to capture and guide a large volume of water. View Full-Text ","    fog-harvesting,water-channeling,biomimetics,soft lithography   natural surface,beetle,wettability,petal effect,nanostructures,bioinspiration "," Interview with the Guest Editor—Ille C. Gebeshuber   Fog-Harvesting Properties of Dryopteris marginata: Role of Interscalar Microchannels in Water-Channeling   Variation of Goliathus orientalis (Moser, 1909) Elytra Nanostructurations and Their Impact on Wettability   Abstract
Ille C. Gebeshuber is Professor of Physics at the Institute of Applied Physics at the Vienna University of Technology, Austria, where she graduated and completed her Ph.D. on technical biophysics of the inner ear in 1998. In 1999, she undertook postdoctoral training in scanning probe microscopy and biomimetics at the University of California, Santa Barbara, CA, USA, and soon after she returned to Austria to her home university to work on ion surface interactions, tribology and (bio-)nanotechnology. From 2009 to 2015, she joined the Institute of Microengineering and Nanoelectronics at the National University of Malaysia. During her expeditions, together with her students from cultural diverse backgrounds and expertise, she learned from the rainforest how nature develops well-adapted structures and materials, inspiring her to apply these principles to solve technological problems for humans to face global challenges in a safe and sustainable way. Her research focuses on nanotechnology and biomimetics, and takes a multidisciplinary approach, from biology and engineering to the fine arts and the social sciences. In 2017, she was elected Austrian of the Year in the “Research” category. We asked Ille about her career, her thoughts about the potential of biomimetic nanotechnology, and her experience during her editorship with Biomimetics. View Full-Text   Abstract
Several flora and fauna species found in arid areas have adapted themselves to collect water by developing unique structures and to intake the collected moisture. Apart from the capture of the moisture and fog on the surface, water transport and collection both play an important part in fog-harvesting systems as it prevents the loss of captured water through evaporation and makes the surface available for the capture of water again. Here, we report the remarkable fog collection and water-channeling properties of Dryopteris marginata. The surface of D. marginata has developed an integrated system of multiscale channels so that the water spreads quickly and is transported via these channels very efficiently. These integrated multiscale channels have also been replicated using a facile soft lithography technique to prepare biomimetic surfaces and it has been proved that it is the surface architecture that plays a role in the water transport rather than the material’s properties (waxes present on the surface of the leaves). Based on our studies, we infer that the microlevel hierarchy of the structures make the surface hydrophilic and the multiscale channels allow the efficient passage and transport of water. The understanding of the efficient and well-directed water transport and collection in D. marginata is expected to provide valuable insights to design efficient surfaces for fog-harvesting applications. View Full-Text   Abstract
Among the different species of flower beetles, there is one of particular notoriety: the Goliath beetle. This large insect can grow up to 11 cm long and is well-known for its distinctive black and white shield. In this paper, we focus on a particular Goliathus species: G. orientalis (Moser, 1909). We investigated the variations in properties of both the black and white parts of the upper face of G. orientalis; more precisely, the variation in surface properties with respect to the wettability of these two parts. This work reveals that the white parts of the shield have a higher hydrophobic character when compared to the black regions. While the black parts are slightly hydrophobic (θ = 91 ± 5°) and relatively smooth, the white parts are highly hydrophobic (θ = 130 ± 3°) with strong water adhesion (parahydrophobic); similar to the behavior observed for rose petals. Roughness and morphology analyses revealed significant differences between the two parts, and, hence, may explain the change in wettability. The white surfaces are covered with horizontally aligned nanohairs. Interestingly, vertically aligned microhairs are also present on the white surface. Furthermore, the surfaces of the microhairs are not smooth, they contain nanogrooves that are qualitatively similar to those observed in cactus spines. The nanogrooves may have an extremely important function regarding water harvesting, as they preferentially direct the migration of water droplets; this process could be mimicked in the future to capture and guide a large volume of water. View Full-Text      fog-harvesting,water-channeling,biomimetics,soft lithography   natural surface,beetle,wettability,petal effect,nanostructures,bioinspiration ", Biomimetics 
" Comment on Kluckow M. Barriers to the Implementation of Newborn Pulse Oximetry Screening: A Different Perspective. Int. J. Neonatal Screen. 2018, 4(1), 4   Expanded Newborn Screening Using Tandem Mass Spectrometry: Seven Years of Experience in Eastern Sicily "," Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
We read the review article by Kluckow M (Barriers to the Implementation of Newborn Pulse Oximetry Screening[...] View Full-Text   Abstract
The expanded newborn screening for selected inborn errors of metabolism (IEM) in Sicily was introduced in 2007 by a Regional project entitled “Early detection of congenital metabolic diseases: expanded neonatal screening”. It established two newborn screening laboratories, for Western and Eastern Sicily, which started their activity in 2011. Here we present the results of expanded screening (excluding phenylketonuria (PKU)) of the Eastern laboratory from January 2011 to December 2017. Our data highlight the importance of the expanded newborn screening as a basic health program to avoid the underestimation of rare diseases and the need of further investigations even when there are no textbook alterations of the metabolic profiles. We performed our analysis on dried blood spot by tandem mass spectrometry, according to Italian guidelines. A total of 196 samples from 60,408 newborns gave positive screening results (recall rate 0.32%) while 12 babies were true positive, including 2 newborns whose mothers resulted in being affected by a metabolic disease. The overall frequency of IEM found in the screening panel was 1:6041 (mothers excluded) or 1:5034 (mothers included). The introduction of MS/MS technology in Sicily has significantly increased the detection of inherited metabolic disorders, including those not previously covered, with a predictable improved outcome for several disorders. View Full-Text "," pulse oximetry,screening,critical congenital heart disease,neonate   newborn screening,mass spectrometry,inherited diseases "," Comment on Kluckow M. Barriers to the Implementation of Newborn Pulse Oximetry Screening: A Different Perspective. Int. J. Neonatal Screen. 2018, 4(1), 4   Expanded Newborn Screening Using Tandem Mass Spectrometry: Seven Years of Experience in Eastern Sicily   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
We read the review article by Kluckow M (Barriers to the Implementation of Newborn Pulse Oximetry Screening[...] View Full-Text   Abstract
The expanded newborn screening for selected inborn errors of metabolism (IEM) in Sicily was introduced in 2007 by a Regional project entitled “Early detection of congenital metabolic diseases: expanded neonatal screening”. It established two newborn screening laboratories, for Western and Eastern Sicily, which started their activity in 2011. Here we present the results of expanded screening (excluding phenylketonuria (PKU)) of the Eastern laboratory from January 2011 to December 2017. Our data highlight the importance of the expanded newborn screening as a basic health program to avoid the underestimation of rare diseases and the need of further investigations even when there are no textbook alterations of the metabolic profiles. We performed our analysis on dried blood spot by tandem mass spectrometry, according to Italian guidelines. A total of 196 samples from 60,408 newborns gave positive screening results (recall rate 0.32%) while 12 babies were true positive, including 2 newborns whose mothers resulted in being affected by a metabolic disease. The overall frequency of IEM found in the screening panel was 1:6041 (mothers excluded) or 1:5034 (mothers included). The introduction of MS/MS technology in Sicily has significantly increased the detection of inherited metabolic disorders, including those not previously covered, with a predictable improved outcome for several disorders. View Full-Text   pulse oximetry,screening,critical congenital heart disease,neonate   newborn screening,mass spectrometry,inherited diseases ", International Journal of Neonatal Screening 
 A Fluorometric Method for the Quantification of Cell Number in Complex Differentiating Osteoblast-Osteocyte Cultures   Rapid Electrophoretic Staining and Destaining of Polyacrylamide Gels   Paramyxovirus Infections in Ex Vivo Lung Slice Cultures of Different Host Species   Intussusception in Young Children: Protocol for Multisite Hospital Sentinel Surveillance in India ," Abstract
Osteoblast/osteocyte cultures continue to emerge as essential tools for bone biology research in vitro. The change in cell number is an important parameter to be considered for investigating osteogenic differentiation. However, there is no reliable method for quantifying absolute cell count in differentiating osteoblast/osteocyte cultures because of their strongly adherent, multi-layered, super-confluent nature, and their accumulated extracellular matrix production which progressively mineralises in vitro. We developed a practical, simple and cost-effective method based on the fluorometric quantification of a nucleic dye, GelRed™, to enumerate cell number in osteoblast/osteocyte cultures. This method may also be suitable for quantifying cell numbers on other mammalian adherent cell types. View Full-Text   Abstract
Coomassie brilliant blue (CBB) dyes have been commonly used for the staining of protein bands in polyacrylamide gel electrophoresis (PAGE) gels. However, the staining and destaining of CBB dyes are time-consuming, and the use of methanol is hazardous to one’s health. I introduce a rapid electrophoretic destaining method using a semi-dry transfer unit and a high current power supply. In this method, ethanol was used instead of the hazardous methanol. Most of the protein bands became visible in 30 min. After a secondary destaining step, residual CBB was completely destained. The detection limit for a tested protein (5 ng) was higher than that of the conventional method. Therefore, this method is superior in its speed, safety, low cost, and sensitivity. View Full-Text   Abstract
In vivo experiments in animal models of disease are of crucial importance for viral tropism and pathogenesis studies. However, these experiments must be complemented with in vitro and ex vivo experiments. Here, we describe a protocol for the preparation and ex vivo infection of lung slices from different mammalian host species with various respiratory paramyxoviruses expressing fluorescent reporter proteins, and suggest follow-up experiments including immunohistochemistry, flow cytometry and confocal microscopy. View Full-Text   Abstract
India has recently introduced a rotavirus vaccine under a universal immunization program. There is limited information on intussusception, an adverse event, following immunization in children from India. We are conducting sentinel surveillance for intussusception in children aged under two years at 19 hospitals. The sentinel sites’ selection followed a multistage process. The surveillance combines retrospective surveillance for 69 months and prospective surveillance for 18 months. The suspected intussusception cases shall be reviewed for capturing confirmed cases and detailed data collection and classification according to Brighton Collaboration criteria. Data shall be analysed to describe epidemiology, trends, regional and seasonal variations, clinical profiles, management modalities, and outcomes of intussusception. The combination of prospective and retrospective surveillance shall be informative about the trend of intussusception over the last seven years in India. At four sites where rotavirus vaccines have been introduced, the change in intussusception trends shall be documented. The potential association with rotavirus vaccines and other vaccines shall be assessed using case-control and self-controlled case series methodology. Results are forthcoming. The results shall support the national vaccine safety surveillance effort by providing baseline estimates of intussusception for continued monitoring. The surveillance protocol and site selection processes shall inform similar vaccine-safety surveillance in India and other developing countries. View Full-Text "," osteoblast,osteocyte,GelRed™,mineralisation,cell number,fluorometric quantification   SDS-PAGE,Coomassie brilliant blue,electrophoresis,staining,destaining   lung slice,paramyxovirus,respiratory virus,ex vivo model,infection,pathogenesis   intussusception,retrospective,prospective,surveillance,rotavirus vaccine "," A Fluorometric Method for the Quantification of Cell Number in Complex Differentiating Osteoblast-Osteocyte Cultures   Rapid Electrophoretic Staining and Destaining of Polyacrylamide Gels   Paramyxovirus Infections in Ex Vivo Lung Slice Cultures of Different Host Species   Intussusception in Young Children: Protocol for Multisite Hospital Sentinel Surveillance in India   Abstract
Osteoblast/osteocyte cultures continue to emerge as essential tools for bone biology research in vitro. The change in cell number is an important parameter to be considered for investigating osteogenic differentiation. However, there is no reliable method for quantifying absolute cell count in differentiating osteoblast/osteocyte cultures because of their strongly adherent, multi-layered, super-confluent nature, and their accumulated extracellular matrix production which progressively mineralises in vitro. We developed a practical, simple and cost-effective method based on the fluorometric quantification of a nucleic dye, GelRed™, to enumerate cell number in osteoblast/osteocyte cultures. This method may also be suitable for quantifying cell numbers on other mammalian adherent cell types. View Full-Text   Abstract
Coomassie brilliant blue (CBB) dyes have been commonly used for the staining of protein bands in polyacrylamide gel electrophoresis (PAGE) gels. However, the staining and destaining of CBB dyes are time-consuming, and the use of methanol is hazardous to one’s health. I introduce a rapid electrophoretic destaining method using a semi-dry transfer unit and a high current power supply. In this method, ethanol was used instead of the hazardous methanol. Most of the protein bands became visible in 30 min. After a secondary destaining step, residual CBB was completely destained. The detection limit for a tested protein (5 ng) was higher than that of the conventional method. Therefore, this method is superior in its speed, safety, low cost, and sensitivity. View Full-Text   Abstract
In vivo experiments in animal models of disease are of crucial importance for viral tropism and pathogenesis studies. However, these experiments must be complemented with in vitro and ex vivo experiments. Here, we describe a protocol for the preparation and ex vivo infection of lung slices from different mammalian host species with various respiratory paramyxoviruses expressing fluorescent reporter proteins, and suggest follow-up experiments including immunohistochemistry, flow cytometry and confocal microscopy. View Full-Text   Abstract
India has recently introduced a rotavirus vaccine under a universal immunization program. There is limited information on intussusception, an adverse event, following immunization in children from India. We are conducting sentinel surveillance for intussusception in children aged under two years at 19 hospitals. The sentinel sites’ selection followed a multistage process. The surveillance combines retrospective surveillance for 69 months and prospective surveillance for 18 months. The suspected intussusception cases shall be reviewed for capturing confirmed cases and detailed data collection and classification according to Brighton Collaboration criteria. Data shall be analysed to describe epidemiology, trends, regional and seasonal variations, clinical profiles, management modalities, and outcomes of intussusception. The combination of prospective and retrospective surveillance shall be informative about the trend of intussusception over the last seven years in India. At four sites where rotavirus vaccines have been introduced, the change in intussusception trends shall be documented. The potential association with rotavirus vaccines and other vaccines shall be assessed using case-control and self-controlled case series methodology. Results are forthcoming. The results shall support the national vaccine safety surveillance effort by providing baseline estimates of intussusception for continued monitoring. The surveillance protocol and site selection processes shall inform similar vaccine-safety surveillance in India and other developing countries. View Full-Text   osteoblast,osteocyte,GelRed™,mineralisation,cell number,fluorometric quantification   SDS-PAGE,Coomassie brilliant blue,electrophoresis,staining,destaining   lung slice,paramyxovirus,respiratory virus,ex vivo model,infection,pathogenesis   intussusception,retrospective,prospective,surveillance,rotavirus vaccine ", Methods and Protocols 
 A Defense of an Amodal Number System   (Mind)-Reading Maps   Cajal’s Law of Dynamic Polarization: Mechanism and Design   How to Make Correct Predictions in False Belief Tasks without Attributing False Beliefs: An Analysis of Alternative Inferences and How to Avoid Them ," Abstract
It has been argued that the approximate number system (ANS) constitutes a problem for the grounded approach to cognition because it implies that some conceptual tasks are performed by non-perceptual systems. The ANS is considered non-perceptual mainly because it processes stimuli from different modalities. Jones (2015) has recently argued that this system has many features (such as being modular) which are characteristic of sensory systems. Additionally, he affirms that traditional sensory systems also process inputs from different modalities. This suggests that the ANS is a perceptual system and therefore it is not problematic for the grounded view. In this paper, I defend the amodal approach to the ANS against these two arguments. In the first place, perceptual systems do not possess the properties attributed to the ANS and therefore these properties do not imply that the ANS is perceptual. In the second place, I will propose that a sensory system only needs to be dedicated to process modality-specific information, which is consistent with responding to inputs from different modalities. I argue that the cross-modal responses exhibited by traditional sensory systems are consistent with modality-specific information whereas some responses exhibited by the ANS are not. View Full-Text   Abstract
In a two-system theory for mind-reading, a flexible system (FS) enables full-blown mind-reading, and an efficient system (ES) enables early mind-reading. Efficient processing differs from flexible processing in terms of restrictions on the kind of input it can take and the kinds of mental states it can ascribe (output). Thus, systems are not continuous and each relies on different representations: the FS on beliefs and other propositional attitudes, and the ES on belief-like states or registrations. There is a conceptual problem in distinguishing the representations each system operates with. They contend that they can solve this problem by appealing to a characterization of registrations based on signature limits, but this does not work. I suggest a solution to this problem. The difference between registration and belief becomes clearer if each vehicle turns out to be different. I offer some reasons in support of this proposal related to the performance of spontaneous-response false belief tasks. View Full-Text   Abstract
Santiago Ramón y Cajal, the primary architect of the neuron doctrine and the law of dynamic polarization, is considered to be the founder of modern neuroscience. At the same time, many philosophers, historians, and neuroscientists agree that modern neuroscience embodies a mechanistic perspective on the explanation of the nervous system. In this paper, I review the extant mechanistic interpretation of Cajal’s contribution to modern neuroscience. Then, I argue that the extant mechanistic interpretation fails to capture the explanatory import of Cajal’s law of dynamic polarization. My claim is that the definitive formulation of Cajal’s law of dynamic polarization, despite its mechanistic inaccuracies, embodies a non-mechanistic pattern of reasoning (i.e., design explanation) that is an integral component of modern neuroscience. View Full-Text   Abstract
The use of new paradigms of false belief tasks (FBT) allowed to reduce the age of children who pass the test from the previous 4 years in the standard version to only 15 months or even a striking 6 months in the nonverbal modification. These results are often taken as evidence that infants already possess an—at least implicit—theory of mind (ToM). We criticize this inferential leap on the grounds that inferring a ToM from the predictive success on a false belief task requires to assume as premise that a belief reasoning is a necessary condition for correct action prediction. It is argued that the FBT does not satisfactorily constrain the predictive means, leaving room for the use of belief-independent inferences (that can rely on the attribution of non-representational mental states or the consideration of behavioral patterns that dispense any reference to other minds). These heuristics, when applied to the FBT, can achieve the same predictive success of a belief-based inference because information provided by the test stimulus allows the recognition of particular situations that can be subsumed by their ‘laws’. Instead of solving this issue by designing a single experimentum crucis that would render unfeasible the use of non-representational inferences, we suggest the application of a set of tests in which, although individually they can support inferences dissociated from a ToM, only an inference that makes use of false beliefs is able to correctly predict all the outcomes. View Full-Text "," perceptual system,grounded cognition,concept empiricism,number representation   cartographic systems,two-systems theory,theory of mind,mind-reading,early social cognitive abilities,false belief task   Cajal,law of dynamic polarization,mechanism,utility,design   false belief task,theory of mind,philosophy of mind "," A Defense of an Amodal Number System   (Mind)-Reading Maps   Cajal’s Law of Dynamic Polarization: Mechanism and Design   How to Make Correct Predictions in False Belief Tasks without Attributing False Beliefs: An Analysis of Alternative Inferences and How to Avoid Them   Abstract
It has been argued that the approximate number system (ANS) constitutes a problem for the grounded approach to cognition because it implies that some conceptual tasks are performed by non-perceptual systems. The ANS is considered non-perceptual mainly because it processes stimuli from different modalities. Jones (2015) has recently argued that this system has many features (such as being modular) which are characteristic of sensory systems. Additionally, he affirms that traditional sensory systems also process inputs from different modalities. This suggests that the ANS is a perceptual system and therefore it is not problematic for the grounded view. In this paper, I defend the amodal approach to the ANS against these two arguments. In the first place, perceptual systems do not possess the properties attributed to the ANS and therefore these properties do not imply that the ANS is perceptual. In the second place, I will propose that a sensory system only needs to be dedicated to process modality-specific information, which is consistent with responding to inputs from different modalities. I argue that the cross-modal responses exhibited by traditional sensory systems are consistent with modality-specific information whereas some responses exhibited by the ANS are not. View Full-Text   Abstract
In a two-system theory for mind-reading, a flexible system (FS) enables full-blown mind-reading, and an efficient system (ES) enables early mind-reading. Efficient processing differs from flexible processing in terms of restrictions on the kind of input it can take and the kinds of mental states it can ascribe (output). Thus, systems are not continuous and each relies on different representations: the FS on beliefs and other propositional attitudes, and the ES on belief-like states or registrations. There is a conceptual problem in distinguishing the representations each system operates with. They contend that they can solve this problem by appealing to a characterization of registrations based on signature limits, but this does not work. I suggest a solution to this problem. The difference between registration and belief becomes clearer if each vehicle turns out to be different. I offer some reasons in support of this proposal related to the performance of spontaneous-response false belief tasks. View Full-Text   Abstract
Santiago Ramón y Cajal, the primary architect of the neuron doctrine and the law of dynamic polarization, is considered to be the founder of modern neuroscience. At the same time, many philosophers, historians, and neuroscientists agree that modern neuroscience embodies a mechanistic perspective on the explanation of the nervous system. In this paper, I review the extant mechanistic interpretation of Cajal’s contribution to modern neuroscience. Then, I argue that the extant mechanistic interpretation fails to capture the explanatory import of Cajal’s law of dynamic polarization. My claim is that the definitive formulation of Cajal’s law of dynamic polarization, despite its mechanistic inaccuracies, embodies a non-mechanistic pattern of reasoning (i.e., design explanation) that is an integral component of modern neuroscience. View Full-Text   Abstract
The use of new paradigms of false belief tasks (FBT) allowed to reduce the age of children who pass the test from the previous 4 years in the standard version to only 15 months or even a striking 6 months in the nonverbal modification. These results are often taken as evidence that infants already possess an—at least implicit—theory of mind (ToM). We criticize this inferential leap on the grounds that inferring a ToM from the predictive success on a false belief task requires to assume as premise that a belief reasoning is a necessary condition for correct action prediction. It is argued that the FBT does not satisfactorily constrain the predictive means, leaving room for the use of belief-independent inferences (that can rely on the attribution of non-representational mental states or the consideration of behavioral patterns that dispense any reference to other minds). These heuristics, when applied to the FBT, can achieve the same predictive success of a belief-based inference because information provided by the test stimulus allows the recognition of particular situations that can be subsumed by their ‘laws’. Instead of solving this issue by designing a single experimentum crucis that would render unfeasible the use of non-representational inferences, we suggest the application of a set of tests in which, although individually they can support inferences dissociated from a ToM, only an inference that makes use of false beliefs is able to correctly predict all the outcomes. View Full-Text   perceptual system,grounded cognition,concept empiricism,number representation   cartographic systems,two-systems theory,theory of mind,mind-reading,early social cognitive abilities,false belief task   Cajal,law of dynamic polarization,mechanism,utility,design   false belief task,theory of mind,philosophy of mind ", Philosophies 
 Robust Secure Authentication and Data Storage with Perfect Secrecy   An Overview of DRAM-Based Security Primitives   Can Ternary Computing Improve Information Assurance?   Evaluating the Efficiency of Physical and Cryptographic Security Solutions for Quantum Immune IoT ," Abstract
We consider an authentication process that makes use of biometric data or the output of a physical unclonable function (PUF), respectively, from an information theoretical point of view. We analyse different definitions of achievability for the authentication model. For the secrecy of the key generated for authentication, these definitions differ in their requirements. In the first work on PUF based authentication, weak secrecy has been used and the corresponding capacity regions have been characterized. The disadvantages of weak secrecy are well known. The ultimate performance criteria for the key are perfect secrecy together with uniform distribution of the key. We derive the corresponding capacity region. We show that, for perfect secrecy and uniform distribution of the key, we can achieve the same rates as for weak secrecy together with a weaker requirement on the distribution of the key. In the classical works on PUF based authentication, it is assumed that the source statistics are known perfectly. This requirement is rarely met in applications. That is why the model is generalized to a compound model, taking into account source uncertainty. We also derive the capacity region for the compound model requiring perfect secrecy. Additionally, we consider results for secure storage using a biometric or PUF source that follow directly from the results for authentication. We also generalize known results for this problem by weakening the assumption concerning the distribution of the data that shall be stored. This allows us to combine source compression and secure storage. View Full-Text   Abstract
Recent developments have increased the demand for adequate security solutions, based on primitives that cannot be easily manipulated or altered, such as hardware-based primitives. Security primitives based on Dynamic Random Access Memory (DRAM) can provide cost-efficient and practical security solutions, especially for resource-constrained devices, such as hardware used in the Internet of Things (IoT), as DRAMs are an intrinsic part of most contemporary computer systems. In this work, we present a comprehensive overview of the literature regarding DRAM-based security primitives and an extended classification of it, based on a number of different criteria. In particular, first, we demonstrate the way in which DRAMs work and present the characteristics being exploited for the implementation of security primitives. Then, we introduce the primitives that can be implemented using DRAM, namely Physical Unclonable Functions (PUFs) and True Random Number Generators (TRNGs), and present the applications of each of the two types of DRAM-based security primitives. We additionally proceed to assess the security such primitives can provide, by discussing potential attacks and defences, as well as the proposed security metrics. Subsequently, we also compare these primitives to other hardware-based security primitives, noting their advantages and shortcomings, and proceed to demonstrate their potential for commercial adoption. Finally, we analyse our classification methodology, by reviewing the criteria employed in our classification and examining their significance. View Full-Text   Abstract
Modern computer microarchitectures build on well-established foundations that have encouraged a pattern of computational homogeneity that many cyberattacks depend on. We suggest that balanced ternary logic can be valuable to Internet of Things (IoT) security, authentication of connected vehicles, as well as hardware and software assurance, and have developed a ternary encryption scheme between a computer and smartcard based on public key exchange through non-secure communication channels to demonstrate the value of balanced ternary systems. The concurrent generation of private keys by the computer and the smartcard uses ternary schemes and cryptographic primitives such as ternary physical unclonable functions. While general purpose ternary computers have not succeeded in general use, heterogeneous computing systems with small ternary computing units dedicated to cryptographic functions have the potential to improve information assurance, and may also be designed to execute binary legacy codes. View Full-Text   Abstract
The threat of quantum-computer-assisted cryptanalysis is forcing the security community to develop new types of security protocols. These solutions must be secure against classical and post-quantum cryptanalysis techniques as well as feasible for all kinds of devices, including energy-restricted Internet of Things (IoT) devices. The quantum immunity can be implemented in the cryptographic layer, e.g., by using recent lattice-based key exchange algorithms NewHope or Frodo, or in the physical layer of wireless communication, by utilizing eavesdropping-resistant secrecy coding techniques. In this study, we explore and compare the feasibility and energy efficiency of selected cryptographic layer and physical layer approaches by applying an evaluation approach that is based on simulation and modeling. In particular, we consider NewHope and Frodo key exchange algorithms as well as novel physical layer secrecy coding approach that is based on polar codes. The results reveal that our proposed physical layer implementation is very competitive with respect to the cryptographic solutions, particularly in short-range wireless communication. We also observed that the total energy consumption is unequally divided between transmitting and receiving devices in all the studied approaches. This may be an advantage when designing security architectures for energy-restricted devices. View Full-Text "," authentication,secure storage,perfect secrecy,privacy leakage   dynamic random access memory (DRAM),physical unclonable function (PUF),true random number generator (TRNG),security primitive,overview   authentication,hardware security,tamper-resistant designs,cryptography,information assurance,ternary computing   communication,security,physical layer security,secrecy coding,post-quantum cryptography,energy-efficiency,Internet of Things (IoT),simulation "," Robust Secure Authentication and Data Storage with Perfect Secrecy   An Overview of DRAM-Based Security Primitives   Can Ternary Computing Improve Information Assurance?   Evaluating the Efficiency of Physical and Cryptographic Security Solutions for Quantum Immune IoT   Abstract
We consider an authentication process that makes use of biometric data or the output of a physical unclonable function (PUF), respectively, from an information theoretical point of view. We analyse different definitions of achievability for the authentication model. For the secrecy of the key generated for authentication, these definitions differ in their requirements. In the first work on PUF based authentication, weak secrecy has been used and the corresponding capacity regions have been characterized. The disadvantages of weak secrecy are well known. The ultimate performance criteria for the key are perfect secrecy together with uniform distribution of the key. We derive the corresponding capacity region. We show that, for perfect secrecy and uniform distribution of the key, we can achieve the same rates as for weak secrecy together with a weaker requirement on the distribution of the key. In the classical works on PUF based authentication, it is assumed that the source statistics are known perfectly. This requirement is rarely met in applications. That is why the model is generalized to a compound model, taking into account source uncertainty. We also derive the capacity region for the compound model requiring perfect secrecy. Additionally, we consider results for secure storage using a biometric or PUF source that follow directly from the results for authentication. We also generalize known results for this problem by weakening the assumption concerning the distribution of the data that shall be stored. This allows us to combine source compression and secure storage. View Full-Text   Abstract
Recent developments have increased the demand for adequate security solutions, based on primitives that cannot be easily manipulated or altered, such as hardware-based primitives. Security primitives based on Dynamic Random Access Memory (DRAM) can provide cost-efficient and practical security solutions, especially for resource-constrained devices, such as hardware used in the Internet of Things (IoT), as DRAMs are an intrinsic part of most contemporary computer systems. In this work, we present a comprehensive overview of the literature regarding DRAM-based security primitives and an extended classification of it, based on a number of different criteria. In particular, first, we demonstrate the way in which DRAMs work and present the characteristics being exploited for the implementation of security primitives. Then, we introduce the primitives that can be implemented using DRAM, namely Physical Unclonable Functions (PUFs) and True Random Number Generators (TRNGs), and present the applications of each of the two types of DRAM-based security primitives. We additionally proceed to assess the security such primitives can provide, by discussing potential attacks and defences, as well as the proposed security metrics. Subsequently, we also compare these primitives to other hardware-based security primitives, noting their advantages and shortcomings, and proceed to demonstrate their potential for commercial adoption. Finally, we analyse our classification methodology, by reviewing the criteria employed in our classification and examining their significance. View Full-Text   Abstract
Modern computer microarchitectures build on well-established foundations that have encouraged a pattern of computational homogeneity that many cyberattacks depend on. We suggest that balanced ternary logic can be valuable to Internet of Things (IoT) security, authentication of connected vehicles, as well as hardware and software assurance, and have developed a ternary encryption scheme between a computer and smartcard based on public key exchange through non-secure communication channels to demonstrate the value of balanced ternary systems. The concurrent generation of private keys by the computer and the smartcard uses ternary schemes and cryptographic primitives such as ternary physical unclonable functions. While general purpose ternary computers have not succeeded in general use, heterogeneous computing systems with small ternary computing units dedicated to cryptographic functions have the potential to improve information assurance, and may also be designed to execute binary legacy codes. View Full-Text   Abstract
The threat of quantum-computer-assisted cryptanalysis is forcing the security community to develop new types of security protocols. These solutions must be secure against classical and post-quantum cryptanalysis techniques as well as feasible for all kinds of devices, including energy-restricted Internet of Things (IoT) devices. The quantum immunity can be implemented in the cryptographic layer, e.g., by using recent lattice-based key exchange algorithms NewHope or Frodo, or in the physical layer of wireless communication, by utilizing eavesdropping-resistant secrecy coding techniques. In this study, we explore and compare the feasibility and energy efficiency of selected cryptographic layer and physical layer approaches by applying an evaluation approach that is based on simulation and modeling. In particular, we consider NewHope and Frodo key exchange algorithms as well as novel physical layer secrecy coding approach that is based on polar codes. The results reveal that our proposed physical layer implementation is very competitive with respect to the cryptographic solutions, particularly in short-range wireless communication. We also observed that the total energy consumption is unequally divided between transmitting and receiving devices in all the studied approaches. This may be an advantage when designing security architectures for energy-restricted devices. View Full-Text   authentication,secure storage,perfect secrecy,privacy leakage   dynamic random access memory (DRAM),physical unclonable function (PUF),true random number generator (TRNG),security primitive,overview   authentication,hardware security,tamper-resistant designs,cryptography,information assurance,ternary computing   communication,security,physical layer security,secrecy coding,post-quantum cryptography,energy-efficiency,Internet of Things (IoT),simulation ", Cryptography 
" Editorial for the Special Issue on Nutritional Requirements in New Fish Species under Culture   On the Status of Threespine Stickleback (Gasterosteus aculeatus Linnaeus 1758) in Lake Bracciano, Italy   The Efficacy of Nile Tilapia (Oreochromis niloticus) Broodstock and Larval Immunization against Streptococcus agalactiae and Aeromonas hydrophila   Evaluation of Fresh Azolla pinnata as a Low-Cost Supplemental Feed for Thai Silver Barb Barbonymus gonionotus "," Abstract
The worldwide interest in developing the culture of nonconventional fish species determines the need to increase knowledge in different aspects of their basic physiology, as well as in the application of such information into practical protocols to be used in their feeding, reproduction, and general handling [...]
View Full-Text   Abstract
For many species, the Mediterranean region harbors distinct lineages that are of conservation concerns. However, many of these are threatened by habitat degradation and by the introduction of non-native species. Here, we assess the status of the native threespine stickleback (Gasterosteus aculeatus) in the Lake Bracciano region in Italy, where stickleback have been historically present. During a dedicated sampling campaign in summer 2015, surveying the potential habitats that sticklebacks commonly occupy, we could not confirm the presence of this species but found introduced species to be often most abundant. Stickleback are thus likely to either have become extinct over the last decades or be on the verge to extinction in the Lake Bracciano region. View Full-Text   Abstract
Streptococcus agalactiae and Aeromonas hydrophila have been recognized as the causative agents of mortality in tilapia larvae with single infection and coinfection. The objective of this study was to evaluate the efficacy of maternal transfer and offspring protection from the immunization of monovalent and bivalent vaccines on Nile tilapia (Oreochromis niloticus) broodstock and larval immunization. Four groups of broodstock were intraperitoneally injected with formalin killed whole-cells of S. agalactiae (Sa group), A. hydrophila (Ah group), the bivalent mixed vaccine of them (Biv group), and phosphate-buffered saline as a control (Pbs group). Immunization of the larvae produced from immunized broodstock with a bivalent vaccine (Biv1 group) and Pbs (Pbs1 group) was performed by immersion at 20 days after hatch. Larvae produced from the Pbs group were unvaccinated as the control (Pbs2 group). Changes in the specific antibody and relative percent survival were measured. The Sa and Ah groups that could increase specific antibodies and protection against pathogenic bacteria were challenged with the homologous bacteria. The Biv group stimulated and protected against both S. agalactiae and A. hydrophila. The specific antibody of the Biv1 group was higher than the Pbs1 and Pbs2 groups. The last observation in this study showed that the relative percent survival of the Biv group after challenged S. agalactiae, A. hydrophila, and coinfection were 74.74 ± 3.18%, 73.81 ± 8.58%, and 71.48 ± 5.70%, respectively. The use of bivalent vaccines on the broodstock and larvae may be a strategy to reduce mortality in Nile tilapia larvae caused by single pathogen infection of S. agalactiae and A. hydrophila, or coinfection with both S. agalactiae and A. hydrophila. View Full-Text   Abstract
Aquatic fern Azolla pinnata comprises significant high food value with a good proportion of protein, vitamins, and minerals. This study was carried out to examine the effect of fresh A. pinnata as a substitution of commercial fish feed (CFF) for Thai silver barb Barbonymus gonionotus. Post fingerlings of B. gonionotus were reared in five treatments, labeled T1 to T5, by substituting 0%, 25%, 50%, 75%, and 100% protein of CFF with A. pinnata protein (dry matter basis) respectively for 56 days. The specific growth rate, net production rate, protein efficiency ratio, proximate composition, and overall conditions of fish were not significantly varied between the fish reared completely with CFF and 25% substitution with A. pinnata. However, a significantly higher profit rate (431.49 USD ha−1 56 day−1) was calculated for fish reared in T2 than other treatments. In contrast, there was a significant reduction of growth and other parameters of the fish that were observed in the case where more than 25% CFF was substituted with A. pinnata. The poorest performance was observed in fish fed completely with A. pinnata, at T5. Based on the results, 25% of CFF of Thai silver barb could be substituted with fresh A. pinnata without significantly lowering their growth and product quality and could contribute significant to a higher profit margin. View Full-Text "," nutrition,energy,protein requirements,practical diets,growers,feeds evaluation   Gasterosteus aculeatus,Mediterranean biota,conservation,ichthyofauna,biogeography   tilapia,maternal immunity,broodstock immunization,larvae immunization,Streptococcus agalactiae,Aeromonas hydrophila   Thai silver barb,fresh Azolla pinnata,commercial fish feed substitution,growth,profit "," Editorial for the Special Issue on Nutritional Requirements in New Fish Species under Culture   On the Status of Threespine Stickleback (Gasterosteus aculeatus Linnaeus 1758) in Lake Bracciano, Italy   The Efficacy of Nile Tilapia (Oreochromis niloticus) Broodstock and Larval Immunization against Streptococcus agalactiae and Aeromonas hydrophila   Evaluation of Fresh Azolla pinnata as a Low-Cost Supplemental Feed for Thai Silver Barb Barbonymus gonionotus   Abstract
The worldwide interest in developing the culture of nonconventional fish species determines the need to increase knowledge in different aspects of their basic physiology, as well as in the application of such information into practical protocols to be used in their feeding, reproduction, and general handling [...]
View Full-Text   Abstract
For many species, the Mediterranean region harbors distinct lineages that are of conservation concerns. However, many of these are threatened by habitat degradation and by the introduction of non-native species. Here, we assess the status of the native threespine stickleback (Gasterosteus aculeatus) in the Lake Bracciano region in Italy, where stickleback have been historically present. During a dedicated sampling campaign in summer 2015, surveying the potential habitats that sticklebacks commonly occupy, we could not confirm the presence of this species but found introduced species to be often most abundant. Stickleback are thus likely to either have become extinct over the last decades or be on the verge to extinction in the Lake Bracciano region. View Full-Text   Abstract
Streptococcus agalactiae and Aeromonas hydrophila have been recognized as the causative agents of mortality in tilapia larvae with single infection and coinfection. The objective of this study was to evaluate the efficacy of maternal transfer and offspring protection from the immunization of monovalent and bivalent vaccines on Nile tilapia (Oreochromis niloticus) broodstock and larval immunization. Four groups of broodstock were intraperitoneally injected with formalin killed whole-cells of S. agalactiae (Sa group), A. hydrophila (Ah group), the bivalent mixed vaccine of them (Biv group), and phosphate-buffered saline as a control (Pbs group). Immunization of the larvae produced from immunized broodstock with a bivalent vaccine (Biv1 group) and Pbs (Pbs1 group) was performed by immersion at 20 days after hatch. Larvae produced from the Pbs group were unvaccinated as the control (Pbs2 group). Changes in the specific antibody and relative percent survival were measured. The Sa and Ah groups that could increase specific antibodies and protection against pathogenic bacteria were challenged with the homologous bacteria. The Biv group stimulated and protected against both S. agalactiae and A. hydrophila. The specific antibody of the Biv1 group was higher than the Pbs1 and Pbs2 groups. The last observation in this study showed that the relative percent survival of the Biv group after challenged S. agalactiae, A. hydrophila, and coinfection were 74.74 ± 3.18%, 73.81 ± 8.58%, and 71.48 ± 5.70%, respectively. The use of bivalent vaccines on the broodstock and larvae may be a strategy to reduce mortality in Nile tilapia larvae caused by single pathogen infection of S. agalactiae and A. hydrophila, or coinfection with both S. agalactiae and A. hydrophila. View Full-Text   Abstract
Aquatic fern Azolla pinnata comprises significant high food value with a good proportion of protein, vitamins, and minerals. This study was carried out to examine the effect of fresh A. pinnata as a substitution of commercial fish feed (CFF) for Thai silver barb Barbonymus gonionotus. Post fingerlings of B. gonionotus were reared in five treatments, labeled T1 to T5, by substituting 0%, 25%, 50%, 75%, and 100% protein of CFF with A. pinnata protein (dry matter basis) respectively for 56 days. The specific growth rate, net production rate, protein efficiency ratio, proximate composition, and overall conditions of fish were not significantly varied between the fish reared completely with CFF and 25% substitution with A. pinnata. However, a significantly higher profit rate (431.49 USD ha−1 56 day−1) was calculated for fish reared in T2 than other treatments. In contrast, there was a significant reduction of growth and other parameters of the fish that were observed in the case where more than 25% CFF was substituted with A. pinnata. The poorest performance was observed in fish fed completely with A. pinnata, at T5. Based on the results, 25% of CFF of Thai silver barb could be substituted with fresh A. pinnata without significantly lowering their growth and product quality and could contribute significant to a higher profit margin. View Full-Text   nutrition,energy,protein requirements,practical diets,growers,feeds evaluation   Gasterosteus aculeatus,Mediterranean biota,conservation,ichthyofauna,biogeography   tilapia,maternal immunity,broodstock immunization,larvae immunization,Streptococcus agalactiae,Aeromonas hydrophila   Thai silver barb,fresh Azolla pinnata,commercial fish feed substitution,growth,profit ", Fishes 
" Suppression of Quantum-Mechanical Collapse in Bosonic Gases with Intrinsic Repulsion: A Brief Review   Effective Control of Chemical Potentials by Rabi Coupling with RF-Fields in Ultracold Mixtures   Formation and Oriented Aggregation of Tabular Hexagonal Silver Particles   Decadal Climate Change in Ny-Ålesund, Svalbard, A Representative Area of the Arctic "," Abstract
It is known that attractive potential ~
−1/
r
2
gives rise to the critical quantum collapse in the framework of the three-dimensional (3D) linear Schrödinger equation. This article summarizes theoretical analysis, chiefly published in several original papers, which demonstrates suppression of the collapse caused by this potential, and the creation of the otherwise missing ground state in a 3D gas of bosonic dipoles pulled by the same potential to the central charge, with repulsive contact interactions between them, represented by the cubic term in the respective Gross–Pitaevskii equation (GPE). In two dimensions (2D), quintic self-repulsion is necessary for the suppression of the collapse; alternatively, this may be provided by the effective quartic repulsion produced by the Lee–Huang–Yang correction to the GPE. 3D states carrying angular momentum are constructed in the model with the symmetry reduced from spherical to cylindrical by an external polarizing field. Interplay of the collapse suppression and miscibility–immiscibility transition is considered in a binary condensate. The consideration of the 3D setting in the form of the many-body quantum system, with the help of the Monte Carlo method, demonstrates that, although the quantum collapse cannot be fully suppressed, the self-trapped states predicted by the GPE exist in the many-body setting as metastable modes protected against the collapse by a tall potential barrier. View Full-Text   Abstract
We show that a linear term coupling the atoms of an ultracold binary mixture provides a simple method to induce an effective and tunable population imbalance between them. This term is easily realized by Rabi coupling between different hyperfine levels of the same atomic species. The resulting effective imbalance holds for one-particle states dressed by the Rabi coupling and obtained by diagonalizing the mixing matrix of the Rabi term. This way of controlling the chemical potentials applies to both bosonic and fermionic atoms and it also allows for spatially- and temporally-dependent imbalances. As a first application, we show that, in the case of two attractive fermionic hyperfine levels with equal chemical potentials coupled by the Rabi pulse, the same superfluid properties of an imbalanced binary mixture are recovered. We finally discuss the properties of m-species mixtures in the presence of SU(m)-invariant interactions. View Full-Text   Abstract
Silver tabular hexagonal particles (<diagonal> = 200 nm) were prepared at 40 °C by the reduction of silver nitrate with ascorbic acid in a solution of a polynaphthalene sulphonic dispersant agent, Daxad 19, in strong acidic conditions. By varying the reaction temperature and thus the dispersion viscosity between 10 °C and 30 °C, mesostructures of silver flat rods and flakes were obtained, the former resulting from linear aggregation of tabular hexagonal particles and the latter formed by intertwined flat rods. The results indicate an easy way to tune the aggregation of particles to obtain ordered mesostructures. View Full-Text   Abstract
In recent decades, global warming hiatus/slowdown has attracted considerable attention and has been strongly debated. Many studies suggested that the Arctic is undergoing rapid warming and significantly contributes to a continual global warming trend rather than a hiatus. In this study, we evaluated the climate changes of Ny-Ålesund, Svalbard, a representative location of the northern North Atlantic sector of the Arctic, based on observational records from 1975–2014. The results showed that the annual warming rate was four times higher than the global mean (+0.76 °C·decade−1) and was also much greater than Arctic average. Additionally, the warming trend of Ny-Ålesund started to slow down since 2005–2006, and our estimates showed that there is a 8–9 years-lagged, but significant, correlation between records of Ny-Ålesund and global HadCRUT4 datasets. This finding indicates that the Arctic was likely experiencing a hiatus pattern, which just appeared later than the low-mid latitudes due to transport processes of atmospheric circulations and ocean currents, heat storage effect of cryospheric components, multidecadal variability of Arctic cyclone activities, etc. This case study provides a new perspective on the global warming hiatus/slowdown debate. View Full-Text "," quantum anomaly,ground state,self-trapping,Bose–Einstein condensate,Gross–Pitaevskii equation,Thomas–Fermi approximation,mean-field approximation,quantum phase transitions,Monte–Carlo method   quantum gases,multicomponent mixtures,rf-fields,Rabi coupling,imbalanced mixtures   metal nanoparticles,1D and 2D nanoparticle structures,nanoparticle oriented aggregation   Arctic,Arctic rapid warming,global warming hiatus,global warming slowdown "," Suppression of Quantum-Mechanical Collapse in Bosonic Gases with Intrinsic Repulsion: A Brief Review   Effective Control of Chemical Potentials by Rabi Coupling with RF-Fields in Ultracold Mixtures   Formation and Oriented Aggregation of Tabular Hexagonal Silver Particles   Decadal Climate Change in Ny-Ålesund, Svalbard, A Representative Area of the Arctic   Abstract
It is known that attractive potential ~
−1/
r
2
gives rise to the critical quantum collapse in the framework of the three-dimensional (3D) linear Schrödinger equation. This article summarizes theoretical analysis, chiefly published in several original papers, which demonstrates suppression of the collapse caused by this potential, and the creation of the otherwise missing ground state in a 3D gas of bosonic dipoles pulled by the same potential to the central charge, with repulsive contact interactions between them, represented by the cubic term in the respective Gross–Pitaevskii equation (GPE). In two dimensions (2D), quintic self-repulsion is necessary for the suppression of the collapse; alternatively, this may be provided by the effective quartic repulsion produced by the Lee–Huang–Yang correction to the GPE. 3D states carrying angular momentum are constructed in the model with the symmetry reduced from spherical to cylindrical by an external polarizing field. Interplay of the collapse suppression and miscibility–immiscibility transition is considered in a binary condensate. The consideration of the 3D setting in the form of the many-body quantum system, with the help of the Monte Carlo method, demonstrates that, although the quantum collapse cannot be fully suppressed, the self-trapped states predicted by the GPE exist in the many-body setting as metastable modes protected against the collapse by a tall potential barrier. View Full-Text   Abstract
We show that a linear term coupling the atoms of an ultracold binary mixture provides a simple method to induce an effective and tunable population imbalance between them. This term is easily realized by Rabi coupling between different hyperfine levels of the same atomic species. The resulting effective imbalance holds for one-particle states dressed by the Rabi coupling and obtained by diagonalizing the mixing matrix of the Rabi term. This way of controlling the chemical potentials applies to both bosonic and fermionic atoms and it also allows for spatially- and temporally-dependent imbalances. As a first application, we show that, in the case of two attractive fermionic hyperfine levels with equal chemical potentials coupled by the Rabi pulse, the same superfluid properties of an imbalanced binary mixture are recovered. We finally discuss the properties of m-species mixtures in the presence of SU(m)-invariant interactions. View Full-Text   Abstract
Silver tabular hexagonal particles (<diagonal> = 200 nm) were prepared at 40 °C by the reduction of silver nitrate with ascorbic acid in a solution of a polynaphthalene sulphonic dispersant agent, Daxad 19, in strong acidic conditions. By varying the reaction temperature and thus the dispersion viscosity between 10 °C and 30 °C, mesostructures of silver flat rods and flakes were obtained, the former resulting from linear aggregation of tabular hexagonal particles and the latter formed by intertwined flat rods. The results indicate an easy way to tune the aggregation of particles to obtain ordered mesostructures. View Full-Text   Abstract
In recent decades, global warming hiatus/slowdown has attracted considerable attention and has been strongly debated. Many studies suggested that the Arctic is undergoing rapid warming and significantly contributes to a continual global warming trend rather than a hiatus. In this study, we evaluated the climate changes of Ny-Ålesund, Svalbard, a representative location of the northern North Atlantic sector of the Arctic, based on observational records from 1975–2014. The results showed that the annual warming rate was four times higher than the global mean (+0.76 °C·decade−1) and was also much greater than Arctic average. Additionally, the warming trend of Ny-Ålesund started to slow down since 2005–2006, and our estimates showed that there is a 8–9 years-lagged, but significant, correlation between records of Ny-Ålesund and global HadCRUT4 datasets. This finding indicates that the Arctic was likely experiencing a hiatus pattern, which just appeared later than the low-mid latitudes due to transport processes of atmospheric circulations and ocean currents, heat storage effect of cryospheric components, multidecadal variability of Arctic cyclone activities, etc. This case study provides a new perspective on the global warming hiatus/slowdown debate. View Full-Text   quantum anomaly,ground state,self-trapping,Bose–Einstein condensate,Gross–Pitaevskii equation,Thomas–Fermi approximation,mean-field approximation,quantum phase transitions,Monte–Carlo method   quantum gases,multicomponent mixtures,rf-fields,Rabi coupling,imbalanced mixtures   metal nanoparticles,1D and 2D nanoparticle structures,nanoparticle oriented aggregation   Arctic,Arctic rapid warming,global warming hiatus,global warming slowdown ", Condensed Matter 
 Simultaneous Ultra-Fast Imaging and Neutron Emission from a Compact Dense Plasma Focus Fusion Device   Superconducting Strips: A Concept in Thermal Neutron Detection   ArCLight—A Compact Dielectric Large-Area Photon Detector ," Abstract
Recently, there has been intense interest in small dense plasma focus (DPF) devices for use as pulsed neutron and X-ray sources. Although DPFs have been studied for decades and scaling laws for neutron yield versus system discharge current and energy have been established (Milanese, M. et al., Eur. Phys. J. D 2003, 27, 77–81), there are notable deviations at low energies due to contributions from both thermonuclear and beam-target interactions (Schmidt, A. et al., Phys. Rev. Lett. 2012, 109, 1–4). For low energy DPFs (100 s of Joules), other empirical scaling laws have been found (Bures, B.L. et al., Phys. Plasmas 2012, 112702, 1–9). Although theoretical mechanisms to explain this change have been proposed, the cause of this reduced efficiency is not well understood. A new apparatus with advanced diagnostic capabilities allows us to probe this regime, including variants in which a piston gas is employed. Several complementary diagnostics of the pinch dynamics and resulting X-ray neutron production are employed to understand the underlying mechanisms involved. This apparatus is unique in its employment of a 50 fs laser-based shadowgraphy system that possesses unprecedented spatio-temporal resolution. View Full-Text   Abstract
In the never-ending quest for better detection efficiency and spatial resolution, various thermal neutron detection schemes have been proposed over the years. Given the presence of some converting layers (typically boron, but 6LiF is also widely used nowadays), the shift towards concepts based on solid state detectors has been steadily increasing and ingenious schemes thereby proposed. However, a trade-off has been always sought for between efficiency and spatial resolution; the problem can be (at least partially) circumvented using more elaborate geometries, but this complicates the sample preparation and detector construction. Thus, viable alternatives must be found. What we proposed (and verified experimentally) is a detection scheme based on the superconducting to normal transition. More precisely, using a boron converting layer, the α particles (generated in the (n, α) reaction) crossing a low critical temperature superconducting strip some 10 µm wide have been detected; the process, bolometric in nature and based on the ionization energy loss, is intrinsically fast and the spatial resolution very appealing. In this work, some of the work done so far will be illustrated, together with the principles of the measurement and various related problems. The realization of the detector is based on industrial deposition and photolitographic techniques well within the grasp of a condensed matter laboratory, so that there is substantial room for improvement over our elementary strip geometry. Some of the plans for future work will also be presented, together with some improvements both in the choice of the materials and the geometry of the detector. View Full-Text   Abstract
ArgonCube Light readout system (ArCLight) is a novel device for detecting scintillation light over large areas with Photon Detection Efficiency (PDE) of the order of a few percent. Its robust technological design allows for efficient use in large-volume particle detectors, such as Liquid Argon Time Projection Chambers (LArTPCs) or liquid scintillator detectors. Due to its dielectric structure it can be placed inside volumes with high electric field. It could potentially replace vacuum PhotoMultiplier Tubes (PMTs) in applications where high PDE is not required. The photon detection efficiency for a 10 × 10 cm2 detector prototype was measured to be in the range of 0.8% to 2.2% across the active area. View Full-Text "," dense plasma focus,neutron source,plasma pinch,shadowgraph   neutron detectors,superconductivity   scintillation,liquid argon,photo-detectors "," Simultaneous Ultra-Fast Imaging and Neutron Emission from a Compact Dense Plasma Focus Fusion Device   Superconducting Strips: A Concept in Thermal Neutron Detection   ArCLight—A Compact Dielectric Large-Area Photon Detector   Abstract
Recently, there has been intense interest in small dense plasma focus (DPF) devices for use as pulsed neutron and X-ray sources. Although DPFs have been studied for decades and scaling laws for neutron yield versus system discharge current and energy have been established (Milanese, M. et al., Eur. Phys. J. D 2003, 27, 77–81), there are notable deviations at low energies due to contributions from both thermonuclear and beam-target interactions (Schmidt, A. et al., Phys. Rev. Lett. 2012, 109, 1–4). For low energy DPFs (100 s of Joules), other empirical scaling laws have been found (Bures, B.L. et al., Phys. Plasmas 2012, 112702, 1–9). Although theoretical mechanisms to explain this change have been proposed, the cause of this reduced efficiency is not well understood. A new apparatus with advanced diagnostic capabilities allows us to probe this regime, including variants in which a piston gas is employed. Several complementary diagnostics of the pinch dynamics and resulting X-ray neutron production are employed to understand the underlying mechanisms involved. This apparatus is unique in its employment of a 50 fs laser-based shadowgraphy system that possesses unprecedented spatio-temporal resolution. View Full-Text   Abstract
In the never-ending quest for better detection efficiency and spatial resolution, various thermal neutron detection schemes have been proposed over the years. Given the presence of some converting layers (typically boron, but 6LiF is also widely used nowadays), the shift towards concepts based on solid state detectors has been steadily increasing and ingenious schemes thereby proposed. However, a trade-off has been always sought for between efficiency and spatial resolution; the problem can be (at least partially) circumvented using more elaborate geometries, but this complicates the sample preparation and detector construction. Thus, viable alternatives must be found. What we proposed (and verified experimentally) is a detection scheme based on the superconducting to normal transition. More precisely, using a boron converting layer, the α particles (generated in the (n, α) reaction) crossing a low critical temperature superconducting strip some 10 µm wide have been detected; the process, bolometric in nature and based on the ionization energy loss, is intrinsically fast and the spatial resolution very appealing. In this work, some of the work done so far will be illustrated, together with the principles of the measurement and various related problems. The realization of the detector is based on industrial deposition and photolitographic techniques well within the grasp of a condensed matter laboratory, so that there is substantial room for improvement over our elementary strip geometry. Some of the plans for future work will also be presented, together with some improvements both in the choice of the materials and the geometry of the detector. View Full-Text   Abstract
ArgonCube Light readout system (ArCLight) is a novel device for detecting scintillation light over large areas with Photon Detection Efficiency (PDE) of the order of a few percent. Its robust technological design allows for efficient use in large-volume particle detectors, such as Liquid Argon Time Projection Chambers (LArTPCs) or liquid scintillator detectors. Due to its dielectric structure it can be placed inside volumes with high electric field. It could potentially replace vacuum PhotoMultiplier Tubes (PMTs) in applications where high PDE is not required. The photon detection efficiency for a 10 × 10 cm2 detector prototype was measured to be in the range of 0.8% to 2.2% across the active area. View Full-Text   dense plasma focus,neutron source,plasma pinch,shadowgraph   neutron detectors,superconductivity   scintillation,liquid argon,photo-detectors ", Instruments 
 Personalized UV Radiation Risk Monitoring Using Wearable Devices and Fuzzy Modeling   Identification of Milling Status Using Vibration Feature Extraction Techniques and Support Vector Machine Classifier   Towards High Productivity in Precision Grinding   Recent Advances in Soft E-Textiles ," Abstract
This paper presents a solution for monitoring of solar ultraviolet (UV) exposure and alerting about risks in real time. The novel system provides smart personalized indications for solar radiation protection. The system consists of a sensing device and a mobile application. The sensing device monitors solar radiation in real time and transmits the values wirelessly to a smart device, in which the mobile application is installed. Then, the mobile application processes the values from the sensory apparatus, based on a fuzzy expert system (FES) created from personal information (hair and eye color, tanning and burning frequency), which are entered by the user answering a short questionnaire. The FES provides an estimation of the recommended time of safe exposure in direct sunlight. The proposed system is designed to be portable (a wearable sensing device and smartphone) and low cost, while supporting multiple users. View Full-Text   Abstract
The objective of this study is to use the vibration signal features of spindles during the cutting processing to identify the different milling statuses in cases of diverse tooling parameter combinations. Accelerometers were placed on a spindle to measure vibration behaviors, and the milling status could be divided into idle cutting, initial feeding, and stable cutting. Vibration signal processing and analysis were conducted in the time domain, as well as in the frequency domain. The original vibration measurements were separated using empirical mode decomposition (EMD) in the time domain, so that the signal features could be extracted in certain frequency bands and the useless signal components and trends could be removed. Multi-scale entropy (MSE) and root mean square (RMS) were computed to extract the time domain features. In the frequency domain, the specific intrinsic mode functions (IMFs) that were decomposed using the EMD method were analyzed by fast fourier transform (FFT) and a frequency normalization technique to extract the features of apparent physical representations. The Fisher scores (FS) of the extracted features are calculated to select the high-priority signal features. The selected high-priority signal features are utilized to identify the different milling statuses through a support vector machine (SVM). The results show that an identification accuracy of 98.21% could be obtained at the Z axis, and the average accuracy would be 95.91% for the three axes combination. View Full-Text   Abstract
Over the last century, substantial advances have been made, based on improved understanding of the requirements of grinding processes, machines, control systems, materials, abrasives, wheel preparation, coolants, lubricants, and coolant delivery. This paper reviews a selection of areas in which the application of scientific principles and engineering ingenuity has led to the development of new grinding processes, abrasives, tools, machines, and systems. Topics feature a selection of areas where relationships between scientific principles and new techniques are yielding improved productivity and better quality. These examples point towards further advances that can fruitfully be pursued. Applications in modern grinding technology range from high-precision kinematics for grinding very large lenses and reflectors through to medium size grinding machine processes and further down to grinding very small components used in micro electro-mechanical systems (MEMS) devices. The importance of material issues is emphasized for the range of conventional engineering steels, through to aerospace materials, ceramics, and composites. It is suggested that future advances in productivity will include the wider application of artificial intelligence and robotics to improve precision, process efficiency, and features required to integrate grinding processes into wider manufacturing systems. View Full-Text   Abstract
E-textiles (electronic textiles) are fabrics that possesses electronic counterparts and electrical interconnects knitted into them, offering flexibility, stretchability, and a characteristic length scale that cannot be accomplished using other electronic manufacturing methods currently available. However, knitting is only one of the technologies in e-Textile integration. Other technologies, such as sewing, embroidery, and even single fiber-based manufacture technology, are widely employed in next-generation e-textiles. Components and interconnections are barely visible since they are connected intrinsically to soft fabrics that have attracted the attention of those in the fashion and textile industries. These textiles can effortlessly acclimatize themselves to the fast-changing wearable electronic markets with digital, computational, energy storage, and sensing requirements of any specific application. This mini-review focuses on recent advances in the field of e-textiles and focuses particularly on the materials and their functionalities. View Full-Text "," UV radiation,UV sunlight,personalized healthcare,fuzzy expert system,monitoring systems   milling status identification,multi-scale entropy,empirical mode decomposition,Fisher score,support vector machine   grinding,processes,wheels,machines,systems,control,removal rates,precision,sensors,micro-grinding,coolant,lubrication,coolant delivery   textiles,smart fabrics,smart sensing,fibers,electronic textiles "," Personalized UV Radiation Risk Monitoring Using Wearable Devices and Fuzzy Modeling   Identification of Milling Status Using Vibration Feature Extraction Techniques and Support Vector Machine Classifier   Towards High Productivity in Precision Grinding   Recent Advances in Soft E-Textiles   Abstract
This paper presents a solution for monitoring of solar ultraviolet (UV) exposure and alerting about risks in real time. The novel system provides smart personalized indications for solar radiation protection. The system consists of a sensing device and a mobile application. The sensing device monitors solar radiation in real time and transmits the values wirelessly to a smart device, in which the mobile application is installed. Then, the mobile application processes the values from the sensory apparatus, based on a fuzzy expert system (FES) created from personal information (hair and eye color, tanning and burning frequency), which are entered by the user answering a short questionnaire. The FES provides an estimation of the recommended time of safe exposure in direct sunlight. The proposed system is designed to be portable (a wearable sensing device and smartphone) and low cost, while supporting multiple users. View Full-Text   Abstract
The objective of this study is to use the vibration signal features of spindles during the cutting processing to identify the different milling statuses in cases of diverse tooling parameter combinations. Accelerometers were placed on a spindle to measure vibration behaviors, and the milling status could be divided into idle cutting, initial feeding, and stable cutting. Vibration signal processing and analysis were conducted in the time domain, as well as in the frequency domain. The original vibration measurements were separated using empirical mode decomposition (EMD) in the time domain, so that the signal features could be extracted in certain frequency bands and the useless signal components and trends could be removed. Multi-scale entropy (MSE) and root mean square (RMS) were computed to extract the time domain features. In the frequency domain, the specific intrinsic mode functions (IMFs) that were decomposed using the EMD method were analyzed by fast fourier transform (FFT) and a frequency normalization technique to extract the features of apparent physical representations. The Fisher scores (FS) of the extracted features are calculated to select the high-priority signal features. The selected high-priority signal features are utilized to identify the different milling statuses through a support vector machine (SVM). The results show that an identification accuracy of 98.21% could be obtained at the Z axis, and the average accuracy would be 95.91% for the three axes combination. View Full-Text   Abstract
Over the last century, substantial advances have been made, based on improved understanding of the requirements of grinding processes, machines, control systems, materials, abrasives, wheel preparation, coolants, lubricants, and coolant delivery. This paper reviews a selection of areas in which the application of scientific principles and engineering ingenuity has led to the development of new grinding processes, abrasives, tools, machines, and systems. Topics feature a selection of areas where relationships between scientific principles and new techniques are yielding improved productivity and better quality. These examples point towards further advances that can fruitfully be pursued. Applications in modern grinding technology range from high-precision kinematics for grinding very large lenses and reflectors through to medium size grinding machine processes and further down to grinding very small components used in micro electro-mechanical systems (MEMS) devices. The importance of material issues is emphasized for the range of conventional engineering steels, through to aerospace materials, ceramics, and composites. It is suggested that future advances in productivity will include the wider application of artificial intelligence and robotics to improve precision, process efficiency, and features required to integrate grinding processes into wider manufacturing systems. View Full-Text   Abstract
E-textiles (electronic textiles) are fabrics that possesses electronic counterparts and electrical interconnects knitted into them, offering flexibility, stretchability, and a characteristic length scale that cannot be accomplished using other electronic manufacturing methods currently available. However, knitting is only one of the technologies in e-Textile integration. Other technologies, such as sewing, embroidery, and even single fiber-based manufacture technology, are widely employed in next-generation e-textiles. Components and interconnections are barely visible since they are connected intrinsically to soft fabrics that have attracted the attention of those in the fashion and textile industries. These textiles can effortlessly acclimatize themselves to the fast-changing wearable electronic markets with digital, computational, energy storage, and sensing requirements of any specific application. This mini-review focuses on recent advances in the field of e-textiles and focuses particularly on the materials and their functionalities. View Full-Text   UV radiation,UV sunlight,personalized healthcare,fuzzy expert system,monitoring systems   milling status identification,multi-scale entropy,empirical mode decomposition,Fisher score,support vector machine   grinding,processes,wheels,machines,systems,control,removal rates,precision,sensors,micro-grinding,coolant,lubrication,coolant delivery   textiles,smart fabrics,smart sensing,fibers,electronic textiles ", Inventions 
 Biochemical Profile and Body Composition Alteration of Amateur Bodybuilders during the Pre-Contest Period   Preventing Violence and Social Exclusion through Sport and Physical Activity: The SAVE Project   Exploring the Use of 3D Scanning to Determine Whole-Body Volume While Wearing a Triathlon Wetsuit   The “Journal of Functional Morphology and Kinesiology” Journal Club Series: Highlights on Recent Papers in Physical Activity and Sedentary Behavior ," Abstract
The paper aims to analyze body composition and biochemical profile alterations in amateur bodybuilders during the cutting phase of a contest preparation, and to discuss them in light of scientific evidence. For the purpose of this study, bodybuilders and coaches provided details of drug administration, supplement use and training schedule. The four participants were two men competing in different Men’s Physique categories, one woman in the Wellness category, and one woman competing in the Bikini category. Participants were evaluated for anthropometry and body composition before and after the cutting phase. There was an evident decrease in body fat for most of the participants during the cutting phase without evident loss of fat-free mass. In general, participants performed high volume resistance training combined with aerobic training. Regarding drug administration, participants used high doses of anabolic androgen steroids (AAS), combined with clenbuterol, thyroid hormone, and ephedrine. Blood analysis revealed alterations in lipid profiles, with increased total cholesterol and low-density lipoprotein (LDL), and reduced high-density lipoprotein (HDL) levels. There were marked alterations in markers of liver (aspartate aminotransferase) and cardiac (MB isoenzyme creatine kinase) damage. Our analysis suggests that the strategies adopted by bodybuilders during the pre-contest phase (high use of AAS and stimulant-based substances) may result in an increased risk of heart disease and liver dysfunction. View Full-Text   Abstract
Sport Against Violence and Exclusion (SAVE), a project cofounded by the Erasmus + Program of the European Union, seeks to prevent violent and socially exclusive behaviors through physical activity. The current editorial shows a range of possible interpretations of these two phenomena from both a psychological and sociological point of view, offering helpful methods to coaches who train children (ages 6 to 12)in grass-root sport clubs. Following a thorough analysis, partners from seven EU countries (Lithuania, Italy, Croatia, Bosnia and Herzegovina, Serbia, Austria, and Spain) will be able to identify skills and techniques for coaches to ensure inclusive training methods as well as to provide them with effective conflict resolution tools. Furthermore, both trainers and parents will have access to an online platform with useful information regarding these issues. View Full-Text   Abstract
Background: Commercial 3 Dimension (3D) scanners are relatively new to anthropometry. The purpose of this study was to explore ability of using a 3D imaging instrument to measure body volume with and without wearing a wetsuit. Three experiments were conducted to achieve this purpose: (1) to determine if the 3D imaging instrument could accurately measure volume of static objects; (2) to determine the resolution of accuracy of measuring volume of static objects; and (3) to compare whole-body volume of wearing a wetsuit using 3D imaging as well as another body volume measure (air displacement technique). Methods: Three experiments were performed: (1) measurement of volume of a mannequin head and a box using a 3D scanner, water displacement (for mannequin head), and dimension measurements (for box) techniques for determining volume, (2) volume measurements of 1, 2, and 3 layers of neoprene to assess the resolution capabilities of the 3D scanner, and (3) body volume with and without wearing a wetsuit using a 3D scanner and BodPod (air displacement instrument). Results: (1) Mannequin head volume using the 3D scanner was 1.46% greater than a water displacement technique; the box volume from scanning was significantly greater than volume calculated by measuring dimensions of a box. (2) The volume of a single layer of neoprene was 25.3% less with scanning than the criterion; the volume of two layers was 27.2% less than the criterion; the volume of three layers was not significantly different from the criterion. (3) Body volume was not influenced by the interaction of wetsuit and device; body volume was on average 5% greater with wetsuit than without regardless of instrument. Conclusions: We demonstrated that body volume as measured by a 3D scanner increased when a wetsuit was worn. View Full-Text   Abstract
We are glad to introduce the sixth Journal Club. This edition is focused on several relevant studies published in the last years in the field of physical activity and sedentary behavior, chosen by our Editorial Board members and their colleagues. We hope to stimulate your curiosity in this field and to share with you the passion for the sport seen also from the scientific point of view. The Editorial Board members wish you an inspiring lecture. View Full-Text "," ergogenic aids,muscle hypertrophy,fat loss,resistance training,aerobic exercise      3 Dimension (3D) scan,wetsuit fitting,anthropometrics    "," Biochemical Profile and Body Composition Alteration of Amateur Bodybuilders during the Pre-Contest Period   Preventing Violence and Social Exclusion through Sport and Physical Activity: The SAVE Project   Exploring the Use of 3D Scanning to Determine Whole-Body Volume While Wearing a Triathlon Wetsuit   The “Journal of Functional Morphology and Kinesiology” Journal Club Series: Highlights on Recent Papers in Physical Activity and Sedentary Behavior   Abstract
The paper aims to analyze body composition and biochemical profile alterations in amateur bodybuilders during the cutting phase of a contest preparation, and to discuss them in light of scientific evidence. For the purpose of this study, bodybuilders and coaches provided details of drug administration, supplement use and training schedule. The four participants were two men competing in different Men’s Physique categories, one woman in the Wellness category, and one woman competing in the Bikini category. Participants were evaluated for anthropometry and body composition before and after the cutting phase. There was an evident decrease in body fat for most of the participants during the cutting phase without evident loss of fat-free mass. In general, participants performed high volume resistance training combined with aerobic training. Regarding drug administration, participants used high doses of anabolic androgen steroids (AAS), combined with clenbuterol, thyroid hormone, and ephedrine. Blood analysis revealed alterations in lipid profiles, with increased total cholesterol and low-density lipoprotein (LDL), and reduced high-density lipoprotein (HDL) levels. There were marked alterations in markers of liver (aspartate aminotransferase) and cardiac (MB isoenzyme creatine kinase) damage. Our analysis suggests that the strategies adopted by bodybuilders during the pre-contest phase (high use of AAS and stimulant-based substances) may result in an increased risk of heart disease and liver dysfunction. View Full-Text   Abstract
Sport Against Violence and Exclusion (SAVE), a project cofounded by the Erasmus + Program of the European Union, seeks to prevent violent and socially exclusive behaviors through physical activity. The current editorial shows a range of possible interpretations of these two phenomena from both a psychological and sociological point of view, offering helpful methods to coaches who train children (ages 6 to 12)in grass-root sport clubs. Following a thorough analysis, partners from seven EU countries (Lithuania, Italy, Croatia, Bosnia and Herzegovina, Serbia, Austria, and Spain) will be able to identify skills and techniques for coaches to ensure inclusive training methods as well as to provide them with effective conflict resolution tools. Furthermore, both trainers and parents will have access to an online platform with useful information regarding these issues. View Full-Text   Abstract
Background: Commercial 3 Dimension (3D) scanners are relatively new to anthropometry. The purpose of this study was to explore ability of using a 3D imaging instrument to measure body volume with and without wearing a wetsuit. Three experiments were conducted to achieve this purpose: (1) to determine if the 3D imaging instrument could accurately measure volume of static objects; (2) to determine the resolution of accuracy of measuring volume of static objects; and (3) to compare whole-body volume of wearing a wetsuit using 3D imaging as well as another body volume measure (air displacement technique). Methods: Three experiments were performed: (1) measurement of volume of a mannequin head and a box using a 3D scanner, water displacement (for mannequin head), and dimension measurements (for box) techniques for determining volume, (2) volume measurements of 1, 2, and 3 layers of neoprene to assess the resolution capabilities of the 3D scanner, and (3) body volume with and without wearing a wetsuit using a 3D scanner and BodPod (air displacement instrument). Results: (1) Mannequin head volume using the 3D scanner was 1.46% greater than a water displacement technique; the box volume from scanning was significantly greater than volume calculated by measuring dimensions of a box. (2) The volume of a single layer of neoprene was 25.3% less with scanning than the criterion; the volume of two layers was 27.2% less than the criterion; the volume of three layers was not significantly different from the criterion. (3) Body volume was not influenced by the interaction of wetsuit and device; body volume was on average 5% greater with wetsuit than without regardless of instrument. Conclusions: We demonstrated that body volume as measured by a 3D scanner increased when a wetsuit was worn. View Full-Text   Abstract
We are glad to introduce the sixth Journal Club. This edition is focused on several relevant studies published in the last years in the field of physical activity and sedentary behavior, chosen by our Editorial Board members and their colleagues. We hope to stimulate your curiosity in this field and to share with you the passion for the sport seen also from the scientific point of view. The Editorial Board members wish you an inspiring lecture. View Full-Text   ergogenic aids,muscle hypertrophy,fat loss,resistance training,aerobic exercise      3 Dimension (3D) scan,wetsuit fitting,anthropometrics    ", Journal of Functional Morphology and Kinesiology 
 Slant of a Surface Shifts Binocular Visual Direction   Image Stabilization in Central Vision Loss: The Horizontal Vestibulo-Ocular Reflex   Changes in Tonic Alertness but Not Voluntary Temporal Preparation Modulate the Attention Elicited by Task-Relevant Gaze and Arrow Cues   Differential Angular Expansion in Perceived Direction in Azimuth and Elevation Are Yoked to the Presence of a Perceived Ground Plane ," Abstract
We demonstrate how the slant of a surface affects the relative visual direction between binocular stimuli. In two experiments, we measured the visual direction of a binocular stimulus at different distances in the mid-sagittal plane or in the transverse plane at eye level relative to the center of the stimulus field. Experiment 1 showed that when a binocular stimulus (a vertical bar) was presented in front of or behind a surface slanted along the vertical center of the surface, its visual direction shifted toward the surface. Experiment 2 showed that when a binocular stimulus (a horizontal bar) was presented in front of or behind a surface slanted along the horizontal center of the surface, its visual direction also shifted toward the surface. These results indicate that the slant of a surface should be listed among the variables that contribute to the binocular visual direction, as well as the retinal loci of the stimulus, binocular eye position, the location of the visual egocenter, and stimulus properties. View Full-Text   Abstract
For patients with central vision loss and controls with normal vision, we examined the horizontal vestibulo-ocular reflex (VOR) in complete darkness and in the light when enhanced by vision (VVOR). We expected that the visual-vestibular interaction during VVOR would produce an asymmetry in the gain due to the location of the preferred retinal locus (PRL) of the patients. In the dark, we hypothesized that the VOR would not be affected by the loss of central vision. Nine patients (ages 67 to 92 years) and 17 controls (ages 16 to 81 years) were tested in 10-s active VVOR and VOR procedures at a constant frequency of 0.5 Hz while their eyes and head movements were recorded with a video-based binocular eye tracker. We computed the gain by analyzing the eye and head peak velocities produced during the intervals between saccades. In the light and in darkness, a significant proportion of patients showed larger leftward than rightward peak velocities, consistent with a PRL to the left of the scotoma. No asymmetries were found for the controls. These data support the notion that, after central vision loss, the preferred retinal locus (PRL) in eccentric vision becomes the centre of visual direction, even in the dark. View Full-Text   Abstract
Attention is engaged differently depending on the type and utility of an attentional cue. Some cues like visual transients or social gaze engage attention effortlessly. Others like symbols or geometric shapes require task-relevant deliberate processing. In the laboratory, these effects are often measured using a cuing procedure, which typically manipulates cue type and its utility for the task. Recent research however has uncovered that in addition to spatial orienting, this popular paradigm also engages two additional processes—tonic alertness and voluntary temporal preparation—both of which have been found to modulate spatial orienting elicited by task-irrelevant cues but not task-relevant symbols. Here we assessed whether changes in tonic alertness and voluntary temporal preparation also modulated attentional orienting elicited by task-relevant social gaze and nonsocial arrow cues. Our results indicated that while the effects of spatial attention were reliable in all conditions and did not vary with cue type, the magnitude of orienting was larger under high tonic alertness. Thus, while the cue’s task utility appears to have the power to robustly drive attentional orienting, changes in tonic alertness may modulate the magnitude of such deliberate shifts of attention elicited by task-relevant central social and nonsocial cues. View Full-Text   Abstract
It has been proposed that perceived angular direction relative to straight-ahead is exaggerated in perception, and that this exaggeration is greater in elevation (or declination) than in azimuth. Prior research has suggested that exaggerations in elevation may be tied to the presence of a visual ground plane, but there have been mixed results across studies using different methods of dissociation. In the present study, virtual environments were used to dissociate visual from gravitational upright while human participants (N = 128) made explicit angular direction judgments relative to straight ahead. Across these experimental manipulations, observers were positioned either upright (Experiments 1A and 1B) or sideways (Experiment 2), so as to additionally dissociate bodily orientation from gravitational orientation. In conditions in which a virtual environment was perceived as containing a level ground plane, large-scale exaggerations consistent with the visually-specified orientation of the ground plane were observed. In the absence of the perception of a level ground plane, angular exaggerations were relatively small. The ground plane serves as an important reference frame for angular expansion in the perceived visual direction. View Full-Text "," visual direction,slanted surface,inclined surface,binocular disparity stimuli,depth cue conflict   vestibulo-ocular reflex,eye movements,age-related macular degeneration,central vision loss,preferred retinal locus   spatial attention,temporal attention,attentional orienting,reflexive attention,voluntary attention,social attention,automated symbolic orienting,visual attention   visual perception,space perception,angular expansion "," Slant of a Surface Shifts Binocular Visual Direction   Image Stabilization in Central Vision Loss: The Horizontal Vestibulo-Ocular Reflex   Changes in Tonic Alertness but Not Voluntary Temporal Preparation Modulate the Attention Elicited by Task-Relevant Gaze and Arrow Cues   Differential Angular Expansion in Perceived Direction in Azimuth and Elevation Are Yoked to the Presence of a Perceived Ground Plane   Abstract
We demonstrate how the slant of a surface affects the relative visual direction between binocular stimuli. In two experiments, we measured the visual direction of a binocular stimulus at different distances in the mid-sagittal plane or in the transverse plane at eye level relative to the center of the stimulus field. Experiment 1 showed that when a binocular stimulus (a vertical bar) was presented in front of or behind a surface slanted along the vertical center of the surface, its visual direction shifted toward the surface. Experiment 2 showed that when a binocular stimulus (a horizontal bar) was presented in front of or behind a surface slanted along the horizontal center of the surface, its visual direction also shifted toward the surface. These results indicate that the slant of a surface should be listed among the variables that contribute to the binocular visual direction, as well as the retinal loci of the stimulus, binocular eye position, the location of the visual egocenter, and stimulus properties. View Full-Text   Abstract
For patients with central vision loss and controls with normal vision, we examined the horizontal vestibulo-ocular reflex (VOR) in complete darkness and in the light when enhanced by vision (VVOR). We expected that the visual-vestibular interaction during VVOR would produce an asymmetry in the gain due to the location of the preferred retinal locus (PRL) of the patients. In the dark, we hypothesized that the VOR would not be affected by the loss of central vision. Nine patients (ages 67 to 92 years) and 17 controls (ages 16 to 81 years) were tested in 10-s active VVOR and VOR procedures at a constant frequency of 0.5 Hz while their eyes and head movements were recorded with a video-based binocular eye tracker. We computed the gain by analyzing the eye and head peak velocities produced during the intervals between saccades. In the light and in darkness, a significant proportion of patients showed larger leftward than rightward peak velocities, consistent with a PRL to the left of the scotoma. No asymmetries were found for the controls. These data support the notion that, after central vision loss, the preferred retinal locus (PRL) in eccentric vision becomes the centre of visual direction, even in the dark. View Full-Text   Abstract
Attention is engaged differently depending on the type and utility of an attentional cue. Some cues like visual transients or social gaze engage attention effortlessly. Others like symbols or geometric shapes require task-relevant deliberate processing. In the laboratory, these effects are often measured using a cuing procedure, which typically manipulates cue type and its utility for the task. Recent research however has uncovered that in addition to spatial orienting, this popular paradigm also engages two additional processes—tonic alertness and voluntary temporal preparation—both of which have been found to modulate spatial orienting elicited by task-irrelevant cues but not task-relevant symbols. Here we assessed whether changes in tonic alertness and voluntary temporal preparation also modulated attentional orienting elicited by task-relevant social gaze and nonsocial arrow cues. Our results indicated that while the effects of spatial attention were reliable in all conditions and did not vary with cue type, the magnitude of orienting was larger under high tonic alertness. Thus, while the cue’s task utility appears to have the power to robustly drive attentional orienting, changes in tonic alertness may modulate the magnitude of such deliberate shifts of attention elicited by task-relevant central social and nonsocial cues. View Full-Text   Abstract
It has been proposed that perceived angular direction relative to straight-ahead is exaggerated in perception, and that this exaggeration is greater in elevation (or declination) than in azimuth. Prior research has suggested that exaggerations in elevation may be tied to the presence of a visual ground plane, but there have been mixed results across studies using different methods of dissociation. In the present study, virtual environments were used to dissociate visual from gravitational upright while human participants (N = 128) made explicit angular direction judgments relative to straight ahead. Across these experimental manipulations, observers were positioned either upright (Experiments 1A and 1B) or sideways (Experiment 2), so as to additionally dissociate bodily orientation from gravitational orientation. In conditions in which a virtual environment was perceived as containing a level ground plane, large-scale exaggerations consistent with the visually-specified orientation of the ground plane were observed. In the absence of the perception of a level ground plane, angular exaggerations were relatively small. The ground plane serves as an important reference frame for angular expansion in the perceived visual direction. View Full-Text   visual direction,slanted surface,inclined surface,binocular disparity stimuli,depth cue conflict   vestibulo-ocular reflex,eye movements,age-related macular degeneration,central vision loss,preferred retinal locus   spatial attention,temporal attention,attentional orienting,reflexive attention,voluntary attention,social attention,automated symbolic orienting,visual attention   visual perception,space perception,angular expansion ", Vision 
 Design Optimization of Polymer Heat Exchanger for Automated Household-Scale Solar Water Pasteurizer   A Study of the Mixing Performance of Different Impeller Designs in Stirred Vessels Using Computational Fluid Dynamics   Analytical Expression of Parabolic Trough Solar Collector Performance ," Abstract
A promising approach to reducing the >870,000 deaths/year globally from unsafe water is flow-through solar water pasteurization systems (SWPs). Unfortunately, demonstrated systems have high capital costs, which limits access for the poor. The most expensive component of such systems is the heat exchanger (HX). Thus, this study focuses on cost optimization of HX designs for flow-through SWPs using high-effectiveness polymer microchannel HXs. The theoretical foundation for the cost optimization of a polymer microchannel HX is provided, and outputs are plotted in order to provide guidelines for designers to perform HX optimizations. These plots are used in two case studies: (1) substitution of a coiled copper HX with polymer microchannel HX, and (2) design of a polymer microchannel HX for a 3-D printed collector that can fit in an arbitrary build volume. The results show that substitution of the polymer expanded HX reduced the overall expenditure for the system by a factor 50, which aids in making the system more economical. For the second case study, the results show how future system designers can optimize an HX for an arbitrary SWP geometry. The approach of distributed manufacturing using laser welding appears promising for HX for SWP. View Full-Text   Abstract
Design and operation of mixing systems using agitated vessels is a difficult task due to the challenge of obtaining accurate information on impeller-induced turbulence. The use of Computational Fluid Dynamics (CFD) can provide detailed understanding of such systems. In this study, experimental tests and computational fluid dynamics simulations were performed to examine the flow characteristics of four impeller designs (anchor, saw-tooth, counter-flow and Rushton turbine), in achieving solution homogeneity. The impellers were used to mix potassium sulfate granules, from which values of electrical conductivity of the solution were measured and used to estimate the distribution pattern of dissolved solid concentrations within the vessel. CFD models were developed for similar mixing arrangement using commercial software, ANSYS Fluent 18.1 solver and the standard k-epsilon (ε) turbulence model. The Multiple Reference Frame (MRF) approach was used to simulate the impeller rotation. Velocity profiles generated from the simulations were in good agreement with the experimental predictions, as well as with results from previous studies. It was concluded that, through CFD analysis, detailed information can be obtained for optimal design of mixing apparatus. These findings are relevant in choosing the best mixing equipment and provides a basis for scaling up mixing operations in larger systems. View Full-Text   Abstract
The parabolic trough collector is one of the most developed solar concentrating technologies for medium and high temperatures (up to 800 K). This solar technology is applied in many applications and so its investigation is common. The objective of this study is to develop analytical expressions for the determination of the thermal performance of parabolic trough collectors. The non-linear equations of the energy balances in the parabolic trough collector device are simplified using suitable assumptions. The final equation set includes all the possible parameters which influence the system performance and it can be solved directly without computational cost. This model is validated using experimental literature results. Moreover, the developed model is tested using another model written in Engineering Equation Solver under different operating conditions. The impact of the inlet fluid temperature, flow rate, ambient temperature, solar beam irradiation, and the heat transfer coefficient between cover and ambient are the investigated parameters for testing the model accuracy. According to the final results, the thermal efficiency can be found with high accuracy; the deviations are found to be up to 0.2% in the majority of the examined cases. Thus, the results of this work can be used for the quick and accurate thermal analysis of parabolic trough collector. Moreover, the analytical expressions give the possibility for optimizing solar thermal systems driven by parabolic trough collectors with lower computational cost. View Full-Text "," distributed manufacturing,heat exchanger,laser welding,microchannel,open hardware,optimization,solar energy,solar thermal,solar water pasteurization,water pasteurization   impeller design,turbulent mixing,homogeneity,computational fluid dynamics,ANSYS fluent,multiple reference frame,velocity profile   parabolic trough collector,thermal efficiency,analytical expression,solar thermal,optimization tool "," Design Optimization of Polymer Heat Exchanger for Automated Household-Scale Solar Water Pasteurizer   A Study of the Mixing Performance of Different Impeller Designs in Stirred Vessels Using Computational Fluid Dynamics   Analytical Expression of Parabolic Trough Solar Collector Performance   Abstract
A promising approach to reducing the >870,000 deaths/year globally from unsafe water is flow-through solar water pasteurization systems (SWPs). Unfortunately, demonstrated systems have high capital costs, which limits access for the poor. The most expensive component of such systems is the heat exchanger (HX). Thus, this study focuses on cost optimization of HX designs for flow-through SWPs using high-effectiveness polymer microchannel HXs. The theoretical foundation for the cost optimization of a polymer microchannel HX is provided, and outputs are plotted in order to provide guidelines for designers to perform HX optimizations. These plots are used in two case studies: (1) substitution of a coiled copper HX with polymer microchannel HX, and (2) design of a polymer microchannel HX for a 3-D printed collector that can fit in an arbitrary build volume. The results show that substitution of the polymer expanded HX reduced the overall expenditure for the system by a factor 50, which aids in making the system more economical. For the second case study, the results show how future system designers can optimize an HX for an arbitrary SWP geometry. The approach of distributed manufacturing using laser welding appears promising for HX for SWP. View Full-Text   Abstract
Design and operation of mixing systems using agitated vessels is a difficult task due to the challenge of obtaining accurate information on impeller-induced turbulence. The use of Computational Fluid Dynamics (CFD) can provide detailed understanding of such systems. In this study, experimental tests and computational fluid dynamics simulations were performed to examine the flow characteristics of four impeller designs (anchor, saw-tooth, counter-flow and Rushton turbine), in achieving solution homogeneity. The impellers were used to mix potassium sulfate granules, from which values of electrical conductivity of the solution were measured and used to estimate the distribution pattern of dissolved solid concentrations within the vessel. CFD models were developed for similar mixing arrangement using commercial software, ANSYS Fluent 18.1 solver and the standard k-epsilon (ε) turbulence model. The Multiple Reference Frame (MRF) approach was used to simulate the impeller rotation. Velocity profiles generated from the simulations were in good agreement with the experimental predictions, as well as with results from previous studies. It was concluded that, through CFD analysis, detailed information can be obtained for optimal design of mixing apparatus. These findings are relevant in choosing the best mixing equipment and provides a basis for scaling up mixing operations in larger systems. View Full-Text   Abstract
The parabolic trough collector is one of the most developed solar concentrating technologies for medium and high temperatures (up to 800 K). This solar technology is applied in many applications and so its investigation is common. The objective of this study is to develop analytical expressions for the determination of the thermal performance of parabolic trough collectors. The non-linear equations of the energy balances in the parabolic trough collector device are simplified using suitable assumptions. The final equation set includes all the possible parameters which influence the system performance and it can be solved directly without computational cost. This model is validated using experimental literature results. Moreover, the developed model is tested using another model written in Engineering Equation Solver under different operating conditions. The impact of the inlet fluid temperature, flow rate, ambient temperature, solar beam irradiation, and the heat transfer coefficient between cover and ambient are the investigated parameters for testing the model accuracy. According to the final results, the thermal efficiency can be found with high accuracy; the deviations are found to be up to 0.2% in the majority of the examined cases. Thus, the results of this work can be used for the quick and accurate thermal analysis of parabolic trough collector. Moreover, the analytical expressions give the possibility for optimizing solar thermal systems driven by parabolic trough collectors with lower computational cost. View Full-Text   distributed manufacturing,heat exchanger,laser welding,microchannel,open hardware,optimization,solar energy,solar thermal,solar water pasteurization,water pasteurization   impeller design,turbulent mixing,homogeneity,computational fluid dynamics,ANSYS fluent,multiple reference frame,velocity profile   parabolic trough collector,thermal efficiency,analytical expression,solar thermal,optimization tool ", Designs 
 An Experimental Study of Portland Cement and Superfine Cement Slurry Grouting in Loose Sand and Sandy Soil   Novelties in Material Development for Massive Concrete Structures: Reduction in Heat of Hydration Observed in Ternary Replacement Mixtures   Cooperating to Compete in the Global Air Cargo Industry: The Case of the DHL Express and Lufthansa Cargo A.G. Joint Venture Airline ‘AeroLogic’ ," Abstract
Grouting technology is widely applied in the fields of geotechnical engineering in infrastructure. Loose sand and sandy soil are common poor soils in tunnel and foundation treatments. It is necessary to use superfine cement slurry grouting in the micro-cracks of soil. The different effectiveness of Portland cement slurry and superfine cement slurry in sandy soil by the laboratory grouting experiment method were presented in this paper. The grouting situations of superfine cement slurry injected into sand and sandy soil were explored. The investigated parameters were the dry density, wet density, moisture content, internal friction angle, and cohesion force. The results show that the consolidation effect of superfine cement is better than that of Portland cement due to the small size of superfine cement particles. The superfine cement can diffuse into the sand by infiltration, extrusion, and splitting. When the water–cement ratio of superfine cement slurry is less than 2:1 grouting into loose sand, the dry and wet density decrease with the increase in the water–cement ratio, while the moisture content and cohesive force gradually increase. When the water–cement ratio of superfine cement slurry is 1:1 grouting into loose sand and sandy soil, the dry density, wet density, and cohesive force of loose sand are larger than those of sandy soil. The results of the experiment may be relevant for engineering applications. View Full-Text   Abstract
As the size of modern infrastructure increases, novelties related to mass concrete mixtures including supplementary cementitious materials (SCMs) become critical. The effects of binary and ternary cement replacement mixtures including metakaolin, silica fume, ground calcium carbonate, granulated blast furnace slag, and fly ash on the rate and amount of heat generated in concrete mixtures are investigated. Twenty three binary and ternary mixtures with a water-to-cementitious binder ratio of 0.43 are evaluated. Between 15% and 45% cement replacement by weight is considered. Results indicate that binary mixtures containing metakaolin or silica fume offer no advantage in reducing the amount of heat but increase compressive strength by 20%. On contrary, ternary mixtures, including two pozzolanic materials, provide 15% reduction in the amount of heat evolution without compromising strength. This reduction is observed regardless of alumina (Al) or silica (Si) content in pozzolanic materials when 45% cement is replaced with a combination of slag and metakaolin, or slag and silica fume. Furthermore, the effect of increased calcium (Ca) content is investigated. It is concluded that ternary mixtures with decreased Ca/(Al+Si) ratio reduce internal temperature in mass concrete structures and are less likely to be exposed to the threshold temperature for delayed ettringite formation. View Full-Text   Abstract
This paper presents a case study of the DHL Express and Lufthansa Cargo strategic joint venture cargo airline ‘AeroLogic’, the global air cargo industry’s largest operative joint venture between an airline and a leading international express and logistics provider. The study used a qualitative research approach. The data gathered for the study was examined by document analysis. The strategic analysis of the AeroLogic joint venture was based on the use of Porter’s Five Forces framework. The study found that the AeroLogic joint venture airline has provided synergistic benefits to both partners and has allowed the partners to access new markets and to participate in the evolution of the air cargo industry. The new venture has also enabled both joint venture partners to enhance their competitive position in the global air cargo industry through strengthened service offerings and has provided the partners with increased cargo capacities, a larger route network, and greater frequencies within their own route networks. The study also found that the AeroLogic business model is unique in the air cargo industry. A limitation of the study was that AeroLogic’s annual revenue or freight traffic data was not available. It was, therefore, not possible to analyse the business performance of the joint venture. View Full-Text "," Portland cement,superfine cement,loose sandy soil,grouting,model experiment   heat of hydration,ternary mixtures,binary mixtures,supplementary cementitious materials,mass concrete,cement replacement,metakaolin,silica fume,compressive strength,material development   air cargo,AeroLogic,case study,DHL Express,freighter aircraft,joint venture,Lufthansa Cargo,route network "," An Experimental Study of Portland Cement and Superfine Cement Slurry Grouting in Loose Sand and Sandy Soil   Novelties in Material Development for Massive Concrete Structures: Reduction in Heat of Hydration Observed in Ternary Replacement Mixtures   Cooperating to Compete in the Global Air Cargo Industry: The Case of the DHL Express and Lufthansa Cargo A.G. Joint Venture Airline ‘AeroLogic’   Abstract
Grouting technology is widely applied in the fields of geotechnical engineering in infrastructure. Loose sand and sandy soil are common poor soils in tunnel and foundation treatments. It is necessary to use superfine cement slurry grouting in the micro-cracks of soil. The different effectiveness of Portland cement slurry and superfine cement slurry in sandy soil by the laboratory grouting experiment method were presented in this paper. The grouting situations of superfine cement slurry injected into sand and sandy soil were explored. The investigated parameters were the dry density, wet density, moisture content, internal friction angle, and cohesion force. The results show that the consolidation effect of superfine cement is better than that of Portland cement due to the small size of superfine cement particles. The superfine cement can diffuse into the sand by infiltration, extrusion, and splitting. When the water–cement ratio of superfine cement slurry is less than 2:1 grouting into loose sand, the dry and wet density decrease with the increase in the water–cement ratio, while the moisture content and cohesive force gradually increase. When the water–cement ratio of superfine cement slurry is 1:1 grouting into loose sand and sandy soil, the dry density, wet density, and cohesive force of loose sand are larger than those of sandy soil. The results of the experiment may be relevant for engineering applications. View Full-Text   Abstract
As the size of modern infrastructure increases, novelties related to mass concrete mixtures including supplementary cementitious materials (SCMs) become critical. The effects of binary and ternary cement replacement mixtures including metakaolin, silica fume, ground calcium carbonate, granulated blast furnace slag, and fly ash on the rate and amount of heat generated in concrete mixtures are investigated. Twenty three binary and ternary mixtures with a water-to-cementitious binder ratio of 0.43 are evaluated. Between 15% and 45% cement replacement by weight is considered. Results indicate that binary mixtures containing metakaolin or silica fume offer no advantage in reducing the amount of heat but increase compressive strength by 20%. On contrary, ternary mixtures, including two pozzolanic materials, provide 15% reduction in the amount of heat evolution without compromising strength. This reduction is observed regardless of alumina (Al) or silica (Si) content in pozzolanic materials when 45% cement is replaced with a combination of slag and metakaolin, or slag and silica fume. Furthermore, the effect of increased calcium (Ca) content is investigated. It is concluded that ternary mixtures with decreased Ca/(Al+Si) ratio reduce internal temperature in mass concrete structures and are less likely to be exposed to the threshold temperature for delayed ettringite formation. View Full-Text   Abstract
This paper presents a case study of the DHL Express and Lufthansa Cargo strategic joint venture cargo airline ‘AeroLogic’, the global air cargo industry’s largest operative joint venture between an airline and a leading international express and logistics provider. The study used a qualitative research approach. The data gathered for the study was examined by document analysis. The strategic analysis of the AeroLogic joint venture was based on the use of Porter’s Five Forces framework. The study found that the AeroLogic joint venture airline has provided synergistic benefits to both partners and has allowed the partners to access new markets and to participate in the evolution of the air cargo industry. The new venture has also enabled both joint venture partners to enhance their competitive position in the global air cargo industry through strengthened service offerings and has provided the partners with increased cargo capacities, a larger route network, and greater frequencies within their own route networks. The study also found that the AeroLogic business model is unique in the air cargo industry. A limitation of the study was that AeroLogic’s annual revenue or freight traffic data was not available. It was, therefore, not possible to analyse the business performance of the joint venture. View Full-Text   Portland cement,superfine cement,loose sandy soil,grouting,model experiment   heat of hydration,ternary mixtures,binary mixtures,supplementary cementitious materials,mass concrete,cement replacement,metakaolin,silica fume,compressive strength,material development   air cargo,AeroLogic,case study,DHL Express,freighter aircraft,joint venture,Lufthansa Cargo,route network ", Infrastructures 
 ELIMAIA: A Laser-Driven Ion Accelerator for Multidisciplinary Applications   Laser Requirements for High-Order Harmonic Generation by Relativistic Plasma Singularities†   Facilities in Quantum Beam Science ," Abstract
The main direction proposed by the community of experts in the field of laser-driven ion acceleration is to improve particle beam features (maximum energy, charge, emittance, divergence, monochromaticity, shot-to-shot stability) in order to demonstrate reliable and compact approaches to be used for multidisciplinary applications, thus, in principle, reducing the overall cost of a laser-based facility compared to a conventional accelerator one and, at the same time, demonstrating innovative and more effective sample irradiation geometries. The mission of the laser-driven ion target area at ELI-Beamlines (Extreme Light Infrastructure) in Dolní Břežany, Czech Republic, called ELI Multidisciplinary Applications of laser-Ion Acceleration (ELIMAIA) , is to provide stable, fully characterized and tuneable beams of particles accelerated by Petawatt-class lasers and to offer them to the user community for multidisciplinary applications. The ELIMAIA beamline has been designed and developed at the Institute of Physics of the Academy of Science of the Czech Republic (IoP-ASCR) in Prague and at the National Laboratories of Southern Italy of the National Institute for Nuclear Physics (LNS-INFN) in Catania (Italy). An international scientific network particularly interested in future applications of laser driven ions for hadrontherapy, ELI MEDical applications (ELIMED), has been established around the implementation of the ELIMAIA experimental system. The basic technology used for ELIMAIA research and development, along with envisioned parameters of such user beamline will be described and discussed. View Full-Text   Abstract
We discuss requirements on relativistic-irradiance (I0 > 1018 W/cm2) high-power (multi-terawatt) ultrashort (femtosecond) lasers for efficient generation of high-order harmonics in gas jet targets in a new regime discovered recently (Pirozhkov et al., 2012). Here, we present the results of several experimental campaigns performed with different irradiances, analyse the obtained results and derive the required laser parameters. In particular, we found that the root mean square (RMS) wavefront error should be smaller than ~100 nm (~λ/8). Further, the angular dispersion should be kept considerably smaller than the diffraction divergence, i.e., μrad level for 100–300-mm beam diameters. The corresponding angular chirp should not exceed 10−2 μrad/nm for a 40-nm bandwidth. We show the status of the J-KAREN-P laser (Kiriyama et al., 2015; Pirozhkov et al., 2017) and report on the progress towards satisfying these requirements. View Full-Text   Abstract
The year 2017 saw the birth of the journal Quantum Beam Science [1] which is dedicated to the sources and properties of quantum beam radiation [...]
View Full-Text "," laser-plasma acceleration,laser-ion beamline,compact accelerator,pulsed ion beams,multidisciplinary applications of ions,ultrahigh intensity laser-matter interaction,ion beam transport,dosimetry of laser-driven ions   high-power femtosecond lasers,high-power laser quality,relativistic laser plasma,relativistic plasma singularities,coherent X-ray generation,burst intensification by singularity-emitting radiation    "," ELIMAIA: A Laser-Driven Ion Accelerator for Multidisciplinary Applications   Laser Requirements for High-Order Harmonic Generation by Relativistic Plasma Singularities†   Facilities in Quantum Beam Science   Abstract
The main direction proposed by the community of experts in the field of laser-driven ion acceleration is to improve particle beam features (maximum energy, charge, emittance, divergence, monochromaticity, shot-to-shot stability) in order to demonstrate reliable and compact approaches to be used for multidisciplinary applications, thus, in principle, reducing the overall cost of a laser-based facility compared to a conventional accelerator one and, at the same time, demonstrating innovative and more effective sample irradiation geometries. The mission of the laser-driven ion target area at ELI-Beamlines (Extreme Light Infrastructure) in Dolní Břežany, Czech Republic, called ELI Multidisciplinary Applications of laser-Ion Acceleration (ELIMAIA) , is to provide stable, fully characterized and tuneable beams of particles accelerated by Petawatt-class lasers and to offer them to the user community for multidisciplinary applications. The ELIMAIA beamline has been designed and developed at the Institute of Physics of the Academy of Science of the Czech Republic (IoP-ASCR) in Prague and at the National Laboratories of Southern Italy of the National Institute for Nuclear Physics (LNS-INFN) in Catania (Italy). An international scientific network particularly interested in future applications of laser driven ions for hadrontherapy, ELI MEDical applications (ELIMED), has been established around the implementation of the ELIMAIA experimental system. The basic technology used for ELIMAIA research and development, along with envisioned parameters of such user beamline will be described and discussed. View Full-Text   Abstract
We discuss requirements on relativistic-irradiance (I0 > 1018 W/cm2) high-power (multi-terawatt) ultrashort (femtosecond) lasers for efficient generation of high-order harmonics in gas jet targets in a new regime discovered recently (Pirozhkov et al., 2012). Here, we present the results of several experimental campaigns performed with different irradiances, analyse the obtained results and derive the required laser parameters. In particular, we found that the root mean square (RMS) wavefront error should be smaller than ~100 nm (~λ/8). Further, the angular dispersion should be kept considerably smaller than the diffraction divergence, i.e., μrad level for 100–300-mm beam diameters. The corresponding angular chirp should not exceed 10−2 μrad/nm for a 40-nm bandwidth. We show the status of the J-KAREN-P laser (Kiriyama et al., 2015; Pirozhkov et al., 2017) and report on the progress towards satisfying these requirements. View Full-Text   Abstract
The year 2017 saw the birth of the journal Quantum Beam Science [1] which is dedicated to the sources and properties of quantum beam radiation [...]
View Full-Text   laser-plasma acceleration,laser-ion beamline,compact accelerator,pulsed ion beams,multidisciplinary applications of ions,ultrahigh intensity laser-matter interaction,ion beam transport,dosimetry of laser-driven ions   high-power femtosecond lasers,high-power laser quality,relativistic laser plasma,relativistic plasma singularities,coherent X-ray generation,burst intensification by singularity-emitting radiation    ", Quantum Beam Science 
,,,  , Sci 
" Understanding the Importance of Front Yard Accessibility for Community Building: A Case Study of Subiaco, Western Australia   A Method for Mapping Future Urbanization in the United States   Land-Cover Change Analysis and Simulation in Conakry (Guinea), Using Hybrid Cellular-Automata and Markov Model   Assessing Vulnerability to Heat: A Geospatial Analysis for the City of Philadelphia "," Abstract
The residential built form, including open space, provides the physical environment for social interaction. Understanding urban open space, including semi-public and public domains, through the lens of physical accessibility and visual permeability can potentially facilitate the building of a sense of community contributing to a better quality of life. Using an inner-city suburb in Perth, Western Australia as a case study, this research explores the importance of physical accessibility patterns and visual permeability for socialising in semi-public and public domains, such as the front yard and the residential streets. It argues that maintaining a balance between public and private inter-relationship in inner city residential neighbourhoods is important for creating and maintaining a sense of community. View Full-Text   Abstract
Cities are poised to absorb additional people. Their sustainability, or ability to accommodate a population increase without depleting resources or compromising future growth, depends on whether they harness the efficiency gains from urban land management. Population is often projected as a bulk national number without details about spatial distribution. We use Landsat and population data in a methodology to project and map U.S. urbanization for the year 2020 and document its spatial pattern. This methodology is important to spatially disaggregate projected population and assist land managers to monitor land use, assess infrastructure and distribute resources. We found the U.S. west coast urban areas to have the fastest population growth with relatively small land consumption resulting in future decrease in per capita land use. Except for Miami (FL), most other U.S. large urban areas, especially in the Midwest, are growing spatially faster than their population and inadvertently consuming land needed for ecosystem services. In large cities, such as New York, Chicago, Houston and Miami, land development is expected more in suburban zones than urban cores. In contrast, in Los Angeles land development within the city core is greater than in its suburbs. View Full-Text   Abstract
In this study, land-cover change in the capital Conakry of Guinea was simulated using the integrated Cellular Automata and Markov model (CA-Markov) in the Geographic Information System (GIS) and Remote Sensing (RS). Historical land-cover change information was derived from 1986, 2000 and 2016 Landsat data. Using the land-cover change maps of 1986 and 2000, the land-cover change map for 2016 was simulated based on the Markov model in IDRISSI software (Clark University, Worcester, MA, USA). The simulated result was compared with the 2016 land-cover map for validation using the Relative Operating Characteristic (ROC). The ROC result showed a very strong agreement between the two maps. From this result, the land-cover change map for 2025 was simulated using CA-Markov model. The result has indicated that the proportion of the urban area was 49% in 2016, and it is expected to increase to 52% by 2025, while vegetation will decrease from 35% in 2016 to 32% in 2025. This study suggests that the rapid land-cover change has been led by both rapid population growth and extreme poverty in rural areas, which will result in migration into Conakry. The results of this study will provide bases for assessing the sustainability and the management of the urban area and for taking actions to mitigate the degradation of the urban environment. View Full-Text   Abstract
Urban heat island (UHI) effect is an increasingly prominent health and environmental hazard that is linked to urbanization and climate change. Greening reduces the negative impacts of UHI; trees specifically are the most effective in ambient temperature reduction. This paper investigates vulnerability to heat in the Philadelphia, Pennsylvania and identifies where street trees can be planted as a public intervention. We used geospatial information systems (GIS) software to map a validated Heat Vulnerability Index to identify vulnerability at the block level. Using a high-low geospatial cluster analysis, we assessed where the City of Philadelphia can most effectively plant street trees to address UHI. This information was then aggregated to the neighborhood level for more effective citizen communication and policymaking. We identified that 26 of 48 (54%) neighborhoods that were vulnerable to heat also lacked street trees. Of 158 Philadelphia neighborhoods, 63 (40%) contained block groups of high vulnerability to either heat or street tree infrastructure. Neighborhoods that were ranked highest in both classifications were identified in two adjacent West Philadelphia neighborhoods. Planting street trees is a public service a city can potentially reduce the negative health impacts of UHI. GIS can be used to identify and recommend street tree plantings to reduce urban heat. View Full-Text "," community building,quality of life,built form typology,front-yard,physical accessibility,visual permeability,human behaviour   population,NLCD,land use,CONUS,impervious surface,CIESIN   land-cover change simulation,urban growth,CA-Markov model,Conakry   urban heat island,street trees,gis,vulnerability,climate change,urban planning "," Understanding the Importance of Front Yard Accessibility for Community Building: A Case Study of Subiaco, Western Australia   A Method for Mapping Future Urbanization in the United States   Land-Cover Change Analysis and Simulation in Conakry (Guinea), Using Hybrid Cellular-Automata and Markov Model   Assessing Vulnerability to Heat: A Geospatial Analysis for the City of Philadelphia   Abstract
The residential built form, including open space, provides the physical environment for social interaction. Understanding urban open space, including semi-public and public domains, through the lens of physical accessibility and visual permeability can potentially facilitate the building of a sense of community contributing to a better quality of life. Using an inner-city suburb in Perth, Western Australia as a case study, this research explores the importance of physical accessibility patterns and visual permeability for socialising in semi-public and public domains, such as the front yard and the residential streets. It argues that maintaining a balance between public and private inter-relationship in inner city residential neighbourhoods is important for creating and maintaining a sense of community. View Full-Text   Abstract
Cities are poised to absorb additional people. Their sustainability, or ability to accommodate a population increase without depleting resources or compromising future growth, depends on whether they harness the efficiency gains from urban land management. Population is often projected as a bulk national number without details about spatial distribution. We use Landsat and population data in a methodology to project and map U.S. urbanization for the year 2020 and document its spatial pattern. This methodology is important to spatially disaggregate projected population and assist land managers to monitor land use, assess infrastructure and distribute resources. We found the U.S. west coast urban areas to have the fastest population growth with relatively small land consumption resulting in future decrease in per capita land use. Except for Miami (FL), most other U.S. large urban areas, especially in the Midwest, are growing spatially faster than their population and inadvertently consuming land needed for ecosystem services. In large cities, such as New York, Chicago, Houston and Miami, land development is expected more in suburban zones than urban cores. In contrast, in Los Angeles land development within the city core is greater than in its suburbs. View Full-Text   Abstract
In this study, land-cover change in the capital Conakry of Guinea was simulated using the integrated Cellular Automata and Markov model (CA-Markov) in the Geographic Information System (GIS) and Remote Sensing (RS). Historical land-cover change information was derived from 1986, 2000 and 2016 Landsat data. Using the land-cover change maps of 1986 and 2000, the land-cover change map for 2016 was simulated based on the Markov model in IDRISSI software (Clark University, Worcester, MA, USA). The simulated result was compared with the 2016 land-cover map for validation using the Relative Operating Characteristic (ROC). The ROC result showed a very strong agreement between the two maps. From this result, the land-cover change map for 2025 was simulated using CA-Markov model. The result has indicated that the proportion of the urban area was 49% in 2016, and it is expected to increase to 52% by 2025, while vegetation will decrease from 35% in 2016 to 32% in 2025. This study suggests that the rapid land-cover change has been led by both rapid population growth and extreme poverty in rural areas, which will result in migration into Conakry. The results of this study will provide bases for assessing the sustainability and the management of the urban area and for taking actions to mitigate the degradation of the urban environment. View Full-Text   Abstract
Urban heat island (UHI) effect is an increasingly prominent health and environmental hazard that is linked to urbanization and climate change. Greening reduces the negative impacts of UHI; trees specifically are the most effective in ambient temperature reduction. This paper investigates vulnerability to heat in the Philadelphia, Pennsylvania and identifies where street trees can be planted as a public intervention. We used geospatial information systems (GIS) software to map a validated Heat Vulnerability Index to identify vulnerability at the block level. Using a high-low geospatial cluster analysis, we assessed where the City of Philadelphia can most effectively plant street trees to address UHI. This information was then aggregated to the neighborhood level for more effective citizen communication and policymaking. We identified that 26 of 48 (54%) neighborhoods that were vulnerable to heat also lacked street trees. Of 158 Philadelphia neighborhoods, 63 (40%) contained block groups of high vulnerability to either heat or street tree infrastructure. Neighborhoods that were ranked highest in both classifications were identified in two adjacent West Philadelphia neighborhoods. Planting street trees is a public service a city can potentially reduce the negative health impacts of UHI. GIS can be used to identify and recommend street tree plantings to reduce urban heat. View Full-Text   community building,quality of life,built form typology,front-yard,physical accessibility,visual permeability,human behaviour   population,NLCD,land use,CONUS,impervious surface,CIESIN   land-cover change simulation,urban growth,CA-Markov model,Conakry   urban heat island,street trees,gis,vulnerability,climate change,urban planning ", Urban Science 
 An Experience-Centered Framework for Designing Non-Task-Oriented Embodied Interaction Environments   A Review of Heritage Building Information Modeling (H-BIM)   A Novel Immersive VR Game Model for Recontextualization in Virtual Environments: The μVRModel   Who Is at Risk for Problematic Video Gaming? Risk Factors in Problematic Video Gaming in Clinically Referred Canadian Children and Adolescents ," Abstract
Embodied Interaction faces designers with the challenge of thinking about users and interaction from different viewpoints with respect to traditional technologies. This task is even more complex when designing non-task oriented systems. We propose a framework to guide researchers in thinking and designing non-task-oriented Embodied Interaction Environments or, in other words, embodied experiences that users can enjoy for its own sake and not as means for accomplishing a task or achieving an extrinsic goal. The framework is grounded on experience-centered design approaches and will present four qualities ((1) Spatial, Corporeal and Material Consistency, (2) Contingent Enhancement, (3) Mindful Embodied Engagement and (4) Situated Reflexivity) aimed at providing critical lenses, strategies and techniques to guide the design and research processes. Finally, we will discuss how designers can implement the proposed framework in different stages of the design process and paths for future research. View Full-Text   Abstract
Many projects concerning the protection, conservation, restoration, and dissemination of cultural heritage are being carried out around the world due to its growing interest as a driving force of socio-economic development. The existence of reliable, digital three-dimensional (3D) models that allow for the planning and management of these projects in a remote and decentralized way is currently a growing necessity. There are many software tools to perform the modeling and complete three-dimensional documentation of the intervened monuments. However, the Architecture, Engineering and Construction (AEC) sector has adopted the Building Information Modeling (BIM) standard over the last few decades due to the progress that has been made in its qualities and capabilities. The complex modeling of cultural heritage through commercial BIM software leads to the consideration of the concept of Heritage BIM (H-BIM), which pursues the modeling of architectural elements, according to artistic, historical, and constructive typologies. In addition, H-BIM is considered to be an emerging technology that enables us to understand, document, advertize, and virtually reconstruct the built heritage. This article is a review of the existing literature on H-BIM and its effective implementation in the cultural heritage sector, exploring the effectiveness and the usefulness of the different methodologies that were developed to model families of elements of interest. View Full-Text   Abstract
In recent years, immersive VR had a great boost in terms of adoption and research perspectives, especially those regarding the serious gaming universe. Within the cultural heritage field, virtual re-contextualization of items is a crucial task to be accomplished by individuals to understand a 3D reconstructed environment as a whole and to assign a meaning and a value to a specific cultural object. Immersive VR and consumer HMDs still present several issues related to motion sickness and locomotion: the interest in real-walking techniques outperforming other locomotion methods is growing year by year, although limited by physical constraints, higher costs, or current technology. In this work, we propose a novel game model (μVR) that combines real-walking techniques and an adaptive, game-driven, multi-scale progression to craft immersive re-contextualization applications. The presented model aims to minimize motion sickness while fully exploiting the physical tracked area and augmenting the understanding of what the user is experiencing at different world scales. We define and formalize the μVR model and its components mathematically for the sake of reproducibility, then we present results from a pilot test planned to validate the model on real users. Results assure the usability and effectiveness of VR model even if further implementation needs to be done. View Full-Text   Abstract
Both Internet and offline video gaming have become a normal aspect of child development, with estimates of children playing video games ranging from 90% to 97%. Research on problematic video gaming (PVG) has grown substantially in the last decade. Much of that research has focused on community samples, while research on clinically referred children and youth is lacking. The present study includes 5820 clinically referred children and youth across 44 mental health agencies, assessed using the interRAI Child and Youth Mental Health Assessment. Logistic regression analyses revealed that older age, male sex, extreme shyness, internalizing symptoms, externalizing symptoms, and poor relational strengths are all significant predictors of problematic video gaming (PVG). Further analyses suggested that, out of the internalizing symptoms, anhedonia was predictive of PVG in both males and females, but depressive symptoms and anxiety were not predictive of PVG when controlling for other variables in the model. Moreover, proactive aggression and extreme shyness were predictive of PVG in males, but not in females. The implications of these findings are discussed. View Full-Text "," design framework,Embodied Interaction,non-task-oriented interaction,qualities   cultural heritage documentation,BIM,H-BIM,H-BIM literature review,as-is model H-BIM,3D heritage modeling,point clouds,Laser scanner   cognitive perception,VR locomotion,user experience,motion sickness,re-contextualization   video games,Internet gaming,problematic gaming,Internet gaming disorder,depression,anxiety,shyness,anhedonia,aggression,interRAI "," An Experience-Centered Framework for Designing Non-Task-Oriented Embodied Interaction Environments   A Review of Heritage Building Information Modeling (H-BIM)   A Novel Immersive VR Game Model for Recontextualization in Virtual Environments: The μVRModel   Who Is at Risk for Problematic Video Gaming? Risk Factors in Problematic Video Gaming in Clinically Referred Canadian Children and Adolescents   Abstract
Embodied Interaction faces designers with the challenge of thinking about users and interaction from different viewpoints with respect to traditional technologies. This task is even more complex when designing non-task oriented systems. We propose a framework to guide researchers in thinking and designing non-task-oriented Embodied Interaction Environments or, in other words, embodied experiences that users can enjoy for its own sake and not as means for accomplishing a task or achieving an extrinsic goal. The framework is grounded on experience-centered design approaches and will present four qualities ((1) Spatial, Corporeal and Material Consistency, (2) Contingent Enhancement, (3) Mindful Embodied Engagement and (4) Situated Reflexivity) aimed at providing critical lenses, strategies and techniques to guide the design and research processes. Finally, we will discuss how designers can implement the proposed framework in different stages of the design process and paths for future research. View Full-Text   Abstract
Many projects concerning the protection, conservation, restoration, and dissemination of cultural heritage are being carried out around the world due to its growing interest as a driving force of socio-economic development. The existence of reliable, digital three-dimensional (3D) models that allow for the planning and management of these projects in a remote and decentralized way is currently a growing necessity. There are many software tools to perform the modeling and complete three-dimensional documentation of the intervened monuments. However, the Architecture, Engineering and Construction (AEC) sector has adopted the Building Information Modeling (BIM) standard over the last few decades due to the progress that has been made in its qualities and capabilities. The complex modeling of cultural heritage through commercial BIM software leads to the consideration of the concept of Heritage BIM (H-BIM), which pursues the modeling of architectural elements, according to artistic, historical, and constructive typologies. In addition, H-BIM is considered to be an emerging technology that enables us to understand, document, advertize, and virtually reconstruct the built heritage. This article is a review of the existing literature on H-BIM and its effective implementation in the cultural heritage sector, exploring the effectiveness and the usefulness of the different methodologies that were developed to model families of elements of interest. View Full-Text   Abstract
In recent years, immersive VR had a great boost in terms of adoption and research perspectives, especially those regarding the serious gaming universe. Within the cultural heritage field, virtual re-contextualization of items is a crucial task to be accomplished by individuals to understand a 3D reconstructed environment as a whole and to assign a meaning and a value to a specific cultural object. Immersive VR and consumer HMDs still present several issues related to motion sickness and locomotion: the interest in real-walking techniques outperforming other locomotion methods is growing year by year, although limited by physical constraints, higher costs, or current technology. In this work, we propose a novel game model (μVR) that combines real-walking techniques and an adaptive, game-driven, multi-scale progression to craft immersive re-contextualization applications. The presented model aims to minimize motion sickness while fully exploiting the physical tracked area and augmenting the understanding of what the user is experiencing at different world scales. We define and formalize the μVR model and its components mathematically for the sake of reproducibility, then we present results from a pilot test planned to validate the model on real users. Results assure the usability and effectiveness of VR model even if further implementation needs to be done. View Full-Text   Abstract
Both Internet and offline video gaming have become a normal aspect of child development, with estimates of children playing video games ranging from 90% to 97%. Research on problematic video gaming (PVG) has grown substantially in the last decade. Much of that research has focused on community samples, while research on clinically referred children and youth is lacking. The present study includes 5820 clinically referred children and youth across 44 mental health agencies, assessed using the interRAI Child and Youth Mental Health Assessment. Logistic regression analyses revealed that older age, male sex, extreme shyness, internalizing symptoms, externalizing symptoms, and poor relational strengths are all significant predictors of problematic video gaming (PVG). Further analyses suggested that, out of the internalizing symptoms, anhedonia was predictive of PVG in both males and females, but depressive symptoms and anxiety were not predictive of PVG when controlling for other variables in the model. Moreover, proactive aggression and extreme shyness were predictive of PVG in males, but not in females. The implications of these findings are discussed. View Full-Text   design framework,Embodied Interaction,non-task-oriented interaction,qualities   cultural heritage documentation,BIM,H-BIM,H-BIM literature review,as-is model H-BIM,3D heritage modeling,point clouds,Laser scanner   cognitive perception,VR locomotion,user experience,motion sickness,re-contextualization   video games,Internet gaming,problematic gaming,Internet gaming disorder,depression,anxiety,shyness,anhedonia,aggression,interRAI ", Multimodal Technologies and Interaction 
" Echinococcus Granulosus Infection in Two Free-Ranging Lumholtz’sTree-Kangaroo (Dendrolagus lumholtzi) from the Atherton Tablelands, Queensland   Strongyloides stercoralis Hyperinfection in an HIV-Infected Patient Successfully Treated with Subcutaneous Ivermectin   First Aid and Pre-Hospital Management of Venomous Snakebites   Towards TB Elimination in Aotearoa/New Zealand: Key Informant Insights on the Determinants of TB among African Migrants "," Abstract
Infection with the larval stage of the cestode, Echinococcus granulosus sensu lato (s.l.), causes hydatid disease (hydatidosis) in a range of hosts, including macropods and other marsupials, cattle, and humans. Wild macropods are an important sylvatic reservoir for the life cycle of E. granulosus (s.l.) in Australia, and so provide a conduit for transmission of hydatid disease to domestic animals and humans. Two Lumholtz’s tree-kangaroos (Dendrolagus lumholtzi) from the Atherton Tablelands of Far North Queensland were recently found to have hydatid cysts in both liver and lung tissues. Tree-kangaroos may travel across the ground between patches of forest but are primarily arboreal leaf-eating macropods. The finding of hydatid cysts in an arboreal folivore may indicate that the area has a high level of contamination with eggs of E. granulosus (s.l.). This finding may be of significance to human health as well as indicating the need for further investigation into the prevalence of hydatid disease in domestic stock, wildlife and humans living in this rapidly urbanizing region. View Full-Text   Abstract
A 39-year-old Ethiopian HIV-positive man with peripheral T-cell lymphoma developed Strongyloides stercoralis hyperinfection. The patient was initially treated with oral ivermectin for three weeks without response, most likely due to malabsorption because of concomitant paralytic ileus. Given the persistence of larvae in the body fluids, the worsening respiratory status and clinical malabsorption, veterinary parenteral formulation of ivermectin was administered. The very high plasma concentration of ivermectin achieved in the patient after parenteral administration led to a rapid improvement in his clinical condition and rapid disappearance of the parasite from biological samples, without any adverse reaction. View Full-Text   Abstract
Background: Antivenom is the definitive treatment for venomous snakebites, but is expensive and not available in many rural and poorly developed regions. Timely transportation to facilities that stock and administer antivenom may not be available in rural areas with poorly developed emergency medical services. These factors have led to consideration of measures to delay onset of toxicity or alternatives to antivenom therapy. Methods: PubMed searches were conducted for articles on snakebite treatment, or that contained first aid, emergency medical services, tourniquets, pressure immobilization bandages, suction devices, and lymphatic flow inhibitors. Results: The reviewed articles describe how venoms spread after a venomous snakebite on an extremity, list the proposed first aid measures for delaying the spread of venoms, and evaluate the scientific studies that support or refute methods of snakebite first aid. The recommendations for field treatment of venomous snakebites will be discussed. Conclusions: The evidence suggests that pressure immobilization bandages and related strategies are the best interventions to delay onset of systemic toxicity from venomous snakebites but may increase local toxicity for venoms that destroy tissue at the site of the bite, so their use should be individualized to the circumstances and nature of the venom. View Full-Text   Abstract
Migrants living in low incidence countries, including New Zealand (NZ), are disproportionately affected by tuberculosis (TB). This foreign-born group poses important challenges to achieving the national TB elimination targets. Thus, the aim of this study was to contribute to the understandingof factors that influence the incidence of TB among African migrants living in NZ. We employed a semi-structured interview approach to explore the perceptions of NZ-based African community leaders, health professionals and a non-governmental TB support organisation about the wider determinants of TB. The findings, though not completely generalizable, suggest that many NZ-based Africans endure a difficult process of integration, perceive themselves as least susceptible to TB and have low awareness about available health services. Furthermore, the cost of general practitioner (GP) services, mistrust of health professionals, TB stigma and the NZ immigration policy were indicated as important barriers to TB services. Strategies to address TB among migrants must therefore be more holistic and not be centred on a fragmented approach that overemphasises the biomedical approaches, as the incidence of TB is more likely the outcome of a complex interplay of several underlying factors. View Full-Text "," echinococcus,hydatid disease,tree-kangaroo,zoonosis,public health   Strongyloides stercoralis,hyperinfection,HIV,parenteral ivermectin   snakebites,first aid,emergency medicine services,pressure immobilization bandages   tuberculosis,African,migrant,determinants,elimination "," Echinococcus Granulosus Infection in Two Free-Ranging Lumholtz’sTree-Kangaroo (Dendrolagus lumholtzi) from the Atherton Tablelands, Queensland   Strongyloides stercoralis Hyperinfection in an HIV-Infected Patient Successfully Treated with Subcutaneous Ivermectin   First Aid and Pre-Hospital Management of Venomous Snakebites   Towards TB Elimination in Aotearoa/New Zealand: Key Informant Insights on the Determinants of TB among African Migrants   Abstract
Infection with the larval stage of the cestode, Echinococcus granulosus sensu lato (s.l.), causes hydatid disease (hydatidosis) in a range of hosts, including macropods and other marsupials, cattle, and humans. Wild macropods are an important sylvatic reservoir for the life cycle of E. granulosus (s.l.) in Australia, and so provide a conduit for transmission of hydatid disease to domestic animals and humans. Two Lumholtz’s tree-kangaroos (Dendrolagus lumholtzi) from the Atherton Tablelands of Far North Queensland were recently found to have hydatid cysts in both liver and lung tissues. Tree-kangaroos may travel across the ground between patches of forest but are primarily arboreal leaf-eating macropods. The finding of hydatid cysts in an arboreal folivore may indicate that the area has a high level of contamination with eggs of E. granulosus (s.l.). This finding may be of significance to human health as well as indicating the need for further investigation into the prevalence of hydatid disease in domestic stock, wildlife and humans living in this rapidly urbanizing region. View Full-Text   Abstract
A 39-year-old Ethiopian HIV-positive man with peripheral T-cell lymphoma developed Strongyloides stercoralis hyperinfection. The patient was initially treated with oral ivermectin for three weeks without response, most likely due to malabsorption because of concomitant paralytic ileus. Given the persistence of larvae in the body fluids, the worsening respiratory status and clinical malabsorption, veterinary parenteral formulation of ivermectin was administered. The very high plasma concentration of ivermectin achieved in the patient after parenteral administration led to a rapid improvement in his clinical condition and rapid disappearance of the parasite from biological samples, without any adverse reaction. View Full-Text   Abstract
Background: Antivenom is the definitive treatment for venomous snakebites, but is expensive and not available in many rural and poorly developed regions. Timely transportation to facilities that stock and administer antivenom may not be available in rural areas with poorly developed emergency medical services. These factors have led to consideration of measures to delay onset of toxicity or alternatives to antivenom therapy. Methods: PubMed searches were conducted for articles on snakebite treatment, or that contained first aid, emergency medical services, tourniquets, pressure immobilization bandages, suction devices, and lymphatic flow inhibitors. Results: The reviewed articles describe how venoms spread after a venomous snakebite on an extremity, list the proposed first aid measures for delaying the spread of venoms, and evaluate the scientific studies that support or refute methods of snakebite first aid. The recommendations for field treatment of venomous snakebites will be discussed. Conclusions: The evidence suggests that pressure immobilization bandages and related strategies are the best interventions to delay onset of systemic toxicity from venomous snakebites but may increase local toxicity for venoms that destroy tissue at the site of the bite, so their use should be individualized to the circumstances and nature of the venom. View Full-Text   Abstract
Migrants living in low incidence countries, including New Zealand (NZ), are disproportionately affected by tuberculosis (TB). This foreign-born group poses important challenges to achieving the national TB elimination targets. Thus, the aim of this study was to contribute to the understandingof factors that influence the incidence of TB among African migrants living in NZ. We employed a semi-structured interview approach to explore the perceptions of NZ-based African community leaders, health professionals and a non-governmental TB support organisation about the wider determinants of TB. The findings, though not completely generalizable, suggest that many NZ-based Africans endure a difficult process of integration, perceive themselves as least susceptible to TB and have low awareness about available health services. Furthermore, the cost of general practitioner (GP) services, mistrust of health professionals, TB stigma and the NZ immigration policy were indicated as important barriers to TB services. Strategies to address TB among migrants must therefore be more holistic and not be centred on a fragmented approach that overemphasises the biomedical approaches, as the incidence of TB is more likely the outcome of a complex interplay of several underlying factors. View Full-Text   echinococcus,hydatid disease,tree-kangaroo,zoonosis,public health   Strongyloides stercoralis,hyperinfection,HIV,parenteral ivermectin   snakebites,first aid,emergency medicine services,pressure immobilization bandages   tuberculosis,African,migrant,determinants,elimination ", Tropical Medicine and Infectious Disease 
 Component-Specific Preliminary Engine Design Taking into Account Holistic Design Aspects†   Vortex Structure and Kinematics of Encased Axial Turbomachines†   The Influence of Different Wake Profiles on Losses in a Low Pressure Turbine Cascade †   Investigation on Thrust and Moment Coefficients of a Centrifugal Turbomachine† ," Abstract
Efficient aero engine operation requires not only optimized components like compressor, combustor, and turbine, but also an optimal balance between these components. Therefore, a holistic coupled optimization of the whole engine involving all relevant components would be advisable. Due to its high complexity and wide variety of design parameters, however, such an approach is not feasible, which is why today’s aero engine design process is typically split into different component-specific optimization sub-processes. To guarantee the final functionality, components are coupled by fixed aerodynamic and thermodynamic interface parameters predefined by simplified performance calculations early in the design process and held constant for all further design steps. In order not to miss the optimization potential of variable interface parameters and the unlimited design space on higher-fidelity design levels, different coupling and optimization strategies are investigated and demonstrated for a reduced compressor-combustor test case problem by use of 1D and 2D aero design tools. The new holistic design approach enables an exchange of information between components on a higher-fidelity design level than just simple thermodynamic equations, as well as the persecution of global engine design objectives like efficiency or emissions, and provides better results than separated component design with fixed interfaces. View Full-Text   Abstract
This paper models the kinematics of the vortex system of an encased axial turbomachine at part load and overload applying analytical methods. Thus far, the influence of the casing and the tip clearance on the kinematics have been solved separately. The vortex system is composed of a hub, bound and tip vortices. For the nominal operating point
φ≈
φ
opt
and negligible induction, the tip vortices transform into a screw. For part load operation
φ→0
the tip vortices wind up to a vortex ring, i.e., the pitch of the screw vanishes. The vortex ring itself is generated by bound vortices rotating at the angular frequency
Ω
. The hub vortex induces a velocity on the vortex ring causing a rotation at the sub-synchronous frequency
Ω
ind
=0.5Ω
. Besides, the vortex ring itself induces an axial velocity. Superimposed with the axial main flow this results in a stagnation point at the tube wall. This stagnation point may wrongly be interpreted as dynamic induced wall stall. For overload operation
φ→∞
the vortex system of the turbomachine forms a horseshoe, i.e., the pitch of the screw becomes infinite. Both hub and tip vortices are semi-infinite, straight vortex filaments. The tip vortices rotate against the rotating direction of the turbomachine due to the induction of the hub vortex yielding the induced frequency
Ω
ind
=−0.5Ω/s
with the tip clearance s. View Full-Text   Abstract
Large eddy simulations were carried out in order to investigate the influence of unsteady incoming wakes with different profiles on the loss mechanisms of the high lift T106Alinear low-pressure turbine (LPT) cascade. Bars placed upstream of the LPT blade were set into rotation around their axis, thus generating circulation, as well as asymmetrical wake profiles. Three different rotation rates were simulated, yielding different wake parameters that were then compared to an actual turbine blade wake profile. Whereas the commonly-used non-rotating bars generated wakes with turbulent kinetic energy levels several times higher than that of an actual blade wake, the case with counter-clockwise rotation led to more rapid wake mixing. All three wakes were able to trigger boundary layer transition and thus intermittently prevent separation on the suction surface. However, the weaker the wakes, the larger and longer lasting the separation bubbles became, and an increase in profile losses could be observed. Interestingly, the configuration with the weakest wake and the largest separation bubble resulted in a reduction of the overall LPT loss. View Full-Text   Abstract
In radial pumps and turbines, the centrifugal through-flow in both the front and the back chambers is quite common. It strongly impacts the core swirl ratio, pressure distribution, axial thrust and frictional torque. In order to investigate these relationships experimentally, a test rig was designed at the University of Duisburg-Essen and described in this paper. Based on both the experimental and numerical results, correlations are determined to predict the impacts of the centrifugal through-flow on the core swirl ratio, the thrust coefficient and the moment coefficient. Two correlations respectively are determined to associate the core swirl ratio with the local through-flow coefficient for both Batchelor type flow and Stewartson type flow. The correlations describing the thrust coefficient and the moment coefficient in a rotor-stator cavity with centripetal through-flow (Hu et al., 2017) are modified for the case of centrifugal through-flow. The Daily and Nece diagram distinguishing between different flow regimes in rotor-stator cavities is extended with a through-flow coordinate into 3D. The achieved results provide a comprehensive data base which is intended to support the calculation of axial thrust and moment coefficients during the design process of radial pumps and turbines in a more accurate manner. View Full-Text "," holistic optimization,aero engines,aerodynamic design   vortex dynamics,potential flow,part load,overload,sub-synchronous frequency,kinemtatic induced noise   low-pressure turbine,wake boundary layer interaction,transition,incoming wakes,unsteady effects   rotor-stator cavity,centrifugal through-flow,core swirl ratio,pressure,thrust coefficient,moment coefficient "," Component-Specific Preliminary Engine Design Taking into Account Holistic Design Aspects†   Vortex Structure and Kinematics of Encased Axial Turbomachines†   The Influence of Different Wake Profiles on Losses in a Low Pressure Turbine Cascade †   Investigation on Thrust and Moment Coefficients of a Centrifugal Turbomachine†   Abstract
Efficient aero engine operation requires not only optimized components like compressor, combustor, and turbine, but also an optimal balance between these components. Therefore, a holistic coupled optimization of the whole engine involving all relevant components would be advisable. Due to its high complexity and wide variety of design parameters, however, such an approach is not feasible, which is why today’s aero engine design process is typically split into different component-specific optimization sub-processes. To guarantee the final functionality, components are coupled by fixed aerodynamic and thermodynamic interface parameters predefined by simplified performance calculations early in the design process and held constant for all further design steps. In order not to miss the optimization potential of variable interface parameters and the unlimited design space on higher-fidelity design levels, different coupling and optimization strategies are investigated and demonstrated for a reduced compressor-combustor test case problem by use of 1D and 2D aero design tools. The new holistic design approach enables an exchange of information between components on a higher-fidelity design level than just simple thermodynamic equations, as well as the persecution of global engine design objectives like efficiency or emissions, and provides better results than separated component design with fixed interfaces. View Full-Text   Abstract
This paper models the kinematics of the vortex system of an encased axial turbomachine at part load and overload applying analytical methods. Thus far, the influence of the casing and the tip clearance on the kinematics have been solved separately. The vortex system is composed of a hub, bound and tip vortices. For the nominal operating point
φ≈
φ
opt
and negligible induction, the tip vortices transform into a screw. For part load operation
φ→0
the tip vortices wind up to a vortex ring, i.e., the pitch of the screw vanishes. The vortex ring itself is generated by bound vortices rotating at the angular frequency
Ω
. The hub vortex induces a velocity on the vortex ring causing a rotation at the sub-synchronous frequency
Ω
ind
=0.5Ω
. Besides, the vortex ring itself induces an axial velocity. Superimposed with the axial main flow this results in a stagnation point at the tube wall. This stagnation point may wrongly be interpreted as dynamic induced wall stall. For overload operation
φ→∞
the vortex system of the turbomachine forms a horseshoe, i.e., the pitch of the screw becomes infinite. Both hub and tip vortices are semi-infinite, straight vortex filaments. The tip vortices rotate against the rotating direction of the turbomachine due to the induction of the hub vortex yielding the induced frequency
Ω
ind
=−0.5Ω/s
with the tip clearance s. View Full-Text   Abstract
Large eddy simulations were carried out in order to investigate the influence of unsteady incoming wakes with different profiles on the loss mechanisms of the high lift T106Alinear low-pressure turbine (LPT) cascade. Bars placed upstream of the LPT blade were set into rotation around their axis, thus generating circulation, as well as asymmetrical wake profiles. Three different rotation rates were simulated, yielding different wake parameters that were then compared to an actual turbine blade wake profile. Whereas the commonly-used non-rotating bars generated wakes with turbulent kinetic energy levels several times higher than that of an actual blade wake, the case with counter-clockwise rotation led to more rapid wake mixing. All three wakes were able to trigger boundary layer transition and thus intermittently prevent separation on the suction surface. However, the weaker the wakes, the larger and longer lasting the separation bubbles became, and an increase in profile losses could be observed. Interestingly, the configuration with the weakest wake and the largest separation bubble resulted in a reduction of the overall LPT loss. View Full-Text   Abstract
In radial pumps and turbines, the centrifugal through-flow in both the front and the back chambers is quite common. It strongly impacts the core swirl ratio, pressure distribution, axial thrust and frictional torque. In order to investigate these relationships experimentally, a test rig was designed at the University of Duisburg-Essen and described in this paper. Based on both the experimental and numerical results, correlations are determined to predict the impacts of the centrifugal through-flow on the core swirl ratio, the thrust coefficient and the moment coefficient. Two correlations respectively are determined to associate the core swirl ratio with the local through-flow coefficient for both Batchelor type flow and Stewartson type flow. The correlations describing the thrust coefficient and the moment coefficient in a rotor-stator cavity with centripetal through-flow (Hu et al., 2017) are modified for the case of centrifugal through-flow. The Daily and Nece diagram distinguishing between different flow regimes in rotor-stator cavities is extended with a through-flow coordinate into 3D. The achieved results provide a comprehensive data base which is intended to support the calculation of axial thrust and moment coefficients during the design process of radial pumps and turbines in a more accurate manner. View Full-Text   holistic optimization,aero engines,aerodynamic design   vortex dynamics,potential flow,part load,overload,sub-synchronous frequency,kinemtatic induced noise   low-pressure turbine,wake boundary layer interaction,transition,incoming wakes,unsteady effects   rotor-stator cavity,centrifugal through-flow,core swirl ratio,pressure,thrust coefficient,moment coefficient "," International Journal of Turbomachinery, Propulsion and Power "
 Development of Framework for Aggregation and Visualization of Three-Dimensional (3D) Spatial Data   A Deep Learning Model of Perception in Color-Letter Synesthesia   A Multi-Modality Deep Network for Cold-Start Recommendation ," Abstract
Geospatial information plays an important role in environmental modelling, resource management, business operations, and government policy. However, very little or no commonality between formats of various geospatial data has led to difficulties in utilizing the available geospatial information. These disparate data sources must be aggregated before further extraction and analysis may be performed. The objective of this paper is to develop a framework called PlaniSphere, which aggregates various geospatial datasets, synthesizes raw data, and allows for third party customizations of the software. PlaniSphere uses NASA World Wind to access remote data and map servers using Web Map Service (WMS) as the underlying protocol that supports service-oriented architecture (SOA). The results show that PlaniSphere can aggregate and parses files that reside in local storage and conforms to the following formats: GeoTIFF, ESRI shape files, and KML. Spatial data retrieved using WMS from the Internet can create geospatial data sets (map data) from multiple sources, regardless of who the data providers are. The plug-in function of this framework can be expanded for wider uses, such as aggregating and fusing geospatial data from different data sources, by providing customizations to serve future uses, which the capacity of the commercial ESRI ArcGIS software is limited to add libraries and tools due to its closed-source architectures and proprietary data structures. Analysis and increasing availability of geo-referenced data may provide an effective way to manage spatial information by using large-scale storage, multidimensional data management, and Online Analytical Processing (OLAP) capabilities in one system. View Full-Text   Abstract
Synesthesia is a psychological phenomenon where sensory signals become mixed. Input to one sensory modality produces an experience in a second, unstimulated modality. In “grapheme-color synesthesia”, viewed letters and numbers evoke mental imagery of colors. The study of this condition has implications for increasing our understanding of brain architecture and function, language, memory and semantics, and the nature of consciousness. In this work, we propose a novel application of deep learning to model perception in grapheme-color synesthesia. Achromatic letter images, taken from database of handwritten characters, are used to train the model, and to induce computational synesthesia. Results show the model learns to accurately create a colored version of the inducing stimulus, according to a statistical distribution from experiments on a sample population of grapheme-color synesthetes. To the author’s knowledge, this work represents the first model that accurately produces spontaneous, creative mental imagery characteristic of the synesthetic perceptual experience. Experiments in cognitive science have contributed to our understanding of some of the observable behavioral effects of synesthesia, and previous models have outlined neural mechanisms that may account for these observations. A model of synesthesia that generates testable predictions on brain activity and behavior is needed to complement large scale data collection efforts in neuroscience, especially when articulating simple descriptions of cause (stimulus) and effect (behavior). The research and modeling approach reported here provides a framework that begins to address this need. View Full-Text   Abstract
Collaborative filtering (CF) approaches, which provide recommendations based on ratings or purchase history, perform well for users and items with sufficient interactions. However, CF approaches suffer from the cold-start problem for users and items with few ratings. Hybrid recommender systems that combine collaborative filtering and content-based approaches have been proved as an effective way to alleviate the cold-start issue. Integrating contents from multiple heterogeneous data sources such as reviews and product images is challenging for two reasons. Firstly, mapping contents in different modalities from the original feature space to a joint lower-dimensional space is difficult since they have intrinsically different characteristics and statistical properties, such as sparse texts and dense images. Secondly, most algorithms only use content features as the prior knowledge to improve the estimation of user and item profiles but the ratings do not directly provide feedback to guide feature extraction. To tackle these challenges, we propose a tightly-coupled deep network model for fusing heterogeneous modalities, to avoid tedious feature extraction in specific domains, and to enable two-way information propagation from both content and rating information. Experiments on large-scale Amazon product data in book and movie domains demonstrate the effectiveness of the proposed model for cold-start recommendation. View Full-Text "," spatial data fusion,environmental modelling,geospatial information,data mapping,software,big data   synesthesia,deep learning network,color perception,generative adversarial network,cognitive modeling,character recognition,GPU computing   recommender system,deep learning,multimodal learning "," Development of Framework for Aggregation and Visualization of Three-Dimensional (3D) Spatial Data   A Deep Learning Model of Perception in Color-Letter Synesthesia   A Multi-Modality Deep Network for Cold-Start Recommendation   Abstract
Geospatial information plays an important role in environmental modelling, resource management, business operations, and government policy. However, very little or no commonality between formats of various geospatial data has led to difficulties in utilizing the available geospatial information. These disparate data sources must be aggregated before further extraction and analysis may be performed. The objective of this paper is to develop a framework called PlaniSphere, which aggregates various geospatial datasets, synthesizes raw data, and allows for third party customizations of the software. PlaniSphere uses NASA World Wind to access remote data and map servers using Web Map Service (WMS) as the underlying protocol that supports service-oriented architecture (SOA). The results show that PlaniSphere can aggregate and parses files that reside in local storage and conforms to the following formats: GeoTIFF, ESRI shape files, and KML. Spatial data retrieved using WMS from the Internet can create geospatial data sets (map data) from multiple sources, regardless of who the data providers are. The plug-in function of this framework can be expanded for wider uses, such as aggregating and fusing geospatial data from different data sources, by providing customizations to serve future uses, which the capacity of the commercial ESRI ArcGIS software is limited to add libraries and tools due to its closed-source architectures and proprietary data structures. Analysis and increasing availability of geo-referenced data may provide an effective way to manage spatial information by using large-scale storage, multidimensional data management, and Online Analytical Processing (OLAP) capabilities in one system. View Full-Text   Abstract
Synesthesia is a psychological phenomenon where sensory signals become mixed. Input to one sensory modality produces an experience in a second, unstimulated modality. In “grapheme-color synesthesia”, viewed letters and numbers evoke mental imagery of colors. The study of this condition has implications for increasing our understanding of brain architecture and function, language, memory and semantics, and the nature of consciousness. In this work, we propose a novel application of deep learning to model perception in grapheme-color synesthesia. Achromatic letter images, taken from database of handwritten characters, are used to train the model, and to induce computational synesthesia. Results show the model learns to accurately create a colored version of the inducing stimulus, according to a statistical distribution from experiments on a sample population of grapheme-color synesthetes. To the author’s knowledge, this work represents the first model that accurately produces spontaneous, creative mental imagery characteristic of the synesthetic perceptual experience. Experiments in cognitive science have contributed to our understanding of some of the observable behavioral effects of synesthesia, and previous models have outlined neural mechanisms that may account for these observations. A model of synesthesia that generates testable predictions on brain activity and behavior is needed to complement large scale data collection efforts in neuroscience, especially when articulating simple descriptions of cause (stimulus) and effect (behavior). The research and modeling approach reported here provides a framework that begins to address this need. View Full-Text   Abstract
Collaborative filtering (CF) approaches, which provide recommendations based on ratings or purchase history, perform well for users and items with sufficient interactions. However, CF approaches suffer from the cold-start problem for users and items with few ratings. Hybrid recommender systems that combine collaborative filtering and content-based approaches have been proved as an effective way to alleviate the cold-start issue. Integrating contents from multiple heterogeneous data sources such as reviews and product images is challenging for two reasons. Firstly, mapping contents in different modalities from the original feature space to a joint lower-dimensional space is difficult since they have intrinsically different characteristics and statistical properties, such as sparse texts and dense images. Secondly, most algorithms only use content features as the prior knowledge to improve the estimation of user and item profiles but the ratings do not directly provide feedback to guide feature extraction. To tackle these challenges, we propose a tightly-coupled deep network model for fusing heterogeneous modalities, to avoid tedious feature extraction in specific domains, and to enable two-way information propagation from both content and rating information. Experiments on large-scale Amazon product data in book and movie domains demonstrate the effectiveness of the proposed model for cold-start recommendation. View Full-Text   spatial data fusion,environmental modelling,geospatial information,data mapping,software,big data   synesthesia,deep learning network,color perception,generative adversarial network,cognitive modeling,character recognition,GPU computing   recommender system,deep learning,multimodal learning ", Big Data and Cognitive Computing 
 The Craft of Fractional Modeling in Science and Engineering 2017   Option Pricing Models Driven by the Space-Time Fractional Diffusion: Series Representation and Applications   Identifying the Fractional Orders in Anomalous Diffusion Models from Real Data   A Fractional B-spline Collocation Method for the Numerical Solution of Fractional Predator-Prey Models ," No abstract available View Full-Text   Abstract
In this paper, we focus on option pricing models based on space-time fractional diffusion. We briefly revise recent results which show that the option price can be represented in the terms of rapidly converging double-series and apply these results to the data from real markets. We focus on estimation of model parameters from the market data and estimation of implied volatility within the space-time fractional option pricing models. View Full-Text   Abstract
An attempt is made to identify the orders of the fractional derivatives in a simple anomalous diffusion model, starting from real data. We consider experimental data taken at the Columbus Air Force Base in Mississippi. Using as a model a one-dimensional fractional diffusion equation in both space and time, we fit the data by choosing several values of the fractional orders and computing the infinite-norm “errors”, representing the discrepancy between the numerical solution to the model equation and the experimental data. Data were also filtered before being used, to see possible improvements. The minimal discrepancy is attained correspondingly to a fractional order in time around
0.6
and a fractional order in space near 2. These results may describe well the memory properties of the porous medium that can be observed. View Full-Text   Abstract
We present a collocation method based on fractional B-splines for the solution of fractional differential problems. The key-idea is to use the space generated by the fractional B-splines, i.e., piecewise polynomials of noninteger degree, as approximating space. Then, in the collocation step the fractional derivative of the approximating function is approximated accurately and efficiently by an exact differentiation rule that involves the generalized finite difference operator. To show the effectiveness of the method for the solution of nonlinear dynamical systems of fractional order, we solved the fractional Lotka-Volterra model and a fractional predator-pray model with variable coefficients. The numerical tests show that the method we proposed is accurate while keeping a low computational cost. View Full-Text ","    space-time fractional diffusion,European option pricing,Mellin transform,multidimensional complex analysis   inverse problems,anomalous diffusion,fractional differential equations   nonlinear fractional differential system,fractional predator-prey model,fractional B-spline,collocation method "," The Craft of Fractional Modeling in Science and Engineering 2017   Option Pricing Models Driven by the Space-Time Fractional Diffusion: Series Representation and Applications   Identifying the Fractional Orders in Anomalous Diffusion Models from Real Data   A Fractional B-spline Collocation Method for the Numerical Solution of Fractional Predator-Prey Models   No abstract available View Full-Text   Abstract
In this paper, we focus on option pricing models based on space-time fractional diffusion. We briefly revise recent results which show that the option price can be represented in the terms of rapidly converging double-series and apply these results to the data from real markets. We focus on estimation of model parameters from the market data and estimation of implied volatility within the space-time fractional option pricing models. View Full-Text   Abstract
An attempt is made to identify the orders of the fractional derivatives in a simple anomalous diffusion model, starting from real data. We consider experimental data taken at the Columbus Air Force Base in Mississippi. Using as a model a one-dimensional fractional diffusion equation in both space and time, we fit the data by choosing several values of the fractional orders and computing the infinite-norm “errors”, representing the discrepancy between the numerical solution to the model equation and the experimental data. Data were also filtered before being used, to see possible improvements. The minimal discrepancy is attained correspondingly to a fractional order in time around
0.6
and a fractional order in space near 2. These results may describe well the memory properties of the porous medium that can be observed. View Full-Text   Abstract
We present a collocation method based on fractional B-splines for the solution of fractional differential problems. The key-idea is to use the space generated by the fractional B-splines, i.e., piecewise polynomials of noninteger degree, as approximating space. Then, in the collocation step the fractional derivative of the approximating function is approximated accurately and efficiently by an exact differentiation rule that involves the generalized finite difference operator. To show the effectiveness of the method for the solution of nonlinear dynamical systems of fractional order, we solved the fractional Lotka-Volterra model and a fractional predator-pray model with variable coefficients. The numerical tests show that the method we proposed is accurate while keeping a low computational cost. View Full-Text      space-time fractional diffusion,European option pricing,Mellin transform,multidimensional complex analysis   inverse problems,anomalous diffusion,fractional differential equations   nonlinear fractional differential system,fractional predator-prey model,fractional B-spline,collocation method ", Fractal and Fractional 
 Biosensor-Mediated In Situ Imaging Defines the Availability Period of Assimilatory Glutamine in Maize Seedling Leaves Following Nitrogen Fertilization   Nitrogen: A New Cross-Disciplinary International Open Access Journal ," Abstract
The amino acid glutamine (Gln) is an important assimilatory intermediate between root-derived inorganic nitrogen (N) (i.e., ammonium) and downstream macromolecules, and is a central regulator in plant N physiology. The timing of Gln accumulation after N uptake by roots has been well characterized. However, the duration of availability of accumulated Gln at a sink tissue has not been well defined. Measuring Gln availability would require temporal measurements of both Gln accumulation and its reciprocal depletion. Furthermore, as Gln varies spatially within a tissue, whole-organ in situ visualization would be valuable. Here, the accumulation and subsequent disappearance of Gln in maize seedling leaves (Zea mays L.) was imaged in situ throughout the 48 h after N application to roots of N-deprived plants. Free Gln was imaged by placing leaves onto agar embedded with bacterial biosensor cells (GlnLux) that emit luminescence in the presence of leaf-derived Gln. Seedling leaves 1, 2, and 3 were imaged simultaneously to measure Gln availability across tissues that potentially vary in N sink strength. The results show that following root N fertilization, free Gln accumulates and then disappears with an availability period of up to 24 h following peak accumulation. The availability period of Gln was similar in all seedling leaves, but the amount of accumulation was leaf specific. As Gln is not only a metabolic intermediate, but also a signaling molecule, the potential importance of regulating its temporal availability within plant tissues is discussed. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Nitrogen, the element that is intimately associated with essentially all processes on Earth, is the broad focus of a new online, open access journal.[...] View Full-Text "," glutamine,Zea mays,assimilation,nitrogen use efficiency,utilization,biosensor,regulation    "," Biosensor-Mediated In Situ Imaging Defines the Availability Period of Assimilatory Glutamine in Maize Seedling Leaves Following Nitrogen Fertilization   Nitrogen: A New Cross-Disciplinary International Open Access Journal   Abstract
The amino acid glutamine (Gln) is an important assimilatory intermediate between root-derived inorganic nitrogen (N) (i.e., ammonium) and downstream macromolecules, and is a central regulator in plant N physiology. The timing of Gln accumulation after N uptake by roots has been well characterized. However, the duration of availability of accumulated Gln at a sink tissue has not been well defined. Measuring Gln availability would require temporal measurements of both Gln accumulation and its reciprocal depletion. Furthermore, as Gln varies spatially within a tissue, whole-organ in situ visualization would be valuable. Here, the accumulation and subsequent disappearance of Gln in maize seedling leaves (Zea mays L.) was imaged in situ throughout the 48 h after N application to roots of N-deprived plants. Free Gln was imaged by placing leaves onto agar embedded with bacterial biosensor cells (GlnLux) that emit luminescence in the presence of leaf-derived Gln. Seedling leaves 1, 2, and 3 were imaged simultaneously to measure Gln availability across tissues that potentially vary in N sink strength. The results show that following root N fertilization, free Gln accumulates and then disappears with an availability period of up to 24 h following peak accumulation. The availability period of Gln was similar in all seedling leaves, but the amount of accumulation was leaf specific. As Gln is not only a metabolic intermediate, but also a signaling molecule, the potential importance of regulating its temporal availability within plant tissues is discussed. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Nitrogen, the element that is intimately associated with essentially all processes on Earth, is the broad focus of a new online, open access journal.[...] View Full-Text   glutamine,Zea mays,assimilation,nitrogen use efficiency,utilization,biosensor,regulation    ", Nitrogen 
 Nanosensors for Monitoring Bacterial Growth Kinetics and Response to Antibiotics†   Communicating Knowledge and Knowledge of Communication†   Image/Imagery/Imagination in Psychology†   Deliberate Communication with Pictures: A Science Fiction?† ," Abstract
Miniaturized and cost-efficient methods aiming at high throughput analysis of microbes is of   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
In De interpretation, Aristotle writes that those of the voice are symbols of the motions of the soul while the written signs are symbols of those of the voice (16 a, 3-4). [...]   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Nowadays, scientific research is more and more specialized and the same is true for scientific meetings and workshops. [...]   Abstract
There are assumptions about images and how these compare with words, in terms of what is afforded us in communicating with each other. These assumptions have been limited by religion and economic imperatives in the past, and by education systems that grew out of those vested interests. One way to push past these assumptions might be to imagine a world without writing. Some science fiction examples are examined for their feasibility. In addition, the reader is reminded of humanity’s pre-writing past, and that pictures that survived from then are viewed through our present contextual lenses as containing a child-like view of the universe. This view has not been helped in western history by hundreds of years of monotheism and its vested interest in framing earlier belief systems as perverse. The origins of writing however, were completely bound up with accounting for production, for tax collecting and distribution, with specialization into occupations: the beginnings of the organized state. Could a future of pictures-only give us the deliberate communication we’d need for these exchanges or is that also science fiction? The major assumption to overcome is that the dependability of words anchors the waywardness of pictures. This paper shows some quotidian examples of picture-only communications which do not invite ambiguous or vague interpretations, and examples are given where pictures can disambiguate words. The future is most likely to witness the further compression of writing, not its total eradication; it is likely that the co-presence of writing and pictures makes for clearest communication. How would communicators be trained to be productive members of such a world? Research into style, pattern recognition and comprehension are necessary to further break down the historical assumptions about what constitutes good depiction. We need to break the spell of visual realism; to see it as only one of many choices for capturing the image, and to see the schema that make pictures up as components that can be taken apart and reassembled. The paper concludes with some examples of science-fiction curricula given to design students to broaden their thinking about the future potential for visual communications. ","          visual communication,visual realism,future,science-fiction "," Nanosensors for Monitoring Bacterial Growth Kinetics and Response to Antibiotics†   Communicating Knowledge and Knowledge of Communication†   Image/Imagery/Imagination in Psychology†   Deliberate Communication with Pictures: A Science Fiction?†   Abstract
Miniaturized and cost-efficient methods aiming at high throughput analysis of microbes is of   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
In De interpretation, Aristotle writes that those of the voice are symbols of the motions of the soul while the written signs are symbols of those of the voice (16 a, 3-4). [...]   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Nowadays, scientific research is more and more specialized and the same is true for scientific meetings and workshops. [...]   Abstract
There are assumptions about images and how these compare with words, in terms of what is afforded us in communicating with each other. These assumptions have been limited by religion and economic imperatives in the past, and by education systems that grew out of those vested interests. One way to push past these assumptions might be to imagine a world without writing. Some science fiction examples are examined for their feasibility. In addition, the reader is reminded of humanity’s pre-writing past, and that pictures that survived from then are viewed through our present contextual lenses as containing a child-like view of the universe. This view has not been helped in western history by hundreds of years of monotheism and its vested interest in framing earlier belief systems as perverse. The origins of writing however, were completely bound up with accounting for production, for tax collecting and distribution, with specialization into occupations: the beginnings of the organized state. Could a future of pictures-only give us the deliberate communication we’d need for these exchanges or is that also science fiction? The major assumption to overcome is that the dependability of words anchors the waywardness of pictures. This paper shows some quotidian examples of picture-only communications which do not invite ambiguous or vague interpretations, and examples are given where pictures can disambiguate words. The future is most likely to witness the further compression of writing, not its total eradication; it is likely that the co-presence of writing and pictures makes for clearest communication. How would communicators be trained to be productive members of such a world? Research into style, pattern recognition and comprehension are necessary to further break down the historical assumptions about what constitutes good depiction. We need to break the spell of visual realism; to see it as only one of many choices for capturing the image, and to see the schema that make pictures up as components that can be taken apart and reassembled. The paper concludes with some examples of science-fiction curricula given to design students to broaden their thinking about the future potential for visual communications.            visual communication,visual realism,future,science-fiction ", Proceedings 
 Use of UAV-Borne Spectrometer for Land Cover Classification   Vision-Based Autonomous Landing of a Quadrotor on the Perturbed Deck of an Unmanned Surface Vehicle   A Novel Approach for Brushless DC Motors Characterization in Drones Based on Chaos   Development of Small UAS Beyond-Visual-Line-of-Sight (BVLOS) Flight Operations: System Requirements and Procedures ," Abstract
Unmanned aerial vehicles (UAV) are being used for low altitude remote sensing for thematic land classification using visible light and multi-spectral sensors. The objective of this work was to investigate the use of UAV equipped with a compact spectrometer for land cover classification. The UAV platform used was a DJI Flamewheel F550 hexacopter equipped with GPS and Inertial Measurement Unit (IMU) navigation sensors, and a Raspberry Pi processor and camera module. The spectrometer used was the FLAME-NIR, a near-infrared spectrometer for hyperspectral measurements. RGB images and spectrometer data were captured simultaneously. As spectrometer data do not provide continuous terrain coverage, the locations of their ground elliptical footprints were determined from the bundle adjustment solution of the captured images. For each of the spectrometer ground ellipses, the land cover signature at the footprint location was determined to enable the characterization, identification, and classification of land cover elements. To attain a continuous land cover classification map, spatial interpolation was carried out from the irregularly distributed labeled spectrometer points. The accuracy of the classification was assessed using spatial intersection with the object-based image classification performed using the RGB images. Results show that in homogeneous land cover, like water, the accuracy of classification is 78% and in mixed classes, like grass, trees and manmade features, the average accuracy is 50%, thus, indicating the contribution of hyperspectral measurements of low altitude UAV-borne spectrometers to improve land cover classification. View Full-Text   Abstract
Autonomous landing on the deck of an unmanned surface vehicle (USV) is still a major challenge for unmanned aerial vehicles (UAVs). In this paper, a fiducial marker is located on the platform so as to facilitate the task since it is possible to retrieve its six-degrees of freedom relative-pose in an easy way. To compensate interruption in the marker’s observations, an extended Kalman filter (EKF) estimates the current USV’s position with reference to the last known position. Validation experiments have been performed in a simulated environment under various marine conditions. The results confirmed that the EKF provides estimates accurate enough to direct the UAV in proximity of the autonomous vessel such that the marker becomes visible again. Using only the odometry and the inertial measurements for the estimation, this method is found to be applicable even under adverse weather conditions in the absence of the global positioning system. View Full-Text   Abstract
A novel technique named Signal Analysis based on Chaos using Density of Maxima (SAC-DM) is presented to analyze Brushless Direct Current (BLDC) motors behavior. These motors are vastly used in electric vehicles, especially in Drones. The proposed approach is compared with the traditional Fast-Fourier Transform (FFT) and the experiments analyzing a BLDC motor of a drone demonstrates similar results but computationally simpler than that. The main contribution of this technique is the possibility to analyze signals in time domain, instead of the frequency domain. It is possible to identify working and faulty behavior with less computational resources than the traditional approach. View Full-Text   Abstract
Due to safety concerns of integrating small unmanned aircraft systems (UAS) into non-segregated airspace, aviation authorities have required a set of detect and avoid (DAA) systems to be equipped on small UAS for beyond-visual-line-of-sight (BVLOS) flight operations in civil airspace. However, the development of small UAS DAA systems also requires BVLOS flights for testing and validation. To mitigate operational risks for small UAS BVLOS flight operations, this paper proposes to initially test small UAS DAA systems in BVLOS flights in a restricted airspace with additional safety features. Later, this paper further discusses the operating procedures and emergency action plans for small UAS BVLOS flight operations. The testing results show that these safety systems developed can help improve operational safety for small UAS BVLOS flight operations. View Full-Text "," UAV,spectrometer,calibration,spectral exposure,classification,land cover   unmanned aerial vehicle,position control,computer vision,image processing   Chaos,Brushless DC Motors,Densitity of Maxima,UAVs   unmanned aircraft,detect and avoid,unmanned aircraft systems,command and control link,first person view,flight termination system,UA,DAA,UAS,C2,FPV,FTS,VLOS,BVLOS "," Use of UAV-Borne Spectrometer for Land Cover Classification   Vision-Based Autonomous Landing of a Quadrotor on the Perturbed Deck of an Unmanned Surface Vehicle   A Novel Approach for Brushless DC Motors Characterization in Drones Based on Chaos   Development of Small UAS Beyond-Visual-Line-of-Sight (BVLOS) Flight Operations: System Requirements and Procedures   Abstract
Unmanned aerial vehicles (UAV) are being used for low altitude remote sensing for thematic land classification using visible light and multi-spectral sensors. The objective of this work was to investigate the use of UAV equipped with a compact spectrometer for land cover classification. The UAV platform used was a DJI Flamewheel F550 hexacopter equipped with GPS and Inertial Measurement Unit (IMU) navigation sensors, and a Raspberry Pi processor and camera module. The spectrometer used was the FLAME-NIR, a near-infrared spectrometer for hyperspectral measurements. RGB images and spectrometer data were captured simultaneously. As spectrometer data do not provide continuous terrain coverage, the locations of their ground elliptical footprints were determined from the bundle adjustment solution of the captured images. For each of the spectrometer ground ellipses, the land cover signature at the footprint location was determined to enable the characterization, identification, and classification of land cover elements. To attain a continuous land cover classification map, spatial interpolation was carried out from the irregularly distributed labeled spectrometer points. The accuracy of the classification was assessed using spatial intersection with the object-based image classification performed using the RGB images. Results show that in homogeneous land cover, like water, the accuracy of classification is 78% and in mixed classes, like grass, trees and manmade features, the average accuracy is 50%, thus, indicating the contribution of hyperspectral measurements of low altitude UAV-borne spectrometers to improve land cover classification. View Full-Text   Abstract
Autonomous landing on the deck of an unmanned surface vehicle (USV) is still a major challenge for unmanned aerial vehicles (UAVs). In this paper, a fiducial marker is located on the platform so as to facilitate the task since it is possible to retrieve its six-degrees of freedom relative-pose in an easy way. To compensate interruption in the marker’s observations, an extended Kalman filter (EKF) estimates the current USV’s position with reference to the last known position. Validation experiments have been performed in a simulated environment under various marine conditions. The results confirmed that the EKF provides estimates accurate enough to direct the UAV in proximity of the autonomous vessel such that the marker becomes visible again. Using only the odometry and the inertial measurements for the estimation, this method is found to be applicable even under adverse weather conditions in the absence of the global positioning system. View Full-Text   Abstract
A novel technique named Signal Analysis based on Chaos using Density of Maxima (SAC-DM) is presented to analyze Brushless Direct Current (BLDC) motors behavior. These motors are vastly used in electric vehicles, especially in Drones. The proposed approach is compared with the traditional Fast-Fourier Transform (FFT) and the experiments analyzing a BLDC motor of a drone demonstrates similar results but computationally simpler than that. The main contribution of this technique is the possibility to analyze signals in time domain, instead of the frequency domain. It is possible to identify working and faulty behavior with less computational resources than the traditional approach. View Full-Text   Abstract
Due to safety concerns of integrating small unmanned aircraft systems (UAS) into non-segregated airspace, aviation authorities have required a set of detect and avoid (DAA) systems to be equipped on small UAS for beyond-visual-line-of-sight (BVLOS) flight operations in civil airspace. However, the development of small UAS DAA systems also requires BVLOS flights for testing and validation. To mitigate operational risks for small UAS BVLOS flight operations, this paper proposes to initially test small UAS DAA systems in BVLOS flights in a restricted airspace with additional safety features. Later, this paper further discusses the operating procedures and emergency action plans for small UAS BVLOS flight operations. The testing results show that these safety systems developed can help improve operational safety for small UAS BVLOS flight operations. View Full-Text   UAV,spectrometer,calibration,spectral exposure,classification,land cover   unmanned aerial vehicle,position control,computer vision,image processing   Chaos,Brushless DC Motors,Densitity of Maxima,UAVs   unmanned aircraft,detect and avoid,unmanned aircraft systems,command and control link,first person view,flight termination system,UA,DAA,UAS,C2,FPV,FTS,VLOS,BVLOS ", Drones 
" New Observations on High-Speed Machining of Hardened AISI 4340 Steel Using Alumina-Based Ceramic Tools   Application of Finite Element Method to Analyze the Influences of Process Parameters on the Cut Surface in Fine Blanking Processes by Using Clearance-Dependent Critical Fracture Criteria   The Static and Fatigue Behavior of AlSiMg Alloy Plain, Notched, and Diamond Lattice Specimens Fabricated by Laser Powder Bed Fusion "," Abstract
High-speed machining (HSM) is used in industry to improve the productivity and quality of the cutting operations. In this investigation, pure alumina ceramics with the addition of ZrO2, and mixed alumina (Al2O3 + TiC) tools were used in the dry hard turning of AISI 4340 (52 HRC) at different high cutting speeds of 150, 250, 700 and 1000 m/min. It was observed that at cutting speeds of 150 and 250 m/min, pure alumina ceramic tools had better wear resistance than mixed alumina ones. However, upon increasing the cutting speed from 700 to 1000 m/min, mixed alumina ceramic tools outperformed pure ceramic ones. Scanning electron microscopy (SEM) and X-ray photoelectron spectroscopy (XPS) were used to investigate the worn cutting edges and analyze the obtained results. It was found that the tribo-films formed at the cutting zone during machining affected the wear resistances of the tools and influenced the coefficient of friction at the tool-chip interface. These observations were confirmed by the chip compression ratio results at different cutting conditions. Raising cutting speed to 1000 m/min corresponded to a remarkable decrease in cutting force components in the dry hard turning of AISI 4340 steel. View Full-Text   Abstract
The correct choice of process parameters is important in predicting the cut surface and obtaining a fully-fine sheared surface in the fine blanking process. The researchers used the value of the critical fracture criterion obtained by long duration experiments to predict the conditions of cut surfaces in the fine blanking process. In this study, the clearance-dependent critical ductile fracture criteria obtained by the Cockcroft-Latham and Oyane criteria were used to reduce the time and cost of experiments to obtain the value of the critical fracture criterion. The Finite Element Method (FEM) was applied to fine blanking processes to study the influences of process parameters such as the initial compression, the punch and die corner radii and the shape and size of the V-ring indenter on the length of the sheared surface. The effects of stress triaxiality and punch diameters on the cut surface produced by the fine blanking process are also discussed. The verified process parameters and tool geometry for obtaining a fully-fine sheared SPCC surface are described. The results showed that the accurate and stable prediction of ductile fracture initiation can be achieved using the Oyane criterion. View Full-Text   Abstract
The fabrication of engineered lattice structures has recently gained momentum due to the development of novel additive manufacturing techniques. Interest in lattice structures resides not only in the possibility of obtaining efficient lightweight materials, but also in the functionality of pre-designed architectured structures for specific applications, such as biomimetic implants, chemical catalyzers, and heat transfer devices. The mechanical behaviour of lattice structures depends not only the composition of the base material, but also on the type and size of the unit cells, as well as on the material microstructure resulting from a specific fabrication procedure. The present work focuses on the static and fatigue behavior of diamond cell lattice structures fabricated from an AlSiMg alloy by laser powder bed fusion technology. In particular, the specimens were fabricated with three different orientations of lattice cells—[001], [011], [111]—and subjected to static tensile testing and force-controlled pull–pull fatigue testing up to 1 × 107 cycles. In parallel, the mechanical behavior of dense tensile plain and notched specimens was also studied and compared to that of their lattice counterparts. Results showed a significant effect of the cell orientation on the fatigue lives: specimens oriented at [001] were ~30% more fatigue-resistant than specimens oriented at [011] and [111]. View Full-Text "," high speed machining,Alumina-based ceramic tools,tool wear,AISI 4340 hardened steel   fracture criterion,sheared surface,finite element method,fine blanking   laser powder bed fusion,lattice structures,cell orientation,fatigue "," New Observations on High-Speed Machining of Hardened AISI 4340 Steel Using Alumina-Based Ceramic Tools   Application of Finite Element Method to Analyze the Influences of Process Parameters on the Cut Surface in Fine Blanking Processes by Using Clearance-Dependent Critical Fracture Criteria   The Static and Fatigue Behavior of AlSiMg Alloy Plain, Notched, and Diamond Lattice Specimens Fabricated by Laser Powder Bed Fusion   Abstract
High-speed machining (HSM) is used in industry to improve the productivity and quality of the cutting operations. In this investigation, pure alumina ceramics with the addition of ZrO2, and mixed alumina (Al2O3 + TiC) tools were used in the dry hard turning of AISI 4340 (52 HRC) at different high cutting speeds of 150, 250, 700 and 1000 m/min. It was observed that at cutting speeds of 150 and 250 m/min, pure alumina ceramic tools had better wear resistance than mixed alumina ones. However, upon increasing the cutting speed from 700 to 1000 m/min, mixed alumina ceramic tools outperformed pure ceramic ones. Scanning electron microscopy (SEM) and X-ray photoelectron spectroscopy (XPS) were used to investigate the worn cutting edges and analyze the obtained results. It was found that the tribo-films formed at the cutting zone during machining affected the wear resistances of the tools and influenced the coefficient of friction at the tool-chip interface. These observations were confirmed by the chip compression ratio results at different cutting conditions. Raising cutting speed to 1000 m/min corresponded to a remarkable decrease in cutting force components in the dry hard turning of AISI 4340 steel. View Full-Text   Abstract
The correct choice of process parameters is important in predicting the cut surface and obtaining a fully-fine sheared surface in the fine blanking process. The researchers used the value of the critical fracture criterion obtained by long duration experiments to predict the conditions of cut surfaces in the fine blanking process. In this study, the clearance-dependent critical ductile fracture criteria obtained by the Cockcroft-Latham and Oyane criteria were used to reduce the time and cost of experiments to obtain the value of the critical fracture criterion. The Finite Element Method (FEM) was applied to fine blanking processes to study the influences of process parameters such as the initial compression, the punch and die corner radii and the shape and size of the V-ring indenter on the length of the sheared surface. The effects of stress triaxiality and punch diameters on the cut surface produced by the fine blanking process are also discussed. The verified process parameters and tool geometry for obtaining a fully-fine sheared SPCC surface are described. The results showed that the accurate and stable prediction of ductile fracture initiation can be achieved using the Oyane criterion. View Full-Text   Abstract
The fabrication of engineered lattice structures has recently gained momentum due to the development of novel additive manufacturing techniques. Interest in lattice structures resides not only in the possibility of obtaining efficient lightweight materials, but also in the functionality of pre-designed architectured structures for specific applications, such as biomimetic implants, chemical catalyzers, and heat transfer devices. The mechanical behaviour of lattice structures depends not only the composition of the base material, but also on the type and size of the unit cells, as well as on the material microstructure resulting from a specific fabrication procedure. The present work focuses on the static and fatigue behavior of diamond cell lattice structures fabricated from an AlSiMg alloy by laser powder bed fusion technology. In particular, the specimens were fabricated with three different orientations of lattice cells—[001], [011], [111]—and subjected to static tensile testing and force-controlled pull–pull fatigue testing up to 1 × 107 cycles. In parallel, the mechanical behavior of dense tensile plain and notched specimens was also studied and compared to that of their lattice counterparts. Results showed a significant effect of the cell orientation on the fatigue lives: specimens oriented at [001] were ~30% more fatigue-resistant than specimens oriented at [011] and [111]. View Full-Text   high speed machining,Alumina-based ceramic tools,tool wear,AISI 4340 hardened steel   fracture criterion,sheared surface,finite element method,fine blanking   laser powder bed fusion,lattice structures,cell orientation,fatigue ", Journal of Manufacturing and Materials Processing 
" Silent Vestibulopathy in Asymmetric Hearing Loss Can Be a Sign of a Cerebellopontine Angle Tumor   A Study on the Relationship between the Intelligibility and Quality of Algorithmically-Modified Speech for Normal Hearing Listeners   Head and Neck Paraganglioma: Medical Assessment, Management, and Literature Update   Endoplasmic Reticulum Stress in Hearing Loss "," Abstract
The presence of an ipsilateral cerebellopontine angle (CPA) tumor should be ruled out in patients with asymmetric sensorineural hearing loss (ASNHL). Although many patients with CPA tumors have ipsilateral vestibular hypofunction, some of them do not experience dizziness even with ipsilateral vestibular hypofunction. We analyzed the incidence of CPA tumors among patients with ASNHL without subjective dizziness based on the presence of vestibulopathy. We hypothesized that a patient with silent unilateral vestibular hypofunction (UVH) is more likely to be diagnosed with a CPA tumor. Among 157 subjects who underwent MRI for ASNHL, those who did not have “subjective dizziness” were selected. All subjects underwent hearing and vestibular function tests. UVH was diagnosed if canal paresis ≥ 25%, positive head-shake nystagmus, or gain of head-impulse test < 0.8 were detected. The diameters of the CPA tumors were measured along the petrosal ridge on the axial plane of MRI. Among the enrolled subjects, 44 (28.02%) were diagnosed with a CPA tumor. The 37 patients (84.1%) with a CPA tumor had silent UVH, while only 33 of the 113 patients (29.2%) without a CPA tumor had silent UVH (chi-square test, odds ratio = 12.8, p < 0.001). Silent UVH in patients with ASNHL may be a sign of a CPA tumor. View Full-Text   Abstract
This study investigates the relationship between the intelligibility and quality of modified speech in noise and in quiet. Speech signals were processed by seven algorithms designed to increase speech intelligibility in noise without altering speech intensity. In three noise maskers, including both stationary and fluctuating noise at two signal-to-noise ratios (SNR), listeners identified keywords from unmodified or modified sentences. The intelligibility performance of each type of speech was measured as the listeners’ word recognition rate in each condition, while the quality was rated as a mean opinion score. In quiet, only the perceptual quality of each type of speech was assessed. The results suggest that when listening in noise, modification performance on improving intelligibility is more important than its potential negative impact on speech quality. However, when listening in quiet or at SNRs in which intelligibility is no longer an issue to listeners, the impact to speech quality due to modification becomes a concern. View Full-Text   Abstract
Head and neck paraganglioma (HNPGL) are rare, highly vascular; typically slow growing and mostly benign neoplasms arising from paraganglia cells. HNPGL cause morbidity via mass effect on adjacent structures (particularly the cranial nerves), invasion of the skull base and, rarely, catecholamine secretion with associated systemic effects. The last decade has seen significant progress in the understanding of HNPGL genetics, with pertinent implications for diagnostic assessment and management of patients and their relatives. The implicated genes code for three of the five subunits of mitochondrial enzyme succinate dehydrogenase (SDH); recent literature reports that approximately one third of all HNPGL are associated with SDH mutations—a prevalence significantly greater than traditionally thought. There are distinct phenotypical syndromes associated with mutations in each individual SDH subunit (SDHD, SDHB, SDHC, and SDHAF2). This article focuses on the clinical features of HNPGL, the implications of HNPGL genetics, and the current evidence relating to optimal identification, investigation, and management options in HNPGL, which are supported by reference to a personal series of 60 cases. HNPGL require a systematic and thorough assessment to appropriately guide management decisions, and a suggested algorithm is presented in this article. Recent developments are particularly pertinent to surgeons of multiple disciplines, including otolaryngology, neurosurgery, vascular, and general surgery. View Full-Text   Abstract
The endoplasmic reticulum (ER) plays important roles in coordinating protein biosynthesis and secretion in the cell. Accumulation of misfolded and/or unfolded proteins in the ER causes ER stress and the so-called unfolded protein response (UPR). The UPR alleviates ER stress through blocking protein synthesis and activating expression of chaperone genes, whereas prolonged UPR could induce cell death. Recent research has showed that ER stress and UPR are involved in hearing loss. Accordingly, animal experiments showed that chemical chaperones or ER stress inducers alleviate environment-related hearing loss, whereas ER stress inhibitor has been used to treat certain types of hereditary deafness. Further investigations are needed to fully understand the detailed mechanisms of how ER stress contributes to the loss of auditory function, which will help us to eventually develop ER-stress-related treatment of various types of deafness. View Full-Text "," asymmetric sensorineural hearing loss,cerebellopontine angle tumors,unilateral vestibular hypofunction   speech intelligibility,speech quality,normal hearing,speech modification,noise   paraganglioma,head and neck paraganglioma,neoplasms,head and neck,glomus tumor,succinate dehydrogenase   endoplasmic reticulum stress,unfolded protein response,hearing loss,hair cells "," Silent Vestibulopathy in Asymmetric Hearing Loss Can Be a Sign of a Cerebellopontine Angle Tumor   A Study on the Relationship between the Intelligibility and Quality of Algorithmically-Modified Speech for Normal Hearing Listeners   Head and Neck Paraganglioma: Medical Assessment, Management, and Literature Update   Endoplasmic Reticulum Stress in Hearing Loss   Abstract
The presence of an ipsilateral cerebellopontine angle (CPA) tumor should be ruled out in patients with asymmetric sensorineural hearing loss (ASNHL). Although many patients with CPA tumors have ipsilateral vestibular hypofunction, some of them do not experience dizziness even with ipsilateral vestibular hypofunction. We analyzed the incidence of CPA tumors among patients with ASNHL without subjective dizziness based on the presence of vestibulopathy. We hypothesized that a patient with silent unilateral vestibular hypofunction (UVH) is more likely to be diagnosed with a CPA tumor. Among 157 subjects who underwent MRI for ASNHL, those who did not have “subjective dizziness” were selected. All subjects underwent hearing and vestibular function tests. UVH was diagnosed if canal paresis ≥ 25%, positive head-shake nystagmus, or gain of head-impulse test < 0.8 were detected. The diameters of the CPA tumors were measured along the petrosal ridge on the axial plane of MRI. Among the enrolled subjects, 44 (28.02%) were diagnosed with a CPA tumor. The 37 patients (84.1%) with a CPA tumor had silent UVH, while only 33 of the 113 patients (29.2%) without a CPA tumor had silent UVH (chi-square test, odds ratio = 12.8, p < 0.001). Silent UVH in patients with ASNHL may be a sign of a CPA tumor. View Full-Text   Abstract
This study investigates the relationship between the intelligibility and quality of modified speech in noise and in quiet. Speech signals were processed by seven algorithms designed to increase speech intelligibility in noise without altering speech intensity. In three noise maskers, including both stationary and fluctuating noise at two signal-to-noise ratios (SNR), listeners identified keywords from unmodified or modified sentences. The intelligibility performance of each type of speech was measured as the listeners’ word recognition rate in each condition, while the quality was rated as a mean opinion score. In quiet, only the perceptual quality of each type of speech was assessed. The results suggest that when listening in noise, modification performance on improving intelligibility is more important than its potential negative impact on speech quality. However, when listening in quiet or at SNRs in which intelligibility is no longer an issue to listeners, the impact to speech quality due to modification becomes a concern. View Full-Text   Abstract
Head and neck paraganglioma (HNPGL) are rare, highly vascular; typically slow growing and mostly benign neoplasms arising from paraganglia cells. HNPGL cause morbidity via mass effect on adjacent structures (particularly the cranial nerves), invasion of the skull base and, rarely, catecholamine secretion with associated systemic effects. The last decade has seen significant progress in the understanding of HNPGL genetics, with pertinent implications for diagnostic assessment and management of patients and their relatives. The implicated genes code for three of the five subunits of mitochondrial enzyme succinate dehydrogenase (SDH); recent literature reports that approximately one third of all HNPGL are associated with SDH mutations—a prevalence significantly greater than traditionally thought. There are distinct phenotypical syndromes associated with mutations in each individual SDH subunit (SDHD, SDHB, SDHC, and SDHAF2). This article focuses on the clinical features of HNPGL, the implications of HNPGL genetics, and the current evidence relating to optimal identification, investigation, and management options in HNPGL, which are supported by reference to a personal series of 60 cases. HNPGL require a systematic and thorough assessment to appropriately guide management decisions, and a suggested algorithm is presented in this article. Recent developments are particularly pertinent to surgeons of multiple disciplines, including otolaryngology, neurosurgery, vascular, and general surgery. View Full-Text   Abstract
The endoplasmic reticulum (ER) plays important roles in coordinating protein biosynthesis and secretion in the cell. Accumulation of misfolded and/or unfolded proteins in the ER causes ER stress and the so-called unfolded protein response (UPR). The UPR alleviates ER stress through blocking protein synthesis and activating expression of chaperone genes, whereas prolonged UPR could induce cell death. Recent research has showed that ER stress and UPR are involved in hearing loss. Accordingly, animal experiments showed that chemical chaperones or ER stress inducers alleviate environment-related hearing loss, whereas ER stress inhibitor has been used to treat certain types of hereditary deafness. Further investigations are needed to fully understand the detailed mechanisms of how ER stress contributes to the loss of auditory function, which will help us to eventually develop ER-stress-related treatment of various types of deafness. View Full-Text   asymmetric sensorineural hearing loss,cerebellopontine angle tumors,unilateral vestibular hypofunction   speech intelligibility,speech quality,normal hearing,speech modification,noise   paraganglioma,head and neck paraganglioma,neoplasms,head and neck,glomus tumor,succinate dehydrogenase   endoplasmic reticulum stress,unfolded protein response,hearing loss,hair cells "," Journal of Otorhinolaryngology, Hearing and Balance Medicine "
" Optimum Electrode Configurations for Two-Probe, Four-Probe and Multi-Probe Schemes in Electrical Resistance Tomography for Delamination Identification in Carbon Fiber Reinforced Composites   Development of Pb-Free Nanocomposite Solder Alloys   Fatigue-Damage Evolution of Notched Composite Multilayered Structures under Tensile Loads   Prediction of the Fiber Orientation State and the Resulting Structural and Thermal Properties of Fiber Reinforced Additive Manufactured Composites Fabricated Using the Big Area Additive Manufacturing Process "," Abstract
Internal damage in Carbon Fiber Reinforced Polymer (CFRP) composites modifies the internal electrical conductivity of the composite material. Electrical Resistance Tomography (ERT) is a non-destructive evaluation (NDE) technique that determines the extent of damage based on electrical conductivity changes. Implementation of ERT for damage identification in CFRP composites requires the optimal selection of the sensing sites for accurate results. This selection depends on the measuring scheme used. The present work uses an effective independence (EI) measure for selecting the minimum set of measurements for ERT damage identification using three measuring schemes: two-probe, four-probe and multi-probe. The electrical potential field in two CFRP laminate layups with 14 electrodes is calculated using finite element analyses (FEA) for a set of specified delamination damage cases. The measuring schemes consider the cases of 14 electrodes distributed on both sides and seven electrodes on only one side of the laminate for each layup. The effectiveness of EI reduction is demonstrated by comparing the inverse identification results of delamination cases for the full and the reduced sets using the measuring schemes and electrode sets. This work shows that the EI measure optimally reduces electrode and electrode combinations in ERT based damage identification for different measuring schemes. View Full-Text   Abstract
As an alternative to conventional Pb-containing solder material, Sn–Ag–Cu (SAC) based alloys are at the forefront despite limitations associated with relatively poor strength and coarsening of grains/intermetallic compounds (IMCs) during aging/reflow. Accordingly, this study examines the improvement of properties of SAC alloys by incorporating nanoparticles in it. Two different types of nanoparticles were added in monolithic SAC alloy: (1) Al2O3 or (2) Fe and their effect on microstructure and thermal properties were investigated. Addition of Fe nanoparticles leads to the formation of FeSn2 IMCs alongside Ag3Sn and Cu6Sn5 from monolithic SAC alloy. Addition of Al2O3 nano-particles do not contribute to phase formation, however, remains dispersed along primary β-Sn grain boundaries and act as a grain refiner. As the addition of either Fe or Al2O3 nano-particles do not make any significant effect on thermal behavior, these reinforced nanocomposites are foreseen to provide better mechanical characteristics with respect to conventional monolithic SAC solder alloys. View Full-Text   Abstract
The problems discussed in the present paper are well-known both from the theoretical (numerical) and experimental point of view. The novelty of our approach depends on the application of hybrid experimental methods and a comparison of their effectiveness in the description of complicated fatigue problems arising in the analysis of the behavior of laminated panels with open holes and subjected to tensile loading. Three experimental methods were used: infrared thermography (passive), structural health monitoring (active), and digital image correlation. The experimental investigations were supplemented by the finite element description of the problem dealing mainly with the static behavior, monitoring the development and final fracture of composites. The considerations concern laminated panels oriented at ±45° with different types of holes, i.e., vertical elliptical, horizontal elliptical, and circular. View Full-Text   Abstract
Recent advances in Fused Filament Fabrication (FFF) include large material deposition rates and the addition of chopped carbon fibers to the filament feedstock. During processing, the flow field within the polymer melt orients the fiber suspension, which is important to quantify as the underlying fiber orientation influences the mechanical and thermal properties. This paper investigates the correlation between processing conditions and the resulting locally varying thermal-structural properties that dictate both the final part performance and part dimensionality. The flow domain includes both the confined and unconfined flow indicative of the extruder nozzle within the FFF deposition process. The resulting orientation is obtained through two different isotropic rotary diffusion models, the model by Folgar and Tucker and that of Wang et al., and a comparison is made to demonstrate the sensitivity of the deposited bead’s spatially varying orientation as well as the final processed part’s thermal-structural performance. The results indicate the sensitivity of the final part behavior is quite sensitive to the choice of the slowness parameter in the Wang et al. model. Results also show the need, albeit less than that of the choice of fiber interaction model, to include the extrudate swell and deposition within the flow domain. View Full-Text "," electrical resistance tomography,carbon fiber reinforced composites,optimization,damage identification   Pb free,solder alloy,nanocomposite,microstructure   fatigue,open holes tensile tests,infrared thermography,structural health monitoring,digital image correlation   additive manufacturing,short-fiber reinforcement,fiber orientation modeling,fiber interactions "," Optimum Electrode Configurations for Two-Probe, Four-Probe and Multi-Probe Schemes in Electrical Resistance Tomography for Delamination Identification in Carbon Fiber Reinforced Composites   Development of Pb-Free Nanocomposite Solder Alloys   Fatigue-Damage Evolution of Notched Composite Multilayered Structures under Tensile Loads   Prediction of the Fiber Orientation State and the Resulting Structural and Thermal Properties of Fiber Reinforced Additive Manufactured Composites Fabricated Using the Big Area Additive Manufacturing Process   Abstract
Internal damage in Carbon Fiber Reinforced Polymer (CFRP) composites modifies the internal electrical conductivity of the composite material. Electrical Resistance Tomography (ERT) is a non-destructive evaluation (NDE) technique that determines the extent of damage based on electrical conductivity changes. Implementation of ERT for damage identification in CFRP composites requires the optimal selection of the sensing sites for accurate results. This selection depends on the measuring scheme used. The present work uses an effective independence (EI) measure for selecting the minimum set of measurements for ERT damage identification using three measuring schemes: two-probe, four-probe and multi-probe. The electrical potential field in two CFRP laminate layups with 14 electrodes is calculated using finite element analyses (FEA) for a set of specified delamination damage cases. The measuring schemes consider the cases of 14 electrodes distributed on both sides and seven electrodes on only one side of the laminate for each layup. The effectiveness of EI reduction is demonstrated by comparing the inverse identification results of delamination cases for the full and the reduced sets using the measuring schemes and electrode sets. This work shows that the EI measure optimally reduces electrode and electrode combinations in ERT based damage identification for different measuring schemes. View Full-Text   Abstract
As an alternative to conventional Pb-containing solder material, Sn–Ag–Cu (SAC) based alloys are at the forefront despite limitations associated with relatively poor strength and coarsening of grains/intermetallic compounds (IMCs) during aging/reflow. Accordingly, this study examines the improvement of properties of SAC alloys by incorporating nanoparticles in it. Two different types of nanoparticles were added in monolithic SAC alloy: (1) Al2O3 or (2) Fe and their effect on microstructure and thermal properties were investigated. Addition of Fe nanoparticles leads to the formation of FeSn2 IMCs alongside Ag3Sn and Cu6Sn5 from monolithic SAC alloy. Addition of Al2O3 nano-particles do not contribute to phase formation, however, remains dispersed along primary β-Sn grain boundaries and act as a grain refiner. As the addition of either Fe or Al2O3 nano-particles do not make any significant effect on thermal behavior, these reinforced nanocomposites are foreseen to provide better mechanical characteristics with respect to conventional monolithic SAC solder alloys. View Full-Text   Abstract
The problems discussed in the present paper are well-known both from the theoretical (numerical) and experimental point of view. The novelty of our approach depends on the application of hybrid experimental methods and a comparison of their effectiveness in the description of complicated fatigue problems arising in the analysis of the behavior of laminated panels with open holes and subjected to tensile loading. Three experimental methods were used: infrared thermography (passive), structural health monitoring (active), and digital image correlation. The experimental investigations were supplemented by the finite element description of the problem dealing mainly with the static behavior, monitoring the development and final fracture of composites. The considerations concern laminated panels oriented at ±45° with different types of holes, i.e., vertical elliptical, horizontal elliptical, and circular. View Full-Text   Abstract
Recent advances in Fused Filament Fabrication (FFF) include large material deposition rates and the addition of chopped carbon fibers to the filament feedstock. During processing, the flow field within the polymer melt orients the fiber suspension, which is important to quantify as the underlying fiber orientation influences the mechanical and thermal properties. This paper investigates the correlation between processing conditions and the resulting locally varying thermal-structural properties that dictate both the final part performance and part dimensionality. The flow domain includes both the confined and unconfined flow indicative of the extruder nozzle within the FFF deposition process. The resulting orientation is obtained through two different isotropic rotary diffusion models, the model by Folgar and Tucker and that of Wang et al., and a comparison is made to demonstrate the sensitivity of the deposited bead’s spatially varying orientation as well as the final processed part’s thermal-structural performance. The results indicate the sensitivity of the final part behavior is quite sensitive to the choice of the slowness parameter in the Wang et al. model. Results also show the need, albeit less than that of the choice of fiber interaction model, to include the extrudate swell and deposition within the flow domain. View Full-Text   electrical resistance tomography,carbon fiber reinforced composites,optimization,damage identification   Pb free,solder alloy,nanocomposite,microstructure   fatigue,open holes tensile tests,infrared thermography,structural health monitoring,digital image correlation   additive manufacturing,short-fiber reinforcement,fiber orientation modeling,fiber interactions ", Journal of Composites Science 
 A Survey of ReRAM-Based Architectures for Processing-In-Memory and Neural Networks   A Machine Learning Approach to Determine Oyster Vessel Behavior   Category Maps Describe Driving Episodes Recorded with Event Data Recorders†   Learning to Teach Reinforcement Learning Agents ," Abstract
As data movement operations and power-budget become key bottlenecks in the design of computing systems, the interest in unconventional approaches such as processing-in-memory (PIM), machine learning (ML), and especially neural network (NN)-based accelerators has grown significantly. Resistive random access memory (ReRAM) is a promising technology for efficiently architecting PIM- and NN-based accelerators due to its capabilities to work as both: High-density/low-energy storage and in-memory computation/search engine. In this paper, we present a survey of techniques for designing ReRAM-based PIM and NN architectures. By classifying the techniques based on key parameters, we underscore their similarities and differences. This paper will be valuable for computer architects, chip designers and researchers in the area of machine learning. View Full-Text   Abstract
In this work, we address a multi-class classification task of oyster vessel behaviors determination by classifying them into four different classes: fishing, traveling, poling (exploring) and docked (anchored). The main purpose of this work is to automate the oyster vessel behaviors determination task using machine learning and to explore different techniques to improve the accuracy of the oyster vessel behavior prediction problem. To employ machine learning technique, two important descriptors: speed and net speed, are calculated from the trajectory data, recorded by a satellite communication system (Vessel Management System, VMS) attached to the vessels fishing on the public oyster grounds of Louisiana. We constructed a support vector machine (SVM) based method which employs Radial Basis Function (RBF) as a kernel to accurately predict the behavior of oyster vessels. Several validation and parameter optimization techniques were used to improve the accuracy of the SVM classifier. A total 93% of the trajectory data from a July 2013 to August 2014 dataset consisting of 612,700 samples for which the ground truth can be obtained using rule-based classifier is used for validation and independent testing of our method. The results show that the proposed SVM based method is able to correctly classify 99.99% of 612,700 samples using the 10-fold cross validation. Furthermore, we achieved a precision of 1.00, recall of 1.00, F1-score of 1.00 and a test accuracy of 99.99%, while performing an independent test using a subset of 93% of the dataset, which consists of 31,418 points. View Full-Text   Abstract
This study was conducted to create driving episodes using machine-learning-based algorithms that address long-term memory (LTM) and topological mapping. This paper presents a novel episodic memory model for driving safety according to traffic scenes. The model incorporates three important features: adaptive resonance theory (ART), which learns time-series features incrementally while maintaining stability and plasticity; self-organizing maps (SOMs), which represent input data as a map with topological relations using self-mapping characteristics; and counter propagation networks (CPNs), which label category maps using input features and counter signals. Category maps represent driving episode information that includes driving contexts and facial expressions. The bursting states of respective maps produce LTM created on ART as episodic memory. For a preliminary experiment using a driving simulator (DS), we measure gazes and face orientations of drivers as their internal information to create driving episodes. Moreover, we measure cognitive distraction according to effects on facial features shown in reaction to simulated near-misses. Evaluation of the experimentally obtained results show the possibility of using recorded driving episodes with image datasets obtained using an event data recorder (EDR) with two cameras. Using category maps, we visualize driving features according to driving scenes on a public road and an expressway. View Full-Text   Abstract
In this article, we study the transfer learning model of action advice under a budget. We focus on reinforcement learning teachers providing action advice to heterogeneous students playing the game of Pac-Man under a limited advice budget. First, we examine several critical factors affecting advice quality in this setting, such as the average performance of the teacher, its variance and the importance of reward discounting in advising. The experiments show that the best performers are not always the best teachers and reveal the non-trivial importance of the coefficient of variation (CV) as a statistic for choosing policies that generate advice. The CV statistic relates variance to the corresponding mean. Second, the article studies policy learning for distributing advice under a budget. Whereas most methods in the relevant literature rely on heuristics for advice distribution, we formulate the problem as a learning one and propose a novel reinforcement learning algorithm capable of learning when to advise or not. The proposed algorithm is able to advise even when it does not have knowledge of the student’s intended action and needs significantly less training time compared to previous learning approaches. Finally, in this article, we argue that learning to advise under a budget is an instance of a more generic learning problem: Constrained Exploitation Reinforcement Learning. View Full-Text "," review,memristor,resistive memory,artificial intelligence,machine learning,deep learning,hardware architecture,processing-in-memory,non-volatile memory,emerging memory technology   oyster vessel behavior,trajectory data,support vector machine,machine learning   episodic memory,context,facial expressions,category maps,event data recorder,unsupervised learning   machine learning,reinforcement learning,transfer learning,action advice,machine teaching "," A Survey of ReRAM-Based Architectures for Processing-In-Memory and Neural Networks   A Machine Learning Approach to Determine Oyster Vessel Behavior   Category Maps Describe Driving Episodes Recorded with Event Data Recorders†   Learning to Teach Reinforcement Learning Agents   Abstract
As data movement operations and power-budget become key bottlenecks in the design of computing systems, the interest in unconventional approaches such as processing-in-memory (PIM), machine learning (ML), and especially neural network (NN)-based accelerators has grown significantly. Resistive random access memory (ReRAM) is a promising technology for efficiently architecting PIM- and NN-based accelerators due to its capabilities to work as both: High-density/low-energy storage and in-memory computation/search engine. In this paper, we present a survey of techniques for designing ReRAM-based PIM and NN architectures. By classifying the techniques based on key parameters, we underscore their similarities and differences. This paper will be valuable for computer architects, chip designers and researchers in the area of machine learning. View Full-Text   Abstract
In this work, we address a multi-class classification task of oyster vessel behaviors determination by classifying them into four different classes: fishing, traveling, poling (exploring) and docked (anchored). The main purpose of this work is to automate the oyster vessel behaviors determination task using machine learning and to explore different techniques to improve the accuracy of the oyster vessel behavior prediction problem. To employ machine learning technique, two important descriptors: speed and net speed, are calculated from the trajectory data, recorded by a satellite communication system (Vessel Management System, VMS) attached to the vessels fishing on the public oyster grounds of Louisiana. We constructed a support vector machine (SVM) based method which employs Radial Basis Function (RBF) as a kernel to accurately predict the behavior of oyster vessels. Several validation and parameter optimization techniques were used to improve the accuracy of the SVM classifier. A total 93% of the trajectory data from a July 2013 to August 2014 dataset consisting of 612,700 samples for which the ground truth can be obtained using rule-based classifier is used for validation and independent testing of our method. The results show that the proposed SVM based method is able to correctly classify 99.99% of 612,700 samples using the 10-fold cross validation. Furthermore, we achieved a precision of 1.00, recall of 1.00, F1-score of 1.00 and a test accuracy of 99.99%, while performing an independent test using a subset of 93% of the dataset, which consists of 31,418 points. View Full-Text   Abstract
This study was conducted to create driving episodes using machine-learning-based algorithms that address long-term memory (LTM) and topological mapping. This paper presents a novel episodic memory model for driving safety according to traffic scenes. The model incorporates three important features: adaptive resonance theory (ART), which learns time-series features incrementally while maintaining stability and plasticity; self-organizing maps (SOMs), which represent input data as a map with topological relations using self-mapping characteristics; and counter propagation networks (CPNs), which label category maps using input features and counter signals. Category maps represent driving episode information that includes driving contexts and facial expressions. The bursting states of respective maps produce LTM created on ART as episodic memory. For a preliminary experiment using a driving simulator (DS), we measure gazes and face orientations of drivers as their internal information to create driving episodes. Moreover, we measure cognitive distraction according to effects on facial features shown in reaction to simulated near-misses. Evaluation of the experimentally obtained results show the possibility of using recorded driving episodes with image datasets obtained using an event data recorder (EDR) with two cameras. Using category maps, we visualize driving features according to driving scenes on a public road and an expressway. View Full-Text   Abstract
In this article, we study the transfer learning model of action advice under a budget. We focus on reinforcement learning teachers providing action advice to heterogeneous students playing the game of Pac-Man under a limited advice budget. First, we examine several critical factors affecting advice quality in this setting, such as the average performance of the teacher, its variance and the importance of reward discounting in advising. The experiments show that the best performers are not always the best teachers and reveal the non-trivial importance of the coefficient of variation (CV) as a statistic for choosing policies that generate advice. The CV statistic relates variance to the corresponding mean. Second, the article studies policy learning for distributing advice under a budget. Whereas most methods in the relevant literature rely on heuristics for advice distribution, we formulate the problem as a learning one and propose a novel reinforcement learning algorithm capable of learning when to advise or not. The proposed algorithm is able to advise even when it does not have knowledge of the student’s intended action and needs significantly less training time compared to previous learning approaches. Finally, in this article, we argue that learning to advise under a budget is an instance of a more generic learning problem: Constrained Exploitation Reinforcement Learning. View Full-Text   review,memristor,resistive memory,artificial intelligence,machine learning,deep learning,hardware architecture,processing-in-memory,non-volatile memory,emerging memory technology   oyster vessel behavior,trajectory data,support vector machine,machine learning   episodic memory,context,facial expressions,category maps,event data recorder,unsupervised learning   machine learning,reinforcement learning,transfer learning,action advice,machine teaching ", Machine Learning and Knowledge Extraction 
 The Static Profile for a Floating Particle   Thermodynamic Behaviour of Mixed Films of an Unsaturated and a Saturated Polar Lipid. (Oleic Acid-Stearic Acid and POPC-DPPC)   Interfacial Chemistry in Steam-Based Thermal Recovery of Oil Sands Bitumen with Emphasis on Steam-Assisted Gravity Drainage and the Role of Chemical Additives   Application of Bio-Based Wrinkled Surfaces as Cell Culture Scaffolds ," Abstract
The equilibrium profile of a single floating particle is numerically investigated using transformed equations depending on the inclination angle of the deformed surface, which is governed by the Young–Laplace equation. The relationship between the depth far from the flat interface and the filling angle is derived from the force balance acting upon the particle. The Chebyshev nodes are employed as a discretization for the inclination angle and yield satisfactory results for computation. The computational results show that this is an efficient way to analyze the deformed surface around floating particles with an infinity boundary condition. The static profile of the free surface around the spherical particle is largely dependent on the density ratio and the contact angle. View Full-Text   Abstract
Mixed fatty acids or mixed phospholipids systems with saturated-unsaturated hydrocarbon chains are of biological interest. In this work, the monolayers of oleic acid-stearic acid (OA-SA) and palmitoyloleoylphosphatidylcholine-dipalmitoylphosphatidylcholine (POPC-DPPC) have been studied. From the surface pressure-area isotherms, elastic modulus values and virial equation coefficients can be obtained. Thermodynamic treatment also yields excess (GE) and mixing (ΔGmix) free energies. Results indicate positive GE values, that is, molecular interactions in the mixed films are less favourable, due to the presence of unsaturation; however, the mixture is slightly favourable due to the entropic factor that affords positive ΔGmix values. For the OA-SA system, a high SA content and surface pressure facilitate the phase separation, even though a certain miscibility between both components still remains. For the POPC-DPPC system, the most favourable mixing conditions occur for XPOPC ≈ 0.4. For these mixed systems, the values of the elastic modulus are more similar to those of more fluid components (OA or POPC); analysis of the virial coefficients shows that the b1 virial coefficient values lie between those of the individual components and are higher than values suitable for an ideal mixing. View Full-Text   Abstract
In this article, the importance of colloids and interfaces in thermal heavy oil or bitumen extraction methods is reviewed, with particular relevance to oil sands. It begins with a brief introduction to the chemical composition and surface chemistry of oil sands, as well as steam-based thermal recovery methods. This is followed by the specific consideration of steam-assisted gravity drainage (SAGD) from the perspective of the interfacial chemistry involved and factors responsible for the displacement of bitumen from reservoir mineral surfaces. Finally, the roles of the different chemical additives proposed to improve thermal recovery are considered in terms of their contributions to recovery mechanisms from interfacial and colloidal perspectives. Where appropriate, unpublished results from the author’s laboratory have been used to illustrate the discussions. View Full-Text   Abstract
Microscopic surface architectures that can be easily manufactured have been in demand as mechano-structural cues for tissue engineering. Microscopic surface reliefs synthesized by wrinkling were expected as cell culture scaffolds for cell proliferation, control of cellular alignment and differentiation, and spheroid generation. We previously developed bio-based wrinkled films prepared via lignification-mimetic reactions and drying. Although these films are expected as a candidate for cell culture scaffolds, stability and morphology of the wrinkled surfaces in aqueous buffer solutions were not explored. Here, we investigate the surface morphologies of the wrinkled films in phosphate-buffered saline, and their application to 3T3 cell culture. The wrinkled film prepared with the immersion treatment at 40 °C maintained its wrinkled structure in phosphate-buffered saline even after five days, although the wrinkles were broadened by hydration of the skin layer. Interestingly, higher cell numbers were observed in the 3T3 cell culture using the wrinkled film than using flat film with the same surface composition. In addition, the high biocompatibility of the wrinkled film was confirmed by in vivo experiments. These results strongly encourage application of the wrinkled film as a mechano-structural cue. Studies of the advanced applications for the wrinkled films are now in progress. View Full-Text "," flotation,self-assembly,capillarity,Chebyshev nodes   mixed films,fatty acids,phosphatidylcholines,π-A isotherms,virial state equation   emulsions,heavy oil and bitumen,interfaces,oil sands,petroleum colloids,SAGD,surfactants,thermal recovery,wettability   chitosan,surface wrinkling,skin layer,horseradish peroxidase,cell culture substrate,3T3 cell "," The Static Profile for a Floating Particle   Thermodynamic Behaviour of Mixed Films of an Unsaturated and a Saturated Polar Lipid. (Oleic Acid-Stearic Acid and POPC-DPPC)   Interfacial Chemistry in Steam-Based Thermal Recovery of Oil Sands Bitumen with Emphasis on Steam-Assisted Gravity Drainage and the Role of Chemical Additives   Application of Bio-Based Wrinkled Surfaces as Cell Culture Scaffolds   Abstract
The equilibrium profile of a single floating particle is numerically investigated using transformed equations depending on the inclination angle of the deformed surface, which is governed by the Young–Laplace equation. The relationship between the depth far from the flat interface and the filling angle is derived from the force balance acting upon the particle. The Chebyshev nodes are employed as a discretization for the inclination angle and yield satisfactory results for computation. The computational results show that this is an efficient way to analyze the deformed surface around floating particles with an infinity boundary condition. The static profile of the free surface around the spherical particle is largely dependent on the density ratio and the contact angle. View Full-Text   Abstract
Mixed fatty acids or mixed phospholipids systems with saturated-unsaturated hydrocarbon chains are of biological interest. In this work, the monolayers of oleic acid-stearic acid (OA-SA) and palmitoyloleoylphosphatidylcholine-dipalmitoylphosphatidylcholine (POPC-DPPC) have been studied. From the surface pressure-area isotherms, elastic modulus values and virial equation coefficients can be obtained. Thermodynamic treatment also yields excess (GE) and mixing (ΔGmix) free energies. Results indicate positive GE values, that is, molecular interactions in the mixed films are less favourable, due to the presence of unsaturation; however, the mixture is slightly favourable due to the entropic factor that affords positive ΔGmix values. For the OA-SA system, a high SA content and surface pressure facilitate the phase separation, even though a certain miscibility between both components still remains. For the POPC-DPPC system, the most favourable mixing conditions occur for XPOPC ≈ 0.4. For these mixed systems, the values of the elastic modulus are more similar to those of more fluid components (OA or POPC); analysis of the virial coefficients shows that the b1 virial coefficient values lie between those of the individual components and are higher than values suitable for an ideal mixing. View Full-Text   Abstract
In this article, the importance of colloids and interfaces in thermal heavy oil or bitumen extraction methods is reviewed, with particular relevance to oil sands. It begins with a brief introduction to the chemical composition and surface chemistry of oil sands, as well as steam-based thermal recovery methods. This is followed by the specific consideration of steam-assisted gravity drainage (SAGD) from the perspective of the interfacial chemistry involved and factors responsible for the displacement of bitumen from reservoir mineral surfaces. Finally, the roles of the different chemical additives proposed to improve thermal recovery are considered in terms of their contributions to recovery mechanisms from interfacial and colloidal perspectives. Where appropriate, unpublished results from the author’s laboratory have been used to illustrate the discussions. View Full-Text   Abstract
Microscopic surface architectures that can be easily manufactured have been in demand as mechano-structural cues for tissue engineering. Microscopic surface reliefs synthesized by wrinkling were expected as cell culture scaffolds for cell proliferation, control of cellular alignment and differentiation, and spheroid generation. We previously developed bio-based wrinkled films prepared via lignification-mimetic reactions and drying. Although these films are expected as a candidate for cell culture scaffolds, stability and morphology of the wrinkled surfaces in aqueous buffer solutions were not explored. Here, we investigate the surface morphologies of the wrinkled films in phosphate-buffered saline, and their application to 3T3 cell culture. The wrinkled film prepared with the immersion treatment at 40 °C maintained its wrinkled structure in phosphate-buffered saline even after five days, although the wrinkles were broadened by hydration of the skin layer. Interestingly, higher cell numbers were observed in the 3T3 cell culture using the wrinkled film than using flat film with the same surface composition. In addition, the high biocompatibility of the wrinkled film was confirmed by in vivo experiments. These results strongly encourage application of the wrinkled film as a mechano-structural cue. Studies of the advanced applications for the wrinkled films are now in progress. View Full-Text   flotation,self-assembly,capillarity,Chebyshev nodes   mixed films,fatty acids,phosphatidylcholines,π-A isotherms,virial state equation   emulsions,heavy oil and bitumen,interfaces,oil sands,petroleum colloids,SAGD,surfactants,thermal recovery,wettability   chitosan,surface wrinkling,skin layer,horseradish peroxidase,cell culture substrate,3T3 cell ", Colloids and Interfaces 
 Fast-GPU-PCC: A GPU-Based Technique to Compute Pairwise Pearson’s Correlation Coefficients for Time Series Data—fMRI Study   Red Blood Cell Agglutination for Blood Typing Within Passive Microfluidic Biochips   Recent Advances in Targeted and Untargeted Metabolomics by NMR and MS/NMR Methods   The High-Throughput Analyses Era: Are We Ready for the Data Struggle? ," Abstract
Functional magnetic resonance imaging (fMRI) is a non-invasive brain imaging technique, which has been regularly used for studying brain’s functional activities in the past few years. A very well-used measure for capturing functional associations in brain is Pearson’s correlation coefficient. Pearson’s correlation is widely used for constructing functional network and studying dynamic functional connectivity of the brain. These are useful measures for understanding the effects of brain disorders on connectivities among brain regions. The fMRI scanners produce huge number of voxels and using traditional central processing unit (CPU)-based techniques for computing pairwise correlations is very time consuming especially when large number of subjects are being studied. In this paper, we propose a graphics processing unit (GPU)-based algorithm called Fast-GPU-PCC for computing pairwise Pearson’s correlation coefficient. Based on the symmetric property of Pearson’s correlation, this approach returns
N(N−1)/2
correlation coefficients located at strictly upper triangle part of the correlation matrix. Storing correlations in a one-dimensional array with the order as proposed in this paper is useful for further usage. Our experiments on real and synthetic fMRI data for different number of voxels and varying length of time series show that the proposed approach outperformed state of the art GPU-based techniques as well as the sequential CPU-based versions. We show that Fast-GPU-PCC runs 62 times faster than CPU-based version and about 2 to 3 times faster than two other state of the art GPU-based methods. View Full-Text   Abstract
Pre-transfusion bedside compatibility test is mandatory to check that the donor and the recipient present compatible groups before any transfusion is performed. Although blood typing devices are present on the market, they still suffer from various drawbacks, like results that are based on naked-eye observation or difficulties in blood handling and process automation. In this study, we addressed the development of a red blood cells (RBC) agglutination assay for point-of-care blood typing. An injection molded microfluidic chip that is designed to enhance capillary flow contained anti-A or anti-B dried reagents inside its microchannel. The only blood handling step in the assay protocol consisted in the deposit of a blood drop at the tip of the biochip, and imaging was then achieved. The embedded reagents were able to trigger RBC agglutination in situ, allowing for us to monitor in real time the whole process. An image processing algorithm was developed on diluted bloods to compute real-time agglutination indicator and was further validated on undiluted blood. Through this proof of concept, we achieved efficient, automated, real time, and quantitative measurement of agglutination inside a passive biochip for blood typing which could be further generalized to blood biomarker detection and quantification. View Full-Text   Abstract
Metabolomics has made significant progress in multiple fronts in the last 18 months. This minireview aimed to give an overview of these advancements in the light of their contribution to targeted and untargeted metabolomics. New computational approaches have emerged to overcome the manual absolute quantitation step of metabolites in one-dimensional (1D) 1H nuclear magnetic resonance (NMR) spectra. This provides more consistency between inter-laboratory comparisons. Integration of two-dimensional (2D) NMR metabolomics databases under a unified web server allowed for very accurate identification of the metabolites that have been catalogued in these databases. For the remaining uncatalogued and unknown metabolites, new cheminformatics approaches have been developed by combining NMR and mass spectrometry (MS). These hybrid MS/NMR approaches accelerated the identification of unknowns in untargeted studies, and now they are allowing for profiling ever larger number of metabolites in application studies. View Full-Text   Abstract
Recent and rapid technological advances in molecular sciences have dramatically increased the ability to carry out high-throughput studies characterized by big data production. This, in turn, led to the consequent negative effect of highlighting the presence of a gap between data yield and their analysis. Indeed, big data management is becoming an increasingly important aspect of many fields of molecular research including the study of human diseases. Now, the challenge is to identify, within the huge amount of data obtained, that which is of clinical relevance. In this context, issues related to data interpretation, sharing and storage need to be assessed and standardized. Once this is achieved, the integration of data from different -omic approaches will improve the diagnosis, monitoring and therapy of diseases by allowing the identification of novel, potentially actionably biomarkers in view of personalized medicine. View Full-Text "," fMRI,Pearson’s correlation coefficient,GPU,CUDA,matrix multiplication   quantitative agglutination assay,passive microfluidic biochip,embedded reagents,automated image processing,real time detection,blood typing,Point-of-Care   targeted profiling,untargeted metabolomics,mass spectrometry,nuclear magnetic resonance spectroscopy,hybrid MS/NMR methods   high-throughput analysis,next-generation sequencing,big data,-omic sciences,personalized medicine. "," Fast-GPU-PCC: A GPU-Based Technique to Compute Pairwise Pearson’s Correlation Coefficients for Time Series Data—fMRI Study   Red Blood Cell Agglutination for Blood Typing Within Passive Microfluidic Biochips   Recent Advances in Targeted and Untargeted Metabolomics by NMR and MS/NMR Methods   The High-Throughput Analyses Era: Are We Ready for the Data Struggle?   Abstract
Functional magnetic resonance imaging (fMRI) is a non-invasive brain imaging technique, which has been regularly used for studying brain’s functional activities in the past few years. A very well-used measure for capturing functional associations in brain is Pearson’s correlation coefficient. Pearson’s correlation is widely used for constructing functional network and studying dynamic functional connectivity of the brain. These are useful measures for understanding the effects of brain disorders on connectivities among brain regions. The fMRI scanners produce huge number of voxels and using traditional central processing unit (CPU)-based techniques for computing pairwise correlations is very time consuming especially when large number of subjects are being studied. In this paper, we propose a graphics processing unit (GPU)-based algorithm called Fast-GPU-PCC for computing pairwise Pearson’s correlation coefficient. Based on the symmetric property of Pearson’s correlation, this approach returns
N(N−1)/2
correlation coefficients located at strictly upper triangle part of the correlation matrix. Storing correlations in a one-dimensional array with the order as proposed in this paper is useful for further usage. Our experiments on real and synthetic fMRI data for different number of voxels and varying length of time series show that the proposed approach outperformed state of the art GPU-based techniques as well as the sequential CPU-based versions. We show that Fast-GPU-PCC runs 62 times faster than CPU-based version and about 2 to 3 times faster than two other state of the art GPU-based methods. View Full-Text   Abstract
Pre-transfusion bedside compatibility test is mandatory to check that the donor and the recipient present compatible groups before any transfusion is performed. Although blood typing devices are present on the market, they still suffer from various drawbacks, like results that are based on naked-eye observation or difficulties in blood handling and process automation. In this study, we addressed the development of a red blood cells (RBC) agglutination assay for point-of-care blood typing. An injection molded microfluidic chip that is designed to enhance capillary flow contained anti-A or anti-B dried reagents inside its microchannel. The only blood handling step in the assay protocol consisted in the deposit of a blood drop at the tip of the biochip, and imaging was then achieved. The embedded reagents were able to trigger RBC agglutination in situ, allowing for us to monitor in real time the whole process. An image processing algorithm was developed on diluted bloods to compute real-time agglutination indicator and was further validated on undiluted blood. Through this proof of concept, we achieved efficient, automated, real time, and quantitative measurement of agglutination inside a passive biochip for blood typing which could be further generalized to blood biomarker detection and quantification. View Full-Text   Abstract
Metabolomics has made significant progress in multiple fronts in the last 18 months. This minireview aimed to give an overview of these advancements in the light of their contribution to targeted and untargeted metabolomics. New computational approaches have emerged to overcome the manual absolute quantitation step of metabolites in one-dimensional (1D) 1H nuclear magnetic resonance (NMR) spectra. This provides more consistency between inter-laboratory comparisons. Integration of two-dimensional (2D) NMR metabolomics databases under a unified web server allowed for very accurate identification of the metabolites that have been catalogued in these databases. For the remaining uncatalogued and unknown metabolites, new cheminformatics approaches have been developed by combining NMR and mass spectrometry (MS). These hybrid MS/NMR approaches accelerated the identification of unknowns in untargeted studies, and now they are allowing for profiling ever larger number of metabolites in application studies. View Full-Text   Abstract
Recent and rapid technological advances in molecular sciences have dramatically increased the ability to carry out high-throughput studies characterized by big data production. This, in turn, led to the consequent negative effect of highlighting the presence of a gap between data yield and their analysis. Indeed, big data management is becoming an increasingly important aspect of many fields of molecular research including the study of human diseases. Now, the challenge is to identify, within the huge amount of data obtained, that which is of clinical relevance. In this context, issues related to data interpretation, sharing and storage need to be assessed and standardized. Once this is achieved, the integration of data from different -omic approaches will improve the diagnosis, monitoring and therapy of diseases by allowing the identification of novel, potentially actionably biomarkers in view of personalized medicine. View Full-Text   fMRI,Pearson’s correlation coefficient,GPU,CUDA,matrix multiplication   quantitative agglutination assay,passive microfluidic biochip,embedded reagents,automated image processing,real time detection,blood typing,Point-of-Care   targeted profiling,untargeted metabolomics,mass spectrometry,nuclear magnetic resonance spectroscopy,hybrid MS/NMR methods   high-throughput analysis,next-generation sequencing,big data,-omic sciences,personalized medicine. ", High-Throughput 
" Late Pleistocene Deer in the Region of the National Park “Serra da Capivara” (Piauí, Brazil)   Elephant and Mammoth Hunting during the Paleolithic: A Review of the Relevant Archaeological, Ethnographic and Ethno-Historical Records   Holocene Hydroclimate Variability in Central Scandinavia Inferred from Flood Layers in Contourite Drift Deposits in Lake Storsjön   Quaternary—A Multidisciplinary Integrative Journal to Cope with a Complex World "," Abstract
The analysis of the cervid fossil remains from the late Pleistocene fossiliferous deposit Lagoa dos Porcos (in the region of the National Park “Serra da Capivara”, Piauí, Brazil) proves the presence of at least two species: a small deer, belonging to the genus Mazama, and a larger one (Morenelaphus sp.). The latter taxon is recognized for the first time not only in this area, but in the whole Piauí State, enlarging the paleogeographic distribution of the genus. This study also points out the difference between the cervid fauna found in the karstic area of Park and Lagoa dos Porcos, which lies in the alluvial plain. View Full-Text   Abstract
Proboscideans and humans have shared habitats across the Old and New Worlds for hundreds of thousands of years. Proboscideans were included in the human diet starting from the Lower Paleolithic period and until the final stages of the Pleistocene. However, the question of how prehistoric people acquired proboscideans remains unresolved. Moreover, the effect of proboscidean hunting on the eventual extinction of these mega-herbivores was never seriously evaluated, probably because of the lack of acquaintance with the plethora of information available regarding proboscidean hunting by humans. The aim of this paper is to bridge this gap and bring to light the data available in order to estimate the extent and procedures of elephant and mammoth hunting by humans during the Quaternary. This study examines the archaeological evidence of proboscidean hunting during Paleolithic times, and provides a review of ethnographic and ethno-historical accounts, demonstrating a wide range of traditional elephant-hunting strategies. We also discuss the rituals accompanying elephant hunting among contemporary hunter-gatherers, further stressing the importance of elephants among hunter-gatherers. Based on the gathered data, we suggest that early humans possessed the necessary abilities to actively and regularly hunt proboscideans; and performed this unique and challenging task at will. View Full-Text   Abstract
Despite the societal importance of extreme hydroclimate events, few palaeoenvironmental studies of Scandinavian lake sediments have investigated flood occurrences. Here we present a flood history based on lithological, geochemical and mineral magnetic records of a Holocene sediment sequence collected from contourite drift deposits in Lake Storsjön (63.12° N, 14.37° E). After the last deglaciation, the lake began to form around 9800 cal yr BP, but glacial activity persisted in the catchment for ~250 years. Element concentrations and mineral magnetic properties of the sediments indicate relatively stable sedimentation conditions during the Holocene. However, human impact in the form of expanding agriculture is evident from about 1100 cal yr BP, and intensified in the 20th century. Black layers containing iron sulphide appear irregularly throughout the sequence. The increased influx of organic matter during flood events led to decomposition and oxygen consumption, and eventually to anoxic conditions in the interstitial water preserving these layers. Elevated frequencies of black layer occurrence between 3600 and 1800 cal yr BP reflect vegetation changes in the catchment as well as large-scale climatic change. Soil erosion during snowmelt flood events increased with a tree line descent since the onset of the neoglacial period (~4000 cal yr BP). The peak in black layer occurrence coincides with a prominent solar minimum ~2600 cal yr BP, which may have accentuated the observed pattern due to the prevalence of a negative NAO index, a longer snow accumulation period and consequently stronger snowmelt floods. View Full-Text   Abstract
We live in a Quaternary world, that is, a world shaped by the interplay of the different compartments of the earth system—lithosphere, hydrosphere, atmosphere, biosphere, cryosphere—during the last ~2.6 million years [...]
View Full-Text "," Nordeste,cervidae,ecological comparison,Mazama,Morenelaphus   proboscidean,hunting strategies,Paleolithic,human-proboscidean interaction   lake sediments,palaeo-floods,hydroclimate,deglaciation,black layers,contourite,seismic profile,X-ray fluorescence,environmental magnetism,Holocene,Sweden    "," Late Pleistocene Deer in the Region of the National Park “Serra da Capivara” (Piauí, Brazil)   Elephant and Mammoth Hunting during the Paleolithic: A Review of the Relevant Archaeological, Ethnographic and Ethno-Historical Records   Holocene Hydroclimate Variability in Central Scandinavia Inferred from Flood Layers in Contourite Drift Deposits in Lake Storsjön   Quaternary—A Multidisciplinary Integrative Journal to Cope with a Complex World   Abstract
The analysis of the cervid fossil remains from the late Pleistocene fossiliferous deposit Lagoa dos Porcos (in the region of the National Park “Serra da Capivara”, Piauí, Brazil) proves the presence of at least two species: a small deer, belonging to the genus Mazama, and a larger one (Morenelaphus sp.). The latter taxon is recognized for the first time not only in this area, but in the whole Piauí State, enlarging the paleogeographic distribution of the genus. This study also points out the difference between the cervid fauna found in the karstic area of Park and Lagoa dos Porcos, which lies in the alluvial plain. View Full-Text   Abstract
Proboscideans and humans have shared habitats across the Old and New Worlds for hundreds of thousands of years. Proboscideans were included in the human diet starting from the Lower Paleolithic period and until the final stages of the Pleistocene. However, the question of how prehistoric people acquired proboscideans remains unresolved. Moreover, the effect of proboscidean hunting on the eventual extinction of these mega-herbivores was never seriously evaluated, probably because of the lack of acquaintance with the plethora of information available regarding proboscidean hunting by humans. The aim of this paper is to bridge this gap and bring to light the data available in order to estimate the extent and procedures of elephant and mammoth hunting by humans during the Quaternary. This study examines the archaeological evidence of proboscidean hunting during Paleolithic times, and provides a review of ethnographic and ethno-historical accounts, demonstrating a wide range of traditional elephant-hunting strategies. We also discuss the rituals accompanying elephant hunting among contemporary hunter-gatherers, further stressing the importance of elephants among hunter-gatherers. Based on the gathered data, we suggest that early humans possessed the necessary abilities to actively and regularly hunt proboscideans; and performed this unique and challenging task at will. View Full-Text   Abstract
Despite the societal importance of extreme hydroclimate events, few palaeoenvironmental studies of Scandinavian lake sediments have investigated flood occurrences. Here we present a flood history based on lithological, geochemical and mineral magnetic records of a Holocene sediment sequence collected from contourite drift deposits in Lake Storsjön (63.12° N, 14.37° E). After the last deglaciation, the lake began to form around 9800 cal yr BP, but glacial activity persisted in the catchment for ~250 years. Element concentrations and mineral magnetic properties of the sediments indicate relatively stable sedimentation conditions during the Holocene. However, human impact in the form of expanding agriculture is evident from about 1100 cal yr BP, and intensified in the 20th century. Black layers containing iron sulphide appear irregularly throughout the sequence. The increased influx of organic matter during flood events led to decomposition and oxygen consumption, and eventually to anoxic conditions in the interstitial water preserving these layers. Elevated frequencies of black layer occurrence between 3600 and 1800 cal yr BP reflect vegetation changes in the catchment as well as large-scale climatic change. Soil erosion during snowmelt flood events increased with a tree line descent since the onset of the neoglacial period (~4000 cal yr BP). The peak in black layer occurrence coincides with a prominent solar minimum ~2600 cal yr BP, which may have accentuated the observed pattern due to the prevalence of a negative NAO index, a longer snow accumulation period and consequently stronger snowmelt floods. View Full-Text   Abstract
We live in a Quaternary world, that is, a world shaped by the interplay of the different compartments of the earth system—lithosphere, hydrosphere, atmosphere, biosphere, cryosphere—during the last ~2.6 million years [...]
View Full-Text   Nordeste,cervidae,ecological comparison,Mazama,Morenelaphus   proboscidean,hunting strategies,Paleolithic,human-proboscidean interaction   lake sediments,palaeo-floods,hydroclimate,deglaciation,black layers,contourite,seismic profile,X-ray fluorescence,environmental magnetism,Holocene,Sweden    ", Quaternary 
 Design and Feasibility of a Safe Pill Bottle   Crude Glycerol as an Innovative Corrosion Inhibitor   Principles of Product Design in Developing Countries   Health Symptom Checking System for Elderly People Using Fuzzy Analytic Hierarchy Process ," Abstract
Ubiquitous intelligence of Internet of Things (IoT) objects and new sensors provide innovative solutions for a variety of health issues. Unintentional child poisoning represents an increasingly important health issue worldwide, partially because of an increase in the use of drugs and food supplements. Although child-resistant bottle caps have probably saved many lives, they are not foolproof and do not provide warnings for parents and caregivers when children try to access the bottles. In this paper we present a design, implementation, and feasibility analysis of an intelligent “safe pill bottle” that can identify when a child is trying to open a bottle and then generate an immediate warning to deter a child from opening the bottle and send alerts to parents/guardians. The bottle controller uses capacitive sensing to identify the class of user. We present the results of pilot testing with eight adults and eight children using neural networks (NN). With 474 bottle-opening events, our NN had 96.4% accuracy of predicting whether the user was a child or an adult. Preliminary results demonstrate that smart pill bottles may be an effective tool to prevent unintentional child poisoning. View Full-Text   Abstract
Crude glycerol, a byproduct of biodiesel production, was evaluated as a potential green inhibitor for steel corrosion in an acidic environment. The study was conducted using steel specimens placed in hydrochloric acid solutions (0.5 M) at a constant room temperature (25 °C) and crude glycerol concentrations in the range 0.1%–1.0% w/w. The criteria used to evaluate the extent of corrosion were the weight loss and corrosion rate. Additionally, fresh and spent samples were characterized using scanning electron microscopy and potentiodynamic polarization measurements. It was found that, generally, the corrosion inhibition increased with the inhibitor concentration. Results also showed that the maximum inhibition efficiency was achieved at 70 h residence time after which the inhibition efficiency at a given concentration either remained unchanged or dropped slight. Additionally, the overall maximum inhibition efficiency (98%) was observed at 70 h residence time and a 1% inhibitor concentration. View Full-Text   Abstract
Problem—The conventional view of new product development (NPD) methodologies focuses on marketing and commercial prospects in developed countries. There is a need to identify both the barriers and the enablers to design within a rural context in developing countries (DC). Method—A researcher was embedded in a rural DC design project. Issues were observed and critical success and failure factors determined. These were abstracted into a set of design principles, and a new model of the NPD process was created. Findings—Whereas commercial NPD emphasizes market intelligence and a highly directive approach to the engineering workflow, in the DC situation the objective is to fulfil community needs and this necessitates co-determination regarding the engineering. There is commonality between the two NPD processes, with ours having a greater emphasis on the socio-cultural factors. The deployment principles are categorized into technical and socio-cultural. Within these are included project management, design, material selection, visualization, communication, maintainability, safety, and health. Originality—A novel representation of the process for conducting design in developing countries is provided. Critical success factors are identified. The socio-cultural perspective is explicitly included, which is absent from the conventional engineering and business perspectives. View Full-Text   Abstract
The ever-escalating rise in numbers of the aging population has preempted a revolutionary change in the healthcare sector and serves as a major counterpoint to modern life in the 21st century. Increasing demand being placed on the health sector is almost certainly an inevitable process. However, providing appropriate healthcare services is requisite for senior citizens who suffer from various health issues and conditions. To minimize these health risks, we derived an intuitive technique for determining the incongruity of health symptoms by using a symptom checker, which is embedded into a versatile mobile app named Help-to-You (H2U). The designed app helps the users and carers to determine and identify conceivable reasons for elderly ailments and to assist users in deciding when to counsel a health practitioner. The intention of this empirical study was to further analyze and foresee certain variations of infections based on the symptoms accounted for by the patient. The recommended solution consolidated conceptual design with multi-criteria decision analysis (MCDA) technique and an analytic hierarchy process (AHP) with fuzzy weights to deal with the uncertainty of imprecision and ambiguity resulting from various disease factors. Experimental results verified the effectiveness of the proposed model, subsequently providing a variety of life assistance services. View Full-Text "," poisoning prevention,child safety,smart pill bottle,IoT,sensing,neural networks,user identification,biometric identification   green inhibitor,corrosion,crude glycerol,adsorption isotherms,acidic medium   design,new product development,developing,rural,societal   symptom checker,mobile app,H2U,healthcare service,MCDA,fuzzy AHP,decision support "," Design and Feasibility of a Safe Pill Bottle   Crude Glycerol as an Innovative Corrosion Inhibitor   Principles of Product Design in Developing Countries   Health Symptom Checking System for Elderly People Using Fuzzy Analytic Hierarchy Process   Abstract
Ubiquitous intelligence of Internet of Things (IoT) objects and new sensors provide innovative solutions for a variety of health issues. Unintentional child poisoning represents an increasingly important health issue worldwide, partially because of an increase in the use of drugs and food supplements. Although child-resistant bottle caps have probably saved many lives, they are not foolproof and do not provide warnings for parents and caregivers when children try to access the bottles. In this paper we present a design, implementation, and feasibility analysis of an intelligent “safe pill bottle” that can identify when a child is trying to open a bottle and then generate an immediate warning to deter a child from opening the bottle and send alerts to parents/guardians. The bottle controller uses capacitive sensing to identify the class of user. We present the results of pilot testing with eight adults and eight children using neural networks (NN). With 474 bottle-opening events, our NN had 96.4% accuracy of predicting whether the user was a child or an adult. Preliminary results demonstrate that smart pill bottles may be an effective tool to prevent unintentional child poisoning. View Full-Text   Abstract
Crude glycerol, a byproduct of biodiesel production, was evaluated as a potential green inhibitor for steel corrosion in an acidic environment. The study was conducted using steel specimens placed in hydrochloric acid solutions (0.5 M) at a constant room temperature (25 °C) and crude glycerol concentrations in the range 0.1%–1.0% w/w. The criteria used to evaluate the extent of corrosion were the weight loss and corrosion rate. Additionally, fresh and spent samples were characterized using scanning electron microscopy and potentiodynamic polarization measurements. It was found that, generally, the corrosion inhibition increased with the inhibitor concentration. Results also showed that the maximum inhibition efficiency was achieved at 70 h residence time after which the inhibition efficiency at a given concentration either remained unchanged or dropped slight. Additionally, the overall maximum inhibition efficiency (98%) was observed at 70 h residence time and a 1% inhibitor concentration. View Full-Text   Abstract
Problem—The conventional view of new product development (NPD) methodologies focuses on marketing and commercial prospects in developed countries. There is a need to identify both the barriers and the enablers to design within a rural context in developing countries (DC). Method—A researcher was embedded in a rural DC design project. Issues were observed and critical success and failure factors determined. These were abstracted into a set of design principles, and a new model of the NPD process was created. Findings—Whereas commercial NPD emphasizes market intelligence and a highly directive approach to the engineering workflow, in the DC situation the objective is to fulfil community needs and this necessitates co-determination regarding the engineering. There is commonality between the two NPD processes, with ours having a greater emphasis on the socio-cultural factors. The deployment principles are categorized into technical and socio-cultural. Within these are included project management, design, material selection, visualization, communication, maintainability, safety, and health. Originality—A novel representation of the process for conducting design in developing countries is provided. Critical success factors are identified. The socio-cultural perspective is explicitly included, which is absent from the conventional engineering and business perspectives. View Full-Text   Abstract
The ever-escalating rise in numbers of the aging population has preempted a revolutionary change in the healthcare sector and serves as a major counterpoint to modern life in the 21st century. Increasing demand being placed on the health sector is almost certainly an inevitable process. However, providing appropriate healthcare services is requisite for senior citizens who suffer from various health issues and conditions. To minimize these health risks, we derived an intuitive technique for determining the incongruity of health symptoms by using a symptom checker, which is embedded into a versatile mobile app named Help-to-You (H2U). The designed app helps the users and carers to determine and identify conceivable reasons for elderly ailments and to assist users in deciding when to counsel a health practitioner. The intention of this empirical study was to further analyze and foresee certain variations of infections based on the symptoms accounted for by the patient. The recommended solution consolidated conceptual design with multi-criteria decision analysis (MCDA) technique and an analytic hierarchy process (AHP) with fuzzy weights to deal with the uncertainty of imprecision and ambiguity resulting from various disease factors. Experimental results verified the effectiveness of the proposed model, subsequently providing a variety of life assistance services. View Full-Text   poisoning prevention,child safety,smart pill bottle,IoT,sensing,neural networks,user identification,biometric identification   green inhibitor,corrosion,crude glycerol,adsorption isotherms,acidic medium   design,new product development,developing,rural,societal   symptom checker,mobile app,H2U,healthcare service,MCDA,fuzzy AHP,decision support ", Applied System Innovation 
 Welcome to Ceramics: A New Open Access Scientific Journal on Ceramics Science and Engineering ," Abstract
The word ceramics comes from the Greek word keramikos, which means pottery and corresponds to a very old human activity. Indeed, one of the oldest materials fabricated in the world is ceramic pottery [...]
View Full-Text ",  ," Welcome to Ceramics: A New Open Access Scientific Journal on Ceramics Science and Engineering   Abstract
The word ceramics comes from the Greek word keramikos, which means pottery and corresponds to a very old human activity. Indeed, one of the oldest materials fabricated in the world is ceramic pottery [...]
View Full-Text    ", Ceramics 
" An Inexpensive, Pulsed, and Multiple Wavelength Bench-Top Light Source for Biological Spectroscopy   The Role of Magnetic Islands in Collisionless Driven Reconnection: A Kinetic Approach to Multi-Scale Phenomena   Microscopic Effect on Filamentary Coherent Structure Dynamics in Boundary Layer Plasmas   Plasma Medicine: A Brief Introduction "," Abstract
Since signal/noise ratios are proportional to the square root of the intensity, high intensity light sources are advantageous for many forms of UV–Vis and IR spectroscopy particularly with very low or high absorbance samples. We report the construction of a low-cost (≈ £6500 GBP, ca. 2016) bench-top spectrometer suitable for biological spectroscopy, which utilizes a hot plasma, generated with a pulsed Nd:YAG laser (λ = 1064 nm). The properties (reliability, intensity, and spectral profiles) of light generated with the plasma in different gaseous media (helium, neon, argon, and krypton) were investigated. Argon provided high intensity broadband light and was the most cost effective. The instrument was compared for spectral accuracy to a commercially available spectrometer (Thermo Scientific, GENESYS 10S) by measurement of the absorbance spectrum of the UV–Vis calibration standard holmium (III) oxide (4%, w/v) in perchloric acid (10%, w/v) and accurately replicated the results of the commercial spectrometer. This economical instrument can record consecutive absorbance spectra (between λ = 380 and 720 nm) for each laser pulse (6 Hz; ~160 ms/pulse), evinced by investigations into lysozyme aggregation in the presence of heparin. This instrument is suitable for use with lasers of a higher pulse power and repetition rates that would induce higher temperature plasmas. Higher temperature plasma sources offer increased signal to noise ratios due to the higher intensity emission generated. View Full-Text   Abstract
The role of magnetic islands in collisionless driven reconnection has been investigated from the standpoint of a kinetic approach to multi-scale phenomena by means of two-dimensional particle-in-cell (PIC) simulation. There are two different types of the solutions in the evolution of the reconnection system. One is a steady solution in which the system relaxes into a steady state, and no island is generated (the no-island case). The other is an intermittent solution in which the system does not reach a steady state, and magnetic islands are frequently generated in the current sheet (the multi-island case). It is found that the electromagnetic energy is more effectively transferred to the particle energy in the multi-island case compared with the no-island case. The transferred energy is stored inside the magnetic island in the form of the thermal energy through compressional heating, and is carried away together with the magnetic island from the reconnection region. These results suggest that the formation of a magnetic island chain may have a potential to bridge the energy gap between macroscopic and microscopic physics by widening the dissipation region and strengthening the energy dissipation rate. View Full-Text   Abstract
This study has demonstrated kinetic behaviors on the plasma filament propagation with the three-dimensional (3D) Particle-in-Cell (PIC) simulation. When the ion-to-electron temperature ratio
T
i
/
T
e
is higher, the poloidal symmetry breaking in the filament propagation occurs. The poloidal symmetry breaking is thought to be induced by the unbalanced potential structure that arises from the effect of the gyro motion of plasma particles. View Full-Text   Abstract
This mini review is to introduce the readers of Plasma to the field of plasma medicine. This is a multidisciplinary field of research at the intersection of physics, engineering, biology and medicine. Plasma medicine is only about two decades old, but the research community active in this emerging field has grown tremendously in the last few years. Today, research is being conducted on a number of applications including wound healing and cancer treatment. Although a lot of knowledge has been created and our understanding of the fundamental mechanisms that play important roles in the interaction between low temperature plasma and biological cells and tissues has greatly expanded, much remains to be done to get a thorough and detailed picture of all the physical and biochemical processes that enter into play. View Full-Text "," laser-induced plasma,broadband light source,spectroscopy,pulsed laser, heparin,aggregation,lysozyme   magnetic reconnection,magnetic island,multi-scale physics,open system,energy transfer   blob,boundary layer transport,kinetic dynamics,particle-in-cell simulation   low temperature plasma,plasma jet,cells,tissue,apoptosis,cancer,wound healing,reactive species "," An Inexpensive, Pulsed, and Multiple Wavelength Bench-Top Light Source for Biological Spectroscopy   The Role of Magnetic Islands in Collisionless Driven Reconnection: A Kinetic Approach to Multi-Scale Phenomena   Microscopic Effect on Filamentary Coherent Structure Dynamics in Boundary Layer Plasmas   Plasma Medicine: A Brief Introduction   Abstract
Since signal/noise ratios are proportional to the square root of the intensity, high intensity light sources are advantageous for many forms of UV–Vis and IR spectroscopy particularly with very low or high absorbance samples. We report the construction of a low-cost (≈ £6500 GBP, ca. 2016) bench-top spectrometer suitable for biological spectroscopy, which utilizes a hot plasma, generated with a pulsed Nd:YAG laser (λ = 1064 nm). The properties (reliability, intensity, and spectral profiles) of light generated with the plasma in different gaseous media (helium, neon, argon, and krypton) were investigated. Argon provided high intensity broadband light and was the most cost effective. The instrument was compared for spectral accuracy to a commercially available spectrometer (Thermo Scientific, GENESYS 10S) by measurement of the absorbance spectrum of the UV–Vis calibration standard holmium (III) oxide (4%, w/v) in perchloric acid (10%, w/v) and accurately replicated the results of the commercial spectrometer. This economical instrument can record consecutive absorbance spectra (between λ = 380 and 720 nm) for each laser pulse (6 Hz; ~160 ms/pulse), evinced by investigations into lysozyme aggregation in the presence of heparin. This instrument is suitable for use with lasers of a higher pulse power and repetition rates that would induce higher temperature plasmas. Higher temperature plasma sources offer increased signal to noise ratios due to the higher intensity emission generated. View Full-Text   Abstract
The role of magnetic islands in collisionless driven reconnection has been investigated from the standpoint of a kinetic approach to multi-scale phenomena by means of two-dimensional particle-in-cell (PIC) simulation. There are two different types of the solutions in the evolution of the reconnection system. One is a steady solution in which the system relaxes into a steady state, and no island is generated (the no-island case). The other is an intermittent solution in which the system does not reach a steady state, and magnetic islands are frequently generated in the current sheet (the multi-island case). It is found that the electromagnetic energy is more effectively transferred to the particle energy in the multi-island case compared with the no-island case. The transferred energy is stored inside the magnetic island in the form of the thermal energy through compressional heating, and is carried away together with the magnetic island from the reconnection region. These results suggest that the formation of a magnetic island chain may have a potential to bridge the energy gap between macroscopic and microscopic physics by widening the dissipation region and strengthening the energy dissipation rate. View Full-Text   Abstract
This study has demonstrated kinetic behaviors on the plasma filament propagation with the three-dimensional (3D) Particle-in-Cell (PIC) simulation. When the ion-to-electron temperature ratio
T
i
/
T
e
is higher, the poloidal symmetry breaking in the filament propagation occurs. The poloidal symmetry breaking is thought to be induced by the unbalanced potential structure that arises from the effect of the gyro motion of plasma particles. View Full-Text   Abstract
This mini review is to introduce the readers of Plasma to the field of plasma medicine. This is a multidisciplinary field of research at the intersection of physics, engineering, biology and medicine. Plasma medicine is only about two decades old, but the research community active in this emerging field has grown tremendously in the last few years. Today, research is being conducted on a number of applications including wound healing and cancer treatment. Although a lot of knowledge has been created and our understanding of the fundamental mechanisms that play important roles in the interaction between low temperature plasma and biological cells and tissues has greatly expanded, much remains to be done to get a thorough and detailed picture of all the physical and biochemical processes that enter into play. View Full-Text   laser-induced plasma,broadband light source,spectroscopy,pulsed laser, heparin,aggregation,lysozyme   magnetic reconnection,magnetic island,multi-scale physics,open system,energy transfer   blob,boundary layer transport,kinetic dynamics,particle-in-cell simulation   low temperature plasma,plasma jet,cells,tissue,apoptosis,cancer,wound healing,reactive species ", Plasma 
 A Hierarchical Classification of Wildland Fire Fuels for Australian Vegetation Types   The Politically Possible and Wildland Fire Research ," Abstract
Appropriate categorisation and description of living vegetation and dead biomass is necessary to support the rising complexity of managing wildland fire and healthy ecosystems. We propose a hierarchical, physiognomy-based classification of wildland fire fuels—the Bushfire Fuel Classification—aimed at integrating the large diversity of Australian vegetation into distinct fuel types that are easily communicated and quantitatively described. At its basis, the classification integrates life form characteristics, height, and foliage cover. The hierarchical framework, with three tiers, describes fuel types over a range of application requirements and fuel description accuracies. At the higher level, the fuel classification identifies a total of 32 top-tier fuel types divided into 9 native forest or woodland, 2 plantation, 10 shrubland, 7 grassland, and 4 other fuel types: wildland urban interface areas, horticultural crops, flammable wetlands, and nonburnable areas. At an intermediate level, the classification identifies 51 mid-tier fuel types. Each mid-tier fuel type can be divided into 4 bottom-tier fuel descriptions. The fuel types defined within the tier system are accompanied by a quantitative description of their characteristics termed the “fuel catalogue”. Work is currently under way to link existing Australian state- and territory-based fuel and vegetation databases with the fuel classification and to collate existent fuel characteristics information to populate the fuel catalogue. The Bushfire Fuel Classification will underpin a range of fire management applications that require fuel information in order to determine fire behaviour and risk, fuel management, fire danger rating, and fire effects. View Full-Text   Abstract
Often missing or underdeveloped in wildland fire research is a clear sense of the link between contemporaneous political possibility and the desired ecological or management outcomes. We examine the disconnect between desired outcomes and what we call the “politically possible”. Politically possible policy solutions are those that recognize how compromise, stakeholder engagement, and the distribution of costs and benefits combine to structure political acceptability. Better attending to the politically possible in wildland fire-related research can, in turn, inform our understanding of the cause, effect, and the potential solutions to fire management challenges. We observe how a lack of awareness and attention to the politically possible can create divisions or barriers to realistic action. View Full-Text "," fuel type,fire behaviour,eucalypt forest fuels,grassland fuels,WUI fuels,fire danger rating   policy,wildland fire,management,stakeholders,landscapes "," A Hierarchical Classification of Wildland Fire Fuels for Australian Vegetation Types   The Politically Possible and Wildland Fire Research   Abstract
Appropriate categorisation and description of living vegetation and dead biomass is necessary to support the rising complexity of managing wildland fire and healthy ecosystems. We propose a hierarchical, physiognomy-based classification of wildland fire fuels—the Bushfire Fuel Classification—aimed at integrating the large diversity of Australian vegetation into distinct fuel types that are easily communicated and quantitatively described. At its basis, the classification integrates life form characteristics, height, and foliage cover. The hierarchical framework, with three tiers, describes fuel types over a range of application requirements and fuel description accuracies. At the higher level, the fuel classification identifies a total of 32 top-tier fuel types divided into 9 native forest or woodland, 2 plantation, 10 shrubland, 7 grassland, and 4 other fuel types: wildland urban interface areas, horticultural crops, flammable wetlands, and nonburnable areas. At an intermediate level, the classification identifies 51 mid-tier fuel types. Each mid-tier fuel type can be divided into 4 bottom-tier fuel descriptions. The fuel types defined within the tier system are accompanied by a quantitative description of their characteristics termed the “fuel catalogue”. Work is currently under way to link existing Australian state- and territory-based fuel and vegetation databases with the fuel classification and to collate existent fuel characteristics information to populate the fuel catalogue. The Bushfire Fuel Classification will underpin a range of fire management applications that require fuel information in order to determine fire behaviour and risk, fuel management, fire danger rating, and fire effects. View Full-Text   Abstract
Often missing or underdeveloped in wildland fire research is a clear sense of the link between contemporaneous political possibility and the desired ecological or management outcomes. We examine the disconnect between desired outcomes and what we call the “politically possible”. Politically possible policy solutions are those that recognize how compromise, stakeholder engagement, and the distribution of costs and benefits combine to structure political acceptability. Better attending to the politically possible in wildland fire-related research can, in turn, inform our understanding of the cause, effect, and the potential solutions to fire management challenges. We observe how a lack of awareness and attention to the politically possible can create divisions or barriers to realistic action. View Full-Text   fuel type,fire behaviour,eucalypt forest fuels,grassland fuels,WUI fuels,fire danger rating   policy,wildland fire,management,stakeholders,landscapes ", Fire 
" The Control of an Active Seat Suspension Using an Optimised Fuzzy Logic Controller, Based on Preview Information from a Full Vehicle Model   Frequency Measurement of Musical Instrument Strings Using Piezoelectric Transducers   New Vibration Online Journal Will Get Us Back to Basics "," Abstract
The use of suspension preview information obtained from a quarter vehicle model (QvM) to control an active seat has been shown by the authors to be very promising, in terms of improved ride comfort. However, in reality, a road vehicle will be subjected to disturbances from all four wheels, and therefore the concept of preview enhanced control should be applied to a full vehicle model. In this paper, different preview scenarios are examined, in which suspension data is taken from all or limited axles. Accordingly, three control strategies are hypothesized—namely, front-left suspension (FLS), front axle (FA), and four wheel (4W). The former utilises suspension displacement and velocity preview information from the vehicle suspension nearest to the driver’s seat. The FA uses similar preview information, but from both the front-left and front-right suspensions. The 4W controller employs similar preview information from all of the vehicle suspensions. To cope with friction non-linearities, as well as constraints on the active actuator displacement and force capabilities, three optimal fuzzy logic controllers (FLCs) are developed. The structure of each FLC, including membership functions, scaling factors, and rule base, was sequentially optimised based on improving the seat effective amplitude transmissibility (SEAT) factor in the vertical direction, using the particle swarming optimisation (PSO) algorithm. These strategies were evaluated in simulation according to ISO 2631-1, using different road disturbances at a range of vehicle forward speeds. The results show that the proposed controllers are very effective in attenuating the vertical acceleration at the driver’s seat, when compared with a passive system. The controller that utilised suspension preview information from all four corners of the car provided the best seat isolation performance, independent of vehicle speed. Finally, to reduce the implementation cost of the “four suspension” controller, a practical alternative is developed that requires less measured preview information. View Full-Text   Abstract
The use of a piezoelectric transducer to monitor the tuning of a musical instrument string has been investigated. It has been shown that the transverse resonance frequencies of the string can be identified by electrical measurements on a low-cost actuator/sensor, sufficiently discreetly to be done during a performance. This frequency measurement approach can be used as the basis for a tuning control mechanism to maintain a musical instrument string at the required pitch, without it having to be plucked or played. Such a system would be of direct benefit to harp players in particular, who have no other means to adjust a mistuned string during a performance. Some of the practical issues and implications of adding such a tuning control system to the harp are considered. View Full-Text   Abstract
When Vibration approached me to be its founding Editor-in-Chief, it was explained to me that the key selling points of this new online journal would be as follows [...]
View Full-Text "," active seat suspension,optimum fuzzy logic control,preview information,full vehicle model   string,tuning,harp,piezoelectric,resonance    "," The Control of an Active Seat Suspension Using an Optimised Fuzzy Logic Controller, Based on Preview Information from a Full Vehicle Model   Frequency Measurement of Musical Instrument Strings Using Piezoelectric Transducers   New Vibration Online Journal Will Get Us Back to Basics   Abstract
The use of suspension preview information obtained from a quarter vehicle model (QvM) to control an active seat has been shown by the authors to be very promising, in terms of improved ride comfort. However, in reality, a road vehicle will be subjected to disturbances from all four wheels, and therefore the concept of preview enhanced control should be applied to a full vehicle model. In this paper, different preview scenarios are examined, in which suspension data is taken from all or limited axles. Accordingly, three control strategies are hypothesized—namely, front-left suspension (FLS), front axle (FA), and four wheel (4W). The former utilises suspension displacement and velocity preview information from the vehicle suspension nearest to the driver’s seat. The FA uses similar preview information, but from both the front-left and front-right suspensions. The 4W controller employs similar preview information from all of the vehicle suspensions. To cope with friction non-linearities, as well as constraints on the active actuator displacement and force capabilities, three optimal fuzzy logic controllers (FLCs) are developed. The structure of each FLC, including membership functions, scaling factors, and rule base, was sequentially optimised based on improving the seat effective amplitude transmissibility (SEAT) factor in the vertical direction, using the particle swarming optimisation (PSO) algorithm. These strategies were evaluated in simulation according to ISO 2631-1, using different road disturbances at a range of vehicle forward speeds. The results show that the proposed controllers are very effective in attenuating the vertical acceleration at the driver’s seat, when compared with a passive system. The controller that utilised suspension preview information from all four corners of the car provided the best seat isolation performance, independent of vehicle speed. Finally, to reduce the implementation cost of the “four suspension” controller, a practical alternative is developed that requires less measured preview information. View Full-Text   Abstract
The use of a piezoelectric transducer to monitor the tuning of a musical instrument string has been investigated. It has been shown that the transverse resonance frequencies of the string can be identified by electrical measurements on a low-cost actuator/sensor, sufficiently discreetly to be done during a performance. This frequency measurement approach can be used as the basis for a tuning control mechanism to maintain a musical instrument string at the required pitch, without it having to be plucked or played. Such a system would be of direct benefit to harp players in particular, who have no other means to adjust a mistuned string during a performance. Some of the practical issues and implications of adding such a tuning control system to the harp are considered. View Full-Text   Abstract
When Vibration approached me to be its founding Editor-in-Chief, it was explained to me that the key selling points of this new online journal would be as follows [...]
View Full-Text   active seat suspension,optimum fuzzy logic control,preview information,full vehicle model   string,tuning,harp,piezoelectric,resonance    ", Vibration 
 Cooperation between NMDA-Type Glutamate and P2 Receptors for Neuroprotection during Stroke: Combining Astrocyte and Neuronal Protection   The Special Case of Human Astrocytes   Interlaminar Glia and Other Glial Themes Revisited: Pending Answers Following Three Decades of Glial Research   Remembering Ben Barres ," Abstract
Excitotoxicity is the principle mechanism of acute injury during stroke. It is defined as the unregulated accumulation of excitatory neurotransmitters such as glutamate within the extracellular space, leading to over-activation of receptors, ionic disruption, cell swelling, cytotoxic Ca2+ elevation and a feed-forward loop where membrane depolarisation evokes further neurotransmitter release. Glutamate-mediated excitotoxicity is well documented in neurons and oligodendrocytes but drugs targeting glutamate excitotoxicity have failed clinically which may be due to their inability to protect astrocytes. Astrocytes make up ~50% of the brain volume and express high levels of P2 adenosine triphosphate (ATP)-receptors which have excitotoxic potential, suggesting that glutamate and ATP may mediate parallel excitotoxic cascades in neurons and astrocytes, respectively. Mono-cultures of astrocytes expressed an array of P2X and P2Y receptors can produce large rises in [Ca2+]i; mono-cultured neurons showed lower levels of functional P2 receptors. Using high-density 1:1 neuron:astrocyte co-cultures, ischemia (modelled as oxygen-glucose deprivation: OGD) evoked a rise in extracellular ATP, while P2 blockers were highly protective of both cell types. GluR blockers were only protective of neurons. Neither astrocyte nor neuronal mono-cultures showed significant ATP release during OGD, showing that cell type interactions are required for ischemic release. P2 blockers were also protective in normal-density co-cultures, while low doses of combined P2/GluR blockers where highly protective. These results highlight the potential of combined P2/GluR block for protection of neurons and glia. View Full-Text   Abstract
In this first issue of Neuroglia, it is highly appropriate that Professor Jorge A. Colombo at the Unit of Applied Neurobiology (UNA, CEMIC-CONICET) in Buenos Aires, Argentina, writes a perspective of idiosyncrasies of astrocytes in the human brain. Much of his work has been focused on the special case of interlaminar astrocytes, so-named because of their long straight processes that traverse the layers of the human cerebral cortex. Notably, interlaminar astrocytes are primate-specific and their evolutionary development is directly related to that of the columnar organization of the cerebral cortex in higher primates. The human brain also contains varicose projection astrocytes or polarized astrocytes which are absent in lower animals. In addition, classical protoplasmic astrocytes dwelling in the brains of humans are ≈15-times larger and immensely more complex than their rodent counterparts. Human astrocytes retain their peculiar morphology even after grafting into rodent brains; that is, they replace the host astrocytes and confer certain cognitive advantages into so-called ‘humanised’ chimeric mice. Recently, a number of innovative studies have highlighted the major differences between human and rodent astrocytes. Nonetheless, these differences are not widely recognized, and we hope that Jorge Colombo’s Perspective and our associated Commentary will help stimulate appreciation of human astrocytes by neuroscientists and glial cell biologists alike. View Full-Text   Abstract
This review aims to highlight the various significant matters in glial research stemming from personal work by the author and associates at the Unit of Applied Neurobiology (UNA, CEMIC-CONICET), and some of the pending questions. A reassessment and further comments on interlaminar astrocytes—an astroglial cell type that is specific to humans and other non-human primates, and is not found in rodents, is presented. Tentative hypothesis regarding their function and future possible research lines that could contribute to further the analysis of their development and possible role(s), are suggested. The possibility that they function as a separate entity from the “territorial” astrocytes, is also considered. In addition, the potential significance of our observations on interspecies differences in in vitro glial cell dye coupling, on glial diffusible factors affecting the induction of this glial phenotype, and on their interference with the cellular toxic effects of cerebrospinal fluid obtained from l-DOPA treated patients with Parkinson´s disease, is also considered. The major differences oberved in the cerebral cortex glial layout between human and rodents—the main model for studying glial function and pathology—calls for a careful assessment of known and potential species differences in all aspects of glial cell biology. This is essential to provide a better understanding of the organization and function of human and non-human primate brain, and of the neurobiological basis of their behavior. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Ben Barres, who was at the heart of glial cell physiology for over 30 years, died aged 63 on December 27, 2017.[...] View Full-Text "," astrocyte,ATP,excitotoxicity,glutamate,NMDA,neuron,P-2 receptor,stroke   astroglia,protoplasmic astrocytes,interlaminar astrocytes,varicose projection astrocytes,human brain,astroglial domains   interlaminar astrocytes,role(s) of interlaminar astrocytes,control of interlaminar glia development,thalamic regulation of interlaminar glia,comparative dye coupling,glial diffusible factors    "," Cooperation between NMDA-Type Glutamate and P2 Receptors for Neuroprotection during Stroke: Combining Astrocyte and Neuronal Protection   The Special Case of Human Astrocytes   Interlaminar Glia and Other Glial Themes Revisited: Pending Answers Following Three Decades of Glial Research   Remembering Ben Barres   Abstract
Excitotoxicity is the principle mechanism of acute injury during stroke. It is defined as the unregulated accumulation of excitatory neurotransmitters such as glutamate within the extracellular space, leading to over-activation of receptors, ionic disruption, cell swelling, cytotoxic Ca2+ elevation and a feed-forward loop where membrane depolarisation evokes further neurotransmitter release. Glutamate-mediated excitotoxicity is well documented in neurons and oligodendrocytes but drugs targeting glutamate excitotoxicity have failed clinically which may be due to their inability to protect astrocytes. Astrocytes make up ~50% of the brain volume and express high levels of P2 adenosine triphosphate (ATP)-receptors which have excitotoxic potential, suggesting that glutamate and ATP may mediate parallel excitotoxic cascades in neurons and astrocytes, respectively. Mono-cultures of astrocytes expressed an array of P2X and P2Y receptors can produce large rises in [Ca2+]i; mono-cultured neurons showed lower levels of functional P2 receptors. Using high-density 1:1 neuron:astrocyte co-cultures, ischemia (modelled as oxygen-glucose deprivation: OGD) evoked a rise in extracellular ATP, while P2 blockers were highly protective of both cell types. GluR blockers were only protective of neurons. Neither astrocyte nor neuronal mono-cultures showed significant ATP release during OGD, showing that cell type interactions are required for ischemic release. P2 blockers were also protective in normal-density co-cultures, while low doses of combined P2/GluR blockers where highly protective. These results highlight the potential of combined P2/GluR block for protection of neurons and glia. View Full-Text   Abstract
In this first issue of Neuroglia, it is highly appropriate that Professor Jorge A. Colombo at the Unit of Applied Neurobiology (UNA, CEMIC-CONICET) in Buenos Aires, Argentina, writes a perspective of idiosyncrasies of astrocytes in the human brain. Much of his work has been focused on the special case of interlaminar astrocytes, so-named because of their long straight processes that traverse the layers of the human cerebral cortex. Notably, interlaminar astrocytes are primate-specific and their evolutionary development is directly related to that of the columnar organization of the cerebral cortex in higher primates. The human brain also contains varicose projection astrocytes or polarized astrocytes which are absent in lower animals. In addition, classical protoplasmic astrocytes dwelling in the brains of humans are ≈15-times larger and immensely more complex than their rodent counterparts. Human astrocytes retain their peculiar morphology even after grafting into rodent brains; that is, they replace the host astrocytes and confer certain cognitive advantages into so-called ‘humanised’ chimeric mice. Recently, a number of innovative studies have highlighted the major differences between human and rodent astrocytes. Nonetheless, these differences are not widely recognized, and we hope that Jorge Colombo’s Perspective and our associated Commentary will help stimulate appreciation of human astrocytes by neuroscientists and glial cell biologists alike. View Full-Text   Abstract
This review aims to highlight the various significant matters in glial research stemming from personal work by the author and associates at the Unit of Applied Neurobiology (UNA, CEMIC-CONICET), and some of the pending questions. A reassessment and further comments on interlaminar astrocytes—an astroglial cell type that is specific to humans and other non-human primates, and is not found in rodents, is presented. Tentative hypothesis regarding their function and future possible research lines that could contribute to further the analysis of their development and possible role(s), are suggested. The possibility that they function as a separate entity from the “territorial” astrocytes, is also considered. In addition, the potential significance of our observations on interspecies differences in in vitro glial cell dye coupling, on glial diffusible factors affecting the induction of this glial phenotype, and on their interference with the cellular toxic effects of cerebrospinal fluid obtained from l-DOPA treated patients with Parkinson´s disease, is also considered. The major differences oberved in the cerebral cortex glial layout between human and rodents—the main model for studying glial function and pathology—calls for a careful assessment of known and potential species differences in all aspects of glial cell biology. This is essential to provide a better understanding of the organization and function of human and non-human primate brain, and of the neurobiological basis of their behavior. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Ben Barres, who was at the heart of glial cell physiology for over 30 years, died aged 63 on December 27, 2017.[...] View Full-Text   astrocyte,ATP,excitotoxicity,glutamate,NMDA,neuron,P-2 receptor,stroke   astroglia,protoplasmic astrocytes,interlaminar astrocytes,varicose projection astrocytes,human brain,astroglial domains   interlaminar astrocytes,role(s) of interlaminar astrocytes,control of interlaminar glia development,thalamic regulation of interlaminar glia,comparative dye coupling,glial diffusible factors    ", Neuroglia 
 Azimuthal Fermionic Current in the Cosmic String Spacetime Induced by a Magnetic Tube   Scalar Fields as Sources for Wormholes and Regular Black Holes   Realistic Compactification Models in Einstein–Gauss–Bonnet Gravity ," Abstract
In this paper, we calculate the vacuum expectation value of the azimuthal fermionic current, associated with a massive fermionic quantum field in the spacetime of an idealized cosmic string, considering the presence of a magnetic tube of radius a, coaxial to the string. In this analysis three distinct configurations of magnetic field are considered: (i) a magnetic field concentrated on a surface of the tube; (ii) a magnetic field presenting a 1/r
radial dependence; and (iii) an homogeneous magnetic field. In order to develop this analysis , we construct the complete set of normalized solution of the Dirac equation in the region outside the tube. By using the mode-sum formula, we show that the azimuthal induced current is formed by two contributions: the first being the current induced by a line of magnetic flux running along the string, and the second, named core-induced current, is induced by the non-vanishing extension of the magnetic tube. The first contribution depends only on the fractional part of the ration of the magnetic flux inside the tube by the quantum one; as to the second contribution, it depends on the total magnetic flux. We specifically analyze the core-induced current in several limits of the parameters and distance to the tube. View Full-Text   Abstract
We review nonsingular static, spherically symmetric solutions of general relativity with minimally coupled scalar fields. Considered are wormholes and regular black holes (BHs) without a center, including black universes (BHs with expanding cosmology beyond the horizon). Such configurations require a “ghost” field with negative kinetic energy K. Ghosts can be invisible under usual conditions if
K<0
only in strong-field region (“trapped ghost”), or they rapidly decay at large radii. Before discussing particular examples, some general results are presented, such as the necessity of anisotropic matter for asymptotically flat or AdS wormholes, no-hair and global structure theorems for BHs with scalar fields. The stability properties of scalar wormholes and regular BHs under spherical perturbations are discussed. It is stressed that the effective potential
V
eff
for perturbations has universal shapes near generic wormhole throats (a positive pole regularizable by a Darboux transformation) and near transition surfaces from canonical to ghost scalar field behavior (a negative pole at which the perturbation finiteness requirement plays a stabilizing role). Positive poles of
V
eff
emerging at “long throats” (with the radius
r≈
r
0
+const⋅
x
2n
,
n>1
,
x=0
is the throat) may be regularized by repeated Darboux transformations for some values of n. View Full-Text   Abstract
We report the results of a study on the dynamical compactification of spatially flat cosmological models in Einstein–Gauss–Bonnet gravity. The analysis was performed in the arbitrary dimension in order to be more general. We consider both vacuum and
Λ
-term cases. Our results suggest that for vacuum case, realistic compactification into the Kasner (power law) regime occurs with any number of dimensions (D), while the compactification into the exponential solution occurs only for
D⩾2
. For the
Λ
-term case only compactification into the exponential solution exists, and it only occurs for
D⩾2
as well. Our results, combined with the bounds on Gauss–Bonnet coupling and the
Λ
-term (
α,Λ
, respectively) from other considerations, allow for the tightening of the existing constraints and forbid
α<0
. View Full-Text "," cosmic string spacetime,induced current,magnetic flux   general relativity,scalar fields,black holes,wormholes,stability   modified gravity,extra-dimensional models,cosmology,lovelock gravity,Gauss–Bonnet gravity "," Azimuthal Fermionic Current in the Cosmic String Spacetime Induced by a Magnetic Tube   Scalar Fields as Sources for Wormholes and Regular Black Holes   Realistic Compactification Models in Einstein–Gauss–Bonnet Gravity   Abstract
In this paper, we calculate the vacuum expectation value of the azimuthal fermionic current, associated with a massive fermionic quantum field in the spacetime of an idealized cosmic string, considering the presence of a magnetic tube of radius a, coaxial to the string. In this analysis three distinct configurations of magnetic field are considered: (i) a magnetic field concentrated on a surface of the tube; (ii) a magnetic field presenting a 1/r
radial dependence; and (iii) an homogeneous magnetic field. In order to develop this analysis , we construct the complete set of normalized solution of the Dirac equation in the region outside the tube. By using the mode-sum formula, we show that the azimuthal induced current is formed by two contributions: the first being the current induced by a line of magnetic flux running along the string, and the second, named core-induced current, is induced by the non-vanishing extension of the magnetic tube. The first contribution depends only on the fractional part of the ration of the magnetic flux inside the tube by the quantum one; as to the second contribution, it depends on the total magnetic flux. We specifically analyze the core-induced current in several limits of the parameters and distance to the tube. View Full-Text   Abstract
We review nonsingular static, spherically symmetric solutions of general relativity with minimally coupled scalar fields. Considered are wormholes and regular black holes (BHs) without a center, including black universes (BHs with expanding cosmology beyond the horizon). Such configurations require a “ghost” field with negative kinetic energy K. Ghosts can be invisible under usual conditions if
K<0
only in strong-field region (“trapped ghost”), or they rapidly decay at large radii. Before discussing particular examples, some general results are presented, such as the necessity of anisotropic matter for asymptotically flat or AdS wormholes, no-hair and global structure theorems for BHs with scalar fields. The stability properties of scalar wormholes and regular BHs under spherical perturbations are discussed. It is stressed that the effective potential
V
eff
for perturbations has universal shapes near generic wormhole throats (a positive pole regularizable by a Darboux transformation) and near transition surfaces from canonical to ghost scalar field behavior (a negative pole at which the perturbation finiteness requirement plays a stabilizing role). Positive poles of
V
eff
emerging at “long throats” (with the radius
r≈
r
0
+const⋅
x
2n
,
n>1
,
x=0
is the throat) may be regularized by repeated Darboux transformations for some values of n. View Full-Text   Abstract
We report the results of a study on the dynamical compactification of spatially flat cosmological models in Einstein–Gauss–Bonnet gravity. The analysis was performed in the arbitrary dimension in order to be more general. We consider both vacuum and
Λ
-term cases. Our results suggest that for vacuum case, realistic compactification into the Kasner (power law) regime occurs with any number of dimensions (D), while the compactification into the exponential solution occurs only for
D⩾2
. For the
Λ
-term case only compactification into the exponential solution exists, and it only occurs for
D⩾2
as well. Our results, combined with the bounds on Gauss–Bonnet coupling and the
Λ
-term (
α,Λ
, respectively) from other considerations, allow for the tightening of the existing constraints and forbid
α<0
. View Full-Text   cosmic string spacetime,induced current,magnetic flux   general relativity,scalar fields,black holes,wormholes,stability   modified gravity,extra-dimensional models,cosmology,lovelock gravity,Gauss–Bonnet gravity ", Particles 
" Bacillus cereus Induced Necrotizing Fasciitis Mimicking Gastroenteritis: A Case Report   Management and Prevention of Oral Self-Injuries in Lesch–Nyhan Syndrome   Klebsiella pneumoniae-Induced Multiple Infections in a Diabetes Mellitus Patient: Pneumonia, Liver Abscess, Endogenous Endophthalmitis, Urinary Tract Infection   Type A Aortic Dissection Presenting with Neurological Symptoms Mimicking Stroke and Intracranial Hemorrhage "," Abstract
Necrotizing fasciitis is a rapidly spreading inflammation of the soft tissue involving the fascia and the subcutaneous tissue. Early and aggressive surgical intervention accompanied with appropriate antibiotics are the key to improve clinical outcome in patients with necrotizing fasciitis. Here, we present the case of a 46-year-old male who presented with acute onset progressive watery diarrhea and fever for one day. The abdominal ultrasound and computed tomography revealed diffuse gallbladder wall thickening with double layer sign, air density at right hepatic lobe and a small bowel edema. An intra-abdominal infection was initially suspected. However, a progressive erythematous change and bullae was found on the left thigh and lower abdomen. Progressed necrotizing fasciitis was suspected. After administration of broad antibiotics and emergency surgical intervention, the septic shock was reversed. Finally, the blood and wound culture reports revealed Bacillus cereus growth. This paper describes the clinical features of necrotizing fasciitis and highlights the Bacillus cereus-induced necrotizing fasciitis for physicians in order to promote timely intervention for septic shock. View Full-Text   Abstract
Lesch–Nyhan syndrome (LNS) is a rare X-linked recessive disorder with an incidence of 1/100,000–380,000 live births. It is characterized by neurological manifestations, including symptoms of compulsive self-mutilation, which result in the destruction of oral and perioral tissues. This report describes a case of a four-year-old boy diagnosed with LNS, who was referred for evaluation and treatment of self-injury behaviour (SIB). The parents requested the prevention of self-mutilation of the lower lip and tongue by the child’s own teeth. After a thorough discussion with the parents, it was agreed that a conservative approach, avoiding extraction, should be followed initially. A removable dental appliance was fabricated. The parents were instructed and trained about insertion, removal, and cleaning of the appliance. The child was re-examined after one week: biting of the lips and tongue improved immediately after the insertion of the appliances. Initial healing of the lesion was observed. After two and four weeks, positive results were seen. The lesion had resolved completely. In conclusion, appropriate preventive methods have to be developed for each individual patient on the basis of the observation of each single case. Oral appliances represent a conservative solution for SIB and an alternative to more invasive approaches. They can be the initial solution for the management of oral self-injury in LNS patients. View Full-Text   Abstract
Klebsiella pneumoniae-induced endogenous endophthalmitis is a rare but devastating disease, which usually occurs in immunosuppressed patients. Poorly controlled diabetes mellitus is a significant risk factor for this disease. The most common distant infection in patients with K. pneumoniae-induced endogenous endophthalmitis was reported to be liver abscess. Other less commons distant infections were found to be catheter-related bloodstream infection, urinary tract infection, soft tissue infection, renal and psoas abscesses, and endocarditis. Patients with coexisting multiple infection sites are rare according to previous studies. These patients may have a high risk of sepsis and death. Here, we present a case of a 64-year-old male who presented with a progressive visual disturbance with general malaise. A K. pneumoniae-induced endogenous endophthalmitis was suspected. After surveying distant infection sites, pneumonia, liver abscess, and urinary tract infection were reported. This paper also describes the clinical features of endogenous endophthalmitis and highlights K. pneumoniae-induced multiple infections in a diabetes mellitus patient, thus providing information that will be useful for physicians to perform timely interventions and avoid sepsis. View Full-Text   Abstract
Acute aortic dissection is a rare but lethal cardiac disease involving the aorta, which presents with typical symptoms, including severe, sharp, or tearing acute onset of chest or back pain. Other unspecific symptoms, such as epigastric pain, nausea, and vomiting, may be also present. Neurologic symptoms induced by aortic dissection are also present in rare cases but often lead to delate diagnosis because they mimic stroke and intracranial hemorrhage. Therefore, it is important to understand acute aortic dissection-induced neurologic symptoms. Here, we present a case of a 60-year-old male who presented with an acute onset of progressive flaccid hemiplegia on the left side accompanied with slurred speech. Brain computed tomography showed widening of the cortical sulci and dilatation of the ventricles, without intracranial hemorrhage. When waiting for thrombolysis or thrombectomy intervention, acute chest pain was noted. After management, type A dissection from ascending aorta with extension to the right external iliac artery was noted in computed tomography angiography, which also involved the brachiocephalic trunk, left common carotid artery, celiac trunk, superior mesenteric artery, and right renal artery. This paper describes the clinical features of type A dissection, especially the neurological symptoms, and highlights the importance of early diagnosis and timely intervention for type A dissection patients. View Full-Text "," Bacillus cereus,necrotizing fasciitis,gastroenteritis,septic shock   Lesh–Nyhan syndrome,oral self-injury,prevention,appliance   Klebsiella pneumoniae,endogenous endophthalmitis,liver abscess,diabetes mellitus,sepsis   acute aortic dissection,type A dissection,stroke,intracranial hemorrhage "," Bacillus cereus Induced Necrotizing Fasciitis Mimicking Gastroenteritis: A Case Report   Management and Prevention of Oral Self-Injuries in Lesch–Nyhan Syndrome   Klebsiella pneumoniae-Induced Multiple Infections in a Diabetes Mellitus Patient: Pneumonia, Liver Abscess, Endogenous Endophthalmitis, Urinary Tract Infection   Type A Aortic Dissection Presenting with Neurological Symptoms Mimicking Stroke and Intracranial Hemorrhage   Abstract
Necrotizing fasciitis is a rapidly spreading inflammation of the soft tissue involving the fascia and the subcutaneous tissue. Early and aggressive surgical intervention accompanied with appropriate antibiotics are the key to improve clinical outcome in patients with necrotizing fasciitis. Here, we present the case of a 46-year-old male who presented with acute onset progressive watery diarrhea and fever for one day. The abdominal ultrasound and computed tomography revealed diffuse gallbladder wall thickening with double layer sign, air density at right hepatic lobe and a small bowel edema. An intra-abdominal infection was initially suspected. However, a progressive erythematous change and bullae was found on the left thigh and lower abdomen. Progressed necrotizing fasciitis was suspected. After administration of broad antibiotics and emergency surgical intervention, the septic shock was reversed. Finally, the blood and wound culture reports revealed Bacillus cereus growth. This paper describes the clinical features of necrotizing fasciitis and highlights the Bacillus cereus-induced necrotizing fasciitis for physicians in order to promote timely intervention for septic shock. View Full-Text   Abstract
Lesch–Nyhan syndrome (LNS) is a rare X-linked recessive disorder with an incidence of 1/100,000–380,000 live births. It is characterized by neurological manifestations, including symptoms of compulsive self-mutilation, which result in the destruction of oral and perioral tissues. This report describes a case of a four-year-old boy diagnosed with LNS, who was referred for evaluation and treatment of self-injury behaviour (SIB). The parents requested the prevention of self-mutilation of the lower lip and tongue by the child’s own teeth. After a thorough discussion with the parents, it was agreed that a conservative approach, avoiding extraction, should be followed initially. A removable dental appliance was fabricated. The parents were instructed and trained about insertion, removal, and cleaning of the appliance. The child was re-examined after one week: biting of the lips and tongue improved immediately after the insertion of the appliances. Initial healing of the lesion was observed. After two and four weeks, positive results were seen. The lesion had resolved completely. In conclusion, appropriate preventive methods have to be developed for each individual patient on the basis of the observation of each single case. Oral appliances represent a conservative solution for SIB and an alternative to more invasive approaches. They can be the initial solution for the management of oral self-injury in LNS patients. View Full-Text   Abstract
Klebsiella pneumoniae-induced endogenous endophthalmitis is a rare but devastating disease, which usually occurs in immunosuppressed patients. Poorly controlled diabetes mellitus is a significant risk factor for this disease. The most common distant infection in patients with K. pneumoniae-induced endogenous endophthalmitis was reported to be liver abscess. Other less commons distant infections were found to be catheter-related bloodstream infection, urinary tract infection, soft tissue infection, renal and psoas abscesses, and endocarditis. Patients with coexisting multiple infection sites are rare according to previous studies. These patients may have a high risk of sepsis and death. Here, we present a case of a 64-year-old male who presented with a progressive visual disturbance with general malaise. A K. pneumoniae-induced endogenous endophthalmitis was suspected. After surveying distant infection sites, pneumonia, liver abscess, and urinary tract infection were reported. This paper also describes the clinical features of endogenous endophthalmitis and highlights K. pneumoniae-induced multiple infections in a diabetes mellitus patient, thus providing information that will be useful for physicians to perform timely interventions and avoid sepsis. View Full-Text   Abstract
Acute aortic dissection is a rare but lethal cardiac disease involving the aorta, which presents with typical symptoms, including severe, sharp, or tearing acute onset of chest or back pain. Other unspecific symptoms, such as epigastric pain, nausea, and vomiting, may be also present. Neurologic symptoms induced by aortic dissection are also present in rare cases but often lead to delate diagnosis because they mimic stroke and intracranial hemorrhage. Therefore, it is important to understand acute aortic dissection-induced neurologic symptoms. Here, we present a case of a 60-year-old male who presented with an acute onset of progressive flaccid hemiplegia on the left side accompanied with slurred speech. Brain computed tomography showed widening of the cortical sulci and dilatation of the ventricles, without intracranial hemorrhage. When waiting for thrombolysis or thrombectomy intervention, acute chest pain was noted. After management, type A dissection from ascending aorta with extension to the right external iliac artery was noted in computed tomography angiography, which also involved the brachiocephalic trunk, left common carotid artery, celiac trunk, superior mesenteric artery, and right renal artery. This paper describes the clinical features of type A dissection, especially the neurological symptoms, and highlights the importance of early diagnosis and timely intervention for type A dissection patients. View Full-Text   Bacillus cereus,necrotizing fasciitis,gastroenteritis,septic shock   Lesh–Nyhan syndrome,oral self-injury,prevention,appliance   Klebsiella pneumoniae,endogenous endophthalmitis,liver abscess,diabetes mellitus,sepsis   acute aortic dissection,type A dissection,stroke,intracranial hemorrhage ", Reports 
" Substrate Influences Temperature Sensitivity of Dissolved Organic Carbon (DOC) and Nitrogen (DON) Mineralization in Arid Agricultural Soils   Arsenic Speciation of Contaminated Soils/Solid Wastes and Relative Oral Bioavailability in Swine and Mice   Formation of the Azodication (ABTS2+) from ABTS [2,2′-Azinobis-(3-ethylbenzothiazoline-6-sulphonate)] in Sterile Plant Cultures: Root–Exuded Oxidoreductases Contribute to Rhizosphere Priming "," Abstract
The bioavailability of nitrogen (N) in soil relies on the progressive breakdown of necromass protein to peptide and amino acid components and conversion to inorganic N forms. We understand the fluxes and pathways of the N cycle downstream from amino acids, but our understanding of the factors controlling peptide and amino acid mineralization, particularly in arid soils, is lacking. We investigated the influence of temperature on the rate of dissolved organic carbon (DOC) and nitrogen (DON) cycling in three agricultural soils from Saudi Arabia. Although the physical and chemical properties of the soils differed markedly, phospholipid fatty acid (PLFA) analysis revealed they had similar topsoil and subsoil microbial communities. Soils behaved similarly in terms of the rate of substrate use, microbial C-use efficiency, and response to temperature. Substrate mineralization rate increased with temperature with more C being allocated to microbial catabolic rather than anabolic processes. Our results show that climate change is likely to lead to changes in soil organic matter turnover and shift C allocation patterns within the soil microbial community. This is expected to reduce soil quality and exacerbate nutrient losses. Management strategies are required to promote the retention of organic matter in these soils. View Full-Text   Abstract
Arsenic (As) is one of the most widespread, toxic elements in the environment, and human activities have resulted in a large number of contaminated areas. However abundant, the potential of As toxicity from exposure to contaminated soils is limited to the fraction that will dissolve in the gastrointestinal system and be absorbed into systemic circulation or bioavailable species. In part, the release of As from contaminated soil to gastrointestinal fluid depends on the form of solid phase As, also termed “As speciation”. In this study, 27 As-contaminated soils and solid wastes were analyzed using X-ray absorption spectroscopy (XAS) and results were compared to in vivo bioavailability values determined using the adult mouse and juvenile swine bioassays. Arsenic bioavailability was lowest for soils that contained large amounts of arsenopyrite and highest for materials that contained large amounts of ferric arsenates. Soil and solid waste type and properties rather than the contamination source had the greatest influence on As speciation. Principal component analysis determined that As(V) adsorbed and ferric arsenates were the dominant species that control As speciation in the selected materials. Multiple linear regression (MLR) was used to determine the ability of As speciation to predict bioavailability. Arsenic speciation was predictive of 27% and 16% of Relative Bioavailable (RBA) As determined using the juvenile swine and adult mouse models, respectively. Arsenic speciation can provide a conservative estimate of RBA As using MLR for the juvenile swine and adult mouse bioassays at 55% and 53%, respectively. View Full-Text   Abstract
Rhizosphere priming by terrestrial plants comprises increased or repressed efflux of CO2 and N from soil organic matter (SOM), decaying under the impact of temperature, moisture, and the composition of rhizodeposits. Contemporarily, increases in water solubility vs. losses in molecular size, aromaticity, and the content in phenolic OH groups denote the degradation of SOM in planted soil. Root peroxidases (POs) and ‘polyphenoloxidases’ are surmised to contribute to these effects, however, final evidence for this is lacking. Therefore, seedlings of white mustard, alfalfa, and oilseed rape with wide spans in PO release were grown in hydroponic cultures at variable levels of Cu/Fe/Mn as Fenton metals, but also under P and Fe starvation to stimulate the release of carboxylic acids that form catalytic Mn3+ chelants from Mn2+ and MnO2. The shortage in active oxygen as a cosubstrate of POs delayed the immediate oxidation of 2,2′-azinobis-(3-ethylbenzothiazoline-6-sulphonate) (ABTS) supplements to the green ABTS•+ by PO/H2O2, the possible formation of Mn3+ via PO catalyzed aryloxy radicals from root–released phenolics, and of HO• by metal cations in H2O2 dependent Fenton–like reactions. Enhanced by exuded and external malate, O2 independent MnO2 supplements in some treatments formed ABTS•+ spontaneously. The culture fluids then turned red in all treatments within 24–60 h by the formation of azodication (ABTS2+) derivatives in a second plant initiated oxidation step that is known to be catalyzed by substrate radicals. It is concluded that plants initiate oxidative activities that contribute to rhizosphere priming in an environment of oxidoreductase and carboxylate exudates, the indicated presence of mediating substrate radicals, and the cations and (hydr)oxides of transition metals. Pathways of H2O2 production upon the degradation of carboxylates and by the POs themselves are indicated. View Full-Text "," carbon cycling,groundwater,irrigation,microbial uptake kinetics,substrate-induced respiration,wastewater   arsenic,bioavailability,speciation,EXAFS,XANES   rhizosphere priming,humic substances,plant peroxidase,carboxylates,active oxygen,transition metals,Fenton–like reactions,ABTS cation radical,azodication derivatives "," Substrate Influences Temperature Sensitivity of Dissolved Organic Carbon (DOC) and Nitrogen (DON) Mineralization in Arid Agricultural Soils   Arsenic Speciation of Contaminated Soils/Solid Wastes and Relative Oral Bioavailability in Swine and Mice   Formation of the Azodication (ABTS2+) from ABTS [2,2′-Azinobis-(3-ethylbenzothiazoline-6-sulphonate)] in Sterile Plant Cultures: Root–Exuded Oxidoreductases Contribute to Rhizosphere Priming   Abstract
The bioavailability of nitrogen (N) in soil relies on the progressive breakdown of necromass protein to peptide and amino acid components and conversion to inorganic N forms. We understand the fluxes and pathways of the N cycle downstream from amino acids, but our understanding of the factors controlling peptide and amino acid mineralization, particularly in arid soils, is lacking. We investigated the influence of temperature on the rate of dissolved organic carbon (DOC) and nitrogen (DON) cycling in three agricultural soils from Saudi Arabia. Although the physical and chemical properties of the soils differed markedly, phospholipid fatty acid (PLFA) analysis revealed they had similar topsoil and subsoil microbial communities. Soils behaved similarly in terms of the rate of substrate use, microbial C-use efficiency, and response to temperature. Substrate mineralization rate increased with temperature with more C being allocated to microbial catabolic rather than anabolic processes. Our results show that climate change is likely to lead to changes in soil organic matter turnover and shift C allocation patterns within the soil microbial community. This is expected to reduce soil quality and exacerbate nutrient losses. Management strategies are required to promote the retention of organic matter in these soils. View Full-Text   Abstract
Arsenic (As) is one of the most widespread, toxic elements in the environment, and human activities have resulted in a large number of contaminated areas. However abundant, the potential of As toxicity from exposure to contaminated soils is limited to the fraction that will dissolve in the gastrointestinal system and be absorbed into systemic circulation or bioavailable species. In part, the release of As from contaminated soil to gastrointestinal fluid depends on the form of solid phase As, also termed “As speciation”. In this study, 27 As-contaminated soils and solid wastes were analyzed using X-ray absorption spectroscopy (XAS) and results were compared to in vivo bioavailability values determined using the adult mouse and juvenile swine bioassays. Arsenic bioavailability was lowest for soils that contained large amounts of arsenopyrite and highest for materials that contained large amounts of ferric arsenates. Soil and solid waste type and properties rather than the contamination source had the greatest influence on As speciation. Principal component analysis determined that As(V) adsorbed and ferric arsenates were the dominant species that control As speciation in the selected materials. Multiple linear regression (MLR) was used to determine the ability of As speciation to predict bioavailability. Arsenic speciation was predictive of 27% and 16% of Relative Bioavailable (RBA) As determined using the juvenile swine and adult mouse models, respectively. Arsenic speciation can provide a conservative estimate of RBA As using MLR for the juvenile swine and adult mouse bioassays at 55% and 53%, respectively. View Full-Text   Abstract
Rhizosphere priming by terrestrial plants comprises increased or repressed efflux of CO2 and N from soil organic matter (SOM), decaying under the impact of temperature, moisture, and the composition of rhizodeposits. Contemporarily, increases in water solubility vs. losses in molecular size, aromaticity, and the content in phenolic OH groups denote the degradation of SOM in planted soil. Root peroxidases (POs) and ‘polyphenoloxidases’ are surmised to contribute to these effects, however, final evidence for this is lacking. Therefore, seedlings of white mustard, alfalfa, and oilseed rape with wide spans in PO release were grown in hydroponic cultures at variable levels of Cu/Fe/Mn as Fenton metals, but also under P and Fe starvation to stimulate the release of carboxylic acids that form catalytic Mn3+ chelants from Mn2+ and MnO2. The shortage in active oxygen as a cosubstrate of POs delayed the immediate oxidation of 2,2′-azinobis-(3-ethylbenzothiazoline-6-sulphonate) (ABTS) supplements to the green ABTS•+ by PO/H2O2, the possible formation of Mn3+ via PO catalyzed aryloxy radicals from root–released phenolics, and of HO• by metal cations in H2O2 dependent Fenton–like reactions. Enhanced by exuded and external malate, O2 independent MnO2 supplements in some treatments formed ABTS•+ spontaneously. The culture fluids then turned red in all treatments within 24–60 h by the formation of azodication (ABTS2+) derivatives in a second plant initiated oxidation step that is known to be catalyzed by substrate radicals. It is concluded that plants initiate oxidative activities that contribute to rhizosphere priming in an environment of oxidoreductase and carboxylate exudates, the indicated presence of mediating substrate radicals, and the cations and (hydr)oxides of transition metals. Pathways of H2O2 production upon the degradation of carboxylates and by the POs themselves are indicated. View Full-Text   carbon cycling,groundwater,irrigation,microbial uptake kinetics,substrate-induced respiration,wastewater   arsenic,bioavailability,speciation,EXAFS,XANES   rhizosphere priming,humic substances,plant peroxidase,carboxylates,active oxygen,transition metals,Fenton–like reactions,ABTS cation radical,azodication derivatives ", Soil Systems 
 Membrane-Assisted Condenser   Introduction to a New Open Access Journal by MDPI: Clean Technologies ," Abstract
In industrial processes, recycling and reusing of process streams—and of water, in particular—is necessary for minimizing fresh water requirements. Water supply issues are increasing in importance for new and existing industrial plants because the freshwater supply is limited and the forecast are that by 2025 two-thirds of people will live in regions with water scarcity. In this short note, the potentialities of a membrane-assisted condenser for the recovery of evaporated waste water from industrial gases are presented. The modelling of the process was carried out for predicting the membrane-based process performance. The experimental data were compared with the results achieved through the simulations. The comparison showed good agreement confirming the validity of the realized model and its suitability for a screening of the operative conditions to be utilized. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Nowadays, we are experiencing rapid economic and technological development all over the world[...] View Full-Text "," membrane condenser (MC),water recovery,water composition    "," Membrane-Assisted Condenser   Introduction to a New Open Access Journal by MDPI: Clean Technologies   Abstract
In industrial processes, recycling and reusing of process streams—and of water, in particular—is necessary for minimizing fresh water requirements. Water supply issues are increasing in importance for new and existing industrial plants because the freshwater supply is limited and the forecast are that by 2025 two-thirds of people will live in regions with water scarcity. In this short note, the potentialities of a membrane-assisted condenser for the recovery of evaporated waste water from industrial gases are presented. The modelling of the process was carried out for predicting the membrane-based process performance. The experimental data were compared with the results achieved through the simulations. The comparison showed good agreement confirming the validity of the realized model and its suitability for a screening of the operative conditions to be utilized. View Full-Text   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Nowadays, we are experiencing rapid economic and technological development all over the world[...] View Full-Text   membrane condenser (MC),water recovery,water composition    ", Clean Technologies 
 J—A Multidisciplinary Open Access Journal to Accelerate Scientific Communication ," Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
At its best, academic publishing facilitates the communication of the latest research results, accelerates sharing new and verified knowledge, and creates synergies between researchers in answering society’s most fundamental questions.[...] View Full-Text ",  ," J—A Multidisciplinary Open Access Journal to Accelerate Scientific Communication   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
At its best, academic publishing facilitates the communication of the latest research results, accelerates sharing new and verified knowledge, and creates synergies between researchers in answering society’s most fundamental questions.[...] View Full-Text    ", J 
 A Nonparametric Statistical Approach to Content Analysis of Items ," Abstract
In order to use psychometric instruments to assess a multidimensional construct, we may decompose it into dimensions and, in order to assess each dimension, develop a set of items, so one may assess the construct as a whole, by assessing its dimensions. In this scenario, content analysis of items aims to verify if the developed items are assessing the dimension they are supposed to by requesting the judgement of specialists in the studied construct about the dimension that the developed items assess. This paper aims to develop a nonparametric statistical approach based on the Cochran’s Q test to analyse the content of items in order to present a practical method to assess the consistency of the content analysis process; this is achieved by the development of a statistical test that seeks to determine if all the specialists have the same capability to judge the items. A simulation study is conducted to check the consistency of the test and it is applied to a real validation process. View Full-Text "," nonparametric statistics,applied statistics,content validity,psychometric instruments,psychometrics "," A Nonparametric Statistical Approach to Content Analysis of Items   Abstract
In order to use psychometric instruments to assess a multidimensional construct, we may decompose it into dimensions and, in order to assess each dimension, develop a set of items, so one may assess the construct as a whole, by assessing its dimensions. In this scenario, content analysis of items aims to verify if the developed items are assessing the dimension they are supposed to by requesting the judgement of specialists in the studied construct about the dimension that the developed items assess. This paper aims to develop a nonparametric statistical approach based on the Cochran’s Q test to analyse the content of items in order to present a practical method to assess the consistency of the content analysis process; this is achieved by the development of a statistical test that seeks to determine if all the specialists have the same capability to judge the items. A simulation study is conducted to check the consistency of the test and it is applied to a real validation process. View Full-Text   nonparametric statistics,applied statistics,content validity,psychometric instruments,psychometrics ", Stats 
 Forecasting: A New Open Access Journal Dealing with Time Series Analysis and Forecasting ," Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Welcome to Forecasting, a new, online, open access journal, which provides an advanced forum for studies related to forecasting: theoretical, practical, computational and methodological.[...] View Full-Text ",  ," Forecasting: A New Open Access Journal Dealing with Time Series Analysis and Forecasting   Note: In lieu of an abstract, this is an excerpt from the first page.

Excerpt
Welcome to Forecasting, a new, online, open access journal, which provides an advanced forum for studies related to forecasting: theoretical, practical, computational and methodological.[...] View Full-Text    ", Forecasting 
" Integrated Investigation of Built Heritage Monuments: The Case Study of Paphos Harbour Castle, Cyprus "," Abstract
The state of preservation of built heritage monuments is often evaluated by means of several destructive techniques, which are mainly focused on the analysis of small parts of the monuments’ construction materials. The necessary sampling for the accomplishment of these destructive analyses is usually restricted to confined parts of a monument, since monuments are usually under protective legislation, and therefore only indicative of larger areas. Current research attempts to enhance the results of provided by destructive methods, using non-destructive image processing techniques. Towards this end, the potential use of image processing based on rectified images is examined, along with material sampling and laboratory analyses as part of a multi-disciplinary methodology for the investigation of Paphos (Cyprus) Harbour Castle. This approach has been adopted in order to map the degradation patterns observed on the monument’s masonry walls, minimizing destructive methods and attempting to visualize the results of the monument as a whole. The combination of both analytical and non-destructive techniques resulted in the acquisition of large amounts of information, permitting the evaluation of applied non-destructive techniques for the study of the deterioration present on a monument’s external surfaces. This approach led to the assessment of the overall state of preservation of the masonry walls of the structure in an extended scale covering all external façades in a semi-automatic way. View Full-Text "," built heritage,stone deterioration patterns,image processing,image classification,Cyprus "," Integrated Investigation of Built Heritage Monuments: The Case Study of Paphos Harbour Castle, Cyprus   Abstract
The state of preservation of built heritage monuments is often evaluated by means of several destructive techniques, which are mainly focused on the analysis of small parts of the monuments’ construction materials. The necessary sampling for the accomplishment of these destructive analyses is usually restricted to confined parts of a monument, since monuments are usually under protective legislation, and therefore only indicative of larger areas. Current research attempts to enhance the results of provided by destructive methods, using non-destructive image processing techniques. Towards this end, the potential use of image processing based on rectified images is examined, along with material sampling and laboratory analyses as part of a multi-disciplinary methodology for the investigation of Paphos (Cyprus) Harbour Castle. This approach has been adopted in order to map the degradation patterns observed on the monument’s masonry walls, minimizing destructive methods and attempting to visualize the results of the monument as a whole. The combination of both analytical and non-destructive techniques resulted in the acquisition of large amounts of information, permitting the evaluation of applied non-destructive techniques for the study of the deterioration present on a monument’s external surfaces. This approach led to the assessment of the overall state of preservation of the masonry walls of the structure in an extended scale covering all external façades in a semi-automatic way. View Full-Text   built heritage,stone deterioration patterns,image processing,image classification,Cyprus ", Heritage 
