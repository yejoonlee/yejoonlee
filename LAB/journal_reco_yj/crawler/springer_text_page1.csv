journal_title,Science China Materials
article_title,A dual-electrolyte system for photoelectrochemical hydrogen generation using CuInS2-In2O3-TiO2 nanotube array thin filmCuInS2-In2O3-TiO2纳米管阵列薄膜双电介质体系在光电化学产氢中的应用
keyword,"['dual-electrolyte\xa0', 'hydrogen generation\xa0', 'photoelectrochemical\xa0', None, None]"
history,"['2018-04-04', '2017-11-07', '2018-02-26']"
abstract,"Abstract The utilization of Na2S/Na2SO3 mixture as the electrolyte solution to stabilize sulfide anode in a photoelectrochemical cell for hydrogen evolution generally compromises the current-to-hydrogen efficiency (η-current) of the system. Here, the employment of a dual-electrolyte system, that is, Na2S/Na2SO3 mixture and pH-neutral Na2SO4 as the respective electrolyte solutions in the anode and cathode chambers of a water splitting cell is demonstrated to suppress the photocorrosion of CuInS2-In2O3-TiO2 nanotube (CIS-In2O3-TNT) heterostructure, while simultaneously boosts the η-current. Although n-type CIS and In2O3 nanoparticles can be easily formed on TNT array via facile pulse-assisted electrodeposition method, conformal deposition of the nanoparticles homogeneously on the nanotubes wall with preservation of the TNT hollow structure is shown to be essential for achieving efficient charge generation and separation within the heterostructure. In comparison to Na2S/Na2SO3 solution as the sole electrolyte in both the anode and cathode chambers, introduction of dual electrolyte is shown to not only enhance the photostability of the CIS-In2O3-TNT anode, but also lead to near-unity η-current as opposed to the merely 20% η-current of the single-electrolyte system."
journal_title,Science China Materials
article_title,Enhanced thermoelectric performance of Cu12Sb4S13−δ tetrahedrite via nickel dopingNi掺杂提高Cu12Sb4S13−δ黝铜矿热电性能
keyword,"['nickel doping\xa0', 'tetrahedrite\xa0', 'thermoelectric\xa0']"
history,"['2018-03-29', '2018-02-03', '2018-03-05']"
abstract,"Abstract Cu12Sb4S13 tetrahedrite has received great attention as an earth-abundant and environmental-friendly thermoelectric material. This work aims to uncover the thermoelectric performance-enhancing effect and the mechanism of nickel doping on tetrahedrite. A series of Cu12−xNi x Sb4S13−δ (x = 0.5, 0.7, 1.0, 1.5 and 2.0) compounds were synthesized by mechanical alloying combined with spark plasma sintering. It is found that the thermal conductivity sharply reduces with increasing Ni content over the entire temperature range, < 0.9 W m−1 K−1, accompanied with an enhanced thermoelectric power factor. The model predicted that the reduced lattice thermal conductivity is attributed to mid-frequency phonon scattering, caused by precipitates and dislocations resulting from Ni doping. Consequently, a high ZT value up to 0.95 at 723 K was achieved for Cu11NiSb4S13−δ, corresponding to a ∼46% increase over non-doped Cu12Sb4S13−δ. Furthermore, the cyclic measurement showed that the Ni-doped tetrahedrites displayed high chemical stability."
journal_title,Science China Materials
article_title,Macrophages loaded CpG and GNR-PEI for combination of tumor photothermal therapy and immunotherapy载GNR-PEI/CpG巨噬细胞用于肿瘤的光热和免疫联合治疗
keyword,"['hyperbranched polymers\xa0', 'immunotherapy\xa0', 'macrophages\xa0', 'photothermal therapy\xa0', 'synergistic treatment\xa0']"
history,"['2018-03-27', '2018-02-07', '2018-03-03']"
abstract,"Abstract Nano-therapeutic approach for clinical implementation of tumors remains a longstanding challenge in the medical field. The main challenges are rapid clearance, offtarget effect and the limited role in the treatment of metastatic tumors. Toward this objective, a cell-mediated strategy by transporting photothermal reagents and CpG adjuvant within macrophage vehicles is performed. The photothermal reagents are constructed by conjugating of hyperbranched polyethyleimine (PEI) to golden nanorode (GNR) via S-Au bonds. GNR-PEI/CpG nanocomposites, formed via electrostatic interaction and displayed excellent near-infrared (NIR) photothermal performance, exhibit immense macrophage uptake and negligible cytotoxic effect, which is essential for the fabrication of GNR-PEI/CpG loaded macrophages. GNR-PEI/ CpG loaded macrophages demonstrated admirable photothermal response in vitro. Benefited from the functionalization of the binding adhesion between macrophages and 4T1 cells, GNR-PEI/CpG loaded macrophages significantly promoted tumor accumulation in vivo and dramatically enhanced the efficiency of photothermal cancer therapy. Moreover, the immune system is activated after photothermal therapy, which is mainly attributed to the generation of tumor specific antigens and CpG adjuvant in situ. Our findings provide a potential cell-mediated nanoplatform for tumor therapy by combination of near infrared photothermal therapy and immunotherapy."
journal_title,Science China Materials
article_title,"Conducting polymer-based peroxidase mimics: synthesis, synergistic enhanced properties and applications导电高分子基类过氧化物酶: 制备、协同增强性质及其应用"
keyword,"['conducting polymers\xa0', 'artificial enzymes\xa0', 'peroxidase mimics\xa0', 'nanocomposite\xa0', 'synergistic effect\xa0']"
history,"['2018-03-22', '2017-01-12', '2018-02-23']"
abstract,"Abstract The concept of artificial enzymes has been proposed for a long time and a large variety of materials have been exploited in enzyme-like catalytic field for decades. The emergence of nanotechnology provides increasing opportunities for the development of artificial enzymes. Conducting polymer-based nanocomposites are a new type of burgeoning functional materials as enzyme mimics owing to their numerous functional groups, excellent electrical conductivity and redox properties. This review summarizes the recent progress of the synthesis of conducting polymers and their nanocomposites, as well as their applications as efficient peroxidase mimics. After a brief description of the development of conducting polymers, we specifically introduce the fabrication of conducting polymers and their nanocomposites via diverse approaches and show the enhanced peroxidase-like catalytic properties. In addition, the mechanism of the enhanced catalytic efficiency of the conducting polymer-based nanocomposites has been proposed. Finally, we highlight the applications of such conducting polymer-based nanocomposites in the sensitive detection of different types of substances. It is anticipated that this review will pave the way for developing more intriguing functional nanomaterials as enzyme mimics, which shows promising applications in a great many technological fields."
journal_title,Science China Materials
article_title,Additive manufactured metallic implants for orthopaedic applications用于矫形外科的增材制造金属植入物
keyword,"['3D printing\xa0', 'additive manufacturing\xa0', 'electron beam melting\xa0', 'orthopaedic implants\xa0', 'patient-specific\xa0', 'porous scaffold\xa0']"
history,"['2018-03-22', '2017-10-31', '2018-03-06']"
abstract,"Abstract Metallic implants are commonly used in various orthopaedic surgeries, like fracture fixation, spinal instrumentation, joint replacement and bone tumour surgery. Patients may need to adapt to the fixed dimensions of the standard implants. It may result in suboptimal fit to the host bones and possible adverse clinical results. The standard traditional implants may not address the reconstructive challenges such as severe bone deformity or bone loss after implant loosening and bone tumour resection. With the advent of digital technologies in medical imaging, computer programming in three-dimensional (3D) modelling and computer-assisted tools in precise placement of implants, patient-specific implants (PSI) have gained more attention in complex orthopaedic reconstruction. Additive manufacturing technology, in contrast to the conventional subtractive manufacturing, is a flexible process that can fabricate anatomically conforming implants that match the patients’ anatomy and surgical requirements. Complex internal structures with porous scaffold can also be built to enhance osseointegration for better implant longevity. Although basic studies have suggested that additive manufactured (AM) metal structures are good engineered biomaterials for bone replacement, not much peer-reviewed literature is available on the clinical results of the new types of implants. The article gives an overview of the metallic materials commonly used for fabricating orthopaedic implants, describes the metal-based additive manufacturing technology and the processing chain in metallic implants; discusses the features of AM implants; reports the current status in orthopaedic surgical applications and comments on the challenges of AM implants in orthopaedic practice."
journal_title,Science China Materials
article_title,Synthesis of water-soluble dye-cored poly (amidoamine) dendrimers for long-term live cell imaging基于扇形PAMAM树枝制备的水溶性荧光树枝状分子及其长效活细胞荧光成像
keyword,"['fluorescent dendrimers\xa0', 'fan-shaped PAMAM\xa0', 'perylene bisimides\xa0', 'water solubility\xa0', 'live cell imaging\xa0']"
history,"['2018-03-21', '2018-02-09', '2018-03-06']"
abstract,"Abstract Hydrophilic dendrimers, especially poly(amidoamine) (PAMAM) dendrimers are widely applied in modifying fluorescent dyes to endow them with water solubility and biocompatibility for biologic fluorescence imaging. Common preparation strategies of fluorescent dendrimers including encapsulating dyes or attaching dyes at periphery of dendrimers might cause uncertain constituent and lower biocompatibility. Here, we have developed a series of watersoluble fluorescent dendrimers with dye as core and fanshaped PAMAM as arms. Carboxylated perylene bisimides (PBI) dye and squarylium indocyanine (SICy) dye were conjugated with PAMAM dendrons by amidation to obtain a series of fluorescent dendrimers with enhanced water-solubility. Two PBI based dendrimers (PBI-G2.5 and PBI-G1.5) were chosen as model compounds for further optical, selfassembly and biological studies. In aqueous environment, PBI-G2.5 exhibited strong fluorescence, small size (~30 nm) and slightly positive surface charge (~2.46 mV), which are ideal for biomedical applications. In vitro assays demonstrated that PBI-G2.5 nanoparticles accumulated in the cytoplasm of HeLa cells with rapid cellular uptake. The strong fluorescence in HeLa cells remained for over 48 h. To conclude, our study provides an effective strategy for preparing water-soluble fluorescent dendrimers towards long-term live cell imaging."
journal_title,Science China Materials
article_title,Black phosphorus quantum dot/g-C3N4 composites for enhanced CO2 photoreduction to CO黑磷量子点/g-C3N4复合光催化剂的制备及其增强的光催化还原CO2到CO性能
keyword,"['black phosphorus quantum dots\xa0', None, 'photocatalysis\xa0', None]"
history,"['2018-03-21', '2018-02-01', '2018-03-06']"
abstract,"Abstract The development of low cost, metal free semiconductor photocatalysts for CO2 reduction to fuels and valuable chemical feedstocks is a practically imperative for reducing anthropogenic CO2 emissions. In this work, black phosphorus quantum dots (BPQDs) were successfully dispersed on a graphitic carbon nitride (g-C3N4) support via a simple electrostatic attraction approach, and the activities of BP@g-C3N4 composites were evaluated for photocatalytic CO2 reduction. The BP@g-C3N4 composites displayed improved carrier separation efficiency and higher activities for photocatalytic CO2 reduction to CO (6.54 μmol g−1 h−1 at the optimum BPQDs loading of 1 wt%) compared with pure g-C3N4 (2.65 μmol g−1 h−1). This work thus identifies a novel approach towards metal free photocatalysts for CO2 photoreduction."
journal_title,Science China Materials
article_title,Corrosion resistance and cytocompatibility of Ti-20Zr-10Nb-4Ta alloy surface modified by a focused fiber laser激光表面改性Ti-20Zr-10Nb-4Ta合金的耐腐蚀性与细胞相容性研究
keyword,"['laser\xa0', 'Ti-20Zr-10Nb-4Ta\xa0', 'corrosion resistance\xa0', 'cytocompatibility\xa0']"
history,"['2018-03-21', '2017-11-05', '2018-03-05']"
abstract,"Abstract The corrosion resistance and cytocompatibility of Ti-20Zr-10Nb-4Ta (TZNT) alloy modified by surface laser treatment were investigated. The scanning electron microscopy (SEM) measurements indicated that laser treatment on TZNT alloy generated groove morphologies with the width of ~40 μm and the depth of ~10 μm on the surface. The water contact angles along the groove direction decreased by 51% compared with that of the untreated alloy. The laser treatment promoted the oxidation of metallic Ti, Zr and Nb and produced more stable oxides on surface. The corrosion potential increased by 50% and corrosion current density decreased by 72% compared with that of the untreated alloy in the anodic polarization test for the alloy in Hank’s solution at 37°C. This indicated the improvement of the corrosion resistance by laser treatment. The cytotoxicity testing results showed that the laser-treated TZNT alloy performed similar MC3T3-E1 cell viability compared with the untreated alloy. The cells displayed oriented growth along the groove direction due to the increased hydrophilicity. This novel material may be a new candidate in orthopedics and dentistry implantations fields."
journal_title,Science China Materials
article_title,Cu2GeS3 derived ultrafine nanoparticles as high-performance anode for sodium ion batteryCu2GeS3衍生超细纳米微粒作为高性能钠离子电池负极材料
keyword,"['sodium ion battery\xa0', 'nanoparticle copper germanium sulfide\xa0', 'anode material\xa0', 'full cell\xa0']"
history,"['2018-03-16', '2018-01-11', '2018-02-25']"
abstract,"Abstract Germanium based sulfides are potentially attractive as anode material for sodium ion batteries but rarely investigated. Herein, we firstly investigated Na+ storage properties of pristine Cu2GeS3 (PCGS) and found an effective strategy to improve its performance by a single lithiation/delithiation cycle obtaining ultrafine nanoparticle copper germanium sulfide (NCGS). The lithiation/delithiation process leads to the formation of a stable Li-containing solid electrolyte interphase film and a significant improvement of sodiation kinetics. Therefore, the NCGS anode delivers favorable capacity retention and better rate capability compared with that of a PCGS whether in the half cell or in the full cell, showing great promise for energy storage application."
journal_title,Science China Materials
article_title,Maximizing the visible light photoelectrochemical activity of B/N-doped anatase TiO2 microspheres with exposed dominant {001} facetsB/N掺杂富含{001}晶面锐钛矿TiO2的最佳可见光光电催化水氧化活性研究
keyword,"['photoelectrochemistry\xa0', None, 'water splitting\xa0', 'doping\xa0']"
history,"['2018-03-15', '2018-01-27', '2018-02-16']"
abstract,"Abstract Anatase TiO2 microspheres with exposed dominant BBBBB001BBBBB facets were doped with interstitial boron to have a concentration gradient with the maximum concentration at the surface. They were then further doped with substitutional nitrogen by heating in an ammonia atmosphere at different temperatures from 440 to 560°C to give surface N concentrations ranging from 7.03 to 15.47 at%. The optical absorption, atomic and electronic structures and visible-light photoelectrochemical water oxidation activity of these materials were investigated. The maximum activity of the doped TiO2 was achieved at a nitrogen doping temperature of 520°C that gave a high absorbance over the whole visible light region but with no defect-related background absorption."
journal_title,Science China Materials
article_title,PbCrO4 yellow-pigment nanorods: An efficient and stable visible-light-active photocatalyst for O2 evolution and photodegradation铬酸铅纳米棒: 一种高效、稳定的可见光产氧和光降解催化剂
keyword,"[None, 'pollutant\xa0', None, 'visiblelight- active\xa0', 'photocatalyst\xa0']"
history,"['2018-03-15', '2017-12-09', '2018-02-09']"
abstract,"Abstract Here, PbCrO4 nanorods, a commonly used and low-cost yellow pigment, was synthesized via a simple precipitation reaction and can serve as a highly efficient oxygen production and photodegradation photocatalyst. The obtained PbCrO4 nanorods exhibit excellent stability and photocatalytic performance for O2 evolution from water. The production rate is approximately 314.0 μmol h−1 g−1 under visible light, and the quantum efficiency is approximately 2.16% at 420±10 nm and 0.05% at 600±10 nm. In addition, the PbCrO4 shows good degradation performance for methylene blue, methyl blue, methyl orange and phenol under visiblelight irradiation. These results indicate that it is potential to fabricate an effective, robust PbCrO4 photocatalyst by transforming heavy-metal pollutants Pb(II) and Cr(VI) into a highly efficient O2 evolution and photodegradation material. This strategy which uses pollutant to produce clean energy and degrade contaminants is completely green and environmentally benign, and thus could be a promising way for practical environmental applications."
journal_title,Science China Materials
article_title,Humidity-responsive nanocomposite of gold nanoparticles and polyacrylamide brushes grafted on Ag film: synthesis and application as plasmonic nanosensor湿度响应纳米复合材料的组装及其SERS传感器应用
keyword,"['RH-response\xa0', 'plasmonic nanosensor\xa0', 'SERS\xa0']"
history,"['2018-03-15', '2017-12-18', '2018-02-13']"
abstract,"Abstract A general stepwise strategy for the preparation of new humidity-responsive plasmonic nanosensor was described for the first time, based on Ag film functionalization by polyacrylamide (PAAM) brushes via surface-initiated atom transfer radical polymerization (SI-ATRP) method and then assembled with gold nanoparticles (Au NPs). We designed by this way a new plasmonic device made of Au NPs embedded in a humid vapor responsive polymer layer on Ag film and extensively characterized by surface-enhanced Raman scattering (SERS). When the relative humidity (RH) is above 50%, the number of plasmonic hotspots decreases, causing SERS signal reduced noticeably, for the volume expansion of PAAM brushes varied the nano-gap between closely spaced Au NPs, and between Au NPs and Ag film. The reversible optical properties of the prepared nanocomposite tuned by RH were probed through SERS using 4-mercaptopyridine (4-Mpy) as a molecular probe, and the decrease of the RH reversibly induces a significant enhancement of the 4-Mpy SERS signal. By means of the high reversibility, the RH responsive nanocomposite developed in this paper provides a dynamic SERS platform and can be applied as plasmonic nanosensor which is proved to be stable for at least two months."
journal_title,Science China Materials
article_title,CuxO self-assembled mesoporous microspheres with effective surface oxygen vacancy and their room temperature NO2 gas sensing performance精准调控表面氧空位的CuxO自组装介孔微球及其室温检测NO2的气敏性能
keyword,"['self-assembly\xa0', 'mesoporous\xa0', None, 'oxygen vacancy\xa0', None]"
history,"['2018-03-12', '2017-11-24', '2018-01-30']"
abstract,"Abstract A series of Cu x O self-assembled mesoporous microspheres (SMMs), with different and controlled morphology (virus-like, urchin-like, spherical), were synthesized by facile liquid phase approach. The morphology of the as-prepared Cu x O SMMs was evolved from spherical to virus-like shape by controlling the ratio of DI water in solution. It can also realize the transformation from loose assembly to dense assembly by extending the reaction time. These Cu x O SMMs exhibited good response to NO2 gas at room temperature, benefiting from their 3D self-assembly structure. Among these the resulting virus-like CuxO SNMMs-based sensor exhibits largely enhanced response to 1 ppm NO2 gas at room temperature. The enhanced response of the virus-like Cu2O SMMsbased sensor can be ascribed to the high surface area, hierarchical 3D nanostructures, micropores for effective gas diffusion, the heterojunctions formed between CuO and Cu2O, and the existence of abundant surface oxygen vacancies."
journal_title,Science China Materials
article_title,A FeSe-based superconductor (C2H8N2)xFeSe with only ethylenediamine intercalated仅有乙二胺插层的铁硒基超导体(C2H8N2)xFeSe
keyword,"['ethylenediamine\xa0', 'FeSe\xa0', 'intercalation\xa0', 'superconductivity\xa0']"
history,"['2018-03-12', '2017-12-01', '2018-02-10']"
abstract,"Abstract A new FeSe-based superconductor (C2H8N2) x  FeSe with ethylenediamine intercalated into FeSe was successfully synthesized by the solvothermal method, which is the first superconducting instance by metal-free organic molecule intercalation. Elemental analysis and TG-IR-GC/MS data reveal that the ethylenediamine molecules in the interlayer space are separate and intact. The X-ray diffraction (XRD) pattern indicates that the intercalation compound is an orthorhombic lattice rather than a tetragonal lattice applying to almost all the previous FeSe-based superconductors at room temperature. The magnetism measurements display a sharp superconducting transition at ∼10 K which is assigned to (C2H8N2) x FeSe, and a tiny drop in susceptibility at ∼30 K."
journal_title,Science China Materials
article_title,Hierarchical mesoporous Co3O4@ZnCo2O4 hybrid nanowire arrays supported on Ni foam for high-performance asymmetric supercapacitors用于高性能非对称超级电容器电极的泡沫镍负载分层介孔Co3O4@ZnCo2O4混合纳米线阵列
keyword,"[None, 'nanowire arrays\xa0', 'specific capacity\xa0', 'asymmetric supercapacitor\xa0']"
history,"['2018-03-07', '2017-12-11', '2018-02-10']"
abstract,"Abstract In this paper, hierarchical mesoporous Co3O4@ZnCo2O4 hybrid nanowire arrays (NWAs) on Ni foam were prepared through a two-step hydrothermal process associated with successive annealing treatment. The Co3O4@ZnCo2O4 hybrid NWAs exhibited excellent electrochemical performances with a high specific capacity of 1240.5 C g−1 at a current density of 2 mA cm−2, with rate capability of 59.0% shifting from 2 to 30 mA cm−2, and only a 9.1% loss of its capacity even after 3,000 cycles at a consistent current density of 10 mA cm−2. An asymmetric supercapacitor (Co3O4@ZnCo2O4 NWAs||activated carbon) was fabricated and exhibited a high specific capacity of 168 C g−1 at a current density of 1 A g−1. And a preferable energy density of 37.3Wh kg−1 at a power density of 800 W kg−1 was obtained. The excellent electrochemical performances indicate the promising potential application of the hierarchical mesoporous Co3O4@ZnCo2O4 hybrid NWAs in energy storage field."
journal_title,Science China Materials
article_title,Optical visualization of MoS2 grain boundaries by gold deposition金沉积法使MoS2晶界光学可视化
keyword,"['grain boundaries\xa0', 'gold deposition\xa0', 'optical microscope\xa0', None]"
history,"['2018-03-07', '2018-01-03', '2018-02-13']"
abstract,"Abstract The grain boundaries (GBs) in continuous films or domains of MoS2 are vital to its optical and electrical properties. Almost all previous approaches for GBs visualization are based on microscopy and spectroscopy and only effective for domains with less than several micrometers in size. Here we report a simple method for the visualization of large GBs in MoS2 surface by optical microscope. Gold was deposited on the MoS2 grown by chemical vapor deposition, and then the GBs could be observed by optical microscope. Upon gold deposition on MoS2, the entire GBs of large-area MoS2 were clearly visualized using this method. To verify the result, the GBs were also characterized via scanning electron microscopy, transmission electron microscopy and atomic force microscopy. It showed the small particles of gold were clustered together on GBs, which had a larger binding energy than the inner regions. The method is universal and allows for the nondestructive identification of the GBs in any two dimensional materials with large area."
journal_title,Science China Materials
article_title,Rotating magnetic field-controlled fabrication of magnetic hydrogel with spatially disk-like microstructures旋转磁场调控组装圆盘状微结构磁性水凝胶
keyword,"['magnetic nanoparticles\xa0', 'assembly\xa0', 'rotating magnetic field\xa0', 'hydrogel\xa0', 'intelligent fabrication\xa0']"
history,"['2018-03-06', '2017-12-10', '2018-01-27']"
abstract,"Abstract Composite biomaterials with controllable microstructures play an increasingly important role in tissue engineering and regenerative medicine. Here, we report a magnetic hydrogel composite with disk-like microstructure fabricated by assembly of iron oxide nanoparticles during the gelation process in the presence of rotating magnetic field. It should be mentioned that the iron oxide nanoparticles here were synthesized identically following techniques of Ferumoxytol that is the only inorganic nanodrug approved by FDA for clinical applications. The microstructure of nanoparticles inside the hydrogel was ordered three-dimensionally due to the twist of the aligned chains of magnetic nanoparticles which leads to the lowest state of systematic energy. The size of microstructure can be tuned from several micrometers to tens of micrometers by changing the assembly parameters. With the increase of microstructure size, the magnetothermal anisotropy was also augmented. This result confirmed that the assembly-induced anisotropy can occur even for the several micron aggregates of nanoparticles. The rotating magnetic field-assisted technique is cost-effective, simple and flexible for the fabrication of composite hydrogel with ordered microstructure. We believe it will be favorable for the quick, green and intelligent fabrication of some composite materials."
journal_title,Science China Materials
article_title,Towards high-density recording of brain-wide neural activity
keyword,[]
history,"['2018-03', '2018-01-08', '2017-11-30', '2017-12-04']"
abstract,None
journal_title,Science China Materials
article_title,Non-spherical polymersomes driven by directional aromatic interactions
keyword,[]
history,"['2018-03', '2017-12-19', '2017-12-13', '2017-12-14']"
abstract,None
journal_title,Science China Materials
article_title,Biotechnology smart control over stem cell fate commitment at nanoscale
keyword,[]
history,"['2018-03', '2017-12-27', '2017-12-08', '2017-12-12']"
abstract,None
journal_title,Science China Materials
article_title,Graphene-based membranes for organic solvent nanofiltration
keyword,[]
history,"['2018-03', '2018-01-08', '2017-12-08', '2017-12-12']"
abstract,None
journal_title,Science China Materials
article_title,Nano-structured red phosphorus/porous carbon as a superior anode for lithium and sodium-ion batteries红磷/多孔碳纳米复合材料用于高性能锂离子和钠离子电池负极
keyword,"['ion battery\xa0', 'red phosphorus/porous carbon composite\xa0', 'nanostructure\xa0', 'electrochemical performance\xa0']"
history,"['2018-03', '2017-12-22', '2017-09-08', '2017-10-27']"
abstract,"Abstract To enhance electrochemical performance of lithium or sodium-ion batteries (LIBs or NIBs), active materials are usually filled in porous conductive particles to produce anode composites. However, it is still challenging to achieve high performance anode composites with high specific capacity, excellent rate performance, high initial Coulombic efficiency (ICE) and long cycle life. Based on these requirements, we design and fabricate activated carbon-coated carbon nanotubes (AC@CNT) with hierarchical structures containing micro- and meso-pores. A new structure of phosphorus/carbon composite (P@AC@CNT) is prepared by confining red P in porous carbon through a vaporization-condensation-conversion method. The micro-pores are filled with P, while the meso-pores remain unoccupied, and the pore openings on the particle surface are sealed by P. Due to the unique structure of P@AC@CNT, it displays a high specific capacity of 1674 mA h g−1 at 0.2 C, ultrahigh ICE of 92.2%, excellent rate performance of 1116 mA h g−1 at 6 C, and significantly enhanced cycle stability for LIBs. The application of P@AC@CNT in NIBs is further explored. This method for the fabrication of the special composites with improved electrochemical performance can be extended to other energy storage applications."
journal_title,Science China Materials
article_title,Ni(OH)2 nanoflakes supported on 3D hierarchically nanoporous gold/Ni foam as superior electrodes for supercapacitors三维分级结构氢氧化镍纳米片@纳米多孔金/泡沫镍超级电容器电极材料
keyword,"['supercapacitor\xa0', 'nanoporous gold\xa0', 'nickel hydroxide\xa0', 'electrode material\xa0', 'hierarchical porosity\xa0']"
history,"['2018-03', '2017-12-12', '2017-08-08', '2017-10-17']"
abstract,"Abstract The increasing demand for portable electronic devices and hybrid electric vehicles stimulates the development of supercapacitors as an advanced energy storage system. Here, we demonstrate a binder-free nickel hydroxide@nanoporous gold/Ni foam (Ni(OH)2@NPG/Ni foam) electrode for high-performance supercapacitors, which is prepared by a facile three-step fabrication route including electrodeposition of Au-Sn alloy on Ni foam, chemical dealloying of Sn and electrodepostion of Ni(OH)2 on NPG/Ni foam. Such Ni(OH)2@NPG/Ni foam electrode is composed of a thin layer of conformable Ni(OH)2 nanoflakes supported on three-dimensional (3D) hierarchically porous NPG/Ni foam substrate. The resulting Ni(OH)2@NPG/Ni foam electrode can offer highways for both electron transfer and ion transport and lead to an excellent electrochemical performance with an ultrahigh specific capacitance of 3380 F g-1 at a current density of 2 A g−1. Even when the current density was increased to 50 A g−1, it still retained a high capacitance of 1927 F g−1. The promising performance of the Ni(OH)2@NPG/Ni foam electrode is mainly ascribed to the 3D hierarchical porosity and the highly conductive network on the NPG/Ni foam composite current collector, as well as the conformal electrodeposition of Ni(OH)2 active material on the NPG/Ni foam, which induces the formation of interconnected porosity both on the top surface and on the inner surface of the electrode. This inspiring electrochemical performance would make the as-designed electrode material become one of the most promising candidates for future electrochemical energy storage systems."
journal_title,Science China Materials
article_title,Au nanoparticle@silica@europium coordination polymer nanocomposites for enhanced fluorescence and more sensitive monitoring reactive oxygen species复合纳米材料Au@SiO2@Eu配位聚合物的荧光增强及其对活性氧的高灵敏检测研究
keyword,"['nanocomposites\xa0', 'fluorescence enhancement\xa0', 'silica\xa0', 'coordination polymers\xa0', 'reactive oxygen species\xa0']"
history,"['2018-03', '2017-10-26', '2017-08-07', '2017-09-20']"
abstract,"Abstract Au nanoparticle (Au NP)@SiO2@TDA-Eu nanocomposites were prepared by a two-step process: Au NP@SiO2 nanocomposites were prepared by a modified onepot process. Then the europium coordination polymer was deposited on the surface of the Au NP@SiO2 by mixing 2,2’-thiodiacetic acid [S(CH2COO)22-, TDA] and Eu(NO3)3·6H2O in ethanol via a hydrothermal method. The maximum fluorescent enhancement factor of the nanocomposites was 6.81 at 30 nm thickness of silica between the core of the Au NP and the shell of TDA-Eu. The prepared nanocomposites exhibit more sensitive monitoring of reactive oxygen species."
journal_title,Science China Materials
article_title,A stable lead halide perovskite nanocrystals protected by PMMA一种高分子保护的铅卤钙钛矿纳米晶
keyword,"['perovskite nanocrystals\xa0', 'polymer framework\xa0', 'surface coatings\xa0', 'interface phase\xa0']"
history,"['2018-03', '2018-02-25', '2017-08-21', '2017-10-24']"
abstract,"Abstract To enhance the stability in humidity is very crucial to hybrid organic-inorganic lead halide perovskites in a broad range of applications. This report describes a coating stratergy of perovskite nanocrystals via polymethylmethacrylate-introduced ligand-assisted reprecipitation, using the interactions between the Pb cations on the surface of perovskite nanocrystals and the functional ester carbonyl groups in polymethylmethacrylate framework. The hydrophobic framework shields the open metal sites of hybrid organic-inorganic lead halide perovskites from being attacked by water, effectively retarding the diffusion of water into the perovskite nanocrystals. The as-prepared films demonstrate high resistance to heat and moisture. Additionally, the introduction of polymethylmethacrylate into ligand-assisted reprecipitation can effectively control the bulk precipitation and promote the stability of the perovskite solution."
journal_title,Science China Materials
article_title,Room-temperature sintered metal-organic framework nanocrystals: A new type of optical ceramics室温烧结的金属—有机框架纳米晶: 一种新型光学陶瓷
keyword,[]
history,"['2018-03', '2018-01-08', '2017-12-16', '2017-12-18']"
abstract,"摘要光学陶瓷是一种透明的特种陶瓷, 可兼备单晶的高稳定性和玻璃、 流体和其他非晶材料的大尺寸的优点, 是有潜力的激光增益介质. 因为对晶体尺寸和对称性有严格要求, 而且需要高温烧结过程, 只有少数无机非金属材料可用于制备光学陶瓷. 本文报道了一种由配位聚合物(或称金属—有机框架)组成的新型陶瓷. 通过简单地降低溶剂挥发速度, MAF-4(即SOD型二甲基咪唑锌, 也称ZIF-8)的纳米晶即可融合形成致密的陶瓷状块体, 甚至具有毫米级尺寸和高达84%可见光透过率. 该金属—有机光学陶瓷MOOC-1可以负载荧光染料sulforhodamine 640并保持其发光特性, 包括很高的量子产率63.6%和极低的放大自发辐射阈值31 μJ cm-2. 其他几种金属—有机框架的纳米晶也可以在类似条件下融合成陶瓷或光学陶瓷. 考虑到金属—有机框架的结构和功能多样性, 金属—有机陶瓷不但可用作光学器件, 还可能在吸附、 分离、 传感等相关领域展现潜力."
journal_title,Science China Materials
article_title,Thermally-assisted photodegradation of lignin by TiO2/H2O2 under visible/near-infrared light irradiation利用TiO2/H2O2在可见/近红外光照射下热辅助光催化降解木素
keyword,"['lignin\xa0', 'thermally-assisted photocatalysis\xa0', None, None, 'near-infrared light\xa0']"
history,"['2018-03', '2017-12-22', '2017-08-14', '2017-12-08']"
abstract,"Abstract As a bio-recalcitrant organic pollutant in paper mill effluent, lignin is generally removed by an advanced oxidation process, such as a TiO2/H2O2 photocatalytic technique under irradiation with ultraviolet light, which only accounts for less than 5% of sunlight. Herein, we reported a TiO2/H2O2-based thermally-assisted photocatalytic process that allows lignin to be efficiently degraded under visible/near-infrared light at an elevated temperature. Adsorption of H2O2 on TiO2 nanoparticles and an increase of temperature facilitate the production and separation of charge carriers under near-infrared and visible light irradiation, accelerate carrier transfer at the TiO2-electrolyte interface and promote the production of hydroxyl radicals. A higher level of H2O2 addition results in an increased degradation rate of lignin, while the optimal temperature for the thermally-assisted photodegradation of lignin is 70°C. A charge carrier excitation and transfer process was proposed for the TiO2/H2O2 thermally-assisted photocatalytic process. This work describes a new method for the photodegradation of organic pollutants, such as residual lignin in paper mill effluent, using wide band gap semiconductors under visible and near-infrared light irradiation."
journal_title,Science China Materials
article_title,Tuning optical properties of MOF-based thin films by changing the ligands of MOFs配体改变法调控MOFs薄膜的光学性质
keyword,"['metal-organic frameworks\xa0', 'thin film\xa0', 'optical property\xa0', 'refractive index\xa0', 'changing of ligand\xa0']"
history,"['2018-03', '2017-11-24', '2017-07-31', '2017-10-18']"
abstract,"Abstract The preparation and development of novel optical thin films are of great importance to functional optical and opto-electric components requiring a low refractive index. In this study, a typical metal-organic framework (MOF), MIL-101(Cr), is selected as the research model. The corresponding MOF nanoparticles are prepared by a hydrothermal method and the optical thin films are successfully prepared by spin-coating. The optical properties of the corresponding MOF thin films are controlled by changing the type of functional groups on the benzene ring of the ligand (terephthalic acid) on MOFs. The functional groups are hydrogen atoms (H), electron donating groups (−NH2, −OH) and electron withdrawing groups (−NO2, −(NO2)2 or F4), respectively. It is found that the effective refractive index (neff) of MOF thin films decreases along with the increasing voids among MOF nanoparticles. In addition, the extinction coefficient (k) increases with the addition of electron donating groups, and decreases with the addition of electron withdrawing groups. Among the MOFs used in this study, the neff of NO2-MIL-101(Cr) containing electron withdrawing groups is as low as ∼1.2, and value of k is particularly low, which suggests its potential application in antireflective devices. In addition, the intrinsic refractive index (ndense) of the dense MOF materials evaluated according to their porosity increases with the number of the functional groups, and the ndense of the two nitro-substituted MOFs is greater than that of the single nitro-substituted one, and the latter is bigger than that of hydroxyl-substituted one, which is close to that of amino-functionalized one. The diversity of ligands in MOFs makes them a promising new generation of optical materials."
journal_title,Science China Materials
article_title,"Recent progress on nanostructured conducting polymers and composites: synthesis, application and future aspects纳米结构导电聚合物及其复合材料的研究进展: 制备, 应用和展望"
keyword,"['conducting polymer\xa0', 'synthesis\xa0', 'composite\xa0', 'nanostructures\xa0', 'electronic devices\xa0']"
history,"['2018-03', '2018-01-30', '2017-11-22', '2018-01-03']"
abstract,"Abstract Conducting polymers (CPs) have been widely investigated due to their extraordinary advantages over the traditional materials, including wide and tunable electrical conductivity, facile production approach, high mechanical stability, light weight, low cost and ease in material processing. Compared with bulk CPs, nanostructured CPs possess higher electrical conductivity, larger surface area, superior electrochemical activity, which make them suitable for various applications. Hybridization of CPs with other nanomaterials has obtained promising functional nanocomposites and achieved improved performance in different areas, such as energy storage, sensors, energy harvesting and protection applications. In this review, recent progress on nanostructured CPs and their composites is summarized from research all over the world in more than 400 references, especially from the last three years. The relevant synthesizing experiences are outlined and abundant application examples are illustrated. The approaches of production of nanostructured CPs are discussed and the efficacy and benefits of newest trends for the preparation of multifunctional nanomaterials/nanocomposites are presented. Mechanism of their electrical conductivity and the ways to tailor their properties are investigated. The remaining challenges in developing better CPs based nanomaterials are also elaborated."
journal_title,Science China Materials
article_title,Spherical periodicity as structural homology of crystalline and amorphous states晶态与非晶态结构的球周期同源性
keyword,"['spherical periodicity order\xa0', 'Friedel oscillation\xa0', 'metallic glasses\xa0', 'cluster-plus-glue-atom model\xa0', 'principal cluster\xa0']"
history,"['2018-03', '2017-12-22', '2017-07-20', '2017-11-17']"
abstract,"Abstract It has been widely accepted that spherical periodicity generally dominates liquid and amorphous structure formation, where atoms tend to gather near spherically periodic shells according to Friedel oscillation. Here we revealed that the same order is just hidden in the atomic global packing modes of the crystalline phases relevant to bulk metallic glasses. Among the nearest-neighbor clusters developed from all the non-equivalent atomic sites in a given phase, there always exists a principal a principal cluster, centered by which the spherical periodicity, both topologically and chemically, is the most distinct. Then the principal clusters plus specific glue atoms just constitute the cluster-plus-glue-atom structural units shared by both metallic glasses and the corresponding crystalline phases. It is further pointed out that the spherical periodicity order represents a common structural homology of crystalline and amorphous states in the medium-range through scrutinizing all binary bulk-glass-relevant phases in Cu-(Zr, Hf), Ni-(Nb, Ta), Al-Ca, and Pd-Si systems."
journal_title,Science China Materials
article_title,Achieving superior low temperature and high strain rate superplasticity in submerged friction stir welded Ti-6AI-4V alloyTi-6A1-4V合金水下搅拌摩擦焊接头的低温与高应变速率超塑性
keyword,"['titanium alloys\xa0', 'friction stir welding\xa0', 'superplasticity\xa0', 'microstructure\xa0']"
history,"['2018-03', '2017-11-30', '2017-08-07', '2017-10-19']"
abstract,"Abstract The superplastic forming of Ti alloy welds has great application prospects in producing integrated components. However, the nugget zone (NZ) of the Ti alloy welds, produced by fusion welding or conventional friction stir welding (FSW), consists of lamellar microstructure, which exhibits either low superplasticity or high superplastic temperautre and low strain rate. As a result, the NZ plays a leading role in hindering the superplastic forming of the whole welds. In this study, submerged friction stir welding (SFSW) was conducted in Ti-6Al-4V alloy for the first time, and a defectfree weld with the NZ consisting of a strip microstructure was obtained. The NZ exhibited a low-temperature superplasticity at 600°C, which was the lowest superplastic temperature ever reported in the Ti alloy welds. Besides, at 800°C, the NZ showed high strain rate (3×10−2 s−1) superplasticity and a largest elongation of 615% at 1×10−3 s−1. Compared to conventional FSW joints, the NZ of SFSW joint exhibited a much lower flow stress and a decrease in optimal superplastic temperature by 100°C. This is mainly attributed to the easy globularization of the strip microstructure, enhancing the ability of grain/phase boundary sliding."
journal_title,Science China Materials
article_title,High-performance of sodium carboxylate-derived materials for electrochemical energy storage高性能羧酸钠盐衍生物作为电化学储能材料
keyword,"['sodium carboxylate\xa0', 'lithium-ion batteries\xa0', 'organic electrode\xa0', 'electrochemical performance\xa0', 'green and sustainable\xa0']"
history,"['2018-02-26', '2017-11-11', '2018-01-05']"
abstract,"Abstract Four types of sustainable sodium carboxylate-derived materials are investigated as novel electrodes with high performance for lithium-ion batteries. Benefiting from the porous morphology provided by their intermolecular interactions, increasing capacity, excellent cycle stability and superior rate performance are observed for the sodium carboxylate- derived materials. The sodium oxalate (SO) electrodes displayed an increasing discharging capacity at a current density of 50 mA g−1 with with maximum values of 242.9 mA h g−1 for SO-631 and 373.9 mA h g−1 for SO-541 during the 100th cycle. In addition, the SO-541, SC-541 (sodium citrate), ST- 541 (sodium tartrate) and SP-541 (sodium pyromellitate) electrode materials displayed high initial capacities of 619.6, 392.3, 403.7 and 278.1 mA h g−1, respectively, with capacity retentions of 179%, 148%, 173% and 108%, respectively, after 200 cycles at 50 mA g−1 with. Even at a high current density of 2,000 mA g−1 with, the capacities remain 157.6, 131.3, 146.6 and 137.0 mA h g−1, respectively. With these superior electrochemical properties, the sodium carboxylate-derived materials could be considered as promising organic electrode materials for large-scale sustainable lithium-ion batteries."
journal_title,Science China Materials
article_title,Engineering oxygen vacancy on rutile TiO2 for efficient electron-hole separation and high solar-driven photocatalytic hydrogen evolution具有高效电子-空穴分离和优异太阳光催化产氢性能的金红石TiO2表面的氧空位调控
keyword,"['oxygen vacancy\xa0', None, 'surface engineering\xa0', 'solar-driven photocatalysis\xa0', 'hydrogen evolution\xa0']"
history,"['2018-02-13', '2018-01-02', '2018-01-28']"
abstract,"Abstract Oxygen vacancy (VO) plays a vital role in semiconductor photocatalysis. Rutile TiO2 nanomaterials with controllable contents of VO (0–2.18%) are fabricated via an in situ solid-state chemical reduction strategy, with color from white to black. The bandgap of the resultant rutile TiO2 is reduced from 3.0 to 2.56 eV, indicating the enhanced visible light absorption. The resultant rutile TiO2 with optimal contents of VO (∼2.07%) exhibits a high solar-driven photocatalytic hydrogen production rate of 734 μmol h−1, which is about four times as high as that of the pristine one (185 μmol h−1). The presence of VO elevates the apparent Fermi level of rutile TiO2 and promotes the efficient electronhole separation obviously, which favor the escape of photogenerated electrons and prolong the life-time (7.6×103 ns) of photogenerated charge carriers, confirmed by scanning Kelvin probe microscopy, surface photovoltage spectroscopy and transient-state fluorescence. VO-mediated efficient photogenerated electron-hole separation strategy may provide new insight for fabricating other high-performance semiconductor oxide photocatalysts."
journal_title,Science China Materials
article_title,Real-time monitoring of tumor vascular disruption induced by radiofrequency assisted gadofullerene射频辅助金属富勒烯纳米晶体阻断肿瘤血管的原位研究
keyword,"['gadofullerene\xa0', 'radiofrequency\xa0', 'dorsal skin flap chamber\xa0', 'dynamic contrast enhanced magnetic resonance imaging\xa0', 'tumor vasculature\xa0']"
history,"['2018-02-11', '2017-12-23', '2018-01-29']"
abstract,"Abstract The anti-vascular therapy has been extensively studied for high performance tumor therapy by suppressing the tumor angiogenesis or cutting off the existing tumor vasculature. We have previously reported a novel anti-tumor treatment technique using radiofrequency (RF)-assisted gadofullerene nanocrystals (GFNCs) to selectively disrupt the tumor vasculature. In this work, we further revealed the changes on morphology and functionality of the tumor vasculature during the high-performance RF-assisted GFNCs treatment in vivo. Here, a clearly evident mechanism of this technique in tumor vascular disruption was elucidated. Based on the H22 tumor bearing mice with dorsal skin flap chamber (DSFC) model and the dynamic contrast enhanced magnetic resonance imaging (DCE-MRI) technique, it was revealed that the GFNCs would selectively inset in the gaps of tumor vasculature due to the innately incomplete structures and unique microenvironment of tumor vasculature, and they damaged the surrounding endothelia cells excited by the RF to induce a phase transition accompanying with size expansion. Soon afterwards, the blood flow of the tumor blood vessels was permanently shut off, causing the entire tumor vascular network to collapse within 24 h after the treatment. The RF-assistant GFNCs technique was proved to aim at the tumor vasculature precisely, and was harmless to the normal vasculature. The current studies provide a rational explanation on the high efficiency anticancer activity of the RF-assisted GFNCs treatment, suggesting a novel technique with potent clinical application."
journal_title,Science China Materials
article_title,Unique redox properties in defective CeO2-x nanocrystallines synthesized by laser melting激光熔融合成CeO2-x纳米晶的氧化还原性能
keyword,"['cerium oxide\xa0', 'laser melting\xa0', 'defect\xa0', 'boundary\xa0', 'redox property\xa0']"
history,"['2018-02-11', '2017-11-16', '2018-02-01']"
abstract,"Abstract Defects in cerium oxide, especially oxygen vacancies, play an essential role in its versatile applications and are efficiently preserved at ambient conditions in a nonequilibrium process. Herein, defective CeO2-x with heterogeneous structure was synthesized by high-energy laser melting, where a large amount of oxygen vacancies and Ce3+ could be introduced, leading to improved visible light absorption, narrowed bandgap and room temperature ferromagnetism. Moreover, this laser melted CeO2-x exhibits significantly enhanced low-temperature oxidation behaviors than the counterpart prepared by normal hydrogen-reduction. This unique redox performance could be attributed to the intragranular diffusion at the boundaries of assembled nanocrystallites. This method paves a new way for introducing unique multi-functions in oxide ceramics."
journal_title,Science China Materials
article_title,A highly-efficient oxygen evolution electrode based on defective nickel-iron layered double hydroxide基于富缺陷镍铁水滑石材料的高效析氧电极
keyword,"['oxygen evolution reaction\xa0', 'layered double hydroxide\xa0', 'oxygen vacancy\xa0', 'electrocatalysis\xa0']"
history,"['2018-02-11', '2017-12-22', '2018-01-13']"
abstract,"Abstract Exploring efficient and cost-effective electrocatalysts for oxygen evolution reaction (OER) is critical to water splitting. While nickel-iron layered double hydroxide (NiFe LDH) has been long recognized as a promising non-precious electrocatalyst for OER, its intrinsic activity needs further improvement. Herein, we design a highly-efficient oxygen evolution electrode based on defective NiFe LDH nanoarray. By combing the merits of the modulated electronic structure, more exposed active sites, and the conductive electrode, the defective NiFe LDH electrocatalysts show a low onset potential of 1.40 V (vs. RHE). An overpotential of only 200 mV is required for 10 mA cm−2, which is 48 mV lower than that of pristine NiFe-LDH. Density functional theory plus U (DFT+U) calculations are further employed for the origin of this OER activity enhancement. We find the introduction of oxygen vacancies leads to a lower valance state of Fe and the narrowed bandgap, which means the electrons tend to be easily excited into the conduction band, resulting in the lowered reaction overpotential and enhanced OER performance."
journal_title,Science China Materials
article_title,Bimetal-organic-framework derived CoTiO3 mesoporous micro-prisms anode for superior stable power sodium ion batteries双金属-有机框架材料衍生介孔微米棱柱状超高功率和稳定性钠离子电池负极
keyword,"['sodium ion batteries\xa0', 'anode materials\xa0', 'metal-organic framework\xa0', 'cobalt titanate\xa0', 'mesoporous materials\xa0']"
history,"['2018-02-11', '2017-11-07', '2018-01-30']"
abstract,"Abstract Durability, rate capability, capacity and tap density are paramount performance metrics for promising anode materials, especially for sodium ion batteries. Herein, a carbon free mesoporous CoTiO3 micro-prism with a high tap density (1.8 g cm−3) is newly developed by using a novel Co-Ti-bimetal organic framework (BMOF) as precursor. It is also interesting to find that the Co-Ti-BMOF derived carbon-free mesoporous CoTiO3 micro-prisms deliver a superior stable and more powerful Na+ storage than other similar reported titania, titanate and their carbon composites. Its achieved capacity retention ratio for 2,000 cycles is up to 90.1% at 5 A g−1."
journal_title,Science China Materials
article_title,A composite strategy to fabricate high-performance biodegradable stents for tissue regeneration
keyword,[]
history,"['2018-02-10', '2018-02-02', '2018-02-07']"
abstract,None
journal_title,Science China Materials
article_title,"Lead halide perovskites: Recombining faster, emitting brighter"
keyword,[]
history,"['2018-02-10', '2018-01-24', '2018-01-25']"
abstract,None
journal_title,Science China Materials
article_title,Additive-free synthesis of mesoporous FAU-type zeolite with intergrown structure无添加剂体系合成具有共生结构的介孔FAU沸石
keyword,"['mesoporous zeolite\xa0', 'additive-free synthesis\xa0', 'intergrown structure\xa0']"
history,"['2018-02-10', '2017-11-14', '2018-02-03']"
abstract,"Abstract Hierarchical porous zeolites attract great attention because of their porosity on different scales to improve molecular diffusion. Here, we report mesoporous Faujasite (FAU) zeolite nanosheets with intergrown structure synthesized in an additive-free system. The sample was composed of uniform nanosheets with a slice thickness of ∼50 nm, which held a honeycomb-like structure with abundant mesopores. This material exhibits both microporous and mesoporous structure: the intrinsic micropores with a diameter about 0.74 nm in the zeolite framework and the mesopores with a diameter about 10 nm existing within the zeolite nanosheets. The Si/Al ratios can be adjusted from 1.1 to 1.9 (zeolites X or Y). In addition, this simple and environmental method may provide inspiration to the synthesis of other hierarchical zeolites."
journal_title,Science China Materials
article_title,Molecular perovskite high-energetic materials分子钙钛矿含能材料
keyword,[]
history,"['2018-02-10', '2017-12-31', '2018-01-25']"
abstract,"摘要设计合成兼具良好爆轰性能、 高稳定性和低成本的含能化合物是发展实用含能材料的关键. 本文报道了一类新型分子钙钛矿含能化合物, 它们可以通过使用低成本原料经简单一锅反应制备. 作为氧化组分的高氯酸根阴离子和作为燃料组分的还原性有机阳离子交替紧密堆积于钙钛矿结构中, 使该类化合物不仅有比目前军用含能炸药(例如RDX和HMX)更优异的爆炸性能, 而且有更高的稳定性; 其中无金属组分的分子钙钛矿含能化合物具有与CL-20相当的爆炸性能以及更高的比冲(约344秒). 这种将低成本有机燃料组分和氧化剂组分组装在高对称性三元晶体结构的分子组装策略为设计有实用前景的含能材料提供了新思路."
journal_title,Science China Materials
article_title,Fluorescein supramolecular nanosheets: A novel organic photocatalyst for visible-light-driven H2 evolution from water荧光素超分子纳米片: 一种可见光分解水产氢的新型有机光催化剂
keyword,[]
history,"['2018-02-10', '2017-12-10', '2018-01-04']"
abstract,"摘要氢能源是未来最理想的清洁能源, 可以利用太阳能和光催化材料分解水获得. 开发廉价、 资源丰富、 环境友好的光催化材料, 成为近年来能源和环境领域的研究热点. 基于此, 我们报道了一种新型有机光催化材料-不含金属的荧光素超分子纳米片, 其在可见光下显示出高效的光催化分解水产氢活性, 产氢速率接近341 μmol g−1 h−1, 在420±10 nm的波段下表观量子效率达到1.2%. 这是荧光素超分子晶体首次被报道并应用于可见光下分解水产氢, 这一发现丰富了有机和超分子光催化剂的种类."
journal_title,Science China Materials
article_title,Oxygen-doped carbon host with enhanced bonding and electron attraction abilities for efficient and stable SnO2/carbon composite battery anode基于具有增强键能和电子吸引双功能特性的氧掺杂碳载体制备高性能二氧化锡/碳复合负极材料
keyword,"['tin oxide\xa0', 'nanoporous carbon\xa0', 'functional groups\xa0', 'anode materials\xa0', 'lithium-ion batteries\xa0']"
history,"['2018-02-10', '2017-11-18', '2018-01-25']"
abstract,"Abstract The coupling between electrochemically active material and conductive matrix is vitally important for high efficiency lithium ion batteries (LIBs). By introducing oxygen groups into the nanoporous carbon framework, we accomplish sustainably enhanced electrochemical performance for a SnO2/carbon LIB. 2–5 nm SnO2 nanoparticles are hydrothermally grown in different nanoporous carbon frameworks, which are pristine, nitrogen- or oxygen-doped carbons. Compared with pristine and nitrogen-doped carbon hosts, the SnO2/oxygen-doped activated carbon (OAC) composite exhibits a higher discharge capacity of 1,122 mA h g−1 at 500 mA g−1 after 320 cycles operation and a larger lithium storage capacity up to 680 mA h g−1 at a high rate of 2,000 mA g−1. The exceptional electrochemical performance is originated from the oxygen groups, which could act as Lewis acid sites to attract electrons effectively from Sn during the charge process, thus accelerate reversible conversion of Sn to SnO2. Meanwhile, SnO2 nanoparticles are effectively bonded with carbon through such oxygen groups, thus preventing the electrochemical sintering and maintaining the cycling stability of the SnO2/OAC composite anode. The high electrochemical performance, low biomass cost, and facile preparation endows the SnO2/OAC composites a promising candidate for anode materials."
journal_title,Science China Materials
article_title,"Polydopamine-assisted functionalization of heparin and vancomycin onto microarc-oxidized 3D printed porous Ti6Al4V for improved hemocompatibility, osteogenic and anti-infection potencies聚多巴胺辅助微弧氧化后载肝素和万古霉素以提高3D打印多孔钛合金内植物的血液相容性和抗菌成骨功能"
keyword,"['3D printing\xa0', 'porous Ti6Al4V\xa0', 'anti-infection\xa0', 'microarc oxidation\xa0', 'osseointegration\xa0', 'vancomycin\xa0']"
history,"['2018-02-07', '2017-10-27', '2018-01-04']"
abstract,"Abstract Enhanced antiinfection activities, improved hemocompatibility and osteo-compatibility, and reinforced osseointegration are among the most important considerations in designing multifunctional orthopedic biomaterials. Hereby, anti-infective and osteogenic multifunctional 3D printed porous Ti6Al4V implant with excellent hemocompatibility was successfully designed and fabricated. In brief, osteogenic micro-arc oxidation (MAO) coatings with micro/nanoscale porous topography were generated in situ on 3D printed Ti6Al4V scaffolds, on which heparin and vancomycin were easily immobilized. The surface microstructure, morphology, and chemical compositions were characterized employing scanning electron microscopy (SEM), X-ray photoelectron spectroscopy (XPS) and Fourier transform infrared spectroscopy (FTIR). High loading capacity and sustained vancomycin release profiles were revealed using high performance liquid chromatography (HPLC). Favorable anti-bacterial and antibiofilm performances against pathogenic Staphylococcus aureus (S. aureus) were validated in vitro through microbial viability assays, Live/Dead bacterial staining, and crystal violet staining. Human mesenchymal stem cells (hMSCs) were seeded on the scaffolds and their proliferation and viability were assessed using Cell Counting Kit and Live/Dead cell viability kit. Further, osteoblastic differentiation abilities were evaluated using alkaline phosphatase (ALP) activity as a hall marker. Additionally, the improved hemocompatibility of the heparinized scaffolds was confirmed by activated partial thromboplastin time (APTT), prothrombin time (PT) and thrombin time (TT). Overall, our results show that the surface-modified 3D printed porous Ti6Al4V possesses balanced antibacterial and osteogenic functions while exhibiting extra anticlotting effects, boding well for future application in customized functional reconstruction of intricate bone defects."
journal_title,Science China Materials
article_title,Fabrication and photocatalysis of ZnO nanotubes on transparent conductive graphene-based flexible substrates透明导电石墨烯柔性衬底上ZnO纳米管的制备及其光催化性能研究
keyword,[]
history,"['2018-02-07', '2017-12-05', '2018-01-06']"
abstract,"摘要本论文以水热法在透明导电石墨烯柔性衬底(GPET)上生长氧化锌(ZnO)纳米管阵列, 发现其纳米管形成机理为选择性地沿(001)面生长, ZnO/GPET异质结具有较好的整流特性. 光催化测试表明, ZnO/GPET复合结构可提高光催化性能, 并具有良好的循环性. 此方法可在柔性衬底上稳定生长ZnO纳米管, 并可应用于相关光电器件及光催化领域中."
journal_title,Science China Materials
article_title,Preface: Innovative electrode materials for supercapacitors
keyword,[]
history,"['2018-02', '2018-03-01']"
abstract,None
journal_title,Science China Materials
article_title,Self-healable wire-shaped supercapacitors with two twisted NiCo2O4 coated polyvinyl alcohol hydrogel fibers两根NiCo2O4涂覆的聚乙烯醇水凝胶纤维构建线状可自愈超级电容器
keyword,"['supercapacitors\xa0', 'self-healable\xa0', 'nanowires\xa0', 'flexible electronics\xa0']"
history,"['2018-02', '2018-01-12', '2017-11-08', '2017-12-08']"
abstract,"Abstract Wire-shaped supercapacitors (SCs) possessing light-weight, good flexibility and weavability have caught much attention, but it is still a challenge to extend the lifespan of the devices with gradual aging due to the rough usage or external factors. Herein, we report a new stretchable and selfhealable wire-shaped SC. In the typical process, two polyvinyl alcohol/potassium hydroxide (PVA/KOH) hydrogel wrapped with urchin-like NiCo2O4 nanomaterials were twisted together to form a complete SC devices. It is noted that the as-prepared PVA hydrogel can be easily stretched up to 300% with small tensile stress of 12.51 kPa, superior to nearly 350 kPa at 300% strain of the polyurethane. Moreover, the wire-like SCs exhibit excellent electrochemical performance with areal capacitance of 3.88 mF cm−2 at the current density of 0.053 mA cm−2, good cycling stability maintaining 88.23% after 1000 charge/discharge cycles, and 82.19% capacitance retention even after four damaging/healing cycles. These results indicate that wireshaped SCs with two twisted NiCo2O4 coated polyvinyl alcohol hydrogel fibers is a promising structure for achieving the goal of high stability and long-life time. This work may provide a new solution for new generation of self-healable and wearable electronic devices."
journal_title,Science China Materials
article_title,Biomass-derived carbon materials with structural diversities and their applications in energy storage生物质衍生碳材料的结构多样性及其在能量存储方面的应用
keyword,"['biomass-derived carbon materials\xa0', 'supercapacitors\xa0', 'lithium-ion batteries\xa0', 'sodium-ion batteries\xa0']"
history,"['2018-02', '2017-12-27', '2017-10-11', '2017-11-27']"
abstract,"Abstract Currently, carbon materials, such as graphene, carbon nanotubes, activated carbon, porous carbon, have been successfully applied in energy storage area by taking advantage of their structural and functional diversity. However, the development of advanced science and technology has spurred demands for green and sustainable energy storage materials. Biomass-derived carbon, as a type of electrode materials, has attracted much attention because of its structural diversities, adjustable physical/chemical properties, environmental friendliness and considerable economic value. Because the nature contributes the biomass with bizarre microstructures, the biomass-derived carbon materials also show naturally structural diversities, such as 0D spherical, 1D fibrous, 2D lamellar and 3D spatial structures. In this review, the structure design of biomass-derived carbon materials for energy storage is presented. The effects of structural diversity, porosity and surface heteroatom doping of biomass-derived carbon materials in supercapacitors, lithium-ion batteries and sodium-ion batteries are discussed in detail. In addition, the new trends and challenges in biomass-derived carbon materials have also been proposed for further rational design of biomass-derived carbon materials for energy storage."
journal_title,Science China Materials
article_title,Ultrathin silica film derived with ultraviolet irradiation of perhydropolysilazane for high performance and low voltage organic transistor and inverter紫外光辐照全氢聚硅氮烷制备超薄二氧化硅膜及其在有机晶体管和反相器中的应用
keyword,[]
history,"['2018-02-01', '2017-12-12', '2018-01-17']"
abstract,"摘要二氧化硅是一种常见且非常重要的介电材料, 但是其传统的制备方法例如物理气相沉积, 化学气相沉积等无法适应大规模生产以及有机电子工业. 本论文介绍了一种简单的制备二氧化硅超薄膜的方法, 即利用紫外光辐照全氢聚硅氮烷, 使其转化为二氧化硅. 这种方法所制备的二氧化硅超薄膜具有超平的表面以及非常低的漏电. 此外, 我们还将该二氧化硅超薄膜应用于有机晶体管和反相器电路中, 这些器件均表现出良好的电学性能. 这些结果表明该方法制备的二氧化硅超薄膜具有很好的实际应用前景."
journal_title,Science China Materials
article_title,Mesoporous polypyrrole-based graphene nanosheets anchoring redox polyoxometalate for all-solid-state micro-supercapacitors with enhanced volumetric capacitance可控制备磷钼酸复合介孔聚吡咯/石墨烯纳米片应用于高比容量全固态微型超级电容器
keyword,"['mesoporous\xa0', 'graphene\xa0', 'redox\xa0', 'all-solid-state\xa0', 'microsupercapacitors\xa0']"
history,"['2018-02', '2017-10-26', '2017-09-03', '2017-09-26']"
abstract,"Abstract Micro-supercapacitors (MSCs) have emerged as one competitive candidate of high-performance, flexible, safe, portable and wearable energy storage devices. However, improving their electrochemical performance from electrode materials to assembled devices still remains huge challenges. Here, we for the first time synthesized two-dimensional (2D), ultrathin, mesoporous polypyrrole-based graphene nanosheets uniformly anchored with redox polyoxometalate (mPPy@rGO-POM) by soft template approach. Further, using a layer-by-layer deposition and mask-assisted technique, the compactly stacked and sandwich-like hybrid film (mPGM) based on pseudocapacitive mPPy@rGO-POM nanosheets and electrochemically exfoliated graphene was directly fabricated as binder- and additive-free interdigital electrodes for all-solid- state planar micro-supercapacitors (mPGM-MSCs). Notably, the resulted mPGM-MSCs exhibited outstanding areal capacitance (115 mF cm–2), remarkably enhanced volumetric capacitance (137 F cm–3 at 1 mV s–1) in comparison with MSCs based on the films of mPPy@rGO without POM anchoring (95 F cm–3), and non-porous polypyrrole-graphene (68 F cm–3). Further, mPGM-MSCs disclosed robust mechanical flexibility with ~96% of capacitance retention at a highly bending angle of 180°, and impressive parallel or serial interconnection for boosting capacitance or voltage output. As a consequence, our proposed strategy of filling the redox species into mesoporous graphene and other 2D nanosheets will open up new ways to manufacture high-compact and flexible energy storage devices ranging from supercapacitors to batteries."
journal_title,Science China Materials
article_title,Hierarchically nanostructured transition metal oxides for supercapacitors多级纳米结构过渡金属氧化物作为超级电容器电极材料的应用
keyword,"['hierarchical nanostructure\xa0', 'transition metal oxides\xa0', 'supercapacitors\xa0']"
history,"['2018-02', '2017-10-17', '2017-07-07', '2017-08-10']"
abstract,"Abstract Highly efficient, clean, and sustainable electrochemical energy storage technologies have been investigated extensively to counter the shortage of fossil fuels and increasingly prominent environmental problems. Supercapacitors (SCs) have received wide attention as critical devices for electrochemical energy storage because of their rapid charging–discharging capability and long life cycle. Various transition metal oxides (TMOs), such as MnO2, NiO, Co3O4, and CuO, have been extensively studied as electrode materials for SCs. Compared with carbon and conducting polymers, TMO materials can achieve higher specific capacitance. For further improvement of electrochemical performance, hierarchically nanostructured TMO materials have become a hot research area for electrode materials in SCs. The hierarchical nanostructure can not only offer abundant accessible electroactive sites for redox reactions but also shorten the ion diffusion pathway. In this review, we provide an overall summary and evaluation of the recent progress of hierarchically nanostructured TMOs for SCs, including synthesis methods, compositions, structures, and electrochemical performances. Both single-phase TMOs and the composites based on TMOs are summarized. Furthermore, we also prospect the developing foreground of this field. In this view, the important directions mainly include: the nanocomposites of TMOs materials with conductive materials; the cobalt-based materials and the nickel-based materials; the improvement of the volume energy density, the asymmetric SCs, and the flexible all-solid-state SCs."
journal_title,Science China Materials
article_title,Recent advances in flexible supercapacitors based on carbon nanotubes and graphene碳纳米管和石墨烯材料在柔性超级电容器中的应用
keyword,"['flexible supercapacitor\xa0', 'carbon nanotubes\xa0', 'graphene\xa0', 'nanostructure\xa0']"
history,"['2018-02', '2017-12-15', '2017-08-28', '2017-10-31']"
abstract,"Abstract Owing to the rapidly growing market for flexible electronics, there is an urgent demand to develop flexible energy storage devices. Flexible supercapacitors have received much attention due to their good flexibility, fast charge/discharge rate and long lifecycle times. Carbon nanotubes (CNTs) and graphene have good mechanical properties, which make them suitable for flexible supercapacitors. Based on different nanostructures of CNTs and graphene, we summarized the recent progress in CNTs- and graphene-based flexible supercapacitors with a brief description of the basic principles for evaluating their performance. Special emphasis was given to fabrication methods, capacitive performance and electrode configurations of different flexible supercapacitors. Furthermore, the remaining challenges and future research directions for CNTs- and graphene-based flexible supercapacitors have also been discussed."
journal_title,Science China Materials
article_title,"Facile synthesis of T-Nb2O5 nanosheets/nitrogen and sulfur co-doped graphene for high performance lithium-ion hybrid supercapacitorsT-Nb2O5纳米片/N,S共掺杂石墨烯的制备及锂离子混合电容器性能的研究"
keyword,"[None, 'nitrogen and sulfur co-doped graphene\xa0', 'Liion hybrid supercapacitors\xa0', 'great rate capability\xa0', 'excellent cycling stability\xa0']"
history,"['2018-02', '2017-08-08', '2017-05-22', '2017-06-16']"
abstract,"Abstract Li-ion hybrid supercapacitors (Li-HSCs) have attracted increasing attention as a promising energy storage device with both high power and energy densities. We report a facile two-step hydrothermal method to prepare the orthorhombic niobium oxide (T-Nb2O5) nanosheets supported on nitrogen and sulfur co-doped graphene (T-Nb2O5/NS-G) as anode for Li-HSCs. X-ray diffraction and morphological analysis show that the T-Nb2O5 nanosheets successfully and uniformly distributed on the NS-G sheets. The T-Nb2O5/NS-G hybrid exhibits great rate capability (capacity retention of 63.1% from 0.05 to 5 A g−1) and superior cycling stability (a low capacity fading of ~6.4% after 1000 cycles at 0.5 A g−1). The full-cell consisting of T-Nb2O5/NS-G and active carbon (AC) results in high energy density (69.2 W h kg−1 at 0.1 A g−1), high power density (9.17 kW kg−1) and excellent cycling stability (95% of the initial energy after 3000 cycles). This excellent performance is mainly attributed to the highly conductive NS-G sheets, the uniformly distributed T-Nb2O5 nanosheets and the synergetic effects between them. These encouraging performances confirm that the obtained TNb2O5/ NS-G has promising prospect as the anode for Li-HSCs."
journal_title,Science China Materials
article_title,Binary NiCu layered double hydroxide nanosheets for enhanced energy storage performance as supercapacitor electrode基于镍铜层状双金属氢氧化物纳米片的超级电容器电极及其优异的储能性能
keyword,"['biomass-derived carbon materials\xa0', 'supercapacitors\xa0', 'lithium-ion batteries\xa0', 'sodium-ion batteries\xa0']"
history,"['2018-02', '2017-11-16', '2017-08-24', '2017-09-26']"
abstract,"摘要本文通过简便的溶剂热法成功制备了在碳纤维布上原位生长的镍铜层状双金属氢氧化物纳米片阵列. 与纯的氢氧化镍材料相比, 铜的引入极大地增强了其在超级电容器应用方面的各项电化学性能, 包括超过50%的比电容容量的提高(在充放电电流密度为0.5 A g–1时 其比电容达到1953.5 F g–1)和更高的倍率性能(在充放电电流密度为5 A g–1时比电容的保持率为75%). 这些优异的性能是因为镍铜双金属 层状氢氧化物具有更高的导电性和更快的界面电荷迁移率. 本文的研究工作为有效利用地球含量丰富的材料进一步增强基于层状双金属 氢氧化物的超级电容器电极性能提供了新的研究思路和方法."
journal_title,Science China Materials
article_title,Flexible all-solid-state micro-supercapacitor based on Ni fiber electrode coated with MnO2 and reduced graphene oxide via electrochemical deposition电沉积制备氧化石墨烯/二氧化锰包裹镍纤维电极用于柔性固态超级电容器
keyword,"['supercapacitor\xa0', 'flexible\xa0', 'fiber-shaped\xa0', None, 'graphene oxide\xa0', 'electrochemical deposition\xa0']"
history,"['2018-02', '2018-01-19', '2017-09-05', '2017-11-23']"
abstract,"Abstract Flexible and micro-sized energy conversion/ storage components are extremely demanding in portable and multifunctional electronic devices, especially those small, flexible, roll-up and even wearable ones. Here in this paper, a two-step electrochemical deposition method has been developed to coat Ni fibers with reduced graphene oxide and MnO2 subsequently, giving rise to Ni@reduced-graphene-oxide@MnO2 sheath-core flexible electrode with a high areal specific capacitance of 119.4 mF cm−2 at a current density of 0.5 mA cm−2 in 1 mol L−1 Na2SO4 electrolyte. Using polyvinyl alcohol (PVA)- LiCl as a solid state electrolyte, two Ni@reduced-grapheneoxide@ MnO2 flexible electrodes were assembled into a freestanding, lightweight, symmetrical fiber-shaped micro-supercapacitor device with a maximum areal capacitance of 26.9 mF cm−2. A high power density of 0.1W cm−3 could be obtained when the energy density was as high as 0.27 mW h cm−3. Moreover, the resulting micro-supercapacitor device also demonstrated good flexibility and high cyclic stability. The present work provides a simple, facile and low-cost method for the fabrication of flexible, lightweight and wearable energy conversion/storage micro-devices with a high-performance."
journal_title,Science China Materials
article_title,Layered double hydroxides with larger interlayer distance for enhanced pseudocapacitance层状双羟基复合金属氧化物层间距调控及其电容器性能研究
keyword,"['layered double hydroxides\xa0', 'interlayer distance\xa0', 'hydrothermal\xa0', 'asymmetric supercapacitors\xa0']"
history,"['2018-02', '2017-11-30', '2017-08-21', '2017-10-09']"
abstract,"Abstract The interlayer space of the layered materials is not always the electrochemical active area for contributing to the pseudocapacitive process. To our knowledge, few efforts have been devoted to investigating the effect of interlayer distance of layered double hydroxides (LDHs) on pseudocapacitors. Here, we obtained the CoAl–LDH with different interlayer distance via the reaction in aqueous media hydrothermally. Electrochemical characterization reveals that the CoAl(DS–(dodecyl sulfate))–LDHs with an interlayer distance of 2.58 nm can deliver higher specific capacitance of 1481.7 F g–1 than CoAl(SO 4 2– )–LDH (0.87 nm, 1252.7 F g–1) and CoAl (CO 3 2– )–LDH (0.76 nm, 1149.2 F g–1) at a discharge current density of 1 A g–1. An asymmetric supercapacitor with the CoAl(DS–)–LDHs║activated carbon also shows a better electrochemical performance, including a high energy density of 54.2 W h kg–1 at a power density of 0.9 kW kg–1 and a longterm stability, in comparison with CoAl(SO 4 2– )–LDH and CoAl (CO 3 2– )–LDH║activated carbon."
journal_title,Science China Materials
article_title,Recent advancements in metal organic framework based electrodes for supercapacitors金属有机框架材料在超级电容器中的应用研究进展
keyword,"['metal organic frameworks (MOFs)\xa0', 'electrochemistry\xa0', 'supercapacitors\xa0', 'electrode\xa0', 'derivative\xa0']"
history,"['2018-02', '2018-01-12', '2017-09-21', '2017-10-27']"
abstract,"Abstract Metal organic frameworks (MOFs) are considered as very promising candidates to build electrodes for electrochemical energy storage devices such as lithium ion batteries, fuel cells and supercapacitors, due to their diverse structure, adjustable aperture, large specific surface area and abundant active sites. Supercapacitor has been widely investigated in the past decades. Of critical importance in these devices is the electrode active materials, and this application has been intensively studied with the development of novel nanomaterials. In this review we summarize recent reports on MOFs as electrode materials for supercapacitors. Specifically, the synthesis of MOF materials for supercapacitor electrodes and their performance in electrochemical energy storage are discussed. We aim to include supercapacitor electrode materials related to MOFs, such as carbon, metal and composite materials. It is proposed that MOFs play an important role in the development of a new generation of supercapacitor electrode materials. Finally, we discuss the current challenges in the field of supercapacitors, with a view towards how to address these challenges with the future development of MOFs and their derivatives."
journal_title,Science China Materials
article_title,Nanotube-like hard carbon as high-performance anode material for sodium ion hybrid capacitors纳米管状硬碳作为负极材料构建高性能钠离子混合电容器
keyword,"['sodium ion hybrid capacitor\xa0', 'anode\xa0', 'hard carbon\xa0', 'polyaniline\xa0', 'nanotube\xa0']"
history,"['2018-02', '2017-11-27', '2017-09-01', '2017-10-14']"
abstract,"Abstract Sodium ion hybrid capacitors (SIHCs) are of great concern in large-scale energy storage applications due to their good energy-and-power characteristic, as well as abundant reserves and low cost of sodium. However, the sluggish faradaic kinetics of anode materials severely limit the overall electrochemical performance of SIHC devices. Herein, we report an application of nanotube-like hard carbon (NTHC) anode material prepared by high-temperature carbonization (1150°C) of polyaniline (PANI) nanotubes for high-performance SIHCs. As a result, the assembled sodium ion half-cell with NTHC shows a high reversible capacity of 419.5 mA h g−1 at 0.05 A g−1 and a good rate performance of 74.6 mA h g−1 at 2.5 A g−1 in a potential window of 0–2 V (vs. Na/Na+). On this basic, a SIHC using such NTHC as anode and a high-capacity activated carbon (APDC) as cathode is fabricated, which exhibits a high energy density of 133.0 W h kg−1 at 2850 W kg−1 and still remains 100.9 W h kg−1 at 14,250 W kg−1. Within the potential range of 1.5–3.5 V, the SIHCs display an outstanding cycling stability tested at 2 A g−1 with a good capacity retention of 82.5% even after 12,000 cycles."
journal_title,Science China Materials
article_title,In vitroand in vivo studies on as-extruded Mg-5.25wt.%Zn-0.6wt.%Ca alloy as biodegradable metal挤压态Mg-5.25wt.%Zn-0.6wt.%Ca可降解镁合金的体内外研究
keyword,"['magnesium alloy\xa0', 'corrosion\xa0', 'biocompatibility\xa0', 'bone\xa0', 'biomaterial\xa0']"
history,"['2018-01-31', '2017-10-12', '2018-01-03']"
abstract,"Abstract Magnesium alloys have shown prospective applications as a new biodegradable metal within bone. To garantee the longterm biocompatibility, a Mg-Zn-Ca alloy, composing of essential elements for human, was prepared and its feasibility for orthopedic applications was investigated. The in vitro and in vivo corrosion of Mg-Zn-Ca alloy as well as the biocompatibility were studied. The in vitro corrosion tests in five kinds of physiological solutions showed that the corrosion rates and corrosion morphologies of the alloy were strongly influenced by the solution used. The addition of serum in Hank’s and MEM significantly slowed down the corrosion rate and improved the corrosion uniformity of the alloy. The corrosion rate decreased with increasing serum concentration. The alloy showed the slowest corrosion rate as well as homogeneous corrosion morphology in MEM+10%FBS. Both the indirect and direct cell experiments indicated good cytocompatibility of the extruded Mg-Zn-Ca alloy. In vivo, we observed a gradual degradation process from the surface of extruded Mg-Zn-Ca alloy and only 40% in volume of implant was left after 4 weeks implantation in medullary cavities of mice. The micro-CT and histological analyses revealed its good biocompatibility with peri-implant new bone formation and increasing cortical bone thickness with increasing implantation period. This study showed that the extruded Mg-Zn-Ca alloy provided sufficient biocompatibility for orthopedic application, though the in vivo corrosion rate should be further reduced for clinical use."
journal_title,Science China Materials
article_title,Recent progress on advanced design for photoelectrochemical reduction of CO2 to fuels用于光电催化还原CO2为燃料的设计进展
keyword,"['photoelectrocatalysis\xa0', None, 'light utilization\xa0', 'semiconductor\xa0', 'selectivity\xa0']"
history,"['2018-01-31', '2017-09-28', '2017-10-26']"
abstract,"Abstract The energy crisis and global warming become severe issues. Solar-driven CO2 reduction provides a promising route to confront the predicaments, which has received much attention. The photoelectrochemical (PEC) process, which can integrate the merits of both photocatalysis and electrocatalysis, boosts splendid talent for CO2 reduction with high efficiency and excellent selectivity. Recent several decades have witnessed the overwhelming development of PEC CO2 reduction. In this review, we attempt to systematically summarize the recent advanced design for PEC CO2 reduction. On account of basic principles and evaluation parameters, we firstly highlight the subtle construction for photocathodes to enhance the efficiency and selectivity of CO2 reduction, which includes the strategies for improving light utilization, supplying catalytic active sites and steering reaction pathway. Furthermore, diversiform novel PEC setups are also outlined. These exploited setups endow a bright window to surmount the intrinsic disadvantages of photocathode, showing promising potentials for future applications. Finally, we underline the challenges and key factors for the further development of PEC CO2 reduction that would enable more efficient designs for setups and deepen systematic understanding for mechanisms."
journal_title,Science China Materials
article_title,In-situ growth of ultrathin MoS2 nanosheets on sponge-like carbon nanospheres for lithium-ion batteries在多孔碳纳米球上原位生长超薄MoS2纳米片构筑锂离子电池负极材料及其性能研究
keyword,"[None, 'sponge-like carbon\xa0', 'nanosphere\xa0', 'high-rate\xa0', 'lithium-ion batteries\xa0']"
history,"['2018-01-31', '2017-12-07', '2018-01-16']"
abstract,"Abstract Developing novel electrode materials for lithiumion batteries (LIBs) with rapid charge/discharge capability and high cycling stability remains a big challenge to date. Herein, we demonstrate the design and synthesis of ultrathin MoS2 nanosheets in-situ grown on sponge-like carbon nanospheres by a simple diffusion-controlled process. The unique sponge-like carbon nanosphere core can be used as “reservoir” of electrolyte by adsorbing to shorten the iondiffusion path, and meanwhile as “elastomer” to alleviate the structural change of the MoS2 nanosheets during the charge/discharge processes. Furthermore, the vertical ultrathin MoS2 nanosheets with broadened interlayer space greatly enrich the electrochemical active sites. Consequently, the as-obtained MoS2/C nanospheres exhibit increased specific capacities at various rates with superior cycling stability compared to the MoS2/C floccules. It is reckoned that the present concept can be extended to other electrode materials for achieving highrate and stable LIBs."
journal_title,Science China Materials
article_title,Tuning crystal structure and magnetic property of dispersible FePt intermetallic nanoparticles单分散FePt金属间化合物纳米颗粒的可调化学结构和磁性能
keyword,"['FePt intermetallic nanoparticles\xa0', 'chemical ordering\xa0', 'magnetic materials\xa0', 'contrast agent\xa0']"
history,"['2018-01-31', '2017-11-22', '2018-01-02']"
abstract,"Abstract Dispersible FePt intermetallic nanoparticles (NPs) with tunable composition were synthesized by thermal annealing of MgO coated Al-FePt (or Al-FePt-Fe3O4) NPs followed by an acid treatment to remove MgO. High-temperature annealing facilitates the conversion of FePt from disordered alloy to ordered intermetallics. Under the protection of MgO, the diffusion of Fe and Pt atoms was limited, making it possible for the atom reconstruction in the lattice to give discrete FePt intermetallic NPs after a facile acid etching process. FePt intermetallic NPs formed face-centered cubic and face-centered tetragonal structures with their magnetic properties tuned by composition. The saturation magnetization was adjusted from 8 to 52 emu g−1 by increasing the Fe concentration, while the coercivity reached a maximum of 33 kOe when Fe concentration was 44%. After surface modifications by hydrophilic or hydrophobic molecules containing thiol groups, FePt intermetallic NPs could be dissolved into water or hydrocarbon solvents. The hydrophilic L10-FePt intermetallic NPs were applied as contrast agents for magnetic resonance imaging, showing a high transverse relaxivity of 328.6 mmol−1 L s−1, which indicated the great potential of FePt intermetallic NPs as molecular probes for cancer diagnosis."
journal_title,Science China Materials
article_title,Impact of structure and flow-path on in situ synthesis of AlN: Dynamic microstructural evolution of Al-AlN-Si materials微观结构和流动路径对AlN原位合成的影响: Al-AlN-Si微观组织形成的动力学演变研究
keyword,"['Al-AlN-Si materials\xa0', 'flow-reaction-system\xa0', 'turbulence\xa0', 'flow path\xa0']"
history,"['2018-01-31', '2017-10-30', '2017-12-27']"
abstract,"Abstract The Al-AlN-Si composites were prepared in the gas-in-liquid in situ synthesized flow-reaction-system, which was implemented by a powder metallurgy and reaction sintering route. The experimental results showed that Al-AlN-50SiB material (prepared by ball-milling powders) and Al- AlN-50SiM material (prepared by mixing powders) exhibited the semi-continuous Si structures and the isolated Si islands, respectively. Subsequently, the Al-AlN-50Si materials were selected as the model materials by phase identification and microstructure analysis. The dynamic microstructural evolution of Al-AlN-50Si materials was investigated using the computational fluid dynamics (CFD) method. Mathematical models and simulation results showed that the in situ synthesis of AlN was strongly influenced by the structure and the flowpath \(\left( {\left( {c_{g,N_2 } /l_{g,N_2 } } \right) + \left( {c_{s,AlN} /l_{s,AlN} } \right)} \right)\). The flow paths of Al-AlN-50SiB material were restricted by the semi-continuous Si. These Si structures can promote the formation of the strong turbulence with gradually weakened fluctuation, so that the in situ synthesis of AlN was interconnected and surrounded by an interpenetrating Si network. In contrast, the flow paths of Al-AlN-50SiM material can easily pass through the isolated Si due to its mild turbulence with linear relationship. As a result, AlN was separated by the isolated Si and agglomerated in the matrix. Overall, the present work provides new insights into dynamic microstructural evolution in in situ reaction sintering systems."
journal_title,Science China Materials
article_title,"A novel CoOOH/(Ti, C)-Fe2O3 nanorod photoanode for photoelectrochemical water splitting新型CoOOH/(Ti, C)-Fe2O3纳米棒光阳极制备及其光电解水性能研究"
keyword,"['photoelectrochemistry\xa0', 'water splitting\xa0', 'doping\xa0', 'ferric oxide\xa0']"
history,"['2018-01-29', '2017-10-29', '2017-12-28']"
abstract,"Abstract In this work, we demonstrate the CoOOH/(Ti, C)-Fe2O3 (CTCF) nanorods prepared by a facile approach as well as their implementation as photoanodes for photoelectrochemical (PEC) water splitting. The photocurrent density of CTCF photoanode is 1.85 mA cm−2 at +1.23 V vs. reversible hydrogen electrode (RHE), which is more than 20 times higher than that of pristine α-Fe2O3 photoanode (0.08 mA cm−2). The incident-photo-to-current conversion efficiency, applied bias photo-to-current efficiency and transfer efficiency of CTCF photoanode reaches 31.2% at 380 nm (+1.23 V vs. RHE), 0.11% (+1.11 V vs. RHE), 68.2% (+1.23 V vs. RHE) respectively, which are much higher than those of pristine α-Fe2O3 photoanode. Additionally, the longtime irradiation PEC water splitting of CTCF photoanode demonstrates its high stability at extreme voltage in NaOH (pH 14)."
journal_title,Science China Materials
article_title,Amine facilitates the synthesis of silica-supported ultrasmall bimetallic nanoparticles
keyword,[]
history,"['2018-01-25', '2018-01-09', '2018-01-12']"
abstract,None
journal_title,Science China Materials
article_title,Bimetallic zeolite imidazolate framework for enhanced lithium storage boosted by the redox participation of nitrogen atoms基于氮原子氧化还原的双金属沸石咪唑框架用于高性能锂离子电池负极
keyword,"['bimetallic\xa0', 'zeolitic imidazolate framework\xa0', 'lithiumion battery\xa0', 'improved capacity\xa0', 'mechanism study\xa0']"
history,"['2018-01-25', '2017-11-07', '2017-12-28']"
abstract,"Abstract In this work, a bimetallic zeolitic imidazolate framework (ZIF) CoZn-ZIF was synthesized via a facile solvothermal approach and applied in lithium-ion batteries. The as-prepared CoZn-ZIF shows a high reversible capacity of 605.8 mA h g−1 at a current density of 100 mA g−1, far beyond the performance of the corresponding monometallic Co-ZIF- 67 and Zn-ZIF-8. Ex-situ synchrotron soft X-ray absorption spectroscopy, X-ray diffraction, and electron paramagnetic resonance techniques were employed to explore the Li-storage mechanism. The superior performance of CoZn-ZIF over Co- ZIF-67 and Zn-ZIF-8 could be mainly attributed to lithiation and delithiation of nitrogen atoms, accompanied by the breakage and recoordination of metal nitrogen bond. Morever, a few metal nitrogen bonds without recoordination will lead to the amorphization of CoZn-ZIF and the formation of few nitrogen radicals."
journal_title,Science China Materials
article_title,Near UV-pumped yellow-emitting Sr9MgLi(PO4)7:Eu2+ phosphor for white-light LEDs近紫外芯片激发的白光LED用黄色荧光粉Sr9MgLi(PO4)7:Eu2+
keyword,"['phosphor\xa0', 'luminescence\xa0', 'rare earth\xa0', 'LEDs\xa0']"
history,"['2018-01-25', '2017-11-28', '2018-01-03']"
abstract,"Abstract Laboratory discovery of new phosphors for white-light light-emitting diodes (WLEDs) is still an imperative challenge. A new yellow-emitting Sr9MgLi(PO4)7:Eu2+ phosphor was discovered based on the mineral-inspired prototype evolution and new phase construction strategy proposed by our group. Sr9MgLi(PO4)7:Eu2+ has been synthesized by using a high temperature solid-state method, and its phase structure and luminescence properties have been investigated in detail, and applied in WLED lamp. Sr9MgLi(PO4)7 phase is derived from the β-Ca3(PO4)2 -type mineral structure. Upon 365 nm UV light excitation, the Sr9MgLi(PO4)7:Eu2+ phosphor exhibits a broad emission band from 450 nm to 700 nm. The white-light LED lamp was fabricated based on the phosphor blends of the composition-optimized yellow-emitting Sr9MgLi (PO4)7:Eu2+ and commercial blue-emitting BaMgAl10O17:Eu2+, and a 365 nm UV chip was used as the excitation source. The R a, CCT value and CIE of the as-fabricated LEDs were found to be 83, 5,612 K, and (0.324, 0.358), respectively. All the results indicate that Sr9MgLi(PO4)7:Eu2+ could be potential in the development of UV-pumped white-light LEDs."
journal_title,Science China Materials
article_title,Enhanced photoelectrochemical and photocatalytic activities of CdS nanowires by surface modification with MoS2 nanosheetsMoS2纳米片/CdS纳米线复合光催化剂的制备及其光电化学和光催化活性研究
keyword,"[None, 'surface modification\xa0', 'photoelectrochemical activity\xa0', 'photocatalytic hydrogen evolution\xa0', 'glucose and lactic acid\xa0']"
history,"['2018-01-19', '2017-11-02', '2017-11-28']"
abstract,"Abstract Nanocomposites composed of one-dimensional (1D) CdS nanowires (NWs) and 1T-MoS2 nanosheets have been fabricated through a two-step solvothermal process. 5 mol% of MoS2 loading results in the best optical properties, photoelectrochemical (PEC) as well as photocatalytic activities for hydrogen evolution reaction (HER). Compared with pure CdS NWs, the optimized nanocomposite shows 5.5 times enhancement in photocurrent and 86.3 times increase for HER in the presence of glucose and lactic acid as hole scavengers. The enhanced PEC and HER activities are attributed to the intimate contact between MoS2 and CdS that efficiently enhances charge carrier separation. In addition, ultrafast transient absorption (TA) measurements have been used to probe the charge carrier dynamics and gain deeper insight into the mechanism behind the enhanced PEC and photocatalytic performance."
journal_title,Science China Materials
article_title,A simple green approach to synthesis of sub-100 nm carbon spheres as template for TiO2 hollow nanospheres with enhanced photocatalytic activities直径小于100 nm空心二氧化钛纳米球的简单绿色可控合成及其光催化产氢性能研究
keyword,"['carbon nanospheres\xa0', 'hydrothermal carbonization\xa0', 'hollow titanium dioxide nanospheres\xa0', 'photocatalytic hydrogen production\xa0']"
history,"['2018-01-17', '2017-11-07', '2017-12-15']"
abstract,"Abstract Carbon spheres (CSs) have attracted great attention given their wide applications in bio-diagnostics, photonic band-gap crystals and drug delivery, etc. The morphology and size of CSs greatly affect their performances and applications. Herein, we report a green and catalyst-free hydrothermal carbonization (HTC) method to synthesize CSs with glucose as carbon precursor. The diameter of CSs can be tuned within a wide range from 450 to 40 nm by controlling the glucose concentration, reaction time and temperature. Using the obtained CSs as template, hollow TiO2 nanospheres (HTNSs) with controllable diameters are prepared via a sol-gel method. As photocatalysts for hydrogen generation, the photoactivity of the HTNSs shows strong dependence upon size, and is much higher than that of solid TiO2. With particle size decreasing, the photoactivity of the obtained HTNSs gradually increases. Without any co-catalyst, the highest photocatalytic hydrogen generation activity is obtained with HTNSs of 40 nm in diameter, which exceeds that of solid TiO2 and commercial P25 by 64 times and 3 times, respectively."
journal_title,Science China Materials
article_title,Fabrication of tunable hierarchical MXene@AuNPs nanocomposites constructed by self-reduction reactions with enhanced catalytic performances自还原反应制备可调层状MXene@AuNPs复合材料以提高催化性能
keyword,"['MXene\xa0', 'self-reduction\xa0', 'gold nanoparticle\xa0', 'nitro-compound\xa0', 'nanocomposites\xa0']"
history,"['2018-01-17', '2017-11-21', '2017-12-25']"
abstract,"Abstract MXene, a new type of two-dimensional layered transition metal carbide material differing from graphene, demonstrates intriguing chemical/physical properties and wide applications in recent years. Here, the preparation of the self-assembled MXene-gold nanoparticles (MXene@AuNPs) nanocomposites with tunable sizes is reported. The nanocomposites are obtained via the self-reduction reactions of MXene material in a HAuCl4 solution at room temperature. The sizes of the Au particles can be well-controlled by regulating the self-reduction reaction time. They can greatly influence the catalytic behaviors of the MXene@AuNPs composites. MXene@AuNPs composites with optimized reduction time show high catalytic performances and good cycle stability for model catalytic reactions of nitro-compounds, such as 2-nitrophenol and 4-nitrophenol. This work demonstrates a new approach for the preparation of tunable MXene-based self-assembled composites."
journal_title,Science China Materials
article_title,Surprising separation selectivity of ethylene from ethane over pure siliceous zeolites with framework flexibility
keyword,[]
history,"['2018-01-16', '2017-12-23', '2017-12-25']"
abstract,None
journal_title,Science China Materials
article_title,Rational design of sustainable polyurethanes from castor oil: towards simultaneous reinforcement and toughening可持续蓖麻油基聚氨酯的设计合成: 同时实现增强与增韧
keyword,"['sustainable polyurethane\xa0', 'castor oil\xa0', 'isosorbide\xa0', 'crosslink density\xa0', 'mechanical property\xa0']"
history,"['2018-01-16', '2017-11-14', '2017-12-21']"
abstract,"Abstract Sustainable polyurethanes prepared from castor oil and diisocyanates show very low strength and toughness, due to the highly cross-linked and flexible structure. Herein, we report a new strategy to simultaneously reinforce and toughen castor oil-based polyurethane via incorporating a stiff component (isosorbide, IS) to enhance network stiffness and reduce crosslink density. The crosslinking degree decreases while the strength, moduli, ductility and heat resistance significantly increase accordingly with increasing IS content. The tensile behaviors are tunable over a broad range (either as elastomers or as plastics) depending on the compositions. The polyurethanes show excellent thermal stability with onset decomposition temperature higher than 280°C. The investigation provides a new hint for future design and fabrication of high performance sustainable polymers from other vegetable oils."
journal_title,Science China Materials
article_title,One-step synthesis of the PdPt bimetallic nanodendrites with controllable composition for methanol oxidation reaction具有枝状形貌的PdPt双金属纳米颗粒的甲醇氧化活性增强研究
keyword,"['one-pot approach\xa0', 'bayberry tannin\xa0', 'dendritic nanoparticles\xa0', 'controllable composition\xa0', 'methanol oxidation electrocatalysis\xa0']"
history,"['2018-01-16', '2017-09-30', '2017-11-08']"
abstract,"Abstract This paper demonstrates a one-pot approach to produce highly dispersed dendritic palladium-platinum bimetallic nanoparticles (NPs) with small particle size, tunable composition and high catalytic activity. Herein, the PdPt bimetallic NPs have been obtained using bayberry tannin (BT) as both the reducing agent and surfactant. Additionally, the PdPt bimetallic NPs with different Pd/Pt atomic ratios can be prepared by just varying the amounts of the Pd and Pt precursors. Most importantly, the as-prepared Pd52Pt48 catalyst exhibits the optimal catalytic activities compared with the other compositional PdPt NPs (Pd82Pt18, Pd69Pt31, and Pd36 Pt64) and commercial Pt/C (20 wt.%) catalyst for the methanol oxidation reaction (MOR). Meanwhile, Pd52Pt48 also shows better CO tolerance, which can be attributed to the unique dendritic structure and the synergistic effect between Pd and Pt. With evident advantages of the facile preparation and enhanced catalytic performance, it holds great promise as a high-performance catalyst for electrochemical energy conversion."
journal_title,Science China Materials
article_title,Novel Cu3P/g-C3N4 p-n heterojunction photocatalysts for solar hydrogen generation新型磷化铜/氮化碳p-n异质结光催化剂的太阳能产氢性能研究
keyword,"['photocatalysis\xa0', 'copper phosphide\xa0', 'p-n junction\xa0', 'heterostructure\xa0', 'hydrogen production\xa0']"
history,"['2018-01-15', '2017-10-30', '2017-11-28']"
abstract,"Abstract Developing efficient heterostructured photocatalysts to accelerate charge separation and transfer is crucial to improving photocatalytic hydrogen generation using solar energy. Herein, we report for the first time that p-type copper phosphide (Cu3P) coupled with n-type graphitic carbon nitride (g-C3N4) forms a p-n junction to accelerate charge separation and transfer for enhanced photocatalytic activity. The optimized Cu3P/g-C3N4 p-n heterojunction photocatalyst exhibits 95 times higher activity than bare g-C3N4, with an apparent quantum efficiency of 2.6% at 420 nm. A detail analysis of the reaction mechanism by photoluminescence, surface photovoltaics and electrochemical measurements revealed that the improved photocatalytic activity can be ascribed to efficient separation of photo-induced charge carriers. This work demonstrates that p-n junction structure is a useful strategy for developing efficient heterostructured photocatalysts."
journal_title,Science China Materials
article_title,Welding molecules into polymeric chains in one fell swoop
keyword,[]
history,"['2018-01-12', '2017-12-28', '2017-12-29']"
abstract,None
journal_title,Science China Materials
article_title,Surprisingly fast cooling in graphene-based van der Waals stacks
keyword,[]
history,"['2018-01-12', '2017-12-30', '2018-01-02']"
abstract,None
journal_title,Science China Materials
article_title,WS2 nanoplates embedded in graphitic carbon nanotubes with excellent electrochemical performance for lithium and sodium storage具有高电化学性能WS2纳米片嵌石墨化纳米碳管材料(WS2@G)用于锂离子或钠离子电池储能领域研究
keyword,"['two-dimensional materials\xa0', 'lithium-ion battery\xa0', 'sodiumion battery\xa0', 'core-shell nanocables\xa0', 'binder-free\xa0']"
history,"['2018-01-12', '2017-10-23', '2017-12-18']"
abstract,"Abstract WS2 has been considered as a promising anode material due to its high lithium storage capacity as well as fascinating physical properties. However, the insufficient electrical and ionic conductivities deteriorate the rate performance of the batteries. Herein, we report a simple synthetic approach towards graphene-WS2 hybrids by rolling graphene into a hollow nanotube in which WS2 nanoplates are encapsulated. This new electrode design strategy facilitates the fabrication of integrated and binder-free lithium ion battery and sodium ion battery electrodes by combining electrospinning and chemical vapor deposition (CVD) methods. Benefiting from their confined growth and the interconnected in-situ graphitic carbon coating nanocable web, the WS2@G with nano-level WS2 dispersion not only provides an efficiently conductive and electrolyte accessible framework, but effectively alleviates the volume change during the cycling, enabling a mechanically robust binder-free electrode along with the outstanding electrochemical Li+ and Na+ storage properties."
journal_title,Science China Materials
article_title,"Carbon skeleton doped with Co, N, S and P as efficient electrocatalyst for oxygen evolution reaction掺杂钴、 氮、 硫、 磷的碳骨架作为电化学析氧反应的高效催化剂"
keyword,"['electrocatalyst\xa0', 'oxygen evolution\xa0', 'carbonitride\xa0', 'calcination\xa0', 'alkaline\xa0']"
history,"['2018-01-12', '2017-08-26', '2017-10-24']"
abstract,"Abstract A new strategy for the preparation of highly efficient catalyst used in oxygen evolution reaction (OER) in alkaline media was developed. A Co-containing carbonitride polymer network (CoCN) was selected as a structural-directing template and a hypercross-linked polymer containing S and P, which formed on CoCN skeleton in situ, was used as a cover. After calcination at 450°C for 2 h, an interconnected nanostructure was obtained and showed excellent activity and high stability for electrochemical water splitting. Trace amount of Co and other heteroatoms including N, S, P and the formed Co–N and Co–O species are essential for the impressive catalysis performance. The calcination temperature of 450°C is optimal to the catalysis performance. These results suggest that Co in addition to heteroatom-doped (S, P) carbonitride could be used as a supplement and/or an alternative to noble metal oxides for water splitting."
journal_title,Science China Materials
article_title,Catch twin nucleation in action at atomic scale
keyword,[]
history,"['2018-01-11', '2018-01-06', '2018-01-07']"
abstract,None
journal_title,Science China Materials
article_title,Ir-Pd nanoalloys with enhanced surface-microstructure-sensitive catalytic activity for oxygen evolution reaction in acidic and alkaline media在酸碱性介质中具有增强的表面微观结构敏感性的氧析出催化活性的铱-钯纳米合金研究
keyword,"['Ir-Pd alloy nanocatalysts\xa0', 'shape control\xa0', 'oxygen evolution reaction\xa0', 'defective sites\xa0', 'surface effects\xa0']"
history,"['2018-01-10', '2017-11-29', '2017-12-19']"
abstract,"Abstract Ir-based electrocatalysts have been systematically studied for a variety of applications, among which the electrocatalysis for oxygen evolution reaction (OER) is one of the most prominent. The investigation on surface-microstructure- sensitive catalytic activity in different pH media is of great significance for developing efficient electrocatalysts and corresponding mechanism research. Herein, shape-tunable Ir-Pd alloy nanocrystals, including nano-hollow-spheres (NHSs), nanowires (NWs), and nanotetrahedrons (NTs), are synthesized via a facile one-pot solvothermal method. Electrochemical studies show that the OER activity of the Ir-Pd alloy nanocatalysts exhibits surface-microstructure-sensitive enhancement in acidic and alkaline media. Ir-Pd NWs and NTs show more than five times higher mass activity than commercial Ir/C catalyst at an overpotential of 0.25 V in acidic and alkaline media. Post-XPS analyses reveal that surface Ir(VI) oxide generated at surface defective sites of Ir-Pd nanocatalysts is a possible key intermediate for OER. In acidic medium, the specific activity of Ir-Pd nanocatalysts has a positive correlation with the surface roughness of NWs > NHSs > NTs. However, the strong dissociation of surface Ir(VI) species (IrO4 2-) at surface defective sites is a possible obstacle for the formation of Ir(VI) oxide, which reverses the activity sequence for OER in alkaline medium."
journal_title,Science China Materials
article_title,A europium(III) metal-organic framework as ratiometric turn-on luminescent sensor for Al3+ ions基于含铕金属-有机框架的比率turn-on型铝离子发光传感器
keyword,[]
history,"['2018-01-10', '2017-10-23', '2017-12-19']"
abstract,"摘要文制备了三种同构镧系金属有机框架材料(Me2NH2)[Ln2L2(NO3)-OH)(H2O)]·2H2O·2DMA, (Ln = Eu(1), Gd(2) and Tb(3), H2L =9-甲基-9-羟基-2,7-芴二羧酸, DMA = 二甲基乙酰胺). 研究结果显示它们具有三维阴离子型框架结构, 该结构可简化为含有单一的8连接型节点的体心立方(bcu)型拓扑结构. 化合物1表现出基于配体的荧光发射峰以及铕离子的特征荧光发射峰. 荧光实验表明在DMF溶液中Al3+会明显增强配体的荧光强度, 而对Eu3+的荧光强度影响却很小, 这使得1成为了优秀的比率式发光Al3+传感器. 在Al3+浓度处于0.02-0.1 mmol L—1范围内时, 配体与Eu3+荧光强度的比值与Al3+浓度成正比(斜率为18,502 mol—1 L). 本文证实了配体9位的羟基与Al3+之间的相互作用是引起配体荧光增强的主要原因."
journal_title,Science China Materials
article_title,A breakthrough in direct conversion of methane to oxygenates under mild conditions
keyword,[]
history,"['2018-01-10', '2017-12-27', '2017-12-28']"
abstract,None
journal_title,Science China Materials
article_title,In vitro and in vivo cytocompatibility evaluation of biodegradable magnesium-based stents: a review生物可降解镁基支架细胞相容性的体内外评价: 综述
keyword,"['magnesium\xa0', 'stent\xa0', 'cytocompatibility\xa0', None, None]"
history,"['2018-01-10', '2017-11-01', '2017-12-22']"
abstract,"Abstract Biodegradable magnesium (Mg)-based vascular stents have been designed as temporary scaffolds to treat angiostenotic lesions for the maintenance of normal blood flow. Numerous studies have presented in vitro and in vivo tests for the evaluation of the safety and feasibility of Mg-based vascular stents and the related materials. Therein the cytocompatibility is a basic and important parameter in the evaluation system. In this review, we summarize the applications and limitations of in vitro evaluation methods including basic characterization methods and direct and indirect cytotoxicity tests. We discuss the influencing factors on cytotoxicity, such as surface roughness, preconditioning of sample surface, cell type for the biocompatibility evaluation in direct contact as well as conditions for the formation of extracts/degradation products for indirect assays. Besides, we highlight the recent in vivo animal tests and clinical trials about Mgbased stents along with some associated results. The aim of this review is to provide a meaningful reference in the further developments and related evaluation methods of Mg-based stents."
journal_title,Science China Materials
article_title,Graphene-templated synthesis of sandwich-like porous carbon nanosheets for efficient oxygen reduction reaction in both alkaline and acidic media石墨烯模板法制备类似三明治结构的多孔碳纳米片用于高效催化酸/碱性条件下氧还原反应的研究
keyword,"['oxygen reduction reaction\xa0', 'porous carbon\xa0', 'nanosheets\xa0', 'fuel cells\xa0', 'zinc-air batteries\xa0']"
history,"['2018-01-08', '2017-11-20', '2017-12-20']"
abstract,"Abstract Developing low-cost, high-performance electrocatalysts for the oxygen reduction reaction (ORR) is crucial for implementation of fuel cells and metal-air batteries into practical applications. Graphene-based catalysts have been extensively investigated for ORR in alkaline electrolytes. However, their performance in acidic electrolytes still requires further improvement compared to the Pt/C catalyst. Here we report a self-templating approach to prepare graphene-based sandwich-like porous carbon nanosheets for efficient ORR in both alkaline and acidic electrolytes. Graphene oxides were first used to adsorb m-phenylenediamine molecules which can form a nitrogen-rich polymer network after oxidative polymerization. Then iron (Fe) salt was introduced into the polymer network and transformed into ORR active Fe–N–C sites along with Fe, FeS, and FeN0.05 nanoparticles after pyrolysis, generating ORR active sandwich-like carbon nanosheets. Due to the presence of multiple ORR active sites. The as-obtained catalyst exhibited prominent ORR activity with a half-wave potential ∼30 mV more positive than Pt/C in 0.1 mol L−1 KOH, while the half-wave potential of the catalyst was only ∼40 mV lower than that of commercial Pt/C in 0.1 mol L−1 HClO4. The unique planar sandwich-like structure could expose abundant active sites for ORR. Meanwhile, the graphene layer and porous structure could simultaneously enhance electrical conductivity and facilitate mass transport. The prominent electrocatalytic activity and durability in both alkaline and acidic electrolytes indicate that these carbon nanosheets hold great potential as alternatives to precious metal-based catalysts, as demonstrated in zinc-air batteries and proton exchange membrane fuel cells."
journal_title,Science China Materials
article_title,"Three-year anniversary of Science China Materials—Thank you to our authors, reviewers, and readers!"
keyword,[]
history,"['2018-01', '2018-01-22']"
abstract,None
journal_title,Science China Materials
article_title,Cryo-electron microscopy finds place in materials science
keyword,[]
history,"['2018-01', '2017-11-29', '2017-11-09', '2017-11-10']"
abstract,None
journal_title,Science China Materials
article_title,Rise of correlated dislocations in nanotwinned metals against fatigue
keyword,[]
history,"['2018-01', '2017-12-14', '2017-11-21', '2017-11-23']"
abstract,None
journal_title,Science China Materials
article_title,Constructing robust all-inorganic contacts enable stable perovskite solar cells with efficiencies over 20%
keyword,[]
history,"['2018-01', '2017-12-20', '2017-11-17', '2017-11-21']"
abstract,None
journal_title,Science China Materials
article_title,Sequential deposition method fabricating carbonbased fully-inorganic perovskite solar cells连续沉积法制备碳电极无机钙钛矿太阳电池
keyword,"['perovskite solar cell\xa0', 'phase transition\xa0', 'carbon cathode\xa0']"
history,"['2018-01', '2017-10-27', '2017-07-07', '2017-09-12']"
abstract,"Abstract Hybrid organic-inorganic halide perovskite material has been considered as a potential candidate for various optoelectronic applications. However, their high sensitivity to the environment hampers the actual application. Hence the technology replacing the organic part of the hybrid solar cells needs to be developed. Herein, we fabricated fullyinorganic carbon-based perovskite CsPbBr3 solar cells via a sequential deposition method with a power conversion efficiency of 2.53% and long-time stability over 20 d under ambient air conditions without any encapsulation. An evolution process from tetragonal CsPb2Br5 to CsPb2Br5-CsPbBr3 composites to quasi-cubic CsPbBr3 was found, which was investigated by scanning electron microscopy, X-ray diffraction spectra, UV-vis absorption spectra and Fourier transform infrared spectroscopy. Detailed evolution process was studied to learn more information about the formation process before 10 min. Our results are helpful to the development of inorganic perovskite solar cells and the CsPb2Br5 based optoelectronic devices."
journal_title,Science China Materials
article_title,Composite structural modeling and tensile mechanical behavior of graphene reinforced metal matrix composites石墨烯增强金属基复合材料的结构建模与拉伸模拟
keyword,"['graphene/Al composites\xa0', 'structural modeling\xa0', 'mechanical properties\xa0', 'composite configuration\xa0', 'failure behavior\xa0']"
history,"['2018-01', '2017-11-28', '2017-07-27', '2017-10-15']"
abstract,"Abstract Owing to its distinguished mechanical stiffness and strength, graphene has become an ideal reinforcing material in kinds of composite materials. In this work, the graphene (reduced graphene oxide) reinforced aluminum (Al) matrix composites were fabricated by flaky powder metallurgy. Tensile tests of pure Al matrix and graphene/Al composites with bioinspired layered structures are conducted. By means of an independently developed Python-based structural modeling program, three-dimensional microscopic structural models of graphene/Al composites can be established, in which the size, shape, orientation, location and content of graphene can be reconstructed in line with the actual graphene/Al composite structures. Elastoplastic mechanical properties, damaged materials behaviors, graphene-Al interfacial behaviors and reasonable boundary conditions are introduced and applied to perform the simulations. Based on the experimental and numerical tensile behaviors of graphene/ Al composites, the effects of graphene morphology, graphene-Al interface, composite configuration and failure behavior within the tensile mechanical deformations of graphene/ Al composites can be revealed and indicated, respectively. From the analysis above, a good understanding can be brought to light for the deformation mechanism of graphene/Al composites."
journal_title,Science China Materials
article_title,Science and technology in high-entropy alloys高熵合金材料研究进展
keyword,"['high-entropy alloys\xa0', 'multiple principal components\xa0', 'microstructures and properties\xa0', 'phase formation\xa0', 'modeling and simulation calculations\xa0']"
history,"['2018-01', '2018-01-02', '2017-11-20', '2017-12-22']"
abstract,"Abstract As human improve their ability to fabricate materials, alloys have evolved from simple to complex compositions, accordingly improving functions and performances, promoting the advancements of human civilization. In recent years, high-entropy alloys (HEAs) have attracted tremendous attention in various fields. With multiple principal components, they inherently possess unique microstructures and many impressive properties, such as high strength and hardness, excellent corrosion resistance, thermal stability, fatigue, fracture, and irradiation resistance, in terms of which they overwhelm the traditional alloys. All these properties have endowed HEAs with many promising potential applications. An in-depth understanding of the essence of HEAs is important to further developing numerous HEAs with better properties and performance in the future. In this paper, we review the recent development of HEAs, and summarize their preparation methods, composition design, phase formation and microstructures, various properties, and modeling and simulation calculations. In addition, the future trends and prospects of HEAs are put forward."
journal_title,Science China Materials
article_title,Nanocomposite LiFePO4·Li3V2(PO4)3/C synthesized by freeze-drying assisted sol-gel method and its magnetic and electrochemical properties冷冻干燥辅助溶胶-凝胶法制备纳米复合材料LiFePO4·Li3V2(PO4)3/C及其磁学和电化学性能的研究
keyword,"['lithium ion battery\xa0', 'cathode material\xa0', 'lithium iron phosphate\xa0', 'lithium vanadium phosphate\xa0', 'magnetic property\xa0']"
history,"['2018-01', '2017-10-27', '2017-07-11', '2017-09-11']"
abstract,"Abstract Nano-sized LiFePO4·Li3V2(PO4)3/C was synthesized via a sol-gel route combining with freeze-drying. X-ray diffraction results show that this composite mainly consists of olivine LiFePO4 and monoclinic Li3V2(PO4)3 phases with small amounts of V-doped LiFePO4 and Fe-doped Li3V2(PO4)3. The magnetic properties of LiFePO4·Li3V2(PO4)3/C are significantly different from LiFePO4/C. Trace quantities of ferromagnetic impurities and Fe2P are verified in LiFePO4/C and LiFePO4·Li3V2(PO4)3/C by magnetic tests, respectively. LiFe-PO4·Li3V2(PO4)3/C possesses relatively better rate capacities and cyclic stabilities, especially at high charge-discharge rates. The initial discharge capacities are 136.4 and 130.0 mA h g−1, and the capacity retentions are more than 98% after 100 cycles at 2 C and 5 C, respectively, remarkably better than those of LiFePO4/C. The excellent electrochemical performances are ascribed to the mutual doping of V3+ and Fe2+, complementary advantages of LiFePO4 and Li3V2(PO4)3 phases, the residual high-ordered carbon and Fe2P with outstanding electric conductivity in the nanocomposite."
journal_title,Science China Materials
article_title,Topological quantum catalyst: Dirac nodal line states and a potential electrocatalyst of hydrogen evolution in the TiSi family拓扑量子催化: TiSi家族的拓扑节线态和潜在催化析氢性能
keyword,"['topological Dirac nodal line\xa0', 'semimetals\xa0', 'hydrogen evolution\xa0', 'catalyst\xa0']"
history,"['2018-01', '2017-12-22', '2017-12-08', '2017-12-11']"
abstract,"Abstract Topological nodal line (DNL) semimetals, a closed loop of the inverted bands in its bulk phases, result in the almost flat drumhead-like non-trivial surface states (DNSSs) with an unusually high electronic density near the Fermi level. High catalytic active sites generally associated with high electronic densities around the Fermi level, high carrier mobility and a close-to-zero free energy of the adsorbed state of hydrogen (ΔG H*≈0) are prerequisite to design alternative of precious platinum for catalyzing electrochemical hydrogen production from water. By combining these two aspects, it is natural to consider if the DNLs are a good candidate for the hydrogen evolution reaction (HER) or not because its DNSSs provide a robust platform to activate chemical reactions. Here, through first-principles calculations we reported a new DNL TiSi-type family, exhibiting a closed Dirac nodal line due to the linear band crossings in k  y =0 plane. The hydrogen adsorbed state on the surface yields ΔG H* to be almost zero and the topological charge carries participate in HER. The results highlight a new routine to design topological quantum catalyst utilizing the topological DNL-induced surface bands as active sites, rather than edge sites-, vacancy-, dopant-, strain-, or heterostructure-created active sites."
journal_title,Science China Materials
article_title,Electron transport layer driven to improve the open-circuit voltage of CH3NH3PbI3 planar perovskite solar cells电子传输层改善平面CH3NH3PbI3钙钛矿太阳电池开路电压
keyword,"['planar perovskite solar cells\xa0', 'electron transport layer\xa0', 'hydroxide\xa0', 'suppressed decomposition process\xa0', 'enhanced crystallization and morphology\xa0']"
history,"['2018-01', '2017-11-28', '2017-07-19', '2017-09-18']"
abstract,"Abstract Suitable electron transport layers are essential for high performance planar perovskite heterojunction solar cells. Here, we use ZnO electron transport layer sputtered under oxygen-rich atmosphere at room temperature to decrease the hydroxide and then suppress decomposition of perovskite films. The perovskite films with improved crystallinity and morphology are achieved. Besides, on the ZnO substrate fabricated at oxygen-rich atmosphere, open-circuit voltage of the CH3NH3PbI3-based perovskite solar cells increased by 0.13 V. A high open-circuit voltage of 1.16 V provides a good prospect for the perovskite-based tandem solar cells. The ZnO sputtered at room temperature can be easily fabricated industrially on a large scale, therefore, compatible to flexible and tandem devices. Those properties make the sputtered ZnO films promising as electron transport materials for perovskite solar cells."
journal_title,Science China Materials
article_title,Atypical BiOCl/Bi2S3 hetero-structures exhibiting remarkable photo-catalyst response具有显著光催化响应的非典型BiOCl/Bi2S3异质结构
keyword,"['bismuth sulfide\xa0', 'hetero-structures\xa0', 'photo-catalyst response\xa0']"
history,"['2018-01', '2017-11-27', '2017-06-21', '2017-10-03']"
abstract,"Abstract We demonstrate the fabrication of BiOCl/Bi2S3 which is well defined at a large scale. The BiOCl/Bi2S3 hetero-structures exhibit an enhanced photo-catalytic degradation of methyl orange (MO) compared to BiOCl and Bi2S3, attributed to the interface between Bi2S3 and BiOCl, which effectively separate the photo-induced electron-hole pairs and suppress their recombination."
journal_title,Science China Materials
article_title,Electrospun MoO2@NC nanofibers with excellent Li+/Na+ storage for dual applications具有双重优异储锂/钠性能的电纺MoO2@C纳米纤维
keyword,"['electrospinning\xa0', None, 'nanofibers\xa0', 'Li-ion batteries\xa0', 'Na-ion batteries\xa0']"
history,"['2018-01', '2017-10-26', '2017-07-27', '2017-09-12']"
abstract,"Abstract MoO2@N-doped C nanofibers (MoO2@NC NFs) were synthesized by electrospinning with polyacrylonitrile as carbon source. The in situ formed MoO2 nanocrystals are completely embedded in the carbon nanofibers, which can not only accelerate ion transition, but also act as a buffer to avoid the mechanical degradation of active material due to the volume changes during charge/discharge cycling. When used as the anode material for both Li/Na-ion batteries, the as-synthesized MoO2@NC NFs displayed excellent Li+/Na+ storage properties. As the anode for Li-ion battery, the MoO2@NC NFs display a high discharge capacity of 930 mA h g−1 at a current density of 200 mA g−1 for 100 cycles, and 720 mA h g−1 at a current density of 1 A g−1 for 600 cycles. Moreover, the discharge capacity of 350 mA h g−1 could be realized at a current density of 100 mA g−1 for 200 cycles for Na-ion battery."
journal_title,Science China Materials
article_title,Urchin-like FeOOH hollow microspheres decorated with MnO2 for enhanced supercapacitor performance超薄MnO2层修饰的海胆状空心FeOOH微米球及其在提高电容性能中的应用
keyword,"['FeOOH\xa0', None, 'hollow structures\xa0', 'supercapacitor\xa0']"
history,"['2018-01', '2017-10-13', '2017-06-14', '2017-09-15']"
abstract,"Abstract Ultrathin MnO2 decorated hierarchical urchin-like FeOOH hollow micro-nanospheres have been designed and synthesized through a facile hydrothermal route. The microspheres are made of FeOOH nanofibers with a diameter of 10 nm. Due to the synergetic effect between the unique FeOOH hollow micro/nanostructures and ultrathin MnO2 layer, the as-fabricated FeOOH@MnO2 hybrid electrode exhibits a high specific capacitance of 1192 F g−1 at a current density of 1 A g−1. It also reveals high rate capabilities and superior stability. Moreover, the asymmetric supercapacitor (ASC) assembled from the FeOOH@MnO2 and the active carbon (AC) delivers a high energy density of 40.2 W h kg−1 at a power density of 0.78 kW kg−1, and the energy density could remain 10.4 W h kg−1 under a condition of high power density of 11.7 kW kg−1."
journal_title,Science China Materials
article_title,Enhanced photochemical performance of hexagonal WO3 by metal-assisted S–O coupling for solar-driven water splitting金属受体辅助S–O耦合作用改善六方相三氧化钨光解水性能的研究
keyword,"[None, 'hybrid density functional calculation\xa0', 'electronic structure\xa0', 'solar-driven water splitting\xa0']"
history,"['2018-01', '2017-11-16', '2017-07-03', '2017-09-20']"
abstract,"Abstract Hybrid density functional calculations was used to comprehensively study the electronic structure of S-, Snand Pb-monodoped and (Sn, S)- and (Pb, S)-codoped hexagonal WO3 (h-WO3) in order to improve their visible light photocatalytic activity. Results  indicate that the (Sn, S)- and (Pb, S)-codoped h-WO3 can realize a significant band gap reduction and prevent the formation of empty states in the valence band of h-WO3, while Sn/Pb-monodoped h-WO3 cannot, because in (Sn, S)- and (Pb, S)-codoping, the S-doping introduces the fully occupied S 3p states in the forbidden band gap of h-WO3 and the acceptor metals (Sn and Pb) would assist the coupling of the introduced S with its nearest O. In particular, the (Sn, S)-codoped h-WO3 has the narrowest band gap of 1.85 eV and highest reducing ability among the doped case. Moreover, the calculated optical absorption spectra show that (Sn, S)-codoping can improve the visible light absorption. In short, these results indicate that the (Sn, S)-codoped h-WO3 is a promising material in solar-driven water splitting."
journal_title,Science China Materials
article_title,Cobalt-vanadium bimetal-based nanoplates for efficient overall water splittingCo-V双金属基纳米片用于有效电催化全解水
keyword,"['water splitting\xa0', 'electrocatalysis\xa0', None, 'Co/VN\xa0']"
history,"['2018-01', '2017-11-07', '2017-08-15', '2017-09-07']"
abstract,"Abstract The development of effective and low-cost catalysts for overall water splitting is essential for clean production of hydrogen from water. In this paper, we report the synthesis of cobalt-vanadium (Co-V) bimetal-based catalysts for the effective water splitting. The Co2V2O7·xH2O nanoplates containing both Co and V elements were selected as the precursors. After the calcination under NH3 atmosphere, the Co2VO4 and Co/VN could be obtained just by tuning the calcination temperature. Electrochemical tests indicated that the Co-V bimetal-based materials could be used as active hydrogen evolution reaction (HER) and oxygen evolution reaction (OER) catalyst by regulating their structure. The Co/VN showed good performance for HER with the onset potential of 68 mV and can achieve a current density of 10 mA cm−2 at an overpotential of 92 mV. Meanwhile, the Co2VO4 exhibited the obvious OER performance with overpotential of 300 mV to achieve a current density of 10 mA cm−2. When the Co2VO4 and Co/VN were used as the anode and cathode in a two-electrode system, respectively, the cell needed a voltage of 1.65 V to achieve 10 mA cm−2 together with good stability. This work would be indicative to constructing Co-V bimetalbased catalysts for the catalytic application."
journal_title,Science China Materials
article_title,Nanostructuring the electronic conducting La0.8Sr0.2MnO3−δ cathode for high-performance in proton-conducting solid oxide fuel cells below 600°C通过电子导体阴极La0.8Sr0.2MnO3−δ的纳米化制备高性能质子导体固体氧化物燃料电池
keyword,"[None, 'inkjet printing\xa0', 'impregnation\xa0', None, 'solid oxide fuel cells\xa0']"
history,"['2018-01', '2017-10-26', '2017-07-05', '2017-09-18']"
abstract,"Abstract Proton-conducting oxides offer a promising electrolyte solution for intermediate temperature solid oxide fuel cells (SOFCs) due to their high conductivity and low activation energy. However, the lower operation temperature leads to a reduced cathode activity and thus a poorer fuel cell performance. La0.8Sr0.2MnO3−δ  (LSM) is the classical cathode material for high-temperature SOFCs, which lack features as a proper SOFC cathode material at intermediate temperatures. Despite this, we here successfully couple nanostructured LSM cathode with proton-conducting electrolytes to operate below 600°C with desirable SOFC performance. Inkjet printing allows depositing nanostructured particles of LSM on Y-doped BaZrO3 (BZY) backbones as cathodes for proton-conducting SOFCs, which provides one of the highest power output for the BZY-based fuel cells below 600°C. This somehow changes the common knowledge that LSM can be applied as a SOFC cathode materials only at high temperatures (above 700°C)."
journal_title,Science China Materials
article_title,"N, P-dual doped carbon with trace Co and rich edge sites as highly efficient electrocatalyst for oxygen reduction reaction具有痕量钴掺杂且暴露更多边缘活性的N,P共掺杂的多孔碳纳米片作为高效氧还原催化剂"
keyword,"['electrocatalysts\xa0', 'oxygen reduction reaction\xa0', 'dualdoping\xa0', 'Co–N–C\xa0', 'edge exposed\xa0']"
history,"['2017-12-29', '2017-10-23', '2017-11-30']"
abstract,"Abstract Oxygen reduction reaction (ORR) is key to fuel cells and metal-air batteries which are considered as the alternative clean energy. Various carbon materials have been widely researched as ORR electrocatalysts. It has been accepted that heteroatom doping and exposure of the edge sites can effectively improve the activity of carbon materials. In this work, we used a simple method to prepare a novel N, P-dual doped carbon-based catalyst with many holes on the surface. In addition, trace level Co doping in the carbon material forming Co–N–C active species can further enhance the ORR performance. On one hand, the doping can adjust the electronic structure of carbon atoms, which would induce more active sites for ORR. And on the other hand, the holes formed on the surface of carbon nanosheets would expose more edge sites and can improve the intrinsic activity of carbon. Due to the heteroatom doping and the exposed edge sites, the prepared carbon materials showed highly excellent ORR performance, close to that of commercial Pt/C."
journal_title,Science China Materials
article_title,New designing for nanostructured 2D materials and 2D superlattices
keyword,[]
history,"['2017-12-27', '2017-12-18', '2017-12-19']"
abstract,None
journal_title,Science China Materials
article_title,Building towards a standardised approach to biocorrosion studies: a review of factors influencing Mg corrosion in vitro pertinent to in vivo corrosion建立一个生物腐蚀研究的标准化方法:与体内腐蚀相关的体外镁腐蚀影响因素综述
keyword,"['corrosion\xa0', 'biocorrosion\xa0', 'magnesium\xa0', 'biodegradable metals\xa0', None, None]"
history,"['2017-12-27', '2017-10-05', '2017-11-30']"
abstract,"Abstract The factors that influence magnesium (Mg) corrosion in vitro are systematically evaluated from a review of the relevant literature. We analysed the influence of the following factors on Mg biocorrosion in vitro: (i) inorganic ions, including both anions and cations, (ii) organic components such as proteins, amino acids and vitamins, and (iii) experimental parameters such as temperature, pH, buffer system and flow rate. Considerations and recommendations towards a standardised approach to in vitro biocorrosion testing are given. Several potential simulated body fluids are recommended. Implementing a standardised approach to experimental parameters has the potential to significantly reduce variability between in vitro biocorrosion tests, and to help build towards a methodology that accurately and consistently mimics in vivo corrosion. However, there are also knowledge gaps with regard to how best to characterise the in vivo environment and corrosion mechanism. The assumption that blood plasma is the correct bodily fluid upon which to base in vitro methodologies is examined, and factors that influence the corrosion mechanism in vivo, such as specimen encapsulation, bear consideration for further studies."
journal_title,Science China Materials
article_title,Rh single atom catalyst for direct conversion of methane to oxygenates
keyword,[]
history,"['2017-12-22', '2017-12-18', '2017-12-19']"
abstract,None
journal_title,Science China Materials
article_title,Tackling the hurdles of electrically pumped colloidal quantum dot lasers
keyword,[]
history,"['2017-12-22', '2017-12-12', '2017-12-14']"
abstract,None
journal_title,Science China Materials
article_title,Domain-wall nanoelectronics in ferroelectric memory
keyword,[]
history,"['2017-12-22', '2017-12-18', '2017-12-19']"
abstract,None
journal_title,Science China Materials
article_title,Cell thickness dependence of electrically tunable infrared reflectors based on polymer stabilized cholesteric liquid crystals厚度依赖的聚合物稳定胆甾相液晶的电控红外反射器件
keyword,"['cholesteric\xa0', 'cell gap\xa0', 'polymer network\xa0', 'electric regulating\xa0', 'infrared reflector\xa0']"
history,"['2017-12-22', '2017-10-12', '2017-11-17']"
abstract,"Abstract We reported here the fabrication of the electrically tunable infrared (IR) reflectors based on the polymer stabilized cholesteric liquid crystal (PSCLC) with negative dielectric anisotropy. A systematic study of the influence of cell gap on the electrically tunable reflection bandwidth was performed. When a direct current (DC) electric field was applied, the reflection bandwidth red shifted in the cells with small cell gap, whereas the bandwidth broadening was observed in the cells with large cell gap. It is therefore reasonable to deduct that the reflection is dictated by the pitch gradient steepness which strongly relies on the cell thickness. The results reveal that for making PSCLC based IR reflector windows with electrically induced bandwidth broadening, a minimal cell gap thickness is required. The resulted IR reflectors possess a short native switching time and long-term operation stability, and are potentially applicable as smart energy saving windows in buildings and automobiles."
journal_title,Science China Materials
article_title,Performance improvement of organic phototransistors by using polystyrene microspheres使用聚苯乙烯微球提高有机光敏晶体管性能
keyword,"['phototransistor\xa0', 'organic semiconductor\xa0', 'polystyrene microsphere\xa0', 'nanostructure\xa0']"
history,"['2017-12-20', '2017-10-18', '2017-11-21']"
abstract,"Abstract Organic phototransistors (OPTs) have been intensively studied in recent years due to the combined advantages of phototransistors and organic semiconductors (OSCs). However, the electrical performance of OPTs is largely limited by OSCs themselves, posing a challenge to further improve the performance of the devices. Preparing nano/micro-structures of OSCs is considered as an effective way to improve the performance of OPTs. Polystyrene (PS) microsphere, as a kind of insulating and low-cost material, is extensively used in fabricating nano/microporous structures, and the resulting devices exhibit high response to external stimuli. Therefore, we combined PS microspheres with OSCs to fabricate PS/OSC OPTs, and the I light/I dark ratio was enhanced by two orders of magnitude compared with the pristine counterparts, which can be modulated from 46 to 1800 by controlling the diameters of PS microspheres. This strategy paves a way for developing high-performance OPTs with nano/microporous structures with potential applications in organic optoelectronics."
journal_title,Science China Materials
article_title,Construct Fe2+ species and Au particles for significantly enhanced photoelectrochemical performance of α-Fe2O3 by ion implantation使用离子注入产生金颗粒和Fe2+显著增强α-Fe2O3光电化学性能
keyword,"['hematite\xa0', None, 'photoelectrochemical water splitting\xa0', 'ion implantation\xa0']"
history,"['2017-12-20', '2017-08-27', '2017-11-05']"
abstract,"Abstract Photoelectrochemical (PEC) water splitting is a promising approach to producing H2 and O2. Hematite (α-Fe2O3) is considered one of the most promising photoelectrodes for PEC water splitting, due to its good photochemical stability, non-toxicity, abundance in earth, and suitable bandgap (E g∼2.1 eV). However, the PEC water splitting efficiency of hematite is severely hampered by its short hole diffusion length (2–4 nm), poor conductivity, and ultrafast recombination of photogenerated carriers (about 10 ps). Here, we show a novel and effective method for significantly improving the PEC water splitting performance of hematite by Au ion implantation and the following high-temperature annealing process. Based on a series of characterizations and analyses, we have found Fe2+ species and tightly attached Au particles were produced at Au-implanted hematite. As a result, the charge separation and charge injection efficiency of Auimplanted Fe2O3 are markedly increased. The photocurrent density of optimized Au-implanted Fe2O3 could reach 1.16 mA cm−2 at 1.5 V vs. RHE which was nearly 300 times higher than that of the pristine Fe2O3 (4 μA cm−2). Furthermore, the Au-implanted Fe2O3 photoelectrode exhibited great stability for the 8-hour PEC water splitting test without photocurrent decay."
journal_title,Science China Materials
article_title,Weak fatigue notch sensitivity in a biomedical titanium alloy exhibiting nonlinear elasticity非线弹性医用钛合金的抗疲劳缺口损伤行为研究
keyword,"['fatigue\xa0', 'fracture\xa0', 'notch sensitivity\xa0', 'biomedical metal\xa0', 'titanium alloy\xa0']"
history,"['2017-12-20', '2017-09-20', '2017-11-09']"
abstract,"Abstract It is well known that metallic materials exhibit worse fatigue damage tolerance as they behave stronger in strength and softer in modulus. This raises concern on the long term safety of the recently developed biomechanical compatible titanium alloys with high strength and low modulus. Here we demonstrate via a model alloy, Ti-24Nb-4Zr-8Sn in weight percent, that this group of multifunctional titanium alloys possessing nonlinear elastic deformation behavior is tolerant in fatigue notch damage. The results reveal that the alloy has a high strength-to-modulus (σ/E) ratio reaching 2% but its fatigue notch sensitivity (q) is low, which decreases linearly from 0.45 to 0.25 as stress concentration factor increases from 2 to 4. This exceeds significantly the typical relationship between σ/E and q of other metallic materials exhibiting linear elasticity. Furthermore, fatigue damage is characterized by an extremely deflected mountain-shape fracture surface, resulting in much longer and more tortuous crack growth path as compared to these linear elastic materials. The above phenomena can be explained by the nonlinear elasticity and its induced stress relief at the notch root in an adaptive manner of higher stress stronger relief. This finding provides a new strategy to balance high strength and good damage tolerance property of metallic materials."
journal_title,Science China Materials
article_title,An Ostwald ripening route towards Ni-rich layered cathode material with cobalt-rich surface for lithium ion battery奥斯特瓦尔德熟化法制备具有富钴表层的锂离子电池高镍正极材料
keyword,"['nickel-rich layered cathode\xa0', 'cobalt-rich surface\xa0', None, 'ostwald ripening\xa0', 'lithium ion batteries\xa0']"
history,"['2017-12-18', '2017-10-10', '2017-11-17']"
abstract,"Abstract An Ostwald ripening-based route is proposed to prepare Ni-rich layered cathodes with Co-rich surface for lithium-ion batteries (LIBs). Commercially available Ni0.8Co0.1 Mn0.1(OH)2 and spray pyrolysis derived porous Co3O4 are used as mixed precursors. During the lithiation reaction process under high-temperature, the porous Co3O4 microspheres scatter primary particles and spontaneously redeposit on the surface of Ni-rich spheres according to Ostwald ripening mechanism, forming the Ni-rich materials with Co-rich outer layers. When evaluated as cathode for LIBs, the resultant material shows ability to inhibit the cation disorder, relieves the phase transition from H2 to H3 and diminishes side reactions between the electrolyte and Ni-rich cathode material. As a result, the obtained material with Co-rich outer layers exhibits much more improved cycle and rate performance than the material without Co-rich outer layers. Particularly, NCM-Co-1 (molar ratio of Ni0.8Co0.1Mn0.1(OH)2/Co3O4 is 60:1) delivers a reversible capacity of 159.2 mA h g−1 with 90.5% capacity retention after 200 cycles at 1 C. This strategy provides a general and efficient way to produce gradient substances and to address the surface problems of Ni-rich cathode materials."
journal_title,Science China Materials
article_title,Constructing CdS/Cd/doped TiO2 Z-scheme type visible light photocatalyst for H2 production构建高效可见光区分解水制氢的Z型CdS/Cd/掺杂TiO2光催化体系
keyword,"['Z-scheme\xa0', 'CdS\xa0', None, 'Cd\xa0', None]"
history,"['2017-12-15', '2017-10-18', '2017-11-27']"
abstract,"Abstract Constructing Z-scheme type photocatalyst is an efficient way to improve the charge separation efficiency and enhance the photocatalytic activity. In this report, the Cd:TiO2 nanoparticles are prepared via the sol-gel route and employed as a starting material. When it was reduced by NaBH4 at 300°C, the surface oxygen vacancies were produced and Cd2+ was reduced into metal Cd0 nanoparticle (denoted as R-Cd:TiO2). Subsequently, the formed R-Cd:TiO2 was treated with thioureain the hydrothermal reaction. Through the decomposition of thiourea, the oxygen vacancies were refilled by S2− from thiourea to form S:TiO2/TiO2 (d-TiO2) and Cd was partially converted into CdS to form CdS/Cd/d-TiO2 composite. The formed CdS/Cd/d-TiO2 composite exhibits improved photocatalytic activity. Under visible light irradiation (λ>400 nm), the H2 production rate of CdS/Cd/d-TiO2 reaches 119 μmol h−1 with 50 mg of photocatalyst without any cocatalyst, which is about 200 and 60 times higher than that of S:TiO2/TiO2 (0.57 μmol h−1), CdS (2.03 μmol h−1) and heterojunction CdS/d-TiO2 (2.17 μmol h-1) materials, respectively. The results illustrate that metal Cd greatly promotes the charge separation efficiency due to the formation of Z-scheme type composite. In addition, the photocatalytic activity in the visible light region was dramatically enhanced due to the contribution of both CdS and d-TiO2. The method could be easily extended to other wide bandgap semiconductors for constructing visible light responsive Z-scheme type photocatalysts."
journal_title,Science China Materials
article_title,Advancements in three-dimensional titanium alloy mesh scaffolds fabricated by electron beam melting for biomedical devices: mechanical and biological aspects电子束增材制造医用钛合金三维多孔支架力学及生物功能研究进展
keyword,"['Electron beam melting\xa0', '3D printing\xa0', 'tissue engineering\xa0', 'mechanical properties\xa0', 'biocompatibility\xa0']"
history,"['2017-12-14', '2017-08-15', '2017-09-29']"
abstract,"Abstract We elucidate here the process-structure-property relationships in three-dimensional (3D) implantable titanium alloy biomaterials processed by electron beam melting (EBM) that is based on the principle of additive manufacturing. The conventional methods for processing of biomedical devices including freeze casting and sintering are limited because of the difficulties in adaptation at the host site and difference in the micro/macrostructure, mechanical, and physical properties with the host tissue. In this regard, EBM has a unique advantage of processing patient-specific complex designs, which can be either obtained from the computed tomography (CT) scan of the defect site or through a computer-aided design (CAD) program. This review introduces and summarizes the evolution and underlying reasons that have motivated 3D printing of scaffolds for tissue regeneration. The overview comprises of two parts for obtaining ultimate functionalities. The first part focuses on obtaining the ultimate functionalities in terms of mechanical properties of 3D titanium alloy scaffolds fabricated by EBM with different characteristics based on design, unit cell, processing parameters, scan speed, porosity, and heat treatment. The second part focuses on the advancement of enhancing biological responses of these 3D scaffolds and the influence of surface modification on cell-material interactions. The overview concludes with a discussion on the clinical trials of these 3D porous scaffolds illustrating their potential in meeting the current needs of the biomedical industry."
journal_title,Science China Materials
article_title,Versatile MOF-derived cobalt catalyst for the reductive amination
keyword,[]
history,"['2017-12', '2017-11-28', '2017-10-12', '2017-10-12']"
abstract,None
journal_title,Science China Materials
article_title,Crystalline-phase-dependent catalytic performance of MnO2 for aerobic oxidation reactionsMnO2晶相对耗氧反应的催化性能的影晌
keyword,"['crystalline phase\xa0', None, 'aerobic oxidation\xa0']"
history,"['2017-12', '2017-11-16', '2017-08-10', '2017-11-08']"
abstract,"Abstract Knowledge of the catalytic performances of different crystalline phases of a material is vital for the development of superior catalysts. In this study, different phases of MnO2 (α, β, γ, and δ) have been prepared by the oxidation of Mn2+, and their catalytic performances were evaluated using the aerobic oxidation of benzyl alcohol to benzaldehyde as a model reaction. α-MnO2 promoted the reaction to the highest yield. However, when the yields were normalized by the corresponding surface areas, δ-MnO2 exhibited the highest specific activity and α-MnO2 the lowest, indicating that the diverse microstructures resulting from the crystalline phase have a profound effect on catalytic performance. α-MnO2 showed the highest catalytic stability, resulting from its unchanged composition and morphology after use. Informed by the experimental results, a possible reaction mechanism involving the Mars-van Krevelen process was proposed. This work provides useful information for the development of effective catalysts for aerobic oxidation."
journal_title,Science China Materials
article_title,Facile synthesis and excellent electrochemical performance of CoP nanowire on carbon cloth as bifunctional electrode for hydrogen evolution reaction and supercapacitor碳布上快速合成CoP纳米线阵列用于析氢和超级电容器
keyword,"['cobalt phosphide nanowire\xa0', 'hydrogen evolution reaction\xa0', 'supercapacitor\xa0']"
history,"['2017-12', '2017-10-26', '2017-06-30', '2017-09-05']"
abstract,"Abstract In this paper, we report CoP nanowires supported on carbon cloth (CC) (CoP/CC) as a bifunctional electrode for hydrogen evolution reaction (HER) and supercapacitor. CoP/CC possess an excellent electrocatalytic performance for HER, with a Tafel slope of 56 mV/dec and a low overpotential of 68 mV to achieve a current density of 10 mA cm-2. Remarkably, the bifunctional CoP/CC used as electrode for supercapacitor exhibit a higher specific capacitance of 674 F g-1 at a scan rate of 5 mV s-1 and maintains long-life cycling stability, retaining 86% of the initial capacitance after 10,000 cycles. CoP/CC will be a promising candidate as electrode for HER and supercapacitor."
journal_title,Science China Materials
article_title,Fe modified mesoporous hollow carbon spheres for selective oxidation of ethylbenzene铁修饰的中空介孔碳球用于乙苯催化氧化
keyword,"['hollow carbon sphere\xa0', 'Fe modified\xa0', 'catalytic\xa0', 'ethylbenzene oxidation\xa0']"
history,"['2017-12', '2017-11-28', '2017-08-15', '2017-10-09']"
abstract,"Abstract Fe modified hollow carbon spheres with large cavity and mesoporous shell (Fe-MHCs) were successfully synthesized by a simple pyrolysis and simultaneous deposition method. The organic molecules gases (carbon species) from pyrolysis of polystyrene deposited in the hard template at the catalysis of Fe species existing in the sample during calcination at high temperature. The obtained Fe-MHCs showed uniform spherical morphology with large surface area (924 m2 g−1), mesoporous structure and a certain amount of Fe loaded. The Fe species and the special structure endowed the materials excellent catalytic activity in the oxidation of ethylbenzene to acetophenone. The conversion of 94.5% and the high selectivity to targeted product (97.4%) could be achieved and the acceptable recycling stability was also exhibited."
journal_title,Science China Materials
article_title,Diffusion-controlled synthesis of Cu-based for the Rochow reaction扩散控制合成Cu基催化剂及其Rochow反应性能研究
keyword,"['cuprous oxide\xa0', 'hollow spheres\xa0', 'porous spheres\xa0', 'surface oxygen vacancies\xa0', 'Rochow reaction\xa0']"
history,"['2017-12', '2017-11-07', '2017-08-16', '2017-09-20']"
abstract,"Abstract The properties of materials are strongly dependent on their structures. The diffusion effect is a main kinetic factor that can be used to regulate the growth and structure of materials. In this work, we developed a systematic and feasible strategy to synthesize Cu2O solid spheres and hexahedrons by controlling the diffusion coefficients. These Cu2O products can be successively transformed into corresponding Cu hollow spheres and hexahedrons as well as CuO porous spheres and hexahedrons by controlling hydrogen diffusion in hydrazine hydrate solution and controlling oxygen diffusion in air, respectively. The formation of these transformations was also discussed in detail. Tested for Rochow reaction, the as-prepared Cu2O solid and CuO porous spheres exhibit higher dimethyldichlorosilane selectivity and Si conversion than Cu hollow spheres, which is attributed to the active sites for CH3Cl adsorption formed in Cu x Si phase after the removal of oxygen atoms in Cu2O and CuO in the formation of dimethylchlorosilane. The present work not only develops a feasible method for preparing well shape-defined Cu2O solid spheres and hexahedrons but also clarifies the respective roles of Cu, Cu2O and CuO in dimethyldichlorosilane synthesis via Rochow reaction."
journal_title,Science China Materials
article_title,Facile one-pot fabrication of α-Fe2O3 nano-coffee beans by etching along [001] direction for high lithium storage[001]晶向定向刻蚀介导α-Fe2O3纳米咖啡豆的一步合成及其高储锂性能研究
keyword,"['hematite\xa0', 'etching\xa0', 'hydrothermal\xa0', 'lithium storage\xa0', 'designed nanostructures\xa0']"
history,"['2017-12', '2017-11-27', '2017-08-05', '2017-09-03']"
abstract,"Abstract It is a great challenge to finely tune the morphology of iron oxides for energy storage. In this work, we introduced a facile hydrothermal method to obtain single crystalline hematite (α-Fe2O3) nano-coffee beans (NCBs) with the assistance of acetic acid. Interestingly, α-Fe2O3 nanostructures with this special morphology were formed under the effect of Ostwald ripening and oriented etching of H+ ions along [001] direction, which could be proved by the scanning electron microscope /transmission electron microscope and X-ray diffraction. After calcination at high temperature, the as-prepared α-Fe2O3 NCBs were used as potential anode materials, showing a very high reversible capacity of 810 mA h g−1 (0.2 C), excellent cycling stability, and high-rate performance for lithium storage. Hence, in virtue of the good performances, the structural design of nanomaterials would be promoted in the fabrication of electrode materials for lithiumion batteries."
journal_title,Science China Materials
article_title,White-light upconversion emission of lanthanide double-doped oxide nanoparticles via defect state luminescence of ZnO实现基于缺陷能级稀土双掺氧化锌上转换发光
keyword,"['white upconversion luminescence\xa0', 'pencil-shaped ZnO:Yb/Tm nanorods\xa0', 'defect states luminescence\xa0']"
history,"['2017-12', '2017-11-27', '2017-08-02', '2017-09-05']"
abstract,"Abstract The white upconversion luminescence (UCL) of upconversion nanoparticles (UCNPs) is mainly made up of the color red, green and blue. Interestingly, the white-light-emitting UCNPs can be obtained via a complex method of tridoping lanthanide ions such as Yb3+, Er3+, and Tm3+. We herein report that an excellent white UCL can be obtained from Yb/Tm double-doped ZnO. In this system, the blue and red UCL-emissions around 475 and 652 nm originate from 1G4→3H6 and 1G4→3F4 transition of Tm3+, respectively, and the green one can be attributed to the defect states (oxygen vacancies) luminescence (DSL) of the ZnO host. Meanwhile, the fine nanostructure of ZnO:Yb/Tm is prepared by adjusting the concentration of OH−. Particularly, the one dimentional pencil-shaped nanorods with high aspect ratio achieve a strong green DSL emission due to the high concentration of oxygen vacancy. The oxygen vacancy defects play an irreplaceable role in affecting the intensities of blue and red UCL by acting as the intermediate state in the energy transfer process. More importantly, we demonstrate that the DSL and UCL can be combined into systems, paving a new road for obtaining the white UCL emission."
journal_title,International Journal of Thermophysics
article_title,Thermodynamic Properties of Low-Density $${}^{132}\hbox {Xe}$$132Xe Gas in the Temperature Range 165–275 K
keyword,"['Mean-field operator\xa0', 'Static fluctuation approximation\xa0', 'Thermodynamic properties\xa0', 'Xenon gas\xa0']"
history,"['2018-01', '2018-11-24', '2017-02-08', '2017-11-13']"
abstract,"Abstract The method of static fluctuation approximation was used to calculate selected thermodynamic properties (internal energy, entropy, energy capacity, and pressure) for xenon in a particularly low-temperature range (165–270 K) under different conditions. This integrated microscopic study started from an initial basic assumption as the main input. The basic assumption in this method was to replace the local field operator with its mean value, then numerically solve a closed set of nonlinear equations using an iterative method, considering the Hartree–Fock B2-type dispersion potential as the most appropriate potential for xenon. The results are in very good agreement with those of an ideal gas."
journal_title,International Journal of Thermophysics
article_title,Viscosity of Industrially Important Zn–Al Alloys Part II: Alloys with Higher Contents of Al and Si
keyword,"['High-temperature alloys\xa0', 'Oscillating cup viscometer\xa0', 'Phase transitions\xa0', 'Viscosity\xa0', 'Zn–Al alloys\xa0']"
history,"['2018-05', '2018-04-12', '2016-11-11', '2018-04-02']"
abstract,"Abstract 
The viscosity of Zn–Al alloys melts, with industrial interest, was measured for temperatures between 693 K and 915 K, with an oscillating cup viscometer, and estimated expanded uncertainties between 3 and 5 %, depending on the alloy. The influence of minor components, such as Si, Mg and Ce + La, on the viscosity of the alloys is discussed. An increase in the amount of Mg triggers complex melt/solidification processes while the addition of Ce and La renders alloys viscosity almost temperature independent. Furthermore, increases in Al and Si contents decrease melts viscosity and lead to an Arrhenius type behavior. This paper complements a previous study describing the viscosity of Zn–Al alloys with quasi-eutectic compositions."
journal_title,International Journal of Thermophysics
article_title,Thermal Emittance of $$\hbox {La}_{0.7}\hbox {Ca}_{0.3-x}\hbox {K}_x\hbox {MnO}_3$$La0.7Ca0.3-xKxMnO3 Coatings on Aluminum Substrate
keyword,"['K-doped manganite\xa0', 'Thermochromic coating\xa0', 'Variable emittance\xa0']"
history,"['2018-05', '2018-04-07', '2017-01-26', '2018-03-22']"
abstract,"Abstract A novel thermal control coating was presented based on the thermochromism of manganite. The pigment of K-doped manganite nanoparticles was dispersed into polymer matrix to prepare the coating with curing below 200 \(^{\circ }\)C. The nanoparticles size mainly distributes around 100–200 nm, and it shows a comparable stoichiometric ratio. The phase transition of the nanoparticles was observed from ferromagnetic metallic to paramagnetic insulator state. With increasing K doping level, the phase transition temperature increases, achieving controllable adjustment. Coating surface with and without pore defect was obtained by different polymer matrix. A sharp emittance variation was observed with increasing temperature in K-doped coating. The variation magnitude of emittance is up to 0.46, which is attractive to space thermal control. It is suggested that the pigment content of 50 wt% is sufficient to realize a large emittance variation."
journal_title,International Journal of Thermophysics
article_title,Experiences in Calibrating Industrial Platinum Resistance Sensors Between − 196 °C and 80 °C
keyword,"['Calibration\xa0', 'Cycling\xa0', 'Interpolation curves\xa0', 'Platinum resistance thermometers\xa0', 'Pt100\xa0']"
history,"['2018-05', '2018-04-06', '2016-10-24', '2018-03-22']"
abstract,"Abstract Recently, a requirement arose to provide sensors for measuring the temperature of a substantial reference blackbody cavity to operate in vacuum over a temperature range from − 100 °C to 80 °C (~ 170 K to ~ 350 K), with an additional capability to operate at ~− 170 °C (~ 100 K) as a point of near-zero radiance. Several 100 Ω industrial platinum resistance sensors (Pt100) are required for control purposes in order to establish the temperature uniformity of the blackbody structure and its surrounding aluminum-alloy isothermal shield. These sensors should remain stable within the uncertainties of 0.03 °C (k = 3) ideally for 20 years. This paper discusses the testing and calibration of two types of industrial Pt100 resistors, including checking the interchangeability of sensors from a given batch, and the methods of interpolation over the temperature range. It is concluded that the sensors can meet the requirements provided that they have been individually tested, and that there is a degree of duplication of sensors so that long-term changes can be detected. The calibration data could be fitted by cubic or quartic equations expressing temperature as a function of resistance (or resistance ratio), this being simpler than the ITS-90 formulation and more convenient than using the (technically obsolete) Callendar–Van Dusen equation."
journal_title,International Journal of Thermophysics
article_title,Effects of Sample Handling and Transportation on the Moisture Content of Biomass Samples
keyword,"['Biomass\xa0', 'Moisture content\xa0', 'Sample handling\xa0', 'Transportation\xa0']"
history,"['2018-05', '2018-04-06', '2016-06-15', '2018-03-20']"
abstract,"Abstract Using biomass in energy production has a significant role in the progress toward carbon neutrality in Finland. In the biomass combustion process, moisture content is an important factor. To enhance efforts for well-quantified uncertainty estimations in reference moisture measurements for biomass, errors related to handling and transporting samples were studied in this work. At the Centre for metrology of VTT Technical Research Centre of Finland, experiments and simulations were carried out on effects of water mass gain and loss when forest biomass samples are transported to a laboratory and prepared for moisture analysis. Results  suggest that opening the sample bag may change bulk moisture content considerably and homogenization of the sample with varying moisture contents inside sample bags typically takes weeks. Results  with varying thermal conditions show that the moisture content changes in the tested samples were insignificant. Monitoring the masses of samples and sample containers separately is recommended when aiming at high accuracy in the analysis of hygroscopic samples."
journal_title,International Journal of Thermophysics
article_title,Correction to: Thermodynamic Properties of Low-Density $${}^{{132}}\mathrm{Xe}$$132Xe Gas in the Temperature Range 165–275 K
keyword,[]
history,"['2018-05', '2018-03-27']"
abstract,None
journal_title,International Journal of Thermophysics
article_title,Heat and Moisture Transport and Storage Parameters of Bricks Affected by the Environment
keyword,"['Bricks\xa0', 'Hygric properties\xa0', 'Hygrothermal performance\xa0', 'Thermal properties\xa0', 'Weathering\xa0']"
history,"['2018-05', '2018-03-27', '2017-09-19', '2018-03-20']"
abstract,"Abstract The effect of external environment on heat and moisture transport and storage properties of the traditional fired clay brick, sand–lime brick and highly perforated ceramic block commonly used in the Czech Republic and on their hygrothermal performance in building envelopes is analyzed by a combination of experimental and computational techniques. The experimental measurements of thermal, hygric and basic physical parameters are carried out in the reference state and after a 3-year exposure of the bricks to real climatic conditions of the city of Prague. The obtained results showed that after 3 years of weathering the porosity of the analyzed bricks increased up to five percentage points which led to an increase in liquid and gaseous moisture transport parameters and a decrease in thermal conductivity. Computational modeling of hygrothermal performance of building envelopes made of the studied bricks was done using both reference and weather-affected data. The simulated results indicated an improvement in the annual energy balances and a decrease in the time-of-wetness functions as a result of the use of data obtained after the 3-year exposure to the environment. The effects of weathering on both heat and moisture transport and storage parameters of the analyzed bricks and on their hygrothermal performance were found significant despite the occurrence of warm winters in the time period of 2012–2015 when the brick specimens were exposed to the environment."
journal_title,International Journal of Thermophysics
article_title,A New Primary Dew-Point Generator at TUBITAK UME
keyword,"['Dew-point generator\xa0', 'Humidity standard\xa0', 'Saturator\xa0']"
history,"['2018-05', '2018-03-26', '2016-08-31', '2018-03-12']"
abstract,"Abstract An implementation of a new low-range primary humidity generator as a part of an international collaboration between TUBITAK UME and VTT MIKES was initiated as a EURAMET Project Number 1259. The dew-point generator was designed and constructed within the scope of the cooperation between TUBITAK UME and VTT MIKES in order to extend the dew-point temperature measurement capability of Humidity Laboratory of TUBITAK UME down to − 80 °C. The system was thoroughly characterized and validated at TUBITAK UME to support the evidence for dew-point temperature uncertainties. The new generator has a capability of operating in the range of − 80 °C to +10 °C, but at the moment, it was characterized down to − 60 °C. The core of the generator system is a saturator which is fully immersed in a liquid bath. Dry air is supplied to the saturator through a temperature-controlled pre-saturator. The operation of the system is based on the single-pressure generation method with a single pass, i.e., the dew-point temperature is only controlled by the saturator temperature, and the humidity-controlled air is not returned to the system after leaving of the saturator. The metrological performance of the saturator was investigated thoroughly at both National Metrology Institutes. The pre-saturator was also tested using a thermostatic bath at VTT MIKES prior to sending them to TUBITAK UME. This paper describes the principle and design of the generator in detail. The dew-point measurement system and the corresponding uncertainty analysis of the dew-point temperature scale realized with the generator in the range from − 60 °C to 10 °C is also presented."
journal_title,International Journal of Thermophysics
article_title,Effect of Impurities on the Triple Point of Water: Experiments with Doped Cells at Different Liquid Fractions
keyword,"['Frozen fraction\xa0', 'Impurities\xa0', 'Liquid fraction\xa0', 'Raoult’s law\xa0', 'Water triple point cells\xa0']"
history,"['2018-05', '2018-03-24', '2016-11-07', '2018-03-19']"
abstract,"Abstract Recent international comparisons showed that there is still room for improvement in triple point of water (TPW) realization uncertainty. Large groups of cells manufactured, maintained and measured in similar conditions still show a spread in the realized TPW temperature that is larger than the best measurement uncertainties (25 µK). One cause is the time-dependent concentration of dissolved impurities in water. The origin of such impurities is the glass/quartz envelope dissolution during a cell lifetime. The effect is a difference in the triple point temperature proportional to the impurities concentration. In order to measure this temperature difference and to investigate the effect of different types of impurities, we manufactured doped cells with different concentrations of silicon (Si), boron (B), sodium (Na) and potassium (K), the glass main chemical components. To identify any influence of the filling process, two completely independent manufacturing procedures were followed in two different laboratories, both national metrology institutes (VSL, Netherlands and UME, Turkey). Cells glass and filling water were also different while the doping materials were identical. Measuring the temperature difference as a function of the liquid fraction is a method to obtain information about impurities concentrations in TPW. Only cells doped with 1 µmol·mol−1 B, Na and K proved to be suitable for measurements at different liquid fractions. We present here the results with related uncertainties and discuss the critical points in this experimental approach."
journal_title,International Journal of Thermophysics
article_title,Frequency Domain Analysis of Multiwavelength Photoacoustic Signals for Differentiating Tissue Components
keyword,"['Frequency domain analysis\xa0', 'Multiwavelength photoacoustic imaging\xa0', 'Photoacoustic acoustic spectrum\xa0', 'Tissue characterization\xa0']"
history,"['2018-05', '2018-03-24', '2017-06-19', '2018-03-19']"
abstract,"Abstract The feasibility of differentiating tissue components by performing frequency domain analysis of photoacoustic images acquired at different wavelengths was studied in this paper. Firstly, according to the basic theory of photoacoustic imaging, a brief theoretical model for frequency domain analysis of multiwavelength photoacoustic signal was deduced. The experiment results proved that the performance of different targets in frequency domain is quite different. Especially, the acoustic spectrum characteristic peaks of different targets are unique, which are 2.93 MHz, 5.37 MHz, 6.83 MHz, and 8.78 MHz for PDMS phantom, while 13.20 MHz, 16.60 MHz, 26.86 MHz, and 29.30 MHz for pork fat. The results indicated that the acoustic spectrum of photoacoustic imaging signals is possible to be utilized for tissue composition characterization."
journal_title,International Journal of Thermophysics
article_title,"Measurement and Analysis of the Temperature Gradient of Blackbody Cavities, for Use in Radiation Thermometry"
keyword,"['Blackbody\xa0', 'Cylinder-conical cavity\xa0', 'Effective emissivity\xa0', 'Monte Carlo method\xa0', 'Radiation thermometer\xa0', 'Radiation thermometry\xa0', 'Temperature gradient\xa0', 'Uncertainty\xa0']"
history,"['2018-05', '2018-03-24', '2017-12-30', '2018-03-20']"
abstract,"Abstract 
Blackbody cavities are the standard radiation sources widely used in the fields of radiometry and radiation thermometry. Its effective emissivity and uncertainty depend to a large extent on the temperature gradient. An experimental procedure based on the radiometric method for measuring the gradient is followed. Results  are applied to particular blackbody configurations where gradients can be thermometrically estimated by contact thermometers and where the relationship between both basic methods can be established. The proposed procedure may be applied to commercial blackbodies if they are modified allowing secondary contact temperature measurement. In addition, the established systematic may be incorporated as part of the actions for quality assurance in routine calibrations of radiation thermometers, by using the secondary contact temperature measurement for detecting departures from the real radiometrically obtained gradient and the effect on the uncertainty. On the other hand, a theoretical model is proposed to evaluate the effect of temperature variations on effective emissivity and associated uncertainty. This model is based on a gradient sample chosen following plausible criteria. The model is consistent with the Monte Carlo method for calculating the uncertainty of effective emissivity and complements others published in the literature where uncertainty is calculated taking into account only geometrical variables and intrinsic emissivity. The mathematical model and experimental procedure are applied and validated using a commercial type three-zone furnace, with a blackbody cavity modified to enable a secondary contact temperature measurement, in the range between 400 °C and 1000 °C.
"
journal_title,International Journal of Thermophysics
article_title,Evaluation of Different Techniques of Active Thermography for Quantification of Artificial Defects in Fiber-Reinforced Composites Using Thermal and Phase Contrast Data Analysis
keyword,"['Active thermography\xa0', 'CFRP\xa0', 'Delaminations\xa0', 'Flash excitation\xa0', 'Flat bottom holes\xa0', 'GFRP\xa0', 'Lock-in excitation\xa0', '10.105\xa0', '10.200\xa0']"
history,"['2018-05', '2018-03-24', '2017-10-18', '2018-03-12']"
abstract,"Abstract For assuring the safety and reliability of components and constructions in energy applications made of fiber-reinforced polymers (e.g., blades of wind turbines and tidal power plants, engine chassis, flexible oil and gas pipelines) innovative non-destructive testing methods are required. Within the European project VITCEA complementary methods (shearography, microwave, ultrasonics and thermography) have been further developed and validated. Together with partners from the industry, test specimens have been constructed and selected on-site containing different artificial and natural defect artefacts. As base materials, carbon and glass fibers in different orientations and layering embedded in different matrix materials (epoxy, polyamide) have been considered. In this contribution, the validation of flash and lock-in thermography to these testing problems is presented. Data analysis is based on thermal contrasts and phase evaluation techniques. Experimental data are compared to analytical and numerical models. Among others, the influence of two different types of artificial defects (flat bottom holes and delaminations) with varying diameters and depths and of two different materials (CFRP and GFRP) with unidirectional and quasi-isotropic fiber alignment is discussed."
journal_title,International Journal of Thermophysics
article_title,T– P Phase Diagram of Nitrogen at High Pressures
keyword,"['First-order transition\xa0', 'Mean field model\xa0', 'Nitrogen\xa0', None]"
history,"['2018-05', '2018-03-24', '2017-03-13', '2018-03-12']"
abstract,"Abstract By employing a mean field model, calculation of the T–P phase diagram of molecular nitrogen is performed at high pressures up to 200 GPa. Experimental data from the literature are used to fit a quadratic function in T and P, describing the phase line equations which have been derived using the mean field model studied here for N2, and the fitted parameters are determined. Our model study gives that the observed T–P phase diagram can be described satisfactorily for the first-order transitions between the phases at low as well as high pressures in nitrogen. Some thermodynamic quantities can also be predicted as functions of temperature and pressure from the mean field model studied here and they can be compared with the experimental data."
journal_title,International Journal of Thermophysics
article_title,Evaluation of Photopolymerization Kinetics by Means of Transmittance Measurements
keyword,"['Curing time\xa0', 'Kinetic\xa0', 'Light transmittance\xa0', 'Photodiode\xa0', 'Polymerization\xa0', 'Resin\xa0']"
history,"['2018-04', '2018-03-22', '2017-05-11', '2018-03-19']"
abstract,"Abstract Polymeric resins are widely used for dental reconstruction, and most resins use camphorquinone as activator of the polymerization reaction, through the absorption of light at a defined wavelength range (from 400 nm to 460 nm). During the photopolymerization curing, transparency of these resins changes and transmittance variation can be detected by photodiode and bolometer measurements. This change can be used as an index of the reaction rate, and the kinetic parameter k (reaction rate) can be evaluated from transmittance data by means of nonlinear regression. The relation between k and the light intensity impinging on the resin sample can thus be obtained. In the present work, tests were carried out using the resin Enamel Plus HFO GE2. Results  reveal the presence of two different polymerization reactions at two different intensity ranges. The obtained k values were used to predict the most suited curing times for different light intensities. The proposed methodology can be applied to different dental reconstruction materials, provided that the material is partially transparent and that its transparency changes during the polymerization reaction."
journal_title,International Journal of Thermophysics
article_title,Characterization of the Mechanical Stress–Strain Performance of Aerospace Alloy Materials Using Frequency-Domain Photoacoustic Ultrasound and Photothermal Methods: An FEM Approach
keyword,"['Finite element method\xa0', 'Nondestructive testing\xa0', 'Photothermal\xa0', 'Photoacoustic ultrasound\xa0', 'Stress–strain\xa0']"
history,"['2018-04', '2018-03-19', '2017-10-30', '2018-03-12']"
abstract,"Abstract 
Determining and keeping track of a material’s mechanical performance is very important for safety in the aerospace industry. The mechanical strength of alloy materials is precisely quantified in terms of its stress–strain relation. It has been proven that frequency-domain photothermoacoustic (FD-PTA) techniques are effective methods for characterizing the stress–strain relation of metallic alloys. PTA methodologies include photothermal (PT) diffusion and laser thermoelastic photoacoustic ultrasound (PAUS) generation which must be separately discussed because the relevant frequency ranges and signal detection principles are widely different. In this paper, a detailed theoretical analysis of the connection between thermoelastic parameters and stress/strain tensor is presented with respect to FD-PTA nondestructive testing. Based on the theoretical model, a finite element method (FEM) was further implemented to simulate the PT and PAUS signals at very different frequency ranges as an important analysis tool of experimental data. The change in the stress–strain relation has an impact on both thermal and elastic properties, verified by FEM and results/signals from both PT and PAUS experiments."
journal_title,International Journal of Thermophysics
article_title,Viscosity Prediction for Petroleum Fluids Using Free Volume Theory and PC-SAFT
keyword,"['Differential liberation\xa0', 'Free volume theory\xa0', None, 'Reservoir fluid\xa0', 'Viscosity\xa0']"
history,"['2018-04', '2018-03-19', '2017-09-10', '2018-03-12']"
abstract,"Abstract In this study, free volume theory (FVT) in combination with perturbed-chain statistical associating fluid theory is implemented for viscosity prediction of petroleum reservoir fluids containing ill-defined components such as cuts and plus fractions. FVT has three adjustable parameters for each component to calculate viscosity. These three parameters for petroleum cuts (especially plus fractions) are not available. In this work, these parameters are determined for different petroleum fractions. A model as a function of molecular weight and specific gravity is developed using 22 real reservoir fluid samples with API grades in the range of 22 to 45. Afterward, the proposed model accuracy in comparison with the accuracy of De la Porte et al. with reference to experimental data is presented. The presented model is used for six real samples in an evaluation step, and the results are compared with available experimental data and the method of De la Porte et al. Finally, the method of Lohrenz et al. and the method of Pedersen et al. as two common industrial methods for viscosity calculation are compared with the proposed approach. The absolute average deviation was 9.7 % for free volume theory method, 15.4 % for Lohrenz et al., and 22.16 for Pedersen et al."
journal_title,International Journal of Thermophysics
article_title,Measurement of the Diffusion Coefficient of Water in RP-3 and RP-5 Jet Fuels Using Digital Holography Interferometry
keyword,"['Digital holography interferometry\xa0', 'Diffusion coefficient\xa0', 'Jet fuel\xa0', 'Viscosity\xa0', 'Water\xa0']"
history,"['2018-04', '2018-03-15', '2017-07-21', '2018-03-07']"
abstract,"Abstract The diffusion coefficient of water in jet fuel was measured employing double-exposure digital holographic interferometry to clarify the diffusion process and make the aircraft fuel system safe. The experimental method and apparatus are introduced in detail, and the digital image processing program is coded in MATLAB according to the theory of the Fourier transform. At temperatures ranging from 278.15 K to 333.15 K in intervals of 5 K, the diffusion coefficient of water in RP-3 and RP-5 jet fuels ranges from 2.6967 × 10 −10 m2·s−1 to 8.7332 × 10 −10 m2·s−1 and from 2.3517 × 10 −10 m2·s−1 to 8.0099 × 10−10 m2·s−1, respectively. The relationship between the measured diffusion coefficient and temperature can be well fitted by the Arrhenius law. The diffusion coefficient of water in RP-3 jet fuel is higher than that of water in RP-5 jet fuel at the same temperature. Furthermore, the viscosities of the two jet fuels were measured and found to be expressible in the form of the Arrhenius equation. The relationship among the diffusion coefficient, viscosity and temperature is analyzed according to the classic prediction model, namely the Stokes–Einstein correlation, and this correlation is further revised via experimental data to obtain a more accurate predication result."
journal_title,International Journal of Thermophysics
article_title,Correction to: Ab Initio Calculated Results Require New Formulations for Properties in the Limit of Zero Density: The Viscosity of Methane ($$\hbox {CH}_4$$CH4)
keyword,[]
history,"['2018-04', '2018-03-13']"
abstract,None
journal_title,International Journal of Thermophysics
article_title,Research on H500-Type High-Precision Vacuum Blackbody as a Calibration Standard for Infrared Remote Sensing
keyword,"['Emissivity\xa0', 'Infrared remote sensing\xa0', 'Metrology\xa0', 'Stability\xa0', 'Uncertainty\xa0', 'Uniformity\xa0', 'Vacuum blackbody source\xa0']"
history,"['2018-04', '2018-03-12', '2016-07-13', '2018-03-03']"
abstract,"Abstract Based on the calibration requirements of vacuum low background aerospace infrared remote sensing radiance temperature, a high-precision vacuum blackbody (H500 type) is developed for the temperature range from − 93 °C to + 220 °C at the National Institute of Metrology, China. In this paper, the structure and the temperature control system of H500 are introduced, and its performance, such as heating rate and stabilization of temperature control, is tested under the vacuum and low-background condition (liquid-nitrogen-cooled shroud). At room temperature and atmospheric environment, the major technical parameters of this blackbody, such as emissivity and uniformity, are measured. The measurement principle of blackbody emissivity is based on the control of surrounding radiation. Temperature uniformity at the cavity bottom is measured using a standard infrared radiation thermometer. When the heating rate is 1 °C min−1, the time required for the temperature to stabilize is less than 50 min, and within 10 min, the variation in temperature is less than 0.01 °C. The emissivity value of the blackbody is higher than 0.996. Temperature uniformity at the bottom of the blackbody cavity is less than 0.03 °C. The uncertainty is less than 0.1 °C (k = 2) over the temperature range from − 93 °C to + 67 °C."
journal_title,International Journal of Thermophysics
article_title,Novel Calibration Technique for a Coulometric Evolved Vapor Analyzer for Measuring Water Content of Materials
keyword,"['Calibration\xa0', 'Evolved vapor analyzer\xa0', 'Measurement traceability\xa0', 'Water content\xa0']"
history,"['2018-04', '2018-03-10', '2016-10-31', '2018-02-22']"
abstract,"Abstract Evolved vapor coulometry is a measurement technique that selectively detects water and is used to measure water content of materials. The basis of the measurement is the quantitative electrolysis of evaporated water entrained in a carrier gas stream. Although this measurement has a fundamental principle—based on Faraday’s law which directly relates electrolysis current to amount of substance electrolyzed—in practice it requires calibration. Commonly, reference materials of known water content are used, but the variety of these is limited, and they are not always available for suitable values, materials, with SI traceability, or with well-characterized uncertainty. In this paper, we report development of an alternative calibration approach using as a reference the water content of humid gas of defined dew point traceable to the SI via national humidity standards. The increased information available through this new type of calibration reveals a variation of the instrument performance across its range not visible using the conventional approach. The significance of this is discussed along with details of the calibration technique, example results, and an uncertainty evaluation."
journal_title,International Journal of Thermophysics
article_title,Experimental Study on GFRP Surface Cracks Detection Using Truncated-Correlation Photothermal Coherence Tomography
keyword,"['Chirped-pulsed signal\xa0', 'GFRP\xa0', 'Photothermal coherence tomography\xa0', 'Surface cracks\xa0']"
history,"['2018-04', '2018-03-05', '2017-08-26', '2018-02-25']"
abstract,"Abstract In this paper, truncated-correlation photothermal coherence tomography (TC-PCT) was used as a nondestructive inspection technique to evaluate glass-fiber reinforced polymer (GFRP) composite surface cracks. Chirped-pulsed signal that combines linear frequency modulation and pulse excitation was proposed as an excitation signal to detect GFRP composite surface cracks. The basic principle of TC-PCT and extraction algorithm of the thermal wave signal feature was described. The comparison experiments between lock-in thermography, thermal wave radar imaging and chirped-pulsed photothermal radar for detecting GFRP artificial surface cracks were carried out. Experimental results illustrated that chirped-pulsed photothermal radar has the merits of high signal-to-noise ratio in detecting GFRP composite surface cracks. TC-PCT as a depth-resolved photothermal imaging modality was employed to enable three-dimensional visualization of GFRP composite surface cracks. The results showed that TC-PCT can effectively evaluate the cracks depth of GFRP composite.
"
journal_title,International Journal of Thermophysics
article_title,Pulse Phase Dynamic Thermal Tomography Investigation on the Defects of the Solid-Propellant Missile Engine Cladding Layer
keyword,"['Characteristic extraction algorithm\xa0', 'Dynamic thermal tomography\xa0', 'Pulse thermography\xa0', 'Thermal wave\xa0']"
history,"['2018-04', '2018-03-03', '2017-09-19', '2018-02-19']"
abstract,"Abstract Pulse phase dynamic thermal tomography (PP-DTT) was introduced as a nondestructive inspection technique to detect the defects of the solid-propellant missile engine cladding layer. One-dimensional thermal wave mathematical model stimulated by pulse signal was developed and employed to investigate the thermal wave transmission characteristics. The pulse phase algorithm was used to extract the thermal wave characteristic of thermal radiation. Depth calibration curve was obtained by fuzzy c-means algorithm. Moreover, PP-DTT, a depth-resolved photothermal imaging modality, was employed to enable three-dimensional (3D) visualization of cladding layer defects. The comparison experiment between PP-DTT and classical dynamic thermal tomography was investigated. The results showed that PP-DTT can reconstruct the 3D topography of defects in a high quality."
journal_title,International Journal of Thermophysics
article_title,Acousto-optical Transducer with Surface Plasmons
keyword,"['Acousto-optical transducer\xa0', 'Acoustic wave detection\xa0', 'Surface plasmon\xa0']"
history,"['2018-04', '2018-03-02', '2017-10-31', '2018-02-22']"
abstract,"Abstract The surface plasmon resonance (SPR) is a sensitive technique for the detection of changes in dielectric parameters in close proximity to a metal film supporting surface plasmon waves. Here we study the application of the SPR effect to an efficient conversion of an acoustic signal into an optical one. Such a transducer potentially has a large bandwidth and good sensitivity. When an acoustic wave is incident onto a receiving plate positioned within the penetration depth of the surface plasmons, it creates displacements of the surface of the plate and, thus, modulates the dielectric properties in the proximity of the gold film. This modulation, in turn, modifies the light reflection under surface plasmon resonance conditions. We simulate characteristics of this acousto-optical transducer with surface plasmons and provide sets of parameters at the optical wavelength of 800 nm and 633 nm for its realization."
journal_title,International Journal of Thermophysics
article_title,Photo-Acoustic Spectroscopy Reveals Extrinsic Optical Chirality in GaAs-Based Nanowires Partially Covered with Gold
keyword,"['Circular dichroism\xa0', 'Extrinsic chirality\xa0', 'GaAs\xa0', 'Nanowires\xa0', 'Photo-acoustic technique\xa0']"
history,"['2018-04', '2018-02-26', '2017-11-03', '2018-02-19']"
abstract,"Abstract We report on the extrinsic chirality behavior of GaAs-based NWs asymmetrically hybridized with Au. The samples are fabricated by a recently developed, lithography-free self-organized GaAs growth, with the addition of AlGaAs shell and GaAs supershell. The angled Au flux is then used to cover three-out-of-six sidewalls with a thin layer of Au. Oblique incidence and proper sample orientation can lead to circular dichroism. We characterize this chiral behavior at \( 532\,{\text{nm}} \) and \( 980\,{\text{nm}} \) by means of photo-acoustic spectroscopy, which directly measures the difference in absorption for the circularly polarized light of the opposite headedness. For the first time to our knowledge, circular dichroism is observed in both the amplitude and the phase of the photo-acoustic signal. We strongly believe that such samples can be used for chiral applications, spanning from circularly polarized light emission, to the enantioselectivity applications."
journal_title,International Journal of Thermophysics
article_title,Resonant Absorption in GaAs-Based Nanowires by Means of Photo-Acoustic Spectroscopy
keyword,"['GaAs\xa0', 'Nanowires\xa0', 'Photo-acoustic technique\xa0']"
history,"['2018-03', '2018-02-23', '2017-11-03', '2018-02-12']"
abstract,"Abstract Semiconductor nanowires made of high refractive index materials can couple the incoming light to specific waveguide modes that offer resonant absorption enhancement under the bandgap wavelength, essential for light harvesting, lasing and detection applications. Moreover, the non-trivial ellipticity of such modes can offer near field interactions with chiral molecules, governed by near chiral field. These modes are therefore very important to detect. Here, we present the photo-acoustic spectroscopy as a low-cost, reliable, sensitive and scattering-free tool to measure the spectral position and absorption efficiency of these modes. The investigated samples are hexagonal nanowires with GaAs core; the fabrication by means of lithography-free molecular beam epitaxy provides controllable and uniform dimensions that allow for the excitation of the fundamental resonant mode around 800 nm. We show that the modulation frequency increase leads to the discrimination of the resonant mode absorption from the overall absorption of the substrate. As the experimental data are in great agreement with numerical simulations, the design can be optimized and followed by photo-acoustic characterization for a specific application."
journal_title,International Journal of Thermophysics
article_title,Evaluation of Thermodynamic Models for Predicting Phase Equilibria of $$\hbox {CO}_{2}$$CO2 + Impurity Binary Mixture
keyword,"[None, None, 'Equation of state\xa0', 'Phase equilibrium\xa0']"
history,"['2018-03', '2018-02-13', '2017-05-07', '2018-01-29']"
abstract,"Abstract For the design and operation of \(\hbox {CO}_{2}\) capture and storage (CCS) processes, equation of state (EoS) models are used for phase equilibrium calculations. Reliability of an EoS model plays a crucial role, and many variations of EoS models have been reported and continue to be published. The prediction of phase equilibria for \(\hbox {CO}_{2}\) mixtures containing \(\hbox {SO}_{2}\), \(\hbox {N}_{2}\), NO, \(\hbox {H}_{2}\), \(\hbox {O}_{2}\), \(\hbox {CH}_{4}\), \(\hbox {H}_{2}\mathrm{S}\), Ar, and \(\hbox {H}_{2}\mathrm{O}\) is important for \(\hbox {CO}_{2}\) transportation because the captured gas normally contains small amounts of impurities even though it is purified in advance. For the design of pipelines in deep sea or arctic conditions, flow assurance and safety are considered priority issues, and highly reliable calculations are required. In this work, predictive Soave–Redlich–Kwong, cubic plus association, Groupe Européen de Recherches Gazières (GERG-2008), perturbed-chain statistical associating fluid theory, and non-random lattice fluids hydrogen bond EoS models were compared regarding performance in calculating phase equilibria of \(\hbox {CO}_{2}\)-impurity binary mixtures and with the collected literature data. No single EoS could cover the entire range of systems considered in this study. Weaknesses and strong points of each EoS model were analyzed, and recommendations are given as guidelines for safe design and operation of CCS processes."
journal_title,International Journal of Thermophysics
article_title,Thermal Transmittance of Porous Hollow Clay Brick by Guarded Hot Box Method
keyword,"['Guarded hot box method\xa0', 'Porous hollow clay brick\xa0', 'Pore-forming agents\xa0', 'Thermal transmittance\xa0', 'Wood flour\xa0']"
history,"['2018-03', '2018-02-08', '2017-05-24', '2017-12-22']"
abstract,"Abstract The thermal property of a porous hollow clay brick was determined by measuring the thermal transmittance of the wall made of porous hollow clay bricks. Prior to the production of porous hollow clay bricks, nonporous and porous tiny clay bricks were prepared to determine the physico-mechanical properties by modifying the amount of wood flour and firing temperature. The bricks were produced by uniaxial pressing and then fired in an electric furnace. Their physico-mechanical properties were measured by water absorption, apparent porosity, bulk density, and compressive strength. The porous tiny clay bricks were produced with three types of wood flour: coarse wood flour (1–0.36 mm), medium-sized wood flour (0.36–0.15 mm), and fine wood flour (< 0.08 mm). The thermal transmittance of porous hollow clay bricks was determined through the guarded hot box method, which measures the wall made of porous hollow clay bricks and nonporous cement bricks. The two walls had a thermal transmittance of 1.42 and 2.72 \(\hbox {W}\cdot \hbox {m}^{-2}\cdot \hbox {K}^{-1}\), respectively. The difference in thermal transmittance was due to the pores created with fine wood flour (< 0.08 mm) as a pore-forming agent."
journal_title,International Journal of Thermophysics
article_title,Effects of an Inhomogenous Electric Field on an Evaporating Thin Film in a Microchannel
keyword,"['Electric field\xa0', 'Evaporating film\xa0', 'Lattice Boltzmann method\xa0', 'Thin film\xa0']"
history,"['2018-03', '2018-02-08', '2016-12-09', '2018-01-29']"
abstract,"Abstract In this paper, heat transfer enhancement in an evaporating thin film along the wall of a microchannel under an imposed inhomogenous electrostatic field is analyzed. The mathematical model, based on the augmented Young–Laplace equation with the inhomogenous electrostatic field taken into consideration, is developed. The 2D inhomogenous electric field with the curved liquid–vapor interface is solved by the lattice Boltzmann method. Numerical solutions for the thin film characteristics are obtained for both constant wall temperature and uniform wall heat flux boundary conditions. The numerical results show that the liquid film becomes thinner and the heat transfer coefficient increases under an imposed electric field. Both of octane and water are chosen as the working mediums, and similar result about the enhancement of heat transfer on evaporating thin film by imposing electric field is obtained. It is found that applying an electric field on the evaporating thin film can enhance evaporative heat transfer in a microchannel."
journal_title,International Journal of Thermophysics
article_title,Self-Normalized Photoacoustic Technique for the Quantitative Analysis of Paper Pigments
keyword,"['Optical\xa0', 'Photoacoustic\xa0', 'Pigments\xa0', 'Self-normalized\xa0']"
history,"['2018-03', '2018-01-30', '2017-10-30', '2018-01-11']"
abstract,"Abstract A self-normalized photoacoustic technique was applied for quantitative analysis of pigments embedded in solids. Paper samples (filter paper, Whatman No. 1), attached with the pigment: Direct Fast Turquoise Blue GL, were used for this study. This pigment is a blue dye commonly used in industry to dye paper and other fabrics. The optical absorption coefficient, at a wavelength of 660 nm, was measured for this pigment at various concentrations in the paper substrate. It was shown that Beer–Lambert model for light absorption applies well for pigments in solid substrates and optical absorption coefficients as large as \(220\,\hbox {cm}^{-1}\) can be measured with this photoacoustic technique."
journal_title,International Journal of Thermophysics
article_title,Measurement of the Thermal Expansion Coefficient for Ultra-High Temperatures up to 3000 K
keyword,"['High-temperature dilatometer\xa0', 'Machine vision\xa0', 'Single-crystal aluminum oxide\xa0', 'Thermal expansion\xa0']"
history,"['2018-03', '2018-01-30', '2016-08-02', '2017-12-22']"
abstract,"Abstract The paper is devoted to a new high-temperature dilatometer, a part of the State Primary Standard of the thermal expansion coefficient (TEC) unit. The dilatometer is designed for investigation and certification of materials for TEC standards in the range of extremely high temperatures. The critical review of existing methods of TEC measurements is given. Also, the design, principles of operation and metrological parameters of the new device are described. The main attention is paid to the system of machine vision that allows accurate measurement of elongation at high temperatures. The results of TEC measurements for graphite GIP-4, single crystal \(\hbox {Al}_{2}\hbox {O}_{3}\), and some other materials are also presented."
journal_title,International Journal of Thermophysics
article_title,Simulation and Experimental Study on Thermal Conductivity of [EMIM][DEP] + $$\mathbf{H}_\mathbf{2}{} \mathbf{O}$$H2O + SWCNTs Nanofluids as a New Working Pairs
keyword,"['Ionic liquid\xa0', 'Molecular dynamics simulation\xa0', 'Nanofluids\xa0', 'The single-wall carbon nanotubes\xa0', 'Thermal conductivity\xa0']"
history,"['2018-03', '2018-01-30', '2017-03-29', '2018-01-15']"
abstract,"Abstract In this paper, the single-wall carbon nanotubes (SWCNTs) were dispersed into ionic liquid, 1-ethyl-3-methylimidazolium diethylphosphate ([EMIM][DEP]), and its aqueous solution [EMIM][DEP](1) + \(\hbox {H}_{2}\hbox {O}(2)\) to enhance the thermal conductivity of base liquids, which will be the promising working pairs for absorption heat pumps and refrigerators. The enhancement effects on thermal conductivity were studied by experiment and molecular dynamic simulation (MD) methods. The thermal conductivities of [EMIM][DEP] + SWCNTs (INF) and [EMIM][DEP](1) + \(\hbox {H}_{2}\hbox {O}(2)\) + SWCNT(SNF) both with SWCNT mass fraction of 0.5, 1, and 2 (wt%) were measured by transient hot-wire method. The results indicate that the enhancement ratio of thermal conductivity of INF, and SNF can approach 1.30 when SWCNT is 2 (wt%). Moreover, SWCNTs has a higher enhancement ratio than multi-wall carbon nanotubes (MWCNTs). Density and thermal conductivity of [EMIM][DEP], [EMIM][DEP](1) + \(\hbox {H}_{2}\hbox {O}(2)\), INF and SNF systems, together with self-diffusion coefficients of \(\hbox {[EMIM]}^{+}\), \(\hbox {[DEP]}^{-}\), [EMIM][DEP] and water in solution [EMIM][DEP](1) + \(\hbox {H}_{2}\hbox {O}(2)\), were investigated by MD simulations. The results indicate that the maximum relative error between the simulated and experimental densities is about 2 %, and the simulated self-diffusion coefficient of [EMIM][DEP] is in the order of magnitude of \(10^{-11}\,\hbox {m}^{2}\cdot \hbox {s}^{-1}\). The average relative deviation for the simulated thermal conductivity of [EMIM][DEP](1) + \(\hbox {H}_{2}\hbox {O}(2)\), INF and SNF from experimental ones are 23.57 %, 5 %, and 5 %, respectively. In addition, the contributions of kinetic energy, potential energy, and virial and partial enthalpy terms to thermal conductivity were also calculated. The results indicate that virial term’s contribution to thermal conductivity is the maximum, which accounts for 75 % to 80 % of total thermal conductivity."
journal_title,International Journal of Thermophysics
article_title,"Effect of Al$$_2$$2O$$_3$$3 Nanoparticles Additives on the Density, Saturated Vapor Pressure, Surface Tension and Viscosity of Isopropyl Alcohol"
keyword,"[None, 'Density\xa0', 'Isopropyl alcohol\xa0', 'Nanofluid\xa0', 'Stability\xa0', 'Surface tension\xa0', 'Vapor pressure\xa0', 'Viscosity\xa0']"
history,"['2018-03', '2018-01-30', '2017-08-04', '2018-01-15']"
abstract,"Abstract This paper presents results of an experimental study of the density, saturated vapor pressure, surface tension and viscosity of Al\(_2\)O\(_3\) nanoparticle colloidal solutions in isopropyl alcohol. Studies of the thermophysical properties of nanofluids were performed at various temperatures and concentrations of Al\(_2\)O\(_3\) nanoparticles. The paper gives considerable attention to a turbidimetric analysis of the stability of nanofluid samples. Samples of nanofluids remained stable over the range of parameters of the experiments, ensuring the reliability of the thermophysical property data for the Al\(_2\)O\(_3\) nanoparticle colloidal solutions in isopropyl alcohol. The studies show that the addition of Al\(_2\)O\(_3\) nanoparticles leads to an increase of the density, saturated vapor pressure and viscosity, as well as a decrease for the surface tension of isopropyl alcohol. The information reported in this paper on the various thermophysical properties for the isopropyl alcohol/Al\(_2\)O\(_3\) nanoparticle model system is useful for the development of thermodynamically consistent models for predicting properties of nanofluids and correct modeling of the heat exchange processes."
journal_title,International Journal of Thermophysics
article_title,Applicability of a 1D Analytical Model for Pulse Thermography of Laterally Heterogeneous Semitransparent Materials
keyword,"['Absorption coefficient\xa0', 'Analytical model\xa0', 'GFRP\xa0', 'Heterogeneous\xa0', 'Pulse thermography\xa0', 'Semitransparent\xa0']"
history,"['2018-03', '2018-01-30', '2017-10-30', '2018-01-15']"
abstract,"Abstract Pulse thermography (PT) has proven to be a valuable non-destructive testing method to identify and quantify defects in fiber-reinforced polymers. To perform a quantitative defect characterization, the heat diffusion within the material as well as the material parameters must be known. The heterogeneous material structure of glass fiber-reinforced polymers (GFRP) as well as the semitransparency of the material for optical excitation sources of PT is still challenging. For homogeneous semitransparent materials, 1D analytical models describing the temperature distribution are available. Here, we present an analytical approach to model PT for laterally inhomogeneous semitransparent materials. We show the validity of the model by considering different configurations of the optical heating source, the IR camera, and the differently coated GFRP sample. The model considers the lateral inhomogeneity of the semitransparency by an additional absorption coefficient. It includes additional effects such as thermal losses at the samples surfaces, multilayer systems with thermal contact resistance, and a finite duration of the heating pulse. By using a sufficient complexity of the analytical model, similar values of the material parameters were found for all six investigated configurations by numerical fitting."
journal_title,International Journal of Thermophysics
article_title,Emission of Gas and $$\hbox {Al}_{2}\hbox {O}_{3}$$Al2O3 Smoke in Gas–Al Particle Deflagration: Experiments and Emission Modeling for Explosive Fireballs
keyword,"['Alumina\xa0', 'Aluminum particle\xa0', 'Deflagration\xa0', 'Emission spectroscopy\xa0', 'Inverse problems\xa0', 'Pyrometry\xa0']"
history,"['2018-03', '2018-01-29', '2017-05-24', '2018-01-15']"
abstract,"Abstract Emission of gas and \(\hbox {Al}_{2}\hbox {O}_{3}\) smoke within the deflagration of \(\hbox {H}_{2}{-}\hbox {O}_{2}\)–{\(\hbox {N}_{2}{-}\hbox {CO}_{2}\)}–Al particles has been studied in a closed combustion chamber at pressures of up to 18 bar and at gas temperatures of up to 3700 K. Measurements of radiance intensity were taken using a five wavelength pyrometer (0.660 \(\upmu \hbox {m}\), 0.850 \(\upmu \hbox {m}\), 1.083 \(\upmu \hbox {m}\), 1.260 \(\upmu \hbox {m}\), 1.481 \(\upmu \hbox {m}\)) and a grating spectrometer in the range (4.10 \(\upmu \hbox {m}\) to 4.30 \(\upmu \hbox {m}\)). In order to characterize the aluminum oxide smoke size and temperature, an inversion method has been developed based on the radiation transfer equation and using pyrometer measurements and thermochemical calculations of \(\hbox {Al}_{2}\hbox {O}_{3}\) smoke volume fractions. Temperatures in combustion gas have been determined using a method based on the assumed blackbody head of the 4.26 \(\upmu \hbox {m}\) \(\hbox {CO}_{2}\) emission line and on its spectral shift with pressure and temperature. For validation purpose, this method has been applied to measurements obtained when calibrated alumina particles are injected in a combustion chamber prior to gaseous deflagrations. This mathematical inversion method was developed to investigate explosive fireballs."
journal_title,International Journal of Thermophysics
article_title,Canadian Field Soils IV: Modeling Thermal Conductivity at Dryness and Saturation
keyword,"['Database\xa0', 'Dry soils\xa0', 'Predictive models\xa0', 'Saturated soils\xa0', 'Thermal conductivity\xa0', 'Validation\xa0']"
history,"['2018-03', '2018-01-16', '2017-06-18', '2017-12-30']"
abstract,"Abstract The thermal conductivity data of 40 Canadian soils at dryness \((\lambda _{\mathrm{dry}})\) and at full saturation \((\lambda _{\mathrm{sat}})\) were used to verify 13 predictive models, i.e., four mechanistic, four semi-empirical and five empirical equations. The performance of each model, for \(\lambda _{\mathrm{dry}}\) and \(\lambda _{\mathrm{sat}}\), was evaluated using a standard deviation (SD) formula. Among the mechanistic models applied to dry soils, the closest \(\lambda _{\mathrm{dry}}\) estimates were obtained by MaxRTCM \((\textit{SD} = \pm ~0.018\,\hbox { Wm}^{-1}\cdot \hbox {K}^{-1})\), followed by de Vries and a series-parallel model (\(\hbox {S-}{\vert }{\vert }\)). Among the semi-empirical equations (deVries-ave, Advanced Geometric Mean Model (A-GMM), Chaudhary and Bhandari (C–B) and Chen’s equation), the closest \(\lambda _{\mathrm{dry}}\) estimates were obtained by the C–B model \((\pm ~0.022\,\hbox { Wm}^{-1}\cdot \hbox {K}^{-1})\). Among the empirical equations, the top \(\lambda _{\mathrm{dry}}\) estimates were given by CDry-40 \((\pm ~0.021\,\hbox { Wm}^{-1}\cdot \hbox {K}^{-1}\) and \(\pm ~0.018\,\hbox { Wm}^{-1}\cdot \hbox {K}^{-1}\) for18-coarse and 22-fine soils, respectively). In addition, \(\lambda _{\mathrm{dry}}\) and \(\lambda _{\mathrm{sat}}\) models were applied to the \(\lambda _{\mathrm{sat}}\) database of 21 other soils. From all the models tested, only the maxRTCM and the CDry-40 models provided the closest \(\lambda _{\mathrm{dry}}\) estimates for the 40 Canadian soils as well as the 21 soils. The best \(\lambda _{\mathrm{sat}}\) estimates for the 40-Canadian soils and the 21 soils were given by the A-GMM and the \(\hbox {S-}{\vert }{\vert }\) model."
journal_title,International Journal of Thermophysics
article_title,Correction to: Ab Initio Calculated Results Require New Formulations for Properties in the Limit of Zero Density: The Viscosity of Methane ($$\mathbf{CH}_\mathbf{4}$$CH4)
keyword,[]
history,"['2018-02', '2018-01-13']"
abstract,None
journal_title,International Journal of Thermophysics
article_title,Photopyroelectric Calorimetry Investigations of 8CB Liquid Crystal–Microemulsion System
keyword,"['Calorimetry\xa0', 'Liquid crystals\xa0', 'Microemulsions\xa0', 'Phase transitions\xa0']"
history,"['2018-02', '2018-01-12', '2017-09-20', '2017-12-30']"
abstract,"Abstract In this work, the photopyroelectric technique has been used to investigate the phase transitions in a liquid crystal microemulsion by combining the simultaneous high temperature resolution thermal diffusivity measurements and optical polarization microscopy observations. It has been found that, during the conversion from the isotropic phase into the nematic one, the micelles are expelled from the nematic domains and remain confined in islands of isotropic material which survive down to the smectic temperature range. A hysteresis in the thermal diffusivity profiles between heating and cooling run over the isotropic–nematic transition temperature range has been observed which has been ascribed to the different micelles distribution into the sample volume during cooling and heating runs. Finally, the almost bulk-like behavior of the thermal diffusivity over the nematic–smectic phase transition confirms that a significant fraction of the micelles are expelled during the nucleation of the nematic phase."
journal_title,International Journal of Thermophysics
article_title,Photoacoustic Effect Generated from an Expanding Spherical Source
keyword,"['Moving sources\xa0', 'Photoacoustics\xa0', 'Spherical symmetry\xa0']"
history,"['2018-02', '2018-01-08', '2017-08-18', '2017-12-22']"
abstract,"Abstract Although the photoacoustic effect is typically generated by amplitude-modulated continuous or pulsed radiation, the form of the wave equation for pressure that governs the generation of sound indicates that optical sources moving in an absorbing fluid can produce sound as well. Here, the characteristics of the acoustic wave produced by a radially symmetric Gaussian source expanding outwardly from the origin are found. The unique feature of the photoacoustic effect from the spherical source is a trailing compressive wave that arises from reflection of an inwardly propagating component of the wave. Similar to the one-dimensional geometry, an unbounded amplification effect is found for the Gaussian source expanding at the sound speed."
journal_title,International Journal of Thermophysics
article_title,Optimization of Perfect Absorbers with Multilayer Structures
keyword,"['Multilayer structure\xa0', 'Optical materials and properties\xa0', 'Perfect absorber\xa0', 'Solar energy collectors\xa0', 'Thermophotovoltaic\xa0']"
history,"['2018-02', '2018-01-04', '2017-10-30', '2017-12-22']"
abstract,"Abstract We study wide-angle and broadband perfect absorbers with compact multilayer structures made of a sequence of ITO and TiN layers deposited onto a silver thick layer. An optimization procedure is introduced for searching the optimal thicknesses of the layers so as to design a perfect broadband absorber from 400 nm to 750 nm, for a wide range of angles of incidence from \(0{^{\circ }}\) to \(50{^{\circ }}\), for both polarizations and with a low emissivity in the mid-infrared. We eventually compare the performances of several optimal structures that can be very promising for solar thermal energy harvesting and collectors."
journal_title,International Journal of Thermophysics
article_title,Evaluation of Building Energy Saving Through the Development of Venetian Blinds’ Optimal Control Algorithm According to the Orientation and Window-to-Wall Ratio
keyword,"['Building energy\xa0', 'EnergyPlus\xa0', 'Orientation\xa0', 'Slat angle\xa0', 'Venetian blind\xa0', 'Window-to-wall ratio\xa0']"
history,"['2018-02', '2018-01-04', '2017-09-12', '2017-12-22']"
abstract,"Abstract As various studies focusing on building energy saving have been continuously conducted, studies utilizing renewable energy sources, instead of fossil fuel, are needed. In particular, studies regarding solar energy are being carried out in the field of building science; in order to utilize such solar energy effectively, solar radiation being brought into the indoors should be acquired and blocked properly. Blinds are a typical solar radiation control device that is capable of controlling indoor thermal and light environments. However, slat-type blinds are manually controlled, giving a negative effect on building energy saving. In this regard, studies regarding the automatic control of slat-type blinds have been carried out for the last couple of decades. Therefore, this study aims to provide preliminary data for optimal control research through the controlling of slat angle in slat-type blinds by comprehensively considering various input variables. The window area ratio and orientation were selected as input variables. It was found that an optimal control algorithm was different among each window-to-wall ratio and window orientation. In addition, through comparing and analyzing the building energy saving performance for each condition by applying the developed algorithms to simulations, up to 20.7 % energy saving was shown in the cooling period and up to 12.3 % energy saving was shown in the heating period. In addition, building energy saving effect was greater as the window area ratio increased given the same orientation, and the effects of window-to-wall ratio in the cooling period were higher than those of window-to-wall ratio in the heating period."
journal_title,International Journal of Thermophysics
article_title,Calibration Method and Uncertainty Assessment of a High-Temperature GHP Apparatus
keyword,"['Calibration method\xa0', 'Guarded hot plate method\xa0', 'High temperature\xa0', 'Thermal conductivity\xa0', 'Uncertainty\xa0']"
history,"['2018-02', '2017-12-27', '2017-04-15', '2017-12-15']"
abstract,"Abstract In this research, a calibration method of a high-temperature guarded hot plate (GHP) apparatus was proposed in order to improve the measurement accuracy of thermal conductivity. The measurement uncertainties of this GHP apparatus were assessed to validate the reliability of this calibration method. The temperature difference across the guarded gap was set as the bias value to eliminate the heat exchange over the guarded gap. The effects of the thermal expansion and pressure of the apparatus on thickness were investigated to revise the measurement results of in-situ thickness and meter area, respectively. The assessed uncertainty indicated that the related expanded uncertainty approximately increased with the increase in testing temperature and the calibration method should be valid in the temperature range. The contribution of each factor on the combined uncertainty showed that the temperature distribution in plane direction was the main factor in influencing the measurement of thermal conductivity."
journal_title,International Journal of Thermophysics
article_title,Determination of Thermal Conductivity of Silicate Matrix for Applications in Effective Media Theory
keyword,"['Homogenization\xa0', 'Moisture content\xa0', 'Silicate matrix\xa0', 'Thermal conductivity\xa0']"
history,"['2018-02', '2017-12-22', '2016-05-24', '2017-12-12']"
abstract,"Abstract Silicate materials have an irreplaceable role in the construction industry. They are mainly represented by cement-based- or lime-based materials, such as concrete, cement mortar, or lime plaster, and consist of three phases: the solid matrix and air and water present in the pores. Therefore, their effective thermal conductivity depends on thermal conductivities of the involved phases. Due to the time-consuming experimental determination of the effective thermal conductivity, its calculation by means of homogenization techniques presents a reasonable alternative. In the homogenization theory, both volumetric content and particular property of each phase need to be identified. For porous materials the most problematic part is to accurately identify thermal conductivity of the solid matrix. Due to the complex composition of silicate materials, the thermal conductivity of the matrix can be determined only approximately, based on the knowledge of thermal conductivities of its major compounds. In this paper, the thermal conductivity of silicate matrix is determined using the measurement of a sufficiently large set of experimental data. Cement pastes with different open porosities are prepared, dried, and their effective thermal conductivity is determined using a transient heat-pulse method. The thermal conductivity of the matrix is calculated by means of extrapolation of the effective thermal conductivity versus porosity functions to zero porosity. Its practical applicability is demonstrated by calculating the effective thermal conductivity of a three-phase silicate material and comparing it with experimental data."
journal_title,International Journal of Thermophysics
article_title,New Submersed Chamber for Calibration of Relative Humidity Instruments at HMI/FSB-LPM
keyword,"['Comparison calibration\xa0', 'Relative humidity\xa0', 'RH test chamber\xa0']"
history,"['2018-02', '2017-12-22', '2016-10-26', '2017-12-15']"
abstract,"Abstract This paper gives a detailed description of a new chamber designed for calibration of relative humidity (RH) instruments at Laboratory for Process Measurement (HMI/FSB-LPM). To the present time, the calibrations of RH instruments at the HMI/FSB-LPM were done by comparison method using a climatic chamber of large volume and calibrated dew point hygrometer with an additional thermometer. Since 2010, HMI/FSB-LPM in cooperation with Centre for Metrology and Accreditation in Finland (MIKES) developed the two primary dew point generators which cover the dew point temperature range between \(-\,70~{^{\circ }}\hbox {C}\) and \(60~{^{\circ }}\hbox {C}\). In order to utilize these facilities for calibrations of the RH instruments, the new chamber was designed, manufactured and installed in the existing system, aiming to extend its range and reduce the related calibration uncertainties. The chamber construction allows its use in a thermostatic bath of larger volume as well as in the climatic chambers. In the scope of this paper, performances of the new chamber were tested while it was submersed in a thermostated bath. The chamber can simultaneously accommodate up to three RH sensors. In order to keep the design of the chamber simple, only cylindrical RH sensors detachable from display units can be calibrated. Possible optimizations are also discussed, and improvements in the design proposed. By using the new chamber, HMI/FSB-LPM reduced the expanded calibration uncertainties (level of confidence 95 %, coverage factor \(k=2\)) from 0.6 %rh to 0.25 %rh at 30 %rh \((23~{^{\circ }}\hbox {C})\), and from 0.8 %rh to 0.53 %rh at 70 %rh \((23~{^{\circ }}\hbox {C})\)."
journal_title,International Journal of Thermophysics
article_title,Calculating SPRT Interpolation Error
keyword,"['International Temperature Scale of 1990 (ITS-90)\xa0', 'Interpolation error\xa0', 'Type 3 non-uniqueness\xa0']"
history,"['2018-02', '2017-12-19', '2016-06-23', '2017-11-21']"
abstract,"Abstract Interpolation error is a major source of uncertainty in the calibration of standard platinum resistance thermometer (SPRT) in the subranges of the International Temperature Scale of 1990 (ITS-90). This interpolation error arises because the interpolation equations prescribed by the ITS-90 cannot perfectly accommodate all the SPRTs natural variations in the resistance–temperature behavior, and generates different forms of non-uniqueness. This paper investigates the type 3 non-uniqueness for fourteen SPRTs of five different manufacturers calibrated over the water–zinc subrange and demonstrates the use of the method of divided differences for calculating the interpolation error. The calculated maximum standard deviation of 0.25 mK (near \(100\,^{\circ }\hbox {C}\)) is similar to that observed in previous studies."
journal_title,International Journal of Thermophysics
article_title,Effects of Sintering on the Thermal and Optical Properties of Zinc Oxide Ceramic
keyword,"['Diffuse reflectance spectroscopy\xa0', 'Photothermal radiometry\xa0', 'Sintering of zinc oxide ceramic\xa0', 'Thermal conductivity\xa0', 'Thermal diffusivity\xa0']"
history,"['2018-02', '2017-12-18', '2017-03-05', '2017-11-06']"
abstract,"Abstract Microstructure and composition are factors determining heat transfer in ZnO ceramic materials, which define the performance of the material after Joule heating, generated by electron transport. In this study, photothermal radiometry was applied to investigate the influence of the sintering temperature, ranging from \(800\,{^{\circ }}\hbox {C}\) to \(1300\,{^{\circ }}\hbox {C}\), by measuring the thermal diffusivity and thermal conductivity at room temperature, of commercial and sol–gel ZnO pellets. Our results show that the values of these thermal properties for both types of ZnO increase when the sintering temperature increases, displaying maximum energy dissipation at \(1200\,{^{\circ }}\hbox {C}\). Additionally, the role of the sintering temperature on the optical properties was also analyzed using diffuse reflectance spectroscopy, and from these data the optical band-gap was obtained."
journal_title,International Journal of Thermophysics
article_title,Thermal Diffusivity of High-Density Polyethylene Samples of Different Crystallinity Evaluated by Indirect Transmission Photoacoustics
keyword,"['Crystallinity\xa0', 'HDPE\xa0', 'Multi-parameter fitting\xa0', 'Photoacoustics\xa0', 'Photothermal\xa0', 'Thermodynamics\xa0']"
history,"['2018-02', '2017-12-18', '2015-10-14', '2017-12-05']"
abstract,"Abstract In this work, thermal diffusivity of crystalline high-density polyethylene samples of various thickness, and prepared using different procedures, was evaluated by transmission gas-microphone frequency photoacoustics. The samples’ composition analysis and their degree of crystallinity were determined from the wide-angle X-ray diffraction, which confirmed that high-density polyethylene samples, obtained by slow and fast cooling, were equivalent in composition but with different degrees of crystallinity. Structural analysis, performed by differential scanning calorimetry, demonstrated that all of the used samples had different levels of crystallinity, depending not only on the preparing procedure, but also on sample thickness. Therefore, in order to evaluate the samples’ thermal diffusivity, it was necessary to modify standard photoacoustic fitting procedures (based on the normalization of photoacoustic amplitude and phase characteristics on two thickness levels) for the interpretation of photoacoustic measurements. The calculated values of thermal diffusivity were in the range of the expected literature values. Besides that, the obtained results indicate the unexpected correlation between the values of thermal diffusivity and thermal conductivity with the degree of crystallinity of the investigated geometrically thin samples. The results indicate the necessity of additional investigation of energy transport in macromolecular systems, as well as the possible employment of the photoacoustic techniques in order to clarify its mechanism."
journal_title,International Journal of Thermophysics
article_title,In situ Investigation of Microwave Impacts on Ethylene Glycol Aqueous Solutions
keyword,"['Bubble formation\xa0', 'Microwave\xa0', 'Surface tension\xa0']"
history,"['2018-02', '2017-12-18', '2016-09-14', '2017-11-28']"
abstract,"Abstract Recently, the in-situ IMPACT of MICROWAVES on the behavior of aqueous solutions have been reported. The results, including surface tension and in situ bubble formation, indicated a nonthermal effect of microwave on solutions. To clarify the role of fluid properties on such effects, this study applied microwave to ethylene glycol (EG) aqueous solutions at different concentrations. The surface tension, bubble size and convection were monitored during and after microwave irradiation. It was found that surface tension reduction was maximized in the medium EG content, 20 to 60 vol.%. The size of bubble formed during microwave was reduced by the addition of EG. The convection was also reduced by EG. The obtained data indicated that the dielectric constant and intermolecular bonds were the main underlining principles for microwave effects. The new insights can be used to provide practical ways to manipulate microwave effects on aqueous solutions."
journal_title,International Journal of Thermophysics
article_title,European Conference on Thermophysical Properties: The First 50 Years (1968 to 2018)
keyword,"['European Conference on Thermophysical Properties\xa0', 'History\xa0']"
history,"['2018-02', '2017-12-18', '2017-10-15', '2017-12-05']"
abstract,"Abstract This paper presents the story of the initial 50 years of the European Conference on Thermophysical Properties, a successful series of events that started in 1968 and is still going strong. The aim is twofold: to make the story known and to pay gratitude to all those who helped in this endeavor. It also serves as a nice memory of good times for many of us and intends to be a tribute to many colleagues no longer with us."
journal_title,International Journal of Thermophysics
article_title,Design Guideline for New Generation of High-Temperature Guarded Hot Plate
keyword,"['Differential thermal expansion\xa0', 'High-temperature guarded hot plate\xa0', 'High-temperature high-emissivity coating\xa0', 'Sensitivity study\xa0', 'Technical insulation\xa0', 'Thermal conductivity\xa0']"
history,"['2018-02', '2017-12-18', '2016-08-17', '2017-11-30']"
abstract,"Abstract This paper complements the existing measurement standards and literature for high-temperature guarded hot plates (HTGHPs) by addressing specific issues relating to thermal conductivity measurement of technical insulation at high temperatures. The examples given are focused on the designs of HTGHPs for measuring thin thermal insulation. The sensitivity studies have been carried out on major influencing factors that affect the thermal conductivity measurements using HTGHPs, e.g., the uncertainty of temperature measurements, plate flatness and center-guard gap design and imbalance. A new configuration of center-guard gap with triangular shape cross section has been optimized to obtain the same thermal resistance as a 2 mm wide gap with rectangular shape cross section that has been used in the HTGHPs at NPL and LNE. Recommendations have been made on the selections of heater plate materials, high-temperature high-emissivity coatings and miniature temperature sensors. For the first time, thermal stress analysis method has been applied to the field of HTGHPs, in order to estimate the effect of differential thermal expansion on the flatness of thin rigid specimens during thermal conductivity tests in a GHP."
journal_title,International Journal of Thermophysics
article_title,New Primary Standards for Establishing SI Traceability for Moisture Measurements in Solid Materials
keyword,"['Karl Fischer\xa0', 'Loss-on-drying\xa0', 'Moisture\xa0', 'Oven drying\xa0', 'Traceability\xa0']"
history,"['2018-01', '2017-12-01', '2016-06-01', '2017-11-13']"
abstract,"Abstract A European research project METefnet addresses a fundamental obstacle to improving energy-intensive drying process control: due to ambiguous reference analysis methods and insufficient methods for estimating uncertainty in moisture measurements, the achievable accuracy in the past was limited and measurement uncertainties were largely unknown. This paper reports the developments in METefnet that provide a sound basis for the SI traceability: four new primary standards for realizing the water mass fraction were set up, analyzed and compared to each other. The operation of these standards is based on combining sample weighing with different water vapor detection techniques: cold trap, chilled mirror, electrolytic and coulometric Karl Fischer titration. The results show that an equivalence of 0.2 % has been achieved between the water mass fraction realizations and that the developed methods are applicable to a wide range of materials."
journal_title,International Journal of Thermophysics
article_title,A Two-Temperature Photothermal Interaction in a Semiconductor Medium Containing a Cylindrical Hole
keyword,"['A semiconducting material\xa0', 'Cylindrical hole\xa0', 'Eigenvalue approach\xa0', 'Laplace transform\xa0', 'Two-temperature\xa0']"
history,"['2018-01', '2017-11-27', '2016-12-07', '2017-11-13']"
abstract,"Abstract Photothermoelastic interactions in an infinite semiconductor medium containing a cylindrical hole with two temperatures are studied using mathematical method under the purview of the coupled theory of thermal, plasma and elastic waves. The internal surface of the hole is constrained and the carrier density is photogenerated by bound heat flux with an exponentially decaying pulse. Based on Laplace transform and the eigenvalue approach methodology, the solutions of all variables have been obtained analytically. The numerical computations for silicon-like semiconductor material have been obtained. The results further show that the analytical scheme can overcome mathematical problems to analyze these problems."
journal_title,International Journal of Thermophysics
article_title,Determination of Thermal Transmittance of Insulated Double Low-E Glazing Panel Using Portable Uglass Measuring Technique
keyword,"['Glazing panel\xa0', 'Insulation performance\xa0', 'low-E\xa0', 'Thermal transmittance\xa0', None, None]"
history,"['2018-01', '2017-11-27', '2017-04-28', '2017-11-13']"
abstract,"Abstract Windows are regarded as the primary object of energy efficiency in buildings because window is one of the major energy loss areas in building construction. Existing methods were not field measurements and were not enough to get the correct thermal transmittance. We used portable \(U_{g}\) measuring device on field and measured the thermal transmittance with low-E coated and uncoated double glazing panels in existing houses, apartments and buildings. In addition, we prepared four test benches and compared the insulation performance according to the construction conditions. In results, the insulation performance of double glazing panel with low-E coating is up to about 41 % higher than uncoated panel due to low-E coating inside and the glazing panel filled with about 90 % of argon gas decrease about 0.15 \(\hbox {W} \cdot \hbox {m}^{-2} \cdot \hbox {K}^{-1}\) than glazing panel filled with air gas. The measured results were compared with the theoretically calculated results according to DIN EN 673 to confirm the reliability of the analytical results. In this study, portable NETZSCH Uglass is used to increase the accuracy of calculation of thermal transmittance with various double and triple glazing panels. The paper analyzes the insulation performance of the double glazing panels in accordance with the construction conditions."
journal_title,International Journal of Thermophysics
article_title,Thermal Decomposition Study on CuInSe$$_{2}$$2 Single Crystals
keyword,"[None, 'Kinetic parameters\xa0', 'Single crystals\xa0', 'Thermo-curves\xa0']"
history,"['2018-01', '2017-11-27', '2017-07-25', '2017-11-16']"
abstract,"Abstract The thermal analysis of the chemical vapor transport (CVT)-grown \(\hbox {CuInSe}_{2}\) single crystals was carried out by recording the thermogravimetric, differential thermogravimetric and differential thermal analysis curves. All the three thermo-curves were recorded simultaneously by thermal analyzer in the temperature range of ambient to 1080 K in inert nitrogen atmosphere. The thermo-curves were recorded for four heating rates of 5 K \(\cdot \,\hbox {min}^{-1}\), 10 K \(\cdot \,\hbox {min}^{-1}\), 15 K \(\cdot \,\hbox {min}^{-1}\) and 20 K \(\cdot \,\hbox {min}^{-1}\). The TG curve analysis showed negligible mass loss in the temperature range of ambient to 600 K, stating the sample material to be thermally stable in this temperature range. Above 601 K to the temperature of 1080 K, the sample showed continuous mass loss. The DTG curves showed two peaks in the temperature range of 601 K to 1080 K. The corresponding DTA showed initial minor exothermic nature followed by endothermic nature up to nearly 750 K and above it showed exothermic nature. The initial exothermic nature is due to absorbed water converting to water vapor, whereas the endothermic nature states the absorption of heat by the sample up to nearly 950 K. Above nearly 950 K the exothermic nature is due to the decomposition of sample material. The absorption of heat in the endothermic region is substantiated by corresponding weight loss in TG. The thermal kinetic parameters of the CVT-grown \(\hbox {CuInSe}_{2}\) single crystals were determined employing the non-mechanistic Kissinger relation. The determined kinetic parameters support the observations of the thermo-curves."
journal_title,International Journal of Thermophysics
article_title,Calibration of Contact Surface Thermometers
keyword,"['Contact thermometry\xa0', 'Correction function\xa0', 'Heat transfer\xa0', 'Surface temperature measurement\xa0', 'Uncertainty model\xa0']"
history,"['2018-01', '2017-11-25', '2016-06-23', '2017-11-13']"
abstract,"Abstract Some of the national metrology institutes (NMIs) have developed devices which generate a standard surface temperature under conditions which resemble, as closely as possible, those encountered during the routine use of surface sensors. Several comparisons of measurements among European NMIs, coordinated by MKEH, were undertaken in order to validate the methods used and the reference conditions. The characteristics of the reference surface significantly influence the measurement error, as its temperature, inclination and thermophysical properties. This paper presents a method of determining a correction function, containing the effects of these factors. The measurements have been taken in the temperature range from \(100\,^{\circ }\hbox {C}\) to \(500\,^{\circ }\hbox {C}\), with a specific sensor having an inflexible head. The technique developed of MKEH is suitable for quantifying the effect of the above parameters, optimizing the surface temperature measurements in this regard."
journal_title,International Journal of Thermophysics
article_title,Identification and Characterization of New Materials for Construction of Heating Plates for High-Temperature Guarded Hot Plates
keyword,"['Emissivity\xa0', 'High-temperature guarded hot plate\xa0', 'High-temperature high-emissivity coatings\xa0', 'Machinable aluminum nitride\xa0', 'Nickel 201 alloy\xa0', 'Silicon infiltrate silicon carbide\xa0', 'Sintered aluminum nitride\xa0', 'Thermal conductivity\xa0', 'Thermophysical properties\xa0']"
history,"['2018-01', '2017-11-25', '2016-08-01', '2017-10-31']"
abstract,"Abstract The selection of a material for making the hot and cold plates of high-temperature guarded hot plates (HTGHPs) working up to \(800\,{^\circ }\hbox {C}\) is still an issue. The material must be machinable, have a high mechanical stability to keep the high level of flatness of the plates and have a high thermal conductivity and a high resistance to oxidation when used in air. Nickel 201 alloy has been used in several instruments, but has shown, sometimes, problems of mechanical stability. The total hemispherical emissivity of the plates must be higher than 0.8 as recommended by the standards. Three ceramic materials, a silicon infiltrated silicon carbide (SiSiC), a machinable aluminum nitride and a sintered aluminum nitride (AlN) with high thermal conductivity claimed at ambient temperature, were selected for tests in thermal conductivity and opacity to thermal radiation. Three paints withstanding high temperatures were tested in total hemispherical emissivity and durability at high temperature. Above \(600\,{^\circ }\hbox {C}\), Nickel 201 alloy has a higher thermal conductivity than the three ceramics. Below \(600\, \,{^\circ }\hbox {C}\), the SiSiC and the sintered AlN have a thermal conductivity significantly higher than Nickel 201, but the sintered AlN shows a wide transparency spectral band at short wavelengths (below \(6.5\,\upmu \hbox {m}\)). Above \(300\,{^\circ }\hbox {C}\), the three paints have a total hemispherical emissivity above 0.8. One of the paints has polluted the specimens of an insulation material tested in thermal conductivity up to \(650\,{^\circ }\hbox {C}\). The other two can be recommended to coat the hot and cold plates of HTGHPs used up to \(800\,{^\circ }\hbox {C}\)."
journal_title,International Journal of Thermophysics
article_title,Measuring Sound Speed in Gas Mixtures Using a Photoacoustic Generator
keyword,"['Photoacoustic effect\xa0', 'Positive feedback\xa0', 'Speed of sound\xa0']"
history,"['2018-01', '2017-11-24', '2016-11-16', '2017-11-13']"
abstract,"Abstract We present a new method which allows us to percentage distinction of gas composition with a fast response time. This system uses the speed of sound in a resonant cell along with temperature to determine the gas mixture composition. The gas mixtures contain two gases with an unknown combination. In our experiment, the acoustic waves were excited inside the acoustic longitudinal resonator with the use of a positive feedback. This feedback provides fast tracking of a resonance frequency of the cell and causes fast tracking changes in the speed of sound. The presented method corresponds to the theoretical description of this topic. Two gas mixtures—carbon dioxide and argon mixed with nitrogen—were tested."
journal_title,International Journal of Thermophysics
article_title,Measurement of the Nonlinearity of Heat-Flux Sensors Employing a $$\hbox {CO}_2$$CO2 laser
keyword,"['Fire testing\xa0', 'Heat-flux sensor calibration\xa0', 'Nonlinearity\xa0', 'Schmidt–Boelter gauges\xa0']"
history,"['2018-01', '2017-11-24', '2016-06-27', '2017-11-13']"
abstract,"Abstract Heat-flux sensors are widely used in industry to test building products and designs for resistance to bushfire, to test the flammability of textiles and in numerous applications such as concentrated solar collectors. In Australia, such detectors are currently calibrated by the National Measurement Institute Australia (NMIA) at low flux levels of 20 W \(\cdot \) m\(^{-2}\). Estimates of the uncertainty arising from nonlinearity at industrial levels (e.g. 50 kW \(\cdot \) m\(^{-2}\) for bushfire testing) rely on literature information. NMIA has developed a facility to characterize the linearity response of these heat-flux sensors up to 110 kW \(\cdot \) m\(^{-2}\) using a low-power \(\hbox {CO}_2\) laser and a chopped quartz tungsten–halogen lamp. The facility was validated by comparison with the conventional flux-addition method, and used to characterize several Schmidt–Boelter-type sensors. A significant nonlinear response was found, ranging from (\(3.2 \pm 0.9\))% at 40 kW \(\cdot \) m\(^{-2}\) to more than 8 % at 100 kW \(\cdot \) m\(^{-2}\). Additional measurements confirm that this is not attributable to convection effects, but due to the temperature dependence of the sensor’s responsivity."
journal_title,International Journal of Thermophysics
article_title,Calibration of Pyrometers by Using Extrapolation and Interpolation Methods at NIM
keyword,"['Blackbody\xa0', 'Calibration\xa0', 'High-temperature fixed point\xa0', 'Pyrometer\xa0', 'Strip lamp\xa0']"
history,"['2018-01', '2017-11-24', '2016-07-31', '2017-10-31']"
abstract,"Abstract High-temperature fixed points (HTFPs) have been thoroughly investigated, and the performance of variable temperature blackbodies (VTBB) has also improved rapidly. These two are beginning to be used in the calibration of pyrometers; however, tungsten strip lamps (STSL) still play a role in the dissemination of the high-temperature scale in China. International Temperature Scale of 1990 values of HTFPs and the lamps were assigned on a primary standard pyrometer (PSP) and were traced to the primary standard of the high-temperature scale at the National Institute of Metrology. In this paper, two pyrometers calibrated by using extrapolation and interpolation methods are reported. The values of the calibration were compared against the STSL values and the PSP values on HTBB, and their uncertainties are calculated as well. Because the stability of the HTFPs was better than that of the lamps, the calibration chains based on the lamps are starting to be replaced by HTFPs and VTBBs in China."
journal_title,International Journal of Thermophysics
article_title,Improving the Dynamic Emissivity Measurement Above 1000 K by Extending the Spectral Range
keyword,"['Emissivity\xa0', 'Graphite\xa0', 'High temperature\xa0', 'Laser flash\xa0', 'Spectrometry\xa0']"
history,"['2018-01', '2017-11-24', '2016-08-31', '2017-11-13']"
abstract,"Abstract To improve the dynamic emissivity measurement, which is based on the laser-flash method, an array spectrometer is characterized regarding its spectral radiance responsivity for a spectrally resolved emissivity measurement above \(1000\,\)K in the wavelength range between \(550\,\)nm and \(1100\,\)nm. Influences like dark signals, the nonlinearity of the detector, the size-of-source effect, wavelength calibration and the spectral radiance responsivity of the system are investigated to obtain an uncertainty budget for the spectral radiance and emissivity measurements. Uncertainties for the spectral radiance of lower than a relative \(2\,\%\) are achieved for wavelengths longer than \(550\,\)nm. Finally, the spectral emissivity of a graphite sample was determined in the temperature range between \(1000\,\)K and \(1700\,\)K, and the experimental data show a good repeatability and agreement with literature data."
journal_title,International Journal of Thermophysics
article_title,Qualitative Assessments via Infrared Vision of Sub-surface Defects Present Beneath Decorative Surface Coatings
keyword,"['Defect\xa0', 'Gilded coatings\xa0', 'Infrared thermography (IRT)\xa0', 'Near-infrared reflectography (NIRR)\xa0', 'Polychromatic statues\xa0', 'Statistical algorithms\xa0']"
history,"['2018-01', '2017-11-24', '2017-03-24', '2017-11-13']"
abstract,"Abstract In this work, the potentialities of the infrared vision to explore sub-superficial defects in polychromatic statues were investigated. In particular, it was possible to understand how the reflector effect of the exterior golden layers could be minimized, applying advanced statistical algorithms to thermal images. Since this noble metal is present as external coating in both artworks, an in-depth discussion concerning its physicochemical properties is also added. In this context, the principal component thermography technique and, the more recent, partial least squares thermography technique were used on three different datasets recorded, providing long thermal stimuli. The main images were compared both to phasegrams and to the thermographic signal reconstruction results in order to have a clear outline of the situation to be debated. The effects of view factors on the radiation transfer linked to the specular reflections from the surface did not falsely highlight certain features inadvertently. Indeed, the raw thermograms were analyzed one by one. Reflectograms were used to pinpoint emissivity variations due to, e.g., possible repainting. The paper concludes that, as it is possible to understand from a physical point of view, the near-infrared reflectography technique is able to examine the state of conservation of the upper layers in cultural heritage objects, while the infrared thermography technique explores them more in-depth. The thesis statement is based on the thermal and nonthermal parts of the infrared region, therefore, indicating what can be detected by heating the surface and what can be visualized by illuminating the surface, bearing in mind the nature of the external coating."
journal_title,International Journal of Thermophysics
article_title,"New Comment on Gibbs Density Surface of Fluid Argon: Revised Critical Parameters, L. V. Woodcock, Int. J. Thermophys. (2014) 35, 1770–1784"
keyword,"['Coexistence\xa0', 'Critical point\xa0', 'First-order phase transition\xa0', 'Liquid\xa0', 'Phase equilibrium\xa0', 'Vapor\xa0']"
history,"['2018-01', '2017-11-21', '2017-05-19', '2017-11-13']"
abstract,"Abstract The author comments on an article by Woodcock (Int J Thermophys 35:1770–1784, 2014), who investigates the idea of a critical line instead of a single critical point using the example of argon. In the introduction, Woodcock states that “The Van der Waals critical point does not comply with the Gibbs phase rule. Its existence is based upon a hypothesis rather than a thermodynamic definition”. The present comment is a response to the statement by Woodcock. The comment mathematically demonstrates that a critical point is not only based on a hypothesis that is used to define values of two parameters of the Van der Waals equation of state. Instead, the author argues that a critical point is a direct consequence of the thermodynamic phase equilibrium conditions resulting in a single critical point. It is shown that the thermodynamic conditions result in the first and second partial derivatives of pressure with respect to volume at constant temperature at a critical point equal to zero which are usual conditions of an existence of a critical point."
journal_title,International Journal of Thermophysics
article_title,Influence of Chemical Treatment on Thermal Decomposition and Crystallite Size of Coir Fiber
keyword,"['Activation energy\xa0', 'Coir fiber\xa0', 'Crystallinity\xa0', 'Glutaraldehyde\xa0', 'Thermal stability\xa0']"
history,"['2018-01', '2017-11-20', '2017-03-06', '2017-10-31']"
abstract,Abstract Coir fibers were treated with sodium hydroxide (NaOH) and glutaraldehyde (GA). The influence of alkali and aldehyde treatment on thermal degradation and crystallinity of coir fiber was studied in detail. Thermogravimetric analysis and X-ray diffraction techniques were mainly used to characterize the coir samples. Activation energy of degradation was calculated from Broido and Horowitz–Metzger equations. NaOH-treated samples showed an increase in thermal stability. Removal of impurities such as waxy and fatty acid residues from the coir fiber by reacting with strong base solution improved the stability of fiber. Crosslinking of cellulose with GA in the fiber enhanced the stability of the material. Scanning electron microscopy was employed to analyze the change in surface morphology upon chemical treatment. Improvement in the properties suggests that NaOH and GA can be effectively used to modify coir fiber with excellent stability.
journal_title,International Journal of Thermophysics
article_title,A Study on Variation of Thermal Characteristics of Insulation Materials for Buildings According to Actual Long-Term Annual Aging Variation
keyword,"['Actual long-term\xa0', 'Aging variation\xa0', 'Insulation materials\xa0', 'Thermal resistance\xa0']"
history,"['2018-01', '2017-11-20', '2017-05-08', '2017-10-17']"
abstract,"Abstract Insulation materials used for buildings are broadly classified as organic insulation materials or inorganic insulation materials. Foam gas is used for producing organic insulation materials. The thermal conductivity of foam gas is generally lower than that of air. As a result, foam gas is discharged over time and replaced by outside air that has relatively less thermal resistance. The gas composition ratio in air bubbles inside the insulation materials changes rapidly, causing the performance degradation of insulation materials. Such performance degradation can be classified into different stages. Stage 1 appears to have a duration of 5 years, and Stage 2 takes a period of over 10 years. In this study, two insulation materials that are most frequently used in South Korea were analyzed, focusing on the changes thermal resistance for the period of over 5000 days. The measurement result indicated that the thermal resistance of expanded polystyrene fell below the KS performance standards after about 80–150 days from its production date. After about 5000 days, its thermal resistance decreased by 25.7 % to 42.7 % in comparison with the initial thermal resistance. In the case of rigid polyurethane, a pattern of rapid performance degradation appeared about 100 days post-production, and the thermal resistance fell below the KS performance standards after about 1000 days. The thermal resistance decreased by 22.5 % to 27.4 % in comparison with the initial thermal resistance after about 5000 days."
journal_title,International Journal of Thermophysics
article_title,"SI-Traceable Water Content Measurements in Solids, Bulks, and Powders"
keyword,"['Dew point\xa0', 'Moisture content\xa0', 'SI primary standard\xa0', 'Water content\xa0', 'Water mass fraction\xa0']"
history,"['2018-01', '2017-11-20', '2016-06-02', '2017-10-31']"
abstract,"Abstract Methods  such as Karl Fischer titration and Loss-on-Drying, commonly used for estimating moisture content in samples, have been in existence for many years, but have difficulties obtaining a direct calibration chain toward water content. In recognition of this challenge, the joint research project, METefnet, was funded by the European Metrology Research Programme in 2012. The goal of METefnet is to establish a European metrology infrastructure for water content measurement and to develop primary standards for unambiguous determination of water mass fraction in materials. Here, we describe the primary standard developed by Danish Technological Institute in METefnet. This standard establishes traceability of the water content of a sample to dewpoint temperature. The standard only measures water, and the measurement result is not affected by other components."
journal_title,International Journal of Thermophysics
article_title,Simultaneous Measurement of Thermal Conductivity and Specific Heat in a Single TDTR Experiment
keyword,"['Specific heat\xa0', 'Thermal conductivity\xa0', 'Thermal property\xa0', 'Time-domain thermoreflectance\xa0', 'Two-step fitting method\xa0']"
history,"['2018-01', '2017-11-20', '2016-11-27', '2017-11-06']"
abstract,"Abstract Time-domain thermoreflectance (TDTR) technique is a powerful thermal property measurement method, especially for nano-structures and material interfaces. Thermal properties can be obtained by fitting TDTR experimental data with a proper thermal transport model. In a single TDTR experiment, thermal properties with different sensitivity trends can be extracted simultaneously. However, thermal conductivity and volumetric heat capacity usually have similar trends in sensitivity for most materials; it is difficult to measure them simultaneously. In this work, we present a two-step data fitting method to measure the thermal conductivity and volumetric heat capacity simultaneously from a set of TDTR experimental data at single modulation frequency. This method takes full advantage of the information carried by both amplitude and phase signals; it is a more convenient and effective solution compared with the frequency-domain thermoreflectance method. The relative error is lower than 5 % for most cases. A silicon wafer sample was measured by TDTR method to verify the two-step fitting method."
journal_title,International Journal of Thermophysics
article_title,Solubility Determination and Modeling and Dissolution Thermodynamic Properties of Raspberry Ketone in Binary Solvent Mixtures of Ethanol and Water
keyword,"['3D Jouyban–Acree–van’t Hoff model\xa0', 'Binary solvent mixtures\xa0', 'Dissolution thermodynamic properties\xa0', 'Gravimetric method\xa0', 'Raspberry ketone\xa0', 'Solubility\xa0']"
history,"['2018-01', '2017-11-20', '2017-03-13', '2017-10-24']"
abstract,"Abstract The solubility and dissolution thermodynamic properties of raspberry ketone in a set of binary solvent mixtures (ethanol + water) with different compositions were experimentally determined by static gravimetrical method in the temperature range of 283.15–313.15 K at 0.10 MPa. The solubility of raspberry ketone in this series of ethanol/water binary solvent mixtures was found to increase with a rise in temperature and the rising mole fraction of ethanol in binary solvent mixtures. The van’t Hoff, modified Apelblat and 3D Jouyban–Acree–van’t Hoff equations were increasingly applied to correlate the solubility in ethanol/water binary solvent mixtures. The former two models could reach better fitting results with the solubility data, while the 3D model can be comprehensively used to estimate the solubility data in all the ratios of ethanol and water in binary solvent mixtures at random temperature. Furthermore, the changes of dissolution thermodynamic properties of raspberry ketone in experimental ethanol/water solvent mixtures were obtained by van’t Hoff equation. For all the above experiments, these dissolution processes of raspberry ketone in experimental ethanol/water binary solvent mixtures were estimated to be endothermic and enthalpy-driven."
journal_title,International Journal of Thermophysics
article_title,Review on Variable Emissivity Materials and Devices Based on Smart Chromism
keyword,"['Device\xa0', 'Electrochromism\xa0', 'Emissivity\xa0', 'Film\xa0', 'Thermochromism\xa0']"
history,"['2018-01', '2017-11-20', '2017-01-21', '2017-11-06']"
abstract,"Abstract Variable emissivity material (VEM) can dynamically vary its emissivity and infrared radiation under certain conditions, which may find potential applications in infrared stealth/camouflage, solar thermal collector, spacecraft thermal control, and smart energy-saving windows. In this paper, the variable emissivity materials and devices based on electrochromism and thermochromism are introduced. The basic principle and present status of the research in these fields are overviewed. Four kinds of representative VEMs are extensively summarized, which are tungsten trioxides (\(\hbox {WO}_{3})\), conducting polymers (CPs), perovskite oxides (\(\hbox {A}_{1-{x}}\hbox {B}_{{x}}\hbox {MO}_{3})\), and vanadium dioxide (\(\hbox {VO}_{2})\). Finally, specific issues confronted with electrochromic and thermochromic materials and devices are prospected."
journal_title,International Journal of Thermophysics
article_title,Progress Report on NMIJ Acoustic Gas Thermometry at the Triple Point of Water
keyword,"['Acoustic gas thermometry\xa0', 'Acoustic resonance\xa0', 'Boltzmann constant\xa0', 'Microwave resonance\xa0', 'Primary thermometry\xa0']"
history,"['2018-01', '2017-11-20', '2016-07-07', '2017-10-17']"
abstract,"Abstract Herein, progress in the development of an acoustic gas thermometry (AGT) system at the National Metrology Institute of Japan is reported. This AGT system is an initial low-cost version that uses a 1-l quasi-spherical resonator (QSR) made of oxygen-free copper. The system was tested by measuring the speed of sound in argon at the temperature of triple point of water. Measurements were conducted at ten different pressures, ranging from 60 kPa to 420 kPa. The ideal gas limit of the squared speed of sound was obtained through extrapolation, and a preliminary calculation of the Boltzmann constant, which was 12 ppm below the CODATA2014 value, was made. Large inconsistencies among microwave and acoustic modes were observed, which are dominant sources of uncertainty in speed of sound measurements. The system will be improved by replacing the present QSR with another one that is more precisely fabricated."
journal_title,International Journal of Thermophysics
article_title,Considerations Relating to Type 1 and Type 3 Non-uniqueness in SPRT Interpolations of the ITS-90
keyword,"['ITS-90\xa0', 'Non-uniqueness\xa0', 'Standard Platinum Resistance Thermometer\xa0', 'Subrange inconsistency\xa0']"
history,"['2017-12', '2017-11-02', '2016-10-17', '2017-10-23']"
abstract,"Abstract It is well known that different allowed interpolations using a given standard platinum resistance thermometer (SPRT) in overlapping subranges of the ITS-90 do not lead to identical results. This is termed Type 1 non-uniqueness, or subrange inconsistency (SRI), and it arises because of small incompatibilities in the SPRT characteristic \(W(T_{90})\) with respect to the ITS-90 reference function \(W_{r}(T_{90})\), such that the alternative low-order interpolations, fitted to the deviations \(W(T_{90})\) – \(W_{r}(T_{90})\) at different sets of fixed points, are not in general identical. To some extent SRI may be ‘scale-intrinsic,’ i.e., caused by incompatibilities between the resistance ratios, \(W_{r}(T_{90})\), specified at the fixed points of the ITS-90, and hence the same for all SPRTs. However, it has been found that the SRI varies strongly between different SPRTs, and that variability of \(W(T_{90})\) is much the dominant cause. This raises the question of how SRI is linked to Type 3 non-uniqueness between SPRTs in each separate subrange, which is entirely due to differences in SPRT characteristics. This paper explores the connection between them and concludes that they are of similar magnitude and consequently, being different manifestations of the same effects, it is argued that non-uniqueness should be covered by a single component of uncertainty. Following the stated rationale of the ITS-90, it is further suggested that this uncertainty should be estimated only within each subrange, i.e., that shorter subranges should not be deemed subject to potential effects caused by out-of-range data."
journal_title,International Journal of Thermophysics
article_title,Implementation of a Water Heat Pipe at CETIAT
keyword,"['Calibration\xa0', 'Heat pipe\xa0', 'Temperature generator\xa0', 'Thermometry\xa0']"
history,"['2017-12', '2017-11-02', '2016-09-01', '2017-10-23']"
abstract,"Abstract CETIAT’s calibration laboratory, accredited by COFRAC, is a secondary thermometry laboratory. It uses overflow and stirred calibration baths \((\hbox {from} -\,80\,{^{\circ }}\hbox {C} \hbox { up } \hbox { to } +\,215\,{^{\circ }}\hbox {C})\), dry blocks and furnaces \((\hbox {from } +\,100\,{^{\circ }}\hbox {C} \hbox { up } \hbox { to } +\,1050\,{^{\circ }}\hbox {C})\) and thermostatic chambers \((\hbox {from } -\,30\,{^{\circ }}\hbox {C} \hbox { up } \hbox { to } +\,160\,{^{\circ }}\hbox {C})\). Typical calibration uncertainties that can be reached for platinum resistance thermometers in a thermostatic bath are between \(0.03\,{^{\circ }}\hbox {C}\) and \(0.06\,{^{\circ }}\hbox {C}\). In order to improve its calibration capabilities, CETIAT is working on the implementation of a gas-controlled heat pipe (GCHP) temperature generator, used for industrial sensor calibrations. This article presents the results obtained during the characterization of water GCHP for industrial applications. This is a new approach to the use of a heat pipe as a temperature generator for industrial sensor calibrations. The objective of this work is to improve measurement uncertainties and daily productivity. Indeed, as has been shown in many studies (Dunn and Reay in Heat Pipes, Pergamon Press, Oxford, 1976; Merlone et al. 2012), the temperature of the system is pressure dependent and the response time, in temperature, follows the pressure accordingly. Thanks to this generator, it is possible to perform faster calibrations with smaller uncertainties. In collaboration with INRiM, the GCHP developed at CETIAT works with water and covers a temperature range from \(+\,30\,{^{\circ }}\hbox {C}\) up to \(+\,150\,{^{\circ }}\hbox {C}\). This device includes some improvements such as a removable cover, which allows us to have different sets of thermometric wells adjustable according to the probe to be calibrated, and a pressure controller based on a temperature sensor. This article presents the metrological characterization in terms of homogeneity and stability in temperature. A rough investigation of the response time of the system is also presented in order to evaluate the time for reaching thermal equilibrium. The results obtained in this study concern stability and thermal homogeneity. The homogeneity on 200 mm is better than 5 mK and with a calibration uncertainty reduced by a factor of three."
journal_title,International Journal of Thermophysics
article_title,Co–C and Pd–C Eutectic Fixed Points for Radiation Thermometry and Thermocouple Thermometry
keyword,"['Eutectic fixed point\xa0', 'Point of inflection (POI )\xa0', 'Radiation thermometry\xa0', 'Thermocouple thermometry\xa0', 'Transition temperature\xa0']"
history,"['2017-12', '2017-11-01', '2016-07-19', '2017-10-23']"
abstract,"Abstract Two Co–C and Pd–C eutectic fixed point cells for both radiation thermometry and thermocouple thermometry were constructed at NMC. This paper describes details of the cell design, materials used, and fabrication of the cells. The melting curves of the Co–C and Pd–C cells were measured with a reference radiation thermometer realized in both a single-zone furnace and a three-zone furnace in order to investigate furnace effect. The transition temperatures in terms of ITS-90 were determined to be \(1324.18\,{^{\circ }}\hbox {C}\) and \(1491.61\,{^{\circ }}\hbox {C}\) with the corresponding combined standard uncertainty of \(0.44\,{^{\circ }}\hbox {C}\) and \(0.31\,{^{\circ }}\hbox {C}\) for Co–C and Pd–C, respectively, taking into account of the differences of two different types of furnaces used. The determined ITS-90 temperatures are also compared with that of INRIM cells obtained using the same reference radiation thermometer and the same furnaces with the same settings during a previous bilateral comparison exercise (Battuello et al. in Int J Thermophys 35:535–546, 2014). The agreements are within \(k=1\) uncertainty for Co–C cell and \(k = 2\) uncertainty for Pd–C cell. Shapes of the plateaus of NMC cells and INRIM cells are compared too and furnace effects are analyzed as well. The melting curves of the Co–C and Pd–C cells realized in the single-zone furnace are also measured by a Pt/Pd thermocouple, and the preliminary results are presented as well."
journal_title,International Journal of Thermophysics
article_title,Thermographic Assessment of the HAZ Properties and Structure of Thermomechanically Treated Steel
keyword,"['Emissivity correction\xa0', 'HAZ (Heat-affected zone)\xa0', 'Thermography\xa0', 'Thermomechanically treated steels\xa0', 'Welding\xa0']"
history,"['2017-12', '2017-11-01', '2016-11-02', '2017-10-23']"
abstract,"Abstract Thermomechanically processed steels are materials of great mechanical properties connected with more than good weldability. This mixture makes them interesting for different types of industrial applications. When creating welded joints, a specified amount of heat is introduced into the welding area and a so called heat-affected zone (HAZ) is formed. The key issue is to reduce the width of the HAZ, because properties of the material in the HAZ are worse than in the base material. In the paper, thermographic measurements of HAZ temperatures were presented as a potential tool for quality assuring the welding process in terms of monitoring and control. The main issue solved was the precise temperature measurement in terms of varying emissivity during a welding thermal cycle. A model of emissivity changes was elaborated and successfully applied. Additionally, material in the HAZ was tested to reveal its properties and connect changes of those properties with heating parameters. The obtained results prove that correctly modeled emissivity allows measurement of temperature, which is a valuable tool for welding process monitoring."
journal_title,International Journal of Thermophysics
article_title,Ab Initio Calculated Results Require New Formulations for Properties in the Limit of Zero Density: The Viscosity of Methane ($$\hbox {CH}_{4}$$CH4)
keyword,"['Correlation\xa0', 'Limit of zero density\xa0', 'Methane\xa0', 'Molecular interactions\xa0', 'Reference standards\xa0', 'Symbolic regression\xa0', 'Viscosity\xa0']"
history,"['2017-12', '2017-10-27', '2017-06-12', '2017-09-26']"
abstract,"Abstract A wide-ranging formulation for the viscosity of methane in the limit of zero density is presented. Using ab initio calculated data of Hellmann et al. (J Chem Phys 129, 064302, 2008) from 80 K to 1500 K, the functional form was developed by guided symbolic regression with the constraints of correct extrapolation to \(T \rightarrow 0\) and in the high-temperature limit. The formulation was adjusted to the recalibrated experimental data of May et al. (Int J Thermophys 28, 1085–1110, 2007) so that these are represented within their estimated expanded uncertainty of 0.053 % (\(k = 2\)) in their temperature range from 210.756 K to 391.551 K. Based on comparisons with original data and recalibrated viscosity ratio measurements, the expanded uncertainty of the new correlation is estimated outside this temperature range to be 0.2 % to 700 K, 0.5 % to 1100 K, 1 % to 1500 K, and physically correct at higher temperatures. At temperatures below 210 K, the new correlation agrees with recalibrated experimental data within 0.3 % down to 150 K. Hellmann et al. estimated the expanded uncertainty of their calculated data at 1 % to 80 K. The new formulation extrapolates without a singularity to \(T\rightarrow 0\)."
journal_title,International Journal of Thermophysics
article_title,Investigation of Thermal Properties of High-Density Polyethylene/Aluminum Nanocomposites by Photothermal Infrared Radiometry
keyword,"['Nanocomposites\xa0', 'Photothermal radiometry\xa0', 'Polymer\xa0', 'Thermal conductivity\xa0', 'Thermal diffusivity\xa0', 'Thermal effusivity\xa0']"
history,"['2017-12', '2017-10-24', '2016-10-31', '2017-10-07']"
abstract,"Abstract In this study, thermal properties of high-density polyethylene (HDPE) filled with nanosized Al particles (80 nm) were investigated. Samples were prepared using melt mixing method up to filler volume fraction of 29 %, followed by compression molding. By using modulated photothermal radiometry (PTR) technique, thermal diffusivity and thermal effusivity were obtained. The effective thermal conductivity of nanocomposites was calculated directly from PTR measurements and from the measurements of density, specific heat capacity (by differential scanning calorimetry) and thermal diffusivity (obtained from PTR signal amplitude and phase). It is concluded that the thermal conductivity of HDPE composites increases with increasing Al fraction and the highest effective thermal conductivity enhancement of 205 % is achieved at a filler volume fraction of 29 %. The obtained results were compared with the theoretical models and experimental data given in the literature. The results demonstrate that Agari and Uno, and Cheng and Vachon models can predict well the thermal conductivity of HDPE/Al nanocomposites in the whole range of Al fractions."
journal_title,International Journal of Thermophysics
article_title,Thermal Recovery from Cold-Working in Type K Bare-Wire Thermocouples
keyword,"['Base metal\xa0', 'Cold-work\xa0', 'Inhomogeneity\xa0', 'Thermocouple\xa0', 'Type K\xa0']"
history,"['2017-12', '2017-10-23', '2016-08-02', '2017-10-07']"
abstract,"Abstract Cold-working of most thermocouples has a significant, direct impact on the Seebeck coefficient which can lead to regions of thermoelectric inhomogeneity and accelerated drift. Cold-working can occur during the wire swaging process, when winding the wire onto a bobbin, or during handling by the end user—either accidentally or deliberately. Swaging-induced cold-work in thermocouples, if uniformly applied, may result in a high level of homogeneity. However, on exposure to elevated temperatures, the subsequent recovery process from the cold-working can then result in significant drift, and this can in turn lead to erroneous temperature measurements, often in excess of the specified manufacturer tolerances. Several studies have investigated the effects of cold-work in Type K thermocouples usually by bending, or swaging. However, the amount of cold-work applied to the thermocouple is often difficult to quantify, as the mechanisms for applying the strains are typically nonlinear when applied in this fashion. A repeatable level of cold-working is applied to the different wires using a tensional loading apparatus to apply a known yield displacement to the thermoelements. The effects of thermal recovery from cold-working can then be accurately quantified as a function of temperature, using a linear gradient furnace and a high-resolution homogeneity scanner. Variation in these effects due to differing alloy compositions in Type K wire is also explored, which is obtained by sourcing wire from a selection of manufacturers. The information gathered in this way will inform users of Type K thermocouples about the potential consequences of varying levels of cold-working and its impact on the Seebeck coefficient at a range of temperatures between \(\sim 70\,^\circ \)C and \(600\,^\circ \)C. This study will also guide users on the temperatures required to rapidly alleviate the effects of cold-working using thermal annealing treatments."
journal_title,International Journal of Thermophysics
article_title,A Numerical Study of the Thermal Characteristics of an Air Cavity Formed by Window Sashes in a Double Window
keyword,"['Evaluation of a window using a simulation\xa0', 'Energy standards and labelling program for windows\xa0', 'Energy performance of windows\xa0', 'Effective thermal conductivity of an air cavity\xa0', 'WINDOW/THERM\xa0']"
history,"['2017-12', '2017-10-23', '2017-05-17', '2017-10-07']"
abstract,"Abstract Given that the Korean government is implementing what has been termed the energy standards and labelling program for windows, window companies will be required to assign window ratings based on the experimental results of their product. Because this has added to the cost and time required for laboratory tests by window companies, the simulation system for the thermal performance of windows has been prepared to compensate for time and cost burdens. In Korea, a simulator is usually used to calculate the thermal performance of a window through WINDOW/THERM, complying with ISO 15099. For a single window, the simulation results are similar to experimental results. A double window is also calculated using the same method, but the calculation results for this type of window are unreliable. ISO 15099 should not recommend the calculation of the thermal properties of an air cavity between window sashes in a double window. This causes a difference between simulation and experimental results pertaining to the thermal performance of a double window. In this paper, the thermal properties of air cavities between window sashes in a double window are analyzed through computational fluid dynamics (CFD) simulations with the results compared to calculation results certified by ISO 15099. The surface temperature of the air cavity analyzed by CFD is compared to the experimental temperatures. These results show that an appropriate calculation method for an air cavity between window sashes in a double window should be established for reliable thermal performance results for a double window."
journal_title,International Journal of Thermophysics
article_title,"Temperature and Heat Flow Rate Calibration of a Calvet Calorimeter from $$0\,{^{\circ }}\hbox {C}$$0∘C to $$190 \,{^{\circ }}\hbox {C}$$190∘C"
keyword,"['Calibration factor\xa0', 'Calvet calorimeter\xa0', 'DSC\xa0', 'Heat flow calibration\xa0', 'SRM 720\xa0', 'Temperature calibration\xa0']"
history,"['2017-12', '2017-10-19', '2017-04-28', '2017-10-07']"
abstract,"Abstract This study describes the temperature and heat flow rate calibrations of a Calvet calorimeter (SETARAM, BT2.15) in the temperature range of 0–190 \({^{\circ }}\hbox {C}\). Temperature calibration is carried out using three reference materials, namely water, gallium, and indium, as specified in the International Temperature Scale of 1990 (ITS-90). The sample temperature of the Calvet calorimeter is corrected by the obtained mean value, \(-0.489 \,{^{\circ }}\hbox {C}\), of the measured extrapolated peak onset temperature (\(T_{e})\) when the heating rate (\(\upbeta )\) is zero (\(\Delta T_\mathrm{corr }(\upbeta ~=~0\))). The heat flow rate is calibrated using a reference material with a known heat capacity, namely SRM 720 \(\alpha \)-\(\hbox {Al}_{2}\hbox {O}_{3}\) (synthetic sapphire), which is traceable to the National Institute of Standards and Technology. From the heat flow rate measurements of the blank baseline and SRM 720, the proportional calibration factor, \(\hbox {K}_{\Phi }\), in the 0–190\( \,{^{\circ }}\hbox {C}\) temperature range was determined. The specific heat capacity of copper was measured with the obtained calibration values, and the measured data show consistency with the reference value."
journal_title,International Journal of Thermophysics
article_title,Reliability of High-Temperature Fixed-Point Installations over 8 Years
keyword,"['Calibration\xa0', 'Eutectic fixed-point cells\xa0', 'High-temperature fixed points\xa0', 'Lifetime\xa0', 'Thermocouple\xa0']"
history,"['2017-12', '2017-10-19', '2016-08-25', '2017-10-07']"
abstract,"Abstract At NPL, high-temperature metal-carbon eutectic fixed points have been set up for thermocouple calibration purposes since 2006, for realising reference temperatures above the highest point specified in the International Temperature Scale of 1990 for contact thermometer calibrations. Additionally, cells of the same design have been provided by NPL to other national measurement institutes (NMIs) and calibration laboratories over this period, creating traceable and ISO 17025 accredited facilities around the world for calibrating noble metal thermocouples at \(1324~{^{\circ }}\)C (Co–C) and \(1492~{^{\circ }}\)C (Pd–C). This paper shows collections of thermocouple calibration results obtained during use of the high-temperature fixed-point cells at NPL and, as further examples, the use of cells installed at CCPI Europe (UK) and NIMT (Thailand). The lifetime of the cells can now be shown to be in excess of 7 years, whether used on a weekly or monthly basis, and whether used in an NMI or industrial calibration laboratory."
journal_title,International Journal of Thermophysics
article_title,Thermal Conductivity and Thermal Boundary Resistances of ALD Al$$_{2}$$2O$$_{3}$$3 Films on Si and Sapphire
keyword,"[None, None, 'Atomic layer deposition\xa0', 'Thermal boundary resistance\xa0', 'Thermal conductivity\xa0']"
history,"['2017-12', '2017-10-17', '2017-05-02', '2017-10-07']"
abstract,"Abstract On Si and sapphire substrates, 6–45 nm thick films of atomic layer-deposited Al\(_{2}\)O\(_{3}\) were grown. The thermal conductivity of ALD films has been determined from a linear relation between film thickness and thermal resistance measured by the 3\(\omega \) method. ALD films on Si and sapphire showed almost same thermal conductivity in the temperature range of 50–350 K. Residual thermal resistance was also obtained by extrapolation of the linear fit and was modeled as a sum of the thermal boundary resistances at heater–film and film–substrate interfaces. The total thermal resistance addenda for films on sapphire was close to independently measured thermal boundary resistance of heater–sapphire interface. From the result, it was deduced that the thermal boundary resistance at ALD Al\(_{2}\)O\(_{3}\)–sapphire interface was much lower than that of heater–film. By contrast, the films on Si showed significantly larger thermal boundary resistance than films on sapphire. Data of \(< 30\) nm films on Si were excluded because an AC coupling of electrical heating voltage to semiconductive Si complicated the relation between 3\(\omega \) voltage and temperature."
journal_title,International Journal of Thermophysics
article_title,Production and Characterization of Recycled Carbon from Phenol Resin Waste Using Supercritical Methanol
keyword,"['Amorphous carbon\xa0', 'Phenol resin\xa0', 'Recycle\xa0', 'Supercritical fluid\xa0']"
history,"['2017-12', '2017-10-16', '2017-04-30', '2017-10-07']"
abstract,"Abstract In this work, a recycling method for phenol resin (Bakelite) waste using supercritical methanol was investigated. Phenol resin is manufactured by the condensation reaction between phenol and formaldehyde to form insoluble and infusible three-dimensional reticulate structures. For this reason, these resins are mostly buried or incinerated as waste, and only a small percentage is reused as filler materials. In terms of reducing environmental pollution and improving waste management, the development of recycling technologies for phenol resin waste is necessary. In this study, phenol resin waste was treated with supercritical methanol over the 553.15–703.15 K temperature range and at pressures up to 20.6 MPa. As a result of this treatment, waste was decomposed into phenol and carbon particles. Carbon particles began from at temperatures and pressures above 603.15 K and 13.9 MPa, respectively. The sizes of the carbon particles obtained in this manner ranged from 1 to \(4~\upmu \hbox {m}\) and decreased with increasing temperature and pressure. These carbon particles had identical chemical and crystal structures and crystallinities to amorphous carbon. This recycled carbon can be used for the same purposes as existing amorphous carbon."
journal_title,International Journal of Thermophysics
article_title,Solubility of Nitroge n Gas i n Aqueous Solutio n of Tetra- n-Butylammo nium Bromide
keyword,"['Aqueous solution\xa0', 'Nitrogen\xa0', 'Semiclathrate hydrate\xa0', 'Solubility\xa0', None]"
history,"['2017-12', '2017-10-14', '2017-01-20', '2017-10-07']"
abstract,"Abstract Semiclathrate hydrates are water-based host-guest compounds formed from aqueous solutions of ionic guest substances. These materials can greatly moderate formation pressures and temperatures from canonical gas hydrates. This is a significant advantage for industrial applications such as gas separation and storage. \(\hbox {N}_{2}\) gas is a major component contained in various flue gases and is usually mixed with \(\hbox {CO}_{2}\). Semiclathrate hydrates can separate these gases under moderate thermodynamic conditions. Tetra-n-butylammonium bromide (TBAB) is a widely used ionic guest substance. To develop the application technologies and their theoretical models, solubility data of \(\hbox {N}_{2}\) gas in TBAB aqueous solutions are required. In this study, we report \(\hbox {N}_{2}\) gas solubility measured by an absolute gravimetric method for the semiclathrate hydrate formation system of \(\hbox {TBAB} + \hbox {H}_{2}\hbox {O} + \hbox {N}_{2}\). The measurement pressures, temperatures and TBAB mass fractions were 3 MPa, 5 MPa and 7 MPa, 292.15 K, 302.15 K and 307.15 K, and 0 (pure water), 0.10, 0.20, 0.32 and 0.40, respectively. The uncertainties were 0.056 MPa, 0.44 K and 0.00012 in mole fraction. Although the technical difficulty lays on measurements of small \(\hbox {N}_{2}\) gas solubility by the absolute gravimetric method, our data implied the unique gas dissolution property of aqueous TBAB solution depending on the TBAB concentration. The aqueous TBAB solutions with mass fractions of 0.10 and 0.20 had similar \(\hbox {N}_{2}\) gas solubility as that in pure water. With higher mass fractions, 0.32 and 0.40, the \(\hbox {N}_{2}\) gas solubility slightly increased from that in pure water, which implies the salting-in effect of TBAB."
journal_title,International Journal of Thermophysics
article_title,Stability Evaluation and Calibration of Type C Thermocouples at the Pt–C Eutectic Fixed Point
keyword,"['Calibration\xa0', 'Pt–C eutectic fixed point\xa0', 'Stability\xa0', 'Tungsten–rhenium thermocouple\xa0']"
history,"['2017-12', '2017-10-14', '2016-06-27', '2017-10-07']"
abstract,"Abstract Tungsten–rhenium thermocouples (type C thermocouples) are used to measure temperatures higher than 1500 \({^{\circ }}\)C under protective, inert, or vacuum conditions in a wide range of industries, such as metallurgy, power generation, and aerospace. Generally, the measurement uncertainty of a new tungsten–rhenium thermocouple is about 1 % (20 \({^{\circ }}\)C at 2000 \({^{\circ }}\)C), and a significant drift is always observed above 1200 \({^{\circ }}\)C. Recently, the National Institute of Metrology, China, has spent great efforts to calibrate tungsten–rhenium thermocouples with high-temperature fixed points of up to 2000 \({^{\circ }}\)C. In the present work, three tungsten–rhenium thermocouples made by two manufacturers were calibrated at the Pt–C eutectic fixed point (1738 \({^{\circ }}\)C) and their stability was investigated. A linear fitting and extrapolation method was developed to determine the melting and freezing temperatures of the Pt–C eutectic fixed point for avoiding the effect of thermal resistance caused by the sheath and protection tube. The results show that the repeatability of the calibration is better than 0.9 \({^{\circ }}\)C from the melting curve of the Pt–C fixed point and better than 1.2 \({^{\circ }}\)C from the freezing curve of the Pt–C fixed point, and a good agreement was obtained for the calibration with the melting and freezing temperature plateau through the linear fitting and extrapolation method. The calibration uncertainty of the thermocouples at the Pt–C eutectic fixed point was 3.1 \({^{\circ }}\)C (k \(=\) 2)."
journal_title,International Journal of Thermophysics
article_title,Macroscopic Thermal Rectification Device Using Vanadium Dioxide Thin Film
keyword,"['Thermal conductivity\xa0', 'Thermal rectification\xa0', 'Thin film\xa0', 'Vanadium dioxide\xa0']"
history,"['2017-11', '2017-10-13', '2017-04-27', '2017-10-04']"
abstract,"Abstract A thermal rectifier is a device in which heat flows in the forward direction but very little can flow in the opposite direction. Because the heat current can be controlled, the device is promising for future practical applications. In this study, the experiments were performed to investigate temperature-gated thermal rectification using macroscopic vanadium dioxide \((\hbox {VO}_{2})\) thin films deposited on an asymmetric substrate. The \(\hbox {VO}_{2}\) phase transition, occurred near 340 K, changed both the electrical and thermal properties. Therefore, we used these properties to investigate the thermal rectification. The \(\hbox {VO}_{2}\) thin films were prepared on cover glass substrates by RF sputtering with a \(\hbox {VO}_{2}\) disk target at \(500~{^{\circ }}\hbox {C}\). The morphology of the thin films was investigated. Silver paste and a copper band were used to connect the films with a heater and temperature controller. We observed thermal rectification in the temperature range of T = 310 K–370 K in several film samples obtained with different degrees of asymmetry, deposition times, and post-annealing times. It is found that \(60{^{\circ }}\) triangular-shaped samples have a rectification coefficient of 1.14, and the rectification coefficient is increased with the increasing of the angle. In addition, the two rectangular-shaped samples have the coefficient of 1.06, which could also be enhanced by increasing the ratio of width."
journal_title,International Journal of Thermophysics
article_title,Measurement of the Calorific Value of Methane by Calorimetry Using Metal Burner
keyword,"['Metal burner\xa0', 'Methane\xa0', 'Natural gas\xa0', 'Superior calorific value\xa0']"
history,"['2017-11', '2017-10-13', '2017-04-28', '2017-10-03']"
abstract,"Abstract With the diversification of natural gas origins and variations in natural gas compositions, the accurate measurement of the calorific value of natural gas has become a very important issue for the gas industry and standardization. Korea Research Institute of Standards and Science is developing a standard gas calorimeter based on the isoperibolic technique. This work describes the details of the experimental apparatus and procedures of the developed gas calorimeter along with the measurement results for the superior calorific value of methane at \(25\,^{\circ }\hbox {C}\). A burner made of stainless steel was used for the first time in this type of calorimeter, and the potential application of a metal burner to a gas calorimeter was investigated. Eight measurements were performed, and the deviation from international standards was 0.16 %. The deviation was mainly caused by the measurement of the burned methane gas. The measurement results show that the metal burner may potentially be employed in a gas calorimeter."
journal_title,International Journal of Thermophysics
article_title,Comparative Investigation on the Heat Transfer Characteristics of Gaseous $$\hbox {CO}_{2}$$CO2 and Gaseous Water Flowing Through a Single Granite Fracture
keyword,"['Flow and heat transfer\xa0', None, 'Gaseous water\xa0', 'HDR\xa0', 'Single fracture\xa0']"
history,"['2017-11', '2017-10-09', '2016-12-28', '2017-09-26']"
abstract,"Abstract  \(\hbox {CO}_{2}\) and water are two commonly employed heat transmission fluids in several fields. Their temperature and pressure determine their phase states, thus affecting the heat transfer performance of the water/\(\hbox {CO}_{2}\). The heat transfer characteristics of gaseous \(\hbox {CO}_{2}\) and gaseous water flowing through fractured hot dry rock still need a great deal of investigation, in order to understand and evaluate the heat extraction in enhanced geothermal systems. In this work, we develop a 2D numerical model to compare the heat transfer performance of gaseous \(\hbox {CO}_{2}\) and gaseous water flowing through a single fracture aperture of 0.2 mm in a \(\upphi 50\,\times 50\hbox { mm}\) cylindrical granite sample with a confining temperature of \(200\,^{\circ }\hbox {C}\) under different inlet mass flow rates. Our results indicate that: (1) the final outlet temperatures of the fluid are very close to the outer surface temperature under low inlet mass flow rate, regardless of the sample length. (2) Both the temperature of the fluid (gaseous \(\hbox {CO}_{2}\)/gaseous water) and inner surface temperature rise sharply at the inlet, and the inner surface temperature is always higher than the fluid temperature. However, their temperature difference becomes increasingly small. (3) Both the overall heat transfer coefficient (OHTC) and local heat transfer coefficient (LHTC) of gaseous \(\hbox {CO}_{2}\) and gaseous water increase with increasing inlet mass flow rates. (4) Both the OHTC and LHTC of gaseous \(\hbox {CO}_{2}\) are lower than those of gaseous water under the same conditions; therefore, the heat mining performance of gaseous water is superior to gaseous \(\hbox {CO}_{2}\) under high temperature and low pressure."
journal_title,International Journal of Thermophysics
article_title,Thermophysicochemical Reaction of ZrCo–Hydrogen–Helium System
keyword,"['Flow circulation\xa0', 'Hydrogen isotope storage and delivery system (SDS)\xa0', 'Hydrogen\xa0', 'Helium blanketing effect\xa0', 'Thermophysicochemical properties\xa0', 'Zirconium cobalt (ZrCo)\xa0']"
history,"['2017-11', '2017-10-05', '2017-04-28', '2017-09-04']"
abstract,"Abstract Nuclear fusion energy, which is clean and infinite, has been studied for more than half a century. Efforts are in progress worldwide for the demonstration and validation of nuclear fusion energy. Korea has been developing hydrogen isotope storage and delivery system (SDS) technologies including a basic scientific study on a hydrogen storage medium. An SDS bed, which is a key component of the SDS, is used for storing hydrogen isotopes in a metal hydride form and supplying them to a tokamak. Thermophysicochemical properties of the ZrCo–H\(_{2}\)–He system are investigated for the practical utilization of a hydriding alloy system. The hydriding reaction, in which \(\hbox {ZrCoH}_{\mathrm{x}}\) is composed as ZrCo absorbing hydrogen, is exothermic. The dehydriding reaction, in which \(\hbox {ZrCoH}_{\mathrm{x}}\) decomposes into ZrCo and hydrogen, is endothermic. The heat generated through the hydriding reaction interrupts the hydriding progress. The heat loss by a dehydriding reaction impedes the dehydriding progress. The tritium decay product, helium-3, covers the ZrCo and keeps the hydrogen from contact with ZrCo in the SDS bed. In this study, we designed and fabricated a ZrCo bed and its performance test rig. The helium blanketing effect on a ZrCo hydrogen reaction with 0 % to 20 % helium content in a gaseous phase and a helium blanket removal method were studied experimentally. In addition, the volumetric flow rates and temperature at the beginning of a ZrCo hydrogen reaction in a hydrogen or helium atmosphere, and the cooling of the SDS bed by radiation only and by both radiation and natural convection related to the reuse cycle, were obtained."
journal_title,International Journal of Thermophysics
article_title,First Interlaboratory Comparison on Calibration of Temperature-Controlled Enclosures in Turkey
keyword,"['Comparison\xa0', 'EURAMET cg-20\xa0', 'Temperature-controlled enclosure\xa0']"
history,"['2017-11', '2017-09-30', '2016-06-24', '2017-09-20']"
abstract,"Abstract The number of accredited laboratories in the field of calibration of temperature-controlled enclosures has been increasing in Turkey. One of the main criteria demonstrating the competence of a calibration laboratory is successful participation in interlaboratory comparisons. Therefore, TUBITAK UME Temperature Laboratory organized the first interlaboratory comparison on “Calibration of Temperature-Controlled Enclosures” in Turkey as a pilot laboratory between January and November, 2013. Forty accredited laboratories which provide routine calibration services to the industry in this field participated in the comparison. The standards used during the comparison was a climatic chamber for the measurements at \(-40\, {^{\circ }}\hbox {C},\,-20\, {^{\circ }}\hbox {C}, 40\, {^{\circ }}\hbox {C}\) and \(100\, {^{\circ }}\hbox {C}\) and an oven for the measurements at \(200\, {^{\circ }}\hbox {C}\). The protocol of the comparison was prepared considering guide EURAMET cg-20 and BS EN/IEC standards 600068-3-5 and 600068-3-11. During the comparison measurements, each participant had the liberty to choose the most convenient calibration points in terms of their accreditation scope among the values mentioned above and carried out on-site measurements at UME. The details and the results of this comparison are given in the paper. Determination of the statistical consistency of the results with the uncertainties given by the participants can be assessed by the method of \(E_{n}\) value assessment for each laboratory. \(E_{n}\) values for all measurement results based on the results of pilot and participating laboratories were calculated."
journal_title,International Journal of Thermophysics
article_title,Effect of Air Plasma Treatment on Thermal Comfort Properties of Woven Fabric
keyword,"['Air permeability\xa0', 'Plasma\xa0', 'Thermal comfort\xa0', 'Thermal resistance\xa0', 'Water vapor permeability\xa0']"
history,"['2017-11', '2017-09-13', '2017-03-27', '2017-09-04']"
abstract,"Abstract In this study, the effect of air plasma on thermal comfort properties of cotton woven fabric has been investigated. The woven fabric samples were treated with plasma under various parameters like treatment time, the distance between fabric sample and electrode, and frequency of the plasma process. It was observed that air permeability of the fabric has a linear relationship with distance of the sample, and inversely related to time and frequency. The thermal resistance and water vapor permeability decreased with distance and increased with time and frequency."
journal_title,International Journal of Thermophysics
article_title,Effect of Pressure on Deep-Ocean Thermometers
keyword,"['Deep-ocean thermometers\xa0', 'Pressure effect\xa0', 'Thermistors\xa0']"
history,"['2017-11', '2017-09-13', '2016-06-24', '2017-09-04']"
abstract,"Abstract A laboratory experiment was devised and performed to investigate the pressure dependence of Sea-Bird Electronics SBE35 and SBE3 deep-ocean thermometers. The thermometers were mounted in a massive brass comparator together with a calibrated standard platinum resistance thermometer. The measurements were performed in a pressure chamber in the pressure range 0.1 MPa to 60 MPa. The results showed that both the investigated SBE35 and SBE3 thermometers are pressure dependent, with a pressure sensitivity of +41 \(\upmu \)K\(\cdot \)MPa\(^{-1}\) and \(-77\) \(\upmu \)K\(\cdot \)MPa\(^{-1}\), respectively. Nevertheless, the results obtained in only one individual device per model (one SBE35 and one SBE3) cannot be generalized and further investigations of a larger number of devices per model are needed."
journal_title,International Journal of Thermophysics
article_title,Development of a 300 L Calibration Bath for Oceanographic Thermometers
keyword,"['Calibration bath\xa0', 'Comparison calibration\xa0', 'Stability\xa0', 'Uncertainty\xa0', 'Uniformity\xa0', 'Water temperature\xa0']"
history,"['2017-11', '2017-09-13', '2016-08-31', '2017-09-04']"
abstract,"Abstract The Japan Agency for Marine-Earth Science and Technology (JAMSTEC) has been developing a 300 L calibration bath to calibrate 24 oceanographic thermometers (OT) simultaneously and thereby reduce the calibration work load necessary to service more than 180 OT every year. This study investigated characteristics of the developed 300 L calibration bath using a SBE 3plus thermometer produced by an OT manufacturer. We also used 11 thermistor thermometers that were calibrated to be traceable to the international temperature scale of 1990 (ITS-90) within 1 mK of standard uncertainty through collaboration of JAMSTEC and NMIJ/AIST. Results  show that the time stability of temperature of the developed bath was within \(\pm 1 \,\hbox {mK}\). Furthermore, the temperature uniformity was \(\pm 1.3 \,\hbox {mK}\). The expanded uncertainty (\(k=2\)) components for the characteristics of the developed 300 L calibration bath were estimated as 2.9 mK, which is much less than the value of 10 mK: the required specification for uncertainty of calibration for the OT. These results demonstrated the utility of this 300 L calibration bath as a device for use with a new calibration system."
journal_title,International Journal of Thermophysics
article_title,A Simple Prediction Method for the Surface Tension of Ionic Liquids as a Function of Temperature
keyword,"['Density\xa0', 'Ionic liquids\xa0', 'Prediction\xa0', 'Surface tension\xa0', 'Temperature\xa0']"
history,"['2017-11', '2017-09-13', '2017-05-30', '2017-09-04']"
abstract,"Abstract In this study, a simple prediction method for the surface tension of ionic liquids (ILs) as a function of temperature is developed. Based on a database of experimental surface tension values collected from the literature, first a prediction scheme for the surface tension at a reference temperature of 298.15 K using only information on the density, molar mass, and anion type of the IL is suggested. By combination of this approach with the temperature dependence of the density, an extended prediction scheme describing the temperature dependence of the surface tension of ILs is recommended. The optimized prediction model for the surface tension allows for the prediction of about 3500 temperature-dependent experimental surface tension data of 226 different ILs with a standard deviation of about 7 %. In comparison with fluid-specific prediction methods found in the literature, the developed simple empirical prediction model requires only easily accessible parameters and can be applied for ILs with arbitrary cation and anion combinations. Thus, the proposed prediction method seems to be a valuable engineering tool for the quantitative estimation of the surface tension of ILs."
journal_title,International Journal of Thermophysics
article_title,Laser Fluence Recognition Using Computationally Intelligent Pulsed Photoacoustics Within the Trace Gases Analysis
keyword,"['Artificial neural networks\xa0', 'Laser beam profile\xa0', 'Laser fluence\xa0', 'Multiphoton processes\xa0', 'Photoacoustic spectroscopy\xa0']"
history,"['2017-11', '2017-09-13', '2016-01-12', '2017-09-04']"
abstract,"Abstract In this paper, the possibilities of computational intelligence applications for trace gas monitoring are discussed. For this, pulsed infrared photoacoustics is used to investigate \(\hbox {SF}_{6}\)–Ar mixtures in a multiphoton regime, assisted by artificial neural networks. Feedforward multilayer perceptron networks are applied in order to recognize both the spatial characteristics of the laser beam and the values of laser fluence \(\Phi \) from the given photoacoustic signal and prevent changes. Neural networks are trained in an offline batch training regime to simultaneously estimate four parameters from theoretical or experimental photoacoustic signals: the laser beam spatial profile R(r), vibrational-to-translational relaxation time \(\tau _{V-T} \), distance from the laser beam to the absorption molecules in the photoacoustic cell r* and laser fluence \(\Phi \). The results presented in this paper show that neural networks can estimate an unknown laser beam spatial profile and the parameters of photoacoustic signals in real time and with high precision. Real-time operation, high accuracy and the possibility of application for higher intensities of radiation for a wide range of laser fluencies are factors that classify the computational intelligence approach as efficient and powerful for the in situ measurement of atmospheric pollutants."
journal_title,International Journal of Thermophysics
article_title,"Erratum to: Correlations for the Dielectric Constants of $$\mathbf{H }_\mathbf{2 }\mathbf{S }$$H2S, $$\mathbf{SO }_\mathbf{2 }$$SO2, and $$\mathbf{SF }_\mathbf{6 }$$SF6"
keyword,[]
history,"['2017-10', '2017-09-11']"
abstract,None
journal_title,International Journal of Thermophysics
article_title,Development of the High-Temperature Dew-Point Generator Over the Past 15 Years
keyword,"['Calibration\xa0', 'Chilled mirror hygrometer\xa0', 'Dew-point generator\xa0', 'High temperature\xa0']"
history,"['2017-10', '2017-09-06', '2016-05-31', '2017-08-16']"
abstract,"Abstract At VSL a humidity generator was designed and constructed in the early 1990s. This generator was of the re-circulating-single-pressure type. Over the years, the generator has been thoroughly revised and several critical components have been replaced. Among others the pre-saturator and the change from re-circulation to single-pass mode. Validating experiments showed that the range of the new setup could be extended from \(70\,{^{\circ }}\hbox {C}\) to \(95\,{^{\circ }}\hbox {C}\) dew-point temperature, and the last modification allows an uncertainty of \(0.048\,{^{\circ }}\hbox {C}\) (k = 2) at the maximum temperature. In 2009 the setup was used in the Euramet-T-K8 humidity intercomparison at temperatures up to \(95\,{^{\circ }}\hbox {C}\). In the period from 2003 to 2015, four state-of-the-art chilled mirror hygrometers were regularly calibrated with the generator. One of these was also calibrated with the primary dew-point standards of several other European National Metrology Institutes, which made it possible to link the VSL generator to the generators used in these institutes. An analysis of the results of these calibrations shows an agreement in calibration capabilities within \(0.01\,{^{\circ }}\hbox {C}\) with PTB and NPL."
journal_title,International Journal of Thermophysics
article_title,Measurement of Out-of-Plane Thermal Conductivity of Epitaxial $$\hbox {YBa}_{2}\hbox {Cu}_{3}\hbox {O}_{7-{\delta }}$$YBa2Cu3O7-δ Thin Films in the Temperature Range from 10 K to 300 K by Photothermal Reflectance
keyword,"['Low temperature\xa0', 'Photothermal reflectance\xa0', 'Thermal conductivity\xa0', 'Thin film\xa0', 'YBCO\xa0']"
history,"['2017-10', '2017-09-05', '2017-02-01', '2017-08-27']"
abstract,"Abstract We measured the out-of-plane (c-axis) thermal conductivity of epitaxially grown \(\hbox {YBa}_{2}\hbox {Cu}_{3}\hbox {O}_{7-{\delta }}\) (YBCO) thin films (250 nm, 500 nm and 1000 nm) in the temperature range from 10 K to 300 K using the photothermal reflectance technique. The technique enables us to determine the thermal conductivity perpendicular to a thin film on a substrate by curve fitting analysis of the phase lag between the thermoreflectance signal and modulated heating laser beam in the frequency range from \(10^{2}\,\hbox {Hz}\) to \(10^{6}\,\hbox {Hz}\). The uncertainties of measured thermal conductivity of all samples were estimated to be within \({\pm }9\,\%\) at 300 K, \({\pm }12\,\%\) at 180 K, \({\pm }16\,\%\) at 90 K and \({\pm }20\,\%\) below 50 K. The experimental results show that the thermal conductivity is dependent on the thickness of the thin films across the entire temperature range. We also observed that the thermal conductivity of the present YBCO thin films showed \(T^{1.4}\) to \(T^{1.6}\) glass-like dependence below 50 K, even though the films are crystalline solids. In order to explain the reason for this temperature dependence, we attempted to analyze our results using phonon relaxation times for possible phonon scattering models, including stacking faults, grain boundary and tunneling states scattering models."
journal_title,International Journal of Thermophysics
article_title,Radiation Effects on the Thermodiffusive Instability of Premixed Flames on a Cylindrical Porous Flame Holder
keyword,"['Instability\xa0', 'Linear analysis\xa0', 'Premixed annular flames\xa0', 'Radiation heat loss\xa0']"
history,"['2017-10', '2017-09-05', '2016-09-19', '2017-08-14']"
abstract,"Abstract A linear analysis method was used to investigate the mechanics of radiation heat loss and mass transfer in the porous wall of premixed annular flames and their effect on thermodiffusive instability. The dispersion relation between the disturbance wave growth rate and wavenumber was calculated numerically. Results  showed that radiation heat loss elevated the annular flame slightly away from the porous wall. In the annular flame with small Lewis numbers, radiation heat loss changed the thermodiffusive instability from a pulsating to a cellular state, while for the large Lewis numbers, only the pulsating instability was represented. Increasing radiation heat loss and the radius of the porous wall enhanced the instability of the annular flames. Heat losses decreased with the continued increase in thickness of the porous wall and the decrease in porosity. Annular flames with long-wave mode along the angular direction were more unstable than the shortwave mode."
journal_title,International Journal of Thermophysics
article_title,Phase Behavior of Three PBX Elastomers in High-Pressure Chlorodifluoromethane
keyword,"['Alkyl acrylate copolymer (ACM)\xa0', 'Bubble point\xa0', 'Cloud point\xa0', 'Chlorodifluoromethane (HCFC22)\xa0', None, 'Polymer-bonded explosive (PBX)\xa0', 'Viton\xa0']"
history,"['2017-10', '2017-09-04', '2017-04-24', '2017-08-27']"
abstract,"Abstract The phase equilibrium behavior data are presented for three kinds of commercial polymer-bonded explosive (PBX) elastomers in chlorodifluoromethane (HCFC22). \(\hbox {Levapren}^{{\textregistered }}\) ethylene-co-vinyl acetate (LP-EVA), \(\hbox {HyTemp}^{{\textregistered }}\) alkyl acrylate copolymer (HT-ACM), and \(\hbox {Viton}^{{\textregistered }}\) fluoroelastomer (VT-FE) were used as the PBX elastomers. For each elastomer + HCFC22 system, the cloud point (CP) and/or bubble point (BP) pressures were measured while varying the temperature and elastomer composition using a phase equilibrium apparatus fitted with a variable-volume view cell. The elastomers examined in this study indicated a lower critical solution temperature phase behavior in the HCFC22 solvent. LP-EVA showed the CPs at temperatures of 323 K to 343 K and at pressures of 3 MPa to 10 MPa, whereas HT-ACM showed the CPs at conditions between 338 K and 363 K and between 4 MPa and 12 MPa. For the LP-EVA and HT-ACM elastomers, the BP behavior was observed at temperatures below about 323 K. For the VT-FE + HCFC22 system, only the CP behavior was observed at temperatures between 323 K and 353 K and at pressures between 6 MPa and 21 MPa. As the elastomer composition increased, the CP pressure increased, reached a maximum value at a specific elastomer composition, and then remained almost constant."
journal_title,International Journal of Thermophysics
article_title,"The Precise Measurement of Vapor–Liquid Equilibrium Properties of the CO$$_{2}$$2/Isopentane Binary Mixture, and Fitted Parameters for a Helmholtz Energy Mixture Model"
keyword,"['Bubble point pressure\xa0', None, 'Dew point pressure\xa0', 'Helmholtz energy\xa0', 'Measurement\xa0', 'Mixture model\xa0', 'Recirculation method\xa0', 'Vapor–liquid equilibrium\xa0']"
history,"['2017-10', '2017-09-01', '2016-11-30', '2017-08-01']"
abstract,"Abstract Natural working fluid mixtures, including combinations of CO\(_{2}\), hydrocarbons, water, and ammonia, are expected to have applications in energy conversion processes such as heat pumps and organic Rankine cycles. However, the available literature data, much of which were published between 1975 and 1992, do not incorporate the recommendations of the Guide to the Expression of Uncertainty in Measurement. Therefore, new and more reliable thermodynamic property measurements obtained with state-of-the-art technology are required. The goal of the present study was to obtain accurate vapor–liquid equilibrium (VLE) properties for complex mixtures based on two different gases with significant variations in their boiling points. Precise VLE data were measured with a recirculation-type apparatus with a 380 cm\(^{3}\) equilibration cell and two windows allowing observation of the phase behavior. This cell was equipped with recirculating and expansion loops that were immersed in temperature-controlled liquid and air baths, respectively. Following equilibration, the composition of the sample in each loop was ascertained by gas chromatography. VLE data were acquired for CO\(_{2}\)/ethanol and CO\(_{2}\)/isopentane binary mixtures within the temperature range from 300 K to 330 K and at pressures up to 7 MPa. These data were used to fit interaction parameters in a Helmholtz energy mixture model. Comparisons were made with the available literature data and values calculated by thermodynamic property models."
journal_title,International Journal of Thermophysics
article_title,Strain Modulation of Electronic and Heat Transport Properties of Bilayer Boronitrene
keyword,"['Boronitrene\xa0', 'First-principle calculations\xa0', 'Heat transfer\xa0']"
history,"['2017-10', '2017-08-31', '2016-10-09', '2017-08-14']"
abstract,"Abstract Strain engineering has been proven as an effective approach to modify electronic and thermal properties of materials. Recently, strain effects on two-dimensional materials have become important relevant topics in this field. We performed density functional theory studies on the electronic and heat transport properties of bilayer boronitrene samples under an isotropic strain. We demonstrate that the strain will reduce the band gap width but keep the band gap type robust and direct. The strain will enhance the thermal conductivity of the system because of the increase in specific heat. The thermal conductivity was studied as a function of the phonon mean-free path."
journal_title,International Journal of Thermophysics
article_title,Estimating Surface Temperature of a Calibration Apparatus for Contact Surface Thermometers from Its Internal Temperature Profile
keyword,"['Calibration apparatus\xa0', 'Measurement uncertainty\xa0', 'Surface temperature measurement\xa0', 'Surface thermometer\xa0']"
history,"['2017-10', '2017-08-31', '2016-08-31', '2017-08-16']"
abstract,"Abstract A calibration apparatus for contact surface thermometers was developed. Temperature of the upper surface of a copper cube of the calibration apparatus was used as reference surface temperature, which was estimated at around \(50\,{^{\circ }}\hbox {C}\), \(100\,{^{\circ }}\hbox {C}\), and \(150\,{^{\circ }}\hbox {C}\) by not only two conventional industrial platinum resistance thermometers (IPRTs) but also five small-sized platinum resistance thermometers (SSPRTs) calibrated based on the International Temperature Scale of 1990 (ITS-90). These thermometers were inserted horizontally into the copper cube and aligned along the center axis of the copper cube. In the case of a no-load state without anything on the upper surface, the temperature profile inside the copper cube linearly decreased from the lower part to the upper surface, which suggests that the heat conduction inside the copper cube can be regarded as a one-dimensional steady state. On the other hand, in the case of a transient state just after the contact surface thermometer was applied to the upper surface, the temperature profile became a round shape. We obtained good agreement between the curvature of the temperature profiles and the results estimated by using an error function used for a one-dimensional transient heat conduction problem. The temperature difference between the estimated temperature by linear extrapolation using two IPRTs and that by extrapolation using the error function was within \(0.2\,{^{\circ }}\hbox {C}\) in the transient state at around \(150\,{^{\circ }}\hbox {C}\). Over 10 min after the contact surface thermometer was applied, the temperature profile showed a linear shape again, which indicated that linear extrapolation using two IPRTs was well for the estimation of the reference surface temperature because the heat conduction state inside the copper cube came back to the one-dimensional steady state. Difference between the surface temperature and temperature detected by the contact surface thermometer was also observed after the contact surface thermometer touched on the upper surface. The difference was over \(0.1\,{^{\circ }}\hbox {C}\) at several minutes after the contact surface thermometer touching on the reference surface and was suppressed with passing time in the transient state and became negligible over 10 min."
journal_title,International Journal of Thermophysics
article_title,"Effect of Handling, Packing and Transportation on the Moisture of Timber Wood"
keyword,"['Effect of ambient humidity\xa0', 'Moisture content\xa0', 'Timber wood\xa0', 'Transportation\xa0', 'Wood handling\xa0']"
history,"['2017-10', '2017-08-29', '2016-05-31', '2017-08-16']"
abstract,"Abstract In order to improve the efficiency of moisture meters calibrations, we studied the effect of ambient humidity, sample handling, packing and transportation on the timber wood (spruce) moisture determination. It was proved by experiments that dry timber samples (\(12 \times 12 \times 2.5\) cm) reach equilibrium within 30–40 days even when moisturizing them at a high relative air humidity (80 %). On the other hand, the major mass loss of moist samples placed at normal laboratory conditions was found to occur during the first few days while the first 5 days are critical. The effects of sample handling, packing and transportation were studied by means of interlaboratory comparison between CMI, CETIAT, INRIM, NIS and KRISS. The obtained results show that samples with moisture content less than 7 % tend to absorb small amount of water, whereas samples with moisture content larger than 15 % tend to desorb small amount of water during the handling and transporting even when using vacuum packing and short handling times."
journal_title,International Journal of Thermophysics
article_title,Quality Assurance of Rice and Paddy Moisture Measurements in Thailand
keyword,"['Bilateral comparison\xa0', 'Moisture content\xa0', 'Quality assurance\xa0']"
history,"['2017-10', '2017-08-29', '2016-06-30', '2017-08-16']"
abstract,"Abstract A bilateral comparison in moisture measurement between the National Institute of Metrology Thailand (NIMT) and the Central Bureau of Weights and Measures (CBWM) was organized for quality assuring of rice and paddy moisture measurement in Thailand. The bilateral comparison was conducted by using the same batch of sample and moisture meter as transfer device. It consisted of two parts: moisture measurement in rice and in paddy. A rice moisture meter belonging to CBWM and rice standards prepared at the nominal moisture content of 10 %, 12 %, 14 % and 16 % at NIMT, were used for rice moisture comparison, while a paddy moisture meter belonging to NIMT and paddy standards prepared at the nominal moisture content of 12 %, 14 %, 16 % and 18 % at CBWM, were used for paddy moisture comparison. Both laboratories measured the moisture content of a sample by using the standard method in ISO 712 and used that sample to calibrate a moisture meter by means of the method based on ISO 7700-1. Since the moisture content of the sample can change during the comparison, correction values in moisture content between the standard value and the reading value from the moisture meter are used as calibration results for the comparison evaluation. For the rice moisture comparison, differences in the correction value measured by the two laboratories vary from 0.18 % to 0.46 %, with their combined comparison uncertainty of 0.37 % (\(\hbox {k}= 2)\). The main contribution to the difference comes from the standard values from both laboratories differing from 0.27 % to 0.53 %, as the rice standard was found to drift in moisture content less than 0.05 %. Similarly to the rice moisture comparison, differences in the correction value for the paddy moisture measurement range from 0.08 % to 0.56 % with the combined comparison uncertainty of 0.38  % (\(\hbox {k} = 2)\), whereas the stability in moisture content of the paddy sample at NIMT was found to be within 0.12 %."
journal_title,International Journal of Thermophysics
article_title,Electrical and Thermal Characteristics of the Insulator–Metal Transition in Crystalline $$\hbox {V}_{2}\hbox {O}_{5}$$V2O5 Films
keyword,"['Electrical properties\xa0', 'Nanosecond thermoreflectance\xa0', 'Thermal diffusivity\xa0', 'Vanadium pentoxide\xa0']"
history,"['2017-10', '2017-08-28', '2017-04-26', '2017-08-16']"
abstract,"Abstract The electrical and thermal properties with respect to the crystallization in \(\hbox {V}_{2}\hbox {O}_{5}\) thin films were investigated by measuring the resistance at different temperatures and applied voltages. The changes in the crystal structure of the films at different temperatures were also explored using Raman measurements. The thermal diffusivity of the crystalline \(\hbox {V}_{2}\hbox {O}_{5}\) film was measured by the nanosecond thermoreflectance method. The microstructures of amorphous and crystalline \(\hbox {V}_{2}\hbox {O}_{5}\) were observed by SEM and XRD measurements. The temperature-dependent Raman spectra revealed that a structural phase transition does not occur in the crystalline film. The resistance measurements of an amorphous film indicated semiconducting behavior, whereas the resistance of the crystalline film revealed a substantial change near \(250\,{^{\circ }}\hbox {C}\), and Ohmic behavior was observed above \(380\,{^{\circ }}\hbox {C}\). This result was due to the metal–insulator transition induced by lattice distortion in the crystalline film, for which \(T_{\mathrm{c}}\) was \(260\,{^{\circ }}\hbox {C}\). \(T_{\mathrm{c}}\) of the film decreased from 260 \({^{\circ }}\hbox {C}\) to \(230\,{^{\circ }}\hbox {C}\) with increasing applied voltage from 0 V to 10 V. Furthermore, the thermal diffusivity of the crystalline film was \(1.67\times 10^{-7}\,\hbox {m}^{2}\cdot \hbox {s}^{-1}\) according to the nanosecond thermoreflectance measurements."
journal_title,International Journal of Thermophysics
article_title,Thermal Conductivity and Raman Spectra of Carbon Fibers
keyword,"['Thermal conductivity\xa0', 'Thermal diffusivity\xa0', 'Transient electrothermal technique\xa0', 'Raman spectrum\xa0']"
history,"['2017-10', '2017-08-23', '2016-09-13', '2017-07-14']"
abstract,"Abstract Due to its unique physical properties, carbon fiber (CF) has been widely studied for extensive application in aerospace and machinery. In this study, the thermal diffusivity of three kinds of CF sample is characterized by the transient electrothermal technique at room temperature. By subtracting the effect of radiative losses, the effective thermal diffusivity of CFs can be calculated as \(6.46\times 10^{-6}\,\hbox {m}^{2}\cdot \hbox {s}^{-1}\), \(6.58\times 10^{-6}\,\hbox {m}^{2}\cdot \hbox {s}^{-1}\) and \(2.01\times 10^{-4}\,\hbox {m}^{2}\cdot \hbox {s}^{-1}\), respectively. For the first time, the emissivity coefficient of carbon fiber is calibrated as 0.78. Combined with Raman spectra and phonon scattering, we found that the better crystalline structure and low defect in CF have an obvious impact on its thermal diffusivity."
journal_title,International Journal of Thermophysics
article_title,Experimental Investigation on the Specific Heat of Carbonized Phenolic Resin-Based Ablative Materials
keyword,"['Carbon/phenolic composite\xa0', 'Carbonized ablators\xa0', '3D DSC\xa0', 'High silica/phenolic composite\xa0', 'Specific heat\xa0']"
history,"['2017-10', '2017-08-23', '2016-09-29', '2017-08-14']"
abstract,"Abstract As typical phenolic resin-based ablative materials, the high silica/phenolic and carbon/phenolic composites are widely used in aerospace field. The specific heat of the carbonized ablators after ablation is an important thermophysical parameter in the process of heat transfer, but it is rarely reported. In this investigation, the carbonized samples of the high silica/phenolic and carbon/phenolic were obtained through carbonization experiments, and the specific heat of the carbonized samples was determined by a 3D DSC from 150 \(^{\circ }\hbox {C}\) to 970 \(^{\circ }\hbox {C}\). Structural and compositional characterizations were performed to determine the mass fractions of the fiber and the carbonized product of phenolic which are the two constituents of the carbonized samples, while the specific heat of each constituent was also measured by 3D DSC. The masses of the carbonized samples were reduced when heated to a high temperature in the specific heat measurements, due to the thermal degradation of the carbonized product of phenolic resin in the carbonized samples. The raw experimental specific heat of the two carbonized samples and the carbonized product of phenolic resin was modified according to the quality changes of the carbonized samples presented by TGA results. Based on the mass fraction and the specific heat of each constituent, a weighted average method was adopted to obtain the calculated results of the carbonized samples. Due to the unconsolidated property of the fiber samples which impacts the reliability of the DSC measurement, there is a certain deviation between the experimental and calculated results of the carbonized samples. Considering the similarity of composition and structure, the data of quartz glass and graphite were used to substitute the specific heat of the high silica fiber and carbon fiber, respectively, resulting in better agreements with the experimental ones. Furthermore, the accurate specific heat of the high silica fiber and carbon fiber bundles was obtained by inversion, enabling the prediction of the specific heat of the carbonized ablators with different constituent mass fractions by means of the weighted average method in engineering."
journal_title,International Journal of Thermophysics
article_title,Establishment of a New National Reference Ensemble of Water Triple Point Cells
keyword,"['Calibration\xa0', 'ITS-90\xa0', 'National reference\xa0', 'water triple point cells\xa0']"
history,"['2017-10', '2017-08-18', '2016-08-31', '2017-08-01']"
abstract,"Abstract The results of the Bilateral Comparison EURAMET.T-K3.5 (w/VSL, The Netherlands) with the goal to link Switzerland’s ITS-90 realization (Ar to Al) to the latest key comparisons gave strong indications for a discrepancy in the realization of the triple point of water. Due to the age of the cells of about twenty years, it was decided to replace the complete reference ensemble with new “state-of-the-art” cells. Three new water triple point cells from three different suppliers were purchased, as well as a new maintenance bath for an additional improvement of the realization. In several loops measurements were taken, each cell of both ensembles intercompared, and the deviations and characteristics determined. The measurements show a significant lower average value of the old ensemble of \(0.59 \pm 0.25\hbox { mK }(k=2)\) in comparison with the new one. Likewise, the behavior of the old cells is very unstable with a drift downward during the realization of the triple point. Based on these results the impact of the new ensemble on the ITS-90 realization from Ar to Al was calculated and set in the context to performed calibrations and their related uncertainties in the past. This paper presents the instrumentation, cells, measurement procedure, results, uncertainties and impact of the new national reference ensemble of water triple point cells on the current ITS-90 realization in Switzerland."
journal_title,International Journal of Thermophysics
article_title,Unleashing Empirical Equations with “Nonlinear Fitting” and “GUM Tree Calculator”
keyword,"['Correlation\xa0', 'Covariance\xa0', 'Empirical equations\xa0', 'Generalized least squares\xa0', 'Propagation of uncertainty\xa0']"
history,"['2017-10', '2017-08-18', '2016-10-31', '2017-08-01']"
abstract,"Abstract Empirical equations having large numbers of fitted parameters, such as the international standard reference equations published by the International Association for the Properties of Water and Steam (IAPWS), which form the basis of the “Thermodynamic Equation of Seawater—2010” (TEOS-10), provide the means to calculate many quantities very accurately. The parameters of these equations are found by least-squares fitting to large bodies of measurement data. However, the usefulness of these equations is limited since uncertainties are not readily available for most of the quantities able to be calculated, the covariance of the measurement data is not considered, and further propagation of the uncertainty in the calculated result is restricted since the covariance of calculated quantities is unknown. In this paper, we present two tools developed at MSL that are particularly useful in unleashing the full power of such empirical equations. “Nonlinear Fitting” enables propagation of the covariance of the measurement data into the parameters using generalized least-squares methods. The parameter covariance then may be published along with the equations. Then, when using these large, complex equations, “GUM Tree Calculator” enables the simultaneous calculation of any derived quantity and its uncertainty, by automatic propagation of the parameter covariance into the calculated quantity. We demonstrate these tools in exploratory work to determine and propagate uncertainties associated with the IAPWS-95 parameters."
journal_title,International Journal of Thermophysics
article_title,Thermal Conductivity Measurement of Liquids by Using a Suspended Microheater
keyword,"['3 Omega method\xa0', 'Bulk microfabrication\xa0', 'Liquid thermal conductivity\xa0', 'Microheater on a suspended bridge\xa0']"
history,"['2017-10', '2017-08-16', '2017-05-02', '2017-08-01']"
abstract,"Abstract In this paper, the traditional \(3\omega \) method is modified in order to measure the thermal conductivity of a droplet of liquid. The \(3\omega \) sensor is microfabricated using bulk silicon etching on a silicon wafer to form a microheater on a suspended bridge structure. The Si substrate of over 400 \(\upmu \hbox {m}\) thickness beneath the microheater is etched away so that the sample liquid can fill the gap created between the heater and the bottom boundary of the sensor. The frequency of the sinusoidal heating pulses that are generated from the heater is controlled such that the thermal penetration depth is much smaller than the thickness of the liquid layer. The temperature oscillation of the sample fluid is measured at the thin-film heater to calculate the thermal conductivity of the surrounding fluid. The thermal conductivity and measured values of the de-ionized water and ethanol show a good agreement with the theoretical values at room temperature."
journal_title,International Journal of Thermophysics
article_title,Thermal Analysis of Thermal Protection System of Test Launch Vehicle
keyword,"['Plume\xa0', 'Radiation\xa0', 'Test launch vehicle\xa0', 'Thermal protection system\xa0']"
history,"['2017-10', '2017-08-16', '2017-04-12', '2017-08-01']"
abstract,"Abstract In this paper, a thermal analysis of the thermal protection system (TPS) of test launch vehicle (TLV) is explained. TLV is heated during the flight due to engine exhaust plume gas by thermal radiation and a TPS is needed to protect the vehicle from the heating. The thermal analysis of the TPS is conducted to predict the heat flux from plume gas and temperature of the TPS during the flight. To simplify the thermal analysis, plume gas radiation and radiative properties are assumed to be surface radiation and constants, respectively. Thermal conductivity, emissivity and absorptivity of the TPS material are measured. Proper plume conditions are determined from the preliminary analysis and then the heat flux and temperature of the TPS are calculated."
journal_title,International Journal of Thermophysics
article_title,Thermodynamic Temperature of High-Temperature Fixed Points Traceable to Blackbody Radiation and Synchrotron Radiation
keyword,"['Absolute radiometry\xa0', 'Blackbody radiation\xa0', 'Cryogenic substitution radiometer\xa0', 'Filter radiometer\xa0', 'High-temperature fixed points\xa0', 'Irradiance mode\xa0', 'Primary radiation standards\xa0', 'Ratio radiometry\xa0', 'Synchrotron radiation\xa0', 'Thermodynamic temperature\xa0']"
history,"['2017-10', '2017-08-16', '2016-09-13', '2017-07-14']"
abstract,"Abstract Absolute spectral radiometry is currently the only established primary thermometric method for the temperature range above 1300 K. Up to now, the ongoing improvements of high-temperature fixed points and their formal implementation into an improved temperature scale with the mise en pratique for the definition of the kelvin, rely solely on single-wavelength absolute radiometry traceable to the cryogenic radiometer. Two alternative primary thermometric methods, yielding comparable or possibly even smaller uncertainties, have been proposed in the literature. They use ratios of irradiances to determine the thermodynamic temperature traceable to blackbody radiation and synchrotron radiation. At PTB, a project has been established in cooperation with VNIIOFI to use, for the first time, all three methods simultaneously for the determination of the phase transition temperatures of high-temperature fixed points. For this, a dedicated four-wavelengths ratio filter radiometer was developed. With all three thermometric methods performed independently and in parallel, we aim to compare the potential and practical limitations of all three methods, disclose possibly undetected systematic effects of each method and thereby confirm or improve the previous measurements traceable to the cryogenic radiometer. This will give further and independent confidence in the thermodynamic temperature determination of the high-temperature fixed point’s phase transitions."
journal_title,International Journal of Thermophysics
article_title,"Correlations for the Dielectric Constants of $$\hbox {H}_{2}\hbox {S}$$H2S, $$\hbox {SO}_{2}$$SO2, and $$\hbox {SF}_{6}$$SF6"
keyword,"['Dielectric constant\xa0', 'Hydrogen sulfide\xa0', 'Molecular dynamics\xa0', 'Relative permittivity\xa0', 'Sulfur dioxide\xa0', 'Sulfur hexafluoride\xa0']"
history,"['2017-10', '2017-08-16', '2017-05-01', '2017-08-01']"
abstract,"Abstract A new method is developed for correlating the static dielectric constant of polar fluids over wide ranges of conditions where few experimental data exist. Molecular dynamics simulations are used to establish the temperature and density dependence of the Kirkwood g-factor, and also the functional form for the increase of the effective dipole moment with density. Most parameters in the model are obtained entirely from simulation; a single proportionality constant is adjusted to obtain agreement with the limited experimental data. The method is applied to hydrogen sulfide (\(\hbox {H}_{2}\hbox {S}\)) and sulfur dioxide \((\hbox {SO}_{2})\), both of which are important in geochemistry but have only a few dielectric data available. The resulting correlations agree well with the available liquid data, obey physical boundary conditions at low density and at high temperature, and interpolate in density and temperature in a physically reasonable manner. In addition, we present a more conventional correlation for the dielectric constant of sulfur hexafluoride, \(\hbox {SF}_{6}\), where more data are available."
journal_title,International Journal of Thermophysics
article_title,High-Temperature Thermal Conductivity Measurement Apparatus Based on Guarded Hot Plate Method
keyword,"['Heat transfer\xa0', 'High-temperature guarded hot plate\xa0', 'Thermal conductivity\xa0', 'Thermal contact resistance\xa0']"
history,"['2017-10', '2017-08-12', '2016-06-23', '2017-08-01']"
abstract,"Abstract An alternative calibration procedure has been applied using apparatus built in-house, created to optimize thermal conductivity measurements. The new approach compared to those of usual measurement procedures of thermal conductivity by guarded hot plate (GHP) consists of modified design of the apparatus, modified position of the temperature sensors and new conception in the calculation method, applying the temperature at the inlet section of the specimen instead of the temperature difference across the specimen. This alternative technique is suitable for eliminating the effect of thermal contact resistance arising between a rigid specimen and the heated plate, as well as accurate determination of the specimen temperature and of the heat loss at the lateral edge of the specimen. This paper presents an overview of the specific characteristics of the newly developed “high-temperature thermal conductivity measurement apparatus” based on the GHP method, as well as how the major difficulties are handled in the case of this apparatus, as compared to the common GHP method that conforms to current international standards."
journal_title,International Journal of Thermophysics
article_title,Thermodynamic Investigation of the Eutectic Mixture of the $$\hbox {LiNO}_{3}$$LiNO3–$$\hbox {NaNO}_{3}$$NaNO3–$$\hbox {KNO}_{3}$$KNO3–$$\hbox {Ca}(\hbox {NO}_{3})_{2}$$Ca(NO3)2 System
keyword,"['Differential scanning calorimetry (DSC)\xa0', 'Eutectic mixture\xa0', 'Molten nitrate salts\xa0', 'Thermodynamic modeling\xa0']"
history,"['2017-09', '2017-08-09', '2016-12-23', '2017-08-01']"
abstract,"Abstract Molten nitrate salt is usually employed as heat transfer or energy storage medium in concentrating solar power systems to improve the overall efficiency of thermoelectric conversion. In the present work, the liquidus curves of the \(\hbox {LiNO}_{3}\)–\(\hbox {NaNO}_{3}\)–\(\hbox {KNO}_{3}\)–\(\hbox {Ca}(\hbox {NO}_{3})_{2}\) system is determined by conformal ionic solution theory according to the solid–liquid equilibrium state of the binary mixture. The calculated eutectic temperature of the mixture is \(93.17\,{^{\circ }}\hbox {C}\), which is close to the experimental value of \(93.22\,{^{\circ }}\hbox {C}\) obtained from differential scanning calorimetry (DSC). Visualization observation experiments reveal that the quaternary eutectic mixture begins to partially melt when the temperature reaches \(50\,{^{\circ }}\hbox {C}\), and the degree of melting increases with temperature. The mixture is completely melted at \(\hbox {130}\,{^{\circ }}\hbox {C}\). The observed changes in the dissolved state at different temperatures correlate well with the DSC heat flow curve fluctuations."
journal_title,International Journal of Thermophysics
article_title,A Slimline Integrated Self-Validating Thermocouple: Initial Results
keyword,"['Calibration\xa0', 'HTFP\xa0', 'Integrated\xa0', 'Self-validating\xa0', 'Thermocouple\xa0']"
history,"['2017-09', '2017-08-03', '2016-09-05', '2017-07-14']"
abstract,"Abstract NPL, in collaboration with CCPI Europe, have designed a slimline integrated self-validating (“inseva”) thermocouple with the same external form factor as conventional thermocouples, with the aim of making them suitable as direct replacements for existing thermocouples in process. Type S thermocouples have been manufactured in recrystallized alumina-sheathed assemblies, with Cu and Co–C reference ingots, with an outer diameter of 7 mm. The new slimline inseva thermocouple is, in principle, suitable for use in the same positions and conditions as the conventional thermocouple which it replaces. This paper reports the initial reference ingot melt and freeze plateaus successfully observed using the first inseva thermocouples, and demonstrates observation of furnace sensitivity and ramp rate sensitivity of the plateau temperatures."
journal_title,International Journal of Thermophysics
article_title,Thermal Conductivity of Manganin Between 10 mK and 54 mK
keyword,"['Thermal conductivity\xa0', 'Very low temperature\xa0', 'Manganin\xa0']"
history,"['2017-09', '2017-07-26', '2016-08-26', '2017-07-14']"
abstract,"Abstract The thermal conductivity of Manganin (Cu 86 %, Ni 2 %, Mn 12 %) in the range 10–50 mK was measured by means of a new method that uses a metal–insulator junction (M-I.J) of known characteristics to read temperatures at one end of the sample. The same power P that crosses the sample to measure its thermal resistance flows through the M-I.J. A suitable choice of the M-I.J allows the temperature T of the upper end of the sample to rise above 20 mK. T was measured by a small size Ruthenium thermometer."
journal_title,International Journal of Thermophysics
article_title,Effects of Beryllium and Compaction Pressure on the Thermal Diffusivity of Uranium Dioxide Fuel Pellets
keyword,"['Beryllium oxide\xa0', 'Laser flash method\xa0', 'Thermal diffusivity\xa0', 'Uranium dioxide\xa0']"
history,"['2017-09', '2017-07-25', '2016-06-29', '2017-07-14']"
abstract,"Abstract In nuclear reactors, the performance of uranium dioxide \((\hbox {UO}_{2})\) fuel is strongly dependent on the thermal conductivity, which directly affects the fuel pellet temperature, the fission gas release and the fuel rod mechanical behavior during reactor operation. The use of additives to improve \(\hbox {UO}_{2}\) fuel performance has been investigated, and beryllium oxide (BeO) appears as a suitable additive because of its high thermal conductivity and excellent chemical compatibility with \(\hbox {UO}_{2}\). In this paper, \(\hbox {UO}_{2}\)–BeO pellets were manufactured by mechanical mixing, pressing and sintering processes varying the BeO contents and compaction pressures. Pellets with BeO contents of 2 wt%, 3 wt%, 5 wt% and 7 wt% BeO were pressed at 400 MPa, 500 MPa and 600 MPa. The laser flash method was applied to determine the thermal diffusivity, and the results showed that the thermal diffusivity tends to increase with BeO content. Comparing thermal diffusivity results of \(\hbox {UO}_{2}\) with \(\hbox {UO}_{2}\)–BeO pellets, it was observed that there was an increase in thermal diffusivity of at least 18 % for the \(\hbox {UO}_{2}\)-2 wt% BeO pellet pressed at 400 MPa. The maximum relative expanded uncertainty (coverage factor k = 2) of the thermal diffusivity measurements was estimated to be 9 %."
journal_title,International Journal of Thermophysics
article_title,Photothermal Mirror Method for the Study of Thermal Diffusivity and Thermo-Elastic Properties of Opaque Solid Materials
keyword,"['Photothermal effect\xa0', 'Photothermal mirror method\xa0', 'Photothermal properties of materials\xa0', 'Thermal diffusivity of materials\xa0']"
history,"['2017-09', '2017-07-25', '2017-03-23', '2017-07-14']"
abstract,"Abstract We have carried out the theoretical and experimental time evolution and amplitude study of the photothermal mirror signal generated by focusing a laser beam on the surface of a suite of solid samples. Based on a theoretical model that resolves the thermal diffusivity equation and the equation for thermo-elastic deformations simultaneously, we have calculated the transient time evolution and amplitude of the signal. We observe the same time evolution pattern for samples as diverse as glass, quartz, metals, and synthetic ceramic oxides. The data have yielded a linear dependence between the time build-up of the thermal mirror and the inverse of the thermal diffusivity for all the samples. For moderate power levels, we also observe a linear behavior between the stationary value of the signal and the thermally induced phase shift value. From the calibration curves, we have determined the thermally induced phase and the thermal diffusivity coefficients of two prospective nuclear reactor control rod materials, dysprosium titanate (\(\hbox {Dy}_{2}\hbox {TiO}_{5}\)) and dysprosium dititanate (\(\hbox {Dy}_{2}\hbox {Ti}_{2}\hbox {O}_{7}\)) to be \(D = (7.0 \pm 0.4) \times 10^{-7} \mathrm{m^{2}\cdot s^{-1}}\)."
journal_title,International Journal of Thermophysics
article_title,Performance of Different Light Sources for the Absolute Calibration of Radiation Thermometers
keyword,"['Absolute radiometry\xa0', 'Radiance method\xa0', 'Radiometer\xa0', 'Standard radiation thermometer\xa0', 'Thermodynamic temperature\xa0', 'Uncertainty\xa0']"
history,"['2017-09', '2017-07-25', '2016-06-23', '2017-07-14']"
abstract,"Abstract The evolving mise en pratique for the definition of the kelvin (MeP-K) [1, 2] will, in its forthcoming edition, encourage the realization and dissemination of the thermodynamic temperature either directly (primary thermometry) or indirectly (relative primary thermometry) via fixed points with assigned reference thermodynamic temperatures. In the last years, the Centro Español de Metrología (CEM), in collaboration with the Instituto de Óptica of Consejo Superior de Investigaciones Científicas (IO-CSIC), has developed several setups for absolute calibration of standard radiation thermometers using the radiance method to allow CEM the direct dissemination of the thermodynamic temperature and the assignment of the thermodynamic temperatures to several fixed points. Different calibration facilities based on a monochromator and/or a laser and an integrating sphere have been developed to calibrate CEM’s standard radiation thermometers (KE-LP2 and KE-LP4) and filter radiometer (FIRA2). This system is based on the one described in [3] placed in IO-CSIC. Different light sources have been tried and tested for measuring absolute spectral radiance responsivity: a Xe-Hg 500 W lamp, a supercontinuum laser NKT SuperK-EXR20 and a diode laser emitting at 6473 nm with a typical maximum power of 120 mW. Their advantages and disadvantages have been studied such as sensitivity to interferences generated by the laser inside the filter, flux stability generated by the radiant sources and so forth. This paper describes the setups used, the uncertainty budgets and the results obtained for the absolute temperatures of Cu, Co-C, Pt-C and Re-C fixed points, measured with the three thermometers with central wavelengths around 650 nm."
journal_title,International Journal of Thermophysics
article_title,On the Interpretation of Near-Critical Gas–Liquid Heat Capacities
keyword,"['Argon\xa0', 'Critical point\xa0', 'Isochoric heat capacity\xa0', 'Vapor–liquid coexistence\xa0']"
history,"['2017-09', '2017-07-25', '2017-05-02', '2017-07-14']"
abstract,"Abstract This comment is in response to a comment by Sengers and Anisimov on the article “Gibbs density surface of fluid argon” that contradicts prevailing theory. It has not “been established experimentally that the thermodynamic properties of fluids satisfy scaling laws with universal critical exponents asymptotically close to a single critical point of the vapor–liquid phase transition.” Here we explain why an apparent divergence of \(\hbox {C}_{\mathrm{v}}\), in historical experimental “evidence,” is based upon a misinterpretation of near-critical gas–liquid heat capacity measurements in the two-phase coexistence region. The conclusion that there is no “singular critical point” on Gibbs density surface still stands."
journal_title,International Journal of Thermophysics
article_title,Seebeck Changes Due to Residual Cold-Work and Reversible Effects in Type K Bare-Wire Thermocouples
keyword,"['Base-metal\xa0', 'Cold-work\xa0', 'Drift\xa0', 'Hysteresis\xa0', 'Inhomogeneity\xa0', 'Scanning\xa0', 'Short-range ordering\xa0', 'Thermocouples\xa0', 'Type K\xa0']"
history,"['2017-09', '2017-07-18', '2016-12-06', '2017-07-03']"
abstract,"Abstract Type K thermocouples are the most commonly used thermocouple for industrial measurements because of their low cost, wide temperature range, and durability. As with all base-metal thermocouples, Type K is made to match a mathematical temperature-to-emf relationship and not a prescribed alloy formulation. Because different manufacturers use varying alloy formulations and manufacturing techniques, different Type K thermocouples exhibit a range of drift and hysteresis characteristics, largely due to ordering effects in the positive (K+) thermoelement. In this study, these effects are assessed in detail for temperatures below \(700\, {^{\circ }}\hbox {C}\) in the Type K wires from nine manufacturers. A linear gradient furnace and a high-resolution homogeneity scanner combined with the judicious use of annealing processes allow measurements that separately identify the effects of cold-work, ordering, and oxidation to be made. The results show most K+ alloys develop significant errors, but the magnitudes of the contributions of each process vary substantially between the different K+ wires. In practical applications, the measurement uncertainties achievable with Type K therefore depend not only on the wire formulation but also on the temperature, period of exposure, and, most importantly, the thermal treatments prior to use."
journal_title,Science China Information Sciences
article_title,Efficient flush-reload cache attack on scalar multiplication based signature algorithm
keyword,[]
history,"['2018-03', '2018-08-16', '2017-02-20', '2017-05-09', '2017-05-19']"
abstract,None
journal_title,Science China Information Sciences
article_title,Evaluation of redundancy-based system: a model checking approach
keyword,[]
history,"['2018-06', '2018-03-28', '2016-12-14', '2017-06-10', '2017-07-24']"
abstract,None
journal_title,Science China Information Sciences
article_title,Energy efficient power allocation for underlaying mobile D2D communications with peak/average interference constraints
keyword,[]
history,"['2018-08', '2018-03-21', '2017-12-26', '2018-01-29', '2018-02-11']"
abstract,None
journal_title,Science China Information Sciences
article_title,Network protocol architectures for future deep-space internetworking
keyword,"['network protocol architecture\xa0', 'deep-space internetworking\xa0', 'deep-space communications\xa0', 'space internetworking\xa0', 'delay-tolerant networking\xa0']"
history,"['2018-04', '2018-03-19', '2018-02-27', '2018-03-08', '2018-03-15']"
abstract,"Abstract In the next two decades, humans are going to experience a grand age of deep-space exploration, especially in Mars and Lunar spaces. These relatively frequent and long-term activities provide the opportunity, and at the same time, demands the necessity for a true interplanetary network as an essential infrastructure for future deep-space exploration. In this study, we try to provide a picture and a perspective in the current network protocol architectures for future deep-space internetworking. We first investigate the recent technical advances for deep-space internetworking and the challenges to their network protocol architecture. Detailed technical characteristics of three effective network protocol architectures are presented. A special focus is casted on delay tolerant networking (DTN), which is a dedicated network protocol architecture for deep-space internetworking. Finally, several open questions in DTN for future deep-space internetworking are proposed for further study."
journal_title,Science China Information Sciences
article_title,Packing unequal circles into a square container based on the narrow action spaces
keyword,[]
history,"['2018-04', '2018-03-16', '2017-03-22', '2017-08-16']"
abstract,None
journal_title,Science China Information Sciences
article_title,Distribution-dependent concentration inequalities for tighter generalization bounds
keyword,[]
history,"['2018-04', '2018-03-16', '2017-04-09', '2017-08-16', '2017-08-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,Novel distributed UEP rateless coding scheme for data transmission in deep space networks
keyword,"['deep space networks\xa0', 'distributed rateless codes\xa0', 'UEP\xa0', 'encoding overhead\xa0', 'asymptotic analysis\xa0', 'design complexity\xa0']"
history,"['2018-04', '2018-03-07', '2017-09-15', '2017-12-13']"
abstract,"Abstract In deep space data transmission systems, deep space networks can be constructed on different orbits, and the data from each orbit are always associated with the different reliability requirements. In this study, a novel UEP (unequal error protection) transmission scheme based on distributed LT codes is proposed in order to ensure that all the data can be transmitted according to their own reliability requirements and obtain high transmission efficiency property. In the proposed scheme, the sub-codes on each node (orbits) were performed by a classic LT encoding process. By assigning different degree distributions to the sub-codes, all types of data can be transmitted with better transmission efficiency in comparison to the traditional scheme, and can be recovered at the destination with their own reliability requirements. Moreover, the design of the proposed scheme is much easier than that of the traditional scheme, and is also suitable to the strictly limited processing capacity property of deep space networks. By carrying out asymptotic analysis on the proposed scheme, and by obtaining the numerical and simulation results, it can be seen that the proposed scheme can approximately achieve the same UEP property and much better transmission efficiency than the traditional scheme. Additionally, the results demonstrate that the proposed scheme is much more suitable to deep space network data transmission, in comparison to the traditional scheme."
journal_title,Science China Information Sciences
article_title,Review of channel models for deep space communications
keyword,"['deep space communication\xa0', 'channel modeling\xa0', 'microwave communication\xa0', 'optical communication\xa0', 'deep space exploration\xa0']"
history,"['2018-04', '2018-03-07', '2017-09-13', '2017-12-05', '2018-01-23']"
abstract,"Abstract This paper presents a comprehensive review of channel models for deep space communications. Based on the characteristics of environment, deep space channels can be divided into three kinds, i.e., near Earth link, interstellar link and near planet link. The modeling for different kinds of channels are summarized respectively, and some simulation results are provided in this paper. In addition, according to the development trend of deep space communications, optical wave will become an important carrier in the future. Therefore, deep space optical communication is also briefly introduced. Finally, challenges of deep space channel modeling are pointed out and future research direction is also discussed."
journal_title,Science China Information Sciences
article_title,"Solar system interplanetary communication networks: architectures, technologies and developments"
keyword,"['deep space exploration\xa0', 'SSICN\xa0', 'system architecture\xa0', 'physical transmission\xa0', 'network access\xa0', 'up-layer application\xa0', 'time synchronization\xa0']"
history,"['2018-04', '2018-03-07', '2017-09-14', '2018-01-31', '2018-02-02']"
abstract,"Abstract With the development of deep space exploration technologies, main space agencies all over the world are working hard to develop the solar system interplanetary communication networks (SSICN). SSICN is a perspective communication networking system characterized by high data rate, high intelligent and perfect interconnection, which could provide the deep-space mission control and scientific application with the convenient, reliable and secure data transmission services. Following the introduction of future deep space exploration prospect, this paper analyzes the similarities and differences for three networks, terrestrial internet, near Earth space networks and SSICN, then discusses the key technologies and research trends of SSICN in details, and finally proposes the suggestions for the construction of future Chinese SSICN."
journal_title,Science China Information Sciences
article_title,Customizing the HPL for China accelerator
keyword,"['HPL\xa0', 'China accelerator\xa0', 'DPEM\xa0', 'OAMM\xa0', 'OPTVEC\xa0']"
history,"['2018-04', '2018-03-06', '2017-01-17', '2017-07-24', '2017-08-29']"
abstract,"Abstract HPL is a Linpack benchmark package widely used in high-performance computing tests. Customizing the HPL is crucial for a heterogeneous system equipped with CPU and the China accelerator because of the complexity of the China accelerator and the specified interface on matrix multiplication built in the China accelerator. Therefore, it is advisable to use delicate partition and encapsulation on matrix (DPEM) to expose a friendly testing configuration. More importantly, we propose the orchestrating algorithm for matrix multiplication (OAMM) to enhance the efficiency of the heterogeneous system composed of CPU and China accelerator. Furthermore, optimization at vectorization (OPTVEC) is applied to shield the architectural details of the vector processing element (VPE) equipped in the China accelerator. The experimental results validate DPEM, OPTVEC and OAMM. OPTVEC optimizations would speed up matrix multiplication more than twofold, moreover OAMM would improve productivity by up to 10% compared to the traditional HPL tested in a heterogeneous system."
journal_title,Science China Information Sciences
article_title,Visible and infrared image fusion using ℓ0-generalized total variation model
keyword,[]
history,"['2018-04', '2018-03-05', '2017-05-29', '2017-08-23', '2017-09-19']"
abstract,None
journal_title,Science China Information Sciences
article_title,Parameter estimates of Heston stochastic volatility model with MLE and consistent EKF algorithm
keyword,"['Heston model\xa0', 'stochastic volatility model\xa0', 'parameter estimation\xa0', 'normal maximum likelihood estimation\xa0', 'pseudo maximum likelihood estimation\xa0', 'consistent extended Kalman filter\xa0']"
history,"['2018-04', '2018-03-05', '2017-06-21', '2017-08-08']"
abstract,"Abstract Heston model is the most famous stochastic volatility model in finance. This paper considers the parameter estimation problem of Heston model with both known and unknown volatilities. First, parameters in equity process and volatility process of Heston model are estimated separately since there is no explicit solution for the likelihood function with all parameters. Second, the normal maximum likelihood estimation (NMLE) algorithm is proposed based on the Itô transformation of Heston model. The algorithm can reduce the estimate error compared with existing pseudo maximum likelihood estimation. Third, the NMLE algorithm and consistent extended Kalman filter (CEKF) algorithm are combined in the case of unknown volatilities. As an advantage, CEKF algorithm can apply an upper bound of the error covariance matrix to ensure the volatilities estimation errors to be well evaluated. Numerical simulations illustrate that the proposed NMLE algorithm works more efficiently than the existing pseudo MLE algorithm with known and unknown volatilities. Therefore, the upper bound of the error covariance is illustrated. Additionally, the proposed estimation method is applied to American stock market index S&P 500, and the result shows the utility and effectiveness of the NMLE-CEKF algorithm."
journal_title,Science China Information Sciences
article_title,On extended state based Kalman filter design for a class of nonlinear time-varying uncertain systems
keyword,"['Kalman filter\xa0', 'extended state observer\xa0', 'nonlinear time-varying uncertain system\xa0', 'unbiased minimum variance filter\xa0', 'active disturbance rejection control\xa0']"
history,"['2018-04', '2018-03-05', '2017-06-05', '2017-08-04', '2017-09-22']"
abstract,"Abstract This paper considers the filtering problem for a class of multi-input multi-output systems with nonlinear time-varying uncertain dynamics, random process and measurement noise. An extended state based Kalman filter, with the idea of timely estimating the unknown dynamics, is proposed for better robustness and higher estimation precision. The stability of the proposed filter is rigorously proved for nonlinear timevarying uncertain system with weaker stability condition than the extended Kalman filter, i.e., the initial estimation error, the uncertain dynamics and the noises are only required to be bounded rather than small enough. Moreover, quantitative precision of the proposed filter is theoretically evaluated. The proposed algorithm is proved to be the asymptotic unbiased minimum variance filter for constant uncertainty. The simulation results of some benchmark examples demonstrate the feasibility and effectiveness of the method."
journal_title,Science China Information Sciences
article_title,Modeling a target-selection motion by leveraging an optimal feedback control mechanism
keyword,[]
history,"['2018-04', '2018-03-02', '2017-09-27', '2017-12-29']"
abstract,None
journal_title,Science China Information Sciences
article_title,Transmission delay inconsistency in satellite array antennas cause elevation-dependent pseudorange biases in GNSS signals
keyword,[]
history,"['2018-06', '2018-02-12', '2017-08-20', '2017-12-12']"
abstract,None
journal_title,Science China Information Sciences
article_title,Cross-cluster asymmetric group key agreement for wireless sensor networks
keyword,[]
history,"['2018-04', '2018-02-10', '2017-06-13', '2017-07-19']"
abstract,None
journal_title,Science China Information Sciences
article_title,DESC: enabling secure data exchange based on smart contracts
keyword,[]
history,"['2018-04', '2018-02-08', '2017-08-06', '2017-09-20']"
abstract,None
journal_title,Science China Information Sciences
article_title,A computational framework for Karl Popper’s logic of scientific discovery
keyword,"['belief revision\xa0', 'logic of scientific discovery\xa0', 'approximate deduction\xa0', 'approximation algorithms\xa0', 'feasible computation\xa0']"
history,"['2018-04', '2018-02-06', '2017-02-21', '2017-06-19']"
abstract,"Abstract Belief revision is both a philosophical and logical problem. From Popper’s logic of scientific discovery, we know that revision is ubiquitous in physics and other sciences. The AGM postulates and R-calculus are approaches from logic, where the R-calculus is a Gentzen-type concrete belief revision operator. Because deduction is undecidable in first-order logic, we apply approximate deduction to derive an R-calculus that is computational and has finite injury. We further develop approximation algorithms for SAT problems to derive a feasible R-calculus based on the relation between deduction and satisfiability. In this manner, we provide a full spectrum of belief revision: from philosophical to feasible revision."
journal_title,Science China Information Sciences
article_title,A 70 Gbps NRZ optical link based on 850 nm band-limited VCSEL for data-center intra-connects
keyword,"['850 nm VCSEL\xa0', 'band-limited\xa0', '70 Gb/s NRZ\xa0', 'OM4 MMF\xa0', 'equalization\xa0']"
history,"['2018-08', '2018-02-05', '2017-05-31', '2017-09-06', '2017-10-18']"
abstract,"Abstract Short-reach optical interconnects among servers in data centers have attracted extensive studies recently. High capacity and low cost are two key problems for optical link. In this paper, we demonstrate a band-limited 850 nm vertical cavity surface emitting laser (VCSEL) based optical transmission system. The optical link realizes 70 Gb/s (65 Gb/s net rate) non-return-to-zero (NRZ) signal transmission over 11 m and 20 m OM4 multimode fiber (MMF), with the help of equalization for time domain interference elimination. The utilized VCSEL has a bandwidth of only 18 GHz, meeting the principle of low cost. The data baud rate in this paper reaches the highest value for an 18-GHz-class 850 nm VCSEL based optical link, to our best knowledge."
journal_title,Science China Information Sciences
article_title,Privacy-preserving large-scale systems of linear equations in outsourcing storage and computation
keyword,"['cloud computing\xa0', 'privacy-preserving\xa0', 'linear equations\xa0', 'encryption\xa0', 'security\xa0']"
history,"['2018-03', '2018-02-02', '2017-03-18', '2017-07-18', '2017-08-16']"
abstract,"Abstract Along with the prevalence of cloud computing, it can be realised to efficiently outsource costly storage or computations to cloud servers. Recently, secure outsourcing mechanism has received more and more attention. We focus on secure outsourcing storage and computation for large-scale systems of linear equations (LEs) in this paper. Firstly, we construct a new efficient matrix encryption scheme. Then we exploit this encryption scheme to develop a new algorithm which can implement outsourcing storage and computation for large-scale linear equations in the semi-honest setting. Compared with the previous work, the proposed algorithm requires lower storage overhead and is with competitive efficiency."
journal_title,Science China Information Sciences
article_title,Neuromorphic vision chips
keyword,"['neuromorphic\xa0', 'vison chip\xa0', 'frame-driven\xa0', 'address-event-representation (AER)\xa0', 'event-driven\xa0', 'convolution neural network\xa0', 'image sensor\xa0', 'image processing\xa0']"
history,"['2018-06', '2018-02-02', '2017-10-07', '2017-11-13']"
abstract,"Abstract The paper reviews the progress of neuromorphic vision chip research in decades. It focuses on two kinds of the neuromorphic vision chips: frame-driven (FD) and event-driven (ED) vision chips. The FD and ED vision chips are very different from each other in system architecture, image sensing, image information coding, image processing algorithm, design methodology. The vision chips can overcome serial data transmission and processing bottlenecks in traditional image processing systems. They can perform the high speed image capture and real-time image processing operations. This paper selects two typical chips from the two kinds of vision chips, respectively, and introduces their architectures, image sensing schemes, image processing processors and system operation. The FD neuromorphic reconfigurable vision chip comprises a high speed image sensor, a processing element array and self-organizing map neural network. The FD vision chip has the advantages in image resolution, static object detection, time-multiplex image processing, and chip area. The ED neuromorphic vision chip system is based on address-event-representation image sensor and event-driven multi-kernel convolution network. The ED vision chip has the advantages in fast sensing, low communication bandwidth, brain-like processing, and high energy efficiency. Finally, this paper discusses the architecture and the challenges of the future neuromorphic vision chip and indicates that the reconfigurable vision chip with left- and right-brain functions integrated in the three dimensional (3D) large-scale integrated circuit (LSI) technology becomes a trend of the research on the vision chip."
journal_title,Science China Information Sciences
article_title,An adaptive system for detecting malicious queries in web attacks
keyword,"['web attacks\xa0', 'adaptive learning\xa0', 'intrusion detection\xa0', 'anomaly detection\xa0', 'SVM\xa0']"
history,"['2018-03', '2018-02-02', '2017-08-01', '2017-10-27']"
abstract,"Abstract Web request query strings (queries), which pass parameters to a referenced resource, are always manipulated by attackers to retrieve sensitive data and even take full control of victim web servers and web applications. However, existing malicious query detection approaches in the literature cannot cope with changing web attacks. In this paper, we introduce a novel adaptive system (AMOD) that can adaptively detect web-based code injection attacks, which are the majority of web attacks, by analyzing queries. We also present a new adaptive learning strategy, called SVM HYBRID, leveraged by our system to minimize manual work. In the evaluation, an up-to-date detection model is trained on a ten-day query dataset collected from an academic institute’s web server logs. The evaluation shows our approach overwhelms existing approaches in two respects. Firstly, AMOD outperforms existing web attack detection methods with an F-value of 99.50% and FP rate of 0.001%. Secondly, the total number of malicious queries obtained by SVM HYBRID is 3.07 times that by the popular support vector machine adaptive learning (SVM AL) method. The malicious queries obtained can be used to update the web application firewall (WAF) signature library."
journal_title,Science China Information Sciences
article_title,A real-time inversion attack on the GMR-2 cipher used in the satellite phones
keyword,"['satellite phone\xa0', 'stream cipher\xa0', 'GMR-2\xa0', 'cryptanalysis\xa0', 'inversion attack\xa0']"
history,"['2018-03', '2018-02-01', '2017-05-12', '2017-07-19']"
abstract,"Abstract The GMR-2 cipher is a type of stream cipher currently being used in some inmarsat satellite phones. It has been proven that such a cipher can be cracked using only one single-frame (15 bytes) known keystream but with moderate executing time. In this paper, we present a new thorough security analysis of the GMR-2 cipher. We first study the inverse properties of the cipher’s components to reveal a bad one-way character of the cipher. By then introducing a new concept called “valid key chain” according to the cipher’s key schedule, we propose an unprecedented real-time inversion attack using a single-frame keystream. This attack comprises three phases: (1) table generation; (2) dynamic table look-up, filtration and combination; and (3) verification. Our analysis shows that, using the proposed attack, the size of the exhaustive search space for the 64-bit encryption key can be reduced to approximately 213 when a single-frame keystream is available. Compared with previous known attacks, this inversion attack is much more efficient. Finally, the proposed attack is carried out on a 3.3-GHz PC, and the experimental results thus obtained demonstrate that the 64-bit encryption-key could be recovered in approximately 0.02 s on average."
journal_title,Science China Information Sciences
article_title,Simulation-based security of function-hiding inner product encryption
keyword,[]
history,"['2018-04', '2018-01-19', '2017-04-19', '2017-06-20', '2017-08-16']"
abstract,None
journal_title,Science China Information Sciences
article_title,A novel anti-detection criterion for covert storage channel threat estimation
keyword,[]
history,"['2018-04', '2018-01-18', '2017-05-26', '2017-07-19']"
abstract,None
journal_title,Science China Information Sciences
article_title,Similar operation template attack on RSA-CRT as a case study
keyword,"['side channel attack\xa0', 'template attack\xa0', 'RSA-CRT\xa0', 'hidden number problem\xa0', 'prime recovery\xa0']"
history,"['2018-03', '2018-01-18', '2017-05-13', '2017-07-05', '2017-07-19']"
abstract,"Abstract A template attack, the most powerful side-channel attack methods, usually first builds the leakage profiles from a controlled profiling device, and then uses these profiles to recover the secret of the target device. It is based on the fact that the profiling device shares similar leakage characteristics with the target device. In this study, we focus on the similar operations in a single device and propose a new variant of the template attack, called the similar operation template attack (SOTA). SOTA builds the models on public variables (e.g., input/output) and recovers the values of the secret variables that leak similar to the public variables. SOTA’s advantage is that it can avoid the requirement of an additional profiling device. In this study, the proposed SOTA method is applied to a straightforward RSA-CRT implementation. Because the leakage is (almost) the same in similar operations, we reduce the security of RSA-CRT to a hidden multiplier problem (HMP) over GF(q), which can be solved byte-wise using our proposed heuristic algorithm. The effectiveness of our proposed method is verified as an entire prime recovery procedure in a practical leakage scenario."
journal_title,Science China Information Sciences
article_title,Impossible meet-in-the-middle fault analysis on the LED lightweight cipher in VANETs
keyword,"['VANETs\xa0', 'LED\xa0', 'lightweight cipher\xa0', 'impossible meet-in-the-middle\xa0', 'fault analysis\xa0']"
history,"['2018-03', '2018-01-12', '2017-05-10', '2017-07-19']"
abstract,"Abstract With the expansion of wireless technology, vehicular ad-hoc networks (VANETs) are emerging as a promising approach for realizing smart cities and addressing many serious traffic problems, such as road safety, convenience, and efficiency. To avoid any possible rancorous attacks, employing lightweight ciphers is most effective for implementing encryption/decryption, message authentication, and digital signatures for the security of the VANETs. Light encryption device (LED) is a lightweight block cipher with two basic keysize variants: LED-64 and LED-128. Since its inception, many fault analysis techniques have focused on provoking faults in the last four rounds to derive the 64-bit and 128-bit secret keys. It is vital to investigate whether injecting faults into a prior round enables breakage of the LED. This study presents a novel impossible meet-in-the-middle fault analysis on a prior round. A detailed analysis of the expected number of faults is used to uniquely determine the secret key. It is based on the propagation of truncated differentials and is surprisingly reminiscent of the computation of the complexity of a rectangle attack. It shows that the impossible meet-in-the-middle fault analysis could successfully break the LED by fault injections."
journal_title,Science China Information Sciences
article_title,Verifiable random functions with Boolean function constraints
keyword,[]
history,"['2018-03', '2018-01-11', '2017-02-10', '2017-07-19']"
abstract,None
journal_title,Science China Information Sciences
article_title,Nonlocal image denoising using edge-based similarity metric and adaptive parameter selection
keyword,[]
history,"['2018-04', '2018-01-09', '2017-03-16', '2017-06-06', '2017-07-19']"
abstract,None
journal_title,Science China Information Sciences
article_title,Optimal model search for hardware-trojan-based bit-level fault attacks on block ciphers
keyword,[]
history,"['2018-03', '2018-01-05', '2017-04-22', '2017-06-07']"
abstract,None
journal_title,Science China Information Sciences
article_title,Quantum network communication: a discrete-time quantum-walk approach
keyword,"['network coding\xa0', 'quantum network coding\xa0', 'quantum walk\xa0', 'state fidelity\xa0', 'butterfly network\xa0', 'inverted crown network\xa0']"
history,"['2018-04', '2018-01-05', '2017-05-09', '2017-06-24', '2017-07-27']"
abstract,"Abstract We study the problem of quantum multi-unicast communication over the butterfly network in a quantum-walk architecture, where multiple arbitrary single-qubit states are transmitted simultaneously between multiple source-sink pairs. Here, by introducing quantum walks, we demonstrate a quantum multi-unicast communication scheme over the butterfly network and the inverted crown network, respectively, where the arbitrary single-qubit states can be efficiently transferred with both the probability and the state fidelity one. The presented result concerns only the butterfly network and the inverted crown network, but our techniques can be applied to a more general graph. It paves a way to combine quantum computation and quantum network communication."
journal_title,Science China Information Sciences
article_title,Distributed regression estimation with incomplete data in multi-agent networks
keyword,"['multi-agent systems\xa0', 'time-varying network\xa0', 'estimation with incomplete data\xa0', 'online learning\xa0', 'stochastic approximation\xa0']"
history,"['2018-09', '2018-01-04', '2016-11-23', '2017-06-21']"
abstract,"Abstract In this paper, distributed regression estimation problem with incomplete data in a time-varying multi-agent network is investigated. Regression estimation is carried out based on local agent information with incomplete in the non-ignorable mechanism. By virtue of gradient-based design and adaptive filter, a distributed algorithm is proposed to deal with a regression estimation problem with incomplete data. With the help of convex analysis and stochastic approximation techniques, the exact convergence is obtained for the proposed algorithm with incomplete data and a jointly-connected multi-agent topology. Moreover, online regret analysis is also given for real-time learning. Then, simulations for the proposed algorithm are also given to demonstrate how it can solve the estimation problem in a distributed way, even when the network configuration is time-varying."
journal_title,Science China Information Sciences
article_title,How much information is needed in quantized nonlinear control?
keyword,"['nonlinear systems\xa0', 'disturbances\xa0', 'input-to-state stabilizability\xa0', 'sampled systems\xa0', 'quantization rate\xa0']"
history,"['2018-09', '2018-01-04', '2016-11-18', '2017-04-02', '2017-06-20']"
abstract,"Abstract Quantization rate is a crucial measure of complexity in determining stabilizability of control systems subject to quantized state measurements. This paper investigates quantization complexity for a class of nonlinear systems which are subjected to disturbances of unknown statistics and unknown bounds. This class of systems includes linear stablizable systems as special cases. Two lower bounds on the quantization rates are derived which guarantee input-to-state stabilizability for continuous-time and sampled-data feedback strategies, respectively. Simulation examples are provided to validate the results."
journal_title,Science China Information Sciences
article_title,Achievable delay margin using LTI control for plants with unstable complex poles
keyword,"['delay margin\xa0', 'systems with time-delay\xa0', 'time-invariant systems\xa0', 'unstable complex poles\xa0', 'frequency domain method\xa0']"
history,"['2018-09', '2018-01-04', '2017-04-18', '2017-06-20']"
abstract,"Abstract We consider the achievable delay margin of a real rational and strictly proper plant, with unstable complex poles, by a linear time-invariant (LTI) controller. The delay margin is defined as the largest time delay such that, for any delay less than this value, the closed-loop stability is maintained. Drawing upon a frequency domain method, particularly a bilinear transform technique, we provide an upper bound of the delay margin, which requires computing the maximum of a one-variable function. Finally, the effectiveness of the theoretical results is demonstrated through a numerical example."
journal_title,Science China Information Sciences
article_title,Multi-key FHE for multi-bit messages
keyword,[]
history,"['2018-02', '2018-01-03', '2017-03-02', '2017-05-31', '2017-07-19']"
abstract,None
journal_title,Science China Information Sciences
article_title,A transfer alignment method for airborne distributed POS with three-dimensional aircraft flexure angles
keyword,"['position and orientation system\xa0', 'distribution\xa0', 'airborne earth observation\xa0', 'transfer alignment\xa0', 'unscented transformation\xa0', 'Rauch-Tung-Striebel smoother\xa0']"
history,"['2018-09', '2018-01-03', '2017-06-14', '2017-07-20']"
abstract,"Abstract An airborne distributed position and orientation system (POS) appears to satisfy the requirement of multi-point motion parameters measurement. This relies on transfer alignment from a high precision master system to slave systems to obtain high accuracy motion parameters of all points. A key problem for a distributed POS involves determining a method to treat the aircraft flexure appropriately and achieve high precision transfer alignment. In this study, the effect of aircraft flexure on transfer alignment accuracy for airborne earth observation is first analyzed. Based on this, the error model of transfer alignment that considers three-dimensional flexure angles are established, and a transfer alignment based on parameter identification unscented Rauch-Tung-Striebel smoother (PIURTSS) is proposed. The simulations results show that the transfer alignment method based on PIURTSS effectively improves the estimation accuracy."
journal_title,Science China Information Sciences
article_title,A systematic framework to understand central bank digital currency
keyword,"['digital fiat currency\xa0', 'credit-based currency\xa0', 'crypto-currency\xa0', 'algorithm-based currency\xa0', 'smart currency\xa0', 'central bank digital currency\xa0']"
history,"['2018-03', '2018-01-03', '2017-11-02', '2017-11-24']"
abstract,"Abstract The ongoing research and development of digital fiat currency (DFC) have triggered attention of policy makers, regulators and the industrial and academic communities. But there is not yet a clear idea and blueprint of what DFC looks like. This paper establishes a systematic framework to analyze the essence and connotation of DFC from four dimensions: currency value, technical aspects, means of implementation and application scenarios. It is argued that DFC is a credit-based currency in terms of value, a crypto-currency from a technical perspective, an algorithm-based currency in terms of implementation and a smart currency in application scenarios. Compared with existing private digital currencies and electronic currencies, DFC will be equipped with brand new and higher qualities. The goal of Chinese DFC is to contribute to more stable value, more secure data, more powerful regulation, stronger empowerment of individuals in payment activities and smarter application. Chinese DFC should have qualities that enable it to provide better service for the public, to offer effective tools for macroeconomic control and to lay a solid foundation for RegTech development."
journal_title,Science China Information Sciences
article_title,mmWave communications for 5G: implementation challenges and advances
keyword,"['millimeter wave\xa0', 'massive MIMO\xa0', 'beamforming\xa0', 'hybrid precoding\xa0', 'channel estimation\xa0', 'phased array\xa0', 'power amplifier\xa0', 'voltage controlled oscillator (VCO)\xa0']"
history,"['2018-02', '2018-01-02', '2017-07-10', '2017-08-22']"
abstract,"Abstract The requirement of the fifth generation (5G) wireless communication for high throughput motivates the wireless industry to use the mmWave (millimeter wave) communications for its wide bandwidth advantage. To compensate the heavy path loss and increase the communications capacity, phased array beamforming and massive multiple-input multiple-output (MIMO) techniques are employed at both the user equipment (UE) and base stations (BS). Considering the commercial requirements, 5G mmWave large array systems should be implemented in an energy- and cost-efficient way with a small form factor. To address above issues and realize a reliable communications link, taking into account the particular characteristics of 5G mmWave systems, this paper firstly examines the design challenges and trade-offs in system implementations, then some of the design strategies are summarized. At last, recent advance in RF front-end circuits and receiver sub-systems is then highlighted."
journal_title,Science China Information Sciences
article_title,Sliding mode fuzzy control-based path-following control for a dolphin robot
keyword,[]
history,"['2018-02', '2017-12-27', '2017-08-17', '2017-10-16', '2017-11-09']"
abstract,None
journal_title,Science China Information Sciences
article_title,Mutual authenticated quantum no-key encryption scheme over private quantum channel
keyword,"['quantum cryptography\xa0', 'no-key protocol\xa0', 'quantum entanglement\xa0', 'information-theoretical security\xa0', 'private quantum channel\xa0']"
history,"['2018-02', '2017-12-27', '2017-06-13', '2017-06-19', '2017-07-16']"
abstract,"Abstract In this paper, we realize Shamir’s no-key protocol via quantum computation of Boolean functions and a private quantum channel. The proposed quantum no-key protocol has three rounds and provides mutual data origin authentication. Random Boolean functions are used to create entanglement and guarantee that any adversary without keys cannot pass the authentication. Thus, our protocol can resist the man-in-the-middle attack. A security analysis has shown that pieces of ciphertexts of the three rounds are completely mixed state. This property ensures no adversary can get any information about the sent message or authentication keys. Therefore, our protocol is unconditionally secure and its authentication keys can be reused."
journal_title,Science China Information Sciences
article_title,Learning stratified 3D reconstruction
keyword,"['stratified 3D reconstruction\xa0', 'learning\xa0', 'deep neural networks\xa0', 'outlier detector\xa0', 'spatial vision\xa0']"
history,"['2018-02', '2017-12-26', '2017-05-22', '2017-08-08']"
abstract,"Abstract Stratified 3D reconstruction, or a layer-by-layer 3D reconstruction upgraded from projective to affine, then to the final metric reconstruction, is a well-known 3D reconstruction method in computer vision. It is also a key supporting technology for various well-known applications, such as streetview, smart3D, oblique photogrammetry. Generally speaking, the existing computer vision methods in the literature can be roughly classified into either the geometry-based approaches for spatial vision or the learning-based approaches for object vision. Although deep learning has demonstrated tremendous success in object vision in recent years, learning 3D scene reconstruction from multiple images is still rare, even not existent, except for those on depth learning from single images. This study is to explore the feasibility of learning the stratified 3D reconstruction from putative point correspondences across images, and to assess whether it could also be as robust to matching outliers as the traditional geometry-based methods do. In this study, a special parsimonious neural network is designed for the learning. Our results show that it is indeed possible to learn a stratified 3D reconstruction from noisy image point correspondences, and the learnt reconstruction results appear satisfactory although they are still not on a par with the state-of-the-arts in the structure-from-motion community due to largely its lack of an explicit robust outlier detector such as random sample consensus (RANSAC). To the best of our knowledge, our study is the first attempt in the literature to learn 3D scene reconstruction from multiple images. Our results also show that how to implicitly or explicitly integrate an outlier detector in learning methods is a key problem to solve in order to learn comparable 3D scene structures to those by the current geometry-based state-of-the-arts. Otherwise any significant advancement of learning 3D structures from multiple images seems difficult, if not impossible. Besides, we even speculate that deep learning might be, in nature, not suitable for learning 3D structure from multiple images, or more generally, for solving spatial vision problems."
journal_title,Science China Information Sciences
article_title,Symbolic model checking for discrete real-time systems
keyword,"['symbolic model checking\xa0', 'temporal tester\xa0', 'real-time temporal logic\xa0', 'just discrete system\xa0', 'OBDDs\xa0']"
history,"['2018-05', '2017-12-26', '2017-01-10', '2017-05-07', '2017-06-29']"
abstract,"Abstract A considerably large class of critical applications run in distributed and real-time environments, and most of the correctness requirements of such applications must be expressed by time-critical properties. To enable the specification and verification of these properties in both qualitative and quantitative manners, we propose a new real-time temporal logic RTCTL*, by incorporating both the quantitative (bounded) future and past temporal operators from the qualitative temporal logic CTL*. First, we propose a symbolic method for constructing the temporal tester for arbitrary principally temporal formulas. A temporal tester is constructed as a non-deterministic transducer with a fresh boolean output variable, such that at any position the output variable is set to be true if and only if the corresponding formula holds starting from that position. Then we propose a symbolic model checking method for RTCTL* over finite-state transition systems with weak fairness constraints based on the compositionality of testers. The soundness and completeness of the model checking method, the expressiveness of RTCTL*, and the complexity of the tester construction are described and proven. We have already implemented an efficient model checking prototype for the real-time linear temporal logic RTLTL, which is a quantifier-free version of RTCTL*, by building upon the NuSMV model checker. The theoretical and the experimental results from the prototype both confirm that for checking bounded temporal formulae of the form fU[0,b] g or fS[0,b] g, our method performs exponentially better than the translation-based method in NuSMV."
journal_title,Science China Information Sciences
article_title,Parameter influence on electron collection efficiency of a bare electrodynamic tether
keyword,"['multiphysics\xa0', 'coupled\xa0', 'finite element\xa0', 'electrodynamic tether\xa0', 'electron collection efficiency\xa0']"
history,"['2018-02', '2017-12-22', '2017-04-28', '2017-05-30', '2017-07-05']"
abstract,"Abstract This study develops a coupled multiphysics finite element method for the dynamic analysis of a bare flexible electrodynamic tether. Contrary to the existing methods, the new method discretizes and solves the orbital motion limited equation and the dynamic equation of an elastic flexible tether simultaneously. First, the new method is verified via comparison with the existing methods in a straight tether situation. Second, the number of tether elements, tether bending deformation, and two design parameters at the cathodic end affecting the electrical current are investigated. It is determined that the tether bending deformation and the two parameters i.e., the impedance Z  T  and Φ PW have a significant impact on the electron collection efficiency of an electrodynamic tether system. The results indicate that the proposed method should be applied in the refined mission analysis."
journal_title,Science China Information Sciences
article_title,Special focus on analysis and control of finite-valued network systems
keyword,[]
history,"['2018-01', '2017-12-17']"
abstract,None
journal_title,Science China Information Sciences
article_title,Embracing informationization 3.0—an era of computing intelligence
keyword,['010001\xa0']
history,"['2018-01', '2017-12-15']"
abstract,None
journal_title,Science China Information Sciences
article_title,Logical control scheme with real-time statistical learning for residual gas fraction in IC engines
keyword,"['combustion engine\xa0', 'statistical learning\xa0', 'residual gas fraction\xa0', 'variable valve timing\xa0', 'logical control\xa0']"
history,"['2018-01', '2017-12-12', '2017-09-03', '2017-10-07']"
abstract,"Abstract In this paper, an optimal control scheme for reducing the fluctuation of residual gas fraction (RGF) under variational operating condition is developed by combining stochastic logical system approach with statistical learning method. The method estimating RGF from measured in-cylinder pressure is introduced firstly. Then, the stochastic properties of the RGF are analyzed according to statistical data captured by conducting experiments on a test bench equipped with a L4 internal combustion engine. The influences to the probability distribution of the RGF from both control input and environment parameters are also analyzed. Based on the statistical analysis, a stochastic logical transient model is adopted for describing cyclic behavior of the RGF. Optimal control policy maps for different fixed operating conditions are calculated then. Besides, a statistical learning-based method is applied to learn the probability density function (PDF) of RGF in the real-time which is used to adjust the control MAP based on logical optimization. The whole optimal control policy map is obtained based on Gaussian process regression with consideration of statistical information of RGF. Finally, the performance of the proposed method is experimentally validated."
journal_title,Science China Information Sciences
article_title,Design of communication relay mission for supporting lunar-farside soft landing
keyword,"['lunar farside\xa0', 'soft landing\xa0', 'relay communication\xa0', 'Earth-Moon Lagrange point\xa0']"
history,"['2018-04', '2017-12-12', '2017-06-08', '2017-07-03']"
abstract,"Abstract Chang’E-IV will be the first soft-landing and rover mission on the lunar farside. The relay satellite, which is located near the Earth-Moon L2 point for relay communication, is the key to the landing mission. Based on an analysis of the characteristics of the task and the technical difficulties associated with the relay satellite system, the overall design scheme of the relay communication mission is proposed in terms of trajectory design and communication system design among other aspects. First, according to the complex dynamic environment, a mission orbit that serves as an uninterrupted communication link is presented. A short-duration and low-energy transfer trajectory with lunar flyby is discussed. Orbital correction and a low-cost control strategy for orbit maintenance in the Earth-Moon L2 point region are provided. Second, considering the existing technical constraints, the requirement of relay communication in different stages and the design schemes of frequency division and redundant relay communication system are introduced. Finally, based on the trajectory design index and the performance of the communication system, the overall design scheme of the relay communication mission is proposed. This mission will provide the technical support and reference required for the Chang’E-IV mission."
journal_title,Science China Information Sciences
article_title,A survey on applications of semi-tensor product method in engineering
keyword,"['semi-tensor product of matrices\xa0', 'gene regulation\xa0', 'power system\xa0', 'smart grid\xa0', 'information security\xa0', 'vehicle control\xa0']"
history,"['2018-01', '2017-12-12', '2017-08-07', '2017-09-07']"
abstract,"Abstract Semi-tensor product (STP) of matrices has attracted more and more attention from both control theory and engineering in the last two decades. This paper presents a comprehensive survey on the applications of STP method in engineering. Firstly, some preliminary results on STP method are recalled. Secondly, some applications of STP method in engineering, including gene regulation, power system, wireless communication, smart grid, information security, combustion engine and vehicle control, are reviewed. Finally, some potential applications of STP method are predicted."
journal_title,Science China Information Sciences
article_title,A study on the changes of dynamic feature code when fixing bugs: towards the benefits and costs of Python dynamic features
keyword,"['Python\xa0', 'fine-grained code changes\xa0', 'change behaviors\xa0', 'dynamic features\xa0', 'bug fixing\xa0']"
history,"['2018-01', '2017-12-12', '2017-02-18', '2017-06-19']"
abstract,"Abstract Dynamic features in programming languages support the modification of the execution status at runtime, which is often considered helpful in rapid development and prototyping. However, it was also reported that some dynamic feature code tends to be change-prone or error-prone. We present the first study that analyzes the changes of dynamic feature code and the roles of dynamic features in bug-fix activities for the Python language. We used an AST-based differencing tool to capture fine-grained source code changes from 17926 bug-fix commits in 17 Python projects. Using this data, we conducted an empirical study on the changes of dynamic feature code when fixing bugs in Python. First, we investigated the characteristics of dynamic feature code changes, by comparing the changes between dynamic feature code and non-dynamic feature code when fixing bugs, and comparing dynamic feature changes between bug-fix and non-bugfix activities. Second, we explored 226 bug-fix commits to investigate the motivation and behaviors of dynamic feature changes when fixing bugs. The study results reveal that (1) the changes of dynamic feature code are significantly related to bug-fix activities rather than non-bugfix activities; (2) compared with non-dynamic feature code, dynamic feature code is inserted or updated more frequently when fixing bugs; (3) developers often insert dynamic feature code as type checks or attribute checks to fix type errors and attribute errors; (4) the misuse of dynamic features introduces bugs in dynamic feature code, and the bugs are often fixed by adding a check or adding an exception handling. As a benefit of this paper, we gain insights into the manner in which developers and researchers handle the changes of dynamic feature code when fixing bugs."
journal_title,Science China Information Sciences
article_title,Overview of deep space laser communication
keyword,"['deep space communication, deep space observation\xa0', 'development process\xa0', 'free space communication\xa0', 'laser communication\xa0']"
history,"['2018-04', '2017-12-12', '2017-06-05', '2017-07-28']"
abstract,"Abstract The deep space probe is a vital technology for observing and exploring the universe. It is thus intensifying as an aerospace research focus on an international scale. Despite improving the frequency band, the conventional microwave communication technique has difficulty satisfying the increased demand for the enormous volume of scientific data returning to the Earth. With a carrier frequency that is several orders of magnitude higher than the microwave, free-space optical communication is a robust and promising method for achieving both high bit rates and long distances in deep space communication. In this article, the history of this technology is summarized and the objective laws are formulated, while key techniques and development trends are analyzed. Finally, useful concepts and suggestions are proposed for the development of deep space laser communication in China."
journal_title,Science China Information Sciences
article_title,Nonsingularity of Grain-like cascade FSRs via semi-tensor product
keyword,"['Grain-like cascade FSRs\xa0', 'Boolean control networks\xa0', 'Boolean networks\xa0', 'semi-tensor product\xa0', 'nonsingularity\xa0']"
history,"['2018-01', '2017-12-12', '2017-09-07', '2017-10-17']"
abstract,"Abstract In this paper, Grain-like cascade feedback shift registers (FSRs) are regarded as two Boolean networks (BNs), and the semi-tensor product (STP) of the matrices is used to convert the Grain-like cascade FSRs into an equivalent linear equation. Based on the STP, a novel method is proposed herein to investigate the nonsingularity of Grain-like cascade FSRs. First, we investigate the property of the state transition matrix of Grain-like cascade FSRs. We then propose their sufficient and necessary nonsingularity condition. Next, we regard the Grain-like cascade FSRs as Boolean control networks (BCNs) and further provide a sufficient condition of their nonsingularity. Finally, two examples are provided to illustrate the results obtained in this paper."
journal_title,Science China Information Sciences
article_title,From STP to game-based control
keyword,"['semi-tensor product of matrices\xa0', 'Boolean network\xa0', 'logical (control) system\xa0', 'finite game\xa0', 'game theoretic control\xa0']"
history,"['2018-01', '2017-12-12', '2017-08-21', '2017-09-28']"
abstract,"Abstract This paper provides a comprehensive survey on semi-tensor product (STP) of matrices and its applications to different disciplines. First of all, the STP and its basic properties are introduced. Meanwhile, its inside physical meaning is explained. Second, its application to conventional dynamic systems is presented. As an example, the region of attraction of stable equilibriums is discussed. Third, its application to logical systems is presented. Particularly, the algebraic state space representation of logical systems and the important role it plays in analysis and control of logical systems are emphasized. Fourth, its application to finite games is discussed. The most interesting problems include potential game, evolutionary game, and game theoretic control. Finally, the mathematical essence of STP is briefly introduced."
journal_title,Science China Information Sciences
article_title,Modeling and analysis of colored petri net based on the semi-tensor product of matrices
keyword,"['colored petri net\xa0', 'reachability\xa0', 'controllability\xa0', 'marking evolution equation\xa0', 'semi-tensor product of matrices\xa0']"
history,"['2018-01', '2017-12-11', '2017-08-18', '2017-09-28']"
abstract,"Abstract This paper applies the model petri net method based on the semi-tensor product of matrices to colored petri net. Firstly, we establish the marking evolution equation for colored petri net by using the semitensor product of matrices. Then we define the concept of controllability and the control-marking adjacency matrix for colored petri net. Based on the marking evolution equation and control-marking adjacency matrix, we give the necessary and sufficient condition of reachability and controllability for colored petri net. The algorithm to verify the reachability of colored petri net is given, and we analyze the computational complexity of the algorithm. Finally, an example is given to illustrate the effectiveness of the proposed theory. The significance of the paper lies in the application of the model petri net method based on the semitensor product of matrices to colored petri net. This is a convenient way of verifying whether one marking is reachable from another one as well as finding all firing sequences between any two reachable markings. Additionally, the method lays the foundations for the analysis of other properties of colored petri net."
journal_title,Science China Information Sciences
article_title,Non-fragility of multi-agent controllability
keyword,"['non-fragility\xa0', 'controllability preserving\xa0', 'cutset\xa0', 'leader selection\xa0', 'almost surely\xa0']"
history,"['2018-05', '2017-12-07', '2017-03-04', '2017-05-16']"
abstract,"Abstract Controllability of multi-agent systems is determined by the interconnection topologies. In practice, losing agents can change the topologies of multi-agent systems, which may affect the controllability. In order to preserve controllability, this paper first introduces the concept of non-fragility of controllability. In virtue of the notion of cutsets, necessary and sufficient conditions are established from a graphic perspective, for almost surely strongly/weakly preserving controllability, respectively. Then, the problem of leader selection to preserve controllability is proposed. The tight bounds of the fewest leaders to achieve strongly preserving controllability are estimated in terms of the diameter of the interconnection topology, and the cardinality of the node set. Correspondingly, the tight bounds of the fewest leaders to achieve weakly preserving controllability are estimated in terms of the cutsets of the interconnection topology. Furthermore, two algorithms are established for selecting the fewest leaders to strongly/weakly preserve the controllability. In addition, the algorithm for leaders’ locations to maximize non-fragility is also designed. Simulation examples are provided to illuminate the theoretical results and exhibits how the algorithms proceed."
journal_title,Science China Information Sciences
article_title,Anti-chain based algorithms for timed/probabilistic refinement checking
keyword,"['model checking\xa0', 'refinement\xa0', 'anti-chain\xa0', 'timed automata\xa0', 'markov decision process\xa0']"
history,"['2018-05', '2017-12-06', '2017-05-22', '2017-06-09']"
abstract,"Abstract Refinement checking answers the question on whether an implementation model is a refinement of a specification model, which is of great value for system verification. Some refinement relationships, e.g., trace refinement and failures/divergence refinement, have been recognized for different verification purposes. In general, refinement checking algorithms often rely on subset construction, which incurs in the state space explosion problem. Recently the anti-chain based approach has been suggested for trace refinement checking, and the results show a significant improvement. In this paper, we investigate the problems of applying the anti-chain approach to timed refinement checking (a timed implementation vs. a timed or untimed specification) and probabilistic refinement checking (a probabilistic implementation vs. a non-probabilistic specification), and show that the state space can be reduced considerably by employing the anti-chain approach. All the algorithms have been integrated into the model checking tool PAT, and the experiments have been conducted to show the efficiency of the application of anti-chains."
journal_title,Science China Information Sciences
article_title,Network topology inference from incomplete observation data
keyword,[]
history,"['2018-02', '2017-12-05', '2017-05-23', '2017-06-29']"
abstract,None
journal_title,Science China Information Sciences
article_title,An optimization-based shared control framework with applications in multi-robot systems
keyword,['014201\xa0']
history,"['2018-01', '2017-12-05', '2017-07-31', '2017-10-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,An imporosity message scheduling based on modified genetic algorithm for time-triggered ethernet
keyword,[]
history,"['2018-01', '2017-12-04', '2017-03-15', '2017-05-25']"
abstract,None
journal_title,Science China Information Sciences
article_title,A non-alternate 3D structure and its practical security evaluation against differential and linear cryptanalysis
keyword,[]
history,"['2018-05', '2017-11-21', '2017-01-12', '2017-06-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,Surface-plasmonic right-angle waveguide amplifiers
keyword,"['surface-plasmonic\xa0', 'right-angle waveguide\xa0', 'bismuth ion-doped glass film\xa0', 'gain and noise figure\xa0', 'unit-length gain\xa0']"
history,"['2018-06', '2017-11-20', '2017-04-09', '2017-06-19', '2017-08-01']"
abstract,"Abstract We propose a surface-plasmonic right-angle bend waveguide with bismuth ion-doped glass film as core layer and Ag films as cladding layers for first time, to the best of our knowledge. Theoretical analysis shows that the right-angle has bend and absorption losses of 3.17 dB. The rate equations and power evolution equations of high concentration bismuth-doped glass film are setup and solved to analyze the effect of the waveguide length and active ion concentration on the signal gain and Noise Figure (NF). The theoretical results predict that with the pump power 100 mW, the active ion concentration 2.0×1026 ions/m3 and the right-angle waveguide size 1.0 cm×1.0 cm, small-signal unit-length net gain can reach 15.32 dB with NF less than 5.0 dB."
journal_title,Science China Information Sciences
article_title,Secure resource allocation for green and cognitive device-to-device communication
keyword,[]
history,"['2018-02', '2017-11-20', '2016-12-23', '2017-05-15', '2017-08-05']"
abstract,None
journal_title,Science China Information Sciences
article_title,A complexity-reduced fast successive cancellation list decoder for polar codes
keyword,"['polar codes\xa0', 'low-complexity decoder\xa0', 'splitting-reduced\xa0', 'multi-bit decision\xa0', 'list decoder\xa0']"
history,"['2018-02', '2017-11-20', '2017-02-20', '2017-04-25']"
abstract,"Abstract A multi-bit decision for polar codes based on a simplified successive cancellation (SSC) decoding algorithm can improve the throughput of polar decoding. A list algorithm is used to improve the error-correcting performance. However, list decoders are highly complex compared with decoders without a list algorithm. In this paper, a low-complexity list decoder is proposed, where path-splitting operations for a multi-bit decision can be avoided, if the decoding reliability exceeds a threshold. The threshold is determined based on the reliability of subchannels and positions of decoding nodes. Path splitting rules are designed for multi-bit decision processes, and a complexity-reduced list decoder is proposed based on this. Results  show that the number of survival paths can be greatly reduced at the cost of negligible deterioration in block error performance. Thus, the computational complexity can be significantly reduced, especially for a high signal-to-noise ratio (SNR) region."
journal_title,Science China Information Sciences
article_title,Improved meet-in-the-middle attacks on reduced-round Piccolo
keyword,"['block cipher\xa0', 'lightweight\xa0', 'Piccolo\xa0', 'meet-in-the-middle attack\xa0', 'distinguisher\xa0']"
history,"['2018-03', '2017-11-20', '2016-12-22', '2017-04-05', '2017-06-21']"
abstract,"Abstract Piccolo is a lightweight block cipher that adopts a generalized Feistel network structure with 4 branches, each of which is 16 bit long. The key length is 80 or 128 bit, denoted by Piccolo-80 and Piccolo-128, respectively. In this paper, we mounted meet-in-the-middle attacks on 14-round Piccolo-80 without preand post-whitening keys and 18-round Piccolo-128 with post-whitening keys by exploiting the properties of the key schedule and Maximum Distance Separable (MDS) matrix. For Piccolo-80, we first constructed a 5-round distinguisher. Then 4 rounds and 5 rounds were appended at the beginning and at the end, respectively. Based on this structure, we mounted an attack on 14-round Piccolo-80 from the 5th round to the 18th round. The data, time, and memory complexities were 252 chosen plaintexts, 267.44 encryptions, and 264.91 blocks, respectively. For Piccolo-128, we built a 7-round distinguisher to attack 18-round Piccolo-128 from the 4th round to the 21st round. The data, time, and memory complexities were 252 chosen plaintexts, 2126.63 encryptions, and 2125.29 blocks, respectively. If not considering results on biclique cryptanalysis, these are currently the best public results on this reduced version of the Piccolo block cipher."
journal_title,Science China Information Sciences
article_title,Universal enzymatic numerical P systems with small number of enzymatic variables
keyword,"['bio-inspired computing\xa0', 'numerical P system\xa0', 'mobile robot\xa0', 'membrane controller\xa0', 'universality\xa0']"
history,"['2018-09', '2017-11-20', '2017-01-26', '2017-04-20']"
abstract,"Abstract Numerical P systems (for short, NP systems) are distributed and parallel computing models inspired from the structure of living cells and economics. Enzymatic numerical P systems (for short, ENP systems) are a variant of NP systems, which have been successfully applied in designing and implementing controllers for mobile robots. Since ENP systems were proved to be Turing universal, there has been much work to simplify the universal systems, where the complexity parameters considered are the number of membranes, the degrees of polynomial production functions or the number of variables used in the systems. Yet the number of enzymatic variables, which is essential for ENP systems to reach universality, has not been investigated. Here we consider the problem of searching for the smallest number of enzymatic variables needed for universal ENP systems. We prove that for ENP systems as number acceptors working in the all-parallel or one-parallel mode, one enzymatic variable is sufficient to reach universality; while for the one-parallel ENP systems as number generators, two enzymatic variables are sufficient to reach universality. These results improve the best known results that the numbers of enzymatic variables are 13 and 52 for the all-parallel and one-parallel systems, respectively."
journal_title,Science China Information Sciences
article_title,Guaranteed cost boundary control for cluster synchronization of complex spatio-temporal dynamical networks with community structure
keyword,"['cluster synchronization\xa0', 'complex dynamical networks\xa0', 'boundary control\xa0', 'guaranteed control\xa0', 'LMIs\xa0']"
history,"['2018-05', '2017-11-20', '2016-11-23', '2017-04-20']"
abstract,"Abstract This paper discusses the problem for cluster synchronization control of a nonlinear complex spatio-temporal dynamical network (CSDN) with community structure. Initially, a collocated boundary controller with boundary measurement is studied to achieve the cluster synchronization of the CSDN. After that, a guaranteed cost boundary controller is further developed based on the obtained results. Furthermore, the suboptimal control design is addressed by minimizing an upper bound of the cost function. Finally, a numerical example is given to demonstrate the effectiveness of the proposed methods."
journal_title,Science China Information Sciences
article_title,Spatial image encryption algorithm based on chaotic map and pixel frequency
keyword,[]
history,"['2018-05', '2017-11-20', '2017-05-19', '2017-07-19']"
abstract,None
journal_title,Science China Information Sciences
article_title,Impact of self-heating effects on nanoscale Ge p-channel FinFETs with Si substrate
keyword,"['Germanium\xa0', 'FinFET\xa0', 'self-heating effect\xa0', 'thermal resistance\xa0', 'TCAD\xa0']"
history,"['2018-06', '2017-11-20', '2016-12-13', '2017-03-17', '2017-05-04']"
abstract,"Abstract In this paper, self-heating effects (SHE) in nanoscale Ge p-channel FinFETs with Si substrate are evaluated by TCAD simulation. Hydrodynamic transport with modified mobilities and Fourier´s law of heat conduction with modified thermal conductivities are used in the simulation. Ge p-channel single-fin FinFET devices with different S/D extension lengths and fin heights, and multi-fin FinFETs with different fin numbers and fin pitches are successively investigated. Boundary thermal resistances at source, drain and gate contacts are set to 2000 μm2K/W and the substrate thermal boundary condition is set to 300 K so that the source and drain heat dissipation paths are the first two heat dissipation paths. The results are listed below: (i) 14 nm Ge p-channel single-fin FinFETs with a 47 nm fin pitch experience 9.7% on-state current degradation. (ii) Considering the same input power, FinFETs with a longer S/D extension length show a higher lattice temperature and a larger on-state current degradation. (iii) Considering the same input power, FinFETs with a taller fin height show a higher lattice temperature. (iv) The temperature in multi-fin FinFET devices will first increase then saturate with the increasing fin number. At last, thermal resistances in Ge p-channel single-fin FinFETs and multi-fin FinFETs are investigated."
journal_title,Science China Information Sciences
article_title,High-voltage trench-gate hole-gas enhancement-mode HEMT with multi-conduction channels
keyword,"['multi-conduction channels\xa0', '2-D hole gas\xa0', 'polarization-junction\xa0', 'high-voltage\xa0', 'low specific onresistance\xa0', 'drain-induced barrier lowering effect\xa0']"
history,"['2018-06', '2017-11-20', '2017-01-28', '2017-06-25', '2017-07-26']"
abstract,"Abstract In this paper, we present a novel high-voltage low on-resistance trench-gate (TG) hole-gas enhancement-mode (E-mode) high-electron mobility transistor (HEMT) with multi-conduction channels (MCs) and investigate its mechanism using simulations. This device features a repetitive AlN/GaN heterojunction unit and a GaN/Al0.26Ga0.74N hetero-junction. Its source and drain are located on the same side of the metal-insulator-semiconductor (MIS) TG, and the source is located beside the gate. During operation, first, 2-D electron gas (2DEG) forms MCs at multiple AlN/GaN hetero-interfaces. These MCs result in ultra-low specific on-resistance (R on,sp) and improved transconductance (g m). Second, 2-D hole gas (2DHG) is induced at the GaN/Al0.26Ga0.74N hetero-interface to prevent electrons from being injected from the source to the MCs. As such, E-mode operation is realized, which exceeds the performance of the conventional E-mode method by depleting the 2DEG under the gate. Third, in the off-state, 2DHG and 2DEG are depleted into negative and positive charges, respectively, thereby forming the polarization junction. This depletion region is extended due to the electric field (E-field) modulation effect by the polarization junction, thereby achieving an enhanced breakdown voltage (BV). Fourth, the drain-induced barrier lowering (DIBL) effect is significantly suppressed, which ensures a high BV and low leakage current. Additionally, due to the unique source location, the TG-MC-HEMT is smaller than the conventional MIS AlGaN/GaN HEMT (Con-HEMT). The BV of the TG-MC-HEMT is 604 V and the R on,sp value can be as small as 0.38 mΩ·cm2."
journal_title,Science China Information Sciences
article_title,"Turbo equalization based on joint Gaussian, SIC-MMSE and LMMSE for nonlinear satellite channels"
keyword,"['nonlinear satellite channel\xa0', 'turbo equalization\xa0', 'joint Gaussian\xa0', 'soft interference cancellation-minimum mean square error (SIC-MMSE)\xa0', 'linear minimum mean square error (LMMSE)\xa0']"
history,"['2018-04', '2017-11-20', '2016-10-18', '2017-03-21']"
abstract,"Abstract The nonlinear distortion of wideband signal due to the filtering and efficiently operated high power amplifiers limits the performance of satellite communications. Volterra series can be used to describe the nonlinear satellite channels effectively. Most existing equalizers simply ignore the nonlinear terms or treat all the nonlinear combinations of symbols as interference. In this study, by properly exploiting information from nonlinear terms, we propose three turbo equalizers for nonlinear satellite channels, namely, joint Gaussian (JG), soft interference cancellation-minimum mean square error (SIC-MMSE) and linear minimum mean square error (LMMSE) equalizers. In JG and SIC-MMSE-based equalizers, both the linear and nonlinear terms that contain the symbol of interest are considered as desired signals. Accordingly, the required statistics are calculated based on the a priori probabilities of coded bits from output of channel decoder. For LMMSE-based equalizer, we propose to calculate the extrinsic information from output of equalizer by excluding the prior information in both the linear and nonlinear terms. Simulation results demonstrate that the proposed equalizers significantly outperform the method which ignores the presence of nonlinear interferences. Moreover, the nonlinear terms that contain the symbol of interest can be exploited to further improve the performance of turbo equalization."
journal_title,Science China Information Sciences
article_title,Robust MMSE precoding for massive MIMO transmission with hardware mismatch
keyword,"['robust precoding\xa0', 'massive MIMO\xa0', 'hardware mismatch\xa0', 'channel estimation\xa0', 'large dimensional RMT\xa0']"
history,"['2018-04', '2017-11-20', '2016-10-20', '2017-02-21', '2017-05-05']"
abstract,"Abstract Due to hardware mismatch, the channel reciprocity of time-division duplex massive multiple-input multiple-output system is impaired. Under this condition, there exist several different approaches for base station (BS) to obtain downlink (DL) channel information based on the minimum mean-square-error (MMSE) estimation method. In this paper, we show that with the hardware mismatch parameters BS can obtain the same DL channel information via these different approaches. As the obtained DL channel information is usually imperfect, we propose a precoding technique based on the criterion that minimizes the mean-square-error (MSE) of signal detection at the user terminals (UTs). The proposed precoding is robust to the channel estimation error and significantly improves the system performance compared to the conventional regularized zero-forcing precoding. Furthermore, we derive an asymptotic approximation of the ergodic sum rate for the proposed precoding using the large dimensional random matrix theory, which is tight as the number of antennas both at the BS and UT approach infinity with a fixed non-zero and finite ratio. This approximation can provide a reliable sum rate prediction at a much lower computation cost than Monte Carlo simulations. Simulation results show that the approximation is accurate even for a realistic system dimension."
journal_title,Science China Information Sciences
article_title,The verification of conversion algorithms between finite automata
keyword,[]
history,"['2018-02', '2017-11-17', '2017-05-29', '2017-06-29']"
abstract,None
journal_title,Science China Information Sciences
article_title,New constructions for (multiparty) one-round key exchange with strong security
keyword,[]
history,"['2018-05', '2017-11-17', '2017-03-23', '2017-05-16', '2017-06-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,Modern physiognomy: an investigation on predicting personality traits and intelligence from the human face
keyword,[]
history,"['2018-05', '2017-11-17', '2016-11-26', '2017-04-04', '2017-06-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,Securely min and k-th min computations with fully homomorphic encryption
keyword,[]
history,"['2018-05', '2017-11-17', '2017-03-17', '2017-05-16', '2017-06-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,Survey of recent progress in semantic image segmentation with CNNs
keyword,"['semantic image segmentation\xa0', 'CNN\xa0', 'Pascal VOC 2012 challenge\xa0', 'multi-granularity features\xa0', 'construction of contextual relationships\xa0']"
history,"['2018-05', '2017-11-17', '2017-03-18', '2017-07-20']"
abstract,"Abstract In recent years, convolutional neural networks (CNNs) are leading the way in many computer vision tasks, such as image classification, object detection, and face recognition. In order to produce more refined semantic image segmentation, we survey the powerful CNNs and novel elaborate layers, structures and strategies, especially including those that have achieved the state-of-the-art results on the Pascal VOC 2012 semantic segmentation challenge. Moreover, we discuss their different working stages and various mechanisms to utilize the structural and contextual information in the image and feature spaces. Finally, combining some popular underlying referential methods in homologous problems, we propose several possible directions and approaches to incorporate existing effective methods as components to enhance CNNs for the segmentation of specific semantic objects."
journal_title,Science China Information Sciences
article_title,Path planning for mobile robot using self-adaptive learning particle swarm optimization
keyword,"['path planning\xa0', 'self-adaptive learning particle swarm optimization\xa0', 'learning strategy\xa0', 'learning mechanism\xa0', 'boundary violations handling\xa0']"
history,"['2018-05', '2017-11-15', '2016-12-20', '2017-03-19', '2017-05-16']"
abstract,"Abstract As a challenging optimization problem, path planning for mobile robot refers to searching an optimal or near-optimal path under different types of constrains in complex environments. In this paper, a self-adaptive learning particle swarm optimization (SLPSO) with different learning strategies is proposed to address this problem. First, we transform the path planning problem into a minimisation multi-objective optimization problem and formulate the objective function by considering three objectives: path length, collision risk degree and smoothness. Then, a novel self-adaptive learning mechanism is developed to adaptively select the most suitable search strategies at different stages of the optimization process, which can improve the search ability of particle swarm optimization (PSO). Moreover, in order to enhance the feasibility of the generated paths, we further apply the new bound violation handling schemes to restrict the velocity and position of each particle. Finally, experiments respectively with a simulated robot and a real robot are conducted and the results demonstrate the feasibility and effectiveness of SLPSO in solving mobile robot path planning problem."
journal_title,Science China Information Sciences
article_title,Robust video denoising with sparse and dense noise modelings
keyword,[]
history,"['2018-01', '2017-11-15', '2017-03-22', '2017-06-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,A novel approach framework based on statistics for reconstruction and heartrate estimation from PPG with heavy motion artifacts
keyword,"['photoplethysmography (PPG)\xa0', 'motion artifact\xa0', 'empirical mode decomposition (EMD)\xa0', 'singular value decomposition\xa0', 'discrete wavelet transform\xa0', 'higher-order statistics\xa0']"
history,"['2018-02', '2017-11-13', '2017-05-02', '2017-06-27']"
abstract,"Abstract One of the most important applications of photoplethysmography (PPG) signal is heartrate (HR) estimation. For its applications in wearable devices, motion artifact (MA) may be the most serious challenge for randomness both in format and temporal distribution. This paper proposes an advanced time-frequency analysis framework based on empirical mode decomposition (EMD) to select specific time slices for signal reconstruction. This framework operates with a type of pre-processing called variance characterization series (VCS), EMD, singular value decomposition (SVD), and a precise and adaptive 2-D filtration reported first. This filtration is based on Harr wavelet transform (HWT) and 3rd order cumulant analysis, to make it have resolution in both the time domain and different components. The simulation results show that the proposed method gains 1.07 in absolute average error (AAE) and 1.87 in standard deviation (SD); AAEs’ 1st and 3rd quartiles are 0.12 and 1.41, respectively. This framework is tested by the PhysioBank MIMIC II waveform database."
journal_title,Science China Information Sciences
article_title,Bi-directional and concurrent proof of ownership for stronger storage services with de-duplication
keyword,"['cloud storage\xa0', 'secure de-duplication\xa0', 'data out-source\xa0', 'proof of ownership\xa0', 'bi-directional and concurrent proof\xa0']"
history,"['2018-03', '2017-11-13', '2017-01-05', '2017-05-10']"
abstract,"Abstract In storage service, data de-duplication is a specialized technique for eliminating duplicate copies of repeating data in storage. Especially, client-side de-duplication has more merits than server-side de- duplication since they can improve both the space efficiency and the communication bandwidth. For secure client-side de-duplication, we need a way to prove the ownership of a file to be stored. In the upload step, the server should verify the ownership of a client to give the right of the file without uploading it. On the contrary, the client also want to verify the retrievability for the file since he will delete it from his storage after protocol execution. Existing proof of ownership techniques have been designed for server’s need. In this paper, we first point out that we need the second property in client’s view point, and give a very simple and practical solution which can support the server and the client to prove that they have the same file. We first describe a generic strategy which can help us to construction a bi-directional and concurrent proof of ownership technique from an ordinary proof of ownership technique, and then give an efficient hash-based scheme with security proof in the random oracle model."
journal_title,Science China Information Sciences
article_title,Fingerprint-based access to personally controlled health records in emergency situations
keyword,[]
history,"['2018-05', '2017-11-09', '2017-01-21', '2017-07-19']"
abstract,None
journal_title,Science China Information Sciences
article_title,Decentralized backstepping adaptive output tracking of large-scale stochastic nonlinear systems
keyword,"['stochastic nonlinear systems\xa0', 'adaptive control\xa0', 'backstepping\xa0', 'interconnected subsystems\xa0', 'tracking control\xa0']"
history,"['2017-12', '2017-11-09', '2017-04-28', '2017-06-15']"
abstract,"Abstract The problem of decentralized adaptive output tracking control of a class of interconnected stochastic nonlinear systems is considered. In the control design, decentralized state observers and backstepping techniques are applied. To eliminate the influences of interactions with other subsystems, a differentiable function is employed. It is shown that the designed local adaptive controllers can ensure that all the signals in the closed-loop system are bounded in probability. Furthermore, the tracking errors can be limited to a small residual set around the origin in the fourth moment sense and can be adjusted by choosing suitable design parameters."
journal_title,Science China Information Sciences
article_title,Development of electric cart for improving walking ability — application of control theory to assistive technology
keyword,"['aging\xa0', 'Borg’s scale\xa0', 'dynamic parallel distributed compensation\xa0', 'electrical cart\xa0', None, 'Karvonen formula\xa0', 'lower limbs\xa0', 'pedaling\xa0', 'rating of perceived exertion\xa0']"
history,"['2017-12', '2017-11-09', '2017-06-16', '2017-10-23']"
abstract,"Abstract This paper explains the development of an electric cart that helps the elderly maintain or improve their physical strength. Unlike commercially available ones, it has a pedal unit that provides some exercise for a user in training his lower limbs. An impedance model describes the feeling of pushing the pedals. The largest pedal load is determined based on a pedaling experiment. An H ∞ controller is designed for each of the largest pedal load and virtually no load. A control law, which is based on the concept of dynamic parallel distributed compensation, is designed using the rating of perceived exertion of a driver as a criterion to choose a pedal load between the largest and almost zero. Five university students and twelve elderly people participated experiments to verify the system design and the validity of the system."
journal_title,Science China Information Sciences
article_title,Entropy optimization based filtering for non-Gaussian stochastic systems
keyword,"['non-Gaussian systems\xa0', 'joint probability density function (JPDF)\xa0', 'quadratic information potential\xa0', 'relative entropy\xa0', 'optimal filtering\xa0']"
history,"['2017-12', '2017-11-09', '2017-04-18', '2017-06-13']"
abstract,"Abstract This paper is concerned with the entropy optimization based filter design for a class of multivariate dynamic stochastic systems with simultaneous presence of non-Gaussian process noise and measurement noise. The filter consists of time update and measurement update two steps, where the selection of the filter gain in the measurement update equation is a key issue to be addressed. Different from the classic Kalman filter theory, entropy rather than variance is employed as the filtering performance criterion due to the non-Gaussian characteristic of the estimation error. Following the establishment of the relationship between the probability density functions of random noises and estimation error, two kinds of entropy based performance indices are provided. On this basis, the corresponding optimal filter gains are obtained respectively by using the gradient optimization technique. Finally, some numerical simulations are provided to demonstrate the effectiveness of the proposed filtering algorithms."
journal_title,Science China Information Sciences
article_title,Delay-dependent dissipative filtering for nonlinear stochastic singular systems with time-varying delays
keyword,"['nonlinear stochastic singular systems\xa0', 'dissipative filtering\xa0', 'unknown membership functions\xa0', 'stochastic admissibility\xa0', 'time-varying delays\xa0']"
history,"['2017-12', '2017-11-09', '2017-05-10', '2017-07-03']"
abstract,"Abstract This paper concentrates on studying the delay-dependent dissipative filtering problem for nonlinear stochastic singular systems with time-varying delays via a Takagi-Sugeno (T-S) fuzzy control approach. The T-S fuzzy model is employed to represent a nonlinear stochastic singular system with unknown or partially unknown membership functions. Firstly, based on an auxiliary vector function, by utilizing an integral inequality and the free-weighting-matrix approach, a delay-dependent sufficient condition is derived to enable the considered filtering error system with time-varying delays to be stochastically admissible and dissipative. Furthermore, on the basis of the derived condition, by using a new type of candidate Lyapunov-Krasovskii function, the solvability conditions of the dissipative filter are addressed, and the corresponding fuzzy filter parameters can be obtained by solving a set of linear matrix inequalities. And then, we deduce the solving method for the H∞ filter. The delay-dependent sufficient conditions are proposed to guarantee the systems to be regular, impulsefree, stochastically stable and to achieve a prescribed performance index γ̂. Finally, some simulation examples are proposed to manifest the effectiveness and merits of the filter design methodology developed in the paper."
journal_title,Science China Information Sciences
article_title,3D textured model encryption via 3D Lu chaotic mapping
keyword,"['3D model\xa0', 'surface model\xa0', 'textured model\xa0', '3D model encryption\xa0', '3D Lu chaotic mapping\xa0']"
history,"['2017-12', '2017-11-09', '2017-09-07', '2017-09-26']"
abstract,"Abstract In the emerging Virtual/Augmented Reality (VR/AR) era, three dimensional (3D) content will be popularized just as images and videos today. The security and privacy of these 3D contents should be taken into consideration. 3D contents contain surface models and solid models. Surface models include point clouds, meshes and textured models. Previous work mainly focused on the encryption of solid models, point clouds and meshes. This work focuses on the most complicated 3D textured model. We propose a 3D Lu chaotic mapping based encryption method for 3D textured models. We encrypt the vertices, polygons, and textures of 3D models separately using the 3D Lu chaotic mapping. Then the encrypted vertices, polygons and textures are composited together to form the final encrypted 3D textured model. The experimental results reveal that our method can encrypt and decrypt 3D textured models correctly. Furthermore, typical statistic and brute-force attacks can be resisted by the proposed method."
journal_title,Science China Information Sciences
article_title,Optimal fusion estimation for stochastic systems with cross-correlated sensor noises
keyword,"['optimal estimation\xa0', 'distributed fusion\xa0', 'Kalman filter\xa0', 'cross-correlated noises\xa0', 'linear transformation\xa0']"
history,"['2017-12', '2017-11-09', '2017-04-14', '2017-06-14']"
abstract,"Abstract This paper is concerned with the optimal fusion of sensors with cross-correlated sensor noises. By taking linear transformations to the measurements and the related parameters, new measurement models are established, where the sensor noises are decoupled. The centralized fusion with raw data, the centralized fusion with transformed data, and a distributed fusion estimation algorithm are introduced, which are shown to be equivalent to each other in estimation precision, and therefore are globally optimal in the sense of linear minimum mean square error (LMMSE). It is shown that the centralized fusion with transformed data needs lower communication requirements compared to the centralized fusion using raw data directly, and the distributed fusion algorithm has the best flexibility and robustness and proper communication requirements and computation complexity among the three algorithms (less communication and computation complexity compared to the existed distributed Kalman filtering fusion algorithms). An example is shown to illustrate the effectiveness of the proposed algorithms."
journal_title,Science China Information Sciences
article_title,Robust neural output-feedback stabilization for stochastic nonlinear process with time-varying delay and unknown dead zone
keyword,"['stochastic system\xa0', 'robust neural control\xa0', 'time delay\xa0', 'dead zone\xa0', 'output-feedback\xa0']"
history,"['2017-12', '2017-11-09', '2017-04-12', '2017-05-28']"
abstract,"Abstract This article investigates the output-feedback control of a class of stochastic nonlinear system with time-varying delay and unknown dead zone. A robust neural stabilizing algorithm is proposed by using the circle criterion, the NNs approximation and the MLP (minimum learning parameter) technique. In the scheme, the nonlinear observer is first designed to estimate the unmeasurable states and the assumption “linear growth” of the nonlinear function is released. Furthermore, the uncertainty of the whole system (including the perturbation of time-varying delay) is lumped and compensated by employing one RBF NNs (radial basis function neural networks). Though, only two weight-norm related parameters are required to be updated online for the merit of the MLP technique. And the gain-inversion related adaptive law is targetly designed to mitigate the adverse effect of unknown dead zone. Comparing with the previous work, the proposed algorithm obtains the advantage: a concise form and easy to implementation due to its less computational burden. The theoretical analysis and comparison example demonstrate the substantial effectiveness of the proposed scheme."
journal_title,Science China Information Sciences
article_title,Toward a further understanding of bit-based division property
keyword,[]
history,"['2017-12', '2017-11-08', '2017-04-21', '2017-06-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,Towards dataflow based graph processing
keyword,[]
history,"['2017-12', '2017-11-08', '2017-05-18', '2017-08-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,New strategy for searching disturbance vector of SHA-1 collision attack
keyword,[]
history,"['2017-12', '2017-11-08', '2017-05-25', '2017-08-16']"
abstract,None
journal_title,Science China Information Sciences
article_title,Understanding “software-defined” from an OS perspective: technical challenges and research issues
keyword,[]
history,"['2017-12', '2017-11-08', '2017-08-29', '2017-09-13']"
abstract,None
journal_title,Science China Information Sciences
article_title,Semantic segmentation of high-resolution images
keyword,"['image semantic segmentation\xa0', 'high-resolution images\xa0', 'joint bilateral upsampling\xa0']"
history,"['2017-12', '2017-11-07', '2017-05-28', '2017-10-13']"
abstract,"Abstract Image semantic segmentation is a research topic that has emerged recently. Although existing approaches have achieved satisfactory accuracy, they are limited to handling low-resolution images owing to their large memory consumption. In this paper, we present a semantic segmentation method for high-resolution images. First, we downsample the input image to a lower resolution and then obtain a low-resolution semantic segmentation image using state-of-the-art methods. Next, we use joint bilateral upsampling to upsample the low-resolution solution and obtain a high-resolution semantic segmentation image. To modify joint bilateral upsampling to handle discrete semantic segmentation data, we propose using voting instead of interpolation in filtering computation. Compared to state-of-the-art methods, our method significantly reduces memory cost without reducing result quality."
journal_title,Science China Information Sciences
article_title,Integral sliding mode control design for nonlinear stochastic systems under imperfect quantization
keyword,"['stochastic systems\xa0', 'quantized control\xa0', 'sliding mode control\xa0', 'observer design\xa0', 'packet loss\xa0']"
history,"['2017-12', '2017-11-07', '2017-04-20', '2017-06-26']"
abstract,"Abstract This paper presents a sliding mode control (SMC) scheme via output-feedback approach for Itô stochastic systems under a quantization mechanism. The quantization process is formulated with the imperfection that random packet loss occurs at the logarithmic quantizer. A Luenberger observer is designed, based on the packet loss rate and the imperfect quantized measurement. A novel SMC law is synthesized by utilization of an integral sliding surface. The stochastic stability of the resulting closed-loop system is analyzed in terms of Lyapunov stability, and a set of solvable matrix inequalities are established for practical application requirements. Finally, a simulation example is employed for the illustration of the effectiveness of the presented control scheme."
journal_title,Science China Information Sciences
article_title,Time-inconsistent stochastic linear quadratic control for discrete-time systems
keyword,"['time-inconsistency\xa0', 'open-loop equilibrium control\xa0', 'maximum principle\xa0', 'FBSDE\xa0', 'nonsymmetric Riccati equations\xa0']"
history,"['2017-12', '2017-11-06', '2017-04-16', '2017-07-16']"
abstract,"Abstract This paper is mainly concerned with the time-inconsistent stochastic linear quadratic (LQ) control problem in a more general formulation for discrete-time systems. The time-inconsistency arises from three aspects: the coefficient matrices depending on the initial pair, the terminal of the cost function involving the initial pair together with the nonlinear terms of the conditional expectation. The main contributions are: firstly, the maximum principle is derived by using variational methods, which forms a flow of forward and backward stochastic difference equations (FBSDE); secondly, in the case of the system state being one-dimensional, the equilibrium control is obtained by solving the FBSDE with feedback gain based on several nonsymmetric Riccati equations; finally, the necessary and sufficient solvability condition for the time-inconsistent LQ control problem is presented explicitly. The key techniques adopted are the maximum principle and the solution to the FBSDE developed in this paper."
journal_title,Science China Information Sciences
article_title,Total ionizing dose effects and annealing behaviors of HfO2-based MOS capacitor
keyword,[]
history,"['2017-12', '2017-11-06', '2017-07-14', '2017-09-05']"
abstract,None
journal_title,Science China Information Sciences
article_title,High energy proton and heavy ion induced single event transient in 65-nm CMOS technology
keyword,[]
history,"['2017-12', '2017-11-06', '2017-07-15', '2017-08-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,Research on proton radiation effects on CMOS image sensors with experimental and particle transport simulation methods
keyword,[]
history,"['2017-12', '2017-11-06', '2017-07-15', '2017-09-18']"
abstract,None
journal_title,Science China Information Sciences
article_title,Heavy ion micro-beam study of single-event transient (SET) in SiGe heterjunction bipolar transistor
keyword,[]
history,"['2017-12', '2017-11-06', '2017-07-10', '2017-09-18']"
abstract,None
journal_title,Science China Information Sciences
article_title,Consensus control of stochastic multi-agent systems: a survey
keyword,"['stochastic multi-agent systems\xa0', 'consensus control\xa0', 'stochastic noises\xa0', 'Markovian jump systems\xa0', 'random topology\xa0']"
history,"['2017-12', '2017-11-06', '2017-05-10', '2017-07-16']"
abstract,"Abstract In this article, we provide a review of the consensus control problem for stochastic multi-agent systems (MASs). Recent advances are surveyed according to the method of occurrence of the stochasticity of the MASs. First, the consensus problem is discussed for MASs, wherein individual agents are corrupted by random noises, i.e., the dynamics of agents involve stochasticity in process and/or measurement equations. Both additive noises and multiplicative noises are surveyed in detail and special attention is paid to the MASs whose dynamics are governed by Itô differential equations. Moreover, particular effort is devoted to presenting the latest progress on the consensus problem for a special type of stochastic MAS with Markovian jump parameters. Subsequently, the relevant research is summarized for MASs with noisy communication environments and stochastic sampling. Further, we provide a systematic review of the consensus problems for MASs whose communication topology varies randomly in the process of data propagation among agents. Finally, conclusions are drawn and several potential future research directions are outlined."
journal_title,Science China Information Sciences
article_title,1-MeV electron irradiation effects on InGaAsP/InGaAs double-junction solar cell and its component subcells
keyword,[]
history,"['2017-12', '2017-11-03', '2017-07-10', '2017-09-18']"
abstract,None
journal_title,Science China Information Sciences
article_title,Integral cryptanalysis of SPN ciphers with binary permutations
keyword,[]
history,"['2018-01', '2017-11-03', '2016-12-22', '2017-03-20', '2017-06-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,Inferring diffusion networks with life stage heterogeneity
keyword,"['network inference\xa0', 'life stage heterogeneity\xa0', 'social influence\xa0', 'information diffusion\xa0', 'clustering cascade\xa0']"
history,"['2018-09', '2017-11-02', '2016-07-18', '2017-05-10']"
abstract,"Abstract A network inference problem focuses on discovering the structure of a diffusion network from observed cascades. This problem is significantly more challenging in several settings in which this type of an inference is desirable or necessary because of heterogeneity in the diffusion process. The heterogeneity of the diffusion process in different life stages results in the inaccuracy of a common assumption of constant influence strength. In this study, a Life Stage Heuristic (LSH) method is proposed to model life stage heterogeneity by decoupling the popularity level of an item under propagation from a true strength of social ties to improve inference accuracy. The proposed LSH is incorporated into almost all existing state-of-the-art network inference algorithms to improve estimation accuracy with only minimal changes in the implementation and maintaining the same running time. Additionally, NetRate, NetInf, and ConNIe are used as three examples to demonstrate the power of the proposed method. Furthermore, clustering of cascades prior to the LSH is proposed to eliminate noise, and the optimized method is termed as Clustered Life Stage Heuristic (CLSH). Extensive experiments on synthetic and real world datasets indicate that both LSH and CLSH methods significantly improve the accuracy of network inference."
journal_title,Science China Information Sciences
article_title,A lower dimension lattice attack on NTRU
keyword,[]
history,"['2018-05', '2017-10-30', '2017-01-12', '2017-04-11', '2017-06-21']"
abstract,None
journal_title,Science China Information Sciences
article_title,Observability of Boolean control networks
keyword,"['Boolean control network\xa0', 'observability\xa0', 'semi-tensor product\xa0']"
history,"['2018-09', '2017-10-26', '2017-03-16', '2017-05-16']"
abstract,"Abstract We show some new results on the observability of Boolean control networks (BCNs). First, to study the observability, we combine two BCNs with the same transition matrix into a new BCN. Then, we propose the concept of a reachable set that results in a given set of initial states, and we derive four additional necessary and sufficient conditions for the observability of BCNs. In addition, we present an algorithm and construct an observability graph to determine the observability of BCNs. Finally, we illustrate the obtained results using three numerical examples."
journal_title,Science China Information Sciences
article_title,A better bound for implicit factorization problem with shared middle bits
keyword,"['RSA\xa0', 'implicit factorization problem\xa0', 'middle bits\xa0', 'lattice\xa0', 'Coppersmith’s method\xa0']"
history,"['2018-03', '2017-10-26', '2017-02-07', '2017-06-21']"
abstract,"Abstract This paper presents our investigation of the implicit factorization problem, where unknown prime factors of two RSA moduli share a certain number of middle bits. The problem is described as follows. Let N 1 = p 1 q 1, N 2 = p 2 q 2 be two different n-bit RSA moduli, where q 1, q 2 are both αn-bit prime integers. Suppose that p 1, p 2 share tn bits at positions from t 1 n to t 2 n = (t 1 + t)n. Then this problem focuses on the condition about t, α to factor N 1,N 2 efficiently. At PKC 2010, Faugère et al. showed that N 1,N 2 can be factored when t > 4α. Subsequently, in 2015, Peng et al. improved this bound to t > 4α−3α 2. In this paper, we directly apply Coppersmith’s method to the implicit factorization problem with shared middle bits, and a better bound \(t > 4\alpha  - 4{\alpha ^{\frac{3}{2}}}\) is obtained. The correctness of our approach is verified by experiments."
journal_title,Science China Information Sciences
article_title,Multi-pair massive MIMO amplify-and-forward relaying system with low-resolution ADCs: performance analysis and power control
keyword,"['massive MIMO\xa0', 'relaying system\xa0', 'imperfect CSI\xa0', 'low quantization\xa0', 'power control\xa0']"
history,"['2018-02', '2017-10-26', '2017-05-22', '2017-07-11', '2017-07-26']"
abstract,"Abstract In this paper, we focus on a general multi-pair massive MIMO amplify-and-forward (AF) relaying system where the relay antennas employ low-resolution analog-to-digital converters (ADCs) to reduce the hardware cost. First, considering the effect of low quantization on channel estimation, a tight closed form approximation of the system ergodic achievable rate is derived. Second, some asymptotic analysis is presented to reveal the impacts of the system parameters on the achievable rate. Particularly, the generalized power scaling schemes are characterized. The results indicate that in some cases, when the number of relay antennas grows without bound, the impact of the finite resolution ADCs on data transmission can be eliminated. To enhance the achievable rate of the quantized systems, the optimal user and relay power control schemes are proposed. Furthermore, to reap all the benefits of low-resolution ADCs, another power control scheme is also designed to minimize the total power consumption while guaranteeing the quality-of-service (QoS) requirement of each user, which can help draw some useful insights into the optimal ADC resolution from power saving perspectives. The simulation results confirm the accuracy of our theoretical analysis and the effectiveness of the proposed power control schemes."
journal_title,Science China Information Sciences
article_title,On the structural controllability of distributed systems with local structure changes
keyword,"['structural controllability\xa0', 'distributed systems\xa0', 'subsystems\xa0', 'structure changes\xa0', 'graph theory\xa0']"
history,"['2018-05', '2017-10-23', '2017-03-07', '2017-06-21']"
abstract,"Abstract This paper analyzes the structural controllability of distributed systems, which are composed of many subsystems and have complicated interconnections. Different from traditional methods in centralized systems where global information is required, the method proposed in this paper is based on local structural properties and simplified interconnections, by which the computational burden is highly decreased and the implementation is tractable. Moreover, a necessary condition for global structural controllability is obtained by combining local information. When the structure in any subsystems is changed, only corresponding local information needs to be re-evaluated instead of whole distributed systems, which makes the analysis easier. Finally, examples are given to illustrate the effectiveness of our proposed method."
journal_title,Science China Information Sciences
article_title,Special focus on natural language processing and social computing
keyword,[]
history,"['2017-11', '2017-10-18']"
abstract,None
journal_title,Science China Information Sciences
article_title,The design and performance analysis of optical wireless ACO-MC-CDMA system in the presence of clipping noise
keyword,[]
history,"['2018-02', '2017-10-17', '2017-03-07', '2017-05-18']"
abstract,None
journal_title,Science China Information Sciences
article_title,Encoding syntactic representations with a neural network for sentiment collocation extraction
keyword,"['sentiment collocation extraction\xa0', 'sentiment analysis\xa0', 'syntactic representation\xa0', 'neural network\xa0', 'recursive neural network (RNN)\xa0', 'convolutional neural network (CNN)\xa0']"
history,"['2017-11', '2017-10-16', '2017-01-24', '2017-05-08']"
abstract,"Abstract Sentiment collocation refers to the collocation of a target word and a polarity word. Sentiment collocation extraction aims to extract the targets and their modifying polarity words by analyzing the relationships between them. This can be regarded as a basic sentiment analysis task and is relevant in many practical applications. Previous studies relied mainly on the syntactic path, which is used to connect the target word and the polarity word. To deeply exploit the semantic information of the syntactic path, we propose two types of syntactic representation, namely, relation embedding and subtree embedding, to capture the latent semantic features. Relation embedding is used to represent the latent semantics between targets and their corresponding polarity words, and subtree embedding is used to explore the rich syntactic information for each word on the path. To combine the two types of syntactic representations, a neural network is constructed. We use a recursive neural network (RNN) to model the subtree embeddings, and then the subtree embedding and the word embedding are combined as the enhanced word representation for each word in the syntactic path. Finally, a convolutional neural network (CNN) is adopted to integrate the two types of syntactic representations to extract the sentiment collocations from reviews. Our experiments were conducted on six types of reviews, which included product domains (such as cameras and phones) and service domains (such as hotels and restaurants). The experimental results show that our proposed method can accurately capture the latent semantic features hidden behind the syntactic paths that neither the common feature-based methods nor the syntactic-path-based method can handle, and, further, that it significantly outperforms numerous baselines and previous methods."
journal_title,Science China Information Sciences
article_title,Next-generation innovation and development of intelligent transportation system in China
keyword,"['next-generation intelligent transportation system\xa0', 'innovation and development\xa0', 'integrated trans- portation system\xa0', 'traffic management and control\xa0', 'artificial intelligence\xa0']"
history,"['2017-11', '2017-10-13', '2017-04-05', '2017-07-20']"
abstract,"Abstract As an integrated application of advanced technologies such as information technology, system control technology, and artificial intelligence in the transportation field, the intelligent transportation system (ITS) has been regarded as an efficient and effective solution for alleviating transportation issues that are encountered in several countries around the world. In this paper, the development history of the ITS in China is presented, and the problems and challenges faced by the ITS in China in the new normal state are clearly laid out. Three new ITS development requirements in China are then identified, and six development trends and directions are proposed. Through the successful application of the above guidelines, next generation innovation and development of ITS is expected to be realized in China, promoting and supporting the trends of urbanization, motorization, and informationization, which are resulting in fundamental changes in the development of the Chinese society and economy."
journal_title,Science China Information Sciences
article_title,Convolutional neural networks for expert recommendation in community question answering
keyword,"['community question answering\xa0', 'expert recommendation\xa0', 'convolutional neural networks\xa0', 'classification-based method\xa0', 'expert modeling\xa0']"
history,"['2017-11', '2017-10-13', '2017-06-05', '2017-07-17']"
abstract,"Abstract Community Question Answering (CQA) is becoming an increasingly important web service for people to search for expertise and to share their own. With lots of questions being solved, CQA have built a massive, freely accessible knowledge repository, which can provide valuable information for the broader society rather than just satisfy the question askers. It is critically important for CQA services to get high quality answers in order to maximize the benefit of this process. However, people are considered as experts only in their own specialized areas. This paper is concerned with the problem of expert recommendation for a newly posed question, which will reduce the questioner’s waiting time and improve the quality of the answer, so as to improve the satisfaction of the whole community. We propose an approach based on convolutional neural networks (CNN) to resolve this issue. Experimental analysis over a large real-world dataset from Stack Overflow demonstrates that our approach achieves a significant improvement over several baseline methods."
journal_title,Science China Information Sciences
article_title,Integrating a weighted-average method into the random walk framework to generate individual friend recommendations
keyword,"['multi-individual friend recommendation architecture\xa0', 'behavior context analysis\xa0', 'Intimacy degree\xa0', 'random walk framework\xa0', 'social networks\xa0']"
history,"['2017-11', '2017-10-13', '2017-08-15', '2017-09-08']"
abstract,"Abstract Friend recommendation is a fundamental service in both social networks and practical applications, and is influenced by user behaviors such as interactions, interests, and activities. In this study, we first conduct in-depth investigations on factors that affect recommendation results. Next, we design Friend++, a hybrid multi-individual recommendation model that integrates a weighted average method (WAM) into the random walk (RW) framework by seamlessly employing social ties, behavior context, and personal information. In Friend++, the first plus signifies recommending a new friend through network features, while the second plus stands for using node features. To verify our method, we conduct experiments on three social datasets crawled from the Sina microblog system (Weibo). Experimental results show that the proposed method significantly outperforms six baseline methods in terms of recall, precision, F1-measure, and MAP. As a final step, we describe a case study that demonstrates the scalability and universality of our method. Through discussion, we reach a meaningful conclusion: although common interests are more important than user activities in making recommendations, user interactions may be the most important factor in finding the most appropriate potential friends."
journal_title,Science China Information Sciences
article_title,Sub-THz signals’ propagation model in hypersonic plasma sheath under different atmospheric conditions
keyword,"['sub-THz communication\xa0', 'hypersonic cruise flight\xa0', 'communication blackout\xa0', 'plasma sheath\xa0', 'signal propagation model\xa0', 'signal attenuation\xa0']"
history,"['2017-11', '2017-10-11', '2017-07-18', '2017-08-17']"
abstract,"Abstract One of the aims for modern hypersonic cruise flight is hypersonic global reach. The length of route for such flights could be up to thousands of kilometers. The atmospheric conditions on the route are complicated. On the other hand, hypersonic flights used to suffer from communication blackout. The sub-THz communication is considered as a potential solution to the ‘blackout’. In the present study the propagation for sub-THz signals in hypersonic plasma sheaths was modeled under different atmospheric conditions. According to the study, the electron density and the electron collision frequency near the onboard antenna linearly increase with the atmospheric mass density around the vehicle, hence the attenuation of sub-THz signals in hypersonic plasma sheaths increases with the atmospheric mass density. The impact led by the atmospheric temperature is ignorable. Based on the study a new sub-THz signals’ propagation model was developed, which could be utilized for quick estimation for signal propagation under different atmospheric conditions. The geographical difference of signal propagation over the whole globe was obtained with the new model. The results showed that the signal attenuation in plasma sheaths varies with latitude and longitude. The maximum signal attenuation occurs in Alaska, Canada and Russia."
journal_title,Science China Information Sciences
article_title,New quaternary sequences of even length with optimal auto-correlation
keyword,"['binary sequences\xa0', 'quaternary sequences\xa0', 'Gray mapping\xa0', 'interleaving\xa0', 'cyclotomy\xa0']"
history,"['2018-02', '2017-10-11', '2016-10-16', '2017-03-21']"
abstract,"Abstract Sequences with low auto-correlation property have been applied in code-division multiple access communication systems, radar and cryptography. Using the inverse Gray mapping, a quaternary sequence of even length N can be obtained from two binary sequences of the same length, which are called component sequences. In this paper, using interleaving method, we present several classes of component sequences from twin-prime sequences pairs or GMW sequences pairs given by Tang and Ding in 2010; or two, three or four binary sequences defined by cyclotomic classes of order 4. Hence we can obtain new classes of quaternary sequences, which are different from known ones, since known component sequences are constructed from a pair of binary sequences with optimal auto-correlation or Sidel’nikov sequences."
journal_title,Science China Information Sciences
article_title,Opportunistic access control for enhancing security in D2D-enabled cellular networks
keyword,"['device-to-device (D2D) communication\xa0', 'opportunistic access control\xa0', 'physical layer security (PHY-security)\xa0', 'secrecy outage probability (SOP)\xa0', 'connection outage probability (COP)\xa0']"
history,"['2018-04', '2017-10-11', '2017-03-28', '2017-06-26']"
abstract,"Abstract In this paper, we investigate secure communication over cellular uplinks in device-to-device (D2D)-enabled cellular networks. We consider a more general scenario, in which multiple D2D pairs could simultaneously share the same resource block with a specific cellular user. First, an opportunistic access control scheme based on wireless channel gains is proposed, by which the candidate selected set of D2D pairs sharing the same resource block is determined. The proposed scheme could guarantee reliable communications for both cellular users and D2D pairs, and further could combat eavesdroppers while keeping the legitimate cellular user as non-intrusive as possible, regarding D2D pairs as friendly jammers in a non-collaborative way. Then, we derive theoretical results to characterize the security and reliability of the typical cellular and D2D links, respectively. To further support the performance of this hybrid network, we next present an interference threshold optimization model. Our aim is to minimize the connection outage probability (COP) of D2D pairs subject to the secrecy requirement of the cellular user. Finally, simulation results are presented to validate the effectiveness of our proposed scheme."
journal_title,Science China Information Sciences
article_title,Patch-based topic model for group detection
keyword,"['group detection\xa0', 'collective behavior\xa0', 'crowd analysis\xa0', 'latent topic\xa0']"
history,"['2017-11', '2017-10-10', '2017-07-12', '2017-09-19']"
abstract,"Abstract Pedestrians in crowd scenes tend to connect with each other and form coherent groups. In order to investigate the collective behaviors in crowds, plenty of studies have been conducted on group detection. However, most of the existing methods are limited to discover the underlying semantic priors of individuals. By segmenting the crowd image into patches, this paper proposes the Patch-based Topic Model (PTM) for group detection. The main contributions of this study are threefold: (1) the crowd dynamics are represented by patchlevel descriptor, which provides a macroscopic-level representation; (2) the semantic topic label of each patch are inferred by integrating the Latent Dirichlet Allocation (LDA) model and the Markov Random Fields (MRF); (3) the optimal group number is determined automatically with an intro-class distance evaluation criterion. Experimental results on real-world crowd videos demonstrate the superior performance of the proposed method over the state-of-the-arts."
journal_title,Science China Information Sciences
article_title,"Multi-leader multi-follower coordination with cohesion, dispersion, and containment control via proximity graphs"
keyword,"['cooperative control\xa0', 'multi-agent system\xa0', 'containment control\xa0', 'cohesion\xa0', 'dispersion\xa0', 'collision-free movement\xa0']"
history,"['2017-11', '2017-10-10', '2017-04-11', '2017-06-23']"
abstract,"Abstract This paper studies the problem of multi-leader multi-follower coordination with proximity-based network topologies. The particular interest is to drive all the followers towards the convex hull formed by the moving leaders while producing cohesion behavior and keeping group dispersion. First, in the case of stationary leaders, we design a gradient-based continuous control algorithm. We show that with this continuous algorithm the control objective can be achieved, and the tracking error bound can be controlled by tuning some control parameters. We apply the continuous control algorithm to the moving leaders case and show that the tracking error bound is related to the velocities of the leaders. However, in this case, the algorithm has one restriction that the velocities of the leaders should depend on neighboring followers’ velocities, which might not be desirable in some scenarios. Therefore, we propose a nonsmooth algorithm for moving leaders which works under the mild assumption of boundedness of leaders’ velocities. Finally, we present numerical examples to show the validity of the proposed algorithms."
journal_title,Science China Information Sciences
article_title,Automatic salient object sequence rebuilding for video segment analysis
keyword,"['salient object\xa0', 'video attention\xa0', 'sequence segment analysis\xa0', 'conditional random model\xa0']"
history,"['2018-01', '2017-09-29', '2017-05-03', '2017-06-30']"
abstract,"Abstract Detection of salient object sequences from video data is challenging when the salient object changes between consecutive frames. In this study, we addressed the salient object sequence rebuilding problem with video segment analysis. We reformulated the problem as a binary labeling problem, analyzed the potential salient object sequences in the video using a clustering method, and separated the salient object sequence from the background by applying an energy optimization method. Our proposed approach determines whether temporal consecutive pixels belong to the same salient object sequence. The conditional random field is then learned to effectively integrate the salient features and the sequence consecutive constraints. A dynamic programming algorithm was developed to resolve the energy minimization problem efficiently. Experimental results confirmed the ability of our approach to address the salient object rebuilding problem in automatic visual attention applications and video content analysis."
journal_title,Science China Information Sciences
article_title,A secure rational quantum state sharing protocol
keyword,"['rational\xa0', 'quantum state sharing\xa0', 'Nash equilibrium\xa0', 'secure\xa0', 'correct\xa0']"
history,"['2018-02', '2017-09-28', '2016-12-11', '2017-01-16']"
abstract,"Abstract A novel rational protocol to share two arbitrary qubits among multiple parties is investigated in this paper. First, the protocol is presented, which is learned from Li et al.’s protocol. Second, the utility, security, correctness, fairness, Nash equilibrium, and Pareto optimality of our scheme are discussed in detail, where the utility, correctness, and fairness of rational quantum state sharing protocols are creatively given because the agent who recovers the state plays a different and more important role. Another important point is that assumptions about our protocol are more practical and suitable than existing protocols."
journal_title,Trauma und Berufskrankheit
article_title,Erratum zu: Spezifika der Traumatologie bei KindernErratum to: Specifics of traumatology in children
keyword,[]
history,"['2018-08', '2018-01-25']"
abstract,None
journal_title,Trauma und Berufskrankheit
article_title,Neustrukturierung des Verletzungsartenverfahrens-/SchwerstverletzungsartenverfahrenskatalogRestructuring of the injury type procedure/severe injury type procedure catalogue
keyword,"['Verletzungsartenverfahren\xa0', 'Schwerstverletzungsartenverfahren\xa0', 'Kindliche Verletzungen\xa0', 'Hüftgelenknahe Oberschenkelbrüche\xa0', 'Kindesalter\xa0', 'Injury type procedure\xa0', 'Severe injury type procedure\xa0', 'Pediatric injuries\xa0', 'Proximal femoral fractures\xa0', 'Childhood\xa0']"
history,"['2018-08', '2018-01-16']"
abstract,"ZusammenfassungDie Überarbeitung des Verletzungsartenverzeichnisses in der Fassung aus 2013 ging über die ursprünglich vorgesehene redaktionelle Überarbeitung hinaus und kann nunmehr als Fassung 2.0 bezeichnet werden. Als 11. Punkt wurden die Komplikationen, wie sie typisch nach Monaten oder Jahren auftreten, wieder in das Verzeichnis übernommen. Systematisch überarbeitet wurden Aufzählungen, die nunmehr mittels Spiegelstrichen klar dargestellt werden. Neu aufgenommen als Punkt 6.5 wurden die hüftgelenknahen Brüche des Oberschenkels. Das Kindesalter ist für das Verletzungsartenverzeichnis mit der Vollendung des 15. Lebensjahres nach oben definiert. Es ist geplant, die Neufassung im Laufe des Jahres 2018 in Kraft zu setzen."
journal_title,Trauma und Berufskrankheit
article_title,Kausalitätsbeurteilung Berufskrankheit Nr. 2102Assessment of causality for occupational disease nr. 2102
keyword,"['Meniskusschaden\xa0', 'Kniegelenk\xa0', 'Exposition\xa0', 'Verlauf\xa0', 'Minderung der Erwerbsfähigkeit\xa0', 'Meniscal injury\xa0', 'Knee joint\xa0', 'Exposure\xa0', 'Course\xa0', 'Reduction in earning capacity\xa0']"
history,"['2018-08', '2017-09-07']"
abstract,ZusammenfassungBerufsbedingte Meniskusschäden wurden als sog. Bergmann-Meniskus 1952 in die Berufskrankheitenliste aufgenommen. Seit 1988 wurde die Berufskrankheit auf alle Berufe erweitert. Exposition und Meniskusschaden müssen vollbeweislich gesichert sein. Es müssen ein belastungskonformes Schadensbild und ein belastungskonformer Verlauf vorliegen. Bei konstant 1000 bis 1200 Verdachtsanzeigen pro Jahr wird etwa ein Fünftel der Fälle anerkannt. Die Höhe der Minderung der Erwerbsfähigkeit (MdE) richtet sich nach den Erfahrungswerten im Schrifttum.
journal_title,Trauma und Berufskrankheit
article_title,Tipps zur Versorgung der suprakondylären HumerusfrakturTips in the treatment of supracondylar humeral fractures in childhood
keyword,"['Radialer externer Fixateur\xa0', 'Suprakondyläre Humerusfrakturen\xa0', 'Kind\xa0', 'Outcome\xa0', 'Postoperative Komplikationen\xa0', 'Radial external fixators\xa0', 'Supracondylar humeral fractures\xa0', 'Child\xa0', 'Treatment outcome\xa0', 'Postoperative complications\xa0']"
history,"['2018-08', '2018-02-22']"
abstract,ZusammenfassungHintergrundFür Chirurgen mit weniger Erfahrung in der Behandlung von Kinderfrakturen stellt die suprakondyläre Humerusfraktur eine besondere Herausforderung dar. Die hauptsächliche Ursache liegt neben der geringen Erfahrung vor allem in einer mangelhaften Diagnostik im Sinne schlechter Röntgenuntersuchungen und der damit verbundenen schwierigen Beurteilung und der daraus folgenden ungenügenden Behandlung.Ziel dieses ArtikelsEs sollen die häufigsten Diagnostik- und Beurteilungsfehler sowie Fehleinschätzungen dargelegt und diskutiert werden. Mit Tipps und Tricks werden Hinweise zur optimalen Versorgung dieser Fraktur gegeben.
journal_title,Trauma und Berufskrankheit
article_title,Digitale Vernetzung in der MedizinDigital networking in medicine
keyword,"['Unfallmedizin\xa0', 'Prävention\xa0', 'Berufsgenossenschaften\xa0', 'Digitalisierung\xa0', 'Versorgungsprozess\xa0', 'Trauma medicine\xa0', 'Prevention\xa0', 'Occupational insurance association\xa0', 'Digitization\xa0', 'Healthcare process\xa0']"
history,"['2018-08', '2017-12-12']"
abstract,"ZusammenfassungEffektive Vernetzung ist die Voraussetzung guter Unfallmedizin. Erst das Zusammenspiel aller an der Versorgung beteiligten Experten und Fachdisziplinen kann den bestmöglichen Ausgang eines Unfallereignisses, aber auch die Prävention eines solchen sicherstellen helfen. Darüber hinaus ist die Vernetzung des Versorgungsprozesses als Prinzip der Arbeit der Berufsgenossenschaften bewährt und kann als eine Ursache ihres Erfolgs gelten. Mit dem Einsatz digitaler Technologien gelingt es, die Vernetzung weiter zu optimieren. Grund genug, die Anwendungen digitaler Medizin genauer zu betrachten und die Möglichkeiten für die Weiterentwicklung der Unfallmedizin zu nutzen."
journal_title,Trauma und Berufskrankheit
article_title,Sehnenrupturen in der Folge distaler RadiusfrakturenTendon ruptures following distal radius fractures
keyword,"['Distale Radiusfraktur\xa0', 'EPL-Sehnenruptur\xa0', 'FPL-Sehnenruptur\xa0', 'Indicis-Transfer\xa0', 'Tenodese\xa0', 'Distal radial fracture\xa0', 'Closed rupture of EPL tendon\xa0', 'Closed rupture of FPL tendon\xa0', 'Extensor indicis tensor transfer\xa0', 'IP joint fusion\xa0']"
history,"['2018-08', '2017-08-18']"
abstract,"ZusammenfassungRupturen der langen Daumenstrecksehne (EPL) in der Folge einer distalen Radiusfraktur treten nicht nur bei überstehenden Schrauben nach palmarer Plattenosteosynthese auf, sondern auch unter konservativer Therapie und hier insbesondere bei undislozierten Frakturen. Das Zeitintervall zwischen Unfall und Sehnenruptur beträgt wenige Wochen bis Monate. Die motorische Ersatzoperation mit Umlagerung der Extensor-indicis-Sehne auf die EPL-Sehne (der sog. Indicis-Transfer) ist ein bewährtes Verfahren. Die Rekonstruktion mit freiem Sehnentransplantat stellt eine mögliche Alternative dar. Die Wahl der richtigen, leicht überkorrigierten Vorspannung ist entscheidend und wird intraoperativ im Tenodesetest geprüft. Die Arthrodese des Daumenendgelenks stellt bei EPL-Ruptur keine Alternative dar. Rupturen der langen Daumenbeugesehne (FPL) werden in der Folge einer distalen Radiusfraktur ausschließlich nach Osteosynthese mit palmarer Platte beobachtet. Das Zeitintervall zwischen Osteosynthese und Sehnenruptur beträgt Jahre bis mehr als 1 Jahrzehnt. FPL-Sehnenrupturen kündigen sich meist mehrere Wochen lang durch Krepitation und Schmerzen an. Die Indikation zur Metallentfernung nach knöcherner Konsolidierung, bei palmaren distalen Radiusplatten generell gegeben, ist jetzt dringlich. Wenn die FPL-Sehnenruptur dennoch eintritt, dann stellen das Palmaris-longus-Sehneninterponat oder der Ringfinger (FDS4)-Sehnentransfer, oft in zweizeitiger Technik nach Implantation eines Silikonstabes, die Möglichkeiten der Sehnenrekonstruktion dar. Eine für den Patienten weit weniger zeitaufwendige, bei der FPL-Sehnenruptur gute Alternative ist die Daumenendgelenkarthrodese oder -tenodese, sofern die Thenarmuskulatur eine gute Flexion des Daumengrundgelenks zeigt."
journal_title,Trauma und Berufskrankheit
article_title,Berufsgenossenschaftliche Patienten im DRG-SystemOccupational insurance scheme patients in the DRG system
keyword,"['Stationäre Behandlung\xa0', 'Arbeitsunfälle\xa0', 'Berufskrankheiten\xa0', 'Gesetzliche Krankenversicherung\xa0', 'Diagnosis Related Groups\xa0', 'Inpatient treatment\xa0', 'Work-related accidents\xa0', 'Occupational diseases\xa0', 'Statutory health insurance\xa0', 'Diagnosis-related groups\xa0']"
history,"['2018-08', '2017-09-07']"
abstract,"ZusammenfassungIn Deutschland existieren für die Behandlung von Patienten unterschiedliche Versicherungssysteme. Für die Behandlung von Patienten nach Arbeitsunfällen und bei Berufskrankheiten ist die Deutsche Gesetzliche Unfallversicherung (DGUV) zuständig, für die Behandlung aller anderer Patienten entweder die gesetzliche Krankenversicherung (GKV) oder die private Krankenversicherung (PKV). Die stationäre Behandlung von Patienten wird in Deutschland auf der Basis der DRG („diagnosis related groups“) abgerechnet. Das DRG-System ist ganz auf die Belange der GKV ausgerichtet. Die Aufgaben der GKV und der DGUV unterscheiden sich aber deutlich. Die hierdurch bedingten Probleme und Lösungsvorschläge werden aufgezeigt."
journal_title,Trauma und Berufskrankheit
article_title,Berufskrankheit Gonarthrose (BK 2112)Occupational disease gonarthrosis (BK 2112)
keyword,"['Begutachtung\xa0', 'Kniebelastung\xa0', 'Kausalität\xa0', 'Knorpelschäden\xa0', 'Kniegelenk\xa0', 'Expert opinion\xa0', 'Knee burden\xa0', 'Causality\xa0', 'Cartilage injury\xa0', 'Knee joint\xa0']"
history,"['2018-08', '2017-07-13']"
abstract,"ZusammenfassungAm 11.06.2009 wurde in Deutschland die Berufskrankheit „Gonarthrose durch eine Tätigkeit im Knien oder vergleichbare Kniebelastung mit einer kumulativen Einwirkungsdauer während des Arbeitslebens von mindestens 13.000 h und einer Mindesteinwirkungsdauer von mindestens einer Stunde pro Schicht“ in die Berufskrankheitenliste aufgenommen. Mit vergleichbarer Kniebelastung gemeint sind Kriechen, Hocken und Fersensitz. Kriterien für die Zusammenhangsbegutachtung werden dargestellt."
journal_title,Trauma und Berufskrankheit
article_title,Individualisierte Implantate auf der Basis digitaler DatenIndividualized implants based on digital data
keyword,"['Computertomographie\xa0', 'Magnetresonanztomographie\xa0', 'Digitale Volumentomographie\xa0', 'Operationsplanung\xa0', 'Dreidimensionale Modelle\xa0', 'Computed tomography\xa0', 'Magnetic resonance imaging\xa0', 'Digital volume tomography\xa0', 'Operation planning\xa0', 'Three-dimensional models\xa0']"
history,"['2018-08', '2018-03-14']"
abstract,"ZusammenfassungMit Computertomographie (CT), Magnetresonanztomographie (MRT) und digitaler Volumentomographie (DVT) werden digitale Daten generiert, mithilfe derer dreidimensionaler Darstellungsvarianten man sich ein exaktes räumliches Bild des Situs machen kann. Außerdem kann der Datensatz für die Herstellung dreidimensionaler Modelle wie individualisierte Implantate sowie zur intraoperativen Navigation genutzt werden."
journal_title,Trauma und Berufskrankheit
article_title,Spezifika der Traumatologie bei KindernSpecifics of traumatology in children
keyword,"['Kindertraumatologie\xa0', 'Epiphysenfuge\xa0', 'Korrekturpotenzial\xa0', 'Wachstumsstörung\xa0', 'Versorgungsstruktur\xa0', 'Pediatric traumatology\xa0', 'Epiphysis\xa0', 'Remodeling\xa0', 'Growth disturbance\xa0', 'Medical care\xa0']"
history,"['2018-08', '2017-08-02']"
abstract,ZusammenfassungNach Frakturen im Kindesalter führen die offenen Epiphysenfugen sowohl zur Chance einer spontanen Achsenkorrektur als auch zu dem Risiko einer Wachstumsstörung. Die Kenntnis der Grenzen sowohl der operativen als auch der konservativen Therapie ist für eine kindgerechte Frakturversorgung unerlässlich. Allein schon aufgrund der hohen Inzidenz ist eine interdisziplinäre Versorgung von Vorteil.
journal_title,Trauma und Berufskrankheit
article_title,Minderung der Erwerbsfähigkeit (MdE) in der gesetzlichen UnfallversicherungReduction in earning capacity (MdE) in the German statutory accident insurance
keyword,"['Reformbedarf\xa0', 'Unterschenkelamputation\xa0', 'Sozialgesetzbuch\xa0VII\xa0', 'Arbeitsunfall\xa0', 'Konsensusprozess\xa0', 'Reform needs\xa0', 'Lower limb amputation\xa0', 'Social Security Statutes VII\xa0', 'Occupational accident\xa0', 'Consensus process\xa0']"
history,"['2018-08', '2017-09-11']"
abstract,"ZusammenfassungDie Expertengruppe zur Reform der Minderung der Erwerbsfähigkeit (MdE) unter der Schirmherrschaft der Deutschen Gesetzlichen Unfallversicherung (DGUV) hat die v. a. aus dem Deutschen Sozialgerichtstag 2012 hervorgegangene Kritik an den gegenwärtigen MdE-Tabellenwerten für orthopädisch/unfallchirurgische Arbeitsunfallfolgen aufgenommen und in einem interdisziplinären methodischen Ansatz überprüft. Es sollte der Bezug dieser Werte zum aktuellen deutschen Arbeitsmarkt analysiert und auf Aktualität wissenschaftlich überprüft werden. Der Prozess wird hier im Einzelnen dargestellt. Auch unter Zuhilfenahme der Arbeitsmarktforscher in den verschiedenen wissenschaftlichen Instituten der Agentur für Arbeit war es nicht möglich, das von der Expertengruppe für einen prothetisch gut versorgten unterschenkelamputierten Verletzten definierte Teilhabedefizit in der konkreten Beschäftigungsmöglichkeit so abzubilden, dass dabei verlässliche Arbeitsmarktdaten zu verschlossenen Beschäftigungsmöglichkeiten und daraus ableitbaren verwehrten Anteilen am gesamten Arbeitsmarkt abschätzbar waren. Der schon von anderen Arbeitsgruppen immer wieder versuchte Weg muss damit als nicht zielführend angesehen werden. Wissenschaftlich begründbare Daten für einen MdE-Wert im Sinne des Wortlautes des SGB VII lassen sich nicht erheben. Dennoch ist unter den verschiedenen kritischen Punkten, denen sich die MdE-Tabellenwerte ausgesetzt sehen, ein interprofessioneller, interdisziplinärer und innergesellschaftlicher Konsensusprozess zur Vereinheitlichung der MdE-Werte erforderlich und von der Expertengruppe in Gang gesetzt worden."
journal_title,Trauma und Berufskrankheit
article_title,Akutversorgung und Spätfolgen bei kindlichen Verletzungen der HalswirbelsäuleAcute treatment and delayed sequelae of pediatric injuries of the cervical spine
keyword,"['Fraktur\xa0', 'Dislokationen\xa0', 'Röntgen\xa0', 'Therapie\xa0', 'Kyphose\xa0', 'Fracture\xa0', 'Dislocation\xa0', 'Medical history taking\xa0', 'X‑rays\xa0', 'Treatment\xa0', 'Kyphosis\xa0']"
history,['2018-04-04']
abstract,"ZusammenfassungKindliche Verletzungen im Bereich der Halswirbelsäule sind selten. Wesentlich sind eine frühzeitige Diagnosestellung und die rasche, konsequente Therapie. Dies ist die wahrscheinlich beste Ausgangssituation, um Spätfolgen zu vermeiden, denn diese würden das Kind ein Leben lang behindern. Entsprechend behandelt dieser Beitrag die Akutversorgung und Spätfolgen bei kindlichen Verletzungen der Halswirbelsäule."
journal_title,Trauma und Berufskrankheit
article_title,Besonderheiten bei Frakturen rund um den KinderfußSpecial features of fractures of the feet in children
keyword,"['Talus\xa0', 'Kalkaneus\xa0', 'Kindesalter\xa0', 'Operation\xa0', 'Komplikation\xa0', 'Talus\xa0', 'Calcaneus\xa0', 'Childhood\xa0', 'Operation\xa0', 'Complications\xa0']"
history,['2018-04-04']
abstract,"ZusammenfassungFrakturen des Kinderfußes sind meist benigne Verletzungen und können konservativ behandelt werden. Der überwiegende Anteil der Frakturen betrifft den Vorfuß, diese Frakturen können meist ohne besonderen Aufwand konservativ versorgt werden. Im Gegensatz hierzu treten Fußwurzelfrakturen deutlich seltener auf mit einer Inzidenz von ca. 5 %. Diese Frakturen müssen differenziert betrachtet werden insbesondere in Abhängigkeit vom Alter und der Dislokation. Ein Kinderfuß hat in Abhängigkeit vom Geschlecht des Kindes mit dem 12. Lebensjahr deutlich über 90 % seiner prospektiven Endgröße erreicht, und damit sinkt die Fähigkeit des Fußes, Fehlstellungen zu remodellieren. Die Versorgung von Fußwurzelfrakturen muss dieser Fähigkeit Rechnung tragen. Die Versorgung der Kalkaneusfrakturen wird kontrovers diskutiert, und die Tendenz zur operativen Stabilisation bei Jugendlichen mit intraartikulären Kalkaneusfrakturen ähnlich der Versorgung von Erwachsenen findet zunehmend Zuspruch. Kalkaneusfrakturen bei Kindern unter dem 6. Lebensjahr bleiben häufig unentdeckt, hier gilt es, daran zu denken. Nicht dislozierte Talusfrakturen sollten konservativ versorgt werden. Talushalsfrakturen sind die häufigsten Frakturen des Talus, bei dislozierten Talushalsfrakturen sollte die operative Versorgung – wenn möglich semioffen durchgeführt werden. Aufgrund seiner spezifischen Durchblutung stellt hier die Talusnekrose eine besondere Komplikation dar."
journal_title,Trauma und Berufskrankheit
article_title,Der DauerpatientThe long-term patient
keyword,"['Gesetzliche Unfallversicherung\xa0', 'Therapiesteuerung\xa0', 'Qualitätssicherung\xa0', 'Rehabilitationsstandard\xa0', 'Heilverfahren \xa0', 'Statutory accident insurance\xa0', 'Therapy management\xa0', 'Quality assurance\xa0', 'Rehabilitation standards\xa0', 'Healing process\xa0']"
history,['2018-03-19']
abstract,"ZusammenfassungBei näherer Betrachtung der Physiotherapie als etabliertes Heilverfahren der gesetzlichen Unfallversicherung wird deutlich, dass die Organisation und die allgemeinen Inhalte des Verfahrens grundsätzlich geregelt sind. Unter Beachtung von möglichen Entscheidungshilfen und Fallbeispielen erscheint es vielmehr sinnvoll, Maßnahmen in das Therapieverfahren zu integrieren, die die Therapieplanung und -steuerung optimieren und sich an den aktuellen Rehabilitationsstandards orientieren. Die Bestimmung individueller Kontextfaktoren, die Patientenberatung, die Vereinbarung von Reha-Zielen, die Verwendung von Assessments, die Spezifizierung der Behandlungsschwerpunkte sowie die Förderung der Kommunikation zwischen Arzt und Therapeut gelten in diesem Zusammenhang als bedeutsame Entitäten zur Verbesserung des Qualitätsmanagements und folglich zur Findung der angemessenen Behandlungsdosis. Diese sollten bei einer kommenden Überarbeitung der Handlungsanleitung zur Verordnung von Leistungen zur Physiotherapie berücksichtigt werden."
journal_title,Trauma und Berufskrankheit
article_title,Teledermatologie und künstliche IntelligenzTeledermatology and artificial intelligence
keyword,"['Hautarztverfahren\xa0', 'Hautkrebs\xa0', 'Smartphone\xa0', 'Telemedizin\xa0', 'e-Health\xa0', 'Dermatologist procedure\xa0', 'Skin cancer\xa0', 'Smartphone\xa0', 'Telemedicine\xa0', 'eHealth\xa0']"
history,['2018-03-19']
abstract,"ZusammenfassungTelemedizin mit der besonderen Anwendung Teledermatologie (e-Health) ist der Einsatz von Telekommunikationstechnologien zum Austausch medizinischer Informationen für Diagnostik, Konsultation, Therapie und Lehre. Mittels „künstlicher Intelligenz“ (KI) können Maschinen lernen und so unter wechselnden Umweltbedingungen flexibel eingesetzt werden. Teledermatologie und durch KI unterstützte mobile Bildanalysesysteme als Teil von e‑Health dürften für Prävention, Diagnostik, Therapieadhärenz und Nachsorge von Patienten mit (drohenden) Berufskrankheiten der Haut ein erhebliches Potenzial zu einer Verbesserung der Versorgung besitzen. Ein dermatologisches Telekonsil könnte Arbeitsmediziner und Betriebsärzte bei der arbeitsmedizinischen Vorsorge in hautbelastenden Berufen, aber auch beim Hautkrebsscreening von Outdoor-Workern unterstützen und so zu rascherer Prävention oder Anerkennung einer Berufskrankheit beitragen. Mittels moderner, von KI-Technologien unterstützter mobiler Smartphone-Apps könnten auch das Selbstmonitoring von Beschäftigten in Risikoberufen, die frühzeitige arbeitsmedizinische Intervention und die dermatologische Therapiebegleitung verbessert werden."
journal_title,Trauma und Berufskrankheit
article_title,Versorgung von frischen BeugesehnenverletzungenManagement of acute flexor tendon injuries
keyword,"['Nahttechnik\xa0', 'Ergebnisse\xa0', 'Zweistrangnaht\xa0', 'Vierstrangnaht\xa0', 'Ruptur\xa0', 'Suture technique\xa0', 'Results\xa0', 'Two-strand suture\xa0', 'Four-strand suture\xa0', 'Rupture\xa0']"
history,['2018-03-06']
abstract,"ZusammenfassungZiel der chirurgischen Versorgung von Beugesehnenverletzungen ist die frühzeitige Wiederherstellung der Kontinuität durch eine ausreichend stabile Naht, um eine frühfunktionelle passive oder aktive Behandlung zu erlauben und so Adhäsionen der Sehne – insbesondere im osteofibrösen Kanal der Finger – zu vermeiden. In den letzten Jahren wurde eine Vielzahl an Nahttechniken in den unterschiedlichsten Modifikationen beschrieben. Im Sinne „je mehr Nahtmaterial, desto stabiler“ wurde der Fokus auf die Erhöhung der Stranganzahl der Kernnaht gelegt, um frühzeitig aktive Nachbehandlungskonzepte zu erlauben. Trotz der höheren initialen biomechanischen Stabilität dieser Nahttechniken in experimentellen Studien konnte in klinischen Übersichtsarbeiten hinsichtlich der Rupturrate kein statistisch signifikanter Unterschied zwischen Zweistrang- und Mehrstrangnähten nachgewiesen werden. Auch bezüglich des funktionellen Ergebnisses war keine Überlegenheit der Mehrstrangtechniken gegenüber den Zweistrangtechniken nachzuweisen. Dementsprechend gibt es bis heute, abgesehen von einer stabilen Kernnaht und einer glättenden Feinadaptation, keinen Goldstandard hinsichtlich der idealen Nahttechnik oder des optimalen Nahtmaterials zur Versorgung von Beugesehnenverletzungen."
journal_title,Trauma und Berufskrankheit
article_title,Knochen und WeichteilsarkomeBone and soft tissue sarcomas
keyword,[]
history,"['2018-03', '2018-03-09']"
abstract,None
journal_title,Trauma und Berufskrankheit
article_title,Behandlung der Femurschaftfraktur im WachstumsalterTreatment of femoral shaft fractures in the growing phase
keyword,"['Kindesmisshandlung\xa0', 'Kind\xa0', 'Unfall\xa0', 'Hochrasanztrauma\xa0', 'Gips\xa0', 'Child abuse\xa0', 'Child\xa0', 'Accident\xa0', 'High velocity trauma\xa0', 'Plaster casts\xa0']"
history,"['2018-03', '2017-06-21']"
abstract,"ZusammenfassungFemurschaftfrakturen im Kindesalter zeigen im Wesentlichen 2 Altersgipfel. Der eine betrifft Kinder im Alter zwischen 2 und 4 Jahren, der zweite findet sich um die Pubertät. Während in der Gruppe der Kleinkinder Femurschaftfrakturen bereits bei relativ geringer Kraftweinwirkung vorkommen, handelt es sich beim Unfallmechanismus bei den älteren Kindern meist um Hochrasanztraumen. Bei noch nicht gehfähigen Kindern muss stets eine Kindesmisshandlung als Ursache ausgeschlossen werden. Die Behandlung der Femurschaftfraktur im Alter bis 3 Jahre ist in der Regel konservativ mittels Becken-Bein-Gips oder Overheadextension, bei älteren Kindern ist dies die Domäne der elastisch stabilen intramedullären Nagelung (ESIN)."
journal_title,Trauma und Berufskrankheit
article_title,Indikationsprüfung neuer ArmprothesenTesting the indications for new arm prostheses
keyword,"['Amputation\xa0', 'Rehabilitation\xa0', 'Hilfsmittel\xa0', 'Ergotherapie\xa0', 'Assessments\xa0', 'Amputation\xa0', 'Rehabilitation\xa0', 'Medical aids\xa0', 'Occupational therapy\xa0', 'Assessments\xa0']"
history,"['2018-03', '2017-08-02']"
abstract,"ZusammenfassungDie Versorgung mit geeigneten Prothesen von Patienten nach Amputationen an der oberen Extremität stellt eine große Herausforderung dar. Mit der Prothese soll es den Betroffenen erleichtert werden, sich selbst zu versorgen, ihre Freizeit zu gestalten, sich beruflich zu integrieren und an ihrer Umwelt teilzuhaben. Das Ziel der Versorgung ist letztendlich ein „Gleichziehen mit einem gesunden Menschen“. Um aus einer Vielzahl von Versorgungmöglichkeiten den richtigen Prothesentyp und ggf. deren günstigste Konfiguration herauszufiltern, bedarf es eines Messsystems, in dem die Ebenen der ICF (Internationale Klassifikation der Funktionsfähigkeit, Behinderung und Gesundheit) abgebildet sind und das die individuellen Voraussetzungen der Patienten berücksichtigt. Im Rahmen der mehrtägigen stationären Indikationsprüfung erfolgt in der BGU Murnau zunächst eine umfangreiche Testung mit der vorhandenen Prothetik. Nach der Probeversorgung mit der zu testenden Prothese und einer intensiven Gebrauchsschulung werden die Tests nach einigen Tagen mit dem neuen Prothesenpassteil wiederholt. Der Vergleich der Testergebnisse ermöglicht eine sachlich fundierte Aussage hinsichtlich der medizinischen Notwendigkeit einer Versorgung mit der neuen Prothese. Validierte Assessments, wie z. B. OPUS und AM-ULP, sind Teil der Indikationsprüfung. Getestet werden die Bedienung der Prothese auf der Funktionsebene und die Nutzung auf der Aktivitätsebene. Zur Bewertung der Partizipationsfähigkeit werden komplexe Tätigkeiten in Alltagssituationen überprüft, die gemeinsam mit den Probanden ermittelt wurden. In der gesamten Bewertung spielt die Wahrscheinlichkeit für eine langfristige Versorgung eine große Rolle. Besondere Beachtung finden der spontane Gebrauch, mögliche Ausweichbewegungen und die Entlastung der gesunden Gegenseite sowie die der Wirbelsäule. Um einen hohen Grad der Objektivität zu erhalten, bewerten Patienten und medizinisches Personal die einzelnen Teste unabhängig voneinander. Gleichzeitig werden Videoanalysen signifikanter Sequenzen aus der Funktions‑, Aktivitäts- und Partizipationsprüfung erstellt."
journal_title,Trauma und Berufskrankheit
article_title,Leichtes Schädel-Hirn-TraumaMild traumatic brain injury
keyword,"['Postkommotionelles Syndrom\xa0', 'Prognose\xa0', 'Arbeitsfähigkeit\xa0', 'Glasgow Coma Scale\xa0', 'Therapie\xa0', 'Postconcussional syndrome\xa0', 'Prognosis\xa0', 'Return to work\xa0', 'Glasgow coma scale\xa0', 'Treatment\xa0']"
history,"['2018-03', '2017-08-31']"
abstract,"ZusammenfassungHintergrundIn Deutschland erleiden pro Jahr geschätzt ca. 250.000 Menschen ein leichtes Schädel-Hirn-Trauma. Es definiert sich als Folge einer Gewalteinwirkung, die zu einer Funktionsstörung und/oder Verletzung des Gehirns geführt hat über einen Glasgow-Coma-Scale-Wert von 13 bis 15.FragestellungDefinition, Behandlungsoptionen und Prognose des leichten Schädel-Hirn-Traumas werden vorgestellt.Material und MethodenEs erfolgt die Analyse des aktuellen Stands der Wissenschaft nach eigener Erfahrung und Literaturrecherche.ErgebnisseIn der Anfangsphase kann es sich um eine dynamische Störung handeln, sodass eine Krankenhauseinweisung zur genauen Überwachung empfohlen wird. Therapeutisch sollten in den ersten Tagen v. a. äußere Reize durch Abschirmung und Ruhe minimiert werden. Bis zur Symptomfreiheit sollte weder physische noch mentale Aktivität erfolgen. Bei anhaltenden Beschwerden muss eine umfassende Diagnostik eingeleitet werden. Zwar kehrt die Mehrzahl der Betroffenen nach 3 bis 6 Monaten an den vorherigen Arbeitsplatz zurück, es kann aber zu einer Chronifizierung von Beschwerden kommen, dem sog. „chronischen postkommotionellen Syndrom“ (PCS) mit teils unspezifischen Beschwerden wie Kopfschmerzen, Schwindel, kognitiven Störungen, Reizbarkeit etc. Risikofaktoren für die Entwicklung eines PCS können u. a. ein niedriges Bildungsniveau sowie Schwindel und Erbrechen in der Primärsituation sein.DiskussionDas leichte Schädel-Hirn-Trauma wird oft unterschätzt. Es können sich chronische Beschwerden entwickeln, die über Jahre nachweisbar sind und die Rückkehr zum alten Arbeitsplatz verhindern. Daher sollten alle Betroffenen durch eine einfache Fragebogenabfrage nach 3 Monaten gescreent und bei Auffälligkeiten einer ausgiebigen Diagnostik im Rahmen des Brain-Check-Programms zugeführt werden, das von den BG-Kliniken angeboten wird."
journal_title,Trauma und Berufskrankheit
article_title,Primäre und früh-sekundäre Endoprothetik nach Brüchen des HüftgelenksPrimary and early secondary endoprosthesis after fractures of the hip joint
keyword,"['Acetabulumfraktur\xa0', 'Osteosynthese\xa0', 'Hüftendoprothese\xa0', 'Totalendoprothetik\xa0', 'Hüftgelenkersatz\xa0', 'Acetabular fracture\xa0', 'Osteosynthesis\xa0', 'Hip endoprosthesis\xa0', 'Total hip arthroplasty\xa0', 'Hip joint replacement\xa0']"
history,"['2018-03', '2017-12-18']"
abstract,"ZusammenfassungDie Endoprothetik nach Acetabulumfrakturen stellt eine alternative Therapieoption zur Osteosynthese dar. Sowohl beim älteren als auch beim jungen Menschen ist es wesentlich, die Indikationen für beide Verfahren genau zu definieren und voneinander abzugrenzen."
journal_title,Trauma und Berufskrankheit
article_title,Behandlungspfade für WeichteilsarkomePathways in the treatment of soft tissue sarcomas
keyword,"['Algorithmus\xa0', 'Diagnostik\xa0', 'Therapie\xa0', 'Nachsorge\xa0', 'Tumorboard\xa0', 'Algorithm\xa0', 'Diagnostics\xa0', 'Treatment\xa0', 'Follow-up\xa0', 'Tumor board\xa0']"
history,"['2018-03', '2017-10-10']"
abstract,"ZusammenfassungHintergrundWeichteilsarkome stellen mit einer Inzidenz von ca. 1,8–5,5/100.000 pro Jahr nur etwa 1 % der malignen Tumorerkrankungen bei Erwachsenen dar. Diese Seltenheit bedingt gemeinsam mit der Heterogenität und unspezifischen klinischen Symptomatik die häufig verzögerte Diagnostik und uneinheitliche Therapie. Für ein möglichst gutes Outcome ist jedoch ein standardisiertes diagnostisches und therapeutisches Vorgehen notwendig.DiagnostikDer Patient stellt sich typischerweise mit einer schmerzlosen Schwellung vor. Je nach genauer Lage können auch Bewegungseinschränkungen und manchmal neurologische Symptome bestehen. Den Goldstandard der Lokalbildgebung stellt aufgrund ihrer guten Kontraste und Reproduzierbarkeit die Magnetresonanztomographie mit Kontrastmittel dar. Nach Komplettierung der lokalen Bildgebung erfolgt die histologische Tumorbestätigung mittels Stanzbiopsie oder offener Biopsie. Nur in Ausnahmefällen sollte eine Exzisionsbiopsie erfolgen. Bei Bestätigung des Malignitätsverdachts ist vor Therapieeinleitung ein Staging des Patienten zur Metastasensuche notwendig. Dieses erfolgt in der Regel mittels Computertomographie (CT) von Thorax und Abdomen, ggf. auch als PET(Positronenemissionstomographie)-CT.TherapiealgorithmusDas therapeutische Vorgehen wird im Rahmen eines interdisziplinären Tumorboards festgelegt. Für lokal gut resektable Tumoren ohne Metastasen ist die R0-Resektion angezeigt. Diese wird bei High-grade-Sarkomen von einer adjuvanten Strahlentherapie gefolgt. Bei lokal fortgeschrittenen Tumoren oder Metastasen kommen auch neoadjuvante oder adjuvante Chemotherapien sowie die chirurgische Metastasenresektion zum Einsatz.NachsorgeDie Tumornachsorge beinhaltet die regelmäßige klinische und radiologische Kontrolle der Tumorregion sowie Metastasensuche. Sie sollte möglichst am primär behandelnden Tumorzentrum erfolgen."
journal_title,Trauma und Berufskrankheit
article_title,Bildgebung und Interventionen bei Weichteilsarkomen der ExtremitätenImaging and interventions for soft tissue sarcomas of the extremities
keyword,"['Magnetresonanztomographie\xa0', 'Computertomographie\xa0', 'Positronenemissionstomographie\xa0', 'Embolisation\xa0', 'Staging\xa0', 'Magnetic resonance imaging\xa0', 'Computed tomography\xa0', 'Positron emission tomography\xa0', 'Embolization\xa0', 'Staging\xa0']"
history,"['2018-03', '2017-12-18']"
abstract,"ZusammenfassungHintergrundWeichteilsarkome sind seltene Tumoren mit etwa 1 % aller malignen Erkrankungen des Erwachsenen. Das Langzeitergebnis sowie der Erfolg lokaler und systemischer Therapiemaßnahmen hängen entscheidend vom korrekten lokalen Staging des Primärtumors sowie der Tumorausdehnung im Ganzkörperstaging ab.GrundsätzeNeben den klassischen projektionsradiographischen Verfahren und dem Ultraschall spielt beim lokalen Staging von Weichteilsarkomen die Magnetresonanztomographie (MRT) die führende Rolle. Aufgrund des hohen Weichteilkontrastes sowie des Fehlens ionisierender Strahlung ist sie die ideale Methode zur Evaluation und zum Therapiemonitoring nach erfolgter Therapie bei Weichteilsarkomen. Aufgrund des Metastasierungsmusters von Weichteilsarkomen wird das Ganzkörperstaging empfohlen. Hier steht mit der Computertomographie (CT) eine sensitive Methode zur Verfügung. Die Kombination mit metabolischen Verfahren wie der Positronenemissionstomographie (PET) in Form der PET/CT erlaubt eine weitere Steigerung in der Sensitivität pathologischer Befunde. Auch interventionelle Verfahren, wie z. B. Biopsie und Embolisation zur präoperativen Vorbereitung, finden Einsatz.SchlussfolgerungNur durch den gezielten Einsatz moderner bildgebender Verfahren ist heute ein korrektes lokales und systemisches Staging von Weichteilsarkomen zu gewährleisten. In interdisziplinärer Zusammenarbeit in einem Sarkomzentrum sollten Methodenauswahl sowie der Einsatz interventioneller Verfahren individuell für die Situation des Patienten entschieden werden, um so den optimalen Behandlungserfolg bis hin zur langfristigen Tumorfreiheit zu gewährleisten."
journal_title,Trauma und Berufskrankheit
article_title,EllenbogenendoprothetikTotal elbow arthroplasty
keyword,"['Ellenbogentotalendoprothese\xa0', 'Radiuskopfprothese\xa0', 'Prothesenmodelle\xa0', 'Ellenbogenfraktur\xa0', 'Operative Verfahren\xa0', 'Total elbow arthroplasty\xa0', 'Radial head replacement\xa0', 'Prostheses models\xa0', 'Elbow fracture\xa0', 'Surgical procedures\xa0']"
history,"['2018-03', '2017-07-20']"
abstract,"ZusammenfassungEllenbogentotalendoprothesen (EBTEP) finden ihren Einsatz sowohl beim schmerzhaften arthritisch/arthrotisch vorgeschädigten Ellbogengelenk als auch in der akuten Fraktursituation, insbesondere bei nichtrekonstruierbarer distaler Humerusfraktur des geriatrischen Patienten. Die neueren Prothesenmodelle setzten dabei auf einen Semi-constrained-Mechanismus mit Sloppy-hinge-Prinzip (Valgus-Varus-Beweglichkeit ca. ±7°). Die Verwendung trizepserhaltender Zugänge reduziert das Risiko einer postoperativen Trizepsinsuffizienz. Es werden aktuell 10-Jahres-Überlebensraten von 90 % erreicht. Die EBTEP führt zur Schmerzreduktion und zu zufriedenstellenden Bewegungsausmaßen. Die häufigsten Komplikationen sind Infektion, aseptische Lockerung, Gelenkinstabilität und Materialversagen. Radiuskopfprothesen finden ihren Einsatz insbesondere bei nichtrekonstruierbaren Radiuskopffrakturen und seltener bei posttraumatischen Arthrosen des Radiuskopfes. Im eigenen Verfahren wird in der akuten Fraktursituation die monopolare, nicht zementierte Langschaftprothese bevorzugt. Der Kocher-Zugang bietet als Zugangsweg eine gute Exposition des lateralen Ellenbogens, um so die Höheneinstellung der Radiuskopfprothese korrekt durchführen zu können und ein Overstuffing zu vermeiden. In aktuellen Studien konnten mittelfristig in ca. 70–90 % der Fälle gute bis exzellente klinische Ergebnisse ermittelt werden. Die häufigsten Komplikationen sind Overstuffing, Infektion, Implantatversagen und die posttraumatische Arthrose."
journal_title,Trauma und Berufskrankheit
article_title,Prothetische Versorgung der posttraumatischen oberen SprunggelenkarthroseTotal ankle replacement surgery for posttraumatic arthritis
keyword,"['Sprunggelenkarthrodese\xa0', 'Sprunggelenkendoprothese\xa0', 'Mobilität\xa0', 'Lebensqualität\xa0', 'Mobilität\xa0', 'Ankle arthrodesis\xa0', 'Total ankle replacement\xa0', 'Ankle prosthesis\xa0', 'Quality of life\xa0', 'Mobility\xa0']"
history,"['2018-03', '2018-02-05']"
abstract,"ZusammenfassungDer Verlust der Integrität und Funktion des oberen Sprunggelenkes hat für die betroffenen Patienten gravierende Auswirkungen auf die Mobilität und Lebensqualität, die vergleichbar sind mit den Einschränkungen bei Hüftgelenkarthrose. Die weitaus häufigste Ursache von Sprunggelenkarthrosen sind Folgezustände nach Sprunggelenkverletzungen, für die in fortgeschrittenen Stadien mit einer Arthrodese des oberen Sprunggelenkes ein schmerzfreies Gangbild mit guten Ergebnissen auch im mittel- und langfristigen Verlauf wiederhergestellt werden kann. Die alternative Therapieoption des künstlichen Gelenkersatzes mit einer Spunggelenkendoprothese bleibt trotz insgesamt sinkender Fallzahlen in Deutschland aktuell, zumal in den letzten Jahren Neuentwicklungen von Prothesen auf den Markt gekommen sind. Neuere Daten aus den verschiedenen Prothesenregistern zeigen signifikant bessere Ergebnisse in der Standzeit der Prothesen, die als „Ersatz“ des für die Fußfunktion essenziellen Gelenkes unbestritten auch Vorteile für die Gelenkbeweglichkeit, das Abrollverhalten und den Gangzyklus im Vergleich zur Arthrodese des oberen Sprunggelenkes bieten. Auch gibt es Hinweise, dass das Risiko von Anschlussarthrosen von Gelenken des Fußes geringer ist. Unverändert ist die Datenlage der wissenschaftlichen Literatur für die Entscheidung Prothese vs. Arthrodese bei posttraumatischer oberer Sprunggelenkarthrose nicht schlüssig und klar entschieden. Der folgende Beitrag soll einen Überblick über das Thema geben und eine Hilfe bei der Indikationsstellung Arthrodese vs. Prothese sein."
journal_title,Trauma und Berufskrankheit
article_title,Versorgung und Outcome von Patienten mit Schädel-Hirn-TraumaTreatment and outcome of patients with traumatic brain injury
keyword,"['Magnetresonanztomographie\xa0', 'Neuropsychologie\xa0', 'Epidemiologie\xa0', 'Akutbehandlung\xa0', 'Rehabilitation\xa0', 'Magnetic resonance imaging\xa0', 'Neuropsychology\xa0', 'Epidemiology\xa0', 'Acute treatment\xa0', 'Rehabilitation\xa0']"
history,"['2018-03', '2017-07-10']"
abstract,"ZusammenfassungHintergrundDer Beitrag beschreibt Zielsetzung und Methodik einer von der AG Neurotrauma der berufsgenossenschaftlichen (BG-)Kliniken initiierten und von der Deutschen Gesetzlichen Unfallversicherung (DGUV) unterstützen Studie („Prospektive Untersuchung zu Versorgung und Outcome von Patienten mit Schädel-Hirn-Traumen in berufsgenossenschaftlichen Kliniken [ProSHT]“, Reg.-Nr. DRKS00010525).FragestellungIm Rahmen eines epidemiologischen Basisprojektes („SHT-Register“) sollen die Versorgung von Patienten mit Schädel-Hirn-Traumen (SHT) unterschiedlichen Schweregrades, die in BG-Kliniken erstbehandelt werden, dokumentiert und beschrieben sowie das Outcome erfasst werden. In einem eingebetteten Teilprojekt „Leichtes SHT“ sollen darüber hinaus durch zusätzliche Untersuchungen bei Patienten mit leichtem SHT Risikofaktoren für anhaltende Beschwerden nach einem solchen leichten SHT erfasst werden.Material und MethodeIm Basisprojekt erfolgte eine standardisierte Dokumentation von Initialversorgung, stationärer Akutbehandlung und Rehabilitation. Darüber hinaus wurden telefonische Nachbefragungen nach 3 und 12 Monaten durchgeführt. Im Teilprojekt wurden die eingeschlossenen Patienten mit leichtem SHT zusätzlich innerhalb von 4 Wochen und dann noch einmal 3 und 12 Monate nach dem Trauma neurologisch, neuropsychologisch und magnetresonanztomographisch untersucht.ErgebnisseDie Studie ist derzeit noch nicht abgeschlossen, sodass noch keine endgültigen Ergebnisse berichtet werden können.SchlussfolgerungenEs wird erwartet, dass die Ergebnisse der Studie einen wichtigen Beitrag zur Optimierung der Versorgung von Patienten mit SHT liefern können."
journal_title,Trauma und Berufskrankheit
article_title,Szintigraphie/PositronenemissionstomographieScintigraphy/positron emission tomography
keyword,"['Sarkome\xa0', 'Therapieplanung\xa0', 'Rezidiv\xa0', 'PET/Computertomographie\xa0', 'PET/Magnetresonanztomographie\xa0', 'Sarcomas\xa0', 'Treatment planning\xa0', 'Recurrence\xa0', 'PET/Computed tomography\xa0', 'PET/Magnetic resonance imaging\xa0']"
history,"['2018-03', '2017-09-20']"
abstract,"ZusammenfassungSkelettszintigraphie und FDG-PET (Fluorodeoxyglucose-Positronenemissionstomographie)/CT (Computertomographie) sind etablierte nuklearmedizinische Untersuchungsverfahren bei der Diagnostik von Weichteiltumoren. Die Skelettszintigraphie dient dem Nachweis einer ossären Mitbeteiligung des Primärtumors, der Planung der MRT (Magnetresonanztomographie)-Bildgebung und der Suche ossärer Metastasen. Das größte Potenzial der PET/CT liegt in der Abschätzung des Malignitätsgrades, im genauen N‑ und M‑Staging, der Biopsieplanung und der Therapiekontrolle. Rezidive können mit hoher Sicherheit erkannt werden, insbesondere bei Vorhandensein metallischer Implantate, die die radiologische Diagnostik erschweren. Leitliniengerecht besteht bei Vorliegen eines potenziell malignen Weichteiltumors auch im Kindes- und Jugendalter in vielen Fällen die Indikation zur PET/CT bzw. PET/MRT."
journal_title,Trauma und Berufskrankheit
article_title,Sepsis nach PolytraumaSepsis following multiple trauma
keyword,"['Schrankenstörung\xa0', 'Organfunktionsstörung\xa0', 'Multiorganversagen\xa0', 'Komplementsystem\xa0', 'Chirurgisches Management \xa0', 'Barrier dysfunction\xa0', 'Organ functional disorder\xa0', 'Multiple organ failure\xa0', 'Complement system\xa0', 'Surgical management\xa0']"
history,"['2018-03', '2017-09-07']"
abstract,"ZusammenfassungHintergrundTrotz intensiver Forschung und Fortschritte in der Medizin stellt die Versorgung von polytraumatisierten Patienten mit nachfolgender Sepsis eine besondere Herausforderung im medizinischen Alltag dar. Daten aus dem DGU (Deutsche Gesellschaft für Unfallchirurgie)-Polytraumaregister weisen darauf hin, dass posttraumatisch mehr als 6 % der Patienten zusätzlich eine Sepsis entwickeln, die wiederum in 20 % der Fälle zu einem Multiorganversagen führt.FragestellungVorgestellt werden pathophysiologische Auswirkungen der posttraumatischen Sepsisentwicklung sowie aktuelle und zukünftige Forschungsansätze und Therapiemöglichkeiten.Material und MethodenEs erfolgen die Auswertung und Diskussion von fremden und eigenen Grundlagenarbeiten sowie aktuellen Expertenempfehlungen.ErgebnisseAktuell ist Sepsis als lebensbedrohliche Organfunktionsstörung definiert, und somit rückt der SOFA-Score bei der Diagnose in den Mittelpunkt. Des Weiteren belegen Daten, dass ein hämorrhagischer Schock mit verantwortlich für die Entwicklung und Progression der Organdysfunktion ist. Eine entscheidende Rolle in Bezug auf Sepsisentwicklung kommt auch auf die Aktivierung der Gerinnungs- und Komplementkaskade zu. Unter anderem konnte experimentell bereits gezeigt werden, dass ein erhöhter C3a/C3-Quotient auf eine Sepsisentwicklung hinweist und die Hemmung von C5/C5a in verschiedenen Sepsismodellen zu einer deutlich verbesserten Zell‑, Immun- und Organfunktion führte.DiskussionDie aktuellen Therapiemöglichkeiten für Patienten mit posttraumatischer Sepsis stellen noch immer ein ungelöstes Problem dar. Neben dem chirurgischen Management nach dem DCO („damage control orthopedic surgery“)-Stufenkonzept sollte eine Immunkontrolle für den klinischen Einsatz weiter in seinen pathophysiologischen Dimensionen erforscht werden."
journal_title,Trauma und Berufskrankheit
article_title,Behandlung der kindlichen UnterarmschaftfrakturTreatment of pediatric forearm shaft fractures
keyword,"['Kinder\xa0', 'Operation\xa0', 'Osteosynthese\xa0', 'Narkose\xa0', 'Minimalinvasive Technik\xa0', 'Children\xa0', 'Operation\xa0', 'Osteosynthesis\xa0', 'Anesthesia\xa0', 'Minimally invasive technique\xa0']"
history,"['2018-03', '2017-12-13']"
abstract,ZusammenfassungAlle nicht und gering dislozierten Unterarmschaftfrakturen sollten weiterhin mittels Oberarmgipsretention versorgt werden. Für die dislozierte diaphysäre Unterarmschaftfraktur jedoch ist die elastisch stabile intramedulläre Nagelung (ESIN) eine ideale kindgerechte Osteosyntheseform mit sehr guten funktionellen Ergebnissen. Dies rechtfertigt auch eine primäre ESIN bei repositionspflichtigen Grünholzfrakturen im Sinne einer Narkoseindikation.
journal_title,Trauma und Berufskrankheit
article_title,Tumornachsorge bei WeichteilsarkomenFollow-up of soft tissue sarcomas
keyword,"['Tumorgrading\xa0', 'Nachsorge\xa0', 'Pflegeteam\xa0', 'Rezidiv\xa0', 'Spezialisiertes onkologisches Zentrum\xa0', 'Tumor grading\xa0', 'Aftercare\xa0', 'Patient care team\xa0', 'Neoplasm recurrence, local\xa0', 'Special cancer center\xa0']"
history,"['2018-03', '2017-10-20']"
abstract,"ZusammenfassungHintergrundMaligne Weichgewebstumoren der Extremitäten bei Erwachsenen stellen mit 2–3 Neuerkrankungen pro 100.000 Einwohner/Jahr einen sehr geringen Anteil der malignen Neuerkrankungen dar. Nach Abschluss der multimodalen Therapie besteht aufgrund der hohen Rezidivrate die Indikation zu einer strukturierten Tumornachsorge. Rezidive treten häufig innerhalb der ersten 2 Jahre nach der initialen Therapie auf, werden aber auch noch nach Abschluss des 5. Jahres beschrieben.GrundsätzeDie Planung der Nachsorge sollte bereits im Rahmen des stationären Aufenthalts beginnen. Die Kernpunkte der strukturierten Tumornachsorge sind die Einleitung rehabilitativer und psychosozialer Maßnahmen, die Behandlung von Therapienebenwirkungen nach (neo)adjuvanter Therapie, die Erkennung von Sekundärtumoren, die palliative Behandlung sowie die statistische Erfassung der Therapieverläufe. Die Nachsorge sollte an einem spezialisierten Zentrum für muskuloskeletale Tumoren erfolgen. Die Nachsorgesequenz richtet sich hierbei nach der Entität sowie dem Tumorgrading und wird in zunächst engmaschigen und im Verlauf in längerfristigen Kontrollen über mindestens 10 Jahren empfohlen.SchlussfolgerungDie tumorchirurgisch tätige Klinik sollte eng in die strukturierte Tumornachsorge eingebunden sein. Wir empfehlen eine 3‑monatige Kontrolle für die ersten 3 Jahre, eine 6‑monatige Kontrolle im 4. bis 5. Jahr und eine jährliche Kontrolle bis zum Abschluss des 10. Jahres bei hochmalignen Weichgewebstumoren der Extremitäten. Bei Low-grade-Weichteilsarkomen sehen wir die Indikation zur halbjährlichen Kontrolle innerhalb der ersten 5 Jahre und hiernach ein jährliches Nachsorgeintervall bis zur Vollendung des 10. Jahres nach initialem Therapieabschluss."
journal_title,Trauma und Berufskrankheit
article_title,Umsetzung der aktuellen EAP-AnforderungenImplementation of current EAP requirements
keyword,"['Erweiterte ambulante Physiotherapie\xa0', 'Rehabilitation\xa0', 'Teilhabe\xa0', 'Biopsychosoziale Ausrichtung\xa0', 'Outcome\xa0', 'Advanced outpatient physiotherapy (EAP)\xa0', 'Rehabilitation\xa0', 'Participation\xa0', 'Biopsychosocial orientation\xa0', 'Outcome\xa0']"
history,"['2018-03', '2017-12-14']"
abstract,"ZusammenfassungDie erweiterte ambulante Physiotherapie (EAP) ist seit vielen Jahren als essenzielles Element der medizinischen Rehabilitation der gesetzlichen Unfallversicherung fest etabliert. Originär biomedizinisch ausgerichtet, verfolgt die EAP seit 2014 einen ganzheitlich ausgerichteten Ansatz und wurde zur Erreichung der beruflichen und sozialen Teilhabe um weitere Behandlungselemente, wie z. B. die Ergotherapie, die psychologische Betreuung oder die Patientenschulung, ergänzt. Die praktische Umsetzung der resultierenden erhöhten Anforderungen der EAP wird dargestellt mittels bewährter Handlungsempfehlungen wie Berücksichtigung des beruflichen Tätigkeitsprofils, Einsatz von Assessments und Vereinbarung von Reha-Zielen und anhand zweier Fallbeispiele erläutert. Nach Statistiken der BG Ambulanz Bremen gelten durchschnittlich mehr als 90 % der Patienten bei Beendigung der EAP wieder als arbeitsfähig. Die zeitgemäße biopsychosoziale Ausrichtung der EAP ist als positiv zu bewerten, jedoch auch verbunden mit einem deutlichen fachlichen und organisatorischen Mehraufwand."
journal_title,Trauma und Berufskrankheit
article_title,Systemtherapie fortgeschrittener WeichteilsarkomeSystemic treatment of advanced soft tissue sarcoma
keyword,"['Chemotherapie\xa0', 'Monoklonale Antikörper\xa0', 'Metastasenchirurgie\xa0', 'Anthrazyklin\xa0', 'Radiatio\xa0', 'Chemotherapy\xa0', 'Monoclonal antibodies\xa0', 'Metastasectomy\xa0', 'Anthracycline\xa0', 'Irradiation\xa0']"
history,"['2018-03', '2017-10-06']"
abstract,"ZusammenfassungHintergrundWeichteilsarkome sind seltene Erkrankungen. Die Systemtherapie wurde in fortgeschrittenen Stadien bisher vorzugsweise mit Anthrazyklin oder anderen vergleichsweise toxischen klassischen Zytostatika durchgeführt. Ansprechraten sowie ein therapiebedingter Überlebensvorteil sind gering.FragestellungSind Fortschritte hinsichtlich gezielter und immuntherapeutischer Verfahren auf die Therapie von Weichteilsarkomen übertragbar?Material und MethodenEs erfolgen Zusammenfassung, Auswertung und Bewertung der derzeitigen Empfehlungen sowie aktueller Daten zur Systemtherapie im adjuvanten Setting sowie bei fortgeschrittenen oder metastasierten Weichteilsarkomen.ErgebnisseFür Patienten mit bestimmten Risikokonstellationen ist der Stellenwert einer adjuvanten Chemotherapie
						mittlerweile belegt. Im metastasierten Stadium bleibt eine auf Anthrazykline basierte Therapie Standard in der
						Erstlinientherapie für fast alle Subentitäten, die  Kombination mit Ifosfamid oder Dacarbazin (DTIC) erhöht die
						Ansprechrate, ein Überlebensvorteil zeigt sich jedoch nicht. Olaratumab ist der erste für metastasierte
						Weichteilsarkome zugelassene monoklonale Anti-PDGFRα-Antikörper, der ohne wesentliche Erhöhung von Toxizität und
						Ansprechraten in Phase-II-Studien einen Überlebensvorteil in Kombination mit Anthracyclinen zeigen konnte.SchlussfolgerungenDie Prognose von Patienten mit fortgeschrittenen Weichteilsarkomen ist weiterhin vergleichsweise schlecht. Vor dem Einsatz einer Chemotherapie sollte die Möglichkeit einer Metastasenchirurgie, gerade bei niedriggradigen Sarkomen geprüft werden, ebenso eine lokale Radiatio. Anthrazykline sind weiterhin Therapiestandard in der Erstlinientherapie. Daten zu gezielten und immuntherapeutischen Verfahren werden erst in den kommenden Jahren erwartet."
journal_title,Trauma und Berufskrankheit
article_title,Weichteilsarkome der ExtremitätenSoft tissue sarcomas of the extremities
keyword,"['Extremitätenerhalt\xa0', 'Tumorendoprothesen\xa0', 'Modularität\xa0', 'Komplikationen\xa0', 'Amputation\xa0', 'Limb salvage\xa0', 'Tumor prostheses\xa0', 'Modularity\xa0', 'Complications\xa0', 'Amputation\xa0']"
history,"['2018-03', '2017-10-24']"
abstract,"ZusammenfassungWährend vor etwa 3 Dekaden die Amputation als kurative Therapiestrategie regelhaft durchgeführt wurde, steht heute der Extremitätenerhalt im Fokus und führt in Kombination mit der adjuvanten Radiatio zu keiner höheren Rezidivrate.Ein Extremitätenerhalt wird nur dann empfohlen, wenn tumorfreie Ränder zu erreichen sind und der Extremitätenerhalt zu einer besseren Funktion führt als eine Amputation. Die Modularität ist das besondere Merkmal von Tumorendoprothesen und bildet die Basis für die weitgehende Flexibilität des Operateurs sowie die umfassenden Gelenk- und Knochenrekonstruktionsmöglichkeiten. Die Erfolge der Entwicklung von modularen Tumorprothesen müssen vor dem Hintergrund der Komplikationen und Revisionsraten diskutiert werden.In Studien zu Megaprothesen der unteren Extremität wurde über eine 10-jährige Standzeit von 77–100 % und über eine 10-Jahres-Fehlerrate von 22 % berichtet. Aufgrund der geringeren mechanischen Belastung sind die Ergebnisse an der oberen Extremität besser. Die Infektionsraten beim proximalen Humerusersatz sind gering. Demgegenüber stehen Infektionsraten von etwa 20–25 % beim proximalen oder distalen Femurersatz bzw. proximalen Tibiaersatz. Funktionelle Einschränkungen sind insbesondere an der unteren Extremität und dort speziell beim proximalen Tibiaersatz zu erwarten, während die Ergebnisse nach proximalem Femurersatz und an der oberen Extremität gut sind.Studien zur Lebensqualität nach Extremitätenerhalt durch Tumorprothesen sollten auch die Problematik der Komplikations- und Revisionsrate sowie funktionelle Aspekte berücksichtigen, um belastbarere Aussagen für die Entscheidung Amputation vs. Extremitätenerhalt im Einzelfall treffen zu können."
journal_title,Trauma und Berufskrankheit
article_title,„Neue“ Heilverfahren im fünften Jahr„New“ treatment procedures after 5 years
keyword,"['Arbeitsunfall\xa0', 'Gesetzliche Unfallversicherung\xa0', 'Neuordnung stationäre Heilverfahren\xa0', 'Verletzungsartenverfahren\xa0', 'Schwerstverletzungsartenverfahren\xa0', 'Occupational accident\xa0', 'Social accident insurance\xa0', 'Inpatient treatment procedures, restructuring\xa0', 'Injuries type procedure\xa0', 'Severest injuries type procedure\xa0']"
history,"['2018-03', '2017-09-05']"
abstract,"ZusammenfassungDie zum 01.01.2013 verabschiedete Neuordnung der stationären Heilverfahren in der gesetzlichen Unfallversicherung in Form eines neuen stationären Durchgangsarztverfahrens (DAV), eines modifizierten Verletzungsartenverfahrens (VAV) und eines ebenfalls neuen Schwerstverletzungsartenverfahrens (SAV) befindet sich kurz vor Ablauf der 5‑jährigen Übergangsfrist. Zwischenzeitlich sind in Bayern und Sachsen über zwei Drittel der an der Versorgung von Verletzten nach Arbeitsunfällen teilnehmenden Kliniken auf Basis der neuen Anforderungen geprüft. Dabei hat sich in 3 von 4 Fällen die bisherige Einstufung der Kliniken bestätigt. Der Blick auf die Landkarte zeigt eine weitgehend homogene Verteilung der stationären Einrichtungen in den Verfahrensarten. Auch im Schwerstverletzungsartenverfahren steht mit aktuell 23 teilnehmenden Kliniken ein weitgehend flächendeckendes Netz zur Verfügung."
journal_title,Trauma und Berufskrankheit
article_title,Biopsie von Weichteiltumoren des muskuloskeletalen SystemsBiopsy of soft tissue tumors of the musculoskeletal system
keyword,"['Weichteilsarkom\xa0', 'Raumforderung\xa0', 'Neoplasie\xa0', 'Inzisionsbiopsie\xa0', 'Exzisionsbiopsie\xa0', 'Soft tissue sarcoma\xa0', 'Malignant mass\xa0', 'Neoplasia\xa0', 'Incisional biopsy\xa0', 'Excisional biopsy\xa0']"
history,"['2018-03', '2017-09-20']"
abstract,"ZusammenfassungHintergrundTumoren des muskuloskeletalen Systems sind selten, die Symptome eher allgemein und unspezifisch. Sie stellen deshalb, insbesondere im jüngeren Alter, eine große Herausforderung an Diagnostik und Therapie dar. Neben der allgemeinen Anamnese, klinischen Untersuchung und Basisdiagnostik (Labordiagnostik, Röntgen, ggf. Sonographie) stellt die spezielle Tumordiagnostik mit Computertomographie, Magnetresonanztomographie und Szintigraphie (bei Knochentumoren) einen wichtigen Baustein dar. Zur Erstellung einer definitiven Diagnose und des daraus resultierenden interdisziplinären Therapieplans ist eine Biopsie der unklaren Raumforderung oft unerlässlich. Obgleich Leitlinien für Probeentnahmen vorliegen, ist bei dieser operativen Maßnahme die Fehlermöglichkeit hoch.MethodenEs handelt sich um eine Übersichtsarbeit auf Basis eine Literaturrecherche.ErgebnisseBiopsien werden in Inzision- und Exzisionsbiopsien unterteilt. Es existieren Leitlinien der operativen Gesellschaften, die das Vorgehen festlegen. Zu berücksichtigen ist, dass das Biopsieareal durch Tumorzellen kontaminiert wird und bei einer definitiven Resektion mit entfernt werden sollte. Primäre Exzisionsbiopsien sollten nur bei abgrenzbaren, eher subkutan liegenden Raumforderungen unter 5 cm erwogen werden.DiskussionDa die Fehlerquote und Komplikationsrate bei Biopsien hoch sind und erheblichen Einfluss auf die Diagnostik und Therapie der Erkrankung haben, sollte die Biopsie nur in Zentren mit umfangreicher Erfahrung durchgeführt werden, die auch in der Lage sind, die nachfolgenden Operationen vorzunehmen."
journal_title,Trauma und Berufskrankheit
article_title,Die neuen Heilverfahren im 5. JahrThe new healthcare process after 5 years
keyword,"['Verletzungsartenverfahren\xa0', 'Schwerstverletzungsartenverfahren\xa0', 'Kindliche Verletzungen\xa0', 'Hüftgelenknahe Oberschenkelbrüche\xa0', 'Kindesalter\xa0', 'Injury type procedure\xa0', 'Severe injury type procedure\xa0', 'Pediatric injuries\xa0', 'Proximal femoral fractures\xa0', 'Childhood\xa0']"
history,"['2018-03', '2018-01-09']"
abstract,"ZusammenfassungDie Überarbeitung des Verletzungsartenverzeichnisses in der Fassung aus 2013 ging über die ursprünglich vorgesehene redaktionelle Überarbeitung hinaus und kann nunmehr als Fassung 2.0 bezeichnet werden. Als 11. Punkt wurden die Komplikationen, wie sie typisch nach Monaten oder Jahren auftreten, wieder in das Verzeichnis übernommen. Systematisch überarbeitet wurden Aufzählungen, die nunmehr mittels Spiegelstrichen klar dargestellt werden. Neu aufgenommen als Punkt 6.5 wurden die hüftgelenknahen Brüche des Oberschenkels. Das Kindesalter ist für das Verletzungsartenverzeichnis mit der Vollendung des 15. Lebensjahres nach oben definiert. Es ist geplant, die Neufassung im Laufe des Jahres 2018 in Kraft zu setzen."
journal_title,Trauma und Berufskrankheit
article_title,Alternative Operationstechniken zur Behandlung von Femurschaftfrakturen bei Kindern und JugendlichenAlternative surgical techniques for the treatment of femoral shaft fractures in children and adolescents
keyword,"['Adipositas\xa0', 'Platte\xa0', 'Nagel\xa0', 'Osteosynthese\xa0', 'Mobilität\xa0', 'Obesity\xa0', 'Plate\xa0', 'Nail\xa0', 'Osteosynthesis\xa0', 'Mobility\xa0']"
history,"['2018-03', '2017-06-20']"
abstract,"ZusammenfassungMit zunehmendem Mobilitätsbedürfnis steht die operative Therapie der Femurschaftfraktur bei Kindern und Jugendlichen im Vordergrund. Seit Einführung der elastisch stabilen intramedullären Nagelung (ESIN) in den 1980er-Jahren stellt sie den Goldstandard für die Osteosynthese dieser Frakturen dar. Mit immer größerer Ausweitung der Indikation häufen sich jedoch Berichte über Komplikationen dieser Technik. Neuere Studien legen nahe, dass gerade beim älteren und schwereren Kind die ESIN an ihre biomechanischen Grenzen gelangt. Insbesondere in dieser Patientengruppe, aber auch bei allen anderen Frakturtypen, bei denen die ESIN keine sichere Stabilisierung gewährleisten kann, werden alternative Techniken empfohlen. Die Indikation des Fixateur externe liegt im Wesentlichen in der zügigen Stabilisierung bei Polytraumatisierung oder Anwendung bei schlechten Weichteilverhältnissen. Die Plattenosteosynthese stellt eine gute Alternative zur internen Fixierung proximaler oder distaler Femurfrakturen dar, kann jedoch auch – meist in der MIPO (minimalinvasive Plattenosteosynthese)-Technik – für längsinstabile Frakturen des Schaftes verwendet werden. Der konventionelle antegrade Marknagel ist zum einen häufig nicht für den schmalen Markraum bei Adoleszenten geeignet, zum anderen birgt er die Gefahr einer Durchblutungsstörung aufgrund des Eintrittspunktes. Der speziell für das Kindesalter entwickelte laterale Adoleszentennagel ist in geringeren Durchmessern erhältlich und hat wegen seines lateralen Eintrittspunktes nicht das Risiko der Durchblutungsstörung. Letztendlich ist die Therapie der Femurschaftfraktur im Wesentlichen abhängig von Alter und Gewicht der Kinder. Um eine adäquate Osteosynthese für alle Frakturtypen, Gewichts- und Altersgruppen zu erzielen, müssen daher sämtliche Alternativen neben der ESIN beherrscht werden."
journal_title,Trauma und Berufskrankheit
article_title,Läsion der distalen BizepssehneLesions of the distal biceps tendon
keyword,"['Ruptur\xa0', 'Therapie\xa0', 'Differenzialdiagnose\xa0', 'Refixierung\xa0', 'Funktionelles Ergebnis\xa0', 'Rupture\xa0', 'Therapy\xa0', 'Differential diagnosis\xa0', 'Refixation\xa0', 'Functional result\xa0']"
history,"['2018-03', '2018-01-30']"
abstract,"ZusammenfassungDer M. biceps brachii hat aufgrund der Beuge- und Supinationsfunktion am Arm funktionell eine große Bedeutung. Die vollständige Ruptur der distalen Bizepssehne wird typischerweise bei funktionsaktiven Männern gesehen. Der Kraftverlust nach konservativer Therapie ist ausgeprägt (30–40 % für die Flexion, >50 % für die Supination). Durch die Refixierung der Sehne an der Tuberositas radii kann ein gutes funktionelles Ergebnis in Aussicht gestellt werden. Chronische Teilläsionen der distalen Bizepssehne sind schmerzhaft und sollten in die Differenzialdiagnose von Ellenbogenschmerzen einbezogen werden"
journal_title,Trauma und Berufskrankheit
article_title,Endoprothetische Versorgung des posttraumatischen KniegelenksTotal knee arthroplasty following trauma of the knee
keyword,"['Arthrose\xa0', 'Kniegelenkendoprothese\xa0', 'Mobilität\xa0', 'Frakturendoprothetik\xa0', 'Modulare Implantatsysteme\xa0', 'Osteoarthritis\xa0', 'Total knee arthroplasty\xa0', 'Mobility\xa0', 'Fracture endoprosthetics\xa0', 'Modular implant systems\xa0']"
history,"['2018-03', '2017-07-28']"
abstract,"ZusammenfassungHintergrundDas Wiedererlangen der Mobilität nach schwerem Kniegelenktrauma ist bei älteren Patienten oft ein großes Problem. Die primäre Frakturendoprothetik des Kniegelenks kann hier in bestimmten Fällen eine sinnvolle Behandlungsoption darstellen.Ziel der Arbeit (Fragestellung)Das Ziel dieser Arbeit besteht in der Erstellung des Indikationsspektrums, Darlegung der Risiken und Chancen der Frakturendoprothetik des Kniegelenks.Material und MethodenEs erfolgte eine selektive Literaturanalyse unter Berücksichtigung von Empfehlungen und eigenen Erfahrungen.ErgebnisseTrotz adäquater initialer osteosynthetischer Versorgung von kniegelenknahen Frakturen sind beim älteren Patienten die Langzeitergebnisse eher schlecht. Aufgrund der oft nicht umsetzbaren Entlastung kommt es insbesondere bei schlechter Knochenqualität häufig zum sekundären Korrekturverlust. Darüber hinaus ist die Rate an posttraumatischer Gonarthrose im Alter deutlich erhöht. Die moderne Knieendoprothetik erlaubt durch modulare Implantatsysteme mit verschiedenen Kopplungsmechanismen, Verankerungs- und Augmentationsmöglichkeiten die Versorgung auch komplexer Verletzungen und erzielt bei frühzeitiger Mobilisierbarkeit zumindest mittelfristig gute bis sehr gute Ergebnisse. Indikationen für die Endoprothetik nach Kniegelenktrauma sind gelenkflächennahe Frakturen, vorbestehende Arthrose, höheres Alter, Osteoporose und die Unfähigkeit zur Entlastung. Dagegen stellen schwere Weichteilschäden, Infekte oder Verletzungen des Streckapparats Kontraindikationen dar.DiskussionDie Frakturendoprothetik des Kniegelenks kann beim geriatrischen Patienten eine sinnvolle Therapieoption darstellen, sofern die Indikationsstellung gewissenhaft erfolgt."
journal_title,Trauma und Berufskrankheit
article_title,Hart getroffenKnocked out
keyword,"['Schädel-Hirn-Trauma\xa0', 'Diagnostik\xa0', 'Behandlungspfade\xa0', 'Breitensport\xa0', 'Spitzensport\xa0', 'Traumatic brain injury\xa0', 'Diagnostics\xa0', 'Treatment pathway\xa0', 'Leisure sports\xa0', 'Competitive sports\xa0']"
history,"['2018-03', '2017-08-31']"
abstract,"ZusammenfassungSchädel-Hirn-Traumen (SHT) im Sport sind häufig und nehmen weiter zu. Sie treten v. a. bei Kontaktsportarten (Eishockey, Fußball, Handball, Basketball, Kampfsport) auf und können erhebliche akute und langfristige Folgen haben. Aufgrund neuer wissenschaftlicher Erkenntnisse hat diese Thematik international viel Beachtung gefunden. Auch in Deutschland existieren mittlerweile sowohl im Breiten- als auch im Spitzensport Handlungsanweisungen im Umgang mit Schädel-Hirn-Traumen. Eine möglichst flächendeckende Schulung und Umsetzung sollten zügig erfolgen, um die Sicherheit der Sportler zu erhöhen und Folgeerscheinungen zu vermeiden."
journal_title,Trauma und Berufskrankheit
article_title,Nekrotisierende WeichteilinfekteNecrotizing soft tissue infections
keyword,"['Infektionserkrankung\xa0', 'nekrotisierende Weichteilinfektionen\xa0', 'Nekrotisierende Fasziitis\xa0', 'Pyoderma\ufeff\xa0', 'Sepsis\xa0', 'Bakterien\xa0', 'Infectious diseases\xa0', 'Necrotizing soft tissue infection\xa0', 'Necrotizing fasciitis\xa0', 'Pyoderma\xa0', 'Sepsis\xa0', 'Bacteria\xa0']"
history,"['2018-03', '2017-09-13']"
abstract,"ZusammenfassungUnter den nekrotisierenden Haut- und Weichteilinfekten („necrotizing skin and soft tissue infections“ [NSSTIs]) wird eine Entität seltener Infektionserkrankungen zusammengefasst, die ein breites Spektrum an klinischen Erscheinungsbildern bieten. Diese reichen von oberflächlichen Hautnekrosen ohne systemische Infektzeichen bis zur klassischen nekrotisierenden Fasziitis mit begleitender fulminanter Sepsis und einer Dynamik, die innerhalb von Stunden zum Tode führen kann. Eine international einheitliche Klassifikation gibt es nicht. Charakteristisch sind die Infektion und das klinische und histologische Bild der Nekrosen der beteiligten Weichteilschichten, ausgelöst durch unterschiedliche Bakterien als mono- oder polymikrobielle Infektion. Das klinische Erscheinungsbild reicht von subakuten bis fulminanten Verläufen. Entscheidend für die Prognose bei den fulminant verlaufenden NSSTIs sind daher die richtige Einschätzung und Diagnosestellung. Diese erfolgt initial ohne Kenntnis des Keimspektrums, ohne genaue Kenntnis der betroffenen Weichteilschichten und ohne histologische Sicherung der Diagnose. Daher kommt der ersten klinischen Diagnosestellung eine wichtige Bedeutung zu, da diese auch für die Therapieentscheidungen Weichen stellt. Im Folgenden sollen die klinische Diagnose, Differenzialdiagnose, Therapieoptionen und Prognosefaktoren der NSSTIs praxisnah dargestellt werden."
journal_title,Trauma und Berufskrankheit
article_title,SarkomresektionResection of sarcomas
keyword,"['Weichteilsarkom\xa0', 'Operation\xa0', 'Resektion\xa0', 'Rekonstruktion\xa0', 'Multimodale Therapie\xa0', 'Soft tissue sarcoma\xa0', 'Operation\xa0', 'Resection\xa0', 'Reconstruction\xa0', 'Multimodal therapy\xa0']"
history,"['2018-03', '2017-10-06']"
abstract,"ZusammenfassungHintergrundWeichteilsarkome sind eine seltene maligne Tumorerkrankung, deren Therapie eine hohe Spezialisierung der beteiligten Kliniken notwendig macht. Aufgrund besserer Überlebensraten und damit höherer Lebenserwartung der Patienten sind die Anforderungen an die chirurgische Therapie nicht nur im Hinblick auf die Sicherheit der Resektion, sondern auch den Erhalt der Funktion gewachsen.GrundsätzeFür die Planung der Tumortherapie müssen eine adäquate Bildgebung sowie histologische Sicherung mittels Biopsie vorliegen. Die Therapie wird interdisziplinär geplant. Man unterscheidet kurative von palliativen Operationsmethoden. Die Tumorresektion erfolgt anhand der präoperativen Planung unter strikter Vermeidung der Kontamination des Situs. Es werden weite Resektionsverfahren angestrebt.Operative und rekonstruktive VerfahrenDie Resektion erfolgt durch direkten längsverlaufenden Zugang zum betroffenen Kompartiment. Der Tumor wird unter Ausnutzung anatomischer Trennschichten bedeckt mit gesundem Gewebe reseziert. Es ist auf eine suffiziente Blutstillung zu achten – zusätzlich kann präoperativ eine Tumorgefäßembolisation erfolgen. Verbliebene Muskelanteile werden zur Rekonstruktion refixiert oder eine Funktionsverbesserung durch Tenodesen erreicht. Aufwändige Weichteil- und Nervenrekonstruktionen sollten zweizeitig erfolgen und müssen adjuvante Behandlungsverfahren mit berücksichtigen. Bei größeren knöchernen Defekten kommen modulare Endoprothesen und im Fall des Verlusts großer Muskelanteile auch Arthrodesen zum Einsatz. Im Fall von Amputationen sollte eine optimale Prothesenversorgung und Nachbehandlung angestrebt werden.Multimodale TherapieNeoadjuvante und adjuvante Therapieverfahren können sowohl engere Resektionsränder ermöglichen als auch die Gesamtprognose verbessern."
journal_title,Trauma und Berufskrankheit
article_title,Strahlentherapie bei Weichteilsarkomen der ExtremitätenRadiotherapy in soft tissue sarcomas of the extremities
keyword,"['Neoadjuvante Strahlentherapie\xa0', 'Postoperative Strahlentherapie\xa0', 'Intraoperative Radiotherapie\xa0', 'Intensitätsmodulierte Strahlentherapie\xa0', 'Brachytherapie\xa0', 'Neoadjuvant radiotherapy\xa0', 'Postoperative radiotherapy\xa0', 'Intraoperative radiotherapy\xa0', 'Intensity modulated radiotherapy\xa0', 'Brachytherapy\xa0']"
history,"['2018-03', '2017-08-31']"
abstract,"ZusammenfassungHintergrundDie funktionserhaltende Behandlung von Patienten mit Weichteilsarkomen (WTS) der Extremitäten ist eine interdisziplinäre Herausforderung.FragestellungEs erfolgte eine Analyse der Evidenzlage zu Stellenwert und Art der radiotherapeutischen Behandlung (RT) innerhalb multimodaler Konzepte.Material und MethodeEs erfolgten die Zusammenstellung aktueller Leitlinien zur multimodalen Behandlung, insbesondere zur Rolle der prä- oder postoperativen RT bei WTS der Extremitäten sowie Darstellung und Erläuterung der Rolle moderner strahlentherapeutischer Spezialtechniken.ErgebnisseSowohl die prä- als auch die postoperative RT sind empfohlene Indikationen bei WTS-Patienten in den Stadien II und III. Eine klare Empfehlung gibt es auch für die postoperative RT bei inkompletter Resektion. Der Einsatz sowohl der prä- als auch der postoperativen RT korreliert mit einer Verbesserung der lokalen Kontrolle, ein positiver Einfluss auf das Überleben bleibt am ehesten auf die Subgruppe mit High-grade-WTS beschränkt. Langfristig zeigt die präoperative RT weniger Spättoxizitäten, führt jedoch akut zu mehr Wundkomplikationen. Moderne Spezialtechniken wie die bildgeführte intensitätsmodulierte Radiotherapie (IG-IMRT), die intraoperative Radiotherapie (IORT) und die Brachytherapie (BT) können die Nebenwirkungen deutlich reduzieren.SchlussfolgerungenModerne strahlentherapeutische Techniken führen zu einer verbesserten lokalen Kontrolle bei Patienten mit WTS in den Stadien II und III"
journal_title,Trauma und Berufskrankheit
article_title,Diametaphysäre UnterschenkelfrakturFractures of the lower leg shaft
keyword,"['Unterschenkelschaftfraktur\xa0', 'Kind\xa0', 'Adoleszenz\xa0', 'Konservative Therapie\xa0', 'Intramedulläre Nagelung\xa0', 'Lower leg shaft fracture\xa0', 'Child\xa0', 'Adolescent\xa0', 'Conservative therapy\xa0', 'Intramedullary nailing\xa0']"
history,"['2018-03', '2017-10-16']"
abstract,"ZusammenfassungBei der Unterschenkelschaftfraktur handelt es sich um die häufigste Schaftfraktur im Kindesalter. Die Inzidenz wird in der Literatur mit 5,8 % angegeben. Unverschobene Tibiaschaftfrakturen können konservativ behandelt werden, instabile vollständige Unterschenkelschaftfrakturen werden häufig operiert. An Verfahren kommen hier die elastisch-stabile intramedulläre Nagelung (ESIN), der Fixateur externe und (eingeschobene) Plattenosteosynthesen zum Einsatz. Als Komplikation muss v. a. an das Kompartmentsyndrom gedacht werden, welches im Kollektiv der operierten Kinder häufiger Auftritt. Außerdem kann es zu Beinlängendifferenzen kommen. Insgesamt ist die Prognose bei richtiger Behandlung sehr gut."
journal_title,Trauma und Berufskrankheit
article_title,Weichteiltumoren des BewegungsapparatesMusculoskeletal soft tissue tumors
keyword,"['Plastische Deckung\xa0', 'Lappenplastik\xa0', 'Prothese\xa0', 'Resektion\xa0', 'Therapieplanung\xa0', 'Plastic surgery\xa0', 'Free flaps\xa0', 'Prosthesis\xa0', 'Resection\xa0', 'Treatment planning\xa0']"
history,"['2018-03', '2018-02-09']"
abstract,"ZusammenfassungHintergrundResektionen von Weichteiltumoren des Bewegungsapparates können große Resektionsdefekte hinterlassen.FragestellungWelche Defekte nach Resektion von Weichteiltumoren des Bewegungsapparates sind deckbar?Material und MethodeEs erfolgte eine Literaturrecherche.ErgebnisseWeichteiltumoren des Bewegungsapparates sind in Deutschland vergleichsweise seltene Tumoren. Für die onkologische Therapie sind Leitlinien hinterlegt. Für die plastische Rekonstruktion von Weichteiltumoren existieren keine Leitlinien, es sind in der Literatur jedoch multiple Konzepte hinterlegt. Unterschieden werden muss in die Defektdeckung und die Wiederherstellung der Funktion. Auch die Hebedefekte müssen bei der Planung der Deckung beachtet werden. Neben Rekonstruktionen mit körpereigenem Gewebe ist auch eine Rekonstruktion mit Prothesen möglich.SchlussfolgerungenEntscheidend für den Therapieerfolg ist das frühzeitige Hinzuziehen des plastisch/rekonstruktiven Chirurgen in die Therapieplanung, um ein für den Pateinten optimales Ergebnis zu erreichen."
journal_title,Trauma und Berufskrankheit
article_title,Begutachtung der PatellarandschädenAssessment of marginal damage of the patella
keyword,"['Patellafraktur\xa0', 'Patella partita\xa0', 'Patellaluxation\xa0', '„Sleeve fracture“\xa0', 'Stressfrakturen\xa0', 'Patella fracture\xa0', 'Bipartite patella\xa0', 'Patella dislocation\xa0', 'Sleeve fracture\xa0', 'Stress fractures\xa0']"
history,"['2018-03', '2017-03-30']"
abstract,"ZusammenfassungNeben den typischen Patellafrakturen im Erwachsenenalter, meist durch Anpralltraumen entstanden, gibt es Patellarandschäden als Folge einer Ossifikationsstörung (Apophysenäquivalent; Patella partita), sog. Stressfrakturen, aber auch die „sleeve fracture“ und Sehnenabrissfrakturen im jugendlichen Alter sowie den medialen Patellarandabriss durch eine Patellaluxation."
journal_title,Trauma und Berufskrankheit
article_title,Entitäten der WeichteilsarkomeSoft tissue sarcoma entities
keyword,"['Weichteiltumoren\xa0', 'Molekulare Pathologie\xa0', 'DNA-Methylierung\xa0', 'Klassifizierung\xa0', 'Molekulare zielgerichtete Therapie\xa0', 'Soft tissue tumors\xa0', 'Molecular pathology\xa0', 'DNA methylation\xa0', 'Classification\xa0', 'Molecular targeted therapy\xa0']"
history,"['2018-03', '2017-12-12']"
abstract,"ZusammenfassungWeichteilsarkome sind mit weniger als 1 % aller Krebserkrankungen selten. In Deutschland wurden in den letzten Jahren zwischen 3500 und 3750 Neuerkrankungen pro Jahr registriert. Es lassen sich grob 2 Gruppen unterteilen: Entitäten mit einzelnen, gut definierten Treibermutationen und Sarkome mit einem komplexen Genotyp. Als Risikofaktoren gelten eine genetische Prädisposition wie die Neurofibromatose, radioaktive Strahlung, infektiöse Agenzien, Umweltgifte und chronische Entzündungen. Daneben können insbesondere fibroblastische Tumoren mit einem Trauma assoziiert sein. Die vorliegende Übersichtsarbeit basiert auf der mehrjährigen Erfahrung des Erstautors als Leiter des Referenzzentrums für Weichteiltumoren am Institut für Pathologie des Universitätsklinikums Jena und präsentiert aktuelle Daten zur Epidemiologie sowie zur pathologischen, genetischen und epigenetischen Klassifikation von Sarkomen. Darüber hinaus werden die technischen Entwicklungen der Sarkomdiagnostik mittels Methylom- und Genkopienzahlanalytik beleuchtet sowie die Möglichkeit illustriert, wie sich Sarkome anhand ihres Methylierungsmusters klassifizieren lassen. Diese Methodik wird voraussichtlich zusammen mit der massiven parallelen DNA-Sequenzierung Einzug in die Sarkomdiagnostik halten. Dem Pathologen wird zukünftig eine wichtige Rolle in der Interpretation dieser Daten im Kontext seiner konventionellen, auf histomorphologischen und immunhistologischen Befunden basierenden Klassifikation zukommen. Neben der Kenntnis der vielen Tumorentitäten bedarf es dabei eines Verständnisses der molekularen und zellulären Mechanismen im Sinne einer Pathway-Pathologie. Es ist zu hoffen, dass sich daraus neue translationale Ansätze bei der Behandlung dieser aktuell nur schwer medikamentös therapierbaren Tumoren ergeben werden."
journal_title,Trauma und Berufskrankheit
article_title,Weichteilrekonstruktionen an Hand und Fuß im KindesalterSoft tissue reconstruction of hands and feet in childhood
keyword,"['Handverletzungen\xa0', 'Fußverletzungen\xa0', 'Weichteilverletzungen\xa0', 'Kinder\xa0', 'Verletzungsmuster\xa0', 'Hand injuries\xa0', 'Foot injuries\xa0', 'Soft tissue injuries\xa0', 'Children\xa0', 'Injury pattern\xa0']"
history,['2018-02-27']
abstract,"ZusammenfassungIn der Notaufnahme ist, abgesehen von Prellungen und Platzwunden im Bereich des Kopfes, die Hand mit 20–25 % einer der am häufigsten verletzten Körperabschnitte beim Kind. Es finden sich unterschiedliche Verletzungsmuster von banalen bis operationsbedürftigen komplexen Verletzungen. Dabei zeigen sich deutliche Unterschiede bei den Verletzungen zwischen Kleinkindern und älteren Kindern. Der Fuß ist von Verletzungen deutlich seltener betroffen (5–10 %). Hier herrschen banale Weichteilverletzungen wie Prellungen vor. Aufwendige Weichteilrekonstruktionen sind daher mehr im Bereich der Hand notwendig. Hier kommt es in knapp 10 % zu Amputationsverletzungen bzw. Sehnen- und Nervenverletzungen."
journal_title,Trauma und Berufskrankheit
article_title,Spezielle Verletzungen der Strecksehnen an der HandSpecial injuries of the extensor tendons on the hand
keyword,"['Fingergelenk\xa0', 'Fingerverletzungen\xa0', 'Gelenkluxation\xa0', 'Ruptur\xa0', 'Sehnenverletzungen\xa0', 'Finger joint\xa0', 'Finger injuries\xa0', 'Joint dislocation\xa0', 'Rupture\xa0', 'Tendon injuries\xa0']"
history,['2018-02-02']
abstract,"ZusammenfassungDiese Strecksehnenläsionen an Endgelenk, Mittelgelenk sowie langer Daumenstrecksehne sind überwiegend geschlossene Verletzungen. Am Endgelenk handelt sich um rein sehnige oder knöcherne Abrisse des Sehnenansatzes. Die Therapie ist überwiegend konservativ. Am Mittelgelenk kann die Schädigung den Tractus intermedius oder zusätzlich die Seitenzügel betreffen und bestimmt dann das therapeutische Vorgehen. Die Ruptur der langen Daumenstrecksehne entsteht durch lokale Kompromittierung in ihrem osteofibrösen Kanal am Tuberculum listeri. Die Therapie der Wahl ist die Transposition der Extensor-indicis-Sehne."
journal_title,Trauma und Berufskrankheit
article_title,Distorsion des oberen SprunggelenkesAnkle sprain
keyword,"['Fibulotalare Bandruptur\xa0', 'Peronealsehnen\xa0', 'Processus lateralis tali\xa0', 'Syndesmosenruptur\xa0', 'Therapie\xa0', 'Fibulotalar ligament rupture\xa0', 'Peroneal tendon\xa0', 'Lateral tubercle of the talus\xa0', 'Syndesmosis rupture\xa0', 'Treatment\xa0']"
history,['2018-01-09']
abstract,"ZusammenfassungDie Distorsion (Verdrehung) des Sprunggelenks zählt zu den in der Praxis am häufigsten behandelten Verletzungen des oberen Sprunggelenks. Betroffen sind in erster Linie laterale Strukturen des Sprunggelenks und des Fußes, wobei hier die Verletzung des fibulotalaren Bandapparates am häufigsten behandelt werden muss. Neben dem lateralen Bandapparat können sowohl die Peronealsehnen und die Syndesmose als auch knöcherne Strukturen wie der Proc. lateralis tali („snowboarder’s ankle“) verletzt sein. Da aufgrund der räumlichen Nähe der Strukturen das klinische Erscheinungsbild sehr ähnlich sein kann, ist eine genaue klinische Untersuchung essenziell, um höhergradige Verletzungen, die mit einer schlechten Prognose verbunden sind, nicht zu übersehen. Der Beitrag gibt anhand der aktuellen Literatur eine Behandlungsempfehlung für die Therapie der oben genannten Verletzungen."
journal_title,Trauma und Berufskrankheit
article_title,Persönliche Leistungserbringung durch den D‑ArztPersonal service provision by the D‑Arzt
keyword,"['Durchgangsarztverfahren\xa0', 'Unfallärztliche Bereitschaft\xa0', 'Amtshaftung\xa0', 'Auslegungshinweise\xa0', 'Qualifikation\xa0', 'Accident insurance consultant procedure\xa0', 'On call accident medical services\xa0', 'Public liability\xa0', 'Instructions for interpretation\xa0', 'Qualification\xa0']"
history,['2018-01-08']
abstract,"ZusammenfassungDas Durchgangsarztverfahren der Deutschen Gesetzlichen Unfallversicherung e. V. (DGUV) weist im Vergleich zur kassenärztlichen Versorgung einige Besonderheiten auf. Hierzu zählen beispielweise die Vorstellungspflichten beim Durchgangsarzt, die von Ärzten und Unternehmern zu beachten sind. Weiterhin muss eine D‑Arzt-Praxis eine unfallärztliche Bereitschaft von Montag bis Freitag von 08:00 Uhr bis 18:00 Uhr durch den D‑Arzt gewährleisten. Bestimmte ärztliche Leistungen im Durchgangsarztverfahren dürfen nur vom D‑Arzt selbst oder dessen anerkanntem ständigem Vertreter „höchstpersönlich“ erbracht werden. Weitere Informationen zu dieser gesamten Thematik enthalten die „Auslegungshinweise“ der DGUV, die von allen D‑Ärzten zu beachten sind."
journal_title,Trauma und Berufskrankheit
article_title,Exo-ProthesenregisterAmputation register
keyword,"['Prothese\xa0', 'Stumpfprobleme\xa0', 'Behandlungsablauf\xa0', 'Standards\xa0', 'Qualitätsmerkmale\xa0', 'Prosthesis\xa0', 'Stump problems\xa0', 'Treatment course\xa0', 'Standards\xa0', 'Quality features\xa0']"
history,['2017-12-18']
abstract,"ZusammenfassungHintergrundDie medizinische Notwendigkeit eines Exo-Prothesenregisters für Patienten nach Beinamputation sowie deren Versorgung begründet sich darauf, dass zwar verschiedene Fachrichtungen Amputationen durchführen, aber eine Standardisierung der Behandlungsabläufe von der Amputation bis zur prothetischen Versorgung noch unzureichend definiert ist.Material und MethodenWährend des Erfassungszeitraumes 08/2013 bis 08/2017 wurden klinische Daten von Patienten nach Beinamputation prospektiv in unserem Exo-Prothesenregister erfasst. Mittels Expertenbogen und Patientenbogen werden Angaben zur Art der Amputation, zu Stumpfverhältnissen, zur Beweglichkeit und Kraft, zur Mobilität sowie zum Status der prothetischen Versorgung erfasst.ErgebnisseBei 257 beinamputierten Patienten bestand in 232 Fällen (90 %) eine Major- und in 25 Fällen (10 %) eine Minoramputation, die meist Folge eines Unfalls, einer Sepsis/Infektion oder einer Durchblutungsstörung waren. Anteilig 182 Patienten hatten eine Prothese (71 %), 42 Patienten waren nicht prothetisch versorgt (16 %), und bei 33 Patienten (13 %) gab es keine Angabe hierzu. Trotz prothetischer Versorgung kamen 23 % der 182 Patienten aufgrund von Stumpfproblemen oder Passformproblemen nicht mit ihrer Prothese zurecht.DiskussionDie Etablierung eines Exo-Prothesenregisters und die zentrumsinterne Organisation von interdisziplinären Kolloquien sollen dazu beitragen, dass Behandlungsabläufe optimiert werden und Patienten eine zügige Rückkehr nach einer Amputation ins Berufs- und Alltagsleben ermöglicht wird. Eine multizentrische Verbreitung mit interklinischer Vergleichsmöglichkeit kann dazu beitragen, Standards und Qualitätsmerkmale interdisziplinär gemeinsam zu definieren."
journal_title,Trauma und Berufskrankheit
article_title,Ergebnisse der multidirektional-winkelstabilen Versorgung distaler HumerusfrakturenResults of the treatment of distal humeral fractures using multidirectional angular stable implants
keyword,"['Implantat\xa0', 'Outcome\xa0', 'Lebensqualität\xa0', 'Follow-up\xa0', 'Funktionseinschränkung\xa0', 'Komplikationen\xa0', 'Implant\xa0', 'Outcome\xa0', 'Quality of life\xa0', 'Follow-up\xa0', 'Functional impairment\xa0', 'Complications\xa0']"
history,['2017-12-04']
abstract,"ZusammenfassungHintergrundDie Versorgung distaler Humerusfrakturen bei Patienten mit reduzierten Knochenverhältnissen oder komplizierten Frakturmustern gestaltet sich immer noch kompliziert. Die Verwendung winkelstabiler Implantate verspricht hier bessere Ergebnisse.ZielsetzungEs erfolgte die Beurteilung klinischer und funktioneller Ergebnisse sowie der Komplikationen nach der operativen Behandlung distaler Humerusfrakturen mit multidirektional winkelstabilen Implantaten.Material und MethodenIn unserer Klinik behandelten Patienten wurde ein Fragebogen zugeschickt. Zusätzlich wurden diese zu einer Nachuntersuchung eingeladen. Zur Beurteilung der funktionellen Behandlungsergebnisse wurden der Disability of the Arm, Shoulder and Hand Score (DASH-Score), der Mayo Elbow Performance Score (MEPS) und der EQ-5D-3 L erhoben sowie die VAS (visuelle Analogskala) zur Beurteilung der Schmerzen. Röntgenbilder wurden zur Frakturklassifikation nach AO (Arbeitsgemeinschaft für Osteosynthesefragen) und zur Beurteilung etwaiger Komplikationen ausgewertet.ErgebnisseInsgesamt wurden 28 Patienten per Fragebogen nach mindestens 6 Monaten postalisch befragt und 10 davon nachuntersucht. Der DASH-Score betrug 38,40, der MEPS 72,31. Das Ergebnis war bei 15 Patienten gut/exzellent. Der EQ-5D-3 L lag bei 0,790, der VAS bei 2,76. Der DASH-Score korrelierte signifikant mit dem Alter und umgekehrt mit dem EQ-5D-3 L. Die Komplikationsrate betrug 53,6 %. Die 3 größten Komplikationsgruppen waren nervale Komplikationen, Heilungsstörungen und Probleme mit dem Osteosynthesematerial.DiskussionDie Behandlungsergebnisse zeigen, dass auch mit winkelstabilen Implantaten nicht immer gute Behandlungsergebnisse erzielt werden können. Ein schlechtes funktionelles Ergebnis im DASH-Score reduziert die Lebensqualität gemessen am EQ-5D-3 L. Zur Evaluierung des Outcomes nach komplizierten distalen Humerusfrakturen erscheint ein Follow-up-Zeitraum von 6 Monaten ausreichend."
journal_title,Trauma und Berufskrankheit
article_title,LängenkorrekturenLength correction
keyword,[]
history,"['2017-12', '2017-12-11']"
abstract,None
journal_title,Trauma und Berufskrankheit
article_title,Daumenverlängerung mit Distraktionsfixateur nach traumatischer AmputationThumb lengthening using a distraction fixator following traumatic amputation
keyword,"['Rekonstruktion\xa0', 'Kallusdistraktion\xa0', 'Semizirkulärer Fixateur\xa0', 'Sensibilität\xa0', 'Ästhetik\xa0', 'Reconstruction\xa0', 'Callus distraction\xa0', 'Semicircular fixator\xa0', 'Sensitivity\xa0', 'Aesthetics\xa0']"
history,"['2017-12', '2017-11-17']"
abstract,"ZusammenfassungHintergrundDamit der Daumen als wichtigster Teil einer funktionierenden Hand seine Aufgabe übernehmen kann, muss er stabil, genügend lang, sensibel innerviert und beweglich sein.Ziel der ArbeitDargestellt werden Alternativen zur Rekonstruktion eines Daumens, Verfahren der Daumenverlängerung mit semizirkulärem Distraktionsfixateur sowie die Entwicklung von Therapieempfehlungen.Material und MethodeEs erfolgte die Recherche der bestehenden Literatur über die Kallusdistraktion. Der Prototyp eines semizirkulären Distraktionfixateurs wird vorgestellt.ErgebnisseMit der Kallusdistraktion kann durchschnittlich eine Verlängerung von 3 cm erreicht werden. Die Vorteile überwiegen, sodass diese Methode in jeden individuellen Behandlungsplan mit einbezogen werden muss, insbesondere dann, wenn die anderen Möglichkeiten keine Optionen darstellen.SchlussfolgerungenDie Wahl des geeigneten Verfahrens zur Daumenrekonstruktion nach traumatischer Amputation hängt von der Amputationshöhe, dem Alter, dem Beruf und vom funktionellen Anspruch des Patienten ab. Mit der Kallusdistraktion existiert ein technisch einfacheres Verfahren verglichen mit mikrochirurgischen Alternativen zur Rekonstruktion eines amputierten Daumens. Die bedeutendsten Nachteile sind die fehlende Nagelanlage, das fehlende Interphalangealgelenk und die lange Behandlungsdauer. Die 5 notwendigen Ziele einer Daumenrekonstruktion (Länge, Stabilität, Beweglichkeit, schmerzlose Funktion und Sensibilität) können mit diesem Vorgehen alle adressiert werden."
journal_title,Trauma und Berufskrankheit
article_title,Begutachtung des leichten Schädel-Hirn-TraumasAssessment of a mild brain trauma
keyword,"['Verlaufsdokumentation\xa0', 'Bewusstseinsstörung\xa0', 'Dokumentation\xa0', 'Neurologische Untersuchung\xa0', 'Bildgebung\xa0', 'Treatment history\xa0', 'Consciousness disorders\xa0', 'Documentation\xa0', 'Neurologic examination\xa0', 'Imaging\xa0']"
history,"['2017-12', '2017-05-05']"
abstract,"ZusammenfassungDie frühere Annahme, leichte Schädel-Hirn-Traumen (SHT) heilen folgenfrei ab, hat sich als falsch herausgestellt, da sich bei 15–30 % der Betroffenen hirnorganische Folgen mit bleibenden kognitiven und/oder emotionalen Störungen nachweisen lassen. Ursache ist meist eine traumatisch bedingte axonale Läsion. Die einfache Bestimmung des GCS (Glasgow Coma Scale) ist für gutachtliche Fragestellungen völlig unzureichend. Entscheidende Hinweise ergeben sich aus der Verlaufsdokumentation von quantitativen (Benommenheit, Somnolenz, Sopor, Koma) und qualitativen (delirante Syndrome mit Orientierungsstörungen, Verwirrtheit, Halluzinationen, ängstlichen Verkennungen, Unruhe, Agitiertheit, Aggressivität und/oder Störung des Schlaf-Wach-Rhythmus, aber auch auffällige Passivität und emotionale Instabilität) Bewusstseinsstörungen. Die Dokumentation derartiger Störungen und ihrer Dauer gehört zur Sorgfaltspflicht einer unfallchirurgischen Versorgung. Zudem sollte eine neurologische Untersuchung in der Frühphase obligat sein. Bildgebend ist die Magnetresonanztomographie mit T1, T2, Flair und insbesondere diffusionsgewichteter Bildgebung der Computertomographie hoch überlegen. Mikroblutungen als Ausdruck einer axonalen Läsion können über viele Jahre mit T2*- oder Suszeptibilitätssequenzen nachgewiesen werden. Positronenemissionstomographie, Single-Photon-Emissionstomographie, „functional magnetic resonance imaging“, „diffusion tensor imaging“ und Biomarker sind gutachtlich bisher nicht ausreichend validiert. Die Anforderungen an ein neurologisches Gutachten entsprechen denen anderer Fachgebiete, müssen aber neben den allgemeinen Gutachtenregeln zusätzlich psychiatrische und neurokognitive Aspekte berücksichtigen, die hier nur erwähnt werden können. Die Darstellungen werden durch eine illustrative Kasuistik ergänzt."
journal_title,Trauma und Berufskrankheit
article_title,Über kurz oder lang: Stellenwert der einzeitigen Verkürzungs- und VerlängerungsosteotomienAbout short or long: importance of one-stage shortening and lengthening osteotomy
keyword,"['Marknagel\xa0', 'Einzeitige Operation\xa0', 'Kallotasis\xa0', 'Risiken\xa0', 'Nutzen\xa0', 'Intramedullary nail\xa0', 'One-stage operation\xa0', 'Callotasis\xa0', 'Risks\xa0', 'Benefits\xa0']"
history,"['2017-12', '2017-11-20']"
abstract,"ZusammenfassungEinzeitige Verlängerungsosteotomien oder Verkürzungsosteotomien sind seit mehr als 100 Jahren beschrieben und hatten zwischen etwa 1978 und 1998 ihre Hauptanwendung als Alternative der in den ersten Jahren der Anwendung als risikoreich geltenden Methode der Kallotasis nach Ilizarov. Mit besserer Kenntnis der Kallotasis und Entwicklung intramedullärer Verlängerungssysteme hat die Methode an Bedeutung verloren. Einzeitige Knochenverlängerungen und seltener -verkürzungen finden heute am Fuß, am koxalen Femurende und am Unterarm noch Anwendung. Der Beitrag stellt die wesentlichen Aspekte der Anwendung der Methoden vor und diskutiert die Risiken und den Nutzen."
journal_title,Trauma und Berufskrankheit
article_title,Standards: HumerusschaftfrakturStandards: humeral shaft fractures
keyword,"['Nervus-radialis-Parese\xa0', 'Osteosynthese\xa0', 'Marknagelung\xa0', 'Konservative Therapie\xa0', 'Plattenosteosynthese\xa0', 'Radial nerve palsy\xa0', 'Osteosynthesis\xa0', 'Intramedullary nailing\xa0', 'Conservative treatment\xa0', 'Plate osteosynthesis\xa0']"
history,"['2017-12', '2017-11-10']"
abstract,"ZusammenfassungHintergrundEtwa 2–4 % aller Frakturen sind Humerusschaftfrakturen. Bezüglich der Therapie gibt es in der Literatur und in der Praxis keinen Goldstandard. Sowohl die konservative Therapie, die Plattenosteosynthese als auch intramedulläre Osteosyntheseverfahren werden mit großem Erfolg eingesetzt.Ziel der ArbeitZiel des vorliegenden Beitrags ist es, eine Zusammenfassung der vorliegenden Evidenz zu geben und hieran einen klinischen Leitfaden für die Versorgung der Humerusschaftfraktur zu erarbeiten.Material und MethodenEinbezogen wurden die Ergebnisse einer selektiven Literaturrecherche in der Medline-Datenbank und klinische Erfahrung der Autoren.SchlussfolgerungSowohl die bereits lange etablierte Plattenosteosynthese als auch die intramedulläre Marknagelung können mit großem Erfolg zur Behandlung der Humerusschaftfraktur eingesetzt werden. Trotz aller Neuerungen hinsichtlich weniger invasiver Operationstechniken und Implantatentwicklungen bleibt die konservative Therapie eine wichtige Therapieoption bei der Behandlung von Oberarmbrüchen."
journal_title,Trauma und Berufskrankheit
article_title,Längenkorrekturen an der oberen ExtremitätLength equalization of the upper extremities
keyword,"['Kallusdistraktion\xa0', 'Akutkorrektur\xa0', 'Fixateur externe\xa0', 'Osteotomie\xa0', 'Compliance\xa0', 'Distraction osteogenesis\xa0', 'Acute correction\xa0', 'External fixator\xa0', 'Osteotomy\xa0', 'Compliance\xa0']"
history,"['2017-12', '2017-11-09']"
abstract,"ZusammenfassungHintergrundVerkürzte Extremitäten können aufgrund von Funktionseinschränkungen eine Herausforderung bei der Durchführung von Alltagstätigkeiten darstellen. Zusätzlich können Patienten neben der Funktionseinschränkung an Beschwerden als auch an dem kosmetischen Erscheinungsbild der betroffenen Extremität leiden.FragestellungEs erfolgt eine Beschreibung der graduellen und akuten Knochenverlängerung anhand von häufigen Indikationen.Material und MethodePräsentiert werden die aktuelle Literaturlage und eigene klinische Beispiele und Erfahrungen bei der Verwendung der Kallusdistraktion und Akutverlängerung.ErgebnisseObwohl die derzeitige Studienlage keine Erstellung von allgemein gültigen Guidelines erlaubt und jeder Patient individuell betrachtet werden muss, zeigt sich, dass die Kallusdistraktion bei gegebener Patienten-Compliance eine effiziente Methode zur Knochenverlängerung darstellt.SchlussfolgerungenDie Kallusdistraktion sowie die Methode der Akutkorrektur stellen eine gute, wenngleich komplikationsbehaftete Methode zur Knochenverlängerung dar. Die generelle Patientenzufriedenheit ist trotzdem hoch."
journal_title,Trauma und Berufskrankheit
article_title,Ausgleich posttraumatischer Beinlängendifferenzen mit einem VerlängerungsmarknagelCompensation of posttraumatic leg length differences with an intramedullary extension nail
keyword,"['Kallusdistraktion\xa0', 'Implantat\xa0', 'Belastbarkeit\xa0', 'Patientenkomfort\xa0', 'Nachbehandlung\xa0', 'Callus distraction\xa0', 'Implant\xa0', 'Loading capacity\xa0', 'Patient comfort\xa0', 'Follow-up treatment\xa0']"
history,"['2017-12', '2017-11-29']"
abstract,"ZusammenfassungIn den letzten Jahrzehnten wurde im Bereich der Kallusdistraktion die Entwicklung von voll implantierbaren
				 Verlängerungsmarknägeln vorangetrieben. Der von uns verwendete Betzbone® (Medi-Tech GmbH - Betz Institute,
				 Wadern, Deutschland) stellt eine Weiterentwicklung des Albizzia-Nagels® dar und bietet gegenüber anderen erhältlichen Implantaten einige Vorteile. Insbesondere die frühe Belastbarkeit noch während der laufenden Kallusdistraktion führt zu einem erhöhten Patientenkomfort und zu einer deutlichen Reduktion von Folge- und Sozialkosten. Der nachfolgende Beitrag behandelt neben den Grundlagen der Kallusdistraktion auch die notwendigen präoperativen Planungstechniken. Im Weiteren werden die operativen Schritte sowie die spezifische Nachbehandlung zur Beinverlängerung mittels Verlängerungsnagel beschrieben. Einige klinische Beispiele veranschaulichen die mögliche Anwendung."
journal_title,Trauma und Berufskrankheit
article_title,Längenkorrekturen an ExtremitätenknochenLength correction of bones of the extremities
keyword,"['Weichteilschaden\xa0', 'Längenkorrektur\xa0', 'Extremitätenerhalt\xa0', 'Ringfixateur\xa0', 'Septische Chirurgie\xa0', 'Soft tissue damage\xa0', 'Length correction\xa0', 'Extremity preservation\xa0', 'Ring fixator\xa0', 'Septic surgery\xa0']"
history,"['2017-12', '2017-11-24']"
abstract,"ZusammenfassungPrimär traumatisch bedingte Defekte, gleichermaßen jedoch infektionsbedingte Veränderungen der Knochenintegrität machen regelhaft segmentale Resektionen im Tibiaschaftbereich erforderlich. Diese sind am Unterschenkel sehr oft mit einem erheblichen Weichteilschaden vergesellschaftet. Passagere Verkürzungen mit nachfolgender sukzessiver Verlängerung sind eine gängige Möglichkeit des Extremitätenerhaltes und der schrittweisen Wiederherstellung einer Weichteilintegrität und folglich Form und Funktion. Neben monolateralen Fixateursystemen, intramedullären Implantaten und passageren Lösungen mittels Plattenosteosynthesen ist der Ringfixateur, sei es als klassischer Ilizarov-Fixateur oder Hexapodon, das präferierte Verfahren in der septischen Chirurgie."
journal_title,Trauma und Berufskrankheit
article_title,"Längen‑, Achs- und Torsionskorrekturen mit DistraktionsmarknägelnCorrection of length, alignment and torsion with fully implantable lengthening nails"
keyword,"['Beinverlängerung\xa0', 'Kallusdistraktion\xa0', 'Deformitätenkorrektur\xa0', 'Beinachse\xa0', 'Implantate\xa0', 'Limb lengthening\xa0', 'Distraction osteogenesis\xa0', 'Deformity correction\xa0', 'Mechanical axis\xa0', 'Implants\xa0']"
history,"['2017-12', '2017-11-24']"
abstract,"ZusammenfassungHintergrundKallusdistraktion mittels vollimplantierbarer Distraktionsmarknägel ist ein etabliertes Verfahren zur Extremitätenverlängerung. Ein knappes Dutzend verschiedener Systeme ist bekannt. Distraktionsmarknägel unterscheiden sich v. a. im Antriebsmechanismus und in Hub, Dimensionen und Materialien.FragestellungAus einer Analyse von Erfahrungen mit 5 verschiedenen Distraktionsmarknägeln lassen sich Stärken und Schwächen identifizieren und daraus Anforderungen an künftige Implantate ableiten.Material und MethodikNeben der Geschichte der Distraktionsmarknägel werden Grundlagen zu Analyse, Planung und Techniken geschildert. Die ausführlich beschriebenen Systeme sind: Fitbone® (Wittenstein intens, Igersheim, Deutschland) SAA („sliding active actuator“; elektromotorisch, gleitend), Fitbone® TAA („telescope active actuator“; elektromotorisch, teleskopierend), ISKD® (Intramedullary Skeletal Kinetic Distractor, Orthofix, Verona, Italien; Rollratschen, teleskopierend), Phenix® (Phenix® medical, Paris, Frankreich; magnetisch, teleskopierend) und Precice® (NuVasive, San Diego, USA; magnetisch mit Getriebe, teleskopierend).ErgebnisseDie verschiedenen Antriebsmechanismen bedingen die Zuverlässigkeit und auch die Mindestmaße bzw. den Hub der verschiedenen Distraktionsmarknägel. Mit geeigneter Analyse, Planung und technischer Umsetzung sind neben reiner Verlängerung auch Deformitätenkorrekturen möglich. Bei den magnetischen Systemen ist kontrollierter Rücklauf möglich. Lediglich 2 Systeme (ISKD® und Precice®) sind zugelassen und frei erhältlich.SchlussfolgerungenIdeale Distraktionsmarknägel sollten bei ausreichender Distraktionskraft präzise steuerbar sein und kontrollierten Rücklauf ermöglichen. Die Implantate sollten dem Markraum angepasst und auch bei geringen Mindestmaßen stabil sein und den nötigen Hub ermöglichen."
journal_title,Trauma und Berufskrankheit
article_title,PseudarthrosenPseudarthrosis
keyword,"['Fraktur\xa0', 'Intervention\xa0', 'Revision\xa0', 'Infekt\xa0', 'Schmerzen\xa0', 'Fracture\xa0', 'Intervention\xa0', 'Revision surgery\xa0', 'Infection\xa0', 'Pain\xa0']"
history,"['2017-11', '2017-09-20']"
abstract,"ZusammenfassungDie Behandlung von Frakturheilungsstörungen ist aufwendig und geht häufig einher mit langen zeitlichen Verläufen. Ergibt sich aus den klinisch-radiologischen Befunden der Nachweis einer nicht zeitgerechten Frakturheilung, stellt sich die Frage des optimalen Interventionszeitpunktes. Ein Abwarten bis zum 6. Monat ist hier nicht immer sinnvoll. Bereits in der Frühphase der Frakturheilungsstörung kann ein Revisionseingriff notwendig sein, insbesondere im Falle einer biomechanisch insuffizienten Situation (frühzeitige Materialermüdung mit Implantatbruch) oder beim Infektnachweis. Auf diese Weise sind möglicherweise lang andauernde Verläufe mit Schmerzen und großen Einschränkungen für den Patienten sowie hohe sozioökonomische Kosten reduzierbar."
journal_title,Trauma und Berufskrankheit
article_title,Low-Grade-InfektLow-grade infection
keyword,"['Biofilm\xa0', 'Sonikation\xa0', 'Biopsie\xa0', 'Polymerasekettenreaktion\xa0', 'Infektpseudarthrose\xa0', 'Biofilm\xa0', 'Sonication\xa0', 'Biopsy\xa0', 'Polmerase chain reaction\xa0', 'Infected non-union\xa0']"
history,"['2017-11', '2017-08-18']"
abstract,"ZusammenfassungLow-Grade-Infekte bzw. Infektpseudarthrosen sind eine medizinische Herausforderung, da sie schwer zu diagnostizieren und komplex zu therapieren sind. Die tatsächliche Inzidenz ist nicht bekannt. Jedoch finden sich in der aktuellen Literatur zunehmend Hinweise, dass Infektpseudarthrosen wesentlich häufiger sind als bisher angenommen. Voraussetzung für eine erfolgreiche Therapie sind eine korrekte Diagnosestellung sowie die Erregeridentifikation, um eine gezielte antibiotische Therapie zu ermöglichen. Goldstandard in der Diagnostik ist die Biopsie, wobei diese bei fehlenden Infektzeichen und fehlenden Risikofaktoren auch einzeitig erfolgen kann. Eine alleinige Punktion ist nicht ausreichend. Neben den kulturellen Standardverfahren gibt es neuere Diagnostikverfahren wie die Sonikation und die „polymerase chain reaction“ (PCR), denen in aktuellen Studien eine höhere Sensitivität, insbesondere bei Biofilm-bildenden Bakterien oder vorheriger antibiotischer Behandlung, zugesprochen wird. Auch durch die Histologie kann eine Osteomyelitis bewiesen werden, selbst bei fehlendem Keimnachweis. Nachteil ist hier die fehlende Erregeridentifikation. Welche klinische Bedeutung die teilweise sehr hohe Rate positiver Keimnachweise mittels PCR oder auch mittels Sonikation im Einzelfall hat, muss noch abschließend untersucht werden. Zusammenfassend scheinen Low-Grade-Infekte wesentlich häufiger bei Pseudarthrosen vorzuliegen als bisher angenommen. Daher sollte jede Pseudarthrose, die operiert wird, auch biopsiert werden. Insbesondere bei fehlenden Infektzeichen und dem Verdacht auf Low-Grade-Infekt bieten sich neben den kulturellen Standardverfahren zusätzliche Verfahren wie die Sonikation an."
journal_title,Trauma und Berufskrankheit
article_title,Geriatrischer BG-PatientGeriatric occupational insurance association patients
keyword,"['Demografischer Wandel\xa0', 'Patientenalter\xa0', 'Komorbiditäten\xa0', 'Epidemiologie\xa0', 'Geriatrie\xa0', 'Demographic change\xa0', 'Patient age\xa0', 'Comorbidties\xa0', 'Epidemiology\xa0', 'Geriatrics\xa0']"
history,"['2017-11', '2017-07-28']"
abstract,"ZusammenfassungHintergrundIm Zuge des demografischen Wandels der Bevölkerung sowie der Anhebung des Renteneintrittsalters ist von einer Veränderung der Patientenaltersstruktur auch im BG-Wesen auszugehen. Mit höherem Patientenalter steigt vermutlich auch die Prävalenz vieler internistischer Komorbiditäten. Hieraus stellt sich die Frage, ob die BG sich anders aufstellen muss bzw. wie sich das System auf diese Patienten einrichten kann.Ziel der ArbeitZiel des Beitrags ist die Darstellung der Epidemiologie und Komorbidität von BG-Patienten mit speziellem Fokus auf den geriatrischen BG-Patienten an einem Universitätsklinikum der Maximalversorgung.Material und MethodenEs erfolgte eine Auswertung der Altersstruktur und kodierten Komorbiditäten bei BG-Patienten jenseits des 60. Lebensjahrs in den Jahren 2005, 2010 und 2015.SchlussfolgerungBei der Mehrheit der geriatrischen BG-Patienten sind relevante Komorbiditäten vorhanden, die den klinischen Verlauf beeinflussen können und eine interdisziplinäre Zusammenarbeit erfordern werden."
journal_title,Trauma und Berufskrankheit
article_title,Periprothetische GelenksteifePeriprosthetic joint stiffness
keyword,"['Arthrofibrose\xa0', 'Infektion\xa0', 'Malalignment\xa0', 'Instabilität\xa0', 'Diagnostischer Algorithmus\xa0', 'Arthrofibrosis\xa0', 'Infection\xa0', 'Malalignment\xa0', 'Instability\xa0', 'Diagnostic algorithm\xa0']"
history,"['2017-11', '2017-09-14']"
abstract,"ZusammenfassungDie periprothetische Kniegelenksteife ist nach posttraumatischer Arthrose häufiger als nach primärer Arthrose. Es sind zahlreiche mechanische, biologische und sonstige Risikofaktoren bekannt, die eine periprothetische Gelenksteife begünstigen. Ein standardisierter diagnostischer Algorithmus soll potenzielle Ursachen identifizieren. Die Therapie richtet sich nach der wahrscheinlichsten Ursache der Gelenksteife."
journal_title,Trauma und Berufskrankheit
article_title,Operative Optionen bei Plexusverletzungen der oberen ExtremitätSurgical options for brachial plexus injuries
keyword,"['Plexus brachialis\xa0', 'Rekonstruktion\xa0', 'Nervennaht\xa0', 'Nerventransfer\xa0', 'Freie funktionelle Muskeltransplantation\xa0', 'Brachial plexus\xa0', 'Reconstruction\xa0', 'Nerve suture\xa0', 'Nerve transfer\xa0', 'Free functioning muscle transplantation\xa0']"
history,"['2017-11', '2017-10-13']"
abstract,"ZusammenfassungVerletzungen des Plexus brachialis führen zu erheblichen motorischen und sensiblen Ausfällen. Um optimale Ergebnisse zu erzielen, ist ein interdisziplinäres diagnostisches Vorgehen notwendig. Bei offenen, glatten Durchtrennungen des Plexus brachialis ist im Gegensatz zu geschlossenen Traktionsverletzungen eine umgehende operative Intervention angezeigt. Verbesserte diagnostische Möglichkeiten sowie weiterentwickelte chirurgische Techniken, wie der Einsatz intra- und extraplexaler Spendernerven sowie freier mikrovaskulärer Musculus-gracilis-Lappen, erlauben mittlerweile eine zuverlässige Wiedererlangung der Schulterstabilität und Ellenbogenbeugung."
journal_title,Trauma und Berufskrankheit
article_title,Wohin entwickelt sich das D‑Arzt-Verfahren?In which direction is the accident insurance consultant (D-Arzt) procedure developing?
keyword,"['Altersstruktur\xa0', 'Angestellte Ärzte\xa0', 'Teilzeittätigkeit \xa0', 'Frauenanteil\xa0', 'Abgetretene Zulassung\xa0', 'Age structure\xa0', 'Practicing physicians\xa0', 'Part-time work\xa0', 'Proportion of women\xa0', 'Ceded license\xa0']"
history,"['2017-11', '2017-06-29']"
abstract,"ZusammenfassungDie Ärzteschaft im ambulanten Bereich ist dramatischen Veränderungen unterworfen. Es müssen Antworten auf folgende Problemstellungen gefunden werden und schnellstmöglich Änderungen erfolgen: 1. steigendes Durchschnittsalter, 2. niedergelassene angestellte Ärzte mit eigener oder abgetretener Zulassung, 3. zunehmendes Erbringen der ärztlichen Tätigkeit in Teilzeit, 4. steigender Anteil an Ärztinnen."
journal_title,Trauma und Berufskrankheit
article_title,Chronische knöcherne Instabilitäten des EllenbogengelenkesChronic bony instability of the elbow joint
keyword,"['Ellenbogen\xa0', 'Instabilität\xa0', 'Kollateralbänder\xa0', 'Luxation\xa0', 'Radius\xa0', 'Elbow\xa0', 'Instability, joint\xa0', 'Ligaments, collateral \xa0', 'Dislocations\xa0', 'Radius\xa0']"
history,"['2017-11', '2017-10-09']"
abstract,"ZusammenfassungDie hohe Stabilität des Ellenbogengelenks beruht auf der Kongruenz seiner knöchernen Gelenkpartner in Zusammenspiel mit den weichteiligen Stabilisatoren. Aufseiten der knöchernen Stabilität besitzt der Processus coronoideus eine Schlüsselfunktion als primärer, knöcherner Stabilisator. Zusammen mit dem Koronoid unterstützt der Radiuskopf als sekundärer Stabilisator die posterolaterale Rotationsstabilität und wirkt mit dem medialen Kollateralband wesentlich gegenüber Valgusstress. Substanzdefekte der knöchernen Stabilisatoren können in chronischer Dezentrierung und komplexen Instabilitäten des Ellenbogengelenkes resultieren, die aufwendige gelenkrekonstruktive Eingriffe erforderlich machen. Die Rekonstruktion knöcherner Stabilisatoren erfolgt nicht isoliert: Insuffizienzen weichteiliger Stabilisatoren müssen mit beurteilt und adressiert werden. Die Rekonstruktionsmöglichkeiten bei chronischer knöcherner Instabilität des Ellenbogengelenkes sind Inhalt dieser Übersicht."
journal_title,Trauma und Berufskrankheit
article_title,Update vordere KreuzbandrupturUpdate on anterior cruciate ligament rupture
keyword,"['Operation\xa0', 'Refixation\xa0', 'Augmentation\xa0', 'Kollagenmatrizes\xa0', 'Gelenkstabilisierung\xa0', 'Operative procedures\xa0', 'Refixation\xa0', 'Augmentation\xa0', 'Collagen matrix\xa0', 'Joint stabilization\xa0']"
history,"['2017-11', '2017-10-17']"
abstract,"ZusammenfassungFragestellungDiese Arbeit gibt einen Überblick über den aktuellen Stand der Entwicklung von erhaltenden Operationen des vorderen Kreuzbandes (VKB) und deren klinischen Ergebnissen.ErgebnisseIn den letzten 5 Jahren hat die VKB-erhaltende Operation eine neue Bedeutung bekommen, und neue Operationstechniken versprechen verbesserte Ergebnisse. Während refixierende Operationstechniken neue Ankertechniken und neu entwickeltes Fadenmaterial verwenden, bieten neue Augmentationstechniken eine Erweiterung des Spektrums und neue Behandlungsperspektiven. Die refixierenden scheinen – bei geringer Datenlage – nach 28 Monaten eine relativ hohe Reoperationsquote von 20 % aufzuweisen. Auch über die nichtdynamische Augmentation mittels Ligament-Bracing bei isolierten VKB-Rupturen mit einem FiberTape (Arthrex, Naples, USA) existieren keine mittelfristigen klinischen Daten. Ein 1 Jahres-Follow-up wies eine Reoperationsquote von 4 von 68 Patienten auf. Die beste Studienlage besteht bezüglich der dynamischen intraligamentären Stabilisierung mittels des Ligamys®-Systems (Mathys AG, Bettlach, Schweiz). Studien berichten über klinische Verlaufsergebnisse von 2 bis 5 Jahren. Hier scheinen vergleichbare Scoreergebnisse wie nach VKB-Rekonstruktion – jedoch mit leicht erhöhten Reruptur- und Insuffizienzquoten – vorzuliegen. Hinsichtlich der biologischen Heilungsproblematik des intraartikulär liegenden VKB gibt es erste Lösungsansätze mittels Kollagenmatrizes, die in experimentellen tierischen Studien mit vielversprechenden Ergebnissen angewandt wurden.SchlussfolgerungenDer Erhalt des VKB scheint operativ möglich zu sein. Das Ligamys®-Verfahren scheint eine suffiziente Stabilisierung des Kniegelenks zu erreichen. Eine biologische Unterstützung der Heilung ist sinnvoll und klinisch notwendig, jedoch erst im experimentellen Stadium."
journal_title,Trauma und Berufskrankheit
article_title,Ultraschall und Stoßwelle in der PseudarthrosentherapieUltrasound and shock wave treatment of pseudarthrosis
keyword,"['Frakturheilung\xa0', 'Biophysikalische Verfahren\xa0', 'ESWT\xa0', 'LIPUS\xa0', 'Konsolidierungsraten\xa0', 'Fracture healing\xa0', 'Biophysical procedures\xa0', 'ESWT\xa0', 'LIPUS\xa0', 'Consolidation rate\xa0']"
history,"['2017-11', '2017-09-20']"
abstract,"ZusammenfassungBei 5–10 % aller Frakturen entstehen Pseudarthrosen oder Knochenheilungsstörungen. Die Behandlung dieser Verletzungsfolgen ist eine Domäne der operativen Therapie, die jedoch mit hohen perioperativen Komplikationsraten von 32–73 % assoziiert sein kann. In diesem Zusammenhang stellt sich die Frage nach weniger invasiven, schonenden Therapiemöglichkeiten. Hierzu gehören die biophysikalischen Verfahren, welche die Ultraschalltherapie und Stoßwellenbehandlung einschließen. In der Vergangenheit konnten für beide Verfahren unter Berücksichtigung der Indikationskriterien gute bis sehr gute Konsolidierungsraten gezeigt werden, wobei verschiedene Einflussfaktoren identifiziert wurden. Aufgrund fehlender Aufführung im gesetzlichen Leistungskatalog ist die Kostenübernahme durch den gesetzlichen Leistungsträger aktuell problematisch. Hier sind weitere Studien notwendig, um die biophysikalischen Verfahren als Ergänzung der operativen Therapie zu etablieren und verifizieren."
journal_title,Trauma und Berufskrankheit
article_title,Gelenknahe FrakturJuxta-articular fractures
keyword,"['Wachstumsfuge\xa0', 'Osteosynthese\xa0', 'Kirschner-Drähte\xa0', 'Plattenosteosynthese \xa0', 'Fixateur externe\xa0', 'Growth plate\xa0', 'Osteosynthesis\xa0', 'Kirschner wires\xa0', 'Bone plates\xa0', 'External fixator\xa0']"
history,"['2017-11', '2017-06-19']"
abstract,"ZusammenfassungDie gelenknahe Fraktur betrifft definitionsgemäß den metaphysären Knochen. Aufgrund der unmittelbaren Lage zur Wachstumsfuge besteht abhängig von der Lokalisation der Fraktur im Knochen und dem Alter des Kindes ein gutes Korrekturpotenzial von Achsabweichungen, sodass viele dieser Frakturen überhaupt kein Implantat benötigen und konservativ behandelt werden können. Andererseits kann es zu einer Verletzung der Wachstumsfuge mit einer nachfolgenden Wachstumsstörung kommen. Dieser Aspekt ist auch bei der Wahl des Implantates zu berücksichtigen. Zum einen fordern wir eine möglichst stabile Osteosynthese, zum anderen darf die Wachstumsfuge nicht relevant geschädigt werden. Die am häufigsten verwendete Methode in dieser Region ist die Kirschner-Draht-Osteosynthese. Eine Alternative stellt die Schraubenosteosynthese bei Wachstumsfugenlösungen mit ausreichend großem metaphysärem Keil dar. Ebenso wird sie zur stabilen Refixation dislozierter metaphysärer Band- oder Apophysenausrisse verwendet. Der Übergang zwischen Meta- und Diaphyse stellt hinsichtlich der Osteosynthesemethode eine besondere Region dar. In aller Regel gelingt eine stabile Osteosynthese mittels Kirschner-Drähten nicht mehr. Ebenso sind diese Frakturen nicht für eine elastische stabile intramedulläre Nagelung geeignet. Alternativen stellen die Plattenosteosynthese und der Fixateur externe dar."
journal_title,Trauma und Berufskrankheit
article_title,Sekundäre Wiederherstellung von Nervenverletzungen und motorischer Ersatz an der oberen ExtremitätSecondary reconstruction of damaged nerves and motor replacement in the upper extremities
keyword,"['Rekonstruktion\xa0', 'Sekundärversorgung\xa0', 'Operation\xa0', 'Physiotherapie\xa0', 'Ergotherapie\xa0', 'Reconstruction\xa0', 'Secondary treatment\xa0', 'Surgery\xa0', 'Physiotherapy\xa0', 'Ergotherapy\xa0']"
history,"['2017-11', '2017-08-03']"
abstract,ZusammenfassungVerletzungen von großen Nerven an der oberen Extremität können langfristige Einschränkungen für den Patienten bis hin zum Wechsel des Berufs und Berentungen nach sich ziehen. In dem vorliegenden Vortragsbericht werden Voraussetzungen und Strategien zur Rekonstruktion der Verletzungen durch sekundäre Nervenwiederherstellung und motorische Ersatzplastiken vorgestellt.
journal_title,Trauma und Berufskrankheit
article_title,Wohin entwickelt sich das Durchgangsarztverfahren?In which direction is the D‑Arzt procedure developing?
keyword,"['Reha-Management\xa0', 'Spezialisierung\xa0', 'Fortbildung\xa0', 'Digitalisierung\xa0', 'Qualitätssicherung\xa0', 'Rehabilitation management\xa0', 'Specialization\xa0', 'Further education\xa0', 'Digitalization\xa0', 'Quality assurance\xa0']"
history,"['2017-11', '2017-08-02']"
abstract,"ZusammenfassungDie Notwendigkeit zur Weiterentwicklung des Durchgangsarzt (D-Arzt)-Verfahrens kann sich aus der Sicht des Unfallversicherungsträgers aus seinen veränderten Aufgaben oder Aufgabenschwerpunkten, einer Weiterentwicklung der Reha-Management-Prozesse sowie als Konsequenz aus fachlichen oder gesellschaftlichen Entwicklungen ergeben. Der Beitrag beleuchtet zunächst die Auswirkungen des Bundesteilhabegesetzes auf die D‑Arzt-Tätigkeit. Im Anschluss werden die sich aus dem Reha-Management der Unfallversicherungsträger ergebenden Anforderungen dargestellt. Fortschreitende Spezialisierung und interdisziplinäre Arbeitsteilung, die aus der fachlichen Komplexität erwachsenden Fortbildungsnotwendigkeiten, der Trend zur Digitalisierung sowie die Herausforderungen der Qualitätssicherung werden als weitere Auslöser für notwendige Weiterentwicklungen angesprochen."
journal_title,Trauma und Berufskrankheit
article_title,Plastik des medialen patellofemoralen LigamentsLigamentoplasty of the medial patellofemoral ligament
keyword,"['Patella\xa0', 'Instabilität\xa0', 'Maltracking\xa0', 'Osteotomie\xa0', 'Knie\xa0', 'Patella\xa0', 'Instability\xa0', 'Maltracking\xa0', 'Osteotomy\xa0', 'Knee\xa0']"
history,"['2017-11', '2017-10-12']"
abstract,"ZusammenfassungDie Therapie der Patellainstabilität bedarf einer genauen Vorgehensweise im Hinblick auf Klassifikation, Diagnostik und Therapieplanung. Ein undifferenziertes Vorgehen resultiert häufig in persistierender Instabilität und ausbleibendem Therapieerfolg. Es sind verschiedene Ursachen und Therapieansätze der patellofemoralen Instabilität bekannt, das mediale patellofemorale Ligament (MPFL) galt lange als Synonym für die operative Therapie. Heute existieren Behandlungsalgorithmen und Systeme, welche die zugrunde liegenden Pathologien berücksichtigen und Erfolg versprechende Ergebnisse erlauben. Maßgeblich ist hier die Unterscheidung zwischen Patellainstabilität und -maltracking, die jeweils separat zu betrachten sind. Entsprechend der vorliegenden Hauptpathologie kann ein adäquater Algorithmus verfolgt und niedrige Reluxationsraten erreicht werden. Dieser Beitrag beleuchtet den Einfluss verschiedener Pathologien und die Möglichkeiten der operativen Stabilisierung des patellofemoralen Gelenks. Es wird dabei auf die jeweiligen Subtypen eingegangen, und die entsprechenden Optionen werden erläutert."
journal_title,Trauma und Berufskrankheit
article_title,Untere Extremität: die kindliche SchaftfrakturLower extremities: pediatric shaft fractures
keyword,"['Femur\xa0', 'Unterschenkel\xa0', 'Tibia\xa0', 'Konservative Therapie\xa0', 'Elastisch stabile intramedulläre Nagelung \xa0', 'Femur\xa0', 'Lower leg\xa0', 'Tibia\xa0', 'Conservative therapy\xa0', 'Elastic stable intramedullary nailing\xa0']"
history,"['2017-11', '2017-09-22']"
abstract,"ZusammenfassungKindliche und adoleszente Schaftfrakturen an der unteren Extremität sind keine seltene Verletzung. Der Unterschenkel ist häufiger betroffen als der Oberschenkel. Zur Behandlung der Femurschaftfrakturen finden sich deutlich mehr Empfehlungen als zur Behandlung der Unterschenkelschaftrakturen. Die Femurschaftfrakturen im frühen Lebensalter sind eine Domäne der konservativen Therapie, für Ober- und Unterschenkel wird bis zu einem Körpergewicht von 50 kg als operatives Verfahren häufig die elastisch stabile intramedulläre Nagelung (ESIN) verwendet. Die Plattenosteosynthese stellt aber eine ernste Alternative dar. Vorteile der ESIN sind die kleinen Zugänge und die schnellere Belastbarkeit. Für einfache Querfrakturen ist die intramedulläre Stabilisierung klar überlegen. Nachteil der ESIN ist die hohe intraoperative Strahlenbelastung. Auch die Plattenosteosynthese kann minimalinvasiv durchgeführt werden, längere Trümmerzonen lassen sich damit gut überbrücken."
journal_title,Trauma und Berufskrankheit
article_title,"Prothese, Resektionsarthroplastik oder Arthrodese als SalvageverfahrenProsthesis, resection arthroplasty or arthrodesis as salvage procedure"
keyword,"['Ellenbogenprothese\xa0', 'Revisionschirurgie\xa0', 'Rückzugsverfahren\xa0', 'Knochenlager\xa0', 'Komplikation\xa0', 'Total elbow arthroplasty\xa0', 'Revision surgery\xa0', 'Salvage procedure\xa0', 'Bone\xa0', 'Complications\xa0']"
history,"['2017-11', '2017-07-28']"
abstract,"ZusammenfassungDie sog. Rückzugsverfahren gewinnen in der Ellenbogenprothetik zusehends an Bedeutung. Durch die Ausweitung des Indikationsspektrums mit daraus resultierend steigender Anzahl an implantierten Ellenbogenprothesen sind auch vermehrte Komplikations- und Revisionsraten zu erwarten. Lassen sich für solch komplexe Reinterventionen allgemeingültige Richtlinien definieren? Anhand von eindrücklichen Fällen sollen Therapieansätze erläutert, die Kenntnisse möglicher „Second line of defense“-Strategien aufgezeigt werden. Eine Reimplantation einer Ellenbogenprothese ist nicht immer möglich. Bedingt durch ein ungenügendes „Knochenlager“, das eine Verankerung der Komponenten sowohl an der Ulna wie auch am Humerus nicht möglich macht, sind Allograftaufbauten nötig. Jedoch fehlen bis heute Langzeitresultate bezüglich Standzeiten. Zudem besteht ein erhöhtes Risiko für Infekte, und auch die Inkorporation des verwendeten Allografts ist nicht gewährleistet. Letztendlich bleibt dann nur die Möglichkeit des Ausbaus im Sinne einer Resektionsarthroplastik oder die Versteifung des Gelenks, vorausgesetzt, dass auch hier ein genügendes Knochenlager noch vorhanden ist. Unabhängig von den gewählten Verfahren ist mit einem Funktionsverlust der betroffenen Extremität zu rechnen. Die kleinen Fallzahlen, die auf wenige Zentren verteilt sind, erlauben kaum Vergleiche untereinander. Jeweils patientenspezifisch und gestützt auf die zugrunde liegende Pathologie müssen individuelle Therapiekonzepte erarbeitet werden. Hierbei handelt es sich jeweils nicht um „simple single solution“. In naher Zukunft und mit der zu erwartenden Zunahme der primären Prothesenimplantationen ist auch eine Zunahme der Revisionen zu erwarten."
journal_title,Trauma und Berufskrankheit
article_title,Berufsgenossenschaftliches Heilverfahren und AlterstraumazentrenOccupational insurance association treatment and trauma centers for the elderly
keyword,"['Traumatologie\xa0', 'Geriatrie\xa0', 'Zertifikat\xa0', 'Finanzierung\xa0', 'Behandlung\xa0', 'Traumatology\xa0', 'Geriatrics\xa0', 'Certificate\xa0', 'Funding\xa0', 'Treatment\xa0']"
history,"['2017-11', '2017-08-02']"
abstract,"ZusammenfassungDie demografische Entwicklung unserer Gesellschaft bringt Veränderungen mit sich, auf die sich die Traumatologie einstellen muss. Vielerorts sind in den vergangenen Jahren spezialisierte Alterstraumazentren entstanden, in denen in interdisziplinärer und interprofessionaler Zusammenarbeit die Behandlung geriatrischer Traumapatienten erfolgt. Wissenschaftlich konnte der Nutzen solcher Zentren gegenüber der Standardbehandlung in der Zwischenzeit nachgewiesen werden. Abgeleitet vom § 1 des SGB VII müssen die gesetzlichen Unfallversicherungsträger damit darauf drängen, dass ihre Versicherten in eben solchen Einrichtungen behandelt werden, die über ein entsprechendes Zertifikat verfügen. Das Zertifikat selbst sollte von den beiden Fachgesellschaften für Unfallchirurgie und Geriatrie gemeinsam erarbeitet werden, da die Zusammenarbeit der beiden Fächer eben solche Alterstraumazentren ausmacht. Die Möglichkeit zur Beteiligung an einem stationären Heilverfahren für geriatrische Traumapatienten sollte dabei unabhängig von der dreistufigen Einordnung DAV (Durchgangsarztverfahren) – VAV (Verletzungsartenverfahren) – SAV (Schwerstverletzungsartenverfahren) möglich sein. Allerdings muss auch eine adäquate Finanzierung für diese kostenintensive Behandlung sichergestellt werden."
journal_title,Trauma und Berufskrankheit
article_title,Kindliche kniegelenknahe AvulsionenPediatric avulsion fractures near the knee
keyword,"['Kniegelenknahe Avulsionen\xa0', 'Knöcherne Kreuzbandavulsion\xa0', 'Apophysenfrakturen\xa0', 'Arthroskopische Verfahren\xa0', 'Refixation\xa0', 'Avulsion fractures near knee\xa0', 'Bony cruciate ligament avulsions\xa0', 'Apophyseal fractures\xa0', 'Arthroscopic procedures\xa0', 'Refixation\xa0']"
history,"['2017-11', '2017-08-01']"
abstract,"ZusammenfassungHintergrundKindliche kniegelenknahe Avulsionen sind seltene Verletzungen, die v. a. ältere Kinder bzw. Jugendliche im Rahmen von Sportunfällen betreffen.FragestellungDieser Beitrag gibt einen Überblick über Epidemiologie, Klassifikationen und aktuelle Therapiekonzepte kindlicher kniegelenknaher Avulsionsverletzungen.ErgebnisseDie häufigsten kindlichen kniegelenknahen Avulsionen sind die Verletzung der Apophyse der Tuberositas tibiae sowie der knöcherne vordere (VKB) und hintere Kreuzband (HKB)-Ausriss. Die gebräuchlichste Klassifikation ist die nach Meyers und McKeever für die knöchernen VKB-Risse. In vielen Fällen besteht die Indikation für eine operative Therapie. Allenfalls nicht dislozierte Frakturen können konservativ behandelt werden. Apophysenfrakturen der Tuberositas tibiae werden in der Regel offen reponiert und verschraubt. Die Möglichkeiten für die operative Therapie der knöchernen Kreuzbandausrisse sind vielfältig, sie reichen von direkten offenen Verschraubungen über Knochenanker bis zu arthroskopisch durchgeführten Repositionen mittels Fadencerclage. Vorteile arthroskopischer Verfahren sind die Möglichkeit, Begleitverletzungen wie Meniskusrisse einzeitig mitbehandeln zu können.SchlussfolgerungenNicht dislozierte kindliche kniegelenknahe Avulsionsverletzungen können unter regelmäßigen klinischen und radiologischen Verlaufskontrollen konservativ behandelt werden. Dislozierte Avulsionen und nicht dislozierte Avulsionen mit Begleitverletzungen werden operativ therapiert. Arthroskopische Verfahren sollten im Hinblick auf knöcherne VKB-Avulsionen standardmäßig angewendet werden. Hingegen sind knöcherne HKB-Avulsionen und Tuberositas-tibiae-Verletzungen schnell und effektiv mit direkten offenen Repositionen adressierbar."
journal_title,Trauma und Berufskrankheit
article_title,Steifer posttraumatischer EllenbogenPosttraumatic elbow stiffness
keyword,"['Ellenbogenluxation\xa0', 'Gelenksteife\xa0', 'Konservative Therapie\xa0', 'Arthrolyse\xa0', 'Physiotherapie\xa0', 'Elbow dislocation\xa0', 'Joint stiffness\xa0', 'Conservative therapy\xa0', 'Arthrolysis\xa0', 'Physiotherapy\xa0']"
history,"['2017-11', '2017-10-16']"
abstract,"ZusammenfassungPosttraumatische Ellenbogensteifen können nach Frakturen oder Luxationen des Ellenbogengelenks oder nach chirurgischen Eingriffen auftreten. Bewegungseinschränkungen des Ellenbogens sind für den Alltag der Patienten sehr limitierend, da eine hohe Mobilität des Ellenbogens für alltägliche Aufgaben erforderlich ist. Sind mechanische Hindernisse ausgeschlossen, kann eine Ellenbogensteife zunächst konservativ behandelt werden. Bleibt der Behandlungserfolg aus, können insbesondere bei extraartikulären (extrinsischen) Ellenbogensteifen gute Ergebnisse mit einer Arthrolyse erzielt werden. Derzeit gilt die offene Arthrolyse noch als das Standardverfahren. Durch den vermehrten Einsatz weitet sich allerdings auch der Einsatz der arthroskopischen Arthrolyse aus, die auch in Kombination mit dem offenen Verfahren eingesetzt werden kann. In dem vorliegenden Artikel werden Indikationen und therapeutisches Vorgehen bei der posttraumatischen Ellenbogensteife zusammengefasst."
journal_title,Trauma und Berufskrankheit
article_title,Notwendige Weiterentwicklung aus der Sicht des D‑Arztes am KrankenhausNecessary further development from the perspective of accident insurance consultants in hospitals
keyword,"['Bürokratie\xa0', 'Qualität\xa0', 'Vergütung\xa0', 'Ausbildung\xa0', 'Weiterbildung\xa0', 'Bureaucracy\xa0', 'Quality\xa0', 'Compensation\xa0', 'Education\xa0', 'Training\xa0']"
history,"['2017-11', '2017-07-25']"
abstract,"ZusammenfassungMit der Neuausrichtung des stationären Heilverfahrens 2014 erfolgte eine Neuordnung der Patientenversorgung. Unter anderem sollte dadurch die Qualität der Behandlung verbessert werden. Die Unfallversicherungsträger haben mit der Neuausrichtung mehr Einfluss in der Behandlung von Patienten bekommen. Es ist zu einer Zunahme der Bürokratie gekommen. Inwieweit es zu Verbesserungen der Qualität gekommen ist, ist bisher nicht bekannt. Zur Weiterentwicklung der derzeitigen Situation sind Veränderungen der Rahmenbedingungen notwendig. Der bürokratische Aufwand muss verbessert werden. Das Datenübermittlungsverfahren (DALE-UV) sollte überarbeitet werden mit intelligenten IT-Lösungen. Eine intensive Diskussion der Qualitätsmessung ist erforderlich. Lösungen müssen erarbeitet werden, damit v. a. komplexe Fälle ausreichend vergütet werden. Die Aus- und Weiterbildung in den chirurgischen Disziplinen hat sich in den letzten Jahren verändert. Es müssen Strukturen geschaffen werden, damit die Aus- und Weiterbildung im D‑Arzt-Verfahren adäquat für die Zukunft vorbereitet ist. Zur Weiterentwicklung des D‑Arztes im Krankenhaus ist also eine Vielzahl von Veränderungen und Verbesserungen notwendig."
journal_title,Trauma und Berufskrankheit
article_title,Traumatische NervenläsionenTraumatic nerve injury
keyword,"['Schweregrad\xa0', 'Neurologische Untersuchung\xa0', 'Elektrophysiologie\xa0', 'Nervensonographie\xa0', 'Prognose\xa0', 'Severity\xa0', 'Neurological examination\xa0', 'Electrophysiology\xa0', 'Nerve sonography\xa0', 'Prognosis\xa0']"
history,"['2017-11', '2017-10-19']"
abstract,"ZusammenfassungPeriphere Nerven können aufgrund ihrer Nähe zu knöchernen Strukturen oder auch bei sehr oberflächlichem Verlauf bei einem Trauma oder im Rahmen operativer Eingriffe geschädigt werden. Motorische und sensible Defizite oder gelegentlich auch neuropathische Schmerzen sind die Folge. Entscheidend für die Prognose ist neben der Lokalisationsdiagnostik die Einschätzung des Schweregrades der Läsion, die sich an den Klassifikationen nach Seddon 1–3 und nach Sunderland Grad 1–5 orientiert und mithilfe der klinisch neurologischen Untersuchung, der Elektrophysiologie und bildgebenden Verfahren vorgenommen wird. Hier ist insbesondere die Nervensonographie als zunehmend interessante und aussagekräftige Methode zu erwähnen. Leicht bis mäßiggradige Nervenläsionen haben aufgrund der Regenerationsfähigkeit peripherer Nerven eine günstige Prognose, während höhergradige Nervenläsionen unter konservativen Therapiebedingungen häufig eine ungünstige Prognose haben, es kommt zu Defektheilungen. Komplette Nervendurchtrennungen müssen immer operativ behandelt werden."
journal_title,Trauma und Berufskrankheit
article_title,Sekundäre Bandrekonstruktion am EllenbogenSecondary ligament reconstruction of the elbow
keyword,"['Instabilität\xa0', 'Kollateralbänder\xa0', 'Ellenbogen\xa0', 'Luxation\xa0', 'Bandplastik\xa0', 'Instability\xa0', 'Medial collateral ligament\xa0', 'Lateral collateral ligament\xa0', 'Elbow dislocation\xa0', 'Ligament reconstruction\xa0']"
history,"['2017-11', '2017-10-16']"
abstract,"ZusammenfassungChronische ligamentäre Ellenbogeninstabilitäten sind in den allermeisten Fällen posttraumatischer Genese, können schwere Funktionseinschränkungen bedingen und sind ein Risikofaktor für die Entwicklung einer Ellenbogengelenkarthrose. Eine erfolgreiche Behandlung setzt die genaue Kenntnis der Pathogenese, der erforderlichen Diagnostik und der unterschiedlichen Rekonstruktionsmöglichkeiten voraus. Der Instabilitätsrichtung entsprechend können eine posterolaterale Rotationsinstabilität sowie laterale, mediale und multdirektionale Instabilitäten unterschieden werden. Unter Verwendung autologer oder allogener Sehnengrafts sind für die laterale und mediale Seitenbandrekonstruktion vorwiegend gute Ergebnisse beschrieben, wobei spezifische Komplikationen wie Rezidivinstabilität oder Ulnarisneuropathie nicht selten auftreten. Für bilaterale Instabilitäten steht neben der simultanen lateralen und medialen Bandplastik mit der Box-Loop-Technik eine zirkumferente Stabilisierung mit nur einem Sehnengraft zur Verfügung. Sofern noch ausreichend Rest-Bandgewebe vorhanden ist, besteht zudem die Möglichkeit einer verzögerten, augmentierten Primärnaht der Kollateralbänder. Die bereits bestehende Arthrose des Ellenbogengelenks ist ein limitierender Faktor für das postoperative klinische Ergebnis und stellt daher eine relative Kontraindikation für die Bandplastiken dar."
journal_title,Trauma und Berufskrankheit
article_title,Gutachterliche Fragestellungen bei geriatrischen PatientenQuestions arising in expert opinions of geriatric patients
keyword,"['Begutachtung\xa0', 'Gesetzliche Unfallversicherung\xa0', 'Knochenbruch\xa0', 'Vorerkrankungen\xa0', 'Unfall\xa0', 'Expert opinion\xa0', 'Statutory accident insurance\xa0', 'Bone fractures\xa0', 'Pre-existing diseases\xa0', 'Accident\xa0']"
history,"['2017-11', '2017-06-26']"
abstract,"ZusammenfassungDie Begutachtung von Ursachenzusammenhängen und Unfallfolgen kennt keine Altersgrenze. Die Begutachtung alter Versicherter unterscheidet sich nicht von der Begutachtung junger Patienten. Alte Patienten haben aber häufiger Vorerkrankungen und Vorschäden, die evtl. bei der gutachterlichen Einschätzung zu berücksichtigen sind. Bei Knochenbruchverletzungen ist dies die Osteoporose und bei Verletzungen des Bindegewebes die Texturstörung."
journal_title,Trauma und Berufskrankheit
article_title,Behandlung der akuten KniegelenksluxationTreatment of acute knee dislocations
keyword,"['Bandrekonstruktion\xa0', 'Komplexverletzung\xa0', 'Multiligamentverletzung\xa0', 'Hochrasanztraumen\xa0', 'Operation\xa0', 'Ligament reconstruction\xa0', 'Complex injuries\xa0', 'Multiligament injuries\xa0', 'High velocity trauma\xa0', 'Surgery\xa0']"
history,"['2017-11', '2017-10-18']"
abstract,"ZusammenfassungKniegelenksluxationen stellen seltene, aber schwerwiegende Kniegelenksverletzungen dar. Da die Verletzung oftmals im Rahmen von Hochrasanztraumen entsteht, sind häufig junge aktive Patienten betroffen. Dabei sind kombinierte Verletzungen des vorderen und hinteren Kreuzbandes mit Beteiligung des medialen bzw. lateralen Kapselbandapparates typische Verletzungsmuster. Das frühzeitige Erkennen und die Behandlung von neurovaskulären Begleitverletzungen sind therapieentscheidend und haben maßgeblichen Einfluss auf das Outcome. Röntgen, CT-Angiographie, Magnetresonanztomographie und Narkoseuntersuchung unter Durchleuchtung sind therapieweisende diagnostische Untersuchungen. Nach aktueller Datenlage hat das operative Vorgehen Vorteile gegenüber dem konservativen Vorgehen. Maßgeblich für die Wahl des Operationsverfahrens ist das Ausmaß der Gesamtverletzungsschwere. Ziel der operativen Versorgung ist in erster Linie die anatomisch korrekte femorotibiale Einstellung und Stabilisierung des Kniegelenks. Im Rahmen von Polytraumen oder bei Vorliegen von Gefäßverletzungen ist die Anlage eines Fixateur externe zu empfehlen. Ansonsten haben rekonstruktive Operationsverfahren in den ersten 14 Tagen nach Verletzung Vorteile gegenüber verzögerten Rekonstruktionsverfahren. Rekonstruktionsstrategien und -techniken müssen jeweils individuell an das Verletzungsmuster angepasst werden und hängen unter anderem auch von klinikabhängigen Ressourcen und der Erfahrung des Chirurgen ab. Trotz optimaler Versorgung und Nachbehandlung verbleiben nicht selten Restinstabilitäten, Funktions- sowie Belastungseinschränkungen. Das Risiko für die Entwicklung einer Kniegelenksarthrose ist zudem deutlich erhöht."
journal_title,Trauma und Berufskrankheit
article_title,AcetabulumfrakturenAcetabular fractures
keyword,[]
history,"['2017-09', '2017-08-18']"
abstract,None
journal_title,Trauma und Berufskrankheit
article_title,AcetabulumfrakturenAcetabular fractures
keyword,"['Indikation\xa0', 'Operationstechnik\xa0', 'Therapie\xa0', 'Gelenkersatz\xa0', 'Rekonstruktion\xa0', 'Indications\xa0', 'Surgical technique\xa0', 'Therapy\xa0', 'Joint replacement\xa0', 'Reconstruction\xa0']"
history,"['2017-09', '2017-08-16']"
abstract,"ZusammenfassungAcetabulumfrakturen sind seltene Verletzungen mit jedoch steigender Inzidenz, insbesondere bei älteren Patienten. Wie bei allen Gelenkfrakturen ist die anatomische Reposition eine Voraussetzung zur Vermeidung einer posttraumatischen Arthrose. Klassische Operationszugänge zum Acetabulum sind der ilioinguinale und der Kocher-Langenbeck-Zugang. Modifikationen der Zugänge wie der Stoppa-Zugang oder der Pararectus-Zugang erlauben es, auch beim betagten Patienten Osteosynthesen des Acetabulums mit reduzierter Invasivität durchzuführen. Nur etwa 20 % aller Patienten mit Acetabulumfraktur benötigen im Verlauf einen endoprothetischen Gelenkersatz. Daher sollte, wann immer möglich, die Rekonstruktion dem primären Gelenkersatz vorgezogen werden."
journal_title,Trauma und Berufskrankheit
article_title,Begutachtung der PeronealsehnenluxationAssessment of peroneal tendon dislocation
keyword,"['Anatomie\xa0', 'Pathomechanik\xa0', 'Begutachtung\xa0', 'Ruptur\xa0', 'Dorsalextension \xa0', 'Anatomy\xa0', 'Pathomechanics\xa0', 'Expert opinion\xa0', 'Rupture\xa0', 'Dorsal extension\xa0']"
history,"['2017-09', '2017-02-28']"
abstract,"ZusammenfassungEine Peronealsehnenluxation resultiert im Wesentlichen aus der Dorsalextension in Verbindung mit einer Eversion bei maximaler Peronealsehnenkontraktion. Eine Inversion mit Plantarflexion wirkt vorwiegend auf das Lig. fibulotalare anterius und das Lig. fibulocalcaneare ein. Kommt Letzteres zur Anspannung und zur Ruptur, entsteht eine Vorverlagerung der Peronealsehnen in der Richtung Retinaculum peroneorum superius bis hin zur Ruptur mit Luxation der Peronealsehnen. In allen Fällen muss die anatomische Gegebenheit berücksichtigt werden."
journal_title,Trauma und Berufskrankheit
article_title,Was ist der Standard in der Versorgung der Unterarmschaftfraktur?What is state of the art in treatment of forearm shaft fractures?
keyword,"['Obere Extremität\xa0', 'Plattenosteosynthese\xa0', 'Röntgen\xa0', 'Operation\xa0', 'Mobilisation\xa0', 'Upper limb\xa0', 'Plate osteosynthesis\xa0', 'Tomography, X‑ray\xa0', 'Operation\xa0', 'Mobilization\xa0']"
history,"['2017-09', '2017-07-20']"
abstract,"ZusammenfassungUnterarmfrakturen sind häufige knöcherne Verletzungen des Erwachsenen. Die „einfache“ diaphysäre Fraktur von Radius und Ulna ist von Galeazzi‑, Monteggia- und Essex-Lopresti-Verletzungen abzugrenzen. Nach röntgenologischer Diagnostik ist in der Regel eine operative Versorgung notwendig. Der Unterarm bildet ein funktionelles Gelenk, eine Unterarmschaftfraktur ist daher mit besonderer Sorgfalt unter Beachtung von Rotation und Längsachse anatomisch zu rekonstruieren. Über 2 separate Zugänge sollten jeweils 3,5 mm LCDCP („limited-contact dynamic compression plate“) eingebracht werden mit mindestens 3 bikortikalen Schrauben auf jeder Frakturseite, ggf. ergänzt durch interfragmentäre Zugschrauben. Eine frühfunktionelle Mobilisation schließt die Behandlung ab, eine Metallentfernung erfolgt bei störendem Osteosynthesematerial."
journal_title,Trauma und Berufskrankheit
article_title,Neutral-0-MethodeNeutral zero method
keyword,"['Gelenkbeweglichkeit\xa0', 'Bewegungsausmaß\xa0', 'Standardebenen\xa0', 'Messmethode\xa0', 'Nomenklatur\xa0', 'Joint mobility\xa0', 'Range of motion\xa0', 'Standard planes\xa0', 'Measurement methods\xa0', 'Nomenclature\xa0']"
history,"['2017-09', '2017-08-03']"
abstract,"ZusammenfassungDie Neutral-0-Methode ist eine bewährte Methode zur Beschreibung von Befunden, Therapieverlauf und -ergebnis. Sie ist der Versuch, die Gelenkbeweglichkeit standardisiert darzustellen. Bei der Erarbeitung von Nachbehandlungsempfehlungen durch eine Arbeitsgruppe des Arbeitskreises Traumarehabilitation der Sektion Rehabilitation–Physikalische Therapie der DGOU (Deutsche Gesellschaft für Orthopädie und Unfallchirurgie) ist in der Kommunikation zwischen Ärzten und Therapeuten jedoch aufgefallen, dass sich im Laufe der Zeit aufgrund unterschiedlicher Erfahrung und Auffassungen die Nomenklatur im ärztlichen und therapeutischen Bereich voneinander wegentwickelt hat. Unter Beachtung standardisierter Körperebenen ist versucht worden, die Auffassung und Nomenklatur der Neutral-0-Methode wieder zusammenzuführen. Es werden Vorschläge gemacht hinsichtlich der Definition der Standardebenen und deren konsequenter Anwendung bei der Gelenkmessung. Am Beispiel einiger Gelenke wird die Vereinheitlichung der Begriffe im ärztlichen und therapeutischen Bereich dargestellt. Unsere Anregungen sollen eine fachliche Diskussion anstoßen, inwieweit eine Überarbeitung und Aktualisierung einer fast 50 Jahre alten Messmethode, die systematische und logische Schwächen aufweist, jetzt erforderlich ist."
journal_title,Trauma und Berufskrankheit
article_title,Aktuelle Trends in der Behandlung von AcetabulumfrakturenCurrent trends in treatment of acetabular fractures
keyword,"['Osteosynthese\xa0', '3-D-Kontrolle\xa0', 'Computertomographie\xa0', 'Demografische Entwicklung\xa0', 'Ventrale Zugänge \xa0', 'Osteosynthesis\xa0', '3D control\xa0', 'Computed tomography\xa0', 'Demographic development\xa0', 'Ventral approaches\xa0']"
history,"['2017-09', '2017-08-16']"
abstract,"ZusammenfassungHintergrundAuf Basis der Registerdaten der AG Becken der Deutschen Gesellschaft für Unfallchirurgie (DGU) werden Entwicklungen in der Behandlung von Acetabulumfrakturen der letzten 25 Jahre dargestellt.Material und MethodeDie Datenbank der Becken AG der DGU umfasst für den Zeitraum 1991 bis 2017 Daten von mehr als 15.000 Patienten aus ca. 30 Zentren. Zusätzlich werden die eigenen Erfahrungen von 25 Jahren Acetabulumchirurgie dargestellt.ErgebnisseDas Alter der Patienten hat erheblich zugenommen von durchschnittlich etwa 40 in den 1990er-Jahren zu ca. 70 Jahre aktuell. Dadurch hat sich auch die Frakturmorphologie verändert zu vornehmlich Frakturen, die den vorderen Pfeiler betreffen. Entsprechend erfolgen die Osteosynthesen auch zumeist durch weiterentwickelte ventrale Zugänge wie Stoppa und Pararectus mit anatomisch vorkonturierten Platten, die das Gelenk auch von medial abstützen. Intraoperativ ist die 3‑D-Kontrolle anerkannter Standard, zunehmend auch als Computertomographie.SchlussfolgerungDie Registerdaten der Becken AG lassen den Wandel in der Acetabulumchirurgie entsprechend der demografischen Entwicklung sehr gut nachvollziehen."
journal_title,Trauma und Berufskrankheit
article_title,Periprothetische AcetabulumfrakturenPeriprosthetic acetabular fractures
keyword,"['Revisionsendoprothetik\xa0', 'Hüftgelenk\xa0', 'Totalendoprothese\xa0', 'Insuffizienzfrakturen\xa0', 'Diagnostik\xa0', 'Revision arthroplasty\xa0', 'Hip joint\xa0', 'Total hip arthroplasty\xa0', 'Fragility fractures\xa0', 'Diagnostics\xa0']"
history,"['2017-09', '2017-07-28']"
abstract,"ZusammenfassungHintergrundPeriprothetische Acetabulumfrakturen sind eine seltene, aber zunehmende Komplikation in der Primär- und Revisionsendoprothetik des Hüftgelenks.Ziel der ArbeitEs erfolgt die Darstellung von Diagnostik und Therapieoptionen in der Behandlung periprothetischer Acetabulumfrakturen.Material und MethodenEs handelt sich um einen Übersichtsbeitrag unter Einbeziehung von Originalarbeiten und Reviews.ErgebnisseDie intraoperative Inzidenz periprothetischer Acetabulumfrakturen beträgt bis 0,4 %. Eine zementfreie Press-fit-Versorgung ist mit einem höheren Frakturrisiko assoziiert. Weitere Risikofaktoren sind Revisionseingriffe und Osteoporose. Man unterscheidet intraoperative periazetabuläre Frakturen von postoperativen Frakturen, die traumatisch bedingt sein können oder schleichend z. B. als Folge Polyethylenabrieb-induzierter Osteolysen oder bei Pfannenlockerung auftreten. Die Diagnostik umfasst Röntgen und Computertomographie. Vor allem bei schleichenden Frakturen sollte außerdem ein Infektausschluss erfolgen. Die in der Regel operative Therapie richtet sich nach Frakturdislokation, Knochenqualität, Defekten, Pfannenstabilität und patientenindividuellen Faktoren. Wichtig sind die Osteosynthese des hinteren Pfeilers und die Stabilität der Pfanne. Die chirurgische Therapie ist anspruchsvoll und umfasst ein großes Portfolio an Zugangswegen und Implantatoptionen von der Revisionspfanne bis hin zum individuellen Beckenteilersatz.Diskussion/SchlussfolgerungDie Fraktureinteilung nach dem Unified-Classification-System, der Therapiealgorithmus nach Masri oder Simon und die Defektklassifikation nach Paprosky sind für die klinische Anwendung empfohlen. Das Behandlungsteam bedarf der Expertise in der Acetabulumchirurgie und Revisionsendoprothetik."
journal_title,Trauma und Berufskrankheit
article_title,Acetabulumfraktur – Prothesenversorgung wann und wie?Acetabular fractures – when and how to perform hip replacement?
keyword,"['Osteosynthese\xa0', 'Totalendoprothese\xa0', 'Hüftgelenk\xa0', 'Outcome\xa0', 'Endoprothese\xa0', 'Osteosynthesis\xa0', 'Total hip arthroplasty\xa0', 'Hip joint\xa0', 'Outcome\xa0', 'Endoprosthesis\xa0']"
history,"['2017-09', '2017-08-08']"
abstract,"ZusammenfassungAcetabulumfrakturen kommen einerseits bei jüngeren Patienten unter 40 Jahren vor, andererseits sind aber auch zunehmend geriatrische Patienten betroffen. Beim jüngeren Patienten stellt die Osteosynthese den Goldstandard dar. Die endoprothetische Versorgung der Acetabulumfraktur ist hier eine Ausnahmeindikation und reduziert sich auf schwere Gelenkluxationen und Kombinationsverletzungen von Acetabulum, Hüftkopf und Schenkelhals. Beim älteren Menschen ist die osteosynthetische Stabilisierung grundsätzlich ebenfalls ein zu erwägendes Therapiekonzept. Bei bestimmten Konstellationen wie Frakturen mit Beteiligung des vorderen Pfeilers, erheblich dislozierten Frakturen, entsprechender Impaktion des Femurkopfes, vorbestehender klinisch relevanter Koxarthrose, komplexen Luxationsfrakturen auch unter Beteiligung der dorsalen Wand und des dorsalen Pfeilers, Frakturen mit einer entsprechend hohen Arthroserate im frühen Verlauf oder Repositionshindernissen stellt der künstliche Hüftgelenkersatz ein komplikationsarmes Therapieverfahren dar. Das zweizeitige Verfahren mir primär limitierter osteosynthetischer Stabilisierung des Acetabulums eignet sich zum Aufbau eines Knochenstocks für die Pfanne im Rahmen der sekundären Endoprothetik, die im Optimalfall zementfrei, in Press-fit-Technik und ggf. verschraubt implantiert wird."
journal_title,Trauma und Berufskrankheit
article_title,Ventrale Zugänge zum AzetabulumVentral approaches to the acetabulum
keyword,"['Azetabulumfraktur\xa0', 'Ilioinguinaler Zugang\xa0', 'Iliofemoraler Zugang\xa0', 'Stoppa-Zugang\xa0', 'Pararektus-Zugang\xa0', 'Acetabular fracture\xa0', 'Ilioinguinal approach\xa0', 'Iliofemoral approach\xa0', 'Stoppa approach\xa0', 'Pararectal approach\xa0']"
history,"['2017-09', '2017-07-25']"
abstract,"ZusammenfassungDie Wahl eines suffizienten Zuganges ist von immanenter Wichtigkeit, um eine qualitativ hochwertige Reposition zu erreichen und alle Frakturkomponenten sicher zu stabilisieren. Der extrapelvine ilioinguinale Zugang gilt dabei als Goldstandard zur operativen Versorgung von Azetabulumfrakturen. Aufgrund des demografischen Wandels mit veränderten Frakturmustern gewinnen jedoch die intrapelvinen Zugänge zunehmend an Bedeutung. Aktuelle Daten zeigen, dass diese diverse Vorteile in der operativen Stabilisierung ventraler Pathologien innehaben. Analog zum modifizierten Stoppa-Zugang bietet der wenig invasive und weichteilschonende Pararektus-Zugang den Vorteil der direkten Visualisierung intrapelviner Strukturen und erlaubt gleichermaßen die Exposition, die durch den ilioinguinalen Zugang erreicht werden kann. Eine detaillierte präoperative Auseinandersetzung mit der Fraktur und die stringente präoperative Planung bestimmen jedoch letztendlich die Wahl des notwendigen Zuganges und sind damit wegbereitend für ein gutes klinisches Ergebnis."
journal_title,Trauma und Berufskrankheit
article_title,BegrüßungsanspracheWelcome speech
keyword,[]
history,"['2017-08', '2017-03-15']"
abstract,None
journal_title,Trauma und Berufskrankheit
article_title,BegrüßungsanspracheWelcome speech
keyword,[]
history,"['2017-08', '2017-03-13']"
abstract,None
journal_title,Trauma und Berufskrankheit
article_title,SchlussworteClosing remarks
keyword,[]
history,"['2017-08', '2017-03-27']"
abstract,None
journal_title,Trauma und Berufskrankheit
article_title,Komplexe proximale HumerusfrakturenComplex proximal humeral fractures
keyword,"['Schultergelenkfrakturen\xa0', 'Alter\xa0', 'Frakturprothese\xa0', 'Humeruskopf\xa0', 'Schulterfunktion\xa0', 'Shoulder joint fractures\xa0', 'Aged\xa0', 'Fracture prosthesis\xa0', 'Humeral head\xa0', 'Shoulder function\xa0']"
history,"['2017-08', '2017-08-15']"
abstract,"ZusammenfassungDer funktionelle Anspruch nach Schultergelenkfrakturen steigt bei älteren Patienten. Das chirurgische Bestreben ist die stabile und anatomische Rekonstruktion des Humeruskopfes auch bei komplizierten Humeruskopffrakturen. Bei Vorliegen irreparabler Humeruskopffrakturen geht der Trend bei älteren Patienten zur Implantation einer primären, inversen Frakturprothese. Die Indikation erfolgt dabei zunehmend alters- und nicht mehr frakturmusterabhängig. Dieses Vorgehen wird mittlerweile durch verschiedene biomechanische und klinische Studien unterstützt, die die Überlegenheit der inversen Prothese gegenüber anderen Osteosyntheseverfahren und der anatomischen Frakturprothese dokumentieren. Bei jüngeren Patienten wird weiterhin empfohlen, auch bei komplexen Frakturmorphologien, eine primäre Rekonstruktion der Fraktur anzustreben. Dieser Beitrag beleuchtet die chirurgischen Möglichkeiten bei komplexen, proximalen Humerusfrakturen und soll eine Entscheidungshilfe im klinischen Alltag bieten."
journal_title,Trauma und Berufskrankheit
article_title,Sekundäre Rekonstruktionen am Ellenbogengelenk im KindesalterSecondary reconstruction of the elbow joint in childhood
keyword,"['Korrekturosteotomie\xa0', 'Cubitus varus\xa0', 'Cubitus valgus\xa0', 'Condylus radialis\xa0', 'Monteggia-Läsion\xa0', 'Corrective osteotomy\xa0', 'Cubitus varus\xa0', 'Cubitus valgus\xa0', 'Radial condyle\xa0', 'Monteggia’s fracture\xa0']"
history,"['2017-08', '2017-01-10']"
abstract,"ZusammenfassungEs ist bekannt, dass es im Bereich des Ellenbogens bei Kindern und Jugendlichen häufig zu Verletzungen kommt. Der geringe Anteil am Längenwachstum im Bereich des distalen Humerus und proximalen Unterarms trägt dazu bei, dass die Spontankorrektur limitiert und frühzeitig in jungem Alter ausgeschöpft ist. Probleme bei der Primärversorgung sind häufig die Ursache für posttraumatische Deformitäten, die dann gelegentlich eine sekundäre Korrektur erfordern. Besonders hervorzuheben sind die Folgen nach suprakondylärer Humerusfraktur mit Cubitus varus, seltener Cubitus valgus, Fehlstellung bzw. Pseudarthrose des Condylus radialis und eine persistierende Luxation des Radiuskopfes, verursacht durch eine Monteggia-Läsion. Die Korrektur dieser Deformitäten ist anspruchsvoll, und es werden in der Literatur hohe Komplikationsraten angegeben. Unabhängig davon muss entsprechend der Verletzung das zu erwartende Funktionsdefizit abgeschätzt und bei kritisch zu stellender, aber gegebener Korrekturindikation diese zügig durchgeführt werden, bevor es durch die Fehlstellung zu einer sekundären Gelenk- bzw. Knochenumformung kommt."
journal_title,Trauma und Berufskrankheit
article_title,Endoprothetik bei distalen HumerusfrakturenEndoprosthetics for distal humeral fractures
keyword,"['Hemiprothese\xa0', 'Alterstraumatologie\xa0', 'Implantate\xa0', 'Rekonstruktion\xa0', 'Osteosynthese\xa0', 'Hemiarthroplasty\xa0', 'Geriatric traumatology\xa0', 'Implants\xa0', 'Reconstruction\xa0', 'Osteosynthesis\xa0']"
history,"['2017-08', '2017-03-16']"
abstract,"ZusammenfassungDie Rekonstruktion von komplexen distalen Humerusfrakturen stellt trotz moderner winkelstabiler Implantate eine operative Herausforderung dar. Dies gilt insbesondere, wenn im geriatrischen Patientengut die Kombination aus eingeschränkter Knochenqualität und mehrfragmentärer, artikulärer Fraktursituation vorliegt. Das Ziel einer Rekonstruktion und Osteosynthese ist in diesen Fällen mitunter nicht zu erreichen. Cobb und Morrey publizierten vor 20 Jahren erstmals vielversprechende Ergebnisse nach primärer Frakturendoprothetik am distalen Humerus. Seither ist die Frakturversorgung mit einer Ellenbogenprothese zunehmend in den Fokus gerückt. Dies gilt insbesondere für das geriatrische Patientengut mit niedrigen funktionellen Ansprüchen und vorbestehenden Gelenkpathologien. Die strikt einzuhaltende lebenslange Belastungsrestriktion erfordert allerdings ein hohes Maß an Patientencompliance in der Nachbehandlung. Die Ergebnisse im kurzfristigen bis mittelfristigen Verlauf sind vielversprechend. Eine Zunahme der Komplikationsfrequenz ist jedoch bei längeren Nachuntersuchungsintervallen festzustellen. Studien mit relevanten Patientenzahlen im langfristigen Verlauf fehlen fast vollständig. Für ein ausgewähltes Patientengut stellt die Ellenbogenprothese ein geeignetes therapeutisches Verfahren dar. Die mit zunehmenden Implantationszahlen zu erwartende Erhöhung der Spätkomplikationen wird jedoch in Zukunft eine neue Herausforderung darstellen. Komplexe Revisionsoperationen werden die Folge sein."
journal_title,Trauma und Berufskrankheit
article_title,Minimalinvasive Osteosynthese der intraartikulären KalkaneusfrakturMinimally invasive osteosynthesis of intra-articular calcaneal fractures
keyword,"['Zugang\xa0', 'Wundheilung\xa0', 'Durchleuchtung\xa0', 'Implantat\xa0', 'Nachbehandlung\xa0', 'Access\xa0', 'Wound healing\xa0', 'Fluoroscopy\xa0', 'Implant\xa0', 'Aftercare\xa0']"
history,"['2017-08', '2016-12-16']"
abstract,"ZusammenfassungHintergrundMinimalinvasive Operationstechniken finden immer mehr Verbreitung und bieten bei der operativen Versorgung von Kalkaneusfrakturen besonders große Vorteile.Ziel der ArbeitDie Arbeit stellt eine Variante der minimalinvasiven Osteosynthese von Kalkaneusfrakturen und deren Ergebnissen vor.DiskussionDie minimalinvasiven Osteosynthesen von Kalkaneusfrakturen ermöglichen weniger Wundheilungsstörungen und kürzere Operationszeiten. Nachteile sind die schlechtere Übersicht, eine damit verbundene längere Durchleuchtungszeit und weniger stabile Implantate. Mit einer angepassten Nachbehandlung lassen sich nach minimalinvasiver Osteosynthese von Kalkaneusfrakturen gleich gute Resultate wie mit den großen Zugängen erzielen."
journal_title,Trauma und Berufskrankheit
article_title,Operative Möglichkeiten zur Behandlung von fehlverheilten distalen Unterarmfrakturen im KindesalterOperative options for treatment of incorrectly healed distal forearm fractures in childhood
keyword,"['Korrekturosteotomie\xa0', 'Spontankorrektur\xa0', 'Posttraumatische Wachstumsstörung\xa0', 'Kallusdistraktion\xa0', 'Plattenosteosynthese\xa0', 'Corrective osteotomy\xa0', 'Spontaneous correction\xa0', 'Posttraumatic growth disorder\xa0', 'Callus distraction\xa0', 'Plate osteosynthesis\xa0']"
history,"['2017-08', '2017-03-16']"
abstract,"ZusammenfassungMit der operativen Korrektur der in Fehlstellung verheilten distalen Unterarmfraktur im Kindesalter sieht sich der Chirurg im klinischen Alltag eher selten konfrontiert. Grund hierfür ist sicherlich die ausgeprägte Spontankorrekturfähigkeit der Wachstumsfuge am distalen Radius. Hierdurch können selbst gröbere Fehlstellungen altersabhängig toleriert und der Spontankorrektur überlassen werden. In Einzelfällen kommt jedoch auch die Spontankorrektur an ihre Grenzen. In den meisten Fällen betrifft dies Kinder jenseits des 10. Lebensjahres, die über keine ausreichende Korrekturpotenz mehr verfügen. Ein zweites Kollektiv stellen Kinder mit posttraumatischen Wachstumsstörungen am distalen Unterarm dar. Besteht die Indikation zur operativen Korrektur, stehen grundsätzlich 3 Verfahren zur Wahl. Bei alleiniger Achsfehlstellung erfolgen die Korrekturosteotomie und palmare Plattenosteosynthese. Bei Achsfehlstellungen mit Längenverlust sollte zusätzlich die Interposition eines Beckenspans erfolgen. Bei Fehlstellung, die in Folge einer hemmenden Wachstumsstörung entstanden sind, ist eine Korrekturosteotomie mit einer Kallusdistraktion zu kombinieren."
journal_title,Trauma und Berufskrankheit
article_title,Sekundäre NervenrekonstruktionenSecondary nerve reconstruction
keyword,"['Nervenschäden\xa0', 'Reinnervation\xa0', 'Conduits\xa0', 'Allograft\xa0', 'Nerveninterponat\xa0', 'Nerve damage\xa0', 'Reinnervation\xa0', 'Conduits\xa0', 'Allografts\xa0', 'Nerve grafting\xa0']"
history,"['2017-08', '2017-06-02']"
abstract,"ZusammenfassungBei peripheren Nervenschäden ist aus unterschiedlichen Gründen nicht immer eine primäre Rekonstruktion
				 möglich. Dennoch sollte eine schnellstmögliche Reinnervation der Zielorgane angestrebt werden. Das Zeitfenster für die
				 Rekonstruktion motorischer Zielorgane beträgt 18 Monate, für sensible Zielorgane ca. 3 Jahre. Nach Ablauf von 12 Wochen
				 ohne klinische oder neurophysiologische Reinnervationszeichen unter konservativer Therapie sollten daher operative
				 Revisionen erwogen werden. Im Rahmen sekundärer Rekonstruktionen können kleinere Defektstrecken mit resorbierbaren
				 Conduits oder azellulären Allografts überbrückt werden. Bei größeren Defektstrecken >5 cm bleibt der Goldstandard das
				 autologe Nerveninterponat. Durch handgelenknahe Nerventranspositionen lassen sich die Zielorgane früher erreichen und deren irreversible Degeneration vermeiden. Als Rettungsoperationen für funktionslose Muskelgruppen stehen motorische Ersatzplastiken und funktionelle Muskeltransfers zur Verfügung."
journal_title,Trauma und Berufskrankheit
article_title,Rekonstruktion posttraumatischer FehlstellungenReconstruction of posttraumatic malalignment
keyword,"['Verletzungen\xa0', 'Korrektur\xa0', 'Arthrose\xa0', 'Deformitäten\xa0', 'Funktionen\xa0', 'Injuries\xa0', 'Correction\xa0', 'Arthrosis\xa0', 'Deformities\xa0', 'Function\xa0']"
history,"['2017-08', '2017-03-09']"
abstract,"ZusammenfassungVerletzungen der Füße führen häufig aufgrund von Fehlstellungen, schmerzhaften Pseudarthrosen und Instabilitäten zu bleibenden Funktionsbeeinträchtigungen. Ursachen für korrekturbedürftige Fußfehlstellungen sind übersehene oder inadäquat therapierte Verletzungen. Komplizierte postoperative Verläufe mit posttraumatischen Arthrosen, Infekten, Osteonekrosen, ausbleibenden knöchernen Heilungen oder muskulären Imbalancen können auch nach initial korrekter Behandlung zu korrekturbedürftigen Fehlstellungen führen. Korrekturen müssen dabei alle Funktionen des Fußes berücksichtigen. Das Augenmerk muss insbesondere auf die Achsausrichtung des Rückfußes und die Koppelung des Vorfußes gelegt werden. Idealerweise werden Korrektureingriffe vor Auftreten von Anschlussarthrosen benachbarter Gelenke durchgeführt. Zur Wiederherstellung der Funktion des Fußes sollten Arthrodesen auf die unmittelbar betroffenen Gelenke beschränkt bleiben. Deformierende Kräfte der motorisch überwiegenden Muskelgruppen müssen neutralisiert werden, um erneute Deformitäten zu vermeiden. Der Beitrag gibt eine Übersicht über korrigierende Eingriffe am Rückfuß."
journal_title,Trauma und Berufskrankheit
article_title,Knieendoprothetik nach TraumaPosttraumatic knee arthroplasty
keyword,"['Posttraumatische Arthrose\xa0', 'Gonarthrose\xa0', 'Implantat\xa0', 'Prognose\xa0', 'Operation\xa0', 'Posttraumatic arthritis\xa0', 'Osteoarthritis, knee\xa0', 'Implant\xa0', 'Prognosis\xa0', 'Operation\xa0']"
history,"['2017-08', '2017-01-11']"
abstract,"ZusammenfassungHintergrundDie demografische Entwicklung und die Zunahme an Unfällen mit Gelenkbeteiligung im Rahmen von Freizeitaktivitäten bei Jüngeren spiegeln sich in der stetig zunehmenden Anzahl an Implantationen von Knieendoprothesen auf dem Boden einer sekundären, posttraumatischen Gonarthrose wider.Material und MethodenDie prinzipiellen Probleme und deren Lösungen, die im Rahmen der endoprothetischen Versorgung des Kniegelenkes von posttraumatischen Patienten häufig auftreten, werden in diesem Beitrag wiedergegeben. Prinzipielle Aspekte der Operationstechnik und Implantatwahl sowie Prognosefaktoren sollen vorgestellt werden.Ergebnis und DiskussionDie Wahl des Implantates und insbesondere der Kopplungsgrad der Prothese ist bedingt durch die vorliegenden ligamentären Schäden, die verbliebenen Knochendefekte und die vorhandenen Statikfehler der Extremität. Die Wahl des Zuganges muss in diesem Zusammenhang berücksichtigt werden, um Hautnekrosen zu verhindern. Gegebenenfalls ist eine gleichzeitige Lappenversorgung lokal und/oder als freier Lappen angezeigt. Auch eine verbliebene Schädigung des Streckapparates oder Fehlstatik mit nötiger primärer Umstellung muss im Vorfeld avisiert werden.SchlussfolgerungDie endoprothetische Versorgung posttraumatischer Gonarthrosen stellt eine Herausforderung dar. Neben einer Implantatpalette, die von einem unikompartimentellen Ersatz bis hin zur Tumorprothese reicht, müssen zusätzliche Operationsschritte wie Umstellungsosteotomien und Rekonstruktionen des Streckapparates einschließlich interdisziplinärer Lappendeckungen in Betracht gezogen und im Vorfeld geplant werden. Die Ergebnisse hinsichtlich Haltbarkeit und Funktion sind grundsätzlich abhängig von den präoperativen Verhältnissen, aber im Vergleich insgesamt schlechter als entsprechende Versorgungen von primären Arthrosen."
journal_title,Trauma und Berufskrankheit
article_title,Technisch orthopädische Versorgung nach Amputationen am FußTechnical orthopedic care after foot amputation
keyword,"['Technische Orthopädie\xa0', 'Trauma\xa0', 'Einlagen\xa0', 'Prothesen\xa0', 'Orthesen\xa0', 'Technical orthopedics\xa0', 'Trauma\xa0', 'Insoles\xa0', 'Prostheses\xa0', 'Orthoses\xa0']"
history,"['2017-08', '2017-03-28']"
abstract,"ZusammenfassungTechnische orthopädische Versorgungen nach schweren Verletzungen des Fußes oder gar Amputationen ermöglichen dem Betroffenen oftmals eine deutlich verbesserte Mobilität und damit Reintegrationsmöglichkeiten im privaten und beruflichen Umfeld. Im Rahmen der Schuhtechnik gibt es Einlagen, Schuhzurichtungen am Konfektionsschuh, Innenschuhorthesen, Maßschuhe, bei Amputationen bieten moderne Prothesen bisher noch nicht gekannte Versorgungsmöglichkeiten. Diese werden im Beitrag an Beispielen demonstriert."
journal_title,Trauma und Berufskrankheit
article_title,Reha-Management nach komplexen HandverletzungenRehabilitation management after complex hand injuries
keyword,"['Rehabilitation\xa0', 'Heilverfahren\xa0', 'Akutversorgung\xa0', 'Tastvermögen\xa0', 'Motivation \xa0', 'Rehabilitation\xa0', 'Healing\xa0', 'Acute treatment\xa0', 'Sense of touch\xa0', 'Motivation\xa0']"
history,"['2017-08', '2017-04-11']"
abstract,"ZusammenfassungDas Reha-Management nach komplexen Handverletzungen unterscheidet sich prinzipiell nicht vom Reha-Management anderer schwerer Unfallverletzungen. Allerdings unterscheidet sich die persönliche Betroffenheit der Verletzten gegenüber Verletzungen an anderen Köperteilen ganz erheblich. Nicht nur der funktionale Verlust, also die entgangene Körperfunktion, gilt es, durch bestmögliche medizinische Akutversorgung und Rehabilitationsmaßnahmen zu kompensieren. Auch der mit der komplexen Handverletzung einhergehende komplette bzw. teilweise Verlust des Tastvermögens des „Sinnesorganes Hand“ ist mit den bestmöglichen medizinischen und rehabilitativen Maßnahmen so weit wie möglich wieder herzustellen. Dies stellt sowohl die Verletzten als auch die Behandler und die mit der Koordinierung der Reha-Maßnahmen betrauten Reha-Manager vor eine große Herausforderung. Es ist eminent wichtig, dabei ein ausgewogenes Maß an Zuversicht im Hinblick auf die weitgehende Wiederherstellung körperlicher Funktionen als auch die Sinnesfähigkeiten der Hand zu gewährleisten. Gleichzeitig muss die Erforderlichkeit von Leistungen zur Teilhabe realistisch beurteilt und im Hinblick auf Grenzen der Rehabilitation den Versicherten ebenso vermittelt werden. Die Motivation der Versicherten heißt es dabei gleichermaßen zu bewahren, wie die notwendigen Zielsetzungen der Rehabilitation vor dem Hintergrund realistischer Möglichkeiten moderner Wiederherstellungs- und Rehabilitationsmedizin zu gewährleisten. Die aktivierende Begleitung der Verletzten stellt somit eine große Herausforderung, aber auch eine große Befriedigung in der Wahrnehmung ihrer Aufgabenstellungen als Reha-Manager dar. Der Beitrag befasst sich mit den Grundlagen, Möglichkeiten und Grenzen des Reha-Managements am Beispiel komplexer Handverletzungen. Dies wird durch ein Fallbeispiel anschaulich dargestellt."
journal_title,Trauma und Berufskrankheit
article_title,Fehlverheilte Frakturen am Unterschenkel und SprunggelenkMalunion of fractures of the lower leg and ankle
keyword,"['Tibia\xa0', 'Heilungsstörung\xa0', 'Deformität\xa0', 'Therapie\xa0', 'Weichteilschaden \xa0', 'Tibia\xa0', 'Nonunion\xa0', 'Deformity\xa0', 'Therapy\xa0', 'Soft tissue damage\xa0']"
history,"['2017-08', '2017-07-26']"
abstract,"ZusammenfassungFehlverheilte Frakturen oder Heilungsstörungen an Unterschenkel und Sprunggelenk bei Kindern sind eine seltene Entität, die einer stringenten Behandlung in der Hand von Spezialisten bedarf. Sowohl bei konservativer als auch bei operativer Therapie können Heilungsstörungen auftreten. Insofern ist es notwendig, bei einer Fehlstellung die engen altersbezogenen Toleranzgrenzen zu beachten, um funktionshemmende Deformitäten als Komplikation zu vermeiden. Der begleitende Weichteilschaden kann einen konservativen Therapieansatz limitieren, v. a. wenn offene Weichteilschäden vorgefunden werden. Die Therapie der Fehlheilungen ist individuell. Daneben gilt es auch, drohende Fehlheilungen zu verhindern, die v. a. im Adoleszentenalter bei groß gewachsenen und übergewichtigen Jugendlichen auftreten können."
journal_title,Trauma und Berufskrankheit
article_title,Korrektureingriffe der Hand nach thermischer VerletzungHand reconstruction surgery after thermal injury
keyword,"['Verbrennung\xa0', 'Rekonstruktive chirurgische Verfahren\xa0', 'Plastische Chirurgie\xa0', 'Handchirurgie\xa0', 'Schwerbrandverletzte\xa0', 'Burns\xa0', 'Reconstructive surgical procedures\xa0', 'Plastic surgery\xa0', 'Hand surgery\xa0', 'Severe burn injuries\xa0']"
history,"['2017-08', '2017-02-07']"
abstract,ZusammenfassungVerbrennungen im Handbereich zählen zu den häufigsten Verbrennungsverletzungen. Etwa 90 % der Schwerbrandverletzten weisen eine Beteiligung in diesem Bereich auf. Rekonstruktionen erfolgen meist sekundär nach Beherrschen der lebensbedrohlichen Verbrennungsverletzungen und Stabilisierung des Vitalzustandes. Sie erfordern umfassende Kenntnisse der plastischen wie auch der Handchirurgie. Ziel der aufwendigen und oft nur begrenzt erfolgreichen Bemühungen ist eine optimale Wiederherstellung der Funktion als Voraussetzung der Wiedererlangung der Arbeitsfähigkeit.
journal_title,Trauma und Berufskrankheit
article_title,Stellenwert der Endoprothetik nach AcetabulumfrakturImportance of endoprosthetics for acetabular fractures
keyword,"['Osteosynthese\xa0', 'Reposition\xa0', 'Fixation\xa0', 'Gelenkersatz\xa0', 'Operation\xa0', 'Osteosynthesis\xa0', 'Reposition\xa0', 'Fixation\xa0', 'Joint replacement\xa0', 'Surgical procedures, operative\xa0']"
history,"['2017-08', '2017-02-20']"
abstract,"ZusammenfassungAcetabulumfrakturen sind Gelenkfrakturen und sollten durch offene, anatomische Reposition und innere Fixation behandelt werden. Bei hochqualitativer Chirurgie kann die Notwendigkeit eines Gelenkersatzes bei bis zu 80 % der Patienten vermieden werden. Bei betagten Patienten in gutem Allgemeinzustand und mit gut erhaltener Knochenqualität sind die offene Reposition und innere Fixation ebenfalls erstrebenswert. Die Notwendigkeit eines endoprothetischen Ersatzes kann in 70 % verhindert werden. Die konservative Behandlung von Acetabulumfrakturen beim alten Menschen ist mit vielen Komplikationen verbunden und endet mit schlechten funktionellen Ergebnissen. Bei osteoporotischen Frakturen, bei Zertrümmerung oder subchondraler Impaktion bietet der primäre Gelenkersatz eine sinnvolle Alternative. Herausforderung ist die feste Verankerung der künstlichen Pfanne im gebrochenen Acetabulum. Hierfür ist manchmal eine zusätzliche Osteosynthese des Acetabulums notwendig. Da der vordere Pfeiler in der Regel betroffen ist, sind der ilioinguinale oder der modifizierte Stoppa-Zugang für die Osteosynthese geeignet. Die Osteosynthese und der endoprothetische Ersatz können in einer Narkose oder geplant nacheinander durchgeführt werden. Abhängig von der Knochenqualität, von der Qualität der Reposition und Festigkeit der Osteosynthese wird eine nicht zementierte Pfanne oder eine zementierte Pfanne in einem Verstärkungsring eingebracht. Bei periprothetischen Acetabulumfrakturen ist es notwendig, die Acetabulumfraktur zu reponieren und zu fixieren bevor die gelockerte Pfanne gewechselt wird. Ein separater Zugang ist für die Osteosynthese in der Regel notwendig. Da die Pfanne die Reposition der Fraktur verhindern kann, müssen die beiden Operationsschritte in einem Eingriff durchgeführt werden."
journal_title,Trauma und Berufskrankheit
article_title,Behandlung von karpalen und metakarpalen PseudarthrosenTreatment of carpal and metacarpal non-union
keyword,"['Skaphoidpseudarthrose\xa0', 'Osteosynthese\xa0', 'Schmerzen\xa0', 'Bildgebung\xa0', 'Funktionseinschränkung \xa0', 'Scaphoid non-union\xa0', 'Osteosynthesis\xa0', 'Pain\xa0', 'Imaging\xa0', 'Functional impairment\xa0']"
history,"['2017-08', '2017-07-26']"
abstract,"ZusammenfassungPseudarthrosen am Karpus und Metakarpus der Hand können zu einer deutlichen Funktionseinschränkung mit persistierenden Schmerzen und fortschreitender Arthrose führen. Die Pseudarthrose des Skaphoids ist die häufigste Pseudarthroseform am Karpus. Metakarpale Pseudarthrosen haben, abhängig von den Risikofaktoren, eine Inzidenz von 0–15 %. Zur Diagnostik und Therapieplanung ist insbesondere bei der Skaphoidpseudarthrose eine differenzierte Bildgebung mit Röntgen und Computertomographie zu fordern. Als Therapie erfolgen meist eine Ausräumung der Pseudarthrose, die Auffüllung mittels nicht vaskularisierter Spongiosa oder vaskularisierten Knochenspänen sowie eine stabile Osteosynthese."
journal_title,Trauma und Berufskrankheit
article_title,Evolution der OsteosyntheseEvolution of osteosynthesis
keyword,"['Stabilität\xa0', 'Blutversorgung\xa0', 'Fragmente\xa0', 'Knochenbruch\xa0', 'Reposition \xa0', 'Stability\xa0', 'Blood supply\xa0', 'Fragments\xa0', 'Bone fractures\xa0', 'Reduction\xa0']"
history,"['2017-08', '2017-03-03']"
abstract,"ZusammenfassungDie operative Knochenbruchbehandlung fand mit 4 Grundsätzen weltweite Verbreitung: anatomische Reposition, stabile Fixierung, Erhaltung der Blutversorgung und frühe aktive und schmerzfreie Mobilisation. Die zentrale Bedeutung der Erhaltung der Blutversorgung wurde von Anfang an erkannt und ist genauso wie die frühe aktive und schmerzfreie Mobilisation uneingeschränkt gültig. Gleichermaßen unverändert gültig ist das Streben nach möglichst anatomischer Reposition im Gelenkbereich, im Schaftbereich hat sich dagegen gezeigt, dass die anatomische Reposition insbesondere von Mehrfragmentfrakturen nicht ohne erhebliche Beeinträchtigung der Blutversorgung möglich ist. Bei Mehrfragmentfrakturen ist die korrekte Stellung des proximalen zum distalen Hauptfragment entscheidend, Knochenkeile und Trümmerzonen werden überbrückt. Das Ziel absoluter Stabilität, wie sie früher generell angestrebt wurde, gilt heute nur noch im Gelenkbereich. Schaftfrakturen werden heute mit Osteosynthesen mit relativer Stabilität versorgt, da diese über Kallus heilen. Die Fehlschläge bei Schaftfrakturen konnten durch den Wandel vom Ziel der absoluten zur relativen Stabilität und die Schonung der Blutversorgung der Fragmente deutlich vermindert werden."
journal_title,Trauma und Berufskrankheit
article_title,Hüftendoprothetik nach TraumaHip arthroplasty after trauma
keyword,"['Schenkelhalsfraktur\xa0', 'Proximale Femurfraktur\xa0', 'Alterstraumatologie\xa0', 'Geriatrische Fraktur\xa0', 'Gelenkersatz\xa0', 'Femoral neck fracture\xa0', 'Hip fracture\xa0', 'Geriatric trauma\xa0', 'Geriatric fracture\xa0', 'Joint replacement\xa0']"
history,"['2017-08', '2017-03-06']"
abstract,"ZusammenfassungHintergrundSchenkelhalsfrakturen sind typische Frakturen des älteren Menschen, deren Häufigkeit aufgrund des zunehmenden Anteils älterer Menschen an der Bevölkerung in Zukunft weiter steigen wird. Sowohl bei der operativen Behandlung als auch beim perioperativen Management sind aufgrund des größtenteils geriatrischen Patientenguts einige Besonderheiten zu beachten.Ziel der ArbeitIm vorliegenden Beitrag sollen die verschiedenen operativen Therapieoptionen sowie die Besonderheiten in der perioperativen Betreuung von Patienten mit Schenkelhalsfraktur dargestellt werden.Material und MethodenAnhand einer selektiven Literaturrecherche werden die aktuell im klinischen Alltag etablierten Vorgehensweisen dargestellt und diskutiert.Ergebnisse und DiskussionDie operative Therapie bei Schenkelhalsfraktur sollte so schnell wie möglich (innerhalb von 24 h nach dem Unfall) erfolgen. Bei dislozierten Frakturen (Garden III und IV) geriatrischer Patienten wird die Implantation einer zementierten Prothese empfohlen. Bei jüngeren und noch aktiven Patienten wird aufgrund der besseren funktionellen Ergebnisse die Totalendoprothese bevorzugt, während bei älteren, multimorbiden Patienten mit bereits vor der Fraktur eingeschränkter Mobilität in den meisten Fällen eine zementierte Duokopfprothese implantiert wird. Eine geriatrische Mitbetreuung während des stationären Aufenthalts und eine anschließende geriatrische Reha-Maßnahme verbessern das Outcome der Patienten."
journal_title,Trauma und Berufskrankheit
article_title,Intraoperative 3‑D-Röntgenkontrolle bei Verletzungen des Fußes und des SprunggelenksIntraoperative 3D imaging control of injuries to the foot and ankle
keyword,"['Intraoperative Bildgebung\xa0', 'Gelenkverletzung\xa0', 'Fußchirurgie\xa0', 'Reposition\xa0', 'Revision\xa0', 'Intraoperative imaging\xa0', 'Joint injury\xa0', 'Foot surgery\xa0', 'Reduction\xa0', 'Revision\xa0']"
history,"['2017-08', '2017-07-13']"
abstract,"ZusammenfassungSeit über 15 Jahren steht die intraoperative 3‑D-Bildgebung bei der Versorgung komplexer Gelenkverletzungen zur Verfügung. Sie ermöglicht die Darstellung anatomischer Strukturen in komplexen Regionen ebenso wie die dreidimensionale Abbildung knöcherner Strukturen in Fuß und Sprunggelenk. Mit diesem Verfahren lassen sich Repositionsergebnis, Implantatlage sowie Stellung der Syndesmose beurteilen. Unter Einbezug sämtlicher anatomischer Regionen werden in unserer Klinik nach der Kontrolle im 3‑D-Scan in ca. einem Fünftel der Fälle intraoperative Revisionen durchgeführt. Den größten Anteil nehmen dabei Fersenbein, Sprunggelenk und Pilon tibiale ein. Diese Verhältnisse decken sich mit anderen Angaben in der Literatur. Die intraoperative 3‑D-Bildgebung hat sich somit in vielen Kliniken bei bestimmten Indikationen als Routineverfahren etabliert."
journal_title,Trauma und Berufskrankheit
article_title,Frakturen der thorakalen und lumbalen WirbelsäuleFractures of the thoracic and lumbar spine
keyword,[]
history,"['2017-06', '2017-05-10']"
abstract,None
journal_title,Trauma und Berufskrankheit
article_title,Diagnostik zur Klassifikation und Therapiefindung bei thorakolumbalen WirbelsäulenverletzungenDiagnostics for the classification and treatment of thoracolumbar spine injuries
keyword,"['Thorakolumbale Fraktur\xa0', 'Radiologie\xa0', 'Computertomographie\xa0', 'Magnetresonanztomographie\xa0', 'Stabilität\xa0', 'Thoracolumbar fracture\xa0', 'Radiography\xa0', 'Computed tomography\xa0', 'Magnetic resonance imaging\xa0', 'Stability\xa0']"
history,"['2017-06', '2017-05-29']"
abstract,"ZusammenfassungDie Diagnostik thorakolumbaler Frakturen ermöglicht eine korrekte Klassifikation und realistische Einschätzung der Stabilität der Verletzung. Zusammen mit den klinischen Befunden kann so eine sinnvolle therapeutische Entscheidung getroffen werden. Neben einer ausführlichen klinischen Untersuchung stellen Röntgen und vor allem die Computertomographie die Grundpfeiler der Diagnostik dar. Die Magnetresonanztomographie dient der Beantwortung besonderer Fragestellungen, allen voran der Beurteilung der dorsalen ligamentären Strukturen."
journal_title,Trauma und Berufskrankheit
article_title,Arbeitsplatzbezogene muskuloskeletale Rehabilitation im ambulanten SettingWorkplace-oriented musculoskeletal rehabilitation in outpatient setting
keyword,"['Orthopädie\xa0', 'Scoring\xa0', 'Assessments\xa0', 'Leistungsfähigkeit\xa0', 'Wiedereingliederung \xa0', 'Orthopedics\xa0', 'Scoring\xa0', 'Assessment\xa0', 'Performance capability\xa0', 'Reintegration\xa0']"
history,"['2017-06', '2017-04-06']"
abstract,"ZusammenfassungDie ambulante orthopädische Rehabilitation hat sich in Deutschland seit der Jahrtausendwende rasant entwickelt sowohl hinsichtlich der Anzahl der Einrichtungen und behandelter Patienten als auch bezüglich der Qualität der abgegebenen Therapie. Im gleichen Zeitraum zeigte sich in der muskuloskeletalen Rehabilitation ein neuer und zunehmend bedeutender Behandlungsschwerpunkt im Bereich der arbeitsplatzspezifischen Therapie. Vonseiten der Deutschen Gesetzlichen Unfallversicherung (DGUV) wurde deshalb die arbeitsplatzbezogene muskuloskeletale Rehabilitation etabliert. Die vorliegende Studie dokumentiert anhand von 38 Fällen im Beobachtungszeitraum 2014 bis 2016 deskriptiv deutliche Verbesserungen im Rehabilitationsverlauf für die verwendeten Assessments Funktionsfragebogen-Hannover-Rücken, DASH (Disability of Arm, Hand and Shoulder)- und WOMAC (Western Ontario and McMaster Universities Osteoarthritis Index)-Score. Das Ziel der Wiederherstellung der Leistungsfähigkeit für die Wiederaufnahme der Arbeitstätigkeit oder für die Durchführung einer stufenweisen Wiedereingliederung wurde in der weit überwiegenden Anzahl der Fälle erreicht. Somit erbringt die Studie einen Beitrag zum Wirksamkeitsnachweis der arbeitsplatzorientierten muskuloskeletalen Rehabilitation in einem ambulanten orthopädischen Rehabilitationszentrum."
journal_title,Trauma und Berufskrankheit
article_title,Distale RadiusfrakturDistal radius fractures
keyword,"['Osteosynthese\xa0', 'Extensionsfraktur\xa0', 'Flexionsfraktur\xa0', 'Komorbidität\xa0', 'Medline\xa0', 'Osteosynthesis\xa0', 'Smith fracture\xa0', 'Colles’ fracture\xa0', 'Comorbidity\xa0', 'Medline\xa0']"
history,"['2017-06', '2017-05-17']"
abstract,"ZusammenfassungHintergrundDie distale Radiusfraktur ist die häufigste Fraktur beim Menschen. Trotz kontinuierlichen Neuerungen und des Wandels der operativen Therapie sind die aktuellen Behandlungskonzepte uneinheitlich. Eindeutige Empfehlungen zur Indikation der operativen Therapie können aufgrund fehlender Evidenz nicht gegeben werden.Ziel der ArbeitZiel des vorliegenden Artikels ist es, eine Zusammenfassung der vorliegenden Evidenz zu geben und hieran einen klinischen Leitfaden für die Versorgung distaler Radiusfrakturen zu erarbeiten.Material und MethodenSelektive Literaturrecherche in der Medline-Datenbank und klinische Erfahrung der Autoren.SchlussfolgerungUnter Berücksichtigung von Alter und Komorbiditäten des Patienten sowie der Frakturmorphologie kann eine operative oder konservative Therapie indiziert sein. So lassen sich zufriedenstellende Ergebnisse auch bei instabilen Frakturen erzielen."
journal_title,Trauma und Berufskrankheit
article_title,Thorakale und lumbale WirbelsäuleThoracic and lumbar spine
keyword,"['Operativer Zugang\xa0', 'Wirbelsäulenverletzung\xa0', 'Instabilität\xa0', 'Komplikationen\xa0', 'Wirbelkörperersatz\xa0', 'Surgical approach\xa0', 'Spinal injury\xa0', 'Instability\xa0', 'Complications\xa0', 'Vertebral body reconstruction\xa0']"
history,"['2017-06', '2017-05-09']"
abstract,"ZusammenfassungTrotz jahrzehntelanger Erfahrung und einer Fülle an Studien herrscht bis heute keine Einigkeit bezüglich der optimalen Versorgung und des Zugangsweges bei Instabilitäten der Brust und Lendenwirbelsäule. Neben der dorsalen Zuggurtung ist die ventrale Abstützung ein Grundpfeiler der Versorgung in diesem Bereich. Die kombinierte Stabilisierung von ventral und dorsal bietet neben einer exzellenten Übersicht das stabilste biomechanische Konstrukt. Bei einer Versorgung über zwei separate Zugänge werden die Morbidität des Patienten und die möglichen Komplikationen jedoch addiert. Eine ventrale Versorgung über einen dorsalen Zugangsweg scheint daher hinsichtlich der Komplikationen, des Blutverlusts und der Operationsdauer von Vorteil zu sein. Über einen modifizierten Posterior-lumbar-interbody-fusion(PLIF)-/Transforaminal-lumbar-interbody-fusion(TLIF)-Zugang können auf diese Weise ventrale Defekte aufgefüllt werden. Insbesondere im Bereich der Lendenwirbelsäule ist dies jedoch durch die abgehenden Nervenwurzeln anatomisch beschränkt. Häufig sind nur eine Teilkorporektomie und die Auffüllung des verletzten Bandscheibenraumes erforderlich. Durch aufspreizbare Cages gelingt jedoch auch der Ersatz ganzer Wirbelkörper. Patientenfaktoren und der Operateur beeinflussen weiterhin die gewählte Operationstechnik."
journal_title,Trauma und Berufskrankheit
article_title,Wirbelkörperfrakturen und Osteopenie: Augmentieren oder langstreckig?Vertebral body fractures and osteopenia: augmentation or lengthening?
keyword,"['Osteoporose\xa0', 'Zementaugmentation\xa0', 'Ermüdungstest\xa0', 'Dauerbelastung\xa0', 'Pedikelschraube\xa0', 'Osteoporosis\xa0', 'Cement augmentation\xa0', 'Fatigue test\xa0', 'Continuous load\xa0', 'Pedicle screws\xa0']"
history,"['2017-06', '2017-05-15']"
abstract,"ZusammenfassungHintergrundFrakturen im Bereich der Wirbelsäule zählen zu den häufigsten klinischen Manifestationen der Osteoporose. Beim Vorliegen instabiler oder sekundär kyphosierter Frakturen ist die dorsale Instrumentation oft die Therapie der Wahl. Eine Lockerung der eingebrachten Pedikelschrauben ist die häufigste Versagensursache dieser Instrumentationen. Sowohl die Zementaugmentation als auch die Verlängerung der Instrumentationsstrecke stehen als Optionen zur Verfügung, um die Stabilität der dorsalen Instrumentation zu verbessern.Material und MethodenIn einer biomechanischen Untersuchung haben wir anhand von 12 humanen Wirbelsäulen (Th11–L3) eine kurzstreckige sowie langstreckige Versorgung jeweils mit konventionellen und zementaugmentierten Pedikelschrauben miteinander verglichen. Es erfolgte ein biomechanischer Ermüdungstest mit einer sinusförmigen, kraniokaudalen Dauerbelastung und zyklischer Laststeigerung.SchlussfolgerungDie Zementaugmentation von Pedikelschrauben hat keinen so deutlichen Effekt auf die Stabilität von Pedikelschrauben, wie aus biomechanischen Pull-out-Tests vermutet. Eine Verlängerung der Instrumentationsstrecke führt, verglichen mit der Zementaugmentation, zu einem deutlich höheren Stabilitätszuwachs im biomechanischen Belastungstest an der osteoporotischen Wirbelsäule."
journal_title,Multidimensional Systems and Signal Processing
article_title,An integer wavelet transform based scheme for reversible data hiding in encrypted images
keyword,"['Integer wavelet transform\xa0', 'Reversible data hiding\xa0', 'Encrypted images\xa0', 'Histogram shifting\xa0']"
history,"['2018-07', '2017-05-12', '2015-12-28', '2017-03-22', '2017-05-04']"
abstract,"Abstract In this paper, a novel reversible data hiding (RDH) scheme for encrypted digital images using integer wavelet transform, histogram shifting and orthogonal decomposition is presented. This scheme takes advantage of the Laplacian-like distribution of integer wavelet high-frequency coefficients in high frequency sub-bands and the independence of orthogonal coefficients to facilitate data hiding operation in encrypted domain, and to keep the reversibility. Experimental results has demonstrated that this scheme outperforms all of other existing RDH schemes in encrypted domain in terms of higher PSNR at the same amount of payload. Compared with the state-of-the-arts, the proposed scheme can be applied to all natural images with higher embedding rate."
journal_title,Multidimensional Systems and Signal Processing
article_title,A hybrid learning-based framework for blind image quality assessment
keyword,"['Blind video image quality\xa0', 'Convolutional neural network\xa0', 'Support vector regression\xa0', 'Feature extraction\xa0']"
history,"['2018-07', '2017-02-20', '2016-07-01', '2017-02-07', '2017-02-09']"
abstract,"Abstract Blind image quality assessment aims to evaluate the quality of a given image without the availability of the original ground truth image and without the prior knowledge of the types of distortions present. Instead of using hand-crafted features to address specific type of image distortions, a hybrid learning-based blind image quality assessment approach is proposed in this paper to address more challenging mixed types of image distortions. The proposed approach integrates the convolution neural network (CNN) as a feature extractor, plus the support vector regression method to learn a mapping function from the CNN-trained features to the quality score of the input image. Extensive experiments are conducted using both standard image dataset and real-world surveillance video dataset to demonstrate the superior performance of the proposed approach."
journal_title,Multidimensional Systems and Signal Processing
article_title,An improved Bernoulli particle filter for single target tracking
keyword,"['Single target tracking\xa0', 'Bernoulli filter\xa0', 'Particle\xa0', 'Track label\xa0', 'Clutter rate\xa0']"
history,"['2018-07', '2017-01-17', '2016-05-19', '2017-01-01', '2017-01-07']"
abstract,"Abstract Single target tracking is widely applied in the current surveillance systems. The Bernoulli filter can complete the task of single target tracking using available measurements. However, the existing Bernoulli filters have estimation bias during the whole tracking process. Therefore, we present an improved Bernoulli filter and its particle implementation in this paper. Employed the weight optimization strategy, the under-estimated number of target is corrected by enlarging the maximal measurement-updated weight of sampling particle. In addition, the track identification strategy is applied to optimize number of the required particles and extract the actual target. Combined with the unscented transform for the complicated dynamic models, the nonlinear motion state of maneuvering target is effectively estimated. Besides, we extend the proposed filter in unknown clutter environment and estimate the mean clutter rate, which has significant application meaning owing to avoiding the assumption of the given detection profile. Finally, the numerical simulations demonstrate the tracking advantages with the promising results in comparison to the standard Bernoulli filter."
journal_title,Multidimensional Systems and Signal Processing
article_title,Range-angle pencil-beamforming for non-uniformly distributed array radar
keyword,"['Non-uniformly distributed array radar\xa0', 'Frequency diverse array\xa0', 'Range-angle pencil-beamforming\xa0', 'Particle swarm optimization\xa0']"
history,"['2018-07', '2017-02-21', '2016-09-19', '2016-12-06', '2017-02-13']"
abstract,"Abstract Digital beamforming with non-uniformly distributed array radar can make full use of resources and enhance the target detection capability. However, it encounters severe grating lobes and high false alarm probability. In this paper, a novel range-angle pencil-beamforming with the non-uniformly distributed frequency diverse array (FDA) is proposed. FDA is referred to as an array transmitting linearly increased carrier frequencies with the array elements. The FDA is capable of providing controllable degrees-of-freedom in range domain, which is superior to the conventional phased array. In our approach, the frequency increments and element positions are optimally determined via particle swarm optimization algorithm to focus the transmit power within a particular range and angle region. With the proposed method, the range-angle pencil-beampattern is obtained and its side-lobes in range-angle domains can be further lowered down. Numerical simulation examples are provided to verify the effectiveness of the proposed approach."
journal_title,Multidimensional Systems and Signal Processing
article_title,Deep learning of chroma representation for cover song identification in compression domain
keyword,"['Cover song\xa0', 'Music retrieval\xa0', 'Sparse autoencoder\xa0', 'Descriptor\xa0', 'Advanced audio coding\xa0']"
history,"['2018-07', '2017-02-21', '2016-02-26', '2016-10-25', '2017-02-10']"
abstract,"Abstract Methods  for identifying a cover song typically involve comparing the similarity of chroma features between the query song and another song in the data set. However, considerable time is required for pairwise comparisons. In addition, to save disk space, most songs stored in the data set are in a compressed format. Therefore, to eliminate some decoding procedures, this study extracted music information directly from the modified discrete cosine transform coefficients of advanced audio coding and then mapped these coefficients to 12-dimensional chroma features. The chroma features were segmented to preserve the melodies. Each chroma feature segment was trained and learned by a sparse autoencoder, a deep learning architecture of artificial neural networks. The deep learning procedure was to transform chroma features into an intermediate representation for dimension reduction. Experimental results from a covers80 data set showed that the mean reciprocal rank increased to 0.5 and the matching time was reduced by over 94% compared with traditional approaches."
journal_title,Multidimensional Systems and Signal Processing
article_title,A novel passive forgery detection algorithm for video region duplication
keyword,"['Video forgery\xa0', 'Region duplication\xa0', 'Mirror invariant\xa0', 'Passive forensics\xa0']"
history,"['2018-07', '2017-05-09', '2015-11-10', '2017-01-17', '2017-05-02']"
abstract,"Abstract Forgery involving region duplication is one of the most common types of video tampering. However, few algorithms have been suggested for detecting this type of forgery effectively, especially for videos to which a mirroring operation was applied. In this paper, we summarize the properties of duplication forgery of video regions and propose a novel algorithm to detect this forgery. First, the algorithm extracts the feature points in the current frame. The tampered areas in the current frame are then searched, which is implemented in three steps. Finally, our algorithm detects the tampered areas in the remaining frames using spatio-temporal context learning and outputs the detection results. The experimental results demonstrate the satisfactory performance of our algorithm for detecting videos subjected to mirror operations and its higher efficiency than previous algorithms."
journal_title,Multidimensional Systems and Signal Processing
article_title,Semi-supervised superpixel classification for medical images segmentation: application to detection of glaucoma disease
keyword,"['Superpixel segmentation\xa0', 'Semi-supervised\xa0', 'Co-forest\xa0', 'Glaucoma\xa0', 'Fundus images\xa0']"
history,"['2018-07', '2017-03-14', '2016-04-29', '2017-02-27', '2017-03-07']"
abstract,"Abstract Glaucoma is a disease characterized by damaging the optic nerve head, this can result in severe vision loss. An early detection and a good treatment provided by the ophthalmologist are the keys to preventing optic nerve damage and vision loss from glaucoma. Its screening is based on the manual optic cup and disc segmentation to measure the vertical cup to disc ratio (CDR). However, obtaining the regions of interest by the expert ophthalmologist can be difficult and is often a tedious task. In most cases, the unlabeled images are more numerous than the labeled ones.We propose an automatic glaucoma screening approach named Super Pixels for Semi-Supervised Segmentation “SP3S”, which is a semi-supervised superpixel-by-superpixel classification method, consisting of three main steps. The first step has to prepare the labeled and unlabeled data, applying the superpixel method and bringing in an expert for the labeling of superpixels. In the second step, We incorporate prior knowledge of the optic cup and disc by including color and spatial information. In the final step, semi-supervised learning by the Co-forest classifier is trained only with a few number of labeled superpixels and a large number of unlabeled superpixels to generate a robust classifier. For the estimation of the optic cup and disc regions, the active geometric shape model is used to smooth the disc and cup boundary for the calculation of the CDR. The obtained results for glaucoma detection, via an automatic cup and disc segmentation, established a potential solution for glaucoma screening. The SP3S performance shows quantitatively and qualitatively similar correspondence with the expert segmentation, providing an interesting tool for semi-automatic recognition of the optic cup and disc in order to achieve a medical progress of glaucoma disease."
journal_title,Multidimensional Systems and Signal Processing
article_title,Utilizing neighborhood coefficient correlation: a new image watermarking technique robust to singular and hybrid attacks
keyword,"['Blind watermarking\xa0', 'Compression\xa0', 'Robustness\xa0', 'Neighborhood\xa0', 'Extraction\xa0']"
history,"['2018-07', '2017-03-31', '2016-01-06', '2017-02-16', '2017-03-24']"
abstract,"Abstract A new blind digital image watermarking algorithm with watermark embedded in discrete cosine transform (DCT) coefficients is presented in this paper. The proposed scheme exploits correlation between DCT coefficients in neighborhood blocks for embedding. The watermark is embedded by modifying two DCT coefficients, one pertaining to a block in which watermark bit (0 or 1) is to be embedded and the other corresponding to the selected neighborhood block. Both the selected coefficients are modified by a modification factor so that the difference between the pair of coefficients is brought to a predefined zone. This difference between two DCT coefficients is used to extract watermark. The proposed technique has been tested for different attacks like JPEG compression, rotation, cropping, filtering, gaussian noise, salt and pepper noise, histogram equalization etc. It has been observed that the scheme is highly robust not only for the above mentioned attacks used singularly, but also for different possible combinations of simultaneous attacks. A comparison of the proposed technique with some state of art existing algorithms reveals that our scheme provides better results in terms of quality of watermarked images, payload and robustness."
journal_title,Multidimensional Systems and Signal Processing
article_title,Fundamental tensor operations for large-scale data analysis using tensor network formats
keyword,"['Tensor networks\xa0', 'Tensor train\xa0', 'Matrix product state\xa0', 'Matrix product operator\xa0', 'Generalized Tucker model\xa0', 'Strong Kronecker product\xa0', 'Contracted product\xa0', 'Multilinear operator\xa0', 'Tensor calculus\xa0', 'Big data\xa0', '15A63\xa0', '15A69\xa0', '65F25\xa0']"
history,"['2018-07', '2017-03-09', '2016-02-19', '2016-09-06', '2017-02-27']"
abstract,"Abstract We discuss extended definitions of linear and multilinear operations such as Kronecker, Hadamard, and contracted products, and establish links between them for tensor calculus. Then we introduce effective low-rank tensor approximation techniques including Candecomp/Parafac, Tucker, and tensor train (TT) decompositions with a number of mathematical and graphical representations. We also provide a brief review of mathematical properties of the TT decomposition as a low-rank approximation technique. With the aim of breaking the curse-of-dimensionality in large-scale numerical analysis, we describe basic operations on large-scale vectors, matrices, and high-order tensors represented by TT decomposition. The proposed representations can be used for describing numerical methods based on TT decomposition for solving large-scale optimization problems such as systems of linear equations and symmetric eigenvalue problems."
journal_title,Multidimensional Systems and Signal Processing
article_title,A new algorithm of blind color image watermarking based on LU decomposition
keyword,"['Color image watermark\xa0', 'Blind watermarking\xa0', 'LU decomposition\xa0', 'Lower triangular matrix\xa0']"
history,"['2018-07', '2017-03-24', '2015-10-08', '2016-05-20', '2017-03-20']"
abstract,"Abstract This paper proposes a new algorithm of blind color image watermarking based on LU decomposition. Because of the first column the second row element and the first column the third row element of the lower triangular matrix, which obtained by LU decomposition, have higher similarity, and the color image watermark can be embedded into these elements by slightly modifying rules, which can enhance the watermark invisibility. In addition, Arnold transform is applied to improve the watermark security and the Hash pseudo-random number algorithm based on MD5 is used to improve the watermark robustness. In extraction process, the watermark embedding strength and private key are needed to extract watermark information from the attacked host image with blind manner. Experiment results reveal that the proposed method outperforms other related methods in the aspects of the invisibility, robustness, embedding payload and computational complexity."
journal_title,Multidimensional Systems and Signal Processing
article_title,Statistical model and local binary pattern based texture feature extraction in dual-tree complex wavelet transform domain
keyword,"['Texture feature extraction\xa0', 'Dual-tree complex wavelet transform\xa0', 'Generalized Gamma density\xa0', 'Local binary pattern\xa0']"
history,"['2018-07', '2017-02-20', '2016-07-04', '2016-10-17', '2017-02-09']"
abstract,"Abstract This paper presents a new feature extraction method in dual-tree complex wavelet transform domain. Given an input image, we obtain all highpass directional subimages and a set of pyramid lowpass subimages with different resolutions by applying DTCWT decomposition. After that, generalized Gamma density \((\hbox {G}\Gamma \hbox {D})\) models and local binary pattern are utilized respectively to characterize features of both highpass and lowpass subimages. The two kinds of features are combined for texture classification, and the experimental results on datasets Brodatz, Outex and UMD demonstrate that our proposed method can achieve superior classification accuracy than other state-of-the-art methods."
journal_title,Multidimensional Systems and Signal Processing
article_title,Performance evaluation of particle filter resampling techniques for improved estimation of misalignment and trajectory deviation
keyword,"['Kalman filter\xa0', 'Evolutionary particle filter\xa0', 'Transfer alignment\xa0', 'Velocity matching\xa0', 'Systematic resampling\xa0', 'Parallel processing\xa0']"
history,"['2018-07', '2017-02-07', '2016-07-05', '2016-11-23', '2017-01-19']"
abstract,"Abstract Delivery of airborne precision guided vehicles to pre-designated targets has assumed much importance in recent times. Transfer alignment is concerned with estimation of misalignment with respect to the airborne platform. During first few seconds of the post ejection phase, the trajectory deviates from intended one. Estimation of this deviation in trajectory can also be mapped to the transfer alignment problem. Large misalignment angle makes the system nonlinear while usage of mother measurements in each iteration makes it time varying. Particle filter variants can be designed to improve the quality of estimates but the time complexity increases. This work explores different resampling techniques to find a way to decrease the average time to complete an iteration. This allows more room for parallel execution with a residual evolutionary particle filter that does away with resampling by evolving through several system dynamics, thereby performing better when the knowledge of system dynamics is poor. It is observed that when the two filters are run together, the estimation accuracy improves considerably. The scheme is particularly useful in the time critical post ejection phase."
journal_title,Multidimensional Systems and Signal Processing
article_title,Accelerated gradient with optimal step size for second-order blind signal separation
keyword,"['Blind signal separation\xa0', 'Second order\xa0', 'Optimal step size\xa0']"
history,"['2018-07', '2017-02-24', '2016-09-15', '2017-01-15', '2017-02-15']"
abstract,"Abstract This paper proposes an algorithm for the second-order blind signal separation problem with convolutive mixtures. An iterative first order gradient method based on the accelerated gradient is developed for solving the optimization problem. For each search direction, the question becomes how to effectively calculate the optimal step size in each iteration. Here, we propose an efficient algorithm for obtaining the step size by first reformulating the objective function as a fourth order polynomial in terms of the step size, where the polynomial coefficients are required to be calculated only once per iteration. An optimal step size search procedure using the Newton’s method is developed with the step size is efficiently obtained for each iteration. Simulation results in a simulated room environment and a real environment show that the proposed algorithm converges faster than the existing methods with a lower number of iterations and a lower computational complexity. In addition, the proposed algorithm can separate the speech signals and reduce the background noise simultaneously."
journal_title,Multidimensional Systems and Signal Processing
article_title,A locally convergent Jacobi iteration for the tensor singular value problem
keyword,"['Tensor decompositions\xa0', 'Jacobi iteration\xa0', 'Singular value decompositions\xa0']"
history,"['2018-07', '2017-03-29', '2016-09-13', '2017-03-01', '2017-03-16']"
abstract,"Abstract Multi-linear functionals or tensors are useful in study and analysis multi-dimensional signal and system. Tensor approximation, which has various applications in signal processing and system theory, can be achieved by generalizing the notion of singular values and singular vectors of matrices to tensor. In this paper, we showed local convergence of a parallelizable numerical method (based on the Jacobi iteration) for obtaining the singular values and singular vectors of a tensor."
journal_title,Multidimensional Systems and Signal Processing
article_title,Recursive least squares identification methods for multivariate pseudo-linear systems using the data filtering
keyword,"['Parameter estimation\xa0', 'Least squares\xa0', 'Data filtering\xa0', 'Multivariate system\xa0', 'Nonlinear system\xa0', 'Pseudo-linear system\xa0']"
history,"['2018-07', '2017-04-18', '2017-01-20', '2017-03-20', '2017-03-30']"
abstract,"Abstract This paper concerns the parameter identification methods of multivariate pseudo-linear autoregressive systems. A multivariate recursive generalized least squares algorithm is presented as a comparison. By using the data filtering technique, a multivariate pseudo-linear autoregressive system is transformed into a filtered system model and a filtered noise model, and a filtering based multivariate recursive generalized least squares algorithm is developed for estimating the parameters of these two models. The proposed algorithm achieves a higher computational efficiency than the multivariate recursive generalized least squares algorithm, and the simulation results prove that the proposed method is effective."
journal_title,Multidimensional Systems and Signal Processing
article_title,Image restoration method based on fractional variable order differential
keyword,"['Image restoration\xa0', 'Fractional\xa0', 'Variable order differential\xa0', 'Total variation\xa0', 'Combined image similarity index\xa0']"
history,"['2018-07', '2017-03-15', '2015-12-28', '2016-07-25', '2017-03-07']"
abstract,"Abstract In this paper, we study image restoration problem by using fractional variable order differential technique. Our idea is to make use of fractional order differential diffusion equation of evolution procedure into the image restoration problem. An image often exists different low-frequency and high-frequency components, such as flat, texture and edge, etc. Because fractional order differential can enhance the high-frequency components of a signal, meanwhile, nonlinearly preserve the low-frequency components of the signal, we can adapt suitable fractional differential orders to restore their components. In particular, different differential orders can be used in an image at the same time. In order to obtain the restored image automatically, we choose the fractional differential orders by the value of gradient modulus of the image and use the discrete Fourier transform to implement the numerical algorithm. We also provide an iterative scheme in the frequency domain. Experimental results are reported to demonstrate that the visual effects, the combined image similarity index and the peak signal to noise ratio of restored images by using the proposed method are very good, and are competitive with the other testing methods."
journal_title,Multidimensional Systems and Signal Processing
article_title,Frame-groups based fractal video compression and its parallel implementation in Hadoop cloud computing environment
keyword,"['Fractal video compression\xa0', 'Parallel computing\xa0', 'Cloud computing\xa0', 'Hadoop platform\xa0']"
history,"['2018-07', '2017-03-11', '2015-10-31', '2016-08-30', '2017-02-27']"
abstract,"Abstract Fractal video compression is based on the self-similarity search between range cubes and domain cubes, so it can achieve a high compression ratio. However, its computational complexity is relatively high that restricts its studies and applications. Further studies show that the compression process exhibits a high natural parallelism as there exist data independence when computing the compression codes. In this paper, we utilize parallel processing techniques to implement the fractal video compression algorithm to reduce the run time. There are two main works in this article: firstly, a parallel fractal video compression algorithm based on frame-groups is proposed. Secondly, we implemented the parallel algorithm in Hadoop cloud computing environment. The experiment results show the parallel algorithm has a high speedup and the distributed parallel computing systems can utilize network resources sufficiently to implement high-performance computing, and provide a good practicability and a promising future in application."
journal_title,Multidimensional Systems and Signal Processing
article_title,Anomaly detection with a moving camera using spatio-temporal codebooks
keyword,"['Video surveillance\xa0', 'Moving camera\xa0', 'Abandoned object detection\xa0', 'Cluttered environment\xa0', 'Spatiotemporal composition\xa0', 'Bag of video words\xa0']"
history,"['2018-07', '2017-03-23', '2016-08-16', '2017-02-19', '2017-03-16']"
abstract,"Abstract This paper proposes a method to detect anomalies in videos acquired by a camera mounted on a moving inspection robot. The proposed method is based on a spatio-temporal composition (STC) method, where a dense sampling is used to break the video into small 3D volumes that are used to calculate the probability of the spatio-temporal arrangements. This class of methods has been successfully used for surveillance videos obtained by static cameras. However, when applied to videos recorded by cameras on moving platforms, the STC gives a large number of false detections. In this work, we propose improvements to the present STC method that will alleviate this problem in two ways. First, a two-stage dictionary learning process is performed to allow a more reliable anomaly detection. Second, improved spatio-temporal features are employed. These modified features are extracted after an enhanced temporal filtering that performs a temporal regularization of the video sequence. The proposed approach gives very good results in the identification of anomalies without the need of background subtraction, motion estimation or tracking. The results are shown to be comparable or even superior to those of other state-of-the-art methods using bag-of-video words or other moving-camera surveillance methods. The system is accurate even with no prior knowledge of the type of event to be observed, being robust to cluttered environments, as illustrated by several practical examples. These results are obtained without compromising the performance of the algorithm in the static cameras case."
journal_title,Multidimensional Systems and Signal Processing
article_title,A second-order blind source separation method for bilinear mixtures
keyword,"['Blind Source Separation\xa0', 'Second-order Statistics\xa0', 'Bilinear mixing model\xa0']"
history,"['2018-07', '2017-05-06', '2016-09-20', '2017-02-24', '2017-04-21']"
abstract,"Abstract In this paper, we are interested in the problem of Blind Source Separation using a Second-order Statistics (SOS) method in order to separate autocorrelated and mutually independent sources mixed according to a bilinear (BL) model. In this context, we propose a new approach called Bilinear Second-order Blind Source Separation, which is an extension of linear SOS methods, devoted to separate sources present in BL mixtures. These sources, called extended sources, include the actual sources and their products. We first study the statistical properties of the different extended sources, in order to verify the assumption of identifiability when the actual sources are zero-mean and when they are not. Then, we present the different steps performed in order to estimate these actual centred sources and to extract the actual mixing parameters. The obtained results using artificial mixtures of synthetic and real sources confirm the effectiveness of the new proposed approach."
journal_title,Multidimensional Systems and Signal Processing
article_title,Two-dimensional strip spectral correlation algorithm to fast estimation of 2D-cyclic spectral function for texture analysis
keyword,"['2D-CSF\xa0', '2D-SSCA\xa0', 'Texture\xa0', 'MRF\xa0', 'SVM\xa0', 'MLP\xa0']"
history,"['2018-07', '2017-04-18', '2016-06-24', '2017-01-01', '2017-04-11']"
abstract,"Abstract This paper presents a new affective scheme to estimate the two-dimensional cyclic spectral function of a texture as a two-dimensional signal. Recently, considering textures as cyclostationary signals, several algorithms have been introduced to utilize the more discriminant features of hidden periodicity for texture analysis, such as one-dimensional strip spectral correlation analysis (1D-SSCA), one-dimensional FFT-accumulated method, and direct frequency smoothing method. Although the reported results of these algorithms are proper, all of them suffer a drawback: they sweep texture images row by row and column by column and analyze them as one-dimensional signals, and hence lose the relationships between neighboring pixels. In this paper a new efficient extended algorithm namely two-dimensional SSCA is proposed to estimate the two-dimensional cyclic spectral function for two-dimensional signals. This algorithm is fast respect to other cyclic spectral function estimators and is based on 1D-SSCA algorithm. The effectiveness of the proposed algorithm is evaluated on three well-known databases. The experimental results illustrate that the proposed scheme is computationally efficient, generates flexible features and improves correct classification rate, in comparison with other studies in this field."
journal_title,Multidimensional Systems and Signal Processing
article_title,Existence and design of observers for two-dimensional linear systems with multiple channel faults
keyword,"['States/faults estimation\xa0', 'Singular system observer\xa0', 'Two-dimensional systems\xa0', 'Asymptotically stable observer\xa0', 'Uniformly ultimately bounded observer\xa0']"
history,"['2018-04-02', '2017-04-18', '2018-01-25', '2018-03-28']"
abstract,"Abstract Integrated states/faults observers for two-dimensional (2-D) linear systems, which can simultaneously estimate system states and faults, are studied in this study. Multiple channel faults, occurring in both measurement equation and state equation, are considered. On the basis of the singular system observer method and stability theory, asymptotically stable observers and uniformly ultimately bounded observers are proposed for the 2-D systems. For these two cases, constructive methods for observer design and parameter tuning are further provided. Under different system conditions, the necessary and sufficient conditions for the existence of integrated observers are derived and proved through matrix rank analysis. Finally, two examples are given to demonstrate the performance of the proposed methods."
journal_title,Multidimensional Systems and Signal Processing
article_title,Array signal processing and systems
keyword,[]
history,"['2018-04', '2018-02-15']"
abstract,None
journal_title,Multidimensional Systems and Signal Processing
article_title,Minimum sensitivity based robust beamforming with eigenspace decomposition
keyword,"['Eigenspace\xa0', 'Robust beamformer\xa0', 'Minimum sensitivity\xa0']"
history,"['2018-04', '2016-05-20', '2015-10-14', '2016-03-29', '2016-05-10']"
abstract,"Abstract An enhanced eigenspace-based beamformer (ESB) derived using the minimum sensitivity criterion is proposed with significantly improved robustness against steering vector errors. The sensitivity function is defined as the squared norm of the appropriately scaled weight vector and since the sensitivity function of an array to perturbations becomes very large in the presence of steering vector errors, it can be used to find the best projection for the ESB, irrespective of the distribution of additive noises. As demonstrated by simulation results, the proposed method has a better performance than the classic ESBs and the previously proposed uncertainty set based approach."
journal_title,Multidimensional Systems and Signal Processing
article_title,Two-dimensional noisy autoregressive estimation with application to joint frequency and direction of arrival estimation
keyword,"['Two-dimensional noisy autoregressive model\xa0', 'Yule-Walker equations\xa0', 'Least-squares estimation\xa0', 'Spatial spectrum\xa0']"
history,"['2018-04', '2017-11-26', '2017-06-18', '2017-11-20', '2017-11-22']"
abstract,"Abstract The present study addresses the problem of two-dimensional autoregressive estimation in the presence of additive white noise. The estimation method is based on combining the low-order and high-order Yule-Walker equations. The noise-compensated YW equations are solved using an iterative algorithm. The proposed method is also applied to joint frequency and direction of arrival estimation in uniform linear arrays. Using simulation study, the performance of the proposed algorithm is evaluated and compared with other methods."
journal_title,Multidimensional Systems and Signal Processing
article_title,Joint estimation of DOA and polarization based on phase difference analysis of electromagnetic vector sensor array
keyword,"['Spatially separated electromagnetic vector sensor array (SS-EVSA)\xa0', 'Joint estimation of direction of arrival (DOA)\xa0and polarization\xa0', 'Phase difference analysis\xa0']"
history,"['2018-04', '2016-06-22', '2015-11-17', '2016-03-25', '2016-06-13']"
abstract,"Abstract The spatially separated electromagnetic vector sensor array (SS-EVSA) has been widely used in passive radar direction-finding systems. However, when the directional angles of array elements are different, this changes law of the phase difference between the array elements. In this paper, an explicit theoretical analysis of the characteristics of the phase difference between any two array elements in SS-EVSA is conducted. Theoretical formulas describing the phase difference between array elements are derived from the phase descriptor and the geometric descriptor. Based on the characteristics of the phase difference, a new half-interval search MUSIC(HIS-MUSIC) algorithm is proposed. By searching half of the four-dimensional space, a joint estimation of the direction of arrival and polarization of the incident signal is obtained, which can effectively reduce the computational complexity of the joint estimation of the four-dimensional space. Finally, the efficiency of the algorithm is demonstrated by simulation experiments."
journal_title,Multidimensional Systems and Signal Processing
article_title,DOA estimation with a rotational uniform linear array (RULA) and unknown spatial noise covariance
keyword,"['Direction of arrival\xa0', 'Array signal processing\xa0', 'Rotational arrays\xa0', 'Unknown spatial noise covariance\xa0']"
history,"['2018-04', '2016-06-10', '2016-02-09', '2016-05-14', '2016-05-20']"
abstract,"Abstract Direction of Arrival (DOA) estimation is one of the major tasks in array signal processing. In this paper, a new DOA estimation method is proposed using a rotational uniform linear array (RULA) consisting of omnidirectional sensors. The main contribution of the proposed method is that the number of distinguishable signals is larger than the methods in the literature with a uniform linear array consisting of the same number of omnidirectional sensors. Moreover, the new method can effectively reduce unknown spatial noises using a generalized complement projection matrix under the RULA framework. Simulations are presented to illustrate the effectiveness of the proposed method and comparison with some existing DOA estimation methods is also made."
journal_title,Multidimensional Systems and Signal Processing
article_title,Measurement matrix design for CS-MIMO radar using multi-objective optimization
keyword,"['Bhattacharyya distance\xa0', 'CS-MIMO radar\xa0', 'Measurement matrix design\xa0', 'Multi-objective optimization\xa0', 'Mutual coherency\xa0', 'Signal-to-clutter-plus-interference ratio\xa0']"
history,"['2018-04', '2017-12-16', '2017-06-27', '2017-10-29', '2017-12-02']"
abstract,"Abstract In this paper, we design a measurement matrix for a compressive sensing-multiple-input multiple-output radar in the presence of clutter and interference. To optimize the measurement matrix, three main criteria are considered simultaneously to improve detection and sparse recovery performance while suppressing clutter and interference. To this end, we consider three well-known criteria including Bhattacharyya distance, mutual coherency of sensing matrix, and signal-to-clutter-plus-interference ratio. Due to the use of simultaneous multi-objective functions, a multi-objective optimization (MOO) framework is exploited. Some numerical examples are provided to illustrate the achieved improvement of our proposed method in target detection and sparse recovery performance. Simulation results show that the proposed MOO technique for measurement matrix design can achieve superior performance in target detection compared with Gaussian random measurement matrix technique."
journal_title,Multidimensional Systems and Signal Processing
article_title,Compressive sensing-based wind speed estimation for low-altitude wind-shear with airborne phased array radar
keyword,"['Wind-shear\xa0', 'Compressive sensing\xa0', 'Airborne phased array radar\xa0', 'Space time adaptive processing\xa0', 'Wind speed estimation\xa0']"
history,"['2018-04', '2016-09-07', '2016-02-11', '2016-06-24', '2016-08-30']"
abstract,"Abstract An important issue in low-altitude wind-shear detection is to estimate the wind speed of wind field. In this paper, a novel method for wind speed estimation with airborne phased array radar is proposed by combining space time adaptive processing and compressive sensing. The proposed method is able to achieve accurate wind speed estimate in the condition of limited number of sampling pulses, as demonstrated by numerical examples."
journal_title,Multidimensional Systems and Signal Processing
article_title,Direction of arrival estimation using adaptive directional time-frequency distributions
keyword,"['High resolution TFDs\xa0', 'Instantaneous frequency estimation\xa0', 'MUSIC\xa0', 'Direction of arrival estimation\xa0', 'Adaptive directional Time-frequency distribution\xa0']"
history,"['2018-04', '2016-06-20', '2016-01-08', '2016-06-07', '2016-06-13']"
abstract,"Abstract Time-frequency distributions (TFDs) allow direction of arrival (DOA) estimation algorithms to be used in scenarios when the total number of sources are more than the number of sensors. The performance of such time–frequency (t–f) based DOA estimation algorithms depends on the resolution of the underlying TFD as a higher resolution TFD leads to better separation of sources in the t–f domain. This paper presents a novel DOA estimation algorithm that uses the adaptive directional t–f distribution (ADTFD) for the analysis of close signal components. The ADTFD optimizes the direction of kernel at each point in the t–f domain to obtain a clear t–f representation, which is then exploited for DOA estimation. Moreover, the proposed methodology can also be applied for DOA estimation of sparse signals. Experimental results indicate that the proposed DOA algorithm based on the ADTFD outperforms other fixed and adaptive kernel based DOA algorithms."
journal_title,Multidimensional Systems and Signal Processing
article_title,Spectrum blind reconstruction and direction of arrival estimation of multi-band signals at sub-Nyquist sampling rates
keyword,"['Spectrum blind reconstruction\xa0', 'Direction-of-arrival\xa0', 'Sub-Nyquist sampling\xa0', 'MUSIC\xa0', 'ESPRIT\xa0', 'Sparsity\xa0']"
history,"['2018-04', '2016-09-20', '2016-02-12', '2016-06-19', '2016-09-10']"
abstract,"Abstract In this paper we consider the problem of spectrum blind reconstruction (SBR) and direction of arrival (DOA) estimation of constituent sources of a disjoint multi-band signal (MBS) at sub-Nyquist sampling rates. Transformation of the problem into frequency domain indicates that the steering vector is a function of both the carrier frequency and its corresponding DOA. Employing the existing two dimensional frequency-DOA search algorithms suffers from the drawbacks of increased computational complexity and ambiguity issues. To overcome these drawbacks, in this paper we propose a simple modification to the receiver architecture by introducing an additional delay channel at every sensor. Estimation algorithms based on ESPRIT is then employed to estimate the carrier frequencies, while MUSIC algorithm is employed to estimate their corresponding DOAs. Using the knowledge of both these parameters, the MBS spectrum is then reconstructed. A two-dimensional iterative grid refinement algorithm is also described to further improve the estimation accuracy in the presence of noise. Identifiability issues are addressed and the conditions for unique identifiability are discussed. Furthermore, by assuming a two dimensional uniform array the advantages of the proposed approach in terms of identifiability is also provided. We further show that an \(M \ge N+1\) sensors and an overall sampling rate of at least \(2(N+1)B\) would be sufficient to achieve SBR and DOA estimation of an MBS comprising of N disjoint bands each of maximal bandwidth B. Numerical simulations are finally presented which verifies the validity of the proposed approach and compares the performance against appropriate bounds."
journal_title,Multidimensional Systems and Signal Processing
article_title,DOA and phase error estimation using one calibrated sensor in ULA
keyword,"['Phase error calibration\xa0', 'DOA estimation\xa0', 'Partly calibrated array\xa0', 'Array signal processing\xa0']"
history,"['2018-04', '2017-03-17', '2016-02-13', '2017-03-11', '2017-03-13']"
abstract,"Abstract A new method is presented to effectively estimate the direction-of-arrival of a source signal and the phase error of a uniform linear array. Assuming that one sensor (except the reference one) has been calibrated, the proposed method appropriately reconstructs the data matrix and establishes a series of linear equations with respect to the unknown parameters through eigenvalue decomposition. The unknown parameters can be determined directly by the least squares method. Unlike the conventional methods, the proposed method only requires one calibrated sensor, which may not be consecutively spaced to the reference one. The computational complexity analysis is given and the effectiveness of the proposed method is validated by simulation results."
journal_title,Multidimensional Systems and Signal Processing
article_title,2D DOA estimation for noncircular sources using L-shaped sparse array
keyword,"['Direction-of-arrival estimation\xa0', 'Non-circular signal \xa0', 'Sparse linear array\xa0', 'Fourth-order-cumulant\xa0']"
history,"['2018-04', '2016-04-05', '2015-10-16', '2016-02-01', '2016-03-16']"
abstract,"Abstract We present an algorithm for two-dimensional (2D) direction-of-arrival (DOA) estimation of noncircular sources using an L-shaped sparse array. An L-shaped sparse array consisting of two co-prime arrays is firstly introduced. Then, the fourth-order-cumulants (FOCs) of received data are used to construct a FOC matrix (FOCM), by which we can get the estimations of elevation angles. With the estimated elevation angles, the azimuth angles can be estimated by a low-complexity signal separation algorithm. During the procedure used for estimating azimuth angles, no any eigenvalue decomposition (EVD), peak search and pair-matching procedure need to be implemented. Although the aperture is extended significantly, the computation complexity of proposed algorithm still is acceptable. Compared with some analogous algorithms, our approach shows more attractive estimation performance. A lot of simulation results prove the advantages of proposed DOA estimation technology."
journal_title,Multidimensional Systems and Signal Processing
article_title,Nested algorithms for joint DOD and DOA estimation in bistatic MIMO radar
keyword,"['Joint DOD–DOA estimation\xa0', 'Bistatic MIMO radar\xa0', 'ESPRIT\xa0', 'Maximum likelihood signal grouping\xa0', 'Low-cost algorithms\xa0']"
history,"['2018-04', '2017-07-11', '2016-08-23', '2017-04-10', '2017-07-05']"
abstract,"Abstract This paper presents two nested algorithms—one based on the Estimation of Signal Parameters via Rotational Invariance Technique (ESPRIT) algorithm and the other one on the maximum likelihood estimation—for joint direction of departure (DOD) and direction of arrival (DOA) estimation in bistatic multiple-input multiple-output radar. Both of the proposed nested algorithms interweaves signal grouping schemes and DOD/DOA estimation. Thereby, in each stage only DODs or DOAs, but not both, need to be estimated, and thus the complexity called for can be reduced. Also, the signals in each group have close DOAs, yet diverse DODs, and vice versa, so both DODs and DOAs can be precisely estimated even some of them are very close. Additionally, the estimated DODs and DOAs are automatically paired together without extra computations. Also, for the proposed nested-ML, a non-iterative importance sampling-based ML estimator is developed which is ensured to attain global optimum. Simulation results show that the proposed nested-ESPRIT can provide competing performance, yet with much lower complexity compared with the main state-of-the-art works; whereas, nested-ML can reach the Cramer–Rao lower bound with slightly higher complexity."
journal_title,Multidimensional Systems and Signal Processing
article_title,High resolution 3D imaging in MIMO radar with sparse array
keyword,"['Multiple-input multiple-output (MIMO) radar\xa0', 'Sparse array\xa0', 'Three-dimensional (3D) imaging\xa0', 'Compressive sensing (CS)\xa0', 'Matrix completion (MC)\xa0']"
history,"['2018-04', '2017-11-20', '2016-04-22', '2017-08-02', '2017-11-14']"
abstract,"Abstract High resolution three-dimensional (3D) imaging method using MIMO radar with sparse array is studied in this paper. A method based on compressive sensing (CS) is firstly given. However, the CS-based method has the off-grid problem which will reduce the estimation accuracy of scatterers’ position on the target. Moreover, a high dimensional measurement matrix is required in the CS-based method, which will lead to a heavy storage and computation burden. To solve the two problems of CS, a new method based on matrix completion is proposed in this paper. After reshaping the sparse 3D echo into a low-rank structured matrix, the full 3D echo can be recovered by solving a nuclear norm minimization problem. Then the accurate position of scatterers can be estimated by applying multi-dimensional harmonic retrieval methods to the full 3D echo. Finally, the high resolution 3D image of targets is reconstructed. The effectiveness of the method is validated by the results of comparative simulations."
journal_title,Multidimensional Systems and Signal Processing
article_title,Parameter estimation of air maneuvering target for multi-antenna system via reconstructing time samples and signal
keyword,"['Air maneuvering target\xa0', 'Reconstructing time samples\xa0', 'Reconstructing signal\xa0', 'Parameter estimation\xa0', 'Multi-antenna data processing\xa0']"
history,"['2018-04', '2017-05-19', '2016-02-12', '2017-01-17', '2017-04-29']"
abstract,"Abstract A novel algorithm for estimating the motion parameters of air maneuvering target by means of reconstructing time samples and signal is proposed in this paper. Firstly, the received data of multiple antennas are spliced together to reconstruct time samples of a single antenna by compensating a proper phase. This reconstruction is equivalent to increasing time samples within a single coherent processing interval for a single antenna. After that, an ideal signal whose time sample number is equal to the length of the reconstructed time samples is constructed. At last, the estimation results of initial velocity and acceleration of the air maneuvering target are obtained by applying the nonlinear least squares method to compare the similarity between the reconstructed time samples and signal. The proposed algorithm can achieve accurate parameter estimation with limited pulses. The effectiveness of this algorithm is verified and its performance is very close to the Cramer–Rao bound as shown by our simulation results."
journal_title,Multidimensional Systems and Signal Processing
article_title,Direction of arrival estimation via reweighted $$l_1$$l1 norm penalty algorithm for monostatic MIMO radar
keyword,"['MIMO radar\xa0', 'DOA estimation\xa0', 'Sparse representation \xa0', 'High-resolution\xa0', None]"
history,"['2018-04', '2016-03-10', '2015-12-19', '2016-02-15', '2016-03-02']"
abstract,"Abstract In this paper, a reweighted \(l_1\) norm penalty algorithm for direction of arrival (DOA) estimation in monostatic multiple-input multiple-output radar is proposed. In the proposed method, exploiting the inherent multidimensional structure of received data after matched filtering, the singular value decomposition (SVD) technique of the data matrix is employed to reduce the dimension of the received signal. Then a novel weight matrix is designed for reweighting the \(l_1\) norm minimization by exploiting the coefficients of the reduced-dimensional Capon (RD-Capon) spatial spectrum. The proposed algorithm enhances the sparsity of the solution by the reweighted \(l_1\) norm constraint minimization, and the DOAs can be estimated by finding the non-zero rows of the recovered matrix. Owing to utilizing the SVD technique and the novel weight matrix, the proposed algorithm can provide better angle estimation performance than RD-Capon and \(l_1\)-SRACV algorithms. Furthermore, it is suitable for coherent sources and has a low sensitivity to the incorrect determination of the source numbers. The effectiveness and superior performance of the proposed algorithm are demonstrated by numerical simulations."
journal_title,Multidimensional Systems and Signal Processing
article_title,"Past, present and future of ferroelectric and multiferroic thin films for array antennas"
keyword,"['Phased array antennas\xa0', 'Ferroelectric materials\xa0', 'Multiferroic materials\xa0', 'Thin films\xa0']"
history,"['2018-04', '2016-09-26', '2016-02-16', '2016-08-26', '2016-08-31']"
abstract,"Abstract In addition to providing a number of microwave components with frequency agility and voltage-controlled impedance matching, ferroelectric thin films have enabled electrical-control of beam-steerabilty in both reflectarray and phased array antennas. We present a brief history of developments, beginning in the 1830s, which led to the realization of array antennas based on ferroelectric thin films. We highlight key performance differences provided by competing thin film deposition techniques, and we discuss the outlook of the impact that voltage-controlled magnetism and magnetoelasticity (provided by emerging multiferroic thin films) will have on future array antenna technologies."
journal_title,Multidimensional Systems and Signal Processing
article_title,Gunshot acoustic event identification and shooter localization in a WSN of asynchronous multichannel acoustic ground sensors
keyword,"['Shooter acoustic localization\xa0', 'Circular microphone arrays\xa0', 'DOA estimation\xa0', 'SRP-PHAT\xa0', 'Wireless Sensor Networks\xa0']"
history,"['2018-04', '2017-02-23', '2016-02-17', '2016-12-20', '2017-02-15']"
abstract,"Abstract Gunshot acoustic localization for military and civilian security systems has long been an important topic of research. In recent years the development of Wireless Sensor Network (WSN) systems of independent Unmanned Ground Sensors (UGS) performing distributed cooperative localization has grown in popularity. This paper considers a shooter localization approach based on gunshot Shockwave (SW) and Muzzle Blast (MB) event time and Direction of Arrival (DOA) information. The approach accounts for acoustic events Not-of-Interest (NOI), such as target hit noise, reflections and background noise. UGS perform gunshot acoustic event detection and DOA estimation independently; the information regarding every detected shot instance is sent through the WSN to the fusion node, which performs event identification and calculates the shooter’s position. The paper presents a solution to identifying SW and MB among NOI events at the stage of information fusion. The considered approach treats the information gathered from different UGS separately, and thus does not require precise synchronization between the UGS. For DOA estimation, an algorithm designed for circular microphone arrays is proposed and compared with the SRP-PHAT localization algorithm. It is shown to provide adequate DOA estimates, while being more computationally effective. The proposed shooter localization approach is tested on real signals, acquired during three live shooting experiments. It is shown to succeed in localizing the shooter’s position with a mean accuracy of 0.87 m for 30 shots at the range of 35 m, and just above 7 m for 37 shots at the range of 100 m."
journal_title,Multidimensional Systems and Signal Processing
article_title,Mixed microwave-digital and multi-rate approach for wideband beamforming applications using 2-D IIR beam filters and nested uniform linear arrays
keyword,[]
history,"['2018-04', '2016-06-10', '2016-01-19', '2016-04-20', '2016-05-09']"
abstract,Abstract The presented work explores novel methods for synthesizing approximately frequency independent array factors at lower hardware complexity for wideband beamforming applications. The proposed approach employs 2-D infinite impulse response (IIR) digital beam filters together with nested uniform linear arrays (ULAs). The array is designed to have multiple levels of nesting. Each level of nesting consists of a ULA covering a temporal subband of the incident wideband signal. The use of nested arrays provides the required aperture size using a smaller number of elements compared to using a single ULA to capture the entire wideband signal. The use of different levels of nesting allows the operation of the digital processor for each sub-band at different clock rates. This is a hierarchical approach that saves both digital VLSI hardware and power consumption. The 2-D IIR digital beam filters that process each subband signal from each of the nested subarray achieves wideband beamforming. Simulations illustrate approximately frequency independent passbands as required in wideband beamforming.
journal_title,Multidimensional Systems and Signal Processing
article_title,Discrete Roesser state models from 2D frequency data
keyword,"['2D systems\xa0', 'Roesser models\xa0', 'Bilinear difference forms\xa0', '93A30\xa0', '93B15\xa0', '93B20\xa0', '93B30\xa0', '93C20\xa0']"
history,"['2018-03-31', '2017-03-21', '2018-01-17', '2018-03-27']"
abstract,"Abstract We identify a general, i.e. not necessarily denominator-separable Roesser model from 2D discrete vector-geometric trajectories generated by a controllable, quarter-plane causal system. Our procedure consists of two steps: the first one is the computation of state trajectories from the factorization of constant matrices directly constructed from input-output data. The second step is the computation of the state, output, and input matrices of a Roesser model as solutions of a system of linear equations involving the given input-output data and the computed state trajectories."
journal_title,Multidimensional Systems and Signal Processing
article_title,New effective techniques for automatic detection and classification of external olive fruits defects based on image processing techniques
keyword,"['Image segmentation techniques\xa0', 'Features extraction\xa0', 'Image convolution techniques\xa0', 'Artificial vision techniques\xa0', 'Olive fruit classification techniques\xa0', '62H35\xa0', '62H30\xa0', '62H15\xa0', '62H20\xa0']"
history,"['2018-03-31', '2017-11-17', '2018-03-19', '2018-03-27']"
abstract,"Abstract One of the major concerns for fruit selling companies, at present, is to find an effective way for rapid classification and detection of fruit defects. Olive is one of the most important agricultural product, which receives great attention from fruit and vegetables selling companies, for its utilization in various industries such as oils and pickles industry. The small size and multiple colours of the olive fruit increases the difficulty of detecting the external defects. This paper presents new efficient methods for detecting and classifying automatically the external defects of olive fruits. The proposed techniques can separate between the defected and the healthy olive fruits, and then detect and classify the actual defected area.
 The proposed techniques are based on texture analysis and the homogeneity texture measure. The results and the performance of proposed techniques were compared with varies techniques such as Canny, Otsu, local binary pattern algorithm, K-means, and Fuzzy C-Means algorithms. The results reveal that proposed techniques have the highest accuracy rate among other techniques. The simplicity and the efficiency of the proposed techniques make them appropriate for designing a low-cost hardware kit that can be used for real applications."
journal_title,Multidimensional Systems and Signal Processing
article_title,O n characteristic co nes of discrete nD auto nomous systems: theory a nd a n algorithm
keyword,"['Characteristic cones\xa0', None, 'Autonomous systems\xa0', 'Algebraic methods\xa0', 'Affine semigroups\xa0']"
history,"['2018-03-31', '2017-09-14', '2018-03-20', '2018-03-26']"
abstract,"Abstract In this paper, we provide a complete answer to the question of characteristic cones for discrete autonomous nD systems, with arbitrary \(n\geqslant 2\), described by linear partial difference equations with real constant coefficients. A characteristic cone is a special subset (having the structure of a cone) of the domain (here \(\mathbb {Z}^n\)) such that the knowledge of the trajectories on this set uniquely determines them over the whole domain. Despite its importance in numerous system-theoretic issues, the question of characteristic sets for multidimensional systems has not been answered in its full generality except for Valcher’s seminal work for the special case of 2D systems (Valcher in IEEE Trans Circuits and Syst Part I Fundam Theory Appl 47(3):290–302, 2000). This apparent lack of progress is perhaps due to inapplicability of a crucial intermediate result by Valcher to cases with \(n\geqslant 3\). We illustrate this inapplicability of the above-mentioned result in Sect. 3 with the help of an example. We then provide an answer to this open problem of characterizing characteristic cones for discrete nD autonomous systems with general n; we prove an algebraic condition that is necessary and sufficient for a given cone to be a characteristic cone for a given system of linear partial difference equations with real constant coefficients. In the second part of the paper, we convert this necessary and sufficient condition to another equivalent algebraic condition, which is more suited from algorithmic perspective. Using this result, we provide an algorithm, based on Gröbner bases, that is implementable using standard computer algebra packages, for testing whether a given cone is a characteristic cone for a given discrete autonomous nD system."
journal_title,Multidimensional Systems and Signal Processing
article_title,A hybrid defocused region segmentation approach using image matting
keyword,"['Region segmentation\xa0', 'Image matting\xa0', 'Sharpness maps\xa0']"
history,"['2018-03-30', '2017-04-13', '2017-09-18', '2018-03-26']"
abstract,"Abstract In this paper, a hybrid defocused region segmentation using image matting is proposed. The technique incorporates three sharpness metrics which are magnitude spectrum slope, local total variation and local binary patterns to identify the in-focus pixels in the image. Trimap is generated automatically using sharpness maps to obtain the prior information and matting Laplacian is applied to propagate the trimap to the entire image based on color similarities. Simulation results compared using visual and quantitative metrics show the strength of the proposed technique."
journal_title,Multidimensional Systems and Signal Processing
article_title,Asynchronous filtering for 2-D switched systems with missing measurements
keyword,"['Asynchronous filtering\xa0', None, 'Mode-dependent average dwell time\xa0', 'Missing measurements\xa0', '2-D switched system\xa0']"
history,"['2018-03-29', '2017-08-22', '2018-03-21', '2018-03-26']"
abstract,"Abstract This work is concerned with \(\mathscr {H}_{\infty }\) filter design with missing measurements for a class of two-dimensional (2-D) switched systems represented by Fornasini–Marchesini local state-space model. The switching signal of the switched filters involve time delays, which result in the asynchronism between the filter and the system switching. The issues of asymptotic mean-square stability and \(\ell _{2}\)-gain analysis for the 2-D switched systems are addressed firstly, based on which mode-dependent filters are designed with mode-dependent average dwell time scheme. Finally, two examples are given to demonstrate the validity of the proposed technique."
journal_title,Multidimensional Systems and Signal Processing
article_title,A two-level secure data hiding algorithm for video steganography
keyword,"['Data hiding\xa0', 'Video steganography\xa0', 'Adaptive LSB\xa0', 'Randomized encoding\xa0']"
history,"['2018-03-20', '2016-11-07', '2018-03-09', '2018-03-16']"
abstract,"Abstract Sensitive data is exchanged frequently through wired or wireless communication that are vulnerable to unauthorized interception. Cryptography is a solution to overcome this issue, but once decrypted the information secrecy does not exist. Apart from hiding data in an image, it can be extended for digital media. In this work, data hiding and extraction is proposed for Audio Video Interleave videos, that embeds the image in Bitmap Image File, that has the secret information in a frame of the video by segmenting the bytes of the secret image and placing them in the video frame providing a higher level of encryption. This novel method provides a two level encryption, thus to decipher the data, the way in which the secret image is originally decomposed and the frame in which it is embedded should be known. The quality of the secret image embedded and the size of the video is not altered before and after encryption of the secret data. The secret image may contain any multimedia data that can be further extracted and recognized."
journal_title,Multidimensional Systems and Signal Processing
article_title,Ergodic optimization of stochastic differential systems in wireless networks
keyword,"['Heavy traffic analysis\xa0', 'Weak convergence to a diffusion process\xa0', 'Optimal control\xa0', 'Ergodic theorems\xa0']"
history,"['2018-03-19', '2017-01-03', '2018-02-07', '2018-02-28']"
abstract,"Abstract The present work is the second article in a couple of intertwined papers. They form complementary items on the same subject. They both address the problem of joint power allocation and time slot scheduling in a wireless communication system with time varying traffic. The system is handled by a single base station transmitting over time varying channels. The operating time horizon is divided into time slots, and a fixed amount of power is available at each time slot. The mobile users share each time slot and the power available at this time slot. Since many wireless network applications have stringent delay requirements, designing high-performance resource allocation algorithms to achieve minimum possible delay is of great importance, and this is the main objective of the work presented in this paper. The delay performance of a resource allocation algorithm can be characterized by the average delay experienced by the data transmitted in the network. We propose a heavy traffic analysis for the physical system on hand, i.e., appropriate re-scaling that leads to a diffusion approximation of the system in the sense of weak convergence. The approximate diffusion is constrained or bounded in the K-dimensional positive orthant. We establish the convergence result of the heavy traffic analysis, and then a closed form solution to the resource optimization problem is provided. Here the solution relies on the ergodicity of the approximate diffusion."
journal_title,Multidimensional Systems and Signal Processing
article_title,Image denoising using combined higher order non-convex total variation with overlapping group sparsity
keyword,"['Alternating direction method\xa0', 'Total variation\xa0', 'Denoising\xa0', 'Non-convex\xa0', 'Overlapping group sparsity\xa0']"
history,"['2018-03-17', '2017-08-08', '2018-01-11', '2018-03-12']"
abstract,"Abstract It is widely known that the total variation image restoration suffers from the stair casing artifacts which results in blocky restored images. In this paper, we address this problem by proposing a combined non-convex higher order total variation with overlapping group sparse regularizer. The hybrid scheme of both the overlapping group sparse and the non-convex higher order total variation for blocky artifact removal is complementary. The overlapping group sparse term tends to smoothen out blockiness in the restored image more globally, while the non-convex higher order term tends to smoothen parts that are more local to texture while preserving sharp edges. To solve the proposed image restoration model, we develop an iteratively re-weighted \(\ell _1\) based alternating direction method of multipliers algorithm to deal with the constraints and subproblems. In this study, the images are degraded with different levels of Gaussian noise. A comparative analysis of the proposed method with the overlapping group sparse total variation, the Lysaker, Lundervold and Tai model, the total generalized variation and the non-convex higher order total variation, was carried out for image denoising. The results in terms of peak signal-to-noise ratio and structure similarity index measure show that the proposed method gave better performance than the compared algorithms."
journal_title,Multidimensional Systems and Signal Processing
article_title,Collaborative linear dynamical system identification by scarce relevant/irrelevant observations
keyword,"['Linear dynamical system identification\xa0', 'State-space model parameter estimation\xa0', 'Multi-sensor multi-dimensional observations\xa0', 'Unreliable observations\xa0', 'Scarce observations\xa0', 'Relevant/irrelevant observations\xa0']"
history,"['2018-03-12', '2017-10-10', '2018-01-27', '2018-02-27']"
abstract,"Abstract In the current paper, linear dynamical system identification by relevant and irrelevant multi-sensor observations is presented. In common system identification methods, it is presumed that observations are related to the system. However, the present study assumes that there are multi-sensor observations, whose sensors may give relevant information related to the system while some others do not. Furthermore, whether or not the sensor data is related or unrelated is unknown. Especially in large dimensions, the scarce observations of sensors pose a problem for estimating parameters. For this scenario, the current work will show that common methods are not appropriate. Therefore, to solve the problem of scarce relevant/irrelevant observations, the collaborative identification method is presented, in which relevant sensors collaborate with each other and, as a result, the estimation of parameters is more accurate. The results of synthetic and real dataset experiments indicate that the proposed model’s performance is superior to common methods."
journal_title,Multidimensional Systems and Signal Processing
article_title,Convergent method for designing high-accuracy bi-equiripple variable-delay filters using new delay-error expression
keyword,"['Multi-variable (MV) Transfer function\xa0', 'Group-delay\xa0', 'Variable-delay (VD) filter\xa0', 'Odd-order VD filter\xa0', 'Linearized group-delay error\xa0', 'Bi-equiripple design\xa0']"
history,"['2018-03-10', '2017-01-18', '2017-10-07', '2018-02-23']"
abstract,"Abstract This paper proposes a fast non-iterative approach to the design of an odd-order bi-equiripple variable-delay (VD) digital filter whose mathematical model is a multi-variable (MV) transfer function. The objective of the bi-equiripple design is to minimize the maximum frequency-response deviation of this MV transfer function while mitigating the large overshoots of the VD response at the same time. Since the group-delay function is nonlinear with respect to the MV transfer-function coefficients, it is first linearized through using an approximate approach. This linearization enables the bi-equiripple VD filter to be designed with linear constraints, and the bi-equiripple design is then formulated as a convex minimization problem. The convex minimization does not require any iterations and thus it is fast and yields a convergent optimal solution. Solving the convex minimization problem produces a bi-equiripple VD filter with minimized worst-case frequency-response error and mitigated VD-deviation overshoots (jumps). An illustrating example is presented to demonstrate the above simultaneous deviation suppressions."
journal_title,Multidimensional Systems and Signal Processing
article_title,On minor prime factorizations for multivariate polynomial matrices
keyword,"['Multidimensional systems\xa0', 'Multivariate polynomial matrices\xa0', 'Matrix factorizations\xa0', 'Minor prime factorizations\xa0']"
history,"['2018-03-09', '2017-01-14', '2018-03-03', '2018-03-07']"
abstract,"Abstract Multivariate polynomial matrix factorizations have been widely investigated during the past years due to the fundamental importance in the areas of multidimensional systems and signal processing. In this paper, minor prime factorizations for multivariate polynomial matrices are studied. We give a necessary and sufficient condition for the existence of a minor left prime factorization for a multivariate polynomial matrix. This result is a generalization of a theorem in Wang and Kwong (Math Control Signals Syst 17(4):297–311, 2005). On the basis of this result and a method in Fabiańska and Quadrat (Radon Ser Comp Appl Math 3:23–106, 2007), we give an algorithm to decide if a multivariate polynomial matrix has minor left prime factorizations and compute one if they exist."
journal_title,Multidimensional Systems and Signal Processing
article_title,DOA estimation with double L-shaped array based on Hadamard product and joint diagonalization in the presence of sensor gain-phase errors
keyword,"['Array signal processing\xa0', 'DOA estimation\xa0', 'Double L-shaped array\xa0', 'Gain-phase errors\xa0', 'Hadamard product\xa0', 'Joint diagonalization\xa0']"
history,"['2018-03-08', '2017-08-03', '2017-12-30', '2018-03-02']"
abstract,"Abstract A method with double L-shaped array for direction-of-arrival (DOA) estimation in the presence of sensor gain-phase errors is presented. The reason for choosing double L-shaped array is that the shared elements between sub-arrays are the most and rotation invariant property can be applied for this array. The proposed method is introduced as follows. (1) If the number of signal is one, first the gain errors are estimated and removed with the diagonal of the covariance matrix of the array output. Then the array is rotated by an unknown angle and DOA can be estimated with the relationship between signal subspace and steering vector of signal. (2) If signals are more than one, the method for eliminating gain errors is the same with the previous case, and then the phase errors are removed by the Hadamard product of the (cross) covariance matrix and its conjugate. After the errors are eliminated, the DOAs can be estimated by rotation invariant property and orthogonal joint diagonalization for the Hadamard product. This method requires neither calibrated sources nor multidimensional parameter search, and its performance is independent of the phase errors. Simulation results demonstrate the effectiveness of the proposed method."
journal_title,Multidimensional Systems and Signal Processing
article_title,Morphological operations with iterative rotation of structuring elements for segmentation of retinal vessel structures
keyword,"['Computer aided diagnosis\xa0', 'Diabetic retinopathy\xa0', 'Hit-or-miss transform\xa0', 'Segmentation\xa0', 'Wavelet transform\xa0']"
history,"['2018-03-05', '2017-06-30', '2018-02-20', '2018-02-23']"
abstract,"Abstract The development of computer aided diagnosis system has a great impact on early and accurate disease diagnosis. The segmentation of retinal blood vessels aids in identifying the alteration in vessel structure and hence helps to diagnose many diseases such as diabetic retinopathy, glaucoma, hypertension along with some cardiovascular diseases. In this research work, a method is presented for the segmentation of retinal vessel structure from retinal fundus images. 2D wavelet transform assisted morphological gradient operation based ‘Contrast Limited Adaptive Histogram Equalization’ technique has been introduced for the preprocessing of the low contrast fundus images. Morphological gray level hit-or-miss transform with multi-structuring element with varying orientation has been proposed for the separation of blood vessel from its background. Finally a hysteresis thresholding, guided by some morphological operations has been employed to obtain the binary image excluding other unwanted areas. The proposed methodology has been tested on DRIVE database and a maximum accuracy and an average accuracy of 95.65 and 94.31% respectively have been achieved."
journal_title,Multidimensional Systems and Signal Processing
article_title,A nullstellensatz for linear partial differential equations with polynomial coefficients
keyword,"['Algebraic theory of systems\xa0', 'Symbolic methods for systems\xa0', 'Weyl algebra\xa0', 'Nullstellensatz\xa0', 'Riquier bases\xa0']"
history,"['2018-03-05', '2016-08-10', '2017-07-14', '2018-02-23']"
abstract,"Abstract In this paper an equation means a homogeneous linear partial differential equation in n unknown functions of m variables which has real or complex polynomial coefficients. The solution set consists of all n-tuples of real or complex analytic functions that satisfy the equation. For a given system of equations we would like to characterize its Weyl closure, i.e. the set of all equations that vanish on the solution set of the given system. It is well-known that in many special cases the Weyl closure is equal to \(B_m(\mathbb {F})N \cap A_m(\mathbb {F})^n\) where \(\mathbb {F}\in \{\mathbb {R},\mathbb {C}\}\), the algebra \(A_m(\mathbb {F})\) (respectively \(B_m(\mathbb {F})\)) consists of all linear partial differential operators with coefficients in \(\mathbb {F}[x_1,\ldots ,x_m]\) (respectively \(\mathbb {F}(x_1,\ldots ,x_m)\)) and N is the submodule of \(A_m(\mathbb {F})^n\) generated by the given system. Our main result is that this formula holds in general. In particular, we do not assume that the module \(A_m(\mathbb {F})^n/N\) has finite rank which used to be a standard assumption. Our approach works also for the real case which was not possible with previous methods. Moreover, our proof is constructive as it depends only on the Riquier–Janet theory."
journal_title,Multidimensional Systems and Signal Processing
article_title,Parametric estimation of 2D cubic phase signals using high-order Wigner distribution with genetic algorithm
keyword,"['Polynomial-phase signals\xa0', 'Gaussian noise\xa0', 'Wigner distribution\xa0', 'Francos–Friedlander approach\xa0', 'Genetic algorithm\xa0']"
history,"['2018-03-05', '2017-01-17', '2018-02-24', '2018-03-01']"
abstract,"Abstract A two-dimensional (2D) high-order Wigner distribution (HO-WD) is proposed for parameter estimation of 2D polynomial phase signals (PPSs). The genetic algorithm is employed for maximization of the 2D HO-WD. In comparison to the 2D cubic phase function and classical Francos and Friedlander approach, the 2D HO-WD reduces error propagation effect which leads to lower mean squared error in estimation of signal parameters. The proposed technique is generalized for the 2D higher-order PPS."
journal_title,Multidimensional Systems and Signal Processing
article_title,Near-field coherent source localization by planar array design
keyword,"['Coherent sources\xa0', 'Near-field\xa0', 'Source localization\xa0', 'Array design\xa0', 'CRB\xa0']"
history,"['2018-03-02', '2017-07-08', '2017-11-23', '2018-01-29']"
abstract,"Abstract This paper is concerned with near-field source localization for scenarios where coherent narrowband sources exist. In this paper, we propose a new method in which we design a general planar array with a covariance matrix whose rank is not decreased by the coherence between sources. Moreover, conditions for the sensor locations in the designed planar array are derived to reach maximum effective array aperture. The proposed method uses second order statistics and features a separable range-bearing search to reduce the computational complexity. This method localizes near-field sources with a number of one-dimensional searches in two steps. In the first step, ranges of sources is estimated using one 1D search and in the second step, the bearing of each signal source is estimated using the corresponding range estimated in the first step. Simulation results show that the performance of the proposed method is comparable with the Cramer–Rao bound."
journal_title,Multidimensional Systems and Signal Processing
article_title,Anomaly detection with a moving camera using multiscale video analysis
keyword,"['Video surveillance\xa0', 'Moving camera\xa0', 'Abandoned object detection\xa0', 'Cluttered environment\xa0']"
history,"['2018-02-28', '2017-12-18', '2018-02-20', '2018-02-22']"
abstract,"Abstract This paper addresses the problem of abandoned object detection in a cluttered environment using a camera moving along a straight track. The developed system compares captured images to a previously recorded reference video, thus requiring proper temporal alignment and geometric registration between the two signals. A real-time constraint is imposed onto the system to allow an effective surveillance capability in practical situations. In this paper, we propose to deal with the simultaneous detection of objects of different sizes using a multiresolution approach together with normalized cross-correlation and a voting step. In order to develop and properly assess the proposed method we designed a database recorded in a real surveillance scenario, consisting of an industrial plant containing a large number of pipes and rotating machines. Also, we have devised a systematic parameter tuning routine that allows the system to be adapted to different scenarios. We have validated it using the designed database. The obtained results are quite effective, achieving real-time, robust abandoned object detection in an industrial plant scenario."
journal_title,Multidimensional Systems and Signal Processing
article_title,Target recognition and discrimination based on multiple-frequencies LFM signal with subcarrier hopping
keyword,"['Deception jamming\xa0', 'OFDM\xa0', 'Sub-carrier hopping\xa0', 'Likelihood ratio test\xa0', 'Probability of detection\xa0']"
history,"['2018-02-27', '2017-02-27', '2017-11-19', '2017-12-16']"
abstract,"Abstract An anti-deception jamming technique is proposed for moving target indication in a pulse-Doppler (PD) radar. The deceive targets are produced by digital radio frequency memory, which tries to pull off the range and velocity gates of real targets. Similar to orthogonal frequency division multiplexing, we use different sets of orthogonal sub-carriers in consecutive coherent pulse intervals (CPIs). By changing sub-carriers in different CPIs, we show that the deceive targets appear as interference in receiving signals. The generalized likelihood ratio test is used for detection and discrimination of real targets. The performance of the proposed method is achieved analytically and by simulations. Furthermore, we implement a hardware block using a TMS6416-DSK DSP for a PD radar prototype exploiting the proposed algorithm to deception discrimination. The presented results demonstrate the good accordance with theoretical predictions."
journal_title,Multidimensional Systems and Signal Processing
article_title,An optimal robust adaptive beamforming in the presence of unknown mutual coupling
keyword,"['Robust adaptive beamformer\xa0', 'Unknown mutual coupling\xa0', 'Matrix reconstruction\xa0', 'Eigenvalue decomposition\xa0']"
history,"['2018-02-19', '2017-08-23', '2018-01-31', '2018-02-08']"
abstract,"Abstract An optimal robust adaptive beamformer in the presence of unknown mutual coupling is proposed. In this proposed beamformer, envelopes of the received signals in the presence of unknown mutual coupling and their corresponding powers can be estimated by utilizing the Toeplitz characteristics of the mutual coupling matrix. Both of them are used to reconstruct the interference-plus-noise covariance matrix in a novel expression. A subspace orthogonal to the interference space can be obtained by performing the eigenvalue decomposition on this reconstructed matrix. Hence, the desired signal and the noise are retained by projecting the observed data to this orthogonal space. Finally, the optimal weight vector is obtained by passing the desired signal with the maximum output power criterion. The proposed method maintains excellent performance in the presence of unknown mutual coupling and the simulation results are consistent with the theoretical analysis."
journal_title,Multidimensional Systems and Signal Processing
article_title,View synthesis for FTV systems based on a minimum spatial distance and correspondence field
keyword,"['Virtual view synthesis\xa0', 'Correspondence field\xa0', 'Image rectification\xa0', 'Epipolar line\xa0', 'Hole filling\xa0']"
history,"['2018-02-16', '2017-07-05', '2018-01-20', '2018-02-08']"
abstract,"Abstract The main problems with virtual view synthesis based on the common Depth-Image-Based Rendering (DIBR) algorithms are image rectification, depth map and image de-rectification that lead to additional computational load and image distortion. In this paper an efficient and reliable method based on the concept of Correspondence Field and minimum distance among spatial positions of corresponding pixels is proposed to synthesize virtual view images without image rectification, depth map and image de-rectification steps. Simulated multi-view images are used to evaluate the proposed algorithm. By comparison with DIBR algorithms, simulation results show that on average, PSNR is 4.37 dB (14.8%) higher, SSIM is 0.057 (6.2%) more, UNIQUE is 0.13 (20%) more, the running time is 47.34 s (24.5%) less and wrong pixels are 4.35 (38.5%) less."
journal_title,Multidimensional Systems and Signal Processing
article_title,Sparsity and incoherence in orthogonal matching pursuit
keyword,"['Sparsity\xa0', 'Orthogonal matching pursuit\xa0', 'Isotropy property\xa0', 'Incoherence property\xa0', 'Support recovery\xa0']"
history,"['2018-02-15', '2017-08-27', '2018-01-09', '2018-01-29']"
abstract,"Abstract Recovery of sparse signals via approximation methods has been extensively studied in recently years. We consider the nonuniform recovery of orthogonal matching pursuit (OMP) from fewer noisy random measurements. Rows of sensing matrices are assumed to be drawn independently from a probability distribution obeying the isotropy property and the incoherence property. Our models not only include the standard sensing matrices in compressed sensing context, but also cover other new sensing matrices such as random convolutions, subsampled tight or continuous frames. Given m admissible random measurements of a fixed s-sparse signal \(\varvec{x}\in \mathbb {R}^n\), we show that OMP can recover the support of \(\varvec{x}\) exactly after s iterations with overwhelming probability provided that $$\begin{aligned} m=O( s(s+\log (n-s))). \end{aligned}$$It follows that the approximation order of OMP is $$\begin{aligned} \Vert \varvec{x}- \varvec{x}_j\Vert =O(\eta ^j) \end{aligned}$$where \(0<\eta <1\) and \(\varvec{x}_j\) denotes the recovered signal at j-th iteration. As a byproduct of the proof, the necessary number of measurements to ensure sparse recovery by \(l_1\)-minimization with random partial circulant or Toeplitz matrices is proved to be optimal."
journal_title,Multidimensional Systems and Signal Processing
article_title,Two-dimensional DOA estimation for generalized coprime planar arrays: a fast-convergence trilinear decomposition approach
keyword,"['Trilinear decomposition\xa0', 'Parallel factor\xa0', 'Generalized coprime planar array\xa0', 'Two-dimensional direction of arrival\xa0', 'Propagator method\xa0', 'Fast convergence\xa0']"
history,"['2018-02-05', '2017-08-15', '2018-01-25', '2018-01-29']"
abstract,"Abstract In this paper, we investigate the problem of two-dimensional (2D) direction of arrival (DOA) estimation of multiple signals for generalized coprime planar arrays consisting of two rectangular uniform planar subarrays. We propose a fast-convergence trilinear decomposition approach, which uses propagator method (PM) as the initialization of the angle estimation to speed the convergence of trilinear decomposition. The received signal of each subarray can be fitted into a trilinear model or parallel factor (PARAFAC) model so that the trilinear alternating least square algorithm can be used to estimate the angle information. Meanwhile, the necessary initialization of DOA estimates can be achieved via PM, which endows the proposed approach a fast convergence and subsequently results in a low complexity. Specifically, we eliminate the ambiguous estimates by utilizing the coprime property and the true DOA estimates can be achieved by selecting the nearest ones of all DOA estimates. The proposed approach can obtain the same estimation performance as the conventional PARAFAC algorithm, but with a low computational cost. Numerical simulation results are provided to validate the effectiveness and superiority of the proposed algorithm."
journal_title,Multidimensional Systems and Signal Processing
article_title,Extended histogram: probabilistic modelling of video content temporal evolutions
keyword,"['Extended histogram (EH)\xa0', 'Hierarchical extended histogram (HEH)\xa0', 'Probabilistic modelling\xa0', 'Temporal evolutions\xa0', 'Human action recognition\xa0', 'Person re-identification\xa0']"
history,"['2018-02-03', '2017-03-13', '2017-12-09', '2018-01-06']"
abstract,"Abstract A probabilistic video content analysis method called extended histogram (EH) is proposed for modelling temporal evolutions of a set of histograms extracted from video frames. In EH, the number of counts for each histogram bin is considered as a random variable (instead of a single value) to account for bin variations. This representation is especially suitable for modelling the dynamic behaviour of a tracked video content of interest in a general manner. The pitfall of such a modelling is its negligence of the temporal order of observations in the collection. To overcome that problem, a hierarchical approach called hierarchical extended histogram (HEH) is proposed for extracting EHs in different levels of the temporal pyramid. Once these generative models are identified for each video, an information-based metric is proposed to be used for defining the similarity of the two EHs. Having this metric, EHs can be used in many different tasks including video retrieval, classification, summarization, and so forth. Especially in the case of discriminant learning, probabilistic kernels based on this metric are also defined to be able to use EHs/HEHs alongside machine learning models such as the SVM. Person re-identification and human action recognition are used as pilot applications to show the capabilities of proposed representations. Experimental results show the significant effectiveness of proposed models."
journal_title,Multidimensional Systems and Signal Processing
article_title,A simple numerical method based simultaneous stochastic perturbation for estimation of high dimensional matrices
keyword,"['Numerical differentiation\xa0', 'Stochastic simultaneous perturbation\xa0', 'Matrix decomposition\xa0', 'Singular value decomposition\xa0', 'Parameter estimation\xa0', 'Data assimilation\xa0']"
history,"['2018-01-19', '2016-11-25', '2018-01-05', '2018-01-07']"
abstract,Abstract We describe a simple algorithm for estimating the elements of a matrix as well as its decomposition under the condition that only the product of this matrix with a vector is accessible. The algorithm is based on application of the stochastic simultaneous perturbation method. Theoretical results on the convergence of the proposed algorithm are proven. Numerical experiments are presented to show the efficiency of the proposed algorithm.
journal_title,Multidimensional Systems and Signal Processing
article_title,A new nonconvex approach to low-rank matrix completion with application to image inpainting
keyword,"['Low-rank matrix completion\xa0', 'Moreau envelope\xa0', 'Proximal alternating minimization\xa0', 'Image Inpainting\xa0']"
history,"['2018-01-16', '2017-01-01', '2018-01-02', '2018-01-06']"
abstract,"Abstract The problem of recovering a low-rank matrix from partial entries, known as low-rank matrix completion, has been extensively investigated in recent years. It can be viewed as a special case of the affine constrained rank minimization problem which is NP-hard in general and is computationally hard to solve in practice. One widely studied approach is to replace the matrix rank function by its nuclear-norm, which leads to the convex nuclear-norm minimization problem solved efficiently by many popular convex optimization algorithms. In this paper, we propose a new nonconvex approach to better approximate the rank function. The new approximation function is actually the Moreau envelope of the rank function (MER) which has an explicit expression. The new approximation problem of low-rank matrix completion based on MER can be converted to an optimization problem with two variables. We then adapt the proximal alternating minimization algorithm to solve it. The convergence (rate) of the proposed algorithm is proved and its accelerated version is also developed. Numerical experiments on completion of low-rank random matrices and standard image inpainting problems have shown that our algorithms have better performance than some state-of-art methods."
journal_title,Multidimensional Systems and Signal Processing
article_title,Erratum to: Electromagnetic modeling of carbon-fiber reinforced composite materials using the wave digital concept
keyword,[]
history,"['2018-01', '2017-02-15']"
abstract,None
journal_title,Multidimensional Systems and Signal Processing
article_title,Moving target parameter estimation for MIMO radar based on the improved particle filter
keyword,"['IPRBPF\xa0', 'MIMO radar\xa0', 'Parameter estimation\xa0', 'Particle filter\xa0']"
history,"['2018-01', '2016-08-16', '2016-01-13', '2016-08-01', '2016-08-09']"
abstract,"Abstract In this paper, a novel independent partition Rao-Blackwellized particle filter (IPRBPF) is proposed to estimate the moving target parameters in MIMO radar. Firstly, noticing that the likelihood function is a nonlinear function of the nonlinear position parameters, and that the target motion equation is a linear function of linear parameters such as velocity, acceleration and etc. The nonlinear particle filter is proposed to estimate the nonlinear position parameters and the linear Kalman filter is proposed to estimate the linear parameters. Then a new MIMO radar parameter estimation algorithm based on Rao-Blackwellized particle filter is obtained. Furtherly, considering that the computational complexity will increase dramatically with the targets’ state dimension in the case of multiple targets, the independent partition sampling is put forward to improve the performance of our algorithm, then the IPRBPF algorithm is obtained. Compared with the existing methods, the proposed algorithm can achieve the lower computational complexity and the higher accuracy of parameter estimation. Simulation results demonstrate the advantages of the proposed algorithm."
journal_title,Multidimensional Systems and Signal Processing
article_title,Novel features and a cascaded classifier based Arabic numerals recognition system
keyword,"['Zonal moment of inertia (ZMI)\xa0', 'Delta distance coding (DDC)\xa0', 'Delta slope coding (DSC)\xa0', 'Centroidal moment of inertia (CMI)\xa0', 'Statistical features\xa0', 'K-nearest neighbor (KNN)\xa0', 'Support vector machine (SVM)\xa0']"
history,"['2018-01', '2016-12-29', '2016-02-15', '2016-12-13', '2016-12-19']"
abstract,"Abstract Individuality of handwriting inserts varying curvatures and angles whenever someone writes a sample of a particular numeral which makes the task of its off-line recognition more challenging. The paper addresses both these issues in novel and robust ways by merging two Digital domains, namely Digital Communications and Digital Image Processing. Curvature is treated by finding analytical features based on distance and slope. Distance based treatment is done by means of Delta Distance Coding whereas slope based analysis is executed with Delta Slope Coding. Angular variations have been countered with the help of rotation invariant physical feature i.e., Pixel Moment of Inertia. A due stress has been laid on Pixel Moment of Inertia by finding it both globally and locally in terms of Centroidal Moment of Inertia and Zonal Moment of Inertia respectively. The above mentioned features are further supported with statistical features in order to differentiate very similar looking numeral pairs like (3, 8), (1, 7), (7, 9). Feature extraction methods are devoid of cumbersome calculations, and classifiers are capable of yielding instantaneous results. Therefore, the current system is a real time system. The system has been tested on unconstrained MNIST dataset. The overall recognition accuracy of 99.26% has been obtained."
journal_title,Multidimensional Systems and Signal Processing
article_title,Smoothing of adaptive eigenvector extraction in nested orthogonal complement structure with minimum disturbance principle
keyword,"['Generalized Hermitian eigenvalue problem (GHEP)\xa0', 'Adaptive algorithm\xa0', 'Smoothing\xa0', 'Orthogonal complement matrix\xa0', 'Nested orthogonal complement structure\xa0']"
history,"['2018-01', '2017-10-14', '2016-11-29', '2017-09-10', '2017-09-21']"
abstract,"Abstract For adaptive extraction of generalized eigensubspace, Nguyen, Takahashi and Yamada proposed a scheme for solving generalized Hermitian eigenvalue problem based on nested orthogonal complement structure. This scheme can extract multiple generalized eigenvectors by combining with any algorithm designed for estimation of the first minor generalized eigenvector. In this paper, we carefully analyse the effect of a discontinuous function employed in the scheme, and show that the discontinuous function can cause unsmooth changes of the estimates by the scheme in its adaptive implementation. To remedy the weakness, we newly introduce a projection step, for smoothing, without increasing the order of the computational complexity. Numerical experiments show that the learning curves of the non-first generalized eigenvectors are improved drastically through the proposed smoothing even when the original scheme results in unexpected performance degradation."
journal_title,Multidimensional Systems and Signal Processing
article_title,Automatic crack detection from 2D images using a crack measure-based B-spline level set model
keyword,"['Crack identification\xa0', 'Level set function\xa0', 'Image processing\xa0', 'Crack image\xa0']"
history,"['2018-01', '2016-10-22', '2015-11-02', '2016-10-05', '2016-10-11']"
abstract,"Abstract A method is proposed for automatic detection of cracks extracted from 2D images of damaged structures. In the 2D images, the cracks are treated as tree-like topological dark objects of which each tree branch is assumed to be line-like and have local symmetry across the crack center axis. Utilizing the geometric features of the cracks, a novel level set model in which the level set function comprises a set of B-spline basis functions is established to automatically extract the level set function from the 2D crack image with intensity inhomogeneity for crack detection. A new energy functional together with a crack measure technique is introduced to derive an iterative procedure for obtaining the exact level set function of the crack image via an optimization approach. In the iteration process, the level set model can produce smooth and continuous boundaries of the cracks with fast convergence speed. In a comparative study, it has been shown that the proposed method can extract cracks from several real noisy crack images of damaged structures made of various materials more accurate than those determined using the existing crack detection methods which use either different level set models or other image processing techniques in extracting the cracks."
journal_title,Multidimensional Systems and Signal Processing
article_title,State-space formulation of 2-D frequency transformation in Fornasini–Marchesini second model
keyword,"['2-D digital filter\xa0', 'Frequency transformation\xa0', 'Fornasini–Marchesini second model\xa0']"
history,"['2018-01', '2017-01-06', '2016-08-12', '2016-11-08', '2016-12-30']"
abstract,"Abstract This paper presents a state-space formulation for the two-dimensional (2-D) frequency transformation in the Fornasini–Marchesini second (FM II) model. Specifically, by introducing some new state vectors, an equivalent description of the FM II model will be first established. Then based on this new description, a state-space formulation of the 2-D frequency transformation in the FM II model is derived by revealing the substantial input and output relations among the state vectors of the prototype filter, all-pass filters and the transformed filter. The resultant formulation owns an elegant and general expression, and can be viewed as a natural extension of its counterpart in the Roesser model. Furthermore, as one of the various possible applications of the proposed formulation, a 2-D zero-phase IIR filters design procedure will be shown, by which the desired 2-D zero-phase IIR filters can be constructed in a more flexible way to avoid the kind of image distortions caused by the nonlinear phase of the used filter. Three typical image processing examples as well as the computational complexity analysis will be given to show the effectiveness and efficiency of the proposed procedure."
journal_title,Multidimensional Systems and Signal Processing
article_title,Multiplierless lifting-based fast X transforms derived from fast Hartley transform factorization
keyword,[]
history,"['2018-01', '2016-09-24', '2015-08-24', '2016-05-30', '2016-09-20']"
abstract,"Abstract This paper presents M-channel (\(M=2^{N}\), \(N\in \mathbb {N}\), \(N\ge 1\)) multiplierless lifting-based (ML-) fast X transforms (FXTs), where X \(=\) F (Fourier), C (cosine), S (sine), and H (Hartley), i.e., FFT, FCT, FST, and FHT, derived from FHT factorization as way of lowering the cost of signal (image) processing. The basic forms of ML-FXTs are described. Then, they are customized for efficient image processing. The customized ML-FFT has a real-valued calculation followed by a complex-valued one. The ML-FCT customization for a block size of 8, which is a typical size for image coding, further reduces computational costs. We produce two customized ML-FCTs for lossy and lossless image coding. Numerical simulations show that ML-FFT and ML-FCTs perform comparably to the conventional methods in spite of having fewer operations."
journal_title,Multidimensional Systems and Signal Processing
article_title,A PCA-based approach for brain aneurysm segmentation
keyword,"['Cerebral aneurysm\xa0', 'Segmentation\xa0', 'Contrast enhancement\xa0', 'Stochastic resonance\xa0', 'Kalman filter\xa0', 'Principal component analysis\xa0', 'Level sets\xa0']"
history,"['2018-01', '2016-11-15', '2015-12-22', '2016-11-01', '2016-11-10']"
abstract,"Abstract Segmentation of brain aneurysm is of paramount importance in aneurysm treatment planning. However, the segmentation of intensity varying and low-contrast cerebral blood vessels is an extremely challenging task. In this paper, we present an approach to segmenting the brain vasculature in low contrast computed tomography angiography and magnetic resonance angiography. The main contributions are: (1) a stochastic resonance based methodology in discrete Hartley transform domain is developed to enhance the contrast of a selected angiographic image for patch placement, and (2) a multi-scale adaptive principal component analysis based method is proposed that estimates the phase map of input images. Level-set method is applied to the phase-map data in order to segment the vasculature. We have tested the algorithm on real datasets obtained from two sources, CIBC institute and Hamad Medical corporation. The average Dice coefficient (in %) is found to be \(94.1\pm 1.2\) (value indicates the mean and standard deviation) whereas average false positive ratio, false negative ratio, and specificity are found to be 0.019, \(7.55\times 10^{-3}\), and 0.75, respectively. Average Hausdorff distance between segmented contour and ground truth is determined to be 2.97 mm. The qualitative and quantitative results show promising segmentation accuracy reflecting the potential of the proposed method."
journal_title,Multidimensional Systems and Signal Processing
article_title,Electromagnetic modeling of carbon-fiber reinforced composite materials using the wave digital concept
keyword,"['Carbon fiber reinforced composites\xa0', 'Anisotropic electromagnetic model\xa0', 'Wave digital method\xa0', 'Electrostatic phenomena\xa0', 'Scaled speed of light concept\xa0']"
history,"['2018-01', '2017-01-12', '2016-06-16', '2016-12-13', '2016-12-19']"
abstract,"Abstract This paper deals with the modeling of the carbon fiber composite thin plate exposed to an external electromagnetic field. The underlying anisotropic partial differential equations are solved using the wave digital concept. After an appropriate change of the dependent variables and a coordinate transformation, a multidimensional passive reference circuit is derived along with its wave digital implementation. Numerical results, predicted using the multidimensional wave digital filtering approach, are compared to those obtained using the finite element method. Some stability related aspects are discussed. Besides, an electrostatic application of the presented wave digital model is outlined."
journal_title,Multidimensional Systems and Signal Processing
article_title,Identification of Box–Jenkins models for spatially interconnected systems in closed-loop
keyword,"['Distributed systems control\xa0', 'Control of spatially interconnected systems\xa0', 'Identification of distributed systems\xa0', 'Identification of multi-dimensional systems\xa0', 'Linear systems\xa0']"
history,"['2018-01', '2016-10-25', '2016-06-16', '2016-10-13', '2016-10-20']"
abstract,"Abstract This paper presents an identification method for spatially interconnected distributed systems operating in closed-loop. The proposed approach makes use of refined instrumental variable method to identify spatially interconnected systems in Box–Jenkins form, where the controller is assumed to be known. The method presented here can yields statistically optimal estimates, and compared with other approaches to identify such systems under similar scenarios, takes far less time. The approach is applicable to both separable and non-separable systems and takes into account the boundary conditions. Though described only for two-dimensional systems, it is readily extendible to systems having more spatial dimensions. The effectiveness of the method is shown by a simulation example."
journal_title,Multidimensional Systems and Signal Processing
article_title,Analytical design methods for directional Gaussian 2D FIR filters
keyword,"['2D FIR filters\xa0', 'Analytical design methods\xa0', 'Approximations\xa0', 'Frequency transformations\xa0']"
history,"['2018-01', '2016-10-04', '2015-12-16', '2016-06-18', '2016-09-22']"
abstract,"Abstract This paper proposes two analytical design methods in the frequency domain for directional Gaussian 2D FIR filters, with a straight directional or an elliptically-shaped frequency response and with a specified selectivity and orientation in the frequency plane. One method relies on the substitution of a frequency mapping into the factored polynomial approximation of the Gaussian, while the other one is based on decomposing the frequency response into Gaussian components along three properly chosen directions in the frequency plane. The frequency response of the 2D directional filter results directly in a factored form, which is a major advantage in implementation. The filters are accurate, efficient and they eliminate the necessity of interpolation. With the mapping substitution method, they result also adjustable in orientation and aspect ratio. Several design examples are given for various specifications, and simulation results of directional filtering on test images are provided, to prove their applicability in image processing."
journal_title,Multidimensional Systems and Signal Processing
article_title,Applying a modified version of Lyapunov exponent for cancer diagnosis in biomedical images: the case of breast mammograms
keyword,"['Mean Lyapunov exponent\xa0', 'Two-dimensional mean Lyapunov exponent\xa0', 'Partial differential equations\xa0', 'Breast mammograms\xa0', 'Cancer diagnosis\xa0', 'Computer aided diagnosis\xa0']"
history,"['2018-01', '2016-08-26', '2015-08-23', '2016-07-25', '2016-08-09']"
abstract,"Abstract Recently, there has been a great interest in the application of Lyapunov exponents for calculation of chaos levels in dynamical systems. Accordingly, this study aims at presenting two new methods for utilizing Lyapunov exponents to evaluate the spatiotemporal chaos in various images. Further, early detection of cancerous tumors could be obtained by measuring the chaotic indices in biomedical images. Unlike the available systems described by partial differential equations, the proposed method employs a number of interactive dynamic variables for image modeling. Since the Lyapunov exponents cannot be applied to such systems, the image model should be modified. The mean Lyapunov exponent is defined as a chaotic index for measuring the contour borders irregularities in images to detect benign or malignant tumors. Moreover, a two-dimensional mean Lyapunov exponent is incorporated to identify irregularities existing in each axis of the targeted images. Experiments on a set of region of interest in breast mammogram images yielded a sensitivity of 95 % and a specificity of 97.3 % and verified the remarkable precision of the proposed methods in classifying of breast lesions obtained from breast mammogram images."
journal_title,Multidimensional Systems and Signal Processing
article_title,Wavelet inpainting by fractional order total variation
keyword,"['Fractional order derivative\xa0', 'Total variation\xa0', 'Primal–dual\xa0', 'Wavelet inpainting\xa0']"
history,"['2018-01', '2016-11-29', '2016-02-23', '2016-11-05', '2016-11-16']"
abstract,"Abstract Image inpainting in the wavelet domain refers to the recovery of an image from incomplete wavelet coefficients. In this paper, we propose a wavelet inpainting model by using fractional order total variation regularization approach. Moreover, we use a simple but very efficient primal–dual algorithm to calculate the optimal solution. In the light of saddle-point theory, the convergence of new algorithm is guaranteed. Experimental results are presented to show performance of the proposed algorithm."
journal_title,Multidimensional Systems and Signal Processing
article_title,Speech naturalness improvement via $$\mathrm {\epsilon }$$ϵ-closed extended vectors sets in voice conversion systems
keyword,"['Voice conversion\xa0', 'Spectrum envelope reconstruction\xa0', None, 'Speech synthesis\xa0']"
history,"['2018-01', '2017-01-12', '2016-02-20', '2016-11-06', '2017-01-04']"
abstract,"Abstract In conventional voice conversion methods, some features of a speech signal’s spectrum envelope are first extracted. Then, these features are converted so as to best match a target speaker’s speech by designing and using a set of conversions. Ultimately, the spectrum envelope of the target speaker’s speech signal is reconstructed from the converted features. The spectrum envelope reconstructed from the converted features usually deviates from its natural form. This aberration from the natural form observed in cases such as over-smoothing, over-fitting, and widening of formants is partially caused by two factors: (1) there is an error in the reconstruction of spectrum envelope from the features, and (2) the set of features extracted from the spectrum envelope of the speech signal is not closed. A method is put forward to improve the naturalness of speech by means of \(\epsilon \)-closed sets of extended vectors in voice conversion systems. In this approach, \(\epsilon \)-closed sets to reconstruct the natural spectrum envelope of a signal in the synthesis phase are introduced. The elements of these sets are generated by forming a group of extended vectors of features and applying a quantization scheme on the features of a speech signal. The use of this method in speech synthesis leads to a noticeable reduction of error in spectrum reconstruction from the features. Furthermore, the final spectrum envelope extracted from voice conversions maintains its natural form and, consequently, the problems arising from the deviation of voice from its natural state are resolved. The above method can be generally used as one phase of speech synthesis. It is independent of the voice conversion technique used and its parallel or non-parallel training method, and can be applied to improve the naturalness of the generated speech signal in all common voice conversion methods. Moreover, this method can be used in other fields of speech processing like texts to speech systems and vocoders to improve the quality of the output signal in the synthesis step."
journal_title,Multidimensional Systems and Signal Processing
article_title,Sparse representation based two-dimensional direction of arrival estimation using co-prime array
keyword,"['2D DOA estimation\xa0', 'Co-prime array\xa0', 'Automatically pair matching\xa0', 'Sparse representation\xa0']"
history,"['2018-01', '2016-09-14', '2016-04-06', '2016-07-18', '2016-09-07']"
abstract,"Abstract Direction of arrival (DOA) estimation using co-prime array has been attractive for its potential advantages. A co-prime array consists of two uniform linear arrays (ULAs), where one has M elements with \(N\lambda /2\) being the inter-element spacing, and the other has N (co-prime to M) elements with \(M\lambda /2\) being the inter-element spacing . In this paper, the two ULAs of the co-prime array are placed parallel to each other in the same plane for two-dimensional (2D) DOA estimation, and the uniqueness proof of DOA estimation for this geometry is given. By setting the vectorization of the cross covariance matrix of the two ULAs as an observing vector in sparse representation, MN degrees of freedom (DOF) can be achieved via (\(M+N)\) sensors. Then through the enhanced sparse recovery technique, unique and automatically paired 2D DOA estimation can be obtained from the recovery vector via only 1D dictionary. The proposed algorithm can achieve better DOA estimation performance than conventional algorithms. The simulation results verify the effectiveness of the proposed algorithm."
journal_title,Multidimensional Systems and Signal Processing
article_title,Ellipse fitting via low-rank generalized multidimensional scaling matrix recovery
keyword,"['Generalized multidimensional scaling matrix\xa0', 'Givens transform\xa0', 'Low rank\xa0', 'Nuclear norm minimization\xa0', 'Ellipse fitting algorithm\xa0', 'Alternating direction method of multiplier (ADMM)\xa0', 'Unknown auxiliary parameter (UAP)\xa0']"
history,"['2018-01', '2016-09-16', '2015-12-01', '2016-08-30', '2016-09-07']"
abstract,"Abstract This paper develops a novel ellipse fitting algorithm by recovering a low-rank generalized multidimensional scaling (GMDS) matrix. The main contributions of this paper are: i) Based on the derived Givens transform-like ellipse equation, we construct a GMDS matrix characterized by three unknown auxiliary parameters (UAPs), which are functions of several ellipse parameters; ii) Since the GMDS matrix will have low rank when the UAPs are correctly determined, its recovery and the estimation of UAPs are formulated as a rank minimization problem. We then apply the alternating direction method of multipliers as the solver; iii) By utilizing the fact that the noise subspace of the GMDS matrix is orthogonal to the corresponding manifold, we determine the remaining ellipse parameters by solving a specially designed least squares problem. Simulation and experimental results are presented to demonstrate the effectiveness of the proposed algorithm."
journal_title,Multidimensional Systems and Signal Processing
article_title,Edge detection methods based on modified differential phase congruency of monogenic signal
keyword,"['Hilbert transform\xa0', 'Phase space\xa0', 'Poisson operator\xa0', '44A15\xa0', '70G10\xa0', '35105\xa0']"
history,"['2018-01', '2017-01-03', '2016-06-25', '2016-11-15', '2016-12-23']"
abstract,"Abstract Monogenic signal is regarded as a generalization of analytic signal from one dimensional to higher dimensional space, which has been received considerable attention in the literature. It is defined by an original signal with its isotropic Hilbert transform (the combination of Riesz transform). Similar to analytic signal, the monogenic signal can be written in the polar form. Then it provides the signal features representation, such as the local attenuation and the local phase vector. The aim of the paper is twofold: first, to analyze the relationship between the local phase vector and the local attenuation in the higher dimensional spaces. Secondly, a study on image edge detection using modified differential phase congruency is presented. Comparisons with competing methods on real-world images consistently show the superiority of the proposed methods."
journal_title,Multidimensional Systems and Signal Processing
article_title,Early biological vision inspired system for salience computation in images
keyword,"['Bio-inspired signal processing\xa0', 'Early visual system\xa0', 'Visual salience\xa0', 'Eye fixation\xa0']"
history,"['2018-01', '2016-10-01', '2016-01-11', '2016-07-27', '2016-09-17']"
abstract,"Abstract A bio-inspired salience computation system comprising of novel signal processing modules is proposed in this paper that predicts human eye fixation locations in images. The modules are designed based on evidence from early biological vision. Analysis is carried out to intuitively, theoretically and graphically justify various considerations in the proposed modules. The proposed system concurs with existing feature integration theory and guiding representation based visual processing model. The effectiveness of the proposed salience computation system in generating salience maps closer to human eye fixation density maps is demonstrated by comparing it both qualitatively and quantitatively to other existing state-of-the-art salience computation approaches. Several synthetic images and psychological patterns, and real-life images from four well-known datasets are considered for this purpose."
journal_title,Multidimensional Systems and Signal Processing
article_title,Not all frames are equal: aggregating salient features for dynamic texture classification
keyword,"['Dynamic texture\xa0', 'Dynamic scene\xa0', 'Video description\xa0', 'Salient feature\xa0', 'Local binary patterns on three orthogonal planes (LBP-TOP)\xa0']"
history,"['2018-01', '2016-11-16', '2016-02-22', '2016-08-02', '2016-11-07']"
abstract,"Abstract Many recent studies have proposed methods for the classification of dynamic textures (DT). A method involving local binary patterns on three orthogonal planes (LBP-TOP) has shown promising results and generated considerable interest. However, LBP-TOP and most of its variants suffer from drawbacks caused by the accumulation process in the TOP technique. This process uses features from all frames in the DT sequence, including irrelevant frames, and thus disregards the distinct characteristics of each frame. To overcome this problem, we propose a codebook-based DT descriptor that aggregates salient features on three orthogonal planes. Given a DT sequence, only those frame features that are highly correlated with each cluster are selected and aggregated from the perspective of visual words. The proposed DT descriptor removes the feature from outlier frames that suddenly or rarely appear in a particular context, thus enhancing the emphasis of the salient features. Experimental results using public DT and dynamic scene datasets demonstrate the superiority of the proposed method over comparative approaches. The proposed method also yields outstanding results compared to the state-of-the-art DT representation."
journal_title,Multidimensional Systems and Signal Processing
article_title,A novel adaptive wide-angle SAR imaging algorithm based on Boltzmann machine model
keyword,"['Wide-angle synthetic aperture radar (WSAR)\xa0', 'Sparsity-driven (SD)\xa0', 'Boltzmann machine (BM)\xa0 model\xa0', 'Block-coordinate descent process\xa0']"
history,"['2018-01', '2016-10-01', '2015-09-23', '2016-08-02', '2016-09-23']"
abstract,"Abstract Scattering dependency often exists in both the spatial location and the viewing angle. Based on the assumption of isotropic point scattering model, however, conventional narrow-angle synthetic aperture radar (SAR) imaging algorithms have been no longer suitable to the scattering dependency model. To improve azimuth resolution and capture richer observation information, sparsity-driven (SD) wide-angle SAR (WSAR) imaging algorithms have been developed. Actually, existing SD-based WSAR imaging algorithms are sensitive to the regularization parameters which are required to adjust manually. These methods indeed limit their practical applications. To solve this problem, in this paper, we propose an adaptive WSAR imaging algorithm based on the Boltzmann machine (BM) model. In particular, we model the spatial sparsity and high azimuth correlation of scattering energy by virtual of a special BM prior. Then, the support of sparse representation and imaging parameters including BM parameters, noise variance and the variance of each sparse representation element are jointly estimated by a block-coordinate descent process. Finally, the proposed WSAR imaging algorithm is performed adaptively via sparse representation. Experiments are conducted by synthetic scene and simple tank dataset of high-frequency electromagnetic scattering calculation software. Extensive empirical results demonstrate that the proposed algorithm can achieve better imaging performance than the conventional algorithms in terms of relative mean squared error and support identification error."
journal_title,Multidimensional Systems and Signal Processing
article_title,Color compensation via color-flow representation and eigenspace manifold learning for robust color-invariant face recognition
keyword,"['Color face recognition\xa0', 'Color compensation\xa0', 'Non-controlled illuminants\xa0', 'Color-flow value representation\xa0', 'Eigenspace manifold\xa0', 'Reconstruction\xa0']"
history,"['2018-01', '2016-09-19', '2016-01-17', '2016-06-01', '2016-09-01']"
abstract,"Abstract This paper presents a novel color compensation algorithm for improved color-based face recognition (FR) under non-controlled illuminants. Differing from the previous approaches, the underlying idea behind our method is to take advantage of a pair of the probe and gallery face images available to a typical color FR framework. To this end, a new and novel approach for deriving color-flow value representation and constructing color-flow eigenspace manifold learning has been developed to reliably estimate varying illuminations imposed on probe images. In addition, a sophisticated reconstruction solution has been developed to generate color compensated probe images whose illumination condition becomes much similar to the canonical illumination state of gallery images. Comprehensive and comparative experiments have been performed to demonstrate the effectiveness of our color compensation. For this, both quantitative and qualitative assessments of our method over other state-of-the-art color compensation techniques have been performed. Results  show that our color compensation outperforms other color compensation techniques in terms of compensating color face images with non-linear colored-light and illumination cast shadow. Also, it can be shown that our novel framework that incorporates the proposed color compensation into recently developed color FR algorithms (as premilinary step) can significantly improve FR performances for challenging illuminant face images (with performance gains of up to 26 % for particular cases). The reported work provides a new insight into the merits of color compensation methods, as well as their role in dealing with severe illumination changes in color FR."
journal_title,Multidimensional Systems and Signal Processing
article_title,A visible-light and infrared video database for performance evaluation of video/image fusion methods
keyword,"['Infrared/visible image/video database\xa0', 'Image registration\xa0', 'Image fusion\xa0', 'Camera calibration\xa0']"
history,"['2017-12-27', '2017-03-17', '2017-09-28', '2017-12-20']"
abstract,"Abstract In general, the fusion of visible-light and infrared images produces a composite representation where both data are pictured in a single image. The successful development of image/video fusion algorithms relies on realistic infrared/visible-light datasets. To the best of our knowledge, there is a particular shortage of databases with registered and synchronized videos from the infrared and visible-light spectra suitable for image/video fusion research. To address this need we recorded an image/video fusion database using infrared and visible-light cameras under varying illumination conditions. Moreover, different scenarios have been defined to better challenge the fusion methods, with various contexts and contents providing a wide variety of meaningful data for fusion purposes, including non-planar scenes, where objects appear on different depth planes. However, there are several difficulties in creating datasets for research in infrared/visible-light image fusion. Camera calibration, registration, and synchronization can be listed as important steps of this task. In particular, image registration between imagery from sensors of different spectral bands imposes additional difficulties, as it is very challenging to solve the correspondence problem between such images. Motivated by these challenges, this work introduces a novel spatiotemporal video registration method capable of generating registered and temporally aligned infrared/visible-light video sequences. The proposed workflow improves the registration accuracy when compared to the state-of-the art. By applying the proposed methodology to the recorded database we have generated the visible-light and infrared video database for image fusion, a publicly available database to be used by the research community to test and benchmark fusion schemes."
journal_title,Multidimensional Systems and Signal Processing
article_title,Accelerating near-field 3D imaging approach for joint high-resolution imaging and phase error correction
keyword,"['Near-field 3-D imaging\xa0', 'Compressed sensing (CS)\xa0', 'Fast Gaussian gridding nonuniform fast Fourier transform (FGG-NUFFT)\xa0', 'Phase error\xa0', 'Chaotic measurement matrix\xa0', 'Planar scanning\xa0']"
history,"['2017-12-21', '2016-06-07', '2017-11-24', '2017-12-16']"
abstract,"Abstract The computational complexity and memory requirements of large-scale data seriously affect the application of compressed sensing (CS) in near-field three-dimensional (3-D) imaging system. In addition, as influenced by the measurement environment, the error in echo phase results in imaging defocusing. This paper proposes a CS near-field 3-D imaging approach based on nonuniform fast Fourier transform and phase error correction. It applies the fast Gaussian gridding nonuniform fast Fourier transform technique and Separable Surrogate Functionals with only matrix and vector multiplied to accelerate imaging speed and reduce memory requirements; it adopts the phase error correction technique to realize highly-focused imaging; in addition, a sparse observation approach based on Logistic sequence is proposed in this paper for easy availability of engineering realization for CS imaging. As indicated by numerical analysis and actual measurement in anechoic chamber, the approach proposed in this paper, compared with traditional imaging approaches, has the following advantages: accurate high resolution 3-D image of target can be obtained by applying small amount of observation data (10%); the computational complexity falls from O(LN) to O(3N) and memory occupation quantity drops from O(LN) to O(N); it can effectively perform highly-focused imaging for echo signal with phase error; the measurement matrix designed has better non-coherence and easy availability for engineering realization."
journal_title,Multidimensional Systems and Signal Processing
article_title,Synchronization problem of 2-D coupled dynamical networks with communication delays and missing measurements
keyword,"['Two-dimensional networks\xa0', 'Time-varying communication delay\xa0', 'Mean-square synchronization\xa0', 'Missing measurement\xa0']"
history,"['2017-12-15', '2017-05-04', '2017-12-01', '2017-12-11']"
abstract,"Abstract This study addresses a synchronization problem for an array of discrete-time two-dimensional (2-D) coupled dynamical networks with time-varying communication delays and missing measurements, which is oriented from the well-known Roesser model. For such a 2-D complex network model, both network dynamics and couplings evolve in two independent directions. The missing measurements are described by a binary switching sequence satisfying a conditional probability distribution. The purpose of this study is to establish sufficient easy-to-verify conditions ensuring the global mean-square synchronization through constructing an energy-like Lyapunov–Krasovskii function, making use of the Kronecker product and applying some stochastic analysis techniques. Finally, two simulation examples are presented to illustrate the effectiveness of the proposed synchronization scheme."
journal_title,Multidimensional Systems and Signal Processing
article_title,A matrix-based IRLS algorithm for the least $${l}_{p}$$lp-norm design of 2-D FIR filters
keyword,"['2-D FIR filter\xa0', None, 'Matrix-based algorithm\xa0', 'Iterative reweighted least squares algorithm\xa0']"
history,"['2017-12-15', '2017-05-10', '2017-11-19', '2017-12-11']"
abstract,"Abstract Fast design of two-dimensional FIR filters in the least \({l}_{p}\)-norm sense is investigated in this brief. The design problem is first formulated in a matrix form and then solved by a matrix-based iterative reweighted least squares algorithm. The proposed algorithm includes two loops: one for updating the weighting function and the other for solving the weighted least squares (WLS) subproblems. These WLS subproblems are solved using an efficient matrix-based WLS algorithm, which is an iterative procedure with its initial iterative matrix being the solution matrix in the last iteration, resulting in a considerable CPU-time saving. Through analysis, the new algorithm is shown to have a lower complexity than existing methods. Three design examples are provided to illustrate the high computational efficiency and design precision of the proposed algorithm."
journal_title,Multidimensional Systems and Signal Processing
article_title,Radon-S transform for hypersonic maneuvering target detection
keyword,"['Radon-S transform\xa0', 'Long-time coherent integration\xa0', 'Time–frequency representation\xa0', 'Hypersonic maneuvering target detection\xa0']"
history,"['2017-12-15', '2017-06-09', '2017-12-06', '2017-12-11']"
abstract,"Abstract Hypersonic maneuvering target can cause complex range migration and Doppler frequency migration effects even in a very short time. This brings a big challenge to the common long-time coherent integration based target detection methods. To solve this problem, a novel hypersonic maneuvering target detection method called Radon-S transform is proposed in this paper on the basis of Radon transform and S-transform. It performs the coherent integration along the target track on the time–range plane, and then performs the non-coherent integration along the time–frequency curve of target echo on the time–frequency plane. By combining the two energy integration processes, the signal-to-noise/clutter ratio can be effectively improved. The definition of Radon-S transform, the concrete realization of detection process, and the setting of correlative parameters are introduced in detail. Then the performance of Radon-S transform is analyzed in theory. Finally, numerical experiment results show that the proposed method is superior to some common long-time coherent integration methods in the hypersonic maneuvering target detection."
journal_title,Multidimensional Systems and Signal Processing
article_title,Enhanced hybrid image security algorithms for high definition images in multiple applications
keyword,"['Image processing\xa0', 'Image encryption\xa0', 'Image hiding\xa0', 'Hybrid security system\xa0']"
history,"['2017-12-13', '2015-03-09', '2016-12-02', '2017-12-02']"
abstract,"Abstract Protection of multimedia information from different types of attackers has become important for people and governments. A high definition image has a large amount of data, and thus, keeping it secret is difficult. Another challenge that security algorithms must face with respect to high definition images in medical and remote sensing applications is pattern appearances, which results from existing regions with high density in the same color, such as background regions. An encryption and hiding based new hybrid image security systems are proposed in this paper for the purpose of keeping high definition images secret. First, one hiding method and two encryption methods are used in two hybrid algorithms. The new hiding algorithm proposed here starts by applying reordering and scrambling operations to the six Most Significant Bit planes of the secret image, and then, it hides them in an unknown scene cover image using adding or subtracting operations. Second, two different ciphering algorithms are used to encrypt the stego-image to obtain two different hybrid image security systems. The first encryption algorithm is based on binary code decomposition, while the second algorithm is a modification of an advanced encryption standard. After evaluating each hybrid algorithm alone, a comparison between the two hybrid systems is introduced to determine the best system. Several parameters were used for the performance, including the visual scene, histogram analysis, entropy, security analysis, and execution time."
journal_title,Multidimensional Systems and Signal Processing
article_title,Continuous digital zooming of asymmetric dual camera images using registration and variational image restoration
keyword,"['Digital zooming\xa0', 'Asymmetric dual camera\xa0', 'Registration\xa0', 'Super-resolution\xa0', 'Deconvolution\xa0', 'Blur kernel estimation\xa0']"
history,"['2017-11-30', '2017-03-04', '2017-07-14', '2017-11-21']"
abstract,"Abstract This paper presents a theoretical basis to realize a high-quality digital zooming using two camera modules with different focal lengths. First, we describe an image degradation model of the asymmetric dual camera system to analyze the characteristic of the wide- and tele-view images. In an asymmetric dual camera system, we assume that the shorter focal length module produces the wide-view image with the low-resolution. On the other hand, the longer focal length module produces the tele-view image by an optical zooming. To reconstruct a wide-view image of a continuous digital zooming, the proposed method first estimates the point spread function (PSF) between the wide- and tele-view images. Next, the proposed method performs variational-based image restoration using the estimated PSF. In addition, since the tele-view image inserted into appropriate region of the wide-view image, the proposed method can provide significantly improved wide-view image."
journal_title,Multidimensional Systems and Signal Processing
article_title,A learning-based approach for leaf detection in traffic surveillance video
keyword,"['Leaf detection\xa0', 'Video surveillance\xa0', 'Probabilistic model\xa0', 'Feature extraction\xa0']"
history,"['2017-11-29', '2017-01-19', '2017-06-21', '2017-11-23']"
abstract,"Abstract Traffic surveillance video is recorded in uncontrolled outdoor scenarios. If the camera view gets obstructed by the leaves, the video will fail to be used in vehicle tracking and recognition. It is required that the traffic video surveillance systems run self-checking in order to evaluate if the camera view is blocked by leaves or not. In view of this, a two-step learning framework is proposed in this paper to automatically determine whether the video is leaf degraded or leaf free. First, the proposed framework exploits the convolutional neural network to learn the discriminative features of leaf particles. Then the trained model is used to detect candidate leaf patches in the image. Second, a probabilistic approach is used to pool decisions of each candidate leaf patch to generate final leaf detection result in the video. Experimental results are provided to demonstrate that the proposed approach can effectively detect leaves in real-world traffic surveillance video."
journal_title,Multidimensional Systems and Signal Processing
article_title,A perception based bit allocation for 3DTV broadcasting
keyword,"['Perception-based\xa0', 'Rate control\xa0', 'Rate distortion optimization\xa0', '3DTV\xa0', 'Side-by-side\xa0', 'Top-and-bottom\xa0']"
history,"['2017-11-29', '2016-07-29', '2016-11-22', '2017-11-22']"
abstract,"Abstract Perceptually adaptive bit allocation plays vital roles in efficient rate control to achieve rate distortion optimization in terms of perceptual video coding. This paper proposes a perceptually improved bit allocation scheme by employing a more accurate distortion model inspired by a state-of-the-art perceptual video quality metric. The contributions of this paper mainly involve the following three aspects. Firstly, a perceptual rate-distortion model is developed to shape the framework of perceptual video coding. Secondly, based on the characteristics of the model, an adaptively frame-level bit allocation scheme is proposed using the rate distortion optimization technology. Meanwhile, the status of the encoder buffer is also taken into account to avoid overflow or underflow. Finally, a macroblock-level quantization parameter adjustment is presented to improve perceptual video quality. Experimental results demonstrate that the whole proposed bit allocation scheme achieves better perceptual rate-distortion performance and guarantees the accuracy of rate control well."
journal_title,Multidimensional Systems and Signal Processing
article_title,Eigenvalue trim approach to exact order reduction for roesser state-space model of multidimensional systems
keyword,"['Roesser model\xa0', 'Exact order reduction\xa0', 'Eigenvalue trim approach\xa0', 'Transformation\xa0']"
history,"['2017-11-29', '2017-08-28', '2017-10-22', '2017-11-21']"
abstract,"Abstract In this paper, a new notion of eigenvalue trim or co-trim for n-D Roesser (state-space) model is first introduced, which reveals the internal connection between the eigenvalues of the system matrix and the reducibility of the considered Roesser model. Then, new reducibility conditions and the corresponding order reduction algorithms based on eigenvalue trim or co-trim are proposed for exact order reduction of a given n-D Roesser model, and it will be shown that this eigenvalue trim approach can be applied even to those systems for which the existing approaches cannot do any further order reduction. Furthermore, a new transformation for n-D Roesser models, by swapping certain rows and columns and interchanging certain entries that belong to different blocks corresponding to different variables, will be established, which can transform an n-D Roesser model whose order cannot be reduced any more by the proposed approach to another equivalent Roesser model with the same order so that this transformed Roesser model can still be reduced further. Examples are given to illustrate the details as well as the effectiveness of the proposed approach."
journal_title,Multidimensional Systems and Signal Processing
article_title,A method for informed selection of memory-length and nonlinearity-order parameters in Volterra–Wiener systems from exponential sweep excitations
keyword,"['Nonlinear systems identification\xa0', 'Volterra series representation\xa0', 'Parameters selection\xa0', 'Memory-length\xa0', 'Nonlinearity order\xa0', 'Exponential sweep\xa0']"
history,"['2017-11-27', '2017-04-26', '2017-09-20', '2017-11-21']"
abstract,"Abstract We prove that through the analysis of the static, nonlinear system output to an exponential sweep excitation, it is possible to make an easy and informed estimation of memory-length and nonlinearity order parameters, prior to complete identification. The selection of these parameters has been a matter of discussion for many years since most identification techniques require early estimates of those. This work extends the results of previous contributions concerning a constrained set of memory- and order-fading nonlinear systems with diagonal kernels, onto the more general case of memory- and order-fading nonlinear systems that admit a Volterra series representation. A full mathematical formulation of the system output is provided, based on the input. Estimates on the parameters may be obtained by simple inspection on a single, filtered, output to the exponential sweep excitation. This happens to be a projection of the multidimensional, order kernels, as we prove. Examples are provided to evidence the simplicity and reliability of the proposed method."
journal_title,Multidimensional Systems and Signal Processing
article_title,A wavelet transform based contrast enhancement method for underwater acoustic images
keyword,"['Acoustic images\xa0', 'Discrete wavelet\xa0', 'Laplacian\xa0', 'Stationary wavelet\xa0']"
history,"['2017-11-24', '2017-08-28', '2017-11-13', '2017-11-18']"
abstract,"Abstract Dredging the surface of the ocean to identify both living and non living things nowadays has become an unproblematic task with the help of the acoustic instruments. Side scan sonar is one of such instruments used for far-reaching the seafloor. The sonar captures the scene of the sea bed by releasing fan shaped sound signal which is then converted to images. These images are normally gray scale low contrast images where the objects cannot be viewed clearly. The proposed method uses the Stationary Wavelet Transform (SWT) to decompose the input image into four components such as Low–Low, Low–High, High–Low and High–High components. The low frequency component is sharpened using Laplacian filter and a mask is created by subtracting the LL component with the filtered image. Then the enhanced LL component is obtained by adding the mask to the input image. The high contrast image is reconstructed by applying inverse stationary wavelet transform which combines the enhanced LL component and the other sub-bands. The results have been compared by replacing the SWT with the Discrete Wavelet Transform by interpolating the frequency components. The quantitative and visual results show that the proposed method using SWT outperforms the state of art techniques in terms of contrast."
journal_title,Multidimensional Systems and Signal Processing
article_title,A note on “On the ratio of independent complex Gaussian random variables”
keyword,"['Bessel function\xa0', 'Elementary function\xa0', 'Horn confluent hypergeometric function\xa0']"
history,"['2017-11-23', '2017-09-27', '2017-10-02', '2017-11-21']"
abstract,"Abstract Nadimi et al. (Multidimens Syst Signal Process 2017.  https://doi.org/10.1007/s11045-017-0519-3) studied the distribution of the ratio of two independent complex Gaussian random variables. The expressions provided for the distribution involved a hypergeometric function and an infinite sum. Here, we derive simpler and more manageable expressions. The practical usefulness of the expressions in terms of computational time is illustrated."
journal_title,Multidimensional Systems and Signal Processing
article_title,Color image sharpening based on local color statistics
keyword,"['Color image\xa0', 'Sharpening\xa0', 'Variance\xa0', 'Mean\xa0']"
history,"['2017-11-23', '2017-01-09', '2017-10-13', '2017-11-17']"
abstract,"Abstract This paper presents an effective color image sharpening method, which is based on local color statistics. First, the variance of a set of color samples is measured by a scalar that is computed based on the sum of distances of color vectors, whereas other studies usually treat a color variance as a 3D vector. This is because what a variance expresses is the degree of the deviation of the image (vector) signal from its mean, indicating that describing this degree of deviation by a scalar is reasonable. Then, the local scalar variance and mean vector are combined together to measure the change of color image signal from a pixel to its neighboring ones, and the polarity of the change is determined by the change of luminance. Finally, based on the measure of the change, an effective sharpening operator is developed. Experimental results show that the proposed method excellently sharpens different kinds of color images and at the same time preserves image chromaticity well, and outperforms other typical sharpening techniques in both objective assessment and visual evaluation."
journal_title,Multidimensional Systems and Signal Processing
article_title,An AMBTC compression based data hiding scheme using pixel value adjusting strategy
keyword,"['Data hiding\xa0', 'Pixel value adjusting\xa0', 'Secret data\xa0', 'Stego-image\xa0', 'Absolute moment block truncation coding\xa0']"
history,"['2017-11-18', '2015-12-14', '2016-11-23', '2017-11-11']"
abstract,"Abstract Image steganography is one of the most important research areas of information security where secret data is embedded in the images to conceal its existence while getting the minimum possible statistical detectability. To achieve a good tradeoff between the hiding capacity and image quality, more work needs to be further researched. In this paper, we propose high capacity data hiding scheme by employing the absolute moment block truncation coding (AMBTC) compression. It exploits the redundancy of blocks of the AMBTC-compressed image to embed the secret data. The pixel values of the AMBTC-compressed image are modified at most by one for hiding the secret data. Thus, it is able to maintain the stego-image quality after hiding the secret data. Experimental results validate the effectiveness of the proposed scheme and show that it outperforms various existing methods in terms of both hiding capacity and stego-image quality."
journal_title,Multidimensional Systems and Signal Processing
article_title,The data filtering based generalized stochastic gradient parameter estimation algorithms for multivariate output-error autoregressive systems using the auxiliary model
keyword,"['Parameter estimation\xa0', 'Filtering technique\xa0', 'Multi-innovation identification\xa0', 'Multivariate system\xa0', 'Auxiliary model\xa0']"
history,"['2017-10-31', '2017-04-26', '2017-09-21', '2017-10-24']"
abstract,"Abstract Parameter estimation has wide applications in one-dimensional and multidimensional signal processing and filtering. This paper focuses on the parameter estimation problem of multivariate output-error autoregressive systems. Based on the data filtering technique and the auxiliary model identification idea, we derive a filtering based auxiliary model generalized stochastic gradient algorithm. The key is to choose an appropriate filter to filter the input-output data and to study a novel method to get the system model parameters and noise model parameters respectively. By employing the multi-innovation identification theory, a filtering based auxiliary model multi-innovation generalized stochastic gradient algorithm is proposed. Compared with the auxiliary model generalized stochastic gradient algorithm, the proposed algorithms can generate more accurate parameter estimates. Finally, an illustrative example is provided to verify the effectiveness of the proposed algorithms."
journal_title,Multidimensional Systems and Signal Processing
article_title,Subspace identification for closed-loop 2-D separable-in-denominator systems
keyword,"['Subspace algorithms\xa0', 'Closed-loop 2-D CRSD model identification\xa0', 'The white noise external excitation case\xa0', 'Consistency and efficiency\xa0']"
history,"['2017-10', '2016-06-08', '2015-08-27', '2016-03-11', '2016-05-24']"
abstract,"Abstract Identification for closed-loop two-dimensional (2-D) causal, recursive, and separable-in-denominator (CRSD) systems in the Roesser form is discussed in this study. For closed-loop 2-D CRSD systems, under feedback control condition, there exists some correlation between the unknown disturbances and future inputs which offers the fundamental limitation for utilizing standard open-loop 2-D CRSD systems subspace identification methods. In other words, the existing open-loop subspace approaches will result in biased estimates of plant parameters from closed-loop data. In this study, based on orthogonal projection and principal component analysis, novel 2-D CRSD subspace identification methods are developed, which are applicable to both open-loop and closed-loop data. Additionally, the whiteness external excitation case is discussed and subsequently modified instrument variables are adopted to improve the proposed subspace algorithm. An illustrative example of the injection molding process and several numerical examples are used to validate consistency and efficiency of the proposed subspace approaches for 2-D CRSD systems."
journal_title,Multidimensional Systems and Signal Processing
article_title,Envelope detection using generalized analytic signal in 2D QLCT domains
keyword,"['Quaternion Fourier transform\xa0', 'Quaternion linear canonical transform\xa0', 'Hilbert transform\xa0', 'Analytic signal\xa0', 'Instantaneous amplitude\xa0', '30H05\xa0', '42A50\xa0', '42A38\xa0']"
history,"['2017-10', '2016-04-09', '2015-05-05', '2016-03-11', '2016-03-30']"
abstract,"Abstract The hypercomplex 2D analytic signal has been proposed by several authors with applications in color image processing. The analytic signal enables to extract local features from images. It has the fundamental property of splitting the identity, meaning that it separates qualitative and quantitative information of an image in form of the local phase and the local amplitude. The extension of analytic signal of linear canonical transform domain from 1D to 2D, covering also intrinsic 2D structures, has been proposed. We use this improved concept on envelope detector. The quaternion Fourier transform plays a vital role in the representation of multidimensional signals. The quaternion linear canonical transform (QLCT) is a well-known generalization of the quaternion Fourier transform. Some valuable properties of the two-sided QLCT are studied. Different approaches to the 2D quaternion Hilbert transforms are proposed that allow the calculation of the associated analytic signals, which can suppress the negative frequency components in the QLCT domains. As an application, examples of envelope detection demonstrate the effectiveness of our approach."
journal_title,Multidimensional Systems and Signal Processing
article_title,A subspace ensemble framework for classification with high dimensional missing data
keyword,"['High dimensional data\xa0', 'Missing data\xa0', 'Subspace ensemble\xa0', ' Extreme learning machine\xa0']"
history,"['2017-10', '2016-03-31', '2015-10-13', '2016-02-27', '2016-03-03']"
abstract,"Abstract Real world classification tasks may involve high dimensional missing data. The traditional approach to handling the missing data is to impute the data first, and then apply the traditional classification algorithms on the imputed data. This method first assumes that there exist a distribution or feature relations among the data, and then estimates missing items with existing observed values. A reasonable assumption is a necessary guarantee for accurate imputation. The distribution or feature relations of data, however, is often complex or even impossible to be captured in high dimensional data sets, leading to inaccurate imputation. In this paper, we propose a complete-case projection subspace ensemble framework, where two alternative partition strategies, namely bootstrap subspace partition and missing pattern-sensitive subspace partition, are developed for incomplete datasets with even missing patterns and uneven missing patterns, respectively. Multiple component classifiers are then separately trained in these subspaces. After that, a final ensemble classifier is constructed by a weighted majority vote of component classifiers. In the experiments, we demonstrate the effectiveness of the proposed framework over eight high dimensional UCI datasets. Meanwhile, we apply the two proposed partition strategies over data sets with different missing patterns. As indicated, the proposed algorithm significantly outperforms existing imputation methods in most cases."
journal_title,Multidimensional Systems and Signal Processing
article_title,A fast multichannel SAR raw data simulator of clutter and moving targets
keyword,"['Multichannel SAR\xa0', 'Raw data simulation\xa0', 'Stationary clutter\xa0', 'Moving targets\xa0', 'Clutter suppression\xa0']"
history,"['2017-10', '2016-04-13', '2015-09-18', '2016-01-27', '2016-04-06']"
abstract,"Abstract Accessibility of a fast and accurate multichannel synthetic aperture radar raw data generator of stationary clutter and moving targets has high importance, especially in the application of ground moving target indication. In this paper, a fast four-stage algorithm for generating the raw data of each channel stationary clutter and moving targets, has been proposed respectively in the frequency and the hybrid time–frequency domain. Using this simulator, in different conditions in terms of target motion speed, acceleration and direction, for each of the channels, after generating the raw data, its final image has been extracted by the range-Doppler algorithm. Then, using clutter suppression techniques such as DPCA, ATI and hybrid DPCA–ATI, the multichannel SAR final image has been obtained in ideal and nonideal conditions. Finally, the obtained images of the first channel have been studied using the extracted formulas for predicting the effects of target motion parameters on the SAR images as well as analyzing the multichannel SAR final image. The results show that the proposed algorithm for generating the raw data of each channel stationary clutter and moving targets has better performance in terms of speed and accuracy than the other existing simulators and the proposed multichannel SAR simulation method has high quality."
journal_title,Multidimensional Systems and Signal Processing
article_title,A tool supported approach for brightness preserving contrast enhancement and mass segmentation of mammogram images using histogram modified grey relational analysis
keyword,"['Histogram equalization\xa0', 'Contrast enhancement\xa0', 'Brightness preservation\xa0', 'Image segmentation\xa0', 'Breast cancer\xa0', 'Mammogram\xa0', 'Tool supported approach\xa0']"
history,"['2017-10', '2016-06-13', '2016-01-22', '2016-04-06', '2016-06-03']"
abstract,"Abstract Mammography is a tool that uses X-rays to create mammograms. This tool is mainly used to find early signs of breast cancer. Usually, mammogram image contains region with low contrast and complicated structured background. This may cause difficulties in detection of infected cells in their early stage. Using contrast enhancement of mammogram image we can increase the detection rate of early breast cancer. In this paper we propose a tool supported method named histogram modified grey relational analysis, based on HE with local contrast enhancement for mammogram images. This method enhances local as well as global contrast of given mammogram image and segments breast region in order to obtain better visual interpretation, analysis, and classification of mammogram masses to assist radiologists in making more accurate decisions. The main contribution of this work is to show that better breast-region segmentation results can be achieved from simple breast-region segmentation method if the input image has sufficient contrast with good interpretation of local details. We tested proposed method for MIAS mammogram images. To evaluate effectiveness of proposed method we choose three widely used metrics absolute mean brightness error, structural similarity index measure and peak signal to noise ratio for all 322 images of MIAS mammogram images database."
journal_title,Multidimensional Systems and Signal Processing
article_title,Performance analysis of narrowband beamforming using fully and partial adaptive beamformers with a spherical array
keyword,"['Narrowband beamforming\xa0', 'Partial adaptive beamformer\xa0', 'Fully adaptive beamformer\xa0', 'Spherical array\xa0']"
history,"['2017-10', '2016-04-05', '2015-07-30', '2016-01-14', '2016-03-14']"
abstract,"Abstract This research proposes an improved narrowband partial adaptive beamformer analysis using a proposed spherical array. Comparison between the fully and the partial adaptive beamformers is given. The study is performed by investigating performance parameters like the beamformer output signal-to-noise ratio and the beamformer output signal-to-interference-plus-noise ratio both in the steady state and along adaptation. Furthermore, computational complexity and convergence speed of the proposed sensor arrangement are also analyzed and examples are given. The results demonstrate that this beamformer considerably reduces the number of complex operations and features faster convergence speed."
journal_title,Multidimensional Systems and Signal Processing
article_title,A novel elementary operation approach with Jordan transformation to order reduction for Roesser state-space model
keyword,"['Multidimensional systems\xa0', 'Roesser state-space model \xa0', 'Order reduction\xa0', 'Elementary operation\xa0', None]"
history,"['2017-10', '2016-05-05', '2015-12-28', '2016-04-18', '2016-04-21']"
abstract,"Abstract This paper proposes a novel elementary operation approach to order reduction for the Roesser state-space model of multidimensional (n-D) systems by introducing a new kind of transformation, i.e., the Jordan transformation, which guarantees the establishment of an objective matrix with more general structure than the existing one. Then two basic order reduction techniques are developed which can overcome the difficulty encountered by the existing methods and reveal, for the first time, the fact that the order reduction is still possible even when the column (or row) blocks in the related n-D polynomial matrix are full rank. Furthermore, based on the Jordan transformation, an equivalence relationship between two Roesser models after using the elementary operations among the different blocks will be clarified. Although these operations do not directly lower the total order of the model, the partial orders can be changed so that it may nevertheless yield a possibility for further order reduction. It turns out that this new approach includes our previous elementary operation order reduction approach just as a special case. Examples are given to illustrate the details as well as the effectiveness of the proposed approach."
journal_title,Multidimensional Systems and Signal Processing
article_title,Novel distribution model of transformed coefficients in video coding using quad-tree structured block partitioning
keyword,"['DCT coefficient distribution\xa0', 'Quad-tree structure\xa0', 'HEVC\xa0', 'R-D model\xa0', 'Parameter estimation\xa0', 'Rate control\xa0']"
history,"['2017-10', '2016-06-30', '2015-10-12', '2016-04-16', '2016-06-25']"
abstract,"Abstract Today’s video coding standard such as high efficiency video coding uses a full quad-tree structured block partitioning, so the underlying statistics of transformed coefficients becomes more complicated to estimate than the previous standards due to the coding structure. However, a statistical distribution of transformed residue is important for a design of a smart encoder. Thus, in this paper, we present a theoretic analysis of a distribution of transformed coefficients produced from an encoder using different transform sizes, and derive a probability density function (pdf) for the estimation. The proposed density model provides a more accurate distribution model than the conventional pdfs. Parameters are theoretically estimated, and rate-distortion model is established from the proposed pdf. We also apply the proposed method to a rate control problem to show the efficiency of the proposed density model. Our experimental results show that the proposed method is better capable of modeling the mixed sources of multiple-type transform coefficients occurred from the quad-tree coding structure of transform and provides an accurate estimate in rate control."
journal_title,Multidimensional Systems and Signal Processing
article_title,Sparse support recovery using correlation information in the presence of additive noise
keyword,"['Sparse support recovery\xa0', 'Compressive sensing\xa0', 'Regularization parameter\xa0', 'Noise\xa0', 'LASSO\xa0']"
history,"['2017-10', '2016-05-12', '2016-01-26', '2016-04-10', '2016-05-04']"
abstract,"Abstract The correlation based framework has recently been proposed for sparse support recovery in noiseless case. To solve this framework, the constrained least absolute shrinkage and selection operator (LASSO) was employed. The regularization parameter in the constrained LASSO was found to be a key to the recovery. This paper will discuss the sparse support recoverability via the framework and adjustment of the regularization parameter in noisy case. The main contribution is to provide noise-related conditions to guarantee the sparse support recovery. It is pointed out that the candidates of the regularization parameter taken from the noise-related region can achieve the optimization and the effect of the noise cannot be ignored. When the number of the samples is finite, the sparse support recoverability is further discussed by estimating the recovery probability for the fixed regularization parameter in the region. The asymptotic consistency is obtained in probabilistic sense when the number of the samples tends to infinity. Simulations are given to demonstrate the validity of our results."
journal_title,Multidimensional Systems and Signal Processing
article_title,Finite data performance analysis of a sidelobe canceller
keyword,"['The generalized sidelobe canceller\xa0', 'Adaptive beamforming\xa0', 'The signal-to-interference-plus-noise ratio\xa0', 'The direction-of-arrival\xa0']"
history,"['2017-10', '2016-08-16', '2015-09-28', '2016-08-01', '2016-08-08']"
abstract,"Abstract The performance of the generalized sidelobe canceller (GSC) is affected by the desired signal (DS) even if all signals are uncorrelated with each other when the DS exists in the received array data with finite snapshot number. Under the condition that the DS is blocked totally in the auxiliary array, a novel expression of the weight vector of the GSC, where the auxiliary array is separated from the main array, is derived for the finite data. Based on the new weight vector, the corresponding expressions of the output signal-to-interference-plus-noise ratio (SINR) can be developed for the case that all signals, including the DS and interference signals, are independent with each other. Then, effects on the SINR for some parameters, including the signal-to-noise ratio, the array antenna number, the direction-of-arrival of the interference signal and the interference-to-noise ratio, are studied, respectively. Some guidelines can thus be obtained for the practical application."
journal_title,Multidimensional Systems and Signal Processing
article_title,A geometric approach to fault detection and isolation of multi-dimensional (n-D) systems
keyword,"['Multi-dimensional systems\xa0', 'Fornasini–Marchesini model\xa0', 'Infinite dimensional systems\xa0', 'Fault detection and isolation\xa0', 'Geometric approach\xa0', 'LMI-based observer design\xa0']"
history,"['2017-10', '2016-08-08', '2016-01-23', '2016-05-13', '2016-08-03']"
abstract,"Abstract In this work, we develop a novel fault detection and isolation (FDI) scheme for discrete-time multi-dimensional (n-D) systems for the first time in the literature. These systems represent as generalization of the Fornasini–Marchesini model II two- and three-dimensional (2-D and 3-D) systems. This is accomplished by extending the geometric FDI approach of one-dimensional (1-D) systems to n-D systems. The basic invariant subspaces including unobservable, conditioned invariant and unobservability subspaces of 1-D systems are generalized to n-D models. These extensions have been achieved and facilitated by representing an n-D model as an infinite dimensional system, and by particularly constructing algorithms that compute these subspaces in a finite and known number of steps. By utilizing the introduced subspaces the FDI problem is formulated and necessary and sufficient conditions for its solvability are provided. Sufficient conditions for solvability of the FDI problem for n-D systems using LMI filters are also developed. Moreover, the capabilities and advantages of our proposed approach are demonstrated by performing an analytical comparison with the only currently available 3-D geometric methods in the literature."
journal_title,Multidimensional Systems and Signal Processing
article_title,Narrow-band radar imaging for off-grid spinning targets via compressed sensing
keyword,"['Narrow-band radar imaging\xa0', 'Spinning targets\xa0', 'Off-grid\xa0', 'Compressed sensing (CS)\xa0', 'Orthogonal matching pursuit\xa0']"
history,"['2017-10', '2016-02-20', '2015-07-21', '2016-01-24', '2016-02-10']"
abstract,"Abstract Due to the spinning target’s distribution on a continuous scene, it is impossible to guarantee that all scatterers are located exactly on the pre-discretized grid. Off-grid problem will lead to the mismatch of sensing matrix, which severely affect the performance of conventional narrow-band radar imaging based on compressed sensing. By reformatting the signal model and improving the sparse recovery algorithm, a robust narrow-band radar imaging method for off-grid spinning targets is proposed. Firstly, an imaging model, considering the gridding error, is developed, which is more close to the distribution of real target. Secondly, we put forward an improved orthogonal matching pursuit algorithm for the optimization of reconstruction, and introduce the nonlinear least squares method to further improve the reconstruction accuracy of scatterers. Finally, the effectiveness of the proposed method is verified by simulation and real data, and the selection rule of grid size is presented by quantitative analysis."
journal_title,Multidimensional Systems and Signal Processing
article_title,"Applications of RF aperture-array spatially-bandpass 2-D IIR filters in sub-Nyquist spectrum sensing, wideband doppler radar and radio astronomy beamforming"
keyword,"['Multi-dimensional signal processing\xa0', 'Cognitive radio\xa0', 'EARS\xa0', 'Sub-Nyquist\xa0', 'Localization\xa0', 'Radar\xa0']"
history,"['2017-10', '2016-06-13', '2015-05-26', '2015-12-05', '2016-05-10']"
abstract,"Abstract The application of two-dimensional (2-D) infinite impulse response (IIR) spatially-bandpass (SBP) filters as a digital beamformer for a wide spectrum of practical applications spanning wireless cognitive radio communications, doppler radar, and radio astronomy instrumentation is discussed. The paper starts with an introduction of the recently proposed 2-D SBP filter. The first application is a spectrum sensing scheme for dynamic spectrum access based cognitive radios. A 2-D IIR SBP filter is used in conjunction with a sub-Nyquist wideband signal reconstruction technique to achieve aperture-array directional spectrum sensing using sub-Nyquist sparse sampling based on the recently reported Eldar algorithm. The second application is related to wideband pulse and continuous-wave frequency modulated Doppler radar sensing. The SBP filter is integrated with a wideband radar back-end connected to an electronically-steerable aperture antenna. A a low-complexity directional localization algorithm is presented, which estimates the range and angle of a target scatterer with a signal to interference ratio improvement of 10 dB. We also present applications of 2-D IIR SBP in the fields of classification and remote sensing of unmanned aerial vehicles. Finally, a digital aperture-array wideband beamforming model using the 2-D IIR SBP filters is presented for radio telescope systems based on dense aperture arrays and time-domain beamforming. A well-known example is the study of pulsar astrophysics using a highly-directional aperture antenna system. The 2-D IIR SBP beamformer is simulated as the digital backend of the time-domain beamforming system with array signals synthesized using measured time-domain signatures from the Crab pulsar obtained from the GAVRT. The SBP filter shows a gain of 12.3 dB with an order of magnitude lower circuit complexity compared to traditional phased-array digital beamformers. To obtain comparable levels of SINR improvement, the wideband phased-array beamformers require 48-point FFTs per antenna. Assuming the optimum three real-multiplications per complex multiplication for the Gauss algorithm, it is discovered that the proposed 2-D IIR SBP beamformers are more than 97 % lower in digital multiplier complexity compared to traditional FIR phased-array FFT-beamformers."
journal_title,Multidimensional Systems and Signal Processing
article_title,A new eigenvector selection strategy applied to develop spectral clustering
keyword,"['High-dimensional data\xa0', 'Curse of dimensionality\xa0', 'Spectral clustering\xa0', 'Pattern recognition\xa0']"
history,"['2017-10', '2016-03-07', '2015-07-29', '2016-02-08', '2016-02-25']"
abstract,"Abstract Spectral methods are strong tools that can be used for extraction of the data’s structure based on eigenvectors of constructed affinity matrices. In this paper, we aim to propose some new measurement functions to evaluate the ability of each eigenvector of affinity matrix in data clustering. In the proposed strategy, each eigenvector’s elements are clustered by traditional fuzzy c-means algorithm and then informative eigenvectors selection is performed by optimization of an objective function which defined based on three criterions. These criterions are the compactness of clusters, distance between clusters and stability of clustering to evaluate each eigenvector based on considering the structure of clusters which placed on. Finally, Lagrange multipliers method is used to minimize the proposed objective function and extract the most informative eigenvectors. To indicate the merits of our algorithm, we consider UCI Machine Learning Repository databases, COIL20, YALE-B and PicasaWeb as benchmark data sets. Our simulation’s results confirm the superior performance of the proposed strategy in developing spectral clustering compared to conventional clustering methods and recent eigenvector selection based algorithms."
journal_title,Multidimensional Systems and Signal Processing
article_title,Finite frequency $$H_\infty $$H∞ control of 2-D continuous systems in Roesser model
keyword,"['2-D continuous system\xa0', 'KYP lemma\xa0', 'Finite frequency\xa0', None]"
history,"['2017-10', '2016-06-06', '2016-01-05', '2016-05-25', '2016-05-30']"
abstract,"Abstract This paper investigates the finite frequency (FF) \(H_\infty \) control problem of two-dimensional (2-D) continuous systems in Roesser Model. Our attention is focused on designing state feedback controllers guaranteeing the bounded-input-bounded-output stability and FF \(H_\infty \) performance of the corresponding closed-loop system. A generalized 2-D Kalman-Yakubovich-Popov (KYP) lemma is presented for 2-D continuous systems. By the generalized 2-D KYP lemma, the existence conditions of \(H_\infty \) controllers are obtained in terms of linear matrix inequalities. Two examples are given to validate the proposed methods."
journal_title,Multidimensional Systems and Signal Processing
article_title,Sum and difference coarray based MIMO radar array optimization with its application for DOA estimation
keyword,"['Direction-of-arrival (DOA)\xa0 estimation \xa0', 'Modified minimum redundancy monostatic multiple-input multiple-output (MMRM MIMO)\xa0 radar\xa0', 'Toeplitz approximation method (TAM)\xa0', 'Difference coarray\xa0', 'Sum coarray\xa0']"
history,"['2017-10', '2016-02-27', '2015-05-26', '2016-01-04', '2016-02-16']"
abstract,"Abstract Based on the sum and difference coarrays, multiple-input multiple-output (MIMO) radar with minimum redundancy (MR) concept, referred to as MR MIMO, can considerably increase the spatial degrees of freedom (DOFs). However, traditional MR MIMO needs computational search to determine the position of each element. In this paper, a modified MR monostatic MIMO configuration is proposed, referred to as MMRM MIMO. In the proposed system, the MMRM MIMO radar is consisted of several levels of uniform linear array, which brings the advantage that the position of each element can be determined without computational search. Furthermore, it offers more than \(N^{2}\) DOFs for an N-elemental array. In order to utilize the extended DOFs of MMRM MIMO radar for direction-of-arrival (DOA) estimation, an average Toeplitz approximation method (TAM) is employed, which achieves robust performance even under low signal-to-noise ratio, few snapshots and array error. Numerous simulation results are provided to demonstrate the effectiveness of the proposed method for DOA estimation."
journal_title,Multidimensional Systems and Signal Processing
article_title,On 2D integro-differential systems. Stability and sensitivity analysis
keyword,"['2D integro-differential system\xa0', 'Sensitivity\xa0', 'Robustness\xa0', 'Stability\xa0']"
history,"['2017-10', '2016-08-08', '2016-01-23', '2016-07-04', '2016-08-01']"
abstract,"Abstract In the paper a two-dimensional integro-differential system is considered. Using some variational methods we give sufficient conditions for the existence and uniqueness of a solution to the considered system. Moreover, we show that the system is stable and robust."
journal_title,Multidimensional Systems and Signal Processing
article_title,Optimal design of 2-D FIR digital differentiator using $$L_1$$L1-norm based cuckoo-search algorithm
keyword,"['Finite impulse response\xa0', 'Quadrantally odd symmetric\xa0', '2-D differentiators\xa0', None, 'Cuckoo-search algorithm\xa0']"
history,"['2017-10', '2016-06-18', '2015-12-29', '2016-06-06', '2016-06-08']"
abstract,"Abstract In this article, an optimal design of two-dimensional finite impulse response digital differentiators (2-D FIR-DD) with quadrantally odd symmetric impulse response is presented. The design problem of 2-D FIR-DD is formulated as an optimization problem based on the \(L_1\)-error fitness function. The novel error fitness function is based on the \(L_1\) norm which is unique and is liable to produce a flat response. This design methodology incorporates advantages of \(L_1\)-error approximating function and cuckoo-search algorithm (CSA) which is capable of attaining a global optimal solution. The optimized system coefficients are computed using \(L_1\)-CSA and performance is measured in terms of magnitude response, phase response, absolute magnitude error and elapsed time. Simulation results have been compared with other optimization algorithms such as real-coded genetic algorithm and particle swarm optimization and it is observed that \(L_1\)-CSA delivers optimal results for 2-D FIR-DD design problem. Further, performance of the \(L_1\)-CSA based 2-D FIR-DD design is evaluated in terms of absolute magnitude error and algorithm execution time to demonstrate their effect with variation in the control parameters of CSA."
journal_title,Multidimensional Systems and Signal Processing
article_title,Structural stabilization of linear 2D discrete systems using equivalence transformations
keyword,"['System theory\xa0', 'Algebraic approaches\xa0', 'Multidimensional systems\xa0', 'Discrete systems\xa0', 'Structural stability\xa0', 'Stabilization methods\xa0']"
history,"['2017-10', '2016-07-29', '2016-03-02', '2016-06-16', '2016-07-11']"
abstract,Abstract We consider stability and stabilization issues for linear two-dimensional (2D) discrete systems. We give a general definition of structural stability for all linear 2D discrete systems which coincides with the existing definitions in the particular cases of the classical Roesser and Fornasini–Marchesini discrete models. We study the preservation of the structural stability by equivalence transformations in the sense of the algebraic analysis approach to linear systems theory. This allows us to use recent works both on the stabilization of linear 2D Roesser models and on the equivalence of linear multidimensional systems in order to develop a stabilization method for linear 2D discrete Fornasini–Marchesini models.
journal_title,Cryptography and Communications
article_title,Some bounds on binary LCD codes
keyword,"['Binary LCD codes\xa0', 'Bounds\xa0', 'Linear codes\xa0', '94B05\xa0', '94B65\xa0']"
history,"['2018-07', '2017-09-26', '2017-01-14', '2017-09-14']"
abstract,"Abstract A linear code with a complementary dual (or An LCD code) is defined to be a linear code C whose dual code C ⊥ satisfies C ∩ C ⊥= \(\left \{ \mathbf {0}\right \} \). Let L D (n, k) denote the maximum of possible values of d among [n, k, d] binary LCD codes. We give the exact values of L D (n, k) for k = 2 for all n and some bounds on L D (n, k) for other cases. From our results and some direct search we obtain a complete table for the exact values of L D (n, k) for 1 ≤ k ≤ n ≤ 12. As a consequence, we also derive bounds on the dimensions of LCD codes with fixed lengths and minimum distances."
journal_title,Cryptography and Communications
article_title,The symbol-pair distance distribution of a class of repeated-root cyclic codes over Fpm$\phantom {\dot {i}\!}\mathbb {F}_{p^{m}}$
keyword,"['Symbol-pair codes\xa0', 'Distance distribution\xa0', 'Cyclic codes\xa0', '94B15\xa0', '94B05\xa0']"
history,"['2018-07', '2017-08-09', '2016-07-07', '2017-07-31']"
abstract,"Abstract Symbol-pair codes are proposed to protect against pair errors in symbol-pair read channel. One main task in symbol-pair coding theory is to determine the minimum pair-distance of symbol-pair codes. In this paper, we investigate the symbol-pair distance of cyclic codes of length p  e  over \(\phantom {\dot {i}\!}\mathbb {F}_{p^{m}}\). The exact symbol-pair distance of all cyclic codes of such length is determined."
journal_title,Cryptography and Communications
article_title,Characteristic digit-sum sequences
keyword,"['Nonlinearly filtered LFSR sequences\xa0', 'Linear complexity\xa0', 'Maximum period\xa0', 'Correlation\xa0', '94A55\xa0']"
history,"['2018-07', '2017-09-23', '2016-12-22', '2017-08-29']"
abstract,"Abstract We introduce a new type of sequences using the sum of coefficients of characteristic polynomials for elements (in particular, primitive elements) in a finite field. These sequences are nonlinear filtering sequences of the well-known m-sequences. We show that they have large linear complexity and large period. We also provide some examples of such binary sequences with good autocorrelation values."
journal_title,Cryptography and Communications
article_title,A 2D non-overlapping code over a q-ary alphabet
keyword,"['Bidimensional codes\xa0', 'Non-overlapping matrices\xa0', 'Restricted words\xa0', '68R15\xa0', '94B25\xa0', '05A15\xa0']"
history,"['2018-07', '2017-08-18', '2016-02-18', '2017-08-04']"
abstract,"Abstract We define a set of matrices over a finite alphabet where all possible overlaps between any two matrices are forbidden. The set is also enumerated by providing some recurrences counting particular classes of restricted words. Moreover, we analyze the asymptotic cardinality of the set according to the parameters related to the construction of the matrices."
journal_title,Cryptography and Communications
article_title,A generic method to construct zero-difference balanced functions
keyword,"['Constant weight code\xa0', 'Frequency-hopping sequence\xa0', 'Algebraic integers\xa0', 'Zero-difference balanced function\xa0', '06E30\xa0', '05B10\xa0', '94B25\xa0']"
history,"['2018-07', '2017-07-31', '2016-12-25', '2017-07-24']"
abstract,"Abstract Zero-difference balanced (ZDB) function plays an important role in communication field. In this paper, we propose a generic method to construct ZDB functions on generic algebraic rings. Using this method, we construct many new ZDB functions and retrieve some existing ZDB functions in a much simpler way. Moreover, new applications of the constructed ZDB functions, such as constructing optimal constant weight codes and optimal frequency-hopping sequences, are presented."
journal_title,Cryptography and Communications
article_title,On new quantum codes from matrix product codes
keyword,"['Quantum codes\xa0', 'Matrix product codes\xa0', 'Hermitian construction\xa0', '94B05\xa0', '94B15\xa0']"
history,"['2018-07', '2017-07-14', '2017-01-12', '2017-07-03']"
abstract,"Abstract Quantum error-correcting codes are studied from classical matrix product codes point of view. Two methods to construct quantum codes from matrix product codes are provided. These constructions are applied to obtain numerous new quantum codes, some of them have better parameters than current quantum codes available."
journal_title,Cryptography and Communications
article_title,Exact 2-divisibility of exponential sums associated to boolean functions
keyword,"['2-divisibility\xa0', 'Hamming weight\xa0', 'Exponential sums\xa0', 'Balanced Boolean functions\xa0', 'Reed-Muller codes\xa0', '05E05\xa0', '11T23\xa0', '06E30\xa0']"
history,"['2018-07', '2017-08-15', '2017-02-15', '2017-08-07']"
abstract,"Abstract In this paper we extend the covering method for computing the exact 2-divisibility of exponential sums of Boolean functions, improve results on the divisibility of the Hamming weight of deformations of Boolean functions, and provide criteria to obtain non-balanced functions. In particular, we present criteria to determine cosets of Reed-Muller codes that do not contain any balanced function, and to construct deformations of symmetric functions that are not balanced. The use of the covering method together with classifications of cosets of Reed-Muller codes obtained by the action of linear groups can improve the search of balanced functions in Reed-Muller codes dramatically."
journal_title,Cryptography and Communications
article_title,On ideal t- tuple dis tribu tion of fil tering de Bruijn sequence genera tors
keyword,"['Pseudorandom sequences\xa0', 'Statistical properties\xa0', 'De Bruijn sequences\xa0', 'Composited construction\xa0', '94A60\xa0']"
history,"['2018-07', '2017-08-08', '2016-12-30', '2017-07-28']"
abstract,"Abstract A binary de Bruijn sequence is a sequence of period 2 n  in which every n-tuple occurs exactly once in one period. A de Bruijn sequence is attractive because of having good statistical properties such as long period, balance, high linear complexity and ideal n-tuple distribution. A nonlinear feedback shift register (NLFSR) can be used to generate a de Bruijn sequence. A filtering de Bruijn sequence generator (FDBG) is an NLFSR-based filtering generator constructed by applying a filter function to the internal state of the NLFSR generating a de Bruijn sequence. If the filtering function is balanced, then an FDBG inherits the properties long period, balance, and the lower bound of linear complexity, but its ideal t-tuple distribution property is unknown. In this paper we study ideal t-tuple distribution of filtering de Bruijn (DB) sequence generators. First, we present a construction of a q-ary de Bruijn sequence from a binary de Bruijn sequence. Then, we describe the construction of the FDBG and investigate the ideal t-tuple distribution for two types of the FDBGs. The conditions on the filtering functions for having the ideal t-tuple distribution in the filtering sequences are presented. Finally, we perform an experiment on FDBGs with WG transformations as filtering functions to validate our result and find filtering functions with good cryptographic properties."
journal_title,Cryptography and Communications
article_title,Good integers and some applications in coding theory
keyword,"['Good integers\xa0', 'Abelian codes\xa0', 'Hulls\xa0', 'Euclidean inner product\xa0', 'Hermitian inner product\xa0', '94B15\xa0', '94B60\xa0', '11N25\xa0']"
history,"['2018-07', '2017-08-19', '2017-04-06', '2017-08-14']"
abstract,"Abstract A class of good integers has been introduced by P. Moree in 1997 together with the characterization of good odd integers. Such integers have shown to have nice number theoretical properties and wide applications. In this paper, a complete characterization of all good integers is given. Two subclasses of good integers are introduced, namely, oddly-good and evenly-good integers. The characterization and properties of good integers in these two subclasses are determined. As applications, good integers and oddly-good integers are applied in the study of the hulls of abelian codes. The average dimension of the hulls of abelian codes is given together with some upper and lower bounds."
journal_title,Cryptography and Communications
article_title,"Co nstructio ns with high algebraic degree of differe ntially 4-u niform ( n, n − 1)-fu nctio ns a nd differe ntially 8-u niform ( n, n − 2)-fu nctio ns"
keyword,"['Block ciphers\xa0', 'S-boxes\xa0', 'Vectorial Boolean functions\xa0', 'APN functions\xa0', 'Differentially 4-uniform functions\xa0', 'Primary: 11T71\xa0', '94A60\xa0', 'Secondary: 68P25\xa0']"
history,"['2018-07', '2017-08-01', '2016-12-31', '2017-07-17']"
abstract,"Abstract Quadratic differentially 4-uniform (n, n − 1)-functions are given in Carlet J. Adv. Math. Commun. 9(4), 541–565 (2015) where a question is raised of whether non-quadratic differentially 4-uniform (n, n − 1)-functions exist. In this paper, we give highly nonlinear differentially 4-uniform (n, n − 1)-functions of optimal algebraic degree for both n even and odd. Using the approach in Carlet J. Adv. Math. Commun. 9(4), 541–565 (2015), we construct these functions using two APN (n − 1, n − 1)-functions which are EA-equivalent Inverse functions satisfying some necessary and sufficient conditions when n is even. We slightly generalize the approach to construct differentially 4-uniform (n, n − 1)-functions from two differentially 4-uniform (n − 1, n − 1)-functions satisfying some necessary conditions. This allows us to derive the differentially 4-uniform (n, n − 1)-functions \((x,x_{n})\mapsto (x_{n}+1)x^{2^{n}-2}+x_{n} \alpha x^{2^{n}-2}\), \(x \in \mathbb {F}_{2^{n-1}}\), \(x_{n}\in \mathbb {F}_{2}\), and \(\alpha \in \mathbb {F}_{2^{n-1}}\setminus \mathbb {F}_{2}\), where \(Tr_{1}^{n-1}(\alpha )=Tr_{1}^{n-1}(\frac {1}{\alpha })=1\). These (n, n − 1)-functions are balanced whatever the parity of n is and are then better suited for use as S-boxes in a Feistel cipher. We also give some properties of the Walsh spectrum of these functions to prove that they are CCZ-inequivalent to the differentially 4-uniform (n, n − 1)-functions of the form L ∘ F, where F is a known APN (n, n)-function and L is an affine surjective (n, n − 1)-function. Finally, we also give two new constructions of differentially 8-uniform (n, n − 2)-functions from EA-equivalent Cubic functions and from EA-equivalent Inverse functions."
journal_title,Cryptography and Communications
article_title,The exact autocorrelation distribution and 2-adic complexity of a class of binary sequences with almost optimal autocorrelation
keyword,"['Stream ciphers\xa0', 'Pseudo-random sequences\xa0', 'Autocorrelation\xa0', '2-adic complexity\xa0', '94A55\xa0', '94A60\xa0', '65C10\xa0']"
history,"['2018-05', '2017-06-08', '2017-03-26', '2017-06-01']"
abstract,"Abstract Pseudo-random sequences with good statistical properties, such as low autocorrelation, high linear complexity and large 2-adic complexity, have been used in designing reliable stream ciphers. In this paper, we obtain the exact autocorrelation distribution of a class of binary sequences with three-level autocorrelation and analyze the 2-adic complexity of this class of sequences. Our results show that the 2-adic complexity of such a binary sequence with period N is at least (N + 1) − log2 (N + 1). We further show that it is maximal for infinitely many cases. This indicates that the 2-adic complexity of this class of sequences is large enough to resist the attack of the rational approximation algorithm (RAA) for feedback with carry shift registers (FCSRs)."
journal_title,Cryptography and Communications
article_title,"Generalized nonbinary sequences with perfect autocorrelation, flexible alphabets and new periods"
keyword,"['Feedback shift registers\xa0', 'Sequences\xa0', 'Autocorrelation\xa0', 'Finite fields\xa0', '94A55\xa0', '11T23\xa0', '11T71\xa0', '11B50\xa0']"
history,"['2018-05', '2017-06-29', '2016-12-08', '2017-06-16']"
abstract,"Abstract We extend the parameters and generalize existing constructions of perfect autocorrelation sequences over complex alphabets. In particular, we address the PSK+ constellation (Boztaş and Udaya 10) and present an extended number theoretic criterion which is sufficient for the existence of the new sequences with perfect autocorrelation. These sequences are shown to exist for nonprime alphabets and more general lengths in comparison to existing designs. The new perfect autocorrelation sequences provide novel alternatives for wireless communications and radar system designers for applications in ranging and synchronisation as well as channel identification."
journal_title,Cryptography and Communications
article_title,New results on permutation polynomials of the form ( x pm − x + δ)s + x pm + x over 𝔽 p2m
keyword,"['Finite field\xa0', 'Permutation polynomial\xa0', 'Trace function\xa0', '05A05\xa0', '11T06\xa0', '11T55\xa0']"
history,"['2018-05', '2017-07-05', '2016-07-16', '2017-06-15']"
abstract,"Abstract Permutation polynomials over finite fields have significant applications in coding theory, cryptography, combinatorial designs and many other areas of mathematics and engineering. In this paper, we study the permutation behavior of polynomials with the form \((x^{p^{m}}-x+\delta )^{s}+x^{p^{m}}+x\) over the finite field \(\mathbb {F}_{p^{2m}}\). By using the Akbary-Ghioca-Wang (AGW) criterion, we present several new classes of permutations over \(\mathbb {F}_{p^{2m}}\) based on some bijections over the set \(\{t\in \mathbb {F}_{p^{2m}}|t^{p^{m}}+t=0\}\) or the subfield \(\mathbb {F}_{p^{m}}\)."
journal_title,Cryptography and Communications
article_title,Revisiting RC4 key collision: Faster search algorithm and new 22-byte colliding key pairs
keyword,"['Colliding pair\xa0', 'Key collision\xa0', 'Near colliding pair\xa0', 'RC4\xa0', 'Related key cryptanalysis\xa0', 'Stream cipher\xa0', '94A60\xa0']"
history,"['2018-05', '2017-06-09', '2016-10-18', '2017-05-22']"
abstract,"Abstract If two different secret keys of stream cipher RC4 yield the same internal state after the key scheduling algorithm (KSA) and hence generate the same sequence of keystream bits, they are called a colliding key pair. The number of possible internal states of RC4 stream cipher is very large (approximately 21700), which makes finding key collision hard for practical key lengths (i.e., less than 30 bytes). Matsui (2009) for the first time reported a 24-byte colliding key pair and one 20-byte near-colliding key pair (i.e., for which the state arrays after the KSA differ in at most two positions) for RC4. Subsequently, Chen and Miyaji (2011) designed a more efficient search algorithm using Matsui’s collision pattern and reported a 22-byte colliding key pair which remains the only shortest known colliding key pair so far. In this paper, we show some limitations of both the above approaches and propose a faster collision search algorithm that overcomes these limitations. Using our algorithm, we are able to find three additional 22-byte colliding key pairs that are different from the one reported by Chen and Miyaji. We additionally give 12 new 20-byte near-colliding key pairs. These results are significant, considering the argument by Biham and Dunkelman (2007), that for shorter keys there might be no instances of collision at all."
journal_title,Cryptography and Communications
article_title,"Enumeration formulae for self-dual, self-orthogonal and complementary-dual quasi-cyclic codes over finite fields"
keyword,"['Sesquilinear forms\xa0', 'Totally isotropic spaces\xa0', 'Witt index\xa0', '94B15\xa0']"
history,"['2018-05', '2017-05-17', '2016-09-07', '2017-05-01']"
abstract,"Abstract Let \(\mathbb {F}_{q}\) denote the finite field of order q, and let ℓ,m be positive integers with \(\gcd (m,q)=1.\) In this paper, we enumerate all self-orthogonal, self-dual and complementary-dual ℓ-quasi-cyclic codes of length m ℓ over \(\mathbb {F}_{q}\) by placing the Euclidean inner product on \(\mathbb {F}_{q}^{m\ell }.\) "
journal_title,Cryptography and Communications
article_title,Bounds and constructions for 3¯$\overline {3}$-strongly separable codes with length 3
keyword,"['Multimedia fingerprinting\xa0', 'Separable code\xa0', 'Strongly separable code\xa0', 'Forbidden configuration\xa0', 'Difference matrix\xa0', '94B25\xa0', '68P30\xa0']"
history,"['2018-05', '2017-07-04', '2016-11-17', '2017-06-15']"
abstract,"Abstract Separable code (SC, Cheng and Miao IEEE Trans. Inf. Theory 57, 4843–4851, 2011), frameproof code (FPC, Boneh and Shaw IEEE Trans. Inf. Theory 44, 1897–1905, 1998) and strongly separable code (SSC, Jiang et al. Des. Codes Cryptogr. 79:303–318, 2016) are used to construct anti-collusion codes. SSC is better than FPC and SC in the applications for multimedia fingerprinting since SSC has lower identifying complexity than that of SC (the same complexity as FPC) and weaker structure than that of FPC. In this paper, we first derive several upper bounds on the number of codewords of a \(\overline {t}\)-SSC. Then we focus on \(\overline {3}\)-SSCs with codeword length 3 and obtain the following two main results: (1) An equivalence between an SSC and an SC is derived; (2) An improved lower bound Ω(q 5/3 + q 4/3 − q) on the size of a q-ary SSC when \(q={q_{1}^{6}}\) for any prime power q 1 ≡ 1 (mod 6), which is better than the previously known bound \(\lfloor \sqrt {q}\rfloor ^{3}\), is obtained by means of a difference matrix and a known result on the subsets of \(\mathbb {F}^{n}_{q}\) containing no three points on a line."
journal_title,Cryptography and Communications
article_title,Cyclic codes over a non-commutative finite chain ring
keyword,"['Chain rings\xa0', 'Left (right) cyclic codes\xa0', 'Left (right) dual\xa0', 'Self-dual codes\xa0', 'Torsion codes\xa0', 'Gray map\xa0', 'Primary 11T71\xa0', 'Secondary 94B60\xa0']"
history,"['2018-05', '2017-06-29', '2016-07-14', '2017-06-20']"
abstract,"Abstract In this study, we consider the finite (not necessary commutative) chain ring \(\mathcal {R}:=\mathbb {F}_{p^{m}}[u,\theta ]/{\left < u^{2} \right >}\), where θ is an automorphism of \(\mathbb {F}_{p^{m}}\), and completely explore the structure of left and right cyclic codes of any length N over \(\mathcal {R}\), that is, left and right ideals of the ring \(\mathcal {S}:=\mathcal {R}[x]/{\left < x^{N}-1 \right >}\). For a left (right) cyclic code, we determine the structure of its right (left) dual. Using the fact that self-dual codes are bimodules, we discuss on self-dual cyclic codes over \(\mathcal {R}\). Finally, we study Gray images of cyclic codes over \(\mathcal {R}\) and as some examples, three linear codes over \(\mathbb {F}_{4}\) with the parameters of the best known ones, but with different weight distributions, are obtained as the Gray images of cyclic codes over \(\mathcal {R}\)."
journal_title,Cryptography and Communications
article_title,Two classes of near-optimal frequency-hopping sequence sets with prime-power period
keyword,"['Frequency-hopping sequence\xa0', 'Maximal hamming correlation\xa0', 'Generalized cyclotomy\xa0', '94A55\xa0', '11A41\xa0']"
history,"['2018-05', '2017-05-22', '2016-08-15', '2017-05-09']"
abstract,"Abstract In this paper, a kind of generalized cyclotomy with respect to a prime power is introduced and properties of the corresponding generalized cyclotomic numbers are investigated. Based on the generalized cyclotomy, two classes of frequency-hopping sequence (FHS) sets with prime-power period are presented. Meanwhile, we derive the Hamming correlation distribution of the new FHS sets. The results show that the proposed FHSs and FHS sets have (near-) optimal maximum Hamming correlation (MHC). These classes of near-optimal FHS sets have new parameters which are not covered in the literature."
journal_title,Cryptography and Communications
article_title,On lattice-based algebraic feedback shift registers synthesis for multisequences
keyword,"['Feedback shift registers\xa0', 'Register synthesis\xa0', 'N-adic numbers\xa0', 'Lattices\xa0', '14G50\xa0', '11B37\xa0', '11J13\xa0']"
history,"['2018-05', '2017-05-29', '2016-12-16', '2017-05-21']"
abstract,"Abstract In this paper we show that algebraic feedback shift registers synthesis problems over residue class rings, some ramified extensions and some quadratic integer rings for multisequences are reduced to the successive minima problem in lattice theory. Therefore they can be solved by polynomial-time algorithms since the number of multiple sequences is fixed."
journal_title,Cryptography and Communications
article_title,Permutation polynomials of the form cx+Trql/q(xa)$cx+\text {Tr}_{q^{l}/ q}(x^{a})$ and permutation trinomials over finite fields with even characteristic
keyword,"['Finite fields\xa0', 'Permutation polynomials\xa0', 'Trinomials\xa0', '05A05\xa0', '11T06\xa0', '11T55\xa0']"
history,"['2018-05', '2017-07-01', '2016-11-25', '2017-06-16']"
abstract,"Abstract Permutation polynomials over finite fields constitute an active research area and have applications in many areas of science and engineering. Particularly, permutation polynomials with few terms are more popular for their simple algebraic form and additional extraordinary properties. Very recently, G. Kyureghyan and M.E. Zieve (2016) studied permutation polynomials over \(\mathbb {F}_{q^{n}}\) of the form \(x+\gamma \text {Tr}_{q^{n}/q}(x^{k})\), where q is odd, and nine classes of permutation polynomials were constructed. In this paper, we present fifteen new classes of permutation polynomials of the form \(cx+\text {Tr}_{q^{l}/ q}(x^{a})\) over finite fields with even characteristic, which explain most of the examples with q = 2 k , k > 1, k l < 14 and \(c\in \mathbb {F}_{q^{l}}^{*}\). Furthermore, we also construct four classes of permutation trinomials."
journal_title,Cryptography and Communications
article_title,A lower bound on the 2-adic complexity of the modified Jacobi sequence
keyword,"['Gauss period\xa0', 'Generalized cyclotomic class\xa0', 'Modified Jacobi sequence\xa0', '2-adic complexity\xa0', '11B50\xa0', '94A55\xa0', '94A60\xa0']"
history,"['2018-04-11', '2017-11-03', '2018-03-26']"
abstract,"Abstract Let p, q be distinct primes satisfying gcd(p −  1, q −  1) = d and let D i , i =  0, 1, · · · ,d −  1, be Whiteman’s generalized cyclotomic classes with \(\mathbb {Z}_{pq}^{\ast }=\cup _{i = 0}^{d-1}D_{i}\). In this paper, we give the values of Gauss periods based on the generalized cyclotomic sets \(D_{0}^{\ast }=\cup _{i = 0}^{\frac {d}{2}-1}D_{2i}\) and \(D_{1}^{\ast }=\cup _{i = 0}^{\frac {d}{2}-1}D_{2i + 1}\). As an application, we determine a lower bound on the 2-adic complexity of the modified Jacobi sequence. Our result shows that the 2-adic complexity of the modified Jacobi sequence is at least pq − p − q − 1 with period N = pq. This indicates that the 2-adic complexity of the modified Jacobi sequence is large enough to resist the attack of the rational approximation algorithm (RAA) for feedback with carry shift registers (FCSRs)."
journal_title,Cryptography and Communications
article_title,"Q uant um codes o ver Fp from cyclic codes o ver Fp[ u, v]/〈 u2 − 1, v3 − v, u v − v u〉"
keyword,"['Quantum codes\xa0', 'Cyclic codes\xa0', 'Self-orthogonal codes\xa0', 'Gray map\xa0', '94B05\xa0', '94B15\xa0']"
history,"['2018-04-04', '2018-01-03', '2018-03-21']"
abstract,"Abstract In this paper, quantum codes over F p  from cyclic codes over the ring F p [u, v]/〈u2 − 1, v3 − v, uv − vu〉, where u2 = 1, v3 = v, uv = vu and p is an odd prime have been studied. We give the structure of cyclic codes over the ring F p [u, v]/〈u2 − 1, v3 − v, uv − vu〉 and obtain quantum codes over F p  using self-orthogonal property of these classes of codes. Moreover, by using decomposing method, the parameters of the associated quantum code have been determined."
journal_title,Cryptography and Communications
article_title,The multiplicative complexity of 6-variable Boolean functions
keyword,"['Affine equivalence\xa0', 'Boolean functions\xa0', 'Circuit complexity\xa0', 'Cryptography\xa0', 'Multiplicative complexity\xa0', '94A60\xa0', '06E30\xa0']"
history,"['2018-04-03', '2017-11-01', '2018-03-15']"
abstract,"Abstract The multiplicative complexity of a Boolean function is the minimum number of two-input AND gates that are necessary and sufficient to implement the function over the basis (AND, XOR, NOT). Finding the multiplicative complexity of a given function is computationally intractable, even for functions with small number of inputs. Turan et al. [1] showed that n-variable Boolean functions can be implemented with at most \(n-1\) AND gates for \(n\leq 5\). A counting argument can be used to show that, for n ≥ 7, there exist n-variable Boolean functions with multiplicative complexity of at least n. In this work, we propose a method to find the multiplicative complexity of Boolean functions by analyzing circuits with a particular number of AND gates and utilizing the affine equivalence of functions. We use this method to study the multiplicative complexity of 6-variable Boolean functions, and calculate the multiplicative complexities of all 150 357 affine equivalence classes. We show that any 6-variable Boolean function can be implemented using at most 6 AND gates. Additionally, we exhibit specific 6-variable Boolean functions which have multiplicative complexity 6."
journal_title,Cryptography and Communications
article_title,Small low-depth circuits for cryptographic applications
keyword,"['Circuit size\xa0', 'Circuit depth\xa0', 'Cryptographic functions\xa0', 'Boolean functions\xa0', 'See-saw method\xa0', 'Depth-constrained circuit optimization\xa0', '94C10\xa0']"
history,"['2018-03-24', '2017-09-27', '2018-03-15']"
abstract,"Abstract We present techniques to obtain small circuits which also have low depth. The techniques apply to typical cryptographic functions, as these are often specified over the field G F(2), and they produce circuits containing only AND, XOR and XNOR gates. The emphasis is on the linear components (those portions containing no AND gates). A new heuristic, DCLO (for depth-constrained linear optimization), is used to create small linear circuits given depth constraints. DCLO is repeatedly used in a See-Saw method, alternating between optimizing the upper linear component and the lower linear component. The depth constraints specify both the depth at which each input arrives and restrictions on the depth for each output. We apply our techniques to cryptographic functions, obtaining new results for the S-Box of the Advanced Encryption Standard, for multiplication of binary polynomials, and for multiplication in finite fields. Additionally, we constructed a 16-bit S-Box using inversion in GF(216) which may be significantly smaller than alternatives."
journal_title,Cryptography and Communications
article_title,Several classes of permutation trinomials over F5n$\mathbb {F}_{5^{n}}$ from Niho exponents
keyword,"['Finite fields\xa0', 'Permutation polynomials\xa0', 'Trinomials\xa0', 'Niho exponents\xa0', '05A05\xa0', '11T06\xa0']"
history,"['2018-03-22', '2017-08-03', '2018-03-05']"
abstract,"Abstract The construction of permutation trinomials over finite fields attracts people’s interest recently due to their simple form and some additional properties. Motivated by some results on the construction of permutation trinomials with Niho exponents, in this paper, by constructing some new fractional polynomials that permute the set of the (q + 1)-th roots of unity in \(\mathbb {F}_{q^{2}}\), we present several classes of permutation trinomials with Niho exponents over \(\mathbb {F}_{q^{2}}\), where q = 5 k ."
journal_title,Cryptography and Communications
article_title,Upper bounds and constructions of complete Asynchronous channel hopping systems
keyword,"['Difference set\xa0', 'Hopping sequence\xa0', 'Projective plane\xa0', 'Blind rendezvous\xa0', 'Cognitive radio network\xa0', '05B10\xa0', '94A55\xa0', '94C30\xa0']"
history,"['2018-03-19', '2016-12-06', '2018-03-13']"
abstract,"Abstract Asynchronous channel hopping (ACH) systems are widely used for the blind rendezvous among secondary users in cognitive radio networks without requirement for global synchronization and common control channels. We can view an ACH system with n channels as a set of sequences of a common period t on an alphabet of size n satisfying certain rotation closure properties. For any two distinct sequences u, v in an ACH system \(\mathcal {S}\), every l ∈{0,1,⋯ , t − 1} and any letter j in the alphabet, if there always exists i such that the i-th entries of u and L l (v) are identical to j where L l (v) denotes the cyclic shift of v by l, then we say that \(\mathcal {S}\) is a complete ACH system. Such a system can guarantee rendezvous between any two secondary users who share at least one common channel. It is well known that \(t\geqslant n^{2}\). When the equality holds, \(\mathcal {S}\) is called a perfect ACH system. By applying characters of cyclic groups, we obtain a new upper bound on the number of sequences in a perfect ACH system. Furthermore, when q is a prime power and n = q − 1, we present a construction of homogeneous complete ACH systems of period t = 2n2 + o(n2)."
journal_title,Cryptography and Communications
article_title,Analysis of burn-in period for RC4 state transition
keyword,"['Bias\xa0', 'Burn-in\xa0', 'Cryptography\xa0', 'Random permutation\xa0', 'RC4\xa0', 'State transition\xa0', 'Stream cipher\xa0', '94A60\xa0']"
history,"['2018-03-14', '2017-06-29', '2018-02-21']"
abstract,"Abstract The internal state of RC4 stream cipher is a permutation over \({\mathbb Z}_{N}\) and its state transition is effectively a transposition or swapping of two elements. How the randomness of RC4 state evolves due to its state transitions has been studied for many years. As the number of swaps increases, the state comes closer to a uniform random permutation. We define the burn-in period of RC4 state transition as the number of swaps required to make the state very close to uniform random permutation under some suitably defined distance measure. Earlier, Mantin in his Master’s thesis (2001) performed an approximate analysis of the burn-in period. In this paper, we perform a rigorous analysis of the burn-in period and in the process derive the exact distribution of the RC4 state elements at any stage."
journal_title,Cryptography and Communications
article_title,On the nonlinearity of Boolean functions with restricted input
keyword,"['Boolean functions\xa0', 'Nonlinearity\xa0', 'Walsh Hadamard transform\xa0', 'FLIP cipher\xa0', '11T71\xa0', '11T06\xa0']"
history,"['2018-03-13', '2017-10-30', '2018-03-07']"
abstract,"Abstract Very recently, Carlet, Méaux and Rotella have studied the main cryptographic features of Boolean functions when, for a given number n of variables, the input to these functions is restricted to some subset E of \(\mathbb {F}_{2}^{n}\). Their study includes the particular case when E equals the set of vectors of fixed Hamming weight, which is important in the robustness of the Boolean function involved in the FLIP stream cipher. In this paper we focus on the nonlinearity of Boolean functions with restricted input and present new results related to the analysis of this nonlinearity improving the upper bound given by Carlet et al."
journal_title,Cryptography and Communications
article_title,Compositional inverses of permutation polynomials of t he form xr h( xs) over finite fields
keyword,"['Finite fields\xa0', 'Permutation polynomials\xa0', 'Compositional inverses\xa0', '11T06\xa0']"
history,"['2018-03-13', '2017-07-21', '2018-03-06']"
abstract,"Abstract The study of computing compositional inverses of permutation polynomials over finite fields efficiently is motivated by an open problem proposed by G. L. Mullen (1991), as well as the potential applications of these permutation polynomials (Dillon 1974, Khachatrian and Kyureghyan, Discrete Appl. Math. 216, 622–626 2017, Lidl 1985, Lidl and Müller 1984, Rivest et al., ACM Commun. Comput. Algebra. 1978, 120–126 1976, Schwenk and Huber, Electron. Lett. 34, 759–760 1998). It is well known that every permutation polynomial over a finite field \(\mathbb {F}_{q}\) can be reduced to a permutation polynomial of the form x r h(x s ) with s∣(q − 1) and \(h(x) \in \mathbb {F}_{q}[x]\) (Akbary et al., Finite Fields Appl. 15(2), 195–206 2009, Wang, Finite Fields Appl. 22, 57–69 2013). Recently, several explicit classes of permutation polynomials of the form x r h(x s ) over \({\mathbb F}_{q}\) have been constructed. However, all the known methods to compute the compositional inverses of permutation polynomials of this form seem to be inadequately explicit, which could be a hurdle to potential applications. In this paper, for any prime power q, we introduce a new approach to explicitly compute the compositional inverse of a permutation polynomial of the form x r h(x s ) over \({\mathbb F}_{q}\), where s∣(q − 1) and \(\gcd (r,q-1)= 1\). The main idea relies on transforming the problem of computing the compositional inverses of permutation polynomials over \({\mathbb F}_{q}\) into computing the compositional inverses of two restricted permutation mappings, where one of them is a monomial over \(\mathbb {F}_{q}\) and the other is the polynomial x r h(x) s  over a particular subgroup of \(\mathbb {F}_{q}^{*}\) with order (q − 1)/s. This is a multiplicative analog of Tuxanidy and Wang (Finite Fields Appl. 28, 244–281 2014), Wu and Liu (Finite Fields Appl. 24, 136–147 2013). We demonstrate that the inverses of these two restricted permutations can be explicitly obtained in many cases. As consequences, many explicit compositional inverses of permutation polynomials given in Zieve (Proc. Am. Math. Soc. 137, 2209–2216 2009), Zieve (arXiv:1310.0776, 2013), Zieve (arXiv:1312.1325v3, 2013) are obtained using this method."
journal_title,Cryptography and Communications
article_title,New classes of p-ary bent functions
keyword,"['Subspace sum\xa0', None, 'Affine invariance\xa0', '06E30\xa0', '94C10\xa0']"
history,"['2018-03-07', '2017-10-12', '2018-02-28']"
abstract,"Abstract In this paper, we consider the p-ary functions from \({\mathbb {F}_{p}^{n}}\) to \(\mathbb {F}_{p}\), where p is an odd prime. We characterize the subspace sum concept (depending upon the derivative) and give many of its properties. In particular, we show that the subspace sum of p-ary functions with respect to a subspace of \({\mathbb {F}_{p}^{n}}\) is an affine invariant. Further, we construct two new classes of p-ary bent functions, which do not contain one another."
journal_title,Cryptography and Communications
article_title,Statistical integral distinguisher with multi-structure and its application on AES-like ciphers
keyword,"['Statistical integral model\xa0', 'Multi-structure\xa0', 'Secret S-box\xa0', 'Secret-key\xa0', 'Known-key\xa0', 'AES-like cipher\xa0', '94-XX\xa0', '94A60\xa0']"
history,"['2018-03-03', '2017-06-29', '2018-02-21']"
abstract,"Abstract Integral attack is one of the most powerful tools in the field of symmetric ciphers. In order to reduce the time complexity of original integral one, Wang et al. firstly proposed a statistical integral distinguisher at FSE’16. However, they don’t consider the cases that there are several integral properties on output and multiple structures of data should be used at the same time. In terms of such cases, we put forward a new statistical integral distinguisher, which enables us to reduce the data complexity comparing to the traditional integral ones under multiple structures. As illustrations, we use it into the known-key distinguishers on AES-like ciphers including AES and the permutations of Whirlpool, PHOTON and Grøstl-256 hash functions based on the Gilbert’s work at ASIACRYPT’14. These new distinguishers are the best ones comparing with previous ones under known-key setting. Moreover, we propose a secret-key distinguisher on 5-round AES under chosen-ciphertext mode. Its data, time and memory complexities are 2114.32 chosen ciphertexts, 2110 encryptions and 233.32 blocks. This is the best integral distinguisher on AES with secret S-box under secret-key setting so far."
journal_title,Cryptography and Communications
article_title,A note on the constructions of MDS self-dual codes
keyword,"['MDS codes\xa0', 'Self-dual codes\xa0', 'Generalized Reed-Solomon codes\xa0', '94B05\xa0']"
history,"['2018-03-02', '2017-08-10', '2018-02-25']"
abstract,"Abstract Due to the nice structures of maximum distance separable (MDS) codes and self-dual codes, it is worth studying MDS self-dual codes. It is easy to see that parameters of a MDS self-dual code are completely determined by the code length. The main problem in this topic is to determine existence of q-ary MDS self-dual codes of various lengths. The problem is completely solved when q is even. This paper focuses on the case that q is odd. We generalize the technique in [13] and construct several classes of MDS self-dual codes via generalized Reed-Solomon codes and extended generalized Reed-Solomon codes."
journal_title,Cryptography and Communications
article_title,New bounds on the covering radius of the second order Reed-Muller code of length 128
keyword,"['Reed-Muller codes\xa0', 'Covering radius\xa0', 'Boolean functions\xa0', 'Second-order nonlinearity\xa0', '94B65\xa0']"
history,"['2018-03-02', '2017-11-23', '2018-02-25']"
abstract,"Abstract In 1981, Schatz proved that the covering radius of the binary Reed-Muller code RM(2, 6) is 18. It was previously shown that the covering radius of RM(2, 7) is between 40 and 44. In this paper, we prove that the covering radius of RM(2, 7) is at most 42. As a corollary, we also find new upper bounds for RM(2, n), n = 8, 9, 10. Moreover, we give a sufficient and necessary condition for the covering radius of RM(2, 7) to be equal to 42. Using this condition, we prove that the covering radius of RM(2, 7) in RM(4, 7) is exactly 40, and as a by-product, we conclude that the covering radius of RM(2, 7) in the set of 2-resilient Boolean functions is at most 40, which improves the bound given by Borissov et al. (IEEE Trans. Inf. Theory 51(3):1182–1189, 2005)."
journal_title,Cryptography and Communications
article_title,Classification and Construction of quaternary self-dual bent functions
keyword,"['Boolean functions\xa0', 'Bent functions\xa0', 'Walsh Hadamard transform\xa0', 'Gray map\xa0', 'Rayleigh quotient\xa0', '06E30\xa0']"
history,"['2018-03', '2017-03-14', '2016-11-04', '2017-02-16']"
abstract,"Abstract Quaternary self-dual bent functions are studied from the viewpoints of existence, construction, and symmetry. A search algorithm is described to classify their orbits under the orthogonal group in low dimensions. A connection with self-dual bent Boolean functions shows that they do not exist in odd number of variables."
journal_title,Cryptography and Communications
article_title,The weight distribution of a class of two-weight linear codes derived from Kloosterman sums
keyword,"['Linear codes\xa0', 'Optimal codes\xa0', 'Secret sharing schemes\xa0', 'Authentication codes\xa0', 'Kloosterman sums\xa0', '06E30\xa0', '11T71\xa0', '94A60\xa0']"
history,"['2018-03', '2017-03-15', '2016-10-28', '2017-03-08']"
abstract,"Abstract Linear codes with few weights have applications in data storage systems, secret sharing schemes, and authentication codes. In this paper, a class of p-ary two-weight linear codes is constructed using a generic construction developed by Ding et al. recently, where p is a prime. Their length and weight distribution are closed-form expressions of Kloosterman sums over prime finite fields, and are completely determined when p = 2 and p = 3. The dual of this class of linear codes is also studied and is shown to be optimal or almost optimal in the binary case."
journal_title,Cryptography and Communications
article_title,Modified planar functions and their components
keyword,"[None, None, 'Bent\xa0', 'Negabent\xa0', 'Difference set\xa0', '06E30\xa0', '05B10\xa0']"
history,"['2018-03', '2017-03-06', '2016-02-15']"
abstract,"Abstract Zhou (J. Combin. Des. 21(12), 563–584, 2013) introduced modified planar functions in order to describe (2 n , 2 n , 2 n , 1) relative difference sets R as a graph of a function on the finite field \(\mathbb {F}_{2^{n}}\), and pointed out that projections of R are difference sets that can be described by negabent or bent4 functions, which are Boolean functions given in multivariate form. One of the objectives of this paper is to contribute to the understanding of these component functions of modified planar functions. We identify the versions of the Walsh transforms that apply to modified planar functions on \(\mathbb {F}_{2^{n}}\) and their components, obtain a description of modified planar functions by their components which is similar to that of the classical planar functions in odd characteristic as a vectorial bent function, and point out some further properties of these components. Finally we introduce vectorial bent4 functions (over finite fields), which correspond to relative difference sets in certain groups. We give conditions under which Maiorana-McFarland functions are such functions, hence give rise to relative difference sets in \(\mathbb {Z}_{2}^{n/2}\times \mathbb {Z}_{4}^{n/2}\)."
journal_title,Cryptography and Communications
article_title,"Perfect seque nces over the quater nio ns a nd (4 n, 2, 4 n, 2 n)-relative differe nce sets i n C n × Q8"
keyword,"['Perfect sequences\xa0', 'Relative difference sets\xa0', 'Hadamard matrices\xa0', 'Quaternions\xa0', '05B10\xa0', '05B20\xa0', '05B30\xa0', '94C30\xa0']"
history,"['2018-03', '2017-04-11', '2016-11-01', '2017-04-03']"
abstract,"Abstract Perfect sequences over general quaternions were introduced in 2009 by Kuznetsov. The existence of perfect sequences of increasing lengths over the basic quaternions Q 8 = {±1, ±i, ±j, ±k} was established in 2012 by Barrera Acevedo and Hall. The aim of this paper is to prove a 1–1 correspondence between perfect sequences of length n over Q 8 ∪ q Q 8 with q = (1 + i + j + k)/2, and (4n, 2, 4n, 2n)-relative difference sets in C  n  × Q 8 with forbidden subgroup C 2; here C  m  is a cyclic group of order m. We show that if n = p  a  + 1 for a prime p and integer a ≥ 0 with n ≡ 2 mod 4, then there exists a (4n, 2, 4n, 2n)-relative different set in C  n  × Q 8 with forbidden subgroup C 2. Lastly, we show that every perfect sequence of length n over Q 8 ∪ q Q 8 yields a Hadamard matrix of order 4n (and a quaternionic Hadamard matrix of order n over Q 8 ∪ q Q 8)."
journal_title,Cryptography and Communications
article_title,A sequence construction of cyclic codes over finite fields
keyword,"['Dickson polynomial\xa0', 'Cyclic code\xa0', 'Linear code\xa0', 'Planar function\xa0', 'Sequence\xa0', '94B15\xa0', '94B05\xa0', '94A55\xa0', '11B83\xa0']"
history,"['2018-03', '2017-04-01', '2016-12-01', '2017-03-17']"
abstract,"Abstract Due to their efficient encoding and decoding algorithms, cyclic codes, a subclass of linear codes, have applications in communication systems, consumer electronics, and data storage systems. There are several approaches to constructing all cyclic codes over finite fields, including the generator matrix approach, the generator polynomial approach, and the generating idempotent approach. Another one is a sequence approach, which has been intensively investigated in the past decade. The objective of this paper is to survey the progress in this direction in the past decade. Many open problems are also presented in this paper."
journal_title,Cryptography and Communications
article_title,Construction of de Bruijn sequences from product of two irreducible polynomials
keyword,"['Binary periodic sequence\xa0', 'De Bruijn sequence\xa0', 'Cycle structure\xa0', 'Adjacency graph\xa0', 'Cyclotomic number\xa0', '11B50\xa0', '94A55\xa0', '94A60\xa0']"
history,"['2018-03', '2017-03-08', '2016-09-13', '2017-02-26']"
abstract,"Abstract We study a class of Linear Feedback Shift Registers (LFSRs) with characteristic polynomial f(x) = p(x)q(x) where p(x) and q(x) are distinct irreducible polynomials in 𝔽2[x]. Important properties of the LFSRs, such as the cycle structure and the adjacency graph, are derived. A method to determine a state belonging to each cycle and a generic algorithm to find all conjugate pairs shared by any pair of cycles are given. The process explicitly determines the edges and their labels in the adjacency graph. The results are then combined with the cycle joining method to efficiently construct a new class of de Bruijn sequences. An estimate of the number of resulting sequences is given. In some cases, using cyclotomic numbers, we can determine the number exactly."
journal_title,Cryptography and Communications
article_title,Binary linear codes with two or three weights from niho exponents
keyword,"['Linear code\xa0', 'Niho exponent\xa0', 'Secret sharing scheme\xa0', 'Weight distribution\xa0', 'Strongly regular graph\xa0', '94B15\xa0', '11T71\xa0']"
history,"['2018-03', '2017-03-17', '2016-07-12', '2017-03-08']"
abstract,"Abstract Linear codes with few weights have applications in secret sharing, authentication codes, association schemes, date storage systems, strongly regular graphs and some other fields. In this paper, we present several classes of binary linear codes with two or three weights and study their weight distributions. Two classes of strongly regular graphs are constructed from binary linear codes with two weights. Numerical results show that some of the obtained codes are either optimal or near optimal with respect to certain bounds on linear codes."
journal_title,Cryptography and Communications
article_title,Matrix parametrized shift registers
keyword,"['Linear feedback shift register\xa0', 'Feedback with carry shift register\xa0', 'Sequence\xa0', 'Matrix algebra\xa0', 'Stream cipher\xa0', '94A55\xa0']"
history,"['2018-03', '2017-04-28', '2016-12-14', '2017-04-10']"
abstract,"Abstract High speed pseudorandom sequence generators have played roles in an array of applications in communications, cryptography, and computing. At the heart of many of these generators are shift registers of various types. Researchers have studied linear feedback shift registers (LFSRs), feedback with carry shift registers (FCSRs), and various generalizations such as ring FCSRS and algebraic feedback shift registers. The analysis of these sequence generators typically proceeds by defining an algebraic structure on the set of infinite output sequences, based on a choice of uniformizing parameter (e.g., power series for LFSRs, N-adic numbers for FCSRs). In this paper we introduce a new generalization of FCSRs in which the uniformizing parameter \(N\in \mathbb {Z}\) is replaced by a square matrix, T, resulting in what we call T-generators. We describe an algebraic structure, the T-adic numbers, and use it to study the periodicity of T-generators."
journal_title,Cryptography and Communications
article_title,Quadratic residue codes over the ring 𝔽p[u]/〈um−u〉$\mathbb {F}_{p}[u]/\langle u^{m}-u\rangle $ and their Gray images
keyword,"['Self-dual and self-orthogonal codes\xa0', 'Formally self-dual codes\xa0', 'Gray map\xa0', 'Quadratic residue codes\xa0', 'Extended QR-codes\xa0', '11T71\xa0', '94B15\xa0']"
history,"['2018-03', '2017-04-06', '2016-06-20', '2017-03-23']"
abstract,"Abstract Let m ≥ 2 be any natural number and let \(\mathcal {R}=\mathbb {F}_{p}+u\mathbb {F}_{p}+u^{2}\mathbb {F}_{p}+\cdots +u^{m-1}\mathbb {F}_{p}\) be a finite non-chain ring, where u  m  = u and p is a prime congruent to 1 modulo (m − 1). In this paper we study quadratic residue codes over the ring \(\mathcal {R}\) and their extensions. A Gray map from \(\mathcal {R}^{n}\) to \((\mathbb {F}_{p}^{m})^{n}\) is defined which preserves self duality of linear codes. As a consequence, we construct self-dual, formally self-dual and self-orthogonal codes over \(\mathbb {F}_{p}\). To illustrate this, several examples of self-dual, self-orthogonal and formally self-dual codes are given. Among others a [9,3,6] linear code over \(\mathbb {F}_{7}\) is constructed which is self-orthogonal as well as nearly MDS. The best known linear code with these parameters (ref. Magma) is not self-orthogonal."
journal_title,Cryptography and Communications
article_title,Message Authentication Based on Cryptographically Secure CRC without Polynomial Irreducibility Test
keyword,"['Message authentication\xa0', 'Hash function\xa0', 'CRC\xa0', 'LFSR\xa0', '94A60\xa0', '94A62\xa0']"
history,"['2018-03', '2017-04-29', '2016-12-19', '2017-04-10']"
abstract,"Abstract In this paper, we present a message authentication scheme based on cryptographically secure cyclic redundancy check (CRC). Similarly to previously proposed cryptographically secure CRCs, the presented one detects both random and malicious errors without increasing bandwidth. The main difference from previous approaches is that we use random instead of irreducible generator polynomials. This eliminates the need for irreducibility tests. We provide a detailed quantitative analysis of the achieved security as a function of message and CRC sizes. The results show that the presented scheme is particularly suitable for the authentication of short messages."
journal_title,Cryptography and Communications
article_title,On affine variety codes from the Klein quartic
keyword,"['Affine variety codes\xa0', 'Gröbner basis\xa0', 'Klein curve\xa0']"
history,"['2018-02-19', '2017-09-28', '2018-02-07']"
abstract,"Abstract We study a family of primary affine variety codes defined from the Klein quartic. The duals of these codes have previously been treated in Kolluru et al., (Appl. Algebra Engrg. Comm. Comput. 10(6):433–464, 2000, Ex. 3.2). Among the codes that we construct almost all have parameters as good as the best known codes according to Grassl (2007) and in the remaining few cases the parameters are almost as good. To establish the code parameters we apply the footprint bound (Geil and Høholdt, IEEE Trans. Inform. Theory 46(2), 635–641, 2000 and Høholdt 1998) from Gröbner basis theory and for this purpose we develop a new method where we inspired by Buchberger’s algorithm perform a series of symbolic computations."
journal_title,Cryptography and Communications
article_title,More classes of permutation trinomials with Niho exponents
keyword,"['Finite field\xa0', 'Permutation polynomial\xa0', 'Niho exponent\xa0', '05A05\xa0', '11T06\xa0', '11T55\xa0']"
history,"['2018-02-08', '2017-07-03', '2018-01-26']"
abstract,"Abstract This paper presents two classes of permutation trinomials with the form \(x^{s(2^{m}-1)+ 1}+x^{t(2^{m}-1)+ 1}+x\) over the finite field \( \mathbb {F}_{2^{2m}}\) as a supplement of the recent works of Li and Helleseth, and a class of permutation trinomials like this form over \( \mathbb {F}_{3^{2m}}\). Moreover, we give a method to construct permutation polynomials from known ones."
journal_title,Cryptography and Communications
article_title,Statistical attacks on cookie masking for RC4
keyword,"['RC4 stream cipher\xa0', 'Statistical analysis\xa0', 'Masking\xa0', '94A60\xa0', '68P25\xa0']"
history,"['2018-02-06', '2017-08-15', '2018-01-10']"
abstract,"Abstract Levillain et al. (Asia CCS 2015) proposed two cookie masking methods, TLS Scramble and MCookies, to counter a class of attacks on SSL/TLS in which the attacker is able to exploit its ability to obtain many encryptions of a target HTTP cookie. In particular, the masking methods potentially make it viable to continue to use the RC4 algorithm in SSL/TLS. In this paper, we provide a detailed analysis of TLS Scramble and MCookies when used in conjunction with RC4 in SSL/TLS. We show that, in fact, both are vulnerable to variants of the known attacks against RC4 in SSL/TLS exploiting the Mantin biases (Mantin, EUROCRYPT 2005): 
 For the TLS Scramble mechanism, we provide a detailed statistical analysis coupled with extensive simulations that show that about 237 encryptions of the cookie are sufficient to enable its recovery.  For the MCookies mechanism, our analysis is made more complex by the presence of a Base64 encoding step in the mechanism, which (unintentionally) acts like a classical block cipher S-box in the masking process. Despite this, we are able to develop a maximum likelihood analysis which provides a rigorous statistical procedure for estimating the unknown cookie. Based on simulations, we estimate that 245 encryptions of the cookie are sufficient to enable its recovery. Taken together, our analyses show that the cookie masking mechanisms as proposed by Levillain et al. only moderately increase the security of RC4 in SSL/TLS."
journal_title,Cryptography and Communications
article_title,On APN functions L1( x3) + L2( x9) with linear L1 and L2
keyword,"['Boolean function\xa0', 'Almost perfect nonlinear\xa0', 'CCZ-equivalence\xa0', 'Nonlinearity\xa0', '94A60\xa0', '06E30\xa0', '20B40\xa0']"
history,"['2018-02-05', '2017-11-13', '2018-01-22']"
abstract,"Abstract In a recent paper by L. Budaghyan, C. Carlet, and G. Leander (2009) it is shown that functions of the form L1(x3) + L2(x9), where L1 and L2 are linear, are a good source for construction of new infinite families of APN functions. In the present work we study necessary and sufficient conditions for such functions to be APN."
journal_title,Cryptography and Communications
article_title,Bent functions from nonlinear permutations and conversely
keyword,"['Nonlinear permutations\xa0', 'Bent functions\xa0', 'Maiorana-McFarland class\xa0', 'Affine equivalence\xa0', '94A60\xa0', '06E30\xa0']"
history,"['2018-02-02', '2017-06-26', '2018-01-22']"
abstract,"Abstract This work extends the idea introduced by Hou and Langevin (J. Combin. Theory, Ser. A, 80:232–246, 1997) of applying nonlinear permutations to (a portion of) the input variable space of a given Boolean function so that the resulting function is bent. Applying such a permutation to a bent function that can be represented in a suitable form then gives an affine inequivalent bent function which potentially does not belong to the same class as the original one. While Hou and Langevin only provided two sporadic examples of bent functions that can be turned into affine inequivalent ones, in this article we identify two generic families of bent functions suitable for generating such affine inequivalent counterparts. The same method when applied to the Marioana-McFarland class of bent functions, depending on the subset of inputs to which a nonlinear action is applied, either lead to bent functions that are provably within the same class or to bent functions that are potentially outside this class. The problem of finding suitable permutations that act nonlinearly on more than two input variables of the initial function and ensure the bentness of the resulting function appears to be generally hard. In this direction, we only slightly extend the approach of Hou and Langevin by identifying suitable permutations that act nonlinearly on three input variabl es. Most notably, the existence of nonlinear permutations that act without strict separation of the input space in terms of linear and nonlinear action is also confirmed. Finally, we show a direct correspondence between (some classes of) bent functions and permutations by providing an efficient method to define permutations using the derivatives of a given bent function. This not only gives a relationship between two seemingly different algebraic objects, but also provides us with a new infinite family of permutations over finite fields."
journal_title,Cryptography and Communications
article_title,Some new balanced and almost balanced quaternary sequences with low autocorrelation
keyword,"['Periodic sequence\xa0', 'Quaternary sequence\xa0', 'Periodic autocorrelation\xa0', 'Linear complexity\xa0', '05B10\xa0', '05B30\xa0', '11T22\xa0', '94A55\xa0', '94C30\xa0']"
history,"['2018-01-29', '2017-07-13', '2018-01-18']"
abstract,"Abstract Quaternary sequences of both even and odd period having low autocorrelation are studied. We construct new families of balanced quaternary sequences of odd period and low autocorrelation using cyclotomic classes of order eight, as well as investigate the linear complexity of some known quaternary sequences of odd period. We discuss a construction given by Chung et al. in “New Quaternary Sequences with Even Period and Three-Valued Autocorrelation” (IEICE Trans. Fundam. Electron. Commun. Comput. Sci. E93-A(1), 309–315 2010) first by pointing out a slight modification and then by showing that, in certain cases, this slight modification generalizes the construction given by Shen et al. in “New Families of Balanced Quaternary Sequences of Even Period with Three-level Optimal Autocorrelation” (IEEE Commun. Lett. 2017(10), 2146–2149 2017). We investigate the linear complexity of these sequences as well."
journal_title,Cryptography and Communications
article_title,Injectivity on distribution of elements in the compressed sequences derived from primitive sequences over ℤpe$\mathbb {Z}_{p^{e}}$
keyword,"['Residue ring\xa0', 'Primitive sequence\xa0', 'Compressing mapping\xa0', 'Uniformity\xa0', 'Equivalence closure\xa0', '94A55\xa0', '11B50\xa0', '11T71\xa0']"
history,"['2018-01-20', '2017-03-31', '2017-12-19']"
abstract,"Abstract Let p ≥ 3 be a prime, e ≥ 2 an integer and \(\mathbb {Z}_{p^{e}}\) the residue ring modulo p e . Let σ(x) be a primitive polynomial of degree n over \(\mathbb {Z}_{p^{e}}\) and let G′(σ(x), p e ) be the set of primitive linear recurring sequences over \(\mathbb {Z}_{p^{e}}\) generated by σ(x). A compressing mapping \(\varphi :\mathbb {Z}_{p^{e}}\rightarrow \mathscr {A}\) naturally induces a mapping \(\widehat {\varphi }\) on G ′(σ(x), p e ), i.e., \(\widehat {\varphi }\) maps a sequence (…,si− 1,s i ,si+ 1,… ) to (…,φ(si− 1),φ(s i ),φ(si+ 1),… ). For any pair of sequences in \(\{\widehat {\varphi }(\underline {s}):\underline {s}\in G^{\prime }_{~}(\sigma (x),p^{e})\}\), it is desirable to determine whether (at least) one element of \(\mathscr {A}\) is distributed differently in them. For \(\emptyset \neq D\subseteq \mathscr {A}\), \(\widehat {\varphi }\) is said to be injective on G ′(σ(x), p e ) w.r.t. D-uniformity if for any two distinct sequences \(\underline {u},\underline {v}\in G^{\prime }_{~}(\sigma (x),p^{e})\), the distribution of at least one element of D in \(\widehat {\varphi }(\underline {u})\) differs from that in \(\widehat {\varphi }(\underline {v})\). A sufficient condition on φ is given to ensure that \(\widehat {\varphi }\) is injective on G ′(σ(x), p e ) w.r.t. D-uniformity. If \(\left (\left ((x^{p^{n}-1}-1)^{2}\bmod \sigma (x)\right ) \bmod p^{3}\right ) \notin p^{2}\mathbb {Z}_{p}\), then an equivalent condition on φ is obtained to decide whether \(\widehat {\varphi }\) is injective on G ′(σ(x), p e ) w.r.t. D-uniformity. Furthermore, quantitative estimation suggests that almost all mappings on \(\mathbb {Z}_{p^{e}}\) induce injective mappings on G ′(σ(x), p e ) as p and e increase."
journal_title,Cryptography and Communications
article_title,A note on the chi-square method: A tool for proving cryptographic security
keyword,"['Random permutation\xa0', 'pseudorandom function\xa0', None, 'KL divergence\xa0', 'Total variation distance\xa0', 'Pinsker’s inequality\xa0', 'Sum of random permutation\xa0', 'Truncated random permutation\xa0', '62P30\xa0', '60C05\xa0', '68R01\xa0']"
history,"['2018-01-16', '2017-07-31', '2017-12-10']"
abstract,"Abstract Very recently (in CRYPTO 2017) Dai, Hoang, and Tessaro have introduced the Chi-square method (χ2 method) which can be applied to obtain an upper bound on the statistical distance between two joint probability distributions. The authors have applied this method to prove the pseudorandom function security (PRF-security) of sum of two random permutations. In this work, we revisit their proof and find a non-trivial gap in the proof. We plug this gap for two specific cases and state the general case as an assumption whose proof is essential for the completeness of the proof by Dai et al.. A complete, correct, and transparent proof of the full security of the sum of two random permutations construction is much desirable, especially due to its importance and two decades old legacy. The proposed χ2 method seems to have potential for application to similar problems, where a similar gap may creep into a proof. These considerations motivate us to communicate our observation in a formal way. On the positive side, we provide a very simple proof of the PRF-security of the truncated random permutation construction (a method to construct PRF from a random permutation) using the χ2 method. We note that a proof of the PRF-security due to Stam is already known for this construction in a purely statistical context. However, the use of the χ2 method makes the proof much simpler."
journal_title,Cryptography and Communications
article_title,Universal secure rank-metric coding schemes with optimal communication overheads
keyword,"['Communication overheads\xa0', 'Crisscross error-correction\xa0', 'Decoding bandwidth\xa0', 'Information-theoretical security\xa0', 'Rank-metric codes\xa0', '94A60\xa0', '94A62\xa0', '94B99\xa0']"
history,"['2018-01-13', '2017-08-25', '2018-01-02']"
abstract,"Abstract We study the problem of reducing the communication overhead from a noisy wire-tap channel or storage system where data is encoded as a matrix, when more columns (or their linear combinations) are available. We present its applications to reducing communication overheads in universal secure linear network coding and secure distributed storage with crisscross errors and erasures and in the presence of a wire-tapper. Our main contribution is a method to transform coding schemes based on linear rank-metric codes, with certain properties, to schemes with lower communication overheads. By applying this method to pairs of Gabidulin codes, we obtain coding schemes with optimal information rate with respect to their security and rank error correction capability, and with universally optimal communication overheads, when n ≤ m, being n and m the number of columns and number of rows, respectively. Moreover, our method can be applied to other families of maximum rank distance codes when n > m. The downside of the method is generally expanding the packet length, but some practical instances come at no cost."
journal_title,Cryptography and Communications
article_title,Several new classes of linear codes with few weights
keyword,"['Linear codes\xa0', 'Weight distribution\xa0', 'Gauss sum\xa0', '94B05\xa0', '94B15\xa0']"
history,"['2018-01-11', '2017-07-24', '2017-12-17']"
abstract,"Abstract Let \(\phantom {\dot {i}\!}\mathbb {F}_{q}\) be a finite field of order q, where q = p s  is a power of a prime number p. Let m and m1 be two positive integers such that m1 divides m. For any positive divisor e of q − 1, we construct an infinite family of codes with dimension m + m1 and few weights over \(\phantom {\dot {i}\!}\mathbb {F}_{q}\). Using Gauss sum, their weight distributions are provided. When gcd(e, m) = 1, we obtain a subclass of optimal codes which attain the Griesmer bound. Moreover, when gcd(e, m) = 2 or 3 we construct new infinite families of codes with at most four weights."
journal_title,Cryptography and Communications
article_title,On rate-1 and beyond-the-birthday bound secure online ciphers using tweakable block ciphers
keyword,"['Provable security\xa0', 'Online cipher\xa0', 'Tweakable block cipher\xa0', None, None, None, '94A60\xa0']"
history,"['2018-01-06', '2017-07-30', '2017-12-10']"
abstract,"Abstract Recently, Andreeva et al. showed that online ciphers are actually equivalent to arbitrary tweak length (ATL) tweakable block ciphers (TBCs). Within this result they gave a security preserving generic conversion from ATL TBCs to online ciphers. XTX by Minematsu and Iwata is a nice way of extending the tweak space of any fixed tweak length (FTL) TBC using a pAXU hash function. By combining the previous two methods one can get a FTL TBC based online cipher with security in the order of σ2ε where σ is the total number of blocks in all queries, and ε is the pAXU bound of the underlying hash function. In this paper we show that there are genuine practical issues which render it almost impossible to get full security using this approach. We then observe that a recent online enciphering scheme called POEx by Forler et al. is actually an implicit example of this approach. We show a flaw in the analysis of POEx which results in a birthday bound attack and invalidates the beyond-the-birthday bound OSPRP security claim. We take a slightly different approach then the one just mentioned and propose XTC which achieves OSPRP security of O(max(nσ2−n, σ22−(n + t))) where t is the tweak size and n is the block size. While doing so we present an impossibility result for t > n which can be of independent interest."
journal_title,Cryptography and Communications
article_title,Missing a trick: Karatsuba variations
keyword,"['Public key cryptography\xa0', 'Implementation\xa0', '97F90\xa0', '97F40\xa0', '68W40\xa0', '11Y16\xa0']"
history,"['2018-01', '2017-03-07', '2016-11-02', '2017-02-20']"
abstract,"Abstract There are a variety of ways of applying the Karatsuba idea to multi-digit multiplication. These apply particularly well in the context where digits do not use the full word-length of the computer, so that partial products can be safely accumulated without fear of overflow. Here we re-visit the “arbitrary degree” version of Karatsuba and show that the cost of this little-known variant has been over-estimated in the past. We also attempt to definitively answer the question as to the cross-over point where Karatsuba performs better than the classic method."
journal_title,Cryptography and Communications
article_title,Backtracking-assisted multiplication
keyword,"['Multiplication\xa0', 'Integer arithmetics\xa0', 'Backtracking\xa0', '90-08\xa0', '90C39\xa0', '90C90\xa0']"
history,"['2018-01', '2017-09-05', '2016-11-25', '2017-08-13']"
abstract,"Abstract This paper describes a new multiplication algorithm, particularly suited to lightweight microprocessors when one of the operands is known in advance. The method uses backtracking to find a multiplication-friendly encoding of the operand known in advance. A 68hc05 microprocessor implementation shows that the new algorithm indeed yields a twofold speed improvement over classical multiplication for 128-byte numbers."
journal_title,Cryptography and Communications
article_title,Statistical integral attack on CAST-256 and IDEA
keyword,"['Statistical integral attack\xa0', 'IDEA\xa0', 'CAST-256\xa0', '94-XX\xa0', '94A60\xa0']"
history,"['2018-01', '2017-08-04', '2016-11-23', '2017-07-11']"
abstract,"Abstract Integral attack, as a powerful technique in the cryptanalysis field, has been widely utilized to evaluate the security of block ciphers. Integral distinguisher is based on balanced property on output with probability one. To obtain a distinguisher covering more rounds, an attacker will usually increase the data complexity by iterating through all values of more bits of plaintexts under the firm limitation that the data complexity should be less than the whole plaintext space. In order to release the limitation and reduce the data complexity, Wang et al. proposed a statistical integral distinguisher at FSE’16. In this paper, we exploit the statistical integral distinguisher to attack the IDEA and CAST-256 block ciphers. As a result, we manage to mount a key recovery attack on 29-round CAST-256 with 296.8 chosen plaintexts, 2219.4 encryptions and 273 bytes of memory. By making a trade-off between the time complexity and data complexity, the attack can be achieved by 283.9 chosen plaintexts, 2244.4 encryptions and 266 bytes of memory. As far as we know, these are the best attacks on CAST-256 in the single-key model without weak-key assumption so far. What’s more, we find an integral distinguisher of IDEA block cipher, which is the longest integral distinguisher known to now. By taking advantage of this distinguisher, we achieve a key recovery attack on 4.5-round IDEA with 258.5 known plaintexts, 2120.9 encryptions and 246.6 bytes of memory respectively. It is the best integral attack with respect to the number of rounds."
journal_title,Cryptography and Communications
article_title,Editorial: Special issue on recent trends in cryptography
keyword,[]
history,"['2018-01', '2017-11-25']"
abstract,None
journal_title,Cryptography and Communications
article_title,Security of BLS and BGLS signatures in a multi-user setting
keyword,"['Security models\xa0', 'Signatures\xa0', 'Aggregate signatures\xa0', 'Multi-user\xa0', 'Reduction\xa0', '94A60\xa0', '68P25\xa0']"
history,"['2018-01', '2017-08-24', '2016-11-30', '2017-08-08']"
abstract,"Abstract Traditional single-user security models do not necessarily capture the power of real-world attackers. A scheme that is secure in the single-user setting may not be as secure in the multi-user setting. Inspired by the recent analysis of Schnorr signatures in the multi-user setting, we analyse Boneh-Lynn-Shacham (BLS) signatures and Boneh-Gentry-Lynn-Shacham (BGLS) aggregate signatures in the multi-user setting. We obtain a tight reduction from the security of key-prefixed BLS in the multi-user model to normal BLS in the single-user model. We introduce a multi-user security model for general aggregate signature schemes, in contrast to the original “chosen-key” security model of BGLS that is analogous to the single-user setting of a signature scheme. We obtain a tight reduction from the security of multi-user key-prefixed BGLS to the security of multi-user key-prefixed BLS. Finally, we apply a technique of Katz and Wang to present a tight security reduction from a variant of multi-user key-prefixed BGLS to the computational co-Diffie-Hellman (co-CDH) problem. All of our results for BLS and BGLS use type III pairings."
journal_title,Cryptography and Communications
article_title,Generic attacks with standard deviation analysis on a-feistel schemes
keyword,"['Affine permutations\xa0', 'Classical Feistel permutations\xa0', 'Pseudo-random permutations\xa0', 'Generic attacks\xa0', 'Luby-Rackoff theory\xa0', 'Block ciphers\xa0', '94A60\xa0']"
history,"['2018-01', '2017-07-24', '2016-11-29', '2017-07-07']"
abstract,"Abstract A usual way to construct block ciphers is to apply several rounds of a given structure. Many kinds of attacks are mounted against block ciphers. Among them, differential and linear attacks are widely used. Vaudenay showed that ciphers achieving perfect pairwise decorrelation are secure against linear and differential attacks. It is possible to obtain such schemes by introducing at least one random affine permutation as a round function in the design of the scheme. In this paper, we study attacks on schemes based on classical Feistel schemes where we introduce one or two affine permutations. Since these schemes resist against linear and differential attacks, we will study attacks based on specific equations on 4-tuples of plaintext/ciphertext messages. We show that these schemes are stronger than classical Feistel schemes."
journal_title,Cryptography and Communications
article_title,Efficient robust secret sharing from expander graphs
keyword,"['Robust secret sharing\xa0', 'Expander graphs\xa0', 'Secure message transmission\xa0', '94A60\xa0', '11T71\xa0', '94C15\xa0']"
history,"['2018-01', '2017-03-07', '2016-11-29', '2017-02-06']"
abstract,"Abstract Threshold secret sharing allows a dealer to share a secret among n players so that any coalition of t players learns nothing about the secret, but any t+1 players can reconstruct the secret in its entirety. Robust secret sharing (RSS) provides the additional guarantee that even if t malicious players mangle their shares, they cannot cause the honest players to reconstruct an incorrect secret. In this work, we construct a simple RSS protocol for \(t = \left ({ \frac {1}{2} - \epsilon }\right )n\) that achieves logarithmic overhead in terms of share size and simultaneously allows efficient reconstruction. Our shares size increases by an additive term of \(\mathcal {O}(\kappa + \log n)\), and reconstruction succeeds except with probability at most 2−κ . Previous efficient RSS protocols like that of Rabin and Ben-Or (STOC ’89) and Cevallos et al. (Eurocrypt ’12) use MACs to allow each player to check the shares of each other player in the protocol. These checks provide robustness, but require significant overhead in share size. Our construction identifies the n players as nodes in an expander graph, each player only checks its neighbors in the expander graph."
journal_title,Cryptography and Communications
article_title,On the optimality and practicability of mutual information analysis in some scenarios
keyword,"['Side-channel analysis\xa0', 'Unprofiled distinguishers\xa0', 'MIA\xa0', 'CPA\xa0', 'LRA\xa0', 'Maximum likelihood\xa0', 'Complexity\xa0', '62B10\xa0']"
history,"['2018-01', '2017-07-20', '2016-11-30', '2017-06-30']"
abstract,"Abstract The best possible side-channel attack maximizes the success rate and would correspond to a maximum likelihood (ML) distinguisher if the leakage probabilities were totally known or accurately estimated in a profiling phase. When profiling is unavailable, however, it is not clear whether Mutual Information Analysis (MIA), Correlation Power Analysis (CPA), or Linear Regression Analysis (LRA) would be the most successful in a given scenario. In this paper, we show that MIA coincides with the maximum likelihood expression when leakage probabilities are replaced by online estimated probabilities. Moreover, we show that the calculation of MIA is lighter that the computation of the maximum likelihood. We then exhibit two case-studies where MIA outperforms CPA. One case is when the leakage model is known but the noise is not Gaussian. The second case is when the leakage model is partially unknown and the noise is Gaussian. In the latter scenario MIA is more efficient than LRA of any order."
journal_title,Cryptography and Communications
article_title,KISS: A bit too simple
keyword,"['Stream cipher\xa0', 'PRNG\xa0', 'Cryptanalysis\xa0', '94A60\xa0']"
history,"['2018-01', '2017-05-02', '2016-11-05', '2017-04-10']"
abstract,"Abstract KISS (‘Keep it Simple Stupid’) is an efficient pseudo-random number generator originally specified by G. Marsaglia and A. Zaman in 1993. G. Marsaglia in 1998 posted a C version to various USENET newsgroups, including sci.crypt. Marsaglia himself has never claimed cryptographic security for the KISS generator, but others have made the intellectual leap and claimed that it is of cryptographic quality. In this paper we show a number of reasons why the generator does not meet some of the KISS authors’ claims, why it is not suitable for use as a stream cipher, and that it is not cryptographically secure. Our best attack requires about 70 words of generated output and a few hours of computation to recover the initial state. In early 2011, G. Marsaglia posted a new version of KISS, which falls to a simple divide-and-conquer attack."
journal_title,Cryptography and Communications
article_title,Malleability of the blockchain’s entropy
keyword,"['Random number generation\xa0', 'Blockchain\xa0', 'Random beacon\xa0', 'Bitcoin\xa0', 'Dyck language\xa0', '94A60\xa0', '65C10\xa0']"
history,"['2018-01', '2017-11-03', '2016-11-29', '2017-10-16']"
abstract,"Abstract Trustworthy generation of public random numbers is necessary for the security of a number of cryptographic applications. It was suggested to use the inherent unpredictability of blockchains as a source of public randomness. Entropy from the Bitcoin blockchain in particular has been used in lotteries and has been suggested for a number of other applications ranging from smart contracts to election auditing. In this Arcticle, we analyse this idea and show how an adversary could manipulate these random numbers, even with limited computational power and financial budget."
journal_title,Cryptography and Communications
article_title,Searchable symmetric encryption over multiple servers
keyword,"['Searchable encryption\xa0', 'Cloud privacy\xa0', 'Secure storage\xa0', '94A60\xa0']"
history,"['2018-01', '2017-06-07', '2016-11-30', '2017-05-26']"
abstract,"Abstract Searchable Symmetric Encryption (SSE) allows a user to store encrypted documents on server(s) and later efficiently searches these documents in a private manner. So far most existing works have focused on a single storage server. Therefore in this paper we consider the natural extension of SSE to multiple servers. We believe it is of practical interest, given that a user may choose to distribute documents to various cloud storage that are now readily available. The main benefit compared to a single server scheme is that a server can be set to hold only subset of encrypted documents/blocks. A server learns only content of documents/blocks that it stores in the event of successful leakage attack or ciphertext cryptanalysis, provided servers do not collude. We define formally an extension of single server SSE to multiserver and instantiate provably secure schemes that provide the above feature. Our main scheme hides total number of documents and document size even after retrieval, achieving less leakages compared to prior work, while maintaining sublinear search time for each server. We further study leakages under the new setting of non-colluding and colluding servers."
journal_title,Cryptography and Communications
article_title,Cryptanalysis of a homomorphic encryption scheme
keyword,"['Homomorphic encryption\xa0', 'Public key cryptography\xa0', 'Cryptanalysis\xa0', 'Key switching\xa0', '94A60\xa0']"
history,"['2018-01', '2017-07-17', '2016-11-29', '2017-07-06']"
abstract,"Abstract Homomorphic encryption allows to make specific operations on private data which stays encrypted. While applications such as cloud computing require to have a practical solution, the encryption scheme must be secure. In this article, we detail and analyze in-depth the homomorphic encryption scheme proposed by Zhou and Wornell (20). From the analysis of the encryption scheme, we are able to mount three attacks. The first attack enables to recover a secret plaintext message broadcasted to multiple users. The second attack performs a chosen ciphertext key recovery attack. The last attack is a related chosen plaintext decryption attack."
journal_title,Cryptography and Communications
article_title,On generating invertible circulant binary matrices with a prescribed number of ones
keyword,"['Circulant matrices\xa0', 'Invertible matrices\xa0', 'Binary matrices with a prescribed number of ones\xa0', 'QC-LDPC McEliece cryptosystem\xa0', '94A60\xa0']"
history,"['2018-01', '2017-07-11', '2016-11-28', '2017-06-30']"
abstract,"Abstract We study the problem how to efficiently generate circulant binary matrices with a prescribed number of ones which are invertible over \(\mathbb {Z}_{2}\). A natural method to generate such matrices consists of two steps. Firstly, a circulant binary matrix with the prescribed number of ones is generated. Afterwards, it is tested for invertibility and if needed the process is repeated. To increase the efficiency of the process, we are interested in generating the matrices directly, without the need for the additional invertibility testing. We propose algorithms which fulfill this task for a wide range of parameters. Furthermore, we propose algorithms to construct matrices S and Q in the QC-LDPC McEliece cryptosystem. Matrices S and Q have to be composed of blocks of circulant matrices and they have to be invertible. In addition, S has to be dense and Q has to have a prescribed number of ones in a row. To avoid known attacks on the QC-LDPC McEliece cryptosystem, our algorithms generate S and Q with blocks of an odd size."
journal_title,Cryptography and Communications
article_title,POEx: A beyond-birthday-bound-secure on-line cipher
keyword,"['Symmetric cryptography\xa0', 'Provable security\xa0', 'On-line cipher\xa0', 'Universal hash function\xa0', 'Tweakable block cipher\xa0', '11T71\xa0']"
history,"['2018-01', '2017-08-26', '2016-11-29', '2017-06-30']"
abstract,"Abstract On-line ciphers are convenient building blocks for realizing efficient single- pass encryption. In particular, the trend to limit the consequences of nonce reuses rendered them popular in recent authenticated encryption schemes. While encryption schemes, such as POE, COPE, or the ciphers within ElmE/ElmD concentrated on efficiency, their security guarantees and that of all earlier on-line ciphers is limited by the birthday bound, and so are those of the AE schemes built upon them. This work proposes POEx, a beyond-birthday-bound-secure on-line cipher which employs one call to a tweakable block cipher and one call to a 2n-bit universal hash function per message block. POEx builds upon the recently proposed XTX tweak extender by Iwata and Minematsu. We prove the security of our construction and discuss possible instantiations."
journal_title,Cryptography and Communications
article_title,The cycle structure of LFSR with arbitrary characteristic polynomial over finite fields
keyword,"['Cycle structure\xa0', 'Cyclotomic number\xa0', 'de Bruijn sequence\xa0', 'Decimation\xa0', 'LFSR\xa0', 'Periodic sequence\xa0', '11B50\xa0', '94A55\xa0', '94A60\xa0']"
history,"['2017-12-20', '2016-12-23', '2017-11-28']"
abstract,"Abstract We determine the cycle structure of linear feedback shift register with arbitrary monic characteristic polynomial over any finite field. For each cycle, a method to find a state and a new way to represent the state are proposed."
journal_title,Cryptography and Communications
article_title,Statistical properties of side-channel and fault injection attacks using coding theory
keyword,"['Detection of faults\xa0', 'Masking countermeasure\xa0', 'Statistics of leakage\xa0', 'Uni- and multi-variate side-channel attacks\xa0', 'High-order attacks\xa0', 'Probing security model\xa0', 'Bounded moment security model\xa0', 'Inner product masking\xa0', 'Leakage squeezing masking\xa0', '62B10\xa0', '62P30\xa0']"
history,"['2017-12-14', '2017-08-17', '2017-11-23']"
abstract,"Abstract Naïve implementation of block ciphers are subject to side-channel and fault injection attacks. To deceive side-channel attacks and to detect fault injection attacks, the designer inserts specially crafted error correcting codes in the implementation. The impact of codes on protection against fault injection attacks is well studied: the number of detected faults relates to their minimum distance. However, regarding side-channel attacks, the link between codes and protection efficiency is blurred. In this paper, we relate statistical properties of code-based countermeasures against side-channel attacks to their efficiency in terms of security, against uni- and multi-variate attacks."
journal_title,Cryptography and Communications
article_title,Some quantum MDS codes with large minimum distance from generalized Reed-Solomon codes
keyword,"['Quantum MDS codes\xa0', 'Hermitian self-orthogonal\xa0', 'Generalized Reed-Solomon codes\xa0', '81P70\xa0']"
history,"['2017-12-14', '2017-06-10', '2017-11-28']"
abstract,"Abstract Quantum maximum-distance-separable (MDS) codes are a significant class of quantum codes. In this paper, we mainly utilize classical Hermitian self-orthogonal generalized Reed-Solomon codes to construct five new classes of quantum MDS codes with large minimum distance."
journal_title,Cryptography and Communications
article_title,Multiple (Truncated) Differential Cryptanalysis: Explicit Upper Bounds on Data Complexity
keyword,"['Multiple differential cryptanalysis\xa0', 'Chernoff bounds\xa0', 'Hoeffding bounds\xa0', '94A60\xa0', '11T71\xa0', '68P25\xa0', '62P99\xa0']"
history,"['2017-12-04', '2016-11-16', '2017-11-06']"
abstract,"Abstract Statistical analyzes of multiple (truncated) differential attacks are considered in this paper. Following the work of Blondeau and Gérard, the most general situation of multiple differential attack where there are no restrictions on the set of differentials is studied. We obtain closed form upper bounds on the data complexity in terms of the success probability and the advantage of an attack. This is done under two scenarios – one, where an independence assumption used by Blondeau and Gérard is assumed to hold and second, where no such assumption is made. The first case employs the Chernoff bounds while the second case uses the Hoeffding bounds from the theory of concentration inequalities. In both cases, we do not make use of any approximations in our analysis. Moreover, the results are more generally applicable compared to previous works. The analysis without the independence assumption is the first of its kind in the literature. We believe that the current work places the statistical analysis of multiple (truncated) differential attack on a more rigorous foundation than what was previously known."
journal_title,Cryptography and Communications
article_title,Cyclic codes over M2(𝔽2+u𝔽2)$M_{2}(\mathbb {F}_{2}+u\mathbb {F}_{2})$
keyword,"['Cyclic codes\xa0', 'Lee weight\xa0', 'Bachoc weight\xa0', 'Gray map\xa0', '94B05\xa0', '94B15\xa0']"
history,"['2017-12-01', '2016-12-25', '2017-11-03']"
abstract,"Abstract Let \(A=M_{2}(\mathbb {F}_{2}+u\mathbb {F}_{2})\), where u 2 = 0, the ring of 2 × 2 matrices over the finite ring \(\mathbb {F}_{2}+u\mathbb {F}_{2}\). The ring A is a non-commutative Frobenius ring but not a chain ring. In this paper, we derive the structure theorem of cyclic codes of odd length over the ring A and use them to construct some optimal cyclic codes over \(\mathbb {F}_{4}\). Let v 2 = 0 and u v = v u. We also give an isometric map from A to \(\mathbb {F}_{4}+v\mathbb {F}_{4}+u\mathbb {F}_{4}+uv\mathbb {F}_{4}\) using their respective Bachoc weight and Lee weight."
journal_title,Cryptography and Communications
article_title,Five classes of optimal two-weight linear codes
keyword,"['Linear code\xa0', 'Optimality\xa0', 'Griesmer bound\xa0', 'Two-weight code\xa0', '94B15\xa0', '11T71\xa0']"
history,"['2017-12-01', '2017-07-18', '2017-11-27']"
abstract,"Abstract Linear codes with few weights have applications in secret sharing, authentication codes, association schemes, data storage systems, strongly regular graphs and some other fields. Two-weight linear codes are particularly interesting since they are closely related to finite geometry, combinatorial designs, graph theory. In this paper, we propose five classes of two-Lee-weight codes over the ring \(\mathbb {F}_{q}+u\mathbb {F}_{q}\). By the Gray map, we obtain five classes of linear codes with two weights over \(\mathbb {F}_{q}\) and these linear codes are optimal with respect to the Griesmer bound. As applications, we can employ these linear codes to construct secret sharing schemes with nice access structures."
journal_title,Cryptography and Communications
article_title,Complete weight enumerators of three classes of linear codes
keyword,"['Linear code\xa0', 'Complete weight enumerator\xa0', 'Gauss sum\xa0', 'Authentication code\xa0', '94B15\xa0', '11T71\xa0']"
history,"['2017-11-25', '2017-06-22', '2017-11-16']"
abstract,"Abstract In recent years, a great deal of effort has been devoted to the study of linear codes with few weights, since they have applications in secret sharing, authentication codes, association schemes and some other fields. In this paper, we propose three classes of linear codes by using proper defining sets and investigate their complete weight enumerators. As applications, these linear codes are employed to construct secret sharing schemes with access structures and systematic authentication codes. Moreover, we obtain three classes of asymptotically optimal systematic authentication codes."
journal_title,Cryptography and Communications
article_title,Nonlinear vectorial primitive recursive sequences
keyword,"['Multiple-recursive matrix generator\xa0', 'Transformation shift register\xa0', 'Linear complexity\xa0', '94A55\xa0', '94A60\xa0']"
history,"['2017-11-15', '2016-11-30', '2017-11-03']"
abstract,"Abstract We discuss nonlinear vectorial primitive recursive sequences. First we consider the nonlinearly filtered multiple-recursive matrix generator for producing pseudorandom vectors based on some nonlinear schemes and give lower bounds for their componentwise linear complexity. Moreover, we obtain certain results concerning the jump multiple-recursive matrix generator and establish that sequences generated by them have better period and componentwise linear complexity as compared to usual multiple-recursive matrix generator sequences. We also include analogous results for transformation shift registers for generating pseudorandom vectors."
journal_title,Cryptography and Communications
article_title,Correlation immune functions with respect to the q-transform
keyword,"['Correlation immunity\xa0', None, None]"
history,"['2017-11-09', '2016-12-27', '2017-11-03']"
abstract,"Abstract Correlation immunity is a measure of resistance to Siegenthaler’s divide and conquer attack on nonlinear combiners. In this work, we study functions with regard to the q-transform, a generalization of the Walsh-Hadamard transform, that measures the proximity of a function to the set of functions obtained from a function q(x) by linear base change. We propose two notions of q-correlation immune functions and study their relationship between them. We also analyze certain properties of these functions and present some techniques to design these functions."
journal_title,Cryptography and Communications
article_title,Design and analysis of small-state grain-like stream ciphers
keyword,"['Stream ciphers\xa0', 'Lightweight cryptography\xa0', 'Time-memory-data tradeoff attacks\xa0', 'Grain\xa0', 'Fruit\xa0', '94A60\xa0']"
history,"['2017-11-08', '2017-06-25', '2017-10-09']"
abstract,"Abstract Time-memory-data (TMD) tradeoff attacks limit the security level of many classical stream ciphers to the birthday bound. Very recently, a new field of research has emerged, which searches for so-called small-state stream ciphers that try to overcome this limitation. In this paper, existing designs and known analysis of small-state stream ciphers are revisited and new insights on distinguishers and key recovery are derived based on TMD tradeoff attacks. A particular result is the transfer of a generic distinguishing attack suggested in 2007 by Englund et al. to this new class of lightweight ciphers. Our analysis shows that the initial hope of achieving full security against TMD tradeoff attacks by continuously using the secret key has failed. In particular, we provide generic distinguishers for Plantlet and Fruit with complexity significantly smaller than that of exhaustive key search. However, by studying the assumptions underlying the applicability of these attacks, we are able to come up with a new design idea for small-state stream ciphers, which might allow to finally achieve full security against TMD tradeoff attacks. Another contribution of this paper is the first key recovery attack against the most recent version of Fruit. We show that there are at least 264 weak keys, each of which does not provide 80-bit security as promised by designers."
journal_title,Cryptography and Communications
article_title,Sequences of bent functions and near-bent functions
keyword,"['Bent functions\xa0', 'Near-bent functions\xa0']"
history,"['2017-11', '2017-01-18', '2016-01-15', '2017-01-09']"
abstract,Abstract We introduce infinite sequences of Boolean functions whose terms all are bent functions or all are near-bent functions.
journal_title,Cryptography and Communications
article_title,Design sequences with high linear complexity over finite fields using generalized cyclotomy
keyword,"['Pseudorandom sequences\xa0', 'Generalized cyclotomy sequences\xa0', 'Finite fields\xa0', 'Linear complexity\xa0', 'Discrete Fourier transform\xa0', '11B50\xa0', '94A55\xa0', '94A60\xa0']"
history,"['2017-11', '2016-12-08', '2016-06-06', '2016-11-28']"
abstract,"Abstract Based on the generalized cyclotomy theory, we design some classes of sequences with high linear complexity over the finite fields. First, we construct a new class of sequence from some generalized cyclotomic sequences of different orders with different prime powers period. Then we obtain the discrete Fourier transform, defining pairs and the linear complexity of the new sequences. Finally, we study the linear complexity of a special class of q−ary (q prime) sequences."
journal_title,Cryptography and Communications
article_title,Character values of the Sidelnikov-Lempel-Cohn-Eastman sequences
keyword,"['Linear complexity\xa0', 'Feedback shift registers\xa0', 'Autocorrelation\xa0', 'Stream cipher cryptography\xa0', 'Difference sets\xa0', 'Almost difference sets\xa0', 'Jacobi sums\xa0', 'Gauss sums\xa0', '05B10\xa0', '94A55\xa0', '11T23\xa0', '11T71\xa0', '11B50\xa0']"
history,"['2017-11', '2016-11-21', '2016-02-18', '2016-10-26']"
abstract,"Abstract Binary sequences with good autocorrelation properties and large linear complexity are useful in stream cipher cryptography. The Sidelnikov-Lempel-Cohn-Eastman (SLCE) sequences have nearly optimal autocorrelation. However, the problem of determining the linear complexity of the SLCE sequences is still open. It is well known that one can gain insight into the linear complexity of a sequence if one can say something about the divisors of the gcd of a certain pair of polynomials associated with the sequence. Helleseth and Yang (IEEE Trans. Inf. Theory 49(6), 1548–1552 2002), Kyureghyan and Pott (Des. Codes Crypt. 29, 149–164 2003) and Meidl and Winterhof (Des. Codes Crypt. 8, 159–178 2006) were able to obtain some results of this type for the SLCE sequences. Kyureghyan and Pott (Des. Codes Crypt. 29, 149–164 2003) mention that it would be nice to obtain more such results. We derive new divisibility results for the SLCE sequences in this paper. Our approach is to exploit the fact that character values associated with the SLCE sequences can be expressed in terms of a certain type of Jacobi sum. By making use of known evaluations of Gauss and Jacobi sums in the “pure” and “small index” cases, we are able to obtain new insight into the linear complexity of the SLCE sequences."
journal_title,Cryptography and Communications
article_title,On the irreducibility of the hyperplane sections of Fermat varieties in ℙ3$\mathbb {P}^{3}$ in characteristic 2. II
keyword,"['APN functions\xa0', 'Finite fields\xa0', 'Absolute irreducible polynomials\xa0', '12E05\xa0', '14Q10\xa0', '11T71\xa0']"
history,"['2017-11', '2017-02-14', '2016-02-16', '2017-01-19']"
abstract,"Abstract Let t be an integer ≥ 3 such that t ≡ 1 mod 4. The absolute irreducibility of the polynomial \(\phi _{t}(x, y) = \frac {x^{t} + y^{t} + 1 + (x + y + 1)^{t}}{(x + y)(x + 1)(y + 1)}\) (over \(\mathbb {F}_{2}\)) plays an important role in the study of APN functions. We prove that this polynomial is absolutely irreducible under the assumptions that the largest odd integer which divides t − 1 is large enough and can not be written in a specific form."
journal_title,Cryptography and Communications
article_title,Several classes of permutation trinomials from Niho exponents
keyword,"['Finite field\xa0', 'Niho exponent\xa0', 'Permutation trinomial\xa0', '05A05\xa0', '11T06\xa0', '11T55\xa0']"
history,"['2017-11', '2016-12-28', '2016-03-05', '2016-12-13']"
abstract,"Abstract Motivated by recent results on the constructions of permutation polynomials with few terms over the finite field \({\mathbb F}_{2^n}\), where n is a positive even integer, we focus on the construction of permutation trinomials over \({\mathbb F}_{2^n}\) from Niho exponents. As a consequence, several new classes of permutation trinomials over \({\mathbb F}_{2^n}\) are constructed from Niho exponents based on some subtle manipulation of solving equations with low degrees over finite fields."
journal_title,Cryptography and Communications
article_title,Generalized methods to construct low-hit-zone frequency-hopping sequence sets and optimal constructions
keyword,"['Frequency-hopping sequence set\xa0', 'Low-hit-zone\xa0', 'Hamming correlation\xa0', 'Cartesian product\xa0', 'Quasi-synchronous frequency-hopping multiple-access system\xa0', '94A55\xa0', '94B05\xa0']"
history,"['2017-11', '2017-01-18', '2016-06-23', '2017-01-06']"
abstract,"Abstract In a quasi-synchronous frequency-hopping multiple-access system, relative time delay between different users within a zone around the origin can be allowed. Therefore, frequency-hopping sequence (FHS) sets with low-hit-zone (LHZ) have attracted great interest of many related scholars. Moreover, on account of the limited synchronous time or hardware complexity, the periodic partial Hamming correlation (PPHC) plays a major role in determining the synchronization performance. In this paper, we first present three new generalized methods to construct LHZ-FHS sets via Cartesian product. Meanwhile, we pay our attention to the maximum periodic Hamming correlation (PHC) of the constructed LHZ-FHS sets in the first generalized method, and to the maximum PPHC of the constructed LHZ-FHS sets in the rest generalized methods. In addition, we also introduce five new classes of optimal LHZ-FHS sets based on these three generalized methods."
journal_title,Cryptography and Communications
article_title,A new family of arrays with low autocorrelation
keyword,"['Almost perfect arrays\xa0', None, 'Periodic autocorrelation\xa0', 'Recursive constructions\xa0', '94A15\xa0', '94A05\xa0', '94A62\xa0']"
history,"['2017-11', '2017-02-14', '2016-12-19', '2017-01-24']"
abstract,"Abstract Arrays with low autocorrelation are widely sought in applications; important examples are arrays whose periodic autocorrelation is zero for all nontrivial cyclic shifts, so-called perfect arrays. In 2001, Arasu and de Launey defined almost perfect arrays: these have size 2u×v and autocorrelation arrays with only two nonzero entries, namely 2u v and −2u v in positions (0,0) and (u,0), respectively. In this paper we present a new class of arrays with low autocorrelation: for an integer n≥1, we call an array n-perfect if it has size n u×v and if its autocorrelation array has only n nonzero entries, namely n u v λ  i  in position (i u,0) for i=0,1,…,n−1, where λ is a primitive n-th root of unity. Thus, an array is 1-perfect (2-perfect) if and only if it is (almost) perfect. We give examples and describe a recursive construction of families of n-perfect arrays of increasing size."
journal_title,Cryptography and Communications
article_title,On the nonlinearity of monotone Boolean functions
keyword,"['Boolean functions\xa0', 'Nonlinearity\xa0', 'Monotone functions\xa0', 'Walsh–Hadamard spectrum\xa0', '06E30\xa0', '94C10\xa0', '94A60\xa0', '11T71\xa0', '05E99\xa0']"
history,"['2017-10-24', '2016-12-28', '2017-10-11']"
abstract,"Abstract We prove a conjecture on the nonlinearity of monotone Boolean functions in even dimension, proposed in the recent paper “Cryptographic properties of monotone Boolean functions”, by Carlet et al. (J. Math. Cryptol. 10(1), 1–14, 2016). We also prove an upper bound on such nonlinearity, which is asymptotically much stronger than the conjectured upper bound and than the upper bound proved for odd dimension in this same paper. Contrary to these two previous bounds, which were not tight enough for allowing to clarify if monotone functions can have good nonlinearity, this new bound shows that the nonlinearity of monotone functions is always very bad, which represents a fatal cryptographic weakness of monotone Boolean functions; they are too closely approximated by affine functions for being usable as nonlinear components in cryptographic applications. We deduce a necessary criterion to be satisfied by a Boolean (resp. vectorial) function for being nonlinear."
journal_title,Cryptography and Communications
article_title,A new class of permutation trinomials constructed from Niho exponents
keyword,"['Finite fields\xa0', 'Permutation trinomials\xa0', 'Niho exponents\xa0', 'Multiplicative inequivalent\xa0', '94B15\xa0', '11T71\xa0']"
history,"['2017-10-17', '2017-07-11', '2017-10-12']"
abstract,"Abstract Permutation polynomials over finite fields are an interesting subject due to their important applications in the areas of mathematics and engineering. In this paper, we investigate the trinomial f(x) = x (p−1)q+1 + x  p q  − x  q+(p−1) over the finite field \(\mathbb {F}_{q^{2}}\), where p is an odd prime and q = p  k  with k being a positive integer. It is shown that when p = 3 or 5, f(x) is a permutation trinomial of \(\mathbb {F}_{q^{2}}\) if and only if k is even. This property is also true for a more general class of polynomials g(x) = x (q+1)l+(p−1)q+1 + x (q+1)l + p q  − x (q+1)l + q+(p−1), where l is a nonnegative integer and \(\gcd (2l+p,q-1)=1\). Moreover, we also show that for p = 5 the permutation trinomials f(x) proposed here are new in the sense that they are not multiplicative equivalent to previously known ones of similar form."
journal_title,Cryptography and Communications
article_title,On the normality of p-ary bent functions
keyword,"['Bent function\xa0', None, 'Normal bent function\xa0', None, '06E30\xa0', '05B10\xa0', '11T71\xa0']"
history,"['2017-10-17', '2016-12-22', '2017-09-26']"
abstract,"Abstract Depending on the parity of n and the regularity of a bent function f from \({{\mathbb F}_{p}^{n}}\) to \({\mathbb F}_{p}\), f can be affine on a subspace of dimension at most n/2, (n − 1)/2 or n/2 − 1. We point out that many p-ary bent functions take on this bound, and it seems not easy to find examples for which one can show a different behaviour. This resembles the situation for Boolean bent functions of which many are (weakly) n/2-normal, i.e. affine on a n/2-dimensional subspace. However applying an algorithm by Canteaut et.al., some Boolean bent functions were shown to be not n/2-normal. We develop an algorithm for testing normality for functions from \({{\mathbb F}_{p}^{n}}\) to \({\mathbb F}_{p}\). Applying the algorithm, for some bent functions in small dimension we show that they do not take on the bound on normality. Applying direct sum of functions this yields bent functions with this property in infinitely many dimensions."
journal_title,Cryptography and Communications
article_title,On the pseudorandomness of automatic sequences
keyword,"['Finite automaton\xa0', 'Automatic sequences\xa0', 'Correlation measure\xa0', 'Pseudorandom sequences\xa0', 'Thue-Morse sequence\xa0', 'State complexity\xa0', '11K45\xa0', '03D05\xa0', '68Q25\xa0', '68Q70\xa0']"
history,"['2017-10-13', '2016-11-28', '2017-10-04']"
abstract,"Abstract We study the pseudorandomness of automatic sequences in terms of well-distribution and correlation measure of order 2. We detect non-random behavior which can be derived either from the functional equations satisfied by their generating functions or from their generating finite automatons, respectively."
journal_title,Cryptography and Communications
article_title,Success probability of multiple/multidimensional linear cryptanalysis under general key randomisation hypotheses
keyword,"['Multidimensional linear cryptanalysis\xa0', 'Multiple linear cryptanalysis\xa0', 'Chi-squared distribution\xa0', 'Success probability\xa0', 'Data complexity\xa0', 'Advantage\xa0', '94A60\xa0', '11T71\xa0', '68P25\xa0', '62P99\xa0']"
history,"['2017-09-27', '2017-07-27', '2017-09-13']"
abstract,"Abstract This work considers statistical analysis of attacks on block cyphers using several linear approximations. A general and unified approach is adopted. To this end, the general key randomisation hypotheses for multidimensional and multiple linear cryptanalysis are introduced. Expressions for the success probability in terms of the data complexity and the advantage are obtained using the general key randomisation hypotheses for both multidimensional and multiple linear cryptanalysis and under the settings where the plaintexts are sampled with or without replacement. Particularising to standard/adjusted key randomisation hypotheses gives rise to success probabilities in 16 different cases out of which in only five cases expressions for success probabilities have been previously reported. Even in these five cases, the expressions for success probabilities that we obtain are more general than what was previously obtained. A crucial step in the analysis is the derivation of the distributions of the underlying test statistics. Whilst we carry out the analysis formally to the extent possible, there are certain inherently heuristic assumptions that need to be made. In contrast to previous works which have implicitly made such assumptions, we carefully highlight these and discuss why they are unavoidable. Finally, we provide a complete characterisation of the dependence of the success probability on the data complexity."
journal_title,Cryptography and Communications
article_title,Two and three weight codes over Fp+uFp$\mathbb {F}_{p}+u\mathbb {F}_{p}$
keyword,"['Three-weight codes\xa0', 'Two-weight codes\xa0', 'Gauss sums\xa0', 'Trace codes\xa0', 'Secret sharing\xa0', '94B05\xa0', '94B15\xa0']"
history,"['2017-09', '2016-09-27', '2016-06-22', '2016-09-15']"
abstract,"Abstract We construct an infinite family of three-Lee-weight codes of dimension 2m, where m is singly-even, over the ring \(\mathbb {F}_{p}+u\mathbb {F}_{p}\) with u 2=0. These codes are defined as trace codes. They have the algebraic structure of abelian codes. Their Lee weight distribution is computed by using Gauss sums. By Gray mapping, we obtain an infinite family of abelian p-ary three-weight codes. When m is odd, and p≡3 (mod 4), we obtain an infinite family of two-weight codes which meets the Griesmer bound with equality. An application to secret sharing schemes is given."
journal_title,Cryptography and Communications
article_title,A class of hyper-bent functions and Kloosterman sums
keyword,"['Bent functions\xa0', 'Hyper-bent functions\xa0', 'Walsh-Hadmard trasform\xa0', 'Dickson polynomials\xa0', 'Kloosterman sums\xa0', '06E75\xa0', '94A60\xa0']"
history,"['2017-09', '2016-10-10', '2016-05-10', '2016-09-29']"
abstract,"Abstract This paper is devoted to the characterization of hyper-bent functions. Several classes of hyper-bent functions have been studied, such as Charpin and Gong’s family \(\sum \limits _{r\in R}\text {Tr}_{1}^{n} (a_{r}x^{r(2^{m}-1)})\) and Mesnager’s family \(\sum \limits _{r\in R}\text {Tr}_{1}^{n}(a_{r}x^{r(2^{m}-1)}) +\text {Tr}_{1}^{2}(bx^{\frac {2^{n}-1}{3}})\) . In this paper, we generalize these results by considering the following class of Boolean functions over \(\mathbb {F}_{2^{n}}\):
$$\sum\limits_{r\in R}\sum\limits_{i=0}^{2}T{r^{n}_{1}}(a_{r,i} x^{r(2^{m}-1)+\frac{2^{n}-1}{3}i}) +T{r^{2}_{1}}(bx^{\frac{2^{n}-1}{3}}), $$where \(n=2m\), m is odd, \(b\in \mathbb {F}_{4}\), and \(a_{r,i}\in \mathbb {F}_{2^{n}}\). With the restriction of \(a_{r,i}\in \mathbb {F}_{2^{m}}\), we present a characterization of hyper-bentness of these functions in terms of crucial exponential sums. For some special cases, we provide explicit characterizations for some hyper-bent functions in terms of Kloosterman sums and cubic sums. Finally, we explain how our results on binomial, trinomial and quadrinomial hyper-bent functions can be generalized to the general case where the coefficients \(a_{r,i}\) belong to the whole field \(\mathbb {F}_{2^{n}}\)."
journal_title,Cryptography and Communications
article_title,Localised multisecret sharing
keyword,"['Multisecret sharing\xa0', 'Information-theoretic security\xa0', 'Ramp schemes\xa0', 'RFID\xa0', '94A60\xa0', '94A62\xa0']"
history,"['2017-09', '2016-08-31', '2015-09-22', '2016-08-17']"
abstract,"Abstract A localised multisecret sharing scheme is a multisecret sharing scheme for an ordered set of players in which players in the smallest sets who are authorised to access secrets are close together in the underlying ordering. We define threshold versions of localised multisecret sharing schemes, we provide lower bounds on the share size of perfect localised multisecret sharing schemes in an information theoretic setting, and we give explicit constructions of schemes to show that these bounds are tight. We then analyse a range of approaches to relaxing the model that provide trade-offs between the share size and the level of security guarantees provided by the scheme, in order to permit the construction of schemes with smaller shares. We show how these techniques can be used in the context of an application to key distribution for RFID-based supply-chain management motivated by the proposal of Juels, Pappu and Parno from USENIX 2008."
journal_title,Cryptography and Communications
article_title,Secret sharing schemes for compartmented access structures
keyword,"['Secret sharing schemes\xa0', 'Compartmented access structures\xa0', 'Ideality\xa0', 'Bivariate interpolation\xa0', '94A62\xa0', '94A60\xa0']"
history,"['2017-09', '2016-09-20', '2016-04-12', '2016-09-14']"
abstract,"Abstract In this paper, we devise ideal and probabilistic secret sharing schemes for two kinds of compartmented access structures. The first one is a compartmented access structures with hierarchical compartments. The second one is the compartmented access structures with strictly lower bounds. We propose ideal and probabilistic schemes for these two compartmented access structures by using the idea of bivariate interpolation."
journal_title,Cryptography and Communications
article_title,On the best linear approximation of addition modulo 2n
keyword,"['Linear cryptanalysis\xa0', 'Linear approximation\xa0', 'Correlation\xa0', None, '94A60\xa0', '65D15\xa0', '62H20\xa0', '11K60\xa0']"
history,"['2017-09', '2016-08-30', '2015-11-24', '2016-08-17']"
abstract,"Abstract In this paper, the best linear approximations of addition modulo 2 n  are studied. Let x = (x  n−1, x  n−2,…,x 0) and y = (y  n−1, y  n−2,…,y 0) be any two n-bit integers, and let z = x + y (mod 2 n ). Firstly, all the correlations of a single bit z  i  approximated by x  j ’s and y  j ’s (0 ≤ i, j ≤ n − 1) are characterized, and similar results are obtained for the linear approximation of the xoring of the neighboring bits of z  i ’s. Then the maximum correlations and the best linear approximations are presented when these z  j ’s (0 ≤ j ≤ n − 1) are xored in any given means."
journal_title,Cryptography and Communications
article_title,Complete weight enumerators of two classes of linear codes
keyword,"['Complete weight enumerators\xa0', 'Linear codes\xa0', 'A finite non-chain ring\xa0', 'Authentication codes\xa0', '94B05\xa0', '11T71\xa0', '94A62\xa0']"
history,"['2017-09', '2016-07-07', '2015-12-23', '2016-06-28']"
abstract,"Abstract In this paper, we give the complete weight enumerators of two classes of linear codes over the finite field \(\mathbb {F}_{p}\), where p is a prime. These linear codes are the torsion codes of MacDonald codes over the finite non-chain ring \(\mathbb {F}_{p}+v\mathbb {F}_{p}\), where v 2 = v. We also employ these linear codes to construct systematic authentication codes with new parameters."
journal_title,Cryptography and Communications
article_title,Cyclic codes of odd length over ℤ4 [ u] / 〈 uk〉
keyword,"['Cyclic code\xa0', 'Finite chain ring\xa0', 'Non-principal ideal ring\xa0', 'Dual code\xa0', 'Self-dual code\xa0', '94B05\xa0', '94B15\xa0', '11T71\xa0']"
history,"['2017-09', '2016-09-17', '2016-05-02', '2016-08-31']"
abstract,"Abstract Let \(R=\mathbb{Z}_{4}[u]/ \langle u^k \rangle=\mathbb{Z}_{4}+u \mathbb{Z}_{4}+\ldots+u^{k-1}\mathbb{Z}_{4}\) (\(u^{k}=0\)), where k ≥ 2 is an positive integer. For any odd positive integer n, it is known that cyclic codes of length n over R are identified with ideals of the ring \(R[x]/\langle x^{n}-1\rangle\). In this paper, an explicit representation for each cyclic code over R of length n is provided and a formula to count the number of codewords in each code is given. Then a formula to calculate the number of cyclic codes of length n over R is obtained. Precisely, the dual code of each cyclic code and self-dual cyclic codes of length n over R are investigated. As an application, some good quasi-cyclic codes of length 7k and index k over ℤ4 are obtained from cyclic codes over R = ℤ4 [u] / 〈u  k 〉 when k = 2, 3, 4."
journal_title,Cryptography and Communications
article_title,Expansion complexity and linear complexity of sequences over finite fields
keyword,"['Expansion complexity\xa0', 'Linear complexity\xa0', 'Pseudorandom sequences\xa0', 'Binomial coefficients\xa0', 'Finite fields\xa0', 'Cryptography\xa0', '11T71\xa0', '11Y16\xa0', '94A60\xa0', '94A55\xa0', '68Q25\xa0']"
history,"['2017-07', '2016-06-09', '2015-11-09', '2016-05-12']"
abstract,"Abstract The linear complexity is a measure for the unpredictability of a sequence over a finite field and thus for its suitability in cryptography. In 2012, Diem introduced a new figure of merit for cryptographic sequences called expansion complexity. We study the relationship between linear complexity and expansion complexity. In particular, we show that for purely periodic sequences both figures of merit provide essentially the same quality test for a sufficiently long part of the sequence. However, if we study shorter parts of the period or nonperiodic sequences, then we can show, roughly speaking, that the expansion complexity provides a stronger test. We demonstrate this by analyzing a sequence of binomial coefficients modulo p. Finally, we establish a probabilistic result on the behavior of the expansion complexity of random sequences over a finite field."
journal_title,Cryptography and Communications
article_title,Cyclic codes from the second class two-prime Whiteman’s generalized cyclotomic sequence with order 6
keyword,"['Cyclic codes\xa0', 'Finite fields\xa0', 'Cyclotomic sequences\xa0', '94A05\xa0', '94A55\xa0', '94B15\xa0']"
history,"['2017-07', '2016-06-09', '2015-11-06', '2016-05-24']"
abstract,"Abstract Let \(n_{1}=df+1\) and \(n_{2}=df^{\prime }+1\) be two distinct odd primes with positive integers \(d,\ f,\ f^{\prime }\) and \(\gcd (f,f^{\prime })=1\). In this paper, we compute the linear complexity and the minimal polynomial of the two-prime Whiteman’s generalized cyclotomic sequence of order \(d=6\) over \(\text {GF}(q)\), where \(q=p^{m}\) and p is an odd prime and m is an integer. We employ this sequence of order 6 to construct several classes of cyclic codes over \(\text {GF}(q)\) with length \(n_{1}n_{2}\). We also obtain lower bounds on the minimum distance of these cyclic codes."
journal_title,Cryptography and Communications
article_title,Probabilistic signature based generalized framework for differential fault analysis of stream ciphers
keyword,"['Differential attack\xa0', 'Fault attack\xa0', 'Grain family\xa0', 'MICKEY 2.0\xa0', 'Probabilistic signatures\xa0', 'Stream ciphers\xa0', '94A60\xa0']"
history,"['2017-07', '2016-07-01', '2016-01-10', '2016-06-19']"
abstract,"Abstract Differential Fault Attack (DFA) considers injection of faults and the most general set-up should take care of faults at random location and random time. Then one should be able to identify the exact location as well as the exact timing of the fault (including the multi bit ones) with the help of fault signatures. In this paper we solve the problem of DFA under a general frame-work, introducing the idea of probabilistic signatures. The method considers the Maximum Likelihood approach related to probability distributions. Our techniques subsume all the existing DFAs against the Grain family, MICKEY 2.0 and Trivium. In the process we provide improved fault attacks for all the versions of Grain family and also for MICKEY 2.0. Our generalized method successfully takes care of the cases where certain parts of the keystream bits are missing (this situation may arise for authentication purpose). In particular, we show that the unsolved problem of identifying the faults in random time for Grain 128a can be solved in this manner. Moreover, for MICKEY 2.0, our method not only provides improvement in fault identification probability but also reduces the required faults by 60 %, compared to the best known result."
journal_title,Cryptography and Communications
article_title,Linear complexity and trace representation of quaternary sequences over ℤ4$\mathbb {Z}_{4}$ based on generalized cyclotomic classes modulo pq
keyword,"['Quaternary sequences\xa0', 'Generalized cyclotomic classes\xa0', 'Discrete Fourier transform\xa0', 'Linear complexity\xa0', 'Trace representation\xa0', 'Galois rings\xa0', 'Cryptography\xa0', '94A55\xa0', '94A60\xa0', '65C10\xa0']"
history,"['2017-07', '2016-03-09', '2015-11-09', '2016-03-03']"
abstract,"Abstract We define a family of quaternary sequences over the residue class ring modulo 4 of length pq, a product of two distinct odd primes, using the generalized cyclotomic classes modulo pq and calculate the discrete Fourier transform (DFT) of the sequences. The DFT helps us to determine the exact values of linear complexity and the trace representation of the sequences."
journal_title,Cryptography and Communications
article_title,New sets of opti mal low-hit-zone frequency-hopping sequences based on m-sequences
keyword,"['Frequency-hopping sequences\xa0', 'Low-hit-zone sequences\xa0', 'Frequency-hopping multiple-access\xa0', 'Quasi-synchronous systems\xa0', None, 'Decimated sequence\xa0', '94A55\xa0', '94B05\xa0']"
history,"['2017-07', '2016-06-18', '2015-12-18', '2016-05-24']"
abstract,"Abstract In quasi-synchronous frequency-hopping multiple-access systems where relative delays are restricted within a certain correlation zone, low-hit-zone frequency-hopping sequences (LHZ-FHSs) are commonly employed to minimize multiple-access interferences. In this paper, we present two classes of optimal LHZ-FHS sets with respect to the Peng-Fan-Lee bound, which are obtained from an m-sequence and its decimated sequence, respectively. The parameters of these LHZ-FHS sets are new and flexible."
journal_title,Cryptography and Communications
article_title,Practical construction of ring LFSRs and ring FCSRs with low diffusion delay for hardware cryptographic applications
keyword,"['Stream cipher\xa0', 'LFSR\xa0', 'FCSR\xa0', None, None, '14G50\xa0', '94A55\xa0']"
history,"['2017-07', '2016-02-12', '2015-07-08', '2016-01-28']"
abstract,"Abstract Linear Feedback Shift Registers (LFSRs) and Feedback with Carry Shift Registers (FCSRs) are two pseudo-random generators which are widely used in many cryptographic applications. The Ring representation of them has been proposed using a matrix approach. In this paper, we show how to construct Ring LFSRs and Ring FCSRs with low diffusion delay (close to the expected value \(\sqrt {n}\)) when considering other hardware cryptographic criteria."
journal_title,Cryptography and Communications
article_title,(1−2 u3)-constacyclic codes and q uadratic resid ue codes over Fp[ u]/〈 u4− u〉$\mathbb {F}_{p}[ u]/\langle u^{4}- u\rangle $
keyword,"['Constacyclic codes\xa0', 'Negacyclic codes\xa0', 'Self-dual and self-orthogonal codes\xa0', 'Quadratic residue codes\xa0', 'Extended QR-codes\xa0', 'Gray map\xa0', '11T71\xa0', '94B15\xa0']"
history,"['2017-07', '2016-03-12', '2015-08-27', '2016-02-26']"
abstract,"Abstract Let \(\mathcal {R}=\mathbb {F}_{p}+u\mathbb {F}_{p}+u^{2}\mathbb {F}_{p}+u^{3}\mathbb {F}_{p}\) with u 4 = u be a finite non-chain ring, where p is a prime congruent to 1 modulo 3. In this paper we study (1−2u 3)-constacyclic codes over the ring \(\mathcal {R}\), their equivalence to cyclic codes and find their Gray images. To illustrate this, examples of (1−2u 3)-constacyclic codes of lengths 2 m  for p = 7 and of lengths 3 m  for p = 19 are given. We also discuss quadratic residue codes over the ring \(\mathcal {R}\) and their extensions. A Gray map from \(\mathcal {R}\) to \(\mathbb {F}_{p}^{4}\) is defined which preserves self duality and gives self-dual and formally self-dual codes over \(\mathbb {F}_{p}\) from extended quadratic residue codes."
journal_title,Cryptography and Communications
article_title,Asymptotically optimal 2¯$\overline {2}$-separable codes with length 4
keyword,"['Multimedia fingerprinting\xa0', 'Separable code\xa0', 'Asymptotically optimal\xa0', '94B25\xa0', '68P30\xa0']"
history,"['2017-05', '2016-01-25', '2015-07-06', '2016-01-19']"
abstract,"Abstract Multimedia fingerprinting is an effective technique to trace the sources of pirate copies of copyrighted multimedia information. Separable codes can be used to construct fingerprints resistant to the averaging collusion attack on multimedia contents. In this paper, we first show an equivalent condition of a \(\overline {2}\)-SC (4,M,q), and then construct two infinite families of \(\overline {2}\)-SCs of length 4, one of which is asymptotically optimal."
journal_title,Cryptography and Communications
article_title,A kind of three-weight linear codes
keyword,"['Authentication codes\xa0', 'Linear codes\xa0', 'Secret sharing schemes\xa0', 'Weight distribution\xa0']"
history,"['2017-05', '2016-01-12', '2015-09-16', '2015-12-23']"
abstract,"Abstract Recently, linear codes with few weights have been constructed through defining sets. Results  show that some optimal codes can be obtained if the defining sets were well chosen. In this paper, we investigate the linear codes constructed from the absolute trace function. It is shown that the constructed codes are binary linear codes with three weights. The dual codes of the proposed linear codes are also studied and proved to be optimal or almost optimal."
journal_title,Cryptography and Communications
article_title,On the nonlinearity of S-boxes and linear codes
keyword,"['Symmetric cryptography\xa0', 'Multi-output Boolean functions\xa0', 'S-boxes\xa0', 'Affine approximation attack\xa0', 'Nonlinearity\xa0', 'Linear codes\xa0', '06E30\xa0', '94A60\xa0']"
history,"['2017-05', '2016-01-13', '2015-03-15', '2015-12-09']"
abstract,"Abstract For multi-output Boolean functions (also called S-boxes), various measures of nonlinearity have been widely discussed in the literature but many problems are left open in this topic. The purpose of this paper is to present a new approach to estimating the nonlinearity of S-boxes. A more fine-grained view on the notion of nonlinearity of S-boxes is presented and new connections to some linear codes are established. More precisely, we mainly study the nonlinearity indicator (denoted by \(\mathcal {N}_{\mathrm {v}}\)) for S-boxes from a coding theory point of view. Such a cryptographic parameter \(\mathcal {N}_{\mathrm {v}}\) is more related to best affine approximation attacks on stream ciphers. We establish a direct link between \(\mathcal {N}_{\mathrm {v}}\) and the minimum distance of the corresponding linear code. We exploit that connection to derive the first general lower bounds on \(\mathcal {N}_{\mathrm {v}}\) of non-affine functions from \(\mathbb {F}_{2^{n}}\) to \(\mathbb {F}_{2^{m}}\) for m dividing n. Furthermore, we show that \(\mathcal {N}_{\mathrm {v}}\) can be determined directly by the weight distribution of the corresponding linear code."
journal_title,Cryptography and Communications
article_title,New differentially 4-uniform permutations by modifying the inverse function on subfields
keyword,"['S-box\xa0', 'Differentially 4-uniform permutation\xa0', 'Algebraic degree\xa0', 'Nonlinearity\xa0', 'CCZ-equivalent\xa0', '94A60\xa0', '11T71\xa0', '14G50\xa0']"
history,"['2017-05', '2016-01-15', '2015-04-30', '2016-01-05']"
abstract,"Abstract Permutations over \(\mathbb {F}_{2^{2k}}\) with low differential uniformity, high algebraic degree and high nonlinearity are of great cryptographic importance since they can be chosen as the substitution boxes (S-boxes) for many block ciphers with SPN (Substitution Permutation Network) structure. A well known example is that the S-box of the famous Advanced Encryption Standard (AES) is derived from the inverse function on \(\mathbb {F}_{2^{8}}\), which has been proved to be a differentially 4-uniform permutation with the optimal algebraic degree and known best nonlinearity. Recently, Zha et al. proposed two constructions of differentially 4-uniform permutations over \(\mathbb {F}_{2^{2k}}\), say G  t  and G  s, t  with T r(s −1) = 1, by applying affine transformations to the inverse function on some subfields of \(\mathbb {F}_{2^{2k}}\) (Zha et al. Finite Fields Appl. 25, 64–78, 2014). In this paper, we generalize their method by applying other types of EA (extended affine) equivalent transformations to the inverse function on some subfields of \(\mathbb {F}_{2^{2k}}\) and present two new constructions of differentially 4-uniform permutations, say F  α  and F  β, α  with T r(β −1) = 1. Furthermore, we prove that all the functions G  t  with different t are CCZ (Carlet-Charpin-Zinoviev) equivalent to our subclass F 0, while all the functions G  s, t  with different t are CCZ-equivalent to our subclass F  s,0. In addition, both our two constructions give many new CCZ-inequivalent classes of such functions, as checked by computer in small numbers of variables. Moreover, all these newly constructed permutations are proved to have the optimal algebraic degree and high nonlinearity."
journal_title,Cryptography and Communications
article_title,Complete weight distributions of two classes of cyclic codes
keyword,"['Cyclic code\xa0', 'Complete weight distribution\xa0', 'Weight distribution\xa0', 'Quadratic form\xa0', '94B15\xa0', '11T71\xa0']"
history,"['2017-05', '2016-01-13', '2015-07-12', '2015-12-22']"
abstract,"Abstract Complete weight distribution can be used to study authentication codes and the Walsh transform of monomial functions over finite fields. Also, the Hamming weight distribution of a code can be obtained from its complete weight distribution. In this paper, we investigate the complete weight distributions of two classes of cyclic codes. We explicitly present the complete weight enumerators of the cyclic codes. Particularly, we partly solve an open problem proposed in Luo and Feng (IEEE Trans. Inf. Theory 54(12), 5345–5353 (2008))."
journal_title,Cryptography and Communications
article_title,Some new classes of 2-fold optimal or perfect splitting authentication codes
keyword,"[None, None, 'Splitting authentication codes\xa0', '05B05\xa0', '94A62\xa0']"
history,"['2017-05', '2016-01-28', '2015-08-04', '2015-12-23']"
abstract,"Abstract Optimal restricted strong partially balanced t-design can be used to construct splitting authentication codes which achieve combinatorial lower bounds or information-theoretic lower bounds. In this paper, we investigate the existence of optimal restricted strong partially balanced 2-designs ORSPBD (v, k×c,1), and show that there exists an ORSPBD (v,2×c,1) for any positive integer v≡ v 0 (mod 2c 2) and \(v_{0}\in \{1\leq x\leq 2c^{2}:\ \gcd (x,c)=1\ \text {or} \ \gcd (x,c)=c \} \setminus \) \(\{c^{2}+1\leq x\leq (c+1)^{2} :\gcd (x,c)=1\ \text {and}\ \gcd (x,2)=2\}\). Furthermore, we determine the existence of an ORSPBD (v,k×c,1) for any integer v≥k c with (k,c)=(2,4), (2,5), (3,2) or for any even integer v≥k c with (k,c)=(4,2). As their applications, we obtain six new infinite classes of 2-fold optimal or perfect c-splitting authentication codes."
journal_title,Cryptography and Communications
article_title,A new class of Fibonacci sequence based error correcting codes
keyword,"['Fibonacci coding\xa0', 'Encoding matrix\xa0', 'Fibonacci sequence\xa0', '68P30\xa0', '11B39\xa0']"
history,"['2017-05', '2016-01-21', '2015-02-10', '2015-12-23']"
abstract,"Abstract A new class of matrices is introduced for use in error control coding. This extends previous results on the class of Fibonacci error correcting codes. For a given integer p, a (p+1)×(p+1) binary matrix M  p  is given whose nonzero entries are located either on the superdiagonal or the last row of the matrix. The matrices \({M^{n}_{p}}\) and \(M^{-n}_{p}\), the nth power of M  p  and its inverse, are employed as the encoding and decoding matrices, respectively. It is shown that for sufficiently large n, independent of the message matrix M, relations exist among the elements of the encoded matrix \(E=M\times {M_{p}^{n}}\). These relations play a key role in the error detection and correction."
journal_title,Cryptography and Communications
article_title,On the correlation distribution of the generalized maximal length ℤ4-sequences
keyword,"['Correlation distribution\xa0', 'Galois ring\xa0', None, None, '94A05\xa0', '94A55\xa0']"
history,"['2017-03', '2015-11-25', '2015-05-01', '2015-11-13']"
abstract,"Abstract A family of maximal length ℤ4-sequences was proposed by Tang, Udaya and Fan in 2005 by using binary sequences based on quadratic forms over finite fields, and was shown to possess low correlation property. However, its correlation distribution still remains open. In this paper, the maximal length ℤ4-sequences constructed by Tang, Udaya and Fan are equivalently expressed as another form via ℤ4-valued quadratic forms and then the correlation distribution is completely determined from the approach of ℤ4-valued quadratic forms."
journal_title,Cryptography and Communications
article_title,Constructions of negabent functions over finite fields
keyword,"['Negabent functions\xa0', 'Bent functions\xa0', 'Finite fields\xa0', 'Relative difference sets\xa0', 'Projective polynomials\xa0', '05B10\xa0', '11T06\xa0', '06E30\xa0', '11T71\xa0']"
history,"['2017-03', '2015-11-12', '2015-01-14', '2015-10-28']"
abstract,"Abstract Bent functions are actively investigated for their various applications in cryptography, coding theory and combinatorial design. As one of their generalizations, negabent functions are also quite useful, and they are originally defined via nega-Hadamard transforms for boolean functions. In this paper, we look at another equivalent definition of them. It allows us to investigate negabent functions f on \(\mathbb {F}_{2^{n}}\), which can be written as a composition of a univariate polynomial over \(\mathbb {F}_{2^{n}}\) and the trace mapping from \(\mathbb {F}_{2^{n}}\) to \(\mathbb {F}_{2}\). In particular, when this polynomial is a monomial, we call f a monomial negabent function. Families of quadratic and cubic monomial negabent functions are constructed, together with several sporadic examples. To obtain more interesting negabent functions in special forms, we also look at certain negabent polynomials. We obtain several families of cubic negabent functions by using the theory of projective polynomials over finite fields."
journal_title,Cryptography and Communications
article_title,Cryptographic Boolean functions with biased inputs
keyword,"['Boolean functions\xa0', 'Quantum Boolean functions\xa0', 'Bias\xa0', 'Walsh–Hadamard transform\xa0', 'Nega-Hadamard transform\xa0', '94A60\xa0', '94C10\xa0', '81P94\xa0', '06E30\xa0']"
history,"['2017-03', '2015-12-17', '2015-02-10', '2015-11-30']"
abstract,"Abstract While performing cryptanalysis, it is of interest to approximate a Boolean function in n variables \(f: {\mathbb {F}_{2}^{n}} \rightarrow \mathbb {F}_{2}\) by affine functions. Usually, it is assumed that all the input vectors to a Boolean function are equiprobable while mounting affine approximation attack or fast correlation attacks. In this paper we consider a more general case when each component of the input vector to f is independent and identically distributed Bernoulli variates with the parameter p. Since our scope is within the area of cryptography, we initiate an analysis of cryptographic Boolean functions under the previous considerations and derive expression of the analogue of Walsh–Hadamard transform and nonlinearity in the case under consideration. We observe that if we allow p to take up complex values then a framework involving quantum Boolean functions can be introduced, which provides a connection between Walsh-Hadamard transform, nega-Hadamard transform and Boolean functions with biased inputs."
journal_title,Cryptography and Communications
article_title,A mass formula for negacyclic codes of length 2k and some good negacyclic codes over ℤ4+uℤ4$\mathbb {Z}_{4}+u\mathbb {Z}_{4}$
keyword,"[None, 'Negacyclic codes\xa0', 'Cyclic codes\xa0', 'Repeated root cyclic codes\xa0', '94B05\xa0', '94B60\xa0']"
history,"['2017-03', '2015-12-07', '2015-03-20', '2015-11-23']"
abstract,"Abstract In this paper, we study negacyclic codes of length 2 k  over the ring \(R=\mathbb {Z}_{4}+u\mathbb {Z}_{4}\), u 2 = 0. We have obtained a mass formula for the number of negacyclic of length 2 k  over R. We have also determined the number of self-dual negacyclic codes of length 2 k  over R. This study has been further generalized to negacyclic codes of any even length using discrete Fourier transform approach over R. We have conducted an exhaustive search and obtained some new \(\mathbb {Z}_{4}\)-linear codes with good parameters."
journal_title,Cryptography and Communications
article_title,1-generator generalized quasi-cyclic codes over ℤ4$\mathbb {Z}_{4}$
keyword,"['1-generator generalized quasi-cyclic codes\xa0', None, 'Gray map\xa0', 'Good binary nonlinear codes\xa0', '94B05\xa0', '94B15\xa0']"
history,"['2017-03', '2015-12-14', '2015-05-23', '2015-12-03']"
abstract,"Abstract In this short paper, we determine the minimal generating set of 1-generator generalized quasi-cyclic codes over \(\mathbb {Z}_{4}\). We also determine their rank and introduce a lower bound for the minimum distance of free 1-generator generalized quasi-cyclic codes. Further, we construct some new \(\mathbb {Z}_{4}\)-linear codes and we obtain some good binary nonlinear codes using the usual Gray map."
journal_title,Cryptography and Communications
article_title,On the second relative greedy weight
keyword,"['Relative greedy weight\xa0', 'Relative generalized Hamming weight\xa0', 'Value assignment\xa0', 'Upper bound\xa0', 'Support weight\xa0', '94B05\xa0']"
history,"['2017-03', '2015-11-19', '2015-06-20', '2015-11-11']"
abstract,"Abstract Based on the wire-tap channel of type II with two users given by Luo et al. in 2005, we introduce the relative greedy weights. A finite projective geometry method is presented in order to describe the relative greedy weights. By using this finite projective geometry method, the optimal 3-dimensional q-ary codes are searched so as to maximize the effort for the adversary to obtain the second data symbol on condition that he has obtained the first data symbol from the wire-tap channel of type II with two users."
journal_title,Cryptography and Communications
article_title,Counting and characterising functions with “fast points” for differential attacks
keyword,"['Higher order differential attacks\xa0', 'Higher order derivative\xa0', 'Cryptanalysis\xa0', 'Polynomials over finite fields\xa0', '94A60\xa0', '11T55\xa0']"
history,"['2017-03', '2015-11-26', '2015-04-22', '2015-10-21']"
abstract,"Abstract Higher order derivatives have been introduced by Lai in a cryptographic context. A number of attacks such as differential cryptanalysis, the cube and the AIDA attack have been reformulated using higher order derivatives. Duan and Lai have introduced the notion of “fast points” of a polynomial function f as being vectors a so that computing the derivative with respect to a decreases the total degree of f by more than one. This notion is motivated by the fact that most of the attacks become more efficient if they use fast points. Duan and Lai gave a characterisation of fast points and Duan et al. gave some results regarding the number of functions with fast points in some particular cases. We firstly give an alternative characterisation of fast points and secondly give an explicit formula for the number of functions with fast points for any given degree and number of variables, thus covering all the cases left open in Duan et al. Our main tool is an invertible linear change of coordinates which transforms the higher order derivative with respect to an arbitrary set of linearly independent vectors into the higher order derivative with respect to a set of vectors in the canonical basis. Finally we discuss the cryptographic significance of our results."
journal_title,Cryptography and Communications
article_title,Espresso: A stream cipher for 5G wireless communication systems
keyword,"['Stream cipher\xa0', 'Encryption\xa0', 'FSR\xa0', 'Wireless\xa0', '5G\xa0', '94A60\xa0', '68P25\xa0', '11T71\xa0']"
history,"['2017-03', '2015-12-07', '2015-01-20', '2015-11-23']"
abstract,"Abstract The demand for more efficient ciphers is a likely to sharpen with new generation of products and applications. Previous cipher designs typically focused on optimizing only one of the two parameters - hardware size or speed, for a given security level. In this paper, we present a methodology for designing a class of stream ciphers which takes into account both parameters simultaneously. We combine the advantage of the Galois configuration of NLFSRs, short propagation delay, with the advantage of the Fibonacci configuration of NLFSRs, which can be analyzed formally. According to our analysis, the presented stream cipher Espresso is the fastest among the ciphers below 1500 GE, including Grain-128 and Trivium."
journal_title,Cryptography and Communications
article_title,Preface: Special functions and codes
keyword,[]
history,"['2017-01', '2016-08-22']"
abstract,None
journal_title,Statistics and Computing
article_title,Reliable error estimation for Sobol’ indices
keyword,"['Sobol’ index\xa0', 'Error bound\xa0', 'Sequential method\xa0', 'Quasi-Monte Carlo\xa0', '49Q12\xa0', '62L12\xa0', '65R10\xa0']"
history,"['2018-07', '2017-06-14', '2016-10-26', '2017-05-31']"
abstract,"Abstract In the field of sensitivity analysis, Sobol’ indices are sensitivity measures widely used to assess the importance of inputs of a model to its output. The estimation of these indices is often performed through Monte Carlo or quasi-Monte Carlo methods. A notable method is the replication procedure that estimates first-order indices at a reduced cost in terms of number of model evaluations. An inherent practical problem of this estimation is how to quantify the number of model evaluations needed to ensure that estimates satisfy a desired error tolerance. This article addresses this challenge by proposing a reliable error bound for first-order and total effect Sobol’ indices. Starting from the integral formula of the indices, the error bound is defined in terms of the discrete Walsh coefficients of the different integrands. We propose a sequential estimation procedure of Sobol’ indices using the error bound as a stopping criterion. The sequential procedure combines Sobol’ sequences with either Saltelli’s strategy to estimate both first-order and total effect indices, or the replication procedure to estimate only first-order indices."
journal_title,Statistics and Computing
article_title,A network epidemic model for online community commissioning data
keyword,"['Stochastic epidemic models\xa0', 'MCMC\xa0', 'Random graphs\xa0', 'Preferential attachment\xa0', 'Community commissioning\xa0']"
history,"['2018-07', '2017-08-02', '2017-02-27', '2017-07-26']"
abstract,"Abstract A statistical model assuming a preferential attachment network, which is generated by adding nodes sequentially according to a few simple rules, usually describes real-life networks better than a model assuming, for example, a Bernoulli random graph, in which any two nodes have the same probability of being connected, does. Therefore, to study the propagation of “infection” across a social network, we propose a network epidemic model by combining a stochastic epidemic model and a preferential attachment model. A simulation study based on the subsequent Markov Chain Monte Carlo algorithm reveals an identifiability issue with the model parameters. Finally, the network epidemic model is applied to a set of online commissioning data."
journal_title,Statistics and Computing
article_title,Nested Kriging predictions for datasets with a large number of observations
keyword,"['Gaussian process regression\xa0', 'Big data\xa0', 'Aggregation methods\xa0', 'Best linear unbiased predictor\xa0', 'Spatial processes\xa0']"
history,"['2018-07', '2017-07-26', '2016-12-09', '2017-07-19']"
abstract,"Abstract This work falls within the context of predicting the value of a real function at some input locations given a limited number of observations of this function. The Kriging interpolation technique (or Gaussian process regression) is often considered to tackle such a problem, but the method suffers from its computational burden when the number of observation points is large. We introduce in this article nested Kriging predictors which are constructed by aggregating sub-models based on subsets of observation points. This approach is proven to have better theoretical properties than other aggregation methods that can be found in the literature. Contrarily to some other methods it can be shown that the proposed aggregation method is consistent. Finally, the practical interest of the proposed method is illustrated on simulated datasets and on an industrial test case with \(10^4\) observations in a 6-dimensional space."
journal_title,Statistics and Computing
article_title,Variational Bayes with synthetic likelihood
keyword,"['Approximate Bayesian computation\xa0', 'Stochastic gradient ascent\xa0', 'Synthetic likelihoods\xa0', 'Variational Bayes\xa0']"
history,"['2018-07', '2017-08-31', '2016-08-12', '2017-08-21']"
abstract,"Abstract Synthetic likelihood is an attractive approach to likelihood-free inference when an approximately Gaussian summary statistic for the data, informative for inference about the parameters, is available. The synthetic likelihood method derives an approximate likelihood function from a plug-in normal density estimate for the summary statistic, with plug-in mean and covariance matrix obtained by Monte Carlo simulation from the model. In this article, we develop alternatives to Markov chain Monte Carlo implementations of Bayesian synthetic likelihoods with reduced computational overheads. Our approach uses stochastic gradient variational inference methods for posterior approximation in the synthetic likelihood context, employing unbiased estimates of the log likelihood. We compare the new method with a related likelihood-free variational inference technique in the literature, while at the same time improving the implementation of that approach in a number of ways. These new algorithms are feasible to implement in situations which are challenging for conventional approximate Bayesian computation methods, in terms of the dimensionality of the parameter and summary statistic."
journal_title,Statistics and Computing
article_title,Extended differential geometric LARS for high-dimensional GLMs with general dispersion parameter
keyword,"['High-dimensional inference\xa0', 'Generalized linear models\xa0', 'Least angle regression\xa0', 'Predictor–corrector algorithm\xa0', 'Dispersion paremeter\xa0']"
history,"['2018-07', '2017-06-21', '2017-02-10', '2017-06-16']"
abstract,"Abstract A large class of modeling and prediction problems involves outcomes that belong to an exponential family distribution. Generalized linear models (GLMs) are a standard way of dealing with such situations. Even in high-dimensional feature spaces GLMs can be extended to deal with such situations. Penalized inference approaches, such as the \(\ell _1\) or SCAD, or extensions of least angle regression, such as dgLARS, have been proposed to deal with GLMs with high-dimensional feature spaces. Although the theory underlying these methods is in principle generic, the implementation has remained restricted to dispersion-free models, such as the Poisson and logistic regression models. The aim of this manuscript is to extend the differential geometric least angle regression method for high-dimensional GLMs to arbitrary exponential dispersion family distributions with arbitrary link functions. This entails, first, extending the predictor–corrector (PC) algorithm to arbitrary distributions and link functions, and second, proposing an efficient estimator of the dispersion parameter. Furthermore, improvements to the computational algorithm lead to an important speed-up of the PC algorithm. Simulations provide supportive evidence concerning the proposed efficient algorithms for estimating coefficients and dispersion parameter. The resulting method has been implemented in our R package (which will be merged with the original dglars package) and is shown to be an effective method for inference for arbitrary classes of GLMs."
journal_title,Statistics and Computing
article_title,A rare event approach to high-dimensional approximate Bayesian computation
keyword,"['ABC\xa0', 'Markov chain Monte Carlo\xa0', 'Sequential Monte Carlo\xa0', 'Slice sampling\xa0', 'Infectious disease modelling\xa0']"
history,"['2018-07', '2017-07-11', '2016-11-08', '2017-07-04']"
abstract,"Abstract Approximate Bayesian computation (ABC) methods permit approximate inference for intractable likelihoods when it is possible to simulate from the model. However, they perform poorly for high-dimensional data and in practice must usually be used in conjunction with dimension reduction methods, resulting in a loss of accuracy which is hard to quantify or control. We propose a new ABC method for high-dimensional data based on rare event methods which we refer to as RE-ABC. This uses a latent variable representation of the model. For a given parameter value, we estimate the probability of the rare event that the latent variables correspond to data roughly consistent with the observations. This is performed using sequential Monte Carlo and slice sampling to systematically search the space of latent variables. In contrast, standard ABC can be viewed as using a more naive Monte Carlo estimate. We use our rare event probability estimator as a likelihood estimate within the pseudo-marginal Metropolis–Hastings algorithm for parameter inference. We provide asymptotics showing that RE-ABC has a lower computational cost for high-dimensional data than standard ABC methods. We also illustrate our approach empirically, on a Gaussian distribution and an application in infectious disease modelling."
journal_title,Statistics and Computing
article_title,Inferring large graphs using $$\ell _1$$ℓ1-penalized likelihood
keyword,"['Directed acyclic graphs\xa0', 'Lasso\xa0', 'Convex program\xa0', 'Optimization\xa0']"
history,"['2018-07', '2017-08-17', '2017-01-24', '2017-07-26']"
abstract,"Abstract We address the issue of recovering the structure of large sparse directed acyclic graphs from noisy observations of the system. We propose a novel procedure based on a specific formulation of the \(\ell _1\)-norm regularized maximum likelihood, which decomposes the graph estimation into two optimization sub-problems: topological structure and node order learning. We provide convergence inequalities for the graph estimator, as well as an algorithm to solve the induced optimization problem, in the form of a convex program embedded in a genetic algorithm. We apply our method to various data sets (including data from the DREAM4 challenge) and show that it compares favorably to state-of-the-art methods. This algorithm is available on CRAN as the R package GADAG."
journal_title,Statistics and Computing
article_title,Multilevel and Multi-index Monte Carlo methods for the McKean–Vlasov equation
keyword,"['Multi-index Monte Carlo\xa0', 'Multilevel Monte Carlo\xa0', 'Monte Carlo\xa0', 'Particle systems\xa0', 'McKean–Vlasov\xa0', 'Mean-field\xa0', 'Stochastic differential equations\xa0', 'Weak approximation\xa0', 'Sparse approximation\xa0', 'Combination technique\xa0', '65C05 (Monte Carlo methods)\xa0', '65C30 (Stochastic differential and integral equations)\xa0', '65C35 (Stochastic particle methods)\xa0']"
history,"['2018-07', '2017-09-12', '2016-10-31', '2017-07-31']"
abstract,"Abstract We address the approximation of functionals depending on a system of particles, described by stochastic differential equations (SDEs), in the mean-field limit when the number of particles approaches infinity. This problem is equivalent to estimating the weak solution of the limiting McKean–Vlasov SDE. To that end, our approach uses systems with finite numbers of particles and a time-stepping scheme. In this case, there are two discretization parameters: the number of time steps and the number of particles. Based on these two parameters, we consider different variants of the Monte Carlo and Multilevel Monte Carlo (MLMC) methods and show that, in the best case, the optimal work complexity of MLMC, to estimate the functional in one typical setting with an error tolerance of \(\mathrm {TOL}\), is  Open image in new window  when using the partitioning estimator and the Milstein time-stepping scheme. We also consider a method that uses the recent Multi-index Monte Carlo method and show an improved work complexity in the same typical setting of  Open image in new window . Our numerical experiments are carried out on the so-called Kuramoto model, a system of coupled oscillators."
journal_title,Statistics and Computing
article_title,Bayesian Additive Regression Trees using Bayesian model averaging
keyword,"['Bayesian Additive Regression Trees\xa0', 'Bayesian model averaging\xa0', 'Random forest\xa0', 'Biomarker selection\xa0', None]"
history,"['2018-07', '2017-07-27', '2015-07-01', '2017-07-19']"
abstract,"Abstract Bayesian Additive Regression Trees (BART) is a statistical sum of trees model. It can be considered a Bayesian version of machine learning tree ensemble methods where the individual trees are the base learners. However, for datasets where the number of variables p is large the algorithm can become inefficient and computationally expensive. Another method which is popular for high-dimensional data is random forests, a machine learning algorithm which grows trees using a greedy search for the best split points. However, its default implementation does not produce probabilistic estimates or predictions. We propose an alternative fitting algorithm for BART called BART-BMA, which uses Bayesian model averaging and a greedy search algorithm to obtain a posterior distribution more efficiently than BART for datasets with large p. BART-BMA incorporates elements of both BART and random forests to offer a model-based algorithm which can deal with high-dimensional data. We have found that BART-BMA can be run in a reasonable time on a standard laptop for the “small n large p” scenario which is common in many areas of bioinformatics. We showcase this method using simulated data and data from two real proteomic experiments, one to distinguish between patients with cardiovascular disease and controls and another to classify aggressive from non-aggressive prostate cancer. We compare our results to their main competitors. Open source code written in R and Rcpp to run BART-BMA can be found at: https://github.com/BelindaHernandez/BART-BMA.git."
journal_title,Statistics and Computing
article_title,Relabelling in Bayesian mixture models by pivotal units
keyword,"['Label switching\xa0', 'Complex posterior distributions\xa0', 'MCMC\xa0', 'Finite mixture model\xa0']"
history,"['2018-07', '2017-08-28', '2017-01-07', '2017-08-21']"
abstract,"Abstract Label switching is a well-known and fundamental problem in Bayesian estimation of finite mixture models. It arises when exploring complex posterior distributions by Markov Chain Monte Carlo (MCMC) algorithms, because the likelihood of the model is invariant to the relabelling of mixture components. If the MCMC sampler randomly switches labels, then it is unsuitable for exploring the posterior distributions for component-related parameters. In this paper, a new procedure based on the post-MCMC relabelling of the chains is proposed. The main idea of the method is to perform a clustering technique on the similarity matrix, obtained through the MCMC sample, whose elements are the probabilities that any two units in the observed sample are drawn from the same component. Although it cannot be generalized to any situation, it may be handy in many applications because of its simplicity and very low computational burden."
journal_title,Statistics and Computing
article_title,Pivotal variable detection of the covariance matrix and its application to high-dimensional factor models
keyword,"['Covariance matrix estimation\xa0', 'Factor model\xa0', 'Principal component analysis\xa0', 'Pivotal variable detection\xa0', 'Row sparsity\xa0', 'Ultra-high dimension\xa0']"
history,"['2018-07', '2017-07-15', '2015-11-21', '2017-06-26']"
abstract,"Abstract To estimate the high-dimensional covariance matrix, row sparsity is often assumed such that each row has a small number of nonzero elements. However, in some applications, such as factor modeling, there may be many nonzero loadings of the common factors. The corresponding variables are also correlated to one another and the rows are non-sparse or dense. This paper has three main aims. First, a detection method is proposed to identify the rows that may be non-sparse, or at least dense with many nonzero elements. These rows are called dense rows and the corresponding variables are called pivotal variables. Second, to determine the number of rows, a ridge ratio method is suggested, which can be regarded as a sure screening procedure. Third, to handle the estimation of high-dimensional factor models, a two-step procedure is suggested with the above screening as the first step. Simulations are conducted to examine the performance of the new method and a real dataset is analyzed for illustration."
journal_title,Statistics and Computing
article_title,On the exact maximum likelihood inference of Fisher–Bingham distributions using an adjusted holonomic gradient method
keyword,"['Bingham distributions\xa0', 'Fisher–Bingham distributions\xa0', 'Directional statistics\xa0', 'Holonomic functions\xa0']"
history,"['2018-07', '2017-08-09', '2016-10-06', '2017-07-09']"
abstract,"Abstract Holonomic function theory has been successfully implemented in a series of recent papers to efficiently calculate the normalizing constant and perform likelihood estimation for the Fisher–Bingham distributions. A key ingredient for establishing the standard holonomic gradient algorithms is the calculation of the Pfaffian equations. So far, these papers either calculate these symbolically or apply certain methods to simplify this process. Here we show the explicit form of the Pfaffian equations using the expressions from Laplace inversion methods. This improves on the implementation of the holonomic algorithms for these problems and enables their adjustments for the degenerate cases. As a result, an exact and more dimensionally efficient ODE is implemented for likelihood inference."
journal_title,Statistics and Computing
article_title,Fast computation of spatially adaptive kernel estimates
keyword,"['Bandwidth selection\xa0', 'Edge correction\xa0', 'Fourier transform\xa0', 'Intensity\xa0', 'Scale space\xa0', 'Spatial point process\xa0']"
history,"['2018-07', '2017-08-05', '2017-02-03', '2017-08-02']"
abstract,"Abstract Kernel smoothing of spatial point data can often be improved using an adaptive, spatially varying bandwidth instead of a fixed bandwidth. However, computation with a varying bandwidth is much more demanding, especially when edge correction and bandwidth selection are involved. This paper proposes several new computational methods for adaptive kernel estimation from spatial point pattern data. A key idea is that a variable-bandwidth kernel estimator for d-dimensional spatial data can be represented as a slice of a fixed-bandwidth kernel estimator in \((d+1)\)-dimensional scale space, enabling fast computation using Fourier transforms. Edge correction factors have a similar representation. Different values of global bandwidth correspond to different slices of the scale space, so that bandwidth selection is greatly accelerated. Potential applications include estimation of multivariate probability density and spatial or spatiotemporal point process intensity, relative risk, and regression functions. The new methods perform well in simulations and in two real applications concerning the spatial epidemiology of primary biliary cirrhosis and the alarm calls of capuchin monkeys."
journal_title,Statistics and Computing
article_title,Computer experiment designs for accurate prediction
keyword,"['Experimental design\xa0', 'Gaussian process Kriging interpolator\xa0', 'IMSPE\xa0', 'Latin hypercube design\xa0', 'Maximum projection design\xa0', 'Space-filling design\xa0']"
history,"['2018-07', '2017-06-22', '2016-12-11', '2017-06-14']"
abstract,"Abstract Computer experiments using deterministic simulators are sometimes used to replace or supplement physical system experiments. This paper compares designs for an initial computer simulator experiment based on empirical prediction accuracy; it recommends designs for producing accurate predictions. The basis for the majority of the designs compared is the integrated mean squared prediction error (IMSPE) that is computed assuming a Gaussian process model with a Gaussian correlation function. Designs that minimize the IMSPE with respect to a fixed set of correlation parameters as well as designs that minimize a weighted IMSPE over the correlation parameters are studied. These IMSPE-based designs are compared with three widely-used space-filling designs. The designs are used to predict test surfaces representing a range of stationary and non-stationary functions. For the test conditions examined in this paper, the designs constructed under IMSPE-based criteria are shown to outperform space-filling Latin hypercube designs and maximum projection designs when predicting smooth functions of stationary appearance, while space-filling and maximum projection designs are superior for test functions that exhibit strong non-stationarity."
journal_title,Statistics and Computing
article_title,Modified Cholesky Riemann Manifold Hamiltonian Monte Carlo: exploiting sparsity for fast sampling of high-dimensional targets
keyword,"['Bayesian hierarchical models\xa0', 'Hamiltonian Monte Carlo\xa0', 'Hessian\xa0', 'MCMC\xa0', 'Metric tensor\xa0']"
history,"['2018-07', '2017-07-10', '2016-12-13', '2017-07-04']"
abstract,"Abstract Riemann manifold Hamiltonian Monte Carlo (RMHMC) has the potential to produce high-quality Markov chain Monte Carlo output even for very challenging target distributions. To this end, a symmetric positive definite scaling matrix for RMHMC is proposed. The scaling matrix is obtained by applying a modified Cholesky factorization to the potentially indefinite negative Hessian of the target log-density. The methodology is able to exploit the sparsity of the Hessian, stemming from conditional independence modeling assumptions, and thus admit fast implementation of RMHMC even for high-dimensional target distributions. Moreover, the methodology can exploit log-concave conditional target densities, often encountered in Bayesian hierarchical models, for faster sampling and more straightforward tuning. The proposed methodology is compared to alternatives for some challenging targets and is illustrated by applying a state-space model to real data."
journal_title,Statistics and Computing
article_title,Erratum to: Fast covariance estimation for sparse functional data
keyword,[]
history,"['2018-05', '2017-08-23']"
abstract,None
journal_title,Statistics and Computing
article_title,Density estimation with distribution element trees
keyword,"['Nonparametric density estimation\xa0', 'Adaptive histogram\xa0', 'Kernel density estimation\xa0', 'Adaptive binning\xa0', 'Polynomial histogram\xa0', 'Curse of dimensionality\xa0', 'High dimensional\xa0', 'Big data\xa0', 'Pólya tree\xa0', 'Density estimation tree\xa0', '62G07\xa0', '62H10\xa0', '62G10\xa0']"
history,"['2018-05', '2017-05-16', '2016-11-06', '2017-05-02']"
abstract,"Abstract The estimation of probability densities based on available data is a central task in many statistical applications. Especially in the case of large ensembles with many samples or high-dimensional sample spaces, computationally efficient methods are needed. We propose a new method that is based on a decomposition of the unknown distribution in terms of so-called distribution elements (DEs). These elements enable an adaptive and hierarchical discretization of the sample space with small or large elements in regions with smoothly or highly variable densities, respectively. The novel refinement strategy that we propose is based on statistical goodness-of-fit and pairwise (as an approximation to mutual) independence tests that evaluate the local approximation of the distribution in terms of DEs. The capabilities of our new method are inspected based on several examples of different dimensionality and successfully compared with other state-of-the-art density estimators."
journal_title,Statistics and Computing
article_title,Efficient Bayesian inference for COM-Poisson regression models
keyword,"['Bayesian statistics\xa0', 'Conway–Maxwell–Poisson regression\xa0', 'Count data\xa0', 'Exchange algorithm\xa0', 'Markov chain Monte Carlo\xa0', 'Rejection sampling\xa0']"
history,"['2018-05', '2017-04-24', '2016-11-15', '2017-04-18']"
abstract,"Abstract COM-Poisson regression is an increasingly popular model for count data. Its main advantage is that it permits to model separately the mean and the variance of the counts, thus allowing the same covariate to affect in different ways the average level and the variability of the response variable. A key limiting factor to the use of the COM-Poisson distribution is the calculation of the normalisation constant: its accurate evaluation can be time-consuming and is not always feasible. We circumvent this problem, in the context of estimating a Bayesian COM-Poisson regression, by resorting to the exchange algorithm, an MCMC method applicable to situations where the sampling model (likelihood) can only be computed up to a normalisation constant. The algorithm requires to draw from the sampling model, which in the case of the COM-Poisson distribution can be done efficiently using rejection sampling. We illustrate the method and the benefits of using a Bayesian COM-Poisson regression model, through a simulation and two real-world data sets with different levels of dispersion."
journal_title,Statistics and Computing
article_title,Langevin incremental mixture importance sampling
keyword,"['Importance sampling\xa0', 'Langevin diffusion\xa0', 'Mixture density\xa0', 'Optimal importance distribution\xa0', 'Local approximation\xa0', 'Kalman-Bucy filter\xa0']"
history,"['2018-05', '2017-04-19', '2016-11-23', '2017-04-11']"
abstract,"Abstract This work proposes a novel method through which local information about the target density can be used to construct an efficient importance sampler. The backbone of the proposed method is the incremental mixture importance sampling (IMIS) algorithm of Raftery and Bao (Biometrics 66(4):1162–1173, 2010), which builds a mixture importance distribution incrementally, by positioning new mixture components where the importance density lacks mass, relative to the target. The key innovation proposed here is to construct the mean vectors and covariance matrices of the mixture components by numerically solving certain differential equations, whose solution depends on the local shape of the target log-density. The new sampler has a number of advantages: (a) it provides an extremely parsimonious parametrization of the mixture importance density, whose configuration effectively depends only on the shape of the target and on a single free parameter representing pseudo-time; (b) it scales well with the dimensionality of the target; (c) it can deal with targets that are not log-concave. The performance of the proposed approach is demonstrated on two synthetic non-Gaussian densities, one being defined on up to eighty dimensions, and on a Bayesian logistic regression model, using the Sonar dataset. The Julia code implementing the importance sampler proposed here can be found at https://github.com/mfasiolo/LIMIS."
journal_title,Statistics and Computing
article_title,Gradient boosting for distributional regression: faster tuning and improved variable selection via noncyclical updates
keyword,"['Boosting\xa0', 'Additive models\xa0', 'GAMLSS\xa0', 'GamboostLSS\xa0', 'Stability selection\xa0']"
history,"['2018-05', '2017-05-11', '2016-11-03', '2017-05-05']"
abstract,"Abstract We present a new algorithm for boosting generalized additive models for location, scale and shape (GAMLSS) that allows to incorporate stability selection, an increasingly popular way to obtain stable sets of covariates while controlling the per-family error rate. The model is fitted repeatedly to subsampled data, and variables with high selection frequencies are extracted. To apply stability selection to boosted GAMLSS, we develop a new “noncyclical” fitting algorithm that incorporates an additional selection step of the best-fitting distribution parameter in each iteration. This new algorithm has the additional advantage that optimizing the tuning parameters of boosting is reduced from a multi-dimensional to a one-dimensional problem with vastly decreased complexity. The performance of the novel algorithm is evaluated in an extensive simulation study. We apply this new algorithm to a study to estimate abundance of common eider in Massachusetts, USA, featuring excess zeros, overdispersion, nonlinearity and spatiotemporal structures. Eider abundance is estimated via boosted GAMLSS, allowing both mean and overdispersion to be regressed on covariates. Stability selection is used to obtain a sparse set of stable predictors."
journal_title,Statistics and Computing
article_title,Latent single-index models for ordinal data
keyword,"['Free-knot splines\xa0', 'Generalized Gibbs sampler\xa0', 'Ordinal data\xa0', 'Parameter expansion and reparameterization\xa0', 'Single-index model\xa0']"
history,"['2018-05', '2017-05-29', '2016-11-06', '2017-05-23']"
abstract,"Abstract We propose a latent semi-parametric model for ordinal data in which the single-index model is used to evaluate the effects of the latent covariates on the latent response. We develop a Bayesian sampling-based method with free-knot splines to analyze the proposed model. As the index may vary from minus infinity to plus infinity, the traditional spline that is defined on a finite interval cannot be applied directly to approximate the unknown link function. We consider a modified version to address this problem by first transforming the index into the unit interval via a continuously cumulative distribution function and then constructing the spline bases on the unit interval. To obtain a rapidly convergent algorithm, we make use of the partial collapse and parameter expansion and reparameterization techniques, improve the movement step of Bayesian splines with free knots so that all the knots can be relocated each time instead of only one knot, and design a generalized Gibbs step. We check the performance of the proposed model and estimation method by a simulation study and apply them to analyze a real dataset."
journal_title,Statistics and Computing
article_title,A comparison of dependence function estimators in multivariate extremes
keyword,"['Asymmetric logistic model\xa0', 'Componentwise maxima\xa0', 'Convexity\xa0', 'Copula\xa0', 'Greatest convex minorant\xa0', 'Nonparametric and parametric estimators\xa0', 'Pickands dependence function\xa0']"
history,"['2018-05', '2017-05-11', '2016-03-14', '2017-04-08']"
abstract,"Abstract Various nonparametric and parametric estimators of extremal dependence have been proposed in the literature. Nonparametric methods commonly suffer from the curse of dimensionality and have been mostly implemented in extreme-value studies up to three dimensions, whereas parametric models can tackle higher-dimensional settings. In this paper, we assess, through a vast and systematic simulation study, the performance of classical and recently proposed estimators in multivariate settings. In particular, we first investigate the performance of nonparametric methods and then compare them with classical parametric approaches under symmetric and asymmetric dependence structures within the commonly used logistic family. We also explore two different ways to make nonparametric estimators satisfy the necessary dependence function shape constraints, finding a general improvement in estimator performance either (i) by substituting the estimator with its greatest convex minorant, developing a computational tool to implement this method for dimensions \(D\ge 2\) or (ii) by projecting the estimator onto a subspace of dependence functions satisfying such constraints and taking advantage of Bernstein–Bézier polynomials. Implementing the convex minorant method leads to better estimator performance as the dimensionality increases."
journal_title,Statistics and Computing
article_title,Without-replacement sampling for particle methods on finite state spaces
keyword,"['Sequential Monte Carlo\xa0', 'Sampling theory\xa0', 'Rare-event simulation\xa0', 'Network reliability\xa0']"
history,"['2018-05', '2017-05-19', '2016-08-30', '2017-05-02']"
abstract,"Abstract Combinatorial estimation is a new area of application for sequential Monte Carlo methods. We use ideas from sampling theory to introduce new without-replacement sampling methods in such discrete settings. These without-replacement sampling methods allow the addition of merging steps, which can significantly improve the resulting estimators. We give examples showing the use of the proposed methods in combinatorial rare-event probability estimation and in discrete state-space models."
journal_title,Statistics and Computing
article_title,Nonparametric estimation for compound Poisson process via variational analysis on measures
keyword,"['Compound Poisson distribution\xa0', 'Decompounding\xa0', 'Measure optimisation\xa0', 'Gradient methods\xa0', 'Steepest descent algorithms\xa0', 'Primary: 62G05\xa0', 'Secondary: 62M05\xa0', '65C60\xa0']"
history,"['2018-05', '2017-04-19', '2016-02-02', '2017-04-17']"
abstract,"Abstract The paper develops new methods of nonparametric estimation of a compound Poisson process. Our key estimator for the compounding (jump) measure is based on series decomposition of functionals of a measure and relies on the steepest descent technique. Our simulation studies for various examples of such measures demonstrate flexibility of our methods. They are particularly suited for discrete jump distributions, not necessarily concentrated on a grid nor on the positive or negative semi-axis. Our estimators also applicable for continuous jump distributions with an additional smoothing step."
journal_title,Statistics and Computing
article_title,Tracking multiple moving objects in images using Markov Chain Monte Carlo
keyword,"['Mutli-target tracking\xa0', 'Markov Chain Monte Carlo\xa0', 'Particle Markov Chain Monte Carlo\xa0', 'Reversible jump\xa0', 'Single molecule fluorescence microscopy\xa0']"
history,"['2018-05', '2017-03-28', '2016-09-17', '2017-03-22']"
abstract,"Abstract A new Bayesian state and parameter learning algorithm for multiple target tracking models with image observations are proposed. Specifically, a Markov chain Monte Carlo algorithm is designed to sample from the posterior distribution of the unknown time-varying number of targets, their birth, death times and states as well as the model parameters, which constitutes the complete solution to the specific tracking problem we consider. The conventional approach is to pre-process the images to extract point observations and then perform tracking, i.e. infer the target trajectories. We model the image generation process directly to avoid any potential loss of information when extracting point observations using a pre-processing step that is decoupled from the inference algorithm. Numerical examples show that our algorithm has improved tracking performance over commonly used techniques, for both synthetic examples and real florescent microscopy data, especially in the case of dim targets with overlapping illuminated regions."
journal_title,Statistics and Computing
article_title,Supervised functional principal component analysis
keyword,"['Classification\xa0', 'Functional data analysis\xa0', 'Functional linear model\xa0', 'Functional logistic regression\xa0']"
history,"['2018-05', '2017-06-03', '2016-08-11', '2017-05-24']"
abstract,"Abstract In functional linear regression, one conventional approach is to first perform functional principal component analysis (FPCA) on the functional predictor and then use the first few leading functional principal component (FPC) scores to predict the response variable. The leading FPCs estimated by the conventional FPCA stand for the major source of variation of the functional predictor, but these leading FPCs may not be mostly correlated with the response variable, so the prediction accuracy of the functional linear regression model may not be optimal. In this paper, we propose a supervised version of FPCA by considering the correlation of the functional predictor and response variable. It can automatically estimate leading FPCs, which represent the major source of variation of the functional predictor and are simultaneously correlated with the response variable. Our supervised FPCA method is demonstrated to have a better prediction accuracy than the conventional FPCA method by using one real application on electroencephalography (EEG) data and three carefully designed simulation studies."
journal_title,Statistics and Computing
article_title,A note on using the F-measure for evaluating record linkage algorithms
keyword,"['Data linkage\xa0', 'Entity resolution\xa0', 'Classification\xa0', 'Precision\xa0', 'Recall\xa0', 'Class imbalance\xa0']"
history,"['2018-05', '2017-04-19', '2016-10-31', '2017-04-10']"
abstract,"Abstract Record linkage is the process of identifying and linking records about the same entities from one or more databases. Record linkage can be viewed as a classification problem where the aim is to decide whether a pair of records is a match (i.e. two records refer to the same real-world entity) or a non-match (two records refer to two different entities). Various classification techniques—including supervised, unsupervised, semi-supervised and active learning based—have been employed for record linkage. If ground truth data in the form of known true matches and non-matches are available, the quality of classified links can be evaluated. Due to the generally high class imbalance in record linkage problems, standard accuracy or misclassification rate are not meaningful for assessing the quality of a set of linked records. Instead, precision and recall, as commonly used in information retrieval and machine learning, are used. These are often combined into the popular F-measure, which is the harmonic mean of precision and recall. We show that the F-measure can also be expressed as a weighted sum of precision and recall, with weights which depend on the linkage method being used. This reformulation reveals that the F-measure has a major conceptual weakness: the relative importance assigned to precision and recall should be an aspect of the problem and the researcher or user, but not of the particular linkage method being used. We suggest alternative measures which do not suffer from this fundamental flaw."
journal_title,Statistics and Computing
article_title,Regularized Gaussian belief propagation
keyword,"['Belief propagation\xa0', 'Approximate inference\xa0', 'Gaussian distributions\xa0', 'Regularization\xa0', 'Convergence\xa0']"
history,"['2018-05', '2017-05-12', '2017-01-17', '2017-05-03']"
abstract,"Abstract Belief propagation (BP) has been applied in a variety of inference problems as an approximation tool. BP does not necessarily converge in loopy graphs, and even if it does, is not guaranteed to provide exact inference. Even so, BP is useful in many applications due to its computational tractability. In this article, we investigate a regularized BP scheme by focusing on loopy Markov graphs (MGs) induced by a multivariate Gaussian distribution in canonical form. There is a rich literature surrounding BP on Gaussian MGs (labelled Gaussian belief propagation or GaBP), and this is known to experience the same problems as general BP on graphs. GaBP is known to provide the correct marginal means if it converges (this is not guaranteed), but it does not provide the exact marginal precisions. We show that our adjusted BP will always converge, with sufficient tuning, while maintaining the exact marginal means. As a further contribution we show, in an empirical study, that our GaBP variant can accelerate GaBP and compares well with other GaBP-type competitors in terms of convergence speed and accuracy of approximate marginal precisions. These improvements suggest that the principle of regularized BP should be investigated in other inference problems. The selection of the degree of regularization is addressed through the use of two heuristics. A by-product of GaBP is that it can be used to solve linear systems of equations; the same is true for our variant and we make an empirical comparison with the conjugate gradient method."
journal_title,Statistics and Computing
article_title,Objective Bayesian transformation and variable selection using default Bayes factors
keyword,"['Bayesian model selection\xa0', 'Fractional Bayes factor\xa0', 'Intrinsic Bayes factor\xa0', 'Posterior model probabilities\xa0', 'Transformation family selection\xa0', 'Variable selection\xa0']"
history,"['2018-05', '2017-04-22', '2016-10-24', '2017-04-17']"
abstract,"Abstract In this work, the problem of transformation and simultaneous variable selection is thoroughly treated via objective Bayesian approaches by the use of default Bayes factor variants. Four uniparametric families of transformations (Box–Cox, Modulus, Yeo-Johnson and Dual), denoted by T, are evaluated and compared. The subjective prior elicitation for the transformation parameter \(\lambda _T\), for each T, is not a straightforward task. Additionally, little prior information for \(\lambda _T\) is expected to be available, and therefore, an objective method is required. The intrinsic Bayes factors and the fractional Bayes factors allow us to incorporate default improper priors for \(\lambda _T\). We study the behaviour of each approach using a simulated reference example as well as two real-life examples."
journal_title,Statistics and Computing
article_title,An elliptically symmetric angular Gaussian distribution
keyword,"['Angular Gaussian\xa0', 'Bootstrap\xa0', 'Kent distribution\xa0', 'Spherical distribution\xa0']"
history,"['2018-05', '2017-05-22', '2016-09-03', '2017-05-09']"
abstract,"Abstract We define a distribution on the unit sphere \(\mathbb {S}^{d-1}\) called the elliptically symmetric angular Gaussian distribution. This distribution, which to our knowledge has not been studied before, is a subfamily of the angular Gaussian distribution closely analogous to the Kent subfamily of the general Fisher–Bingham distribution. Like the Kent distribution, it has ellipse-like contours, enabling modelling of rotational asymmetry about the mean direction, but it has the additional advantages of being simple and fast to simulate from, and having a density and hence likelihood that is easy and very quick to compute exactly. These advantages are especially beneficial for computationally intensive statistical methods, one example of which is a parametric bootstrap procedure for inference for the directional mean that we describe."
journal_title,Statistics and Computing
article_title,Fast covariance estimation for sparse functional data
keyword,"['Bivariate smoothing\xa0', 'FACEs\xa0', 'fPCA\xa0']"
history,"['2018-05', '2017-04-11', '2016-01-09', '2017-04-01']"
abstract,Abstract Smoothing of noisy sample covariances is an important component in functional data analysis. We propose a novel covariance smoothing method based on penalized splines and associated software. The proposed method is a bivariate spline smoother that is designed for covariance smoothing and can be used for sparse functional or longitudinal data. We propose a fast algorithm for covariance smoothing using leave-one-subject-out cross-validation. Our simulations show that the proposed method compares favorably against several commonly used methods. The method is applied to a study of child growth led by one of coauthors and to a public dataset of longitudinal CD4 counts.
journal_title,Statistics and Computing
article_title,Rank aggregation using latent-scale distance-based models
keyword,"['Ranking data\xa0', 'Latent-scale distance-based model\xa0', 'Rank aggregration\xa0', 'Incomplete ranking\xa0']"
history,"['2018-04-07', '2017-11-27', '2018-04-03']"
abstract,"Abstract Rank aggregation aims at combining rankings of a set of items assigned by a sample of rankers to generate a consensus ranking. A typical solution is to adopt a distance-based approach to minimize the sum of the distances to the observed rankings. However, this simple sum may not be appropriate when the quality of rankers varies. This happens when rankers with different backgrounds may have different cognitive levels of examining the items. In this paper, we develop a new distance-based model by allowing different weights for different rankers. Under this model, the weight associated with a ranker is used to measure his/her cognitive level of ranking of the items, and these weights are unobserved and exponentially distributed. Maximum likelihood method is used for model estimation. Extensions to the cases of incomplete rankings and mixture modeling are also discussed. Empirical applications demonstrate that the proposed model produces better rank aggregation than those generated by Borda and the unweighted distance-based models."
journal_title,Statistics and Computing
article_title,Selection of sparse vine copulas in high dimensions with the Lasso
keyword,"['Dependence modeling\xa0', 'Vine copula\xa0', 'Lasso\xa0', 'Sparsity\xa0']"
history,"['2018-03-24', '2017-05-02', '2018-02-27']"
abstract,"Abstract We propose a novel structure selection method for high-dimensional (\(d > 100\)) sparse vine copulas. Current sequential greedy approaches for structure selection require calculating spanning trees in hundreds of dimensions and fitting the pair copulas and their parameters iteratively throughout the structure selection process. Our method uses a connection between the vine and structural equation models. The later can be estimated very fast using the Lasso, also in very high dimensions, to obtain sparse models. Thus, we obtain a structure estimate independently of the chosen pair copulas and parameters. Additionally, we define the novel concept of regularization paths for R-vine matrices. It relates sparsity of the vine copula model in terms of independence copulas to a penalization coefficient in the structural equation models. We illustrate our approach and provide many numerical examples. These include simulations and data applications in high dimensions, showing the superiority of our approach to other existing methods."
journal_title,Statistics and Computing
article_title,Orthant probabilities of elliptical distributions from orthogonal projections to subspaces
keyword,"['Cumulative distribution function\xa0', 'Elliptical distribution\xa0', 'Orthant probability\xa0', 'Polyhedral cone\xa0', 'Recursive integration\xa0']"
history,"['2018-03-20', '2017-08-14', '2018-03-06']"
abstract,"Abstract A new procedure is proposed for evaluating non-centred orthant probabilities of elliptical distributed vectors, which is the probabilities that all elements of a vector are non-negative. The definition of orthant probabilities is simple, formulated as a multiple integral of the density function; however, applying direct numerical integration is not practical, except in low-dimensional cases, and methods for evaluating orthant probabilities are not trivial. This probability arises frequently in statistics; in particular, the normal distribution and Student’s t-distribution are in the family of elliptical distribution. In the procedure proposed in this paper, an orthant probability is approximated by the probability that the vector falls in a simplex. In the process, the problem is decomposed into sub-problems of lower dimension based on the symmetry of elliptical distributions. Intermediate sub-problems can be generated by projection onto subspaces, and the sub-problems form a lattice structure. Considering this structure, intermediate computations are shared between the evaluations of higher-dimensional problems, and computational time is reduced. The procedure can be applied not only to normal distributions, but also to general elliptical distributions, especially t-distributions, which are used in the multiple comparison procedure."
journal_title,Statistics and Computing
article_title,GPU-accelerated Gibbs sampling: a case study of the Horseshoe Probit model
keyword,"['Bayesian generalized linear models\xa0', 'Big data\xa0', 'Graphics processing units\xa0', 'High-dimensional statistical modeling\xa0', 'Markov chain Monte Carlo\xa0', 'Parallel computing\xa0']"
history,"['2018-03-19', '2017-07-31', '2018-03-07']"
abstract,"Abstract Gibbs sampling is a widely used Markov chain Monte Carlo (MCMC) method for numerically approximating integrals of interest in Bayesian statistics and other mathematical sciences. Many implementations of MCMC methods do not extend easily to parallel computing environments, as their inherently sequential nature incurs a large synchronization cost. In the case study illustrated by this paper, we show how to do Gibbs sampling in a fully data-parallel manner on a graphics processing unit, for a large class of exchangeable models that admit latent variable representations. Our approach takes a systems perspective, with emphasis placed on efficient use of compute hardware. We demonstrate our method on a Horseshoe Probit regression model and find that our implementation scales effectively to thousands of predictors and millions of data points simultaneously."
journal_title,Statistics and Computing
article_title,Learning causal structure from mixed data with missing values using Gaussian copula models
keyword,"['Gaussian copula\xa0', 'Causal discovery\xa0', 'Mixed data\xa0', 'Missing values\xa0']"
history,"['2018-03-17', '2017-10-05', '2018-03-12']"
abstract,"Abstract We consider the problem of causal structure learning from data with missing values, assumed to be drawn from a Gaussian copula model. First, we extend the ‘Rank PC’ algorithm, designed for Gaussian copula models with purely continuous data (so-called nonparanormal models), to incomplete data by applying rank correlation to pairwise complete observations and replacing the sample size with an effective sample size in the conditional independence tests to account for the information loss from missing values. When the data are missing completely at random (MCAR), we provide an error bound on the accuracy of ‘Rank PC’ and show its high-dimensional consistency. However, when the data are missing at random (MAR), ‘Rank PC’ fails dramatically. Therefore, we propose a Gibbs sampling procedure to draw correlation matrix samples from mixed data that still works correctly under MAR. These samples are translated into an average correlation matrix and an effective sample size, resulting in the ‘Copula PC’ algorithm for incomplete data. Simulation study shows that: (1) ‘Copula PC’ estimates a more accurate correlation matrix and causal structure than ‘Rank PC’ under MCAR and, even more so, under MAR and (2) the usage of the effective sample size significantly improves the performance of ‘Rank PC’ and ‘Copula PC.’ We illustrate our methods on two real-world datasets: riboflavin production data and chronic fatigue syndrome data."
journal_title,Statistics and Computing
article_title,Interpretable sparse SIR for functional data
keyword,"['Functional regression\xa0', 'SIR\xa0', 'Lasso\xa0', 'Ridge regression\xa0', 'Interval selection\xa0']"
history,"['2018-03-02', '2016-12-19', '2018-02-26']"
abstract,"Abstract We propose a semiparametric framework based on sliced inverse regression (SIR) to address the issue of variable selection in functional regression. SIR is an effective method for dimension reduction which computes a linear projection of the predictors in a low-dimensional space, without loss of information on the regression. In order to deal with the high dimensionality of the predictors, we consider penalized versions of SIR: ridge and sparse. We extend the approaches of variable selection developed for multidimensional SIR to select intervals that form a partition of the definition domain of the functional predictors. Selecting entire intervals rather than separated evaluation points improves the interpretability of the estimated coefficients in the functional framework. A fully automated iterative procedure is proposed to find the critical (interpretable) intervals. The approach is proved efficient on simulated and real data. The method is implemented in the R package SISIR available on CRAN at https://cran.r-project.org/package=SISIR."
journal_title,Statistics and Computing
article_title,I-robust and D-robust designs on a finite design space
keyword,"['Alphabetic optimality\xa0', 'Asymptotic monotonicity\xa0', 'Asymptotic optimality\xa0', 'D-optimal\xa0', 'D-robust\xa0', 'I-optimal\xa0', 'I-robust\xa0', 'Linear regression\xa0', 'Model misspecification\xa0', 'Nonlinear regression\xa0', 'Particle swarm optimization\xa0', 'Response-adaptive design\xa0', 'Sequential design\xa0', '62F35\xa0', '62K05\xa0']"
history,"['2018-03', '2017-01-31', '2016-08-19', '2017-01-19']"
abstract,"Abstract We present and discuss the theory of minimax I- and D-robust designs on a finite design space, and detail three methods for their construction that are new in this context: (i) a numerical search for the optimal parameters in a provably minimax robust parametric class of designs, (ii) a first-order iterative algorithm similar to that of Wynn (Ann Math Stat 5:1655–1664, 1970), and (iii) response-adaptive designs. These designs minimize a loss function, based on the mean squared error of the predicted responses or the parameter estimates, when the regression response is possibly misspecified. The loss function being minimized has first been maximized over a neighbourhood of the approximate and possibly inadequate response being fitted by the experimenter. The methods presented are all vastly more economical, in terms of the computing time required, than previously available algorithms."
journal_title,Statistics and Computing
article_title,Dynamic model-based clustering for spatio-temporal data
keyword,"['Bayesian analysis\xa0', 'Finite mixture models\xa0', 'Markov chain Monte Carlo\xa0', 'State-space modeling\xa0']"
history,"['2018-03', '2017-02-20', '2016-11-10', '2017-02-07']"
abstract,"Abstract In many research fields, scientific questions are investigated by analyzing data collected over space and time, usually at fixed spatial locations and time steps and resulting in geo-referenced time series. In this context, it is of interest to identify potential partitions of the space and study their evolution over time. A finite space-time mixture model is proposed to identify level-based clusters in spatio-temporal data and study their temporal evolution along the time frame. We anticipate space-time dependence by introducing spatio-temporally varying mixing weights to allocate observations at nearby locations and consecutive time points with similar cluster’s membership probabilities. As a result, a clustering varying over time and space is accomplished. Conditionally on the cluster’s membership, a state-space model is deployed to describe the temporal evolution of the sites belonging to each group. Fully posterior inference is provided under a Bayesian framework through Monte Carlo Markov chain algorithms. Also, a strategy to select the suitable number of clusters based upon the posterior temporal patterns of the clusters is offered. We evaluate our approach through simulation experiments, and we illustrate using air quality data collected across Europe from 2001 to 2012, showing the benefit of borrowing strength of information across space and time."
journal_title,Statistics and Computing
article_title,An approach for finding fully Bayesian optimal designs using normal-based approximations to loss functions
keyword,"['Loss function\xa0', 'Model discrimination\xa0', 'Bayesian optimal design\xa0', 'Parameter estimation\xa0', 'Hierarchical model\xa0']"
history,"['2018-03', '2017-02-20', '2016-08-20', '2017-02-05']"
abstract,"Abstract The generation of decision-theoretic Bayesian optimal designs is complicated by the significant computational challenge of minimising an analytically intractable expected loss function over a, potentially, high-dimensional design space. A new general approach for approximately finding Bayesian optimal designs is proposed which uses computationally efficient normal-based approximations to posterior summaries to aid in approximating the expected loss. This new approach is demonstrated on illustrative, yet challenging, examples including hierarchical models for blocked experiments, and experimental aims of parameter estimation and model discrimination. Where possible, the results of the proposed methodology are compared, both in terms of performance and computing time, to results from using computationally more expensive, but potentially more accurate, Monte Carlo approximations. Moreover, the methodology is also applied to problems where the use of Monte Carlo approximations is computationally infeasible."
journal_title,Statistics and Computing
article_title,Adaptive grid semidefinite programming for finding optimal designs
keyword,"['Adaptive grid\xa0', 'Continuous design\xa0', 'Model-based optimal design\xa0', 'Nonlinear programming\xa0', 'Semidefinite programming\xa0', '62K05\xa0', '90C47\xa0']"
history,"['2018-03', '2017-03-23', '2016-07-30', '2017-03-15']"
abstract,"Abstract We find optimal designs for linear models using a novel algorithm that iteratively combines a semidefinite programming (SDP) approach with adaptive grid techniques. The proposed algorithm is also adapted to find locally optimal designs for nonlinear models. The search space is first discretized, and SDP is applied to find the optimal design based on the initial grid. The points in the next grid set are points that maximize the dispersion function of the SDP-generated optimal design using nonlinear programming. The procedure is repeated until a user-specified stopping rule is reached. The proposed algorithm is broadly applicable, and we demonstrate its flexibility using (i) models with one or more variables and (ii) differentiable design criteria, such as A-, D-optimality, and non-differentiable criterion like E-optimality, including the mathematically more challenging case when the minimum eigenvalue of the information matrix of the optimal design has geometric multiplicity larger than 1. Our algorithm is computationally efficient because it is based on mathematical programming tools and so optimality is assured at each stage; it also exploits the convexity of the problems whenever possible. Using several linear and nonlinear models with one or more factors, we show the proposed algorithm can efficiently find optimal designs."
journal_title,Statistics and Computing
article_title,Likelihood-free inference via classification
keyword,"['Approximate Bayesian computation\xa0', 'Generative models\xa0', 'Intractable likelihood\xa0', 'Latent variable models\xa0', 'Simulator-based models\xa0']"
history,"['2018-03', '2017-03-13', '2016-06-27', '2017-02-28']"
abstract,"Abstract Increasingly complex generative models are being used across disciplines as they allow for realistic characterization of data, but a common difficulty with them is the prohibitively large computational cost to evaluate the likelihood function and thus to perform likelihood-based statistical inference. A likelihood-free inference framework has emerged where the parameters are identified by finding values that yield simulated data resembling the observed data. While widely applicable, a major difficulty in this framework is how to measure the discrepancy between the simulated and observed data. Transforming the original problem into a problem of classifying the data into simulated versus observed, we find that classification accuracy can be used to assess the discrepancy. The complete arsenal of classification methods becomes thereby available for inference of intractable generative models. We validate our approach using theory and simulations for both point estimation and Bayesian inference, and demonstrate its use on real data by inferring an individual-based epidemiological model for bacterial infections in child care centers."
journal_title,Statistics and Computing
article_title,Conditional density estimation using the local Gaussian correlation
keyword,"['Conditional density estimation\xa0', 'Local likelihood\xa0', 'Multivariate data\xa0', 'Cross-validation\xa0']"
history,"['2018-03', '2017-02-15', '2016-10-21', '2017-01-27']"
abstract,"Abstract Let \(\mathbf {X} = (X_1,\ldots ,X_p)\) be a stochastic vector having joint density function \(f_{\mathbf {X}}(\mathbf {x})\) with partitions \(\mathbf {X}_1 = (X_1,\ldots ,X_k)\) and \(\mathbf {X}_2 = (X_{k+1},\ldots ,X_p)\). A new method for estimating the conditional density function of \(\mathbf {X}_1\) given \(\mathbf {X}_2\) is presented. It is based on locally Gaussian approximations, but simplified in order to tackle the curse of dimensionality in multivariate applications, where both response and explanatory variables can be vectors. We compare our method to some available competitors, and the error of approximation is shown to be small in a series of examples using real and simulated data, and the estimator is shown to be particularly robust against noise caused by independent variables. We also present examples of practical applications of our conditional density estimator in the analysis of time series. Typical values for k in our examples are 1 and 2, and we include simulation experiments with values of p up to 6. Large sample theory is established under a strong mixing condition."
journal_title,Statistics and Computing
article_title,Gaussian variational approximation with sparse precision matrices
keyword,"['Gaussian variational approximation\xa0', 'Stochastic gradient algorithms\xa0', 'Sparse precision matrix\xa0', 'Variational Bayes\xa0']"
history,"['2018-03', '2017-02-10', '2016-05-18', '2017-01-23']"
abstract,"Abstract We consider the problem of learning a Gaussian variational approximation to the posterior distribution for a high-dimensional parameter, where we impose sparsity in the precision matrix to reflect appropriate conditional independence structure in the model. Incorporating sparsity in the precision matrix allows the Gaussian variational distribution to be both flexible and parsimonious, and the sparsity is achieved through parameterization in terms of the Cholesky factor. Efficient stochastic gradient methods that make appropriate use of gradient information for the target distribution are developed for the optimization. We consider alternative estimators of the stochastic gradients, which have lower variation and are more stable. Our approach is illustrated using generalized linear mixed models and state-space models for time series."
journal_title,Statistics and Computing
article_title,Ensemble preconditioning for Markov chain Monte Carlo simulation
keyword,"['Stochastic sampling\xa0', 'Markov chain Monte Carlo\xa0', 'MCMC\xa0', 'Computational statistics\xa0', 'Machine learning\xa0', 'BFGS\xa0', 'Langevin methods\xa0', 'Brownian dynamics\xa0']"
history,"['2018-03', '2017-02-27', '2016-09-15', '2017-01-23']"
abstract,"Abstract We describe parallel Markov chain Monte Carlo methods that propagate a collective ensemble of paths, with local covariance information calculated from neighbouring replicas. The use of collective dynamics eliminates multiplicative noise and stabilizes the dynamics, thus providing a practical approach to difficult anisotropic sampling problems in high dimensions. Numerical experiments with model problems demonstrate that dramatic potential speedups, compared to various alternative schemes, are attainable."
journal_title,Statistics and Computing
article_title,Conditional vs marginal estimation of the predictive loss of hierarchical models using WAIC and cross-validation
keyword,"['Cross-validation\xa0', 'Hierarchical model\xa0', 'Importance sampling\xa0', 'Leave-one-out\xa0', 'Marginalized likelihood\xa0', 'Model comparison\xa0', 'Over-dispersed count data\xa0', 'Pointwise predictive loss\xa0', 'WAIC\xa0']"
history,"['2018-03', '2017-02-23', '2016-07-05', '2017-02-10']"
abstract,"Abstract The predictive loss of Bayesian models can be estimated using a sample from the full-data posterior by evaluating the Watanabe-Akaike information criterion (WAIC) or using an importance sampling (ISCVL) approximation to leave-one-out cross-validation loss. With hierarchical models the loss can be specified at different levels of the hierarchy, and in the published literature, it is routine for these estimators to use the conditional likelihood provided by the lowest level of model hierarchy. However, the regularity conditions underlying these estimators may not hold at this level, and the behaviour of conditional-level WAIC as an estimator of conditional-level predictive loss must be determined on a case-by-case basis. Conditional-level ISCVL does not target conditional-level predictive loss and instead is an estimator of marginal-level predictive loss. Using examples for analysis of over-dispersed count data, it is shown that conditional-level WAIC does not provide a reliable estimator of its target loss, and simulations show that it can favour the incorrect model. Moreover, conditional-level ISCVL is numerically unstable compared to marginal-level ISCVL. It is recommended that WAIC and ISCVL be evaluated using the marginalized likelihood where practicable and that the reliability of these estimators always be checked using appropriate diagnostics."
journal_title,Statistics and Computing
article_title,A reweighting approach to robust clustering
keyword,"['Cluster analysis\xa0', 'Trimming\xa0', 'Robustness\xa0', 'Minimum covariance determinant estimator\xa0']"
history,"['2018-03', '2017-03-28', '2016-06-24', '2017-03-22']"
abstract,Abstract An iteratively reweighted approach for robust clustering is presented in this work. The method is initialized with a very robust clustering partition based on an high trimming level. The initial partition is then refined to reduce the number of wrongly discarded observations and substantially increase efficiency. Simulation studies and real data examples indicate that the final clustering solution has both good properties in terms of robustness and efficiency and naturally adapts to the true underlying contamination level.
journal_title,Statistics and Computing
article_title,A global optimisation approach to range-restricted survey calibration
keyword,"['Calibration estimation\xa0', 'Calibration weighting\xa0', 'Design-based inference\xa0', 'Generalised regression\xa0', 'Penalised calibration\xa0', 'Raking\xa0', 'Ridge calibration\xa0', 'Range restrictions\xa0']"
history,"['2018-03', '2017-03-21', '2016-09-07', '2017-03-02']"
abstract,"Abstract Survey calibration methods modify minimally sample weights to satisfy domain-level benchmark constraints (BC), e.g. census totals. This allows exploitation of auxiliary information to improve the representativeness of sample data (addressing coverage limitations, non-response) and the quality of sample-based estimates of population parameters. Calibration methods may fail with samples presenting small/zero counts for some benchmark groups or when range restrictions (RR), such as positivity, are imposed to avoid unrealistic or extreme weights. User-defined modifications of BC/RR performed after encountering non-convergence allow little control on the solution, and penalisation approaches modelling infeasibility may not guarantee convergence. Paradoxically, this has led to underuse in calibration of highly disaggregated information, when available. We present an always-convergent flexible two-step global optimisation (GO) survey calibration approach. The feasibility of the calibration problem is assessed, and automatically controlled minimum errors in BC or changes in RR are allowed to guarantee convergence in advance, while preserving the good properties of calibration estimators. Modelling alternatives under different scenarios using various error/change and distance measures are formulated and discussed. The GO approach is validated by calibrating the weights of the 2012 Health Survey for England to a fine age–gender–region cross-tabulation (378 counts) from the 2011 Census in England and Wales."
journal_title,Statistics and Computing
article_title,Model distances for vine copulas in high dimensions
keyword,"['Vine copulas\xa0', 'Model distances\xa0', 'Kullback–Leibler\xa0', 'Jeffreys distance\xa0', 'Monte Carlo integration\xa0']"
history,"['2018-03', '2017-02-11', '2016-04-20', '2017-01-30']"
abstract,"Abstract Vine copulas are a flexible class of dependence models consisting of bivariate building blocks and have proven to be particularly useful in high dimensions. Classical model distance measures require multivariate integration and thus suffer from the curse of dimensionality. In this paper, we provide numerically tractable methods to measure the distance between two vine copulas even in high dimensions. For this purpose, we consecutively develop three new distance measures based on the Kullback–Leibler distance, using the result that it can be expressed as the sum over expectations of KL distances between univariate conditional densities, which can be easily obtained for vine copulas. To reduce numerical calculations, we approximate these expectations on adequately designed grids, outperforming Monte Carlo integration with respect to computational time. For the sake of interpretability, we provide a baseline calibration for the proposed distance measures. We further develop similar substitutes for the Jeffreys distance, a symmetrized version of the Kullback–Leibler distance. In numerous examples and applications, we illustrate the strengths and weaknesses of the developed distance measures."
journal_title,Statistics and Computing
article_title,On coupling particle filter trajectories
keyword,"['Particle filter\xa0', 'Multi-level Monte Carlo\xa0', 'Coupling\xa0', 'Optimal transport\xa0', 'Markov chain Monte Carlo\xa0']"
history,"['2018-03', '2017-03-24', '2016-09-15', '2017-03-15']"
abstract,"Abstract Particle filters are a powerful and flexible tool for performing inference on state-space models. They involve a collection of samples evolving over time through a combination of sampling and re-sampling steps. The re-sampling step is necessary to ensure that weight degeneracy is avoided. In several situations of statistical interest, it is important to be able to compare the estimates produced by two different particle filters; consequently, being able to efficiently couple two particle filter trajectories is often of paramount importance. In this text, we propose several ways to do so. In particular, we leverage ideas from the optimal transportation literature. In general, though computing the optimal transport map is extremely computationally expensive, to deal with this, we introduce computationally tractable approximations to optimal transport couplings. We demonstrate that our resulting algorithms for coupling two particle filter trajectories often perform orders of magnitude more efficiently than more standard approaches."
journal_title,Statistics and Computing
article_title,Long memory and changepoint models: a spectral classification procedure
keyword,"['Classification\xa0', 'Long memory\xa0', 'Changepoint\xa0', 'Wavelet spectrum\xa0', 'Non-stationarity\xa0']"
history,"['2018-03', '2017-02-13', '2016-07-20', '2017-01-24']"
abstract,"Abstract Time series within fields such as finance and economics are often modelled using long memory processes. Alternative studies on the same data can suggest that series may actually contain a ‘changepoint’ (a point within the time series where the data generating process has changed). These models have been shown to have elements of similarity, such as within their spectrum. Without prior knowledge this leads to an ambiguity between these two models, meaning it is difficult to assess which model is most appropriate. We demonstrate that considering this problem in a time-varying environment using the time-varying spectrum removes this ambiguity. Using the wavelet spectrum, we then use a classification approach to determine the most appropriate model (long memory or changepoint). Simulation results are presented across a number of models followed by an application to stock cross-correlations and US inflation. The results indicate that the proposed classification outperforms an existing hypothesis testing approach on a number of models and performs comparatively across others."
journal_title,Statistics and Computing
article_title,Estimating non-simplified vine copulas using penalized splines
keyword,"['Vine\xa0', 'Pair-copula\xa0', 'Simplifying assumption\xa0', 'Conditional copula\xa0', 'Penalized spline\xa0']"
history,"['2018-03', '2017-02-27', '2016-03-03', '2017-02-16']"
abstract,"Abstract Vine copulas (or pair-copula constructions) have become an important tool for high-dimensional dependence modeling. Typically, so-called simplified vine copula models are estimated where bivariate conditional copulas are approximated by bivariate unconditional copulas. We present the first nonparametric estimator of a non-simplified vine copula that allows for varying conditional copulas using penalized hierarchical B-splines. Throughout the vine copula, we test for the simplifying assumption in each edge, establishing a data-driven non-simplified vine copula estimator. To overcome the curse of dimensionality, we approximate conditional copulas with more than one conditioning argument by a conditional copula with the first principal component as conditioning argument. An extensive simulation study is conducted, showing a substantial improvement in the out-of-sample Kullback–Leibler divergence if the null hypothesis of a simplified vine copula can be rejected. We apply our method to the famous uranium data and present a classification of an eye state data set, demonstrating the potential benefit that can be achieved when conditional copulas are modeled."
journal_title,Statistics and Computing
article_title,Stochastic proximal-gradient algorithms for penalized mixed models
keyword,"['Proximal-gradient algorithm\xa0', 'Stochastic gradient\xa0', 'Stochastic EM algorithm\xa0', 'Stochastic approximation\xa0', 'Nonlinear mixed effect models\xa0']"
history,"['2018-02-12', '2017-04-28', '2018-02-02']"
abstract,"Abstract Motivated by penalized likelihood maximization in complex models, we study optimization problems where neither the function to optimize nor its gradient has an explicit expression, but its gradient can be approximated by a Monte Carlo technique. We propose a new algorithm based on a stochastic approximation of the proximal-gradient (PG) algorithm. This new algorithm, named stochastic approximation PG (SAPG) is the combination of a stochastic gradient descent step which—roughly speaking—computes a smoothed approximation of the gradient along the iterations, and a proximal step. The choice of the step size and of the Monte Carlo batch size for the stochastic gradient descent step in SAPG is discussed. Our convergence results cover the cases of biased and unbiased Monte Carlo approximations. While the convergence analysis of some classical Monte Carlo approximation of the gradient is already addressed in the literature (see Atchadé et al. in J Mach Learn Res 18(10):1–33, 2017), the convergence analysis of SAPG is new. Practical implementation is discussed, and guidelines to tune the algorithm are given. The two algorithms are compared on a linear mixed effect model as a toy example. A more challenging application is proposed on nonlinear mixed effect models in high dimension with a pharmacokinetic data set including genomic covariates. To our best knowledge, our work provides the first convergence result of a numerical method designed to solve penalized maximum likelihood in a nonlinear mixed effect model."
journal_title,Statistics and Computing
article_title,Bayesian nonparametric clustering for large data sets
keyword,"['Big data clustering\xa0', 'Gene–gene interactions\xa0', 'Predictive recursion\xa0', 'Nonparametric Bayes\xa0', 'TCGA\xa0']"
history,"['2018-02-12', '2017-04-21', '2018-01-31']"
abstract,"Abstract We propose two nonparametric Bayesian methods to cluster big data and apply them to cluster genes by patterns of gene–gene interaction. Both approaches define model-based clustering with nonparametric Bayesian priors and include an implementation that remains feasible for big data. The first method is based on a predictive recursion which requires a single cycle (or few cycles) of simple deterministic calculations for each observation under study. The second scheme is an exact method that divides the data into smaller subsamples and involves local partitions that can be determined in parallel. In a second step, the method requires only the sufficient statistics of each of these local clusters to derive global clusters. Under simulated and benchmark data sets the proposed methods compare favorably with other clustering algorithms, including k-means, DP-means, DBSCAN, SUGS, streaming variational Bayes and an EM algorithm. We apply the proposed approaches to cluster a large data set of gene–gene interactions extracted from the online search tool “Zodiac.”"
journal_title,Statistics and Computing
article_title,Tree-structured modelling of varying coefficients
keyword,"['Varying-coefficient models\xa0', 'Interactions\xa0', 'Recursive partitioning\xa0', 'Tree-based models\xa0']"
history,"['2018-02-07', '2017-06-02', '2018-01-31']"
abstract,"Abstract The varying-coefficient model is a strong tool for the modelling of interactions in generalized regression. It is easy to apply if both the variables that are modified as well as the effect modifiers are known. However, in general one has a set of explanatory variables, and it is unknown which covariates are modified by which variables. A recursive partitioning strategy is proposed that is able to deal with this complex selection problem. The tree-structured modelling yields for each covariate, which is modified by other variables, a tree that visualizes the modified effects. The performance of the method is investigated in simulations, and two applications illustrate its usefulness."
journal_title,Statistics and Computing
article_title,Penalized estimation of directed acyclic graphs from discrete data
keyword,"['Coordinate descent\xa0', 'Discrete Bayesian network\xa0', 'Multi-logit regression\xa0', 'Structure learning\xa0', 'Group norm penalty\xa0']"
history,"['2018-02-02', '2017-06-20', '2018-01-24']"
abstract,"Abstract Bayesian networks, with structure given by a directed acyclic graph (DAG), are a popular class of graphical models. However, learning Bayesian networks from discrete or categorical data is particularly challenging, due to the large parameter space and the difficulty in searching for a sparse structure. In this article, we develop a maximum penalized likelihood method to tackle this problem. Instead of the commonly used multinomial distribution, we model the conditional distribution of a node given its parents by multi-logit regression, in which an edge is parameterized by a set of coefficient vectors with dummy variables encoding the levels of a node. To obtain a sparse DAG, a group norm penalty is employed, and a blockwise coordinate descent algorithm is developed to maximize the penalized likelihood subject to the acyclicity constraint of a DAG. When interventional data are available, our method constructs a causal network, in which a directed edge represents a causal relation. We apply our method to various simulated and real data sets. The results show that our method is very competitive, compared to many existing methods, in DAG estimation from both interventional and high-dimensional observational data."
journal_title,Statistics and Computing
article_title,Irreversible samplers from jump and continuous Markov processes
keyword,"['Bayesian inference\xa0', 'Hamiltonian Monte Carlo\xa0', 'Irreversible samplers\xa0', 'Jump processes\xa0', 'Markov chain Monte Carlo\xa0', 'Metropolis–Hastings\xa0']"
history,"['2018-02-02', '2017-06-25', '2018-01-29']"
abstract,"Abstract In this paper, we propose irreversible versions of the Metropolis–Hastings (MH) and Metropolis-adjusted Langevin algorithm (MALA) with a main focus on the latter. For the former, we show how one can simply switch between different proposal and acceptance distributions upon rejection to obtain an irreversible jump sampler (I-Jump). The resulting algorithm has a simple implementation akin to MH, but with the demonstrated benefits of irreversibility. We then show how the previously proposed MALA method can also be extended to exploit irreversible stochastic dynamics as proposal distributions in the I-Jump sampler. Our experiments explore how irreversibility can increase the efficiency of the samplers in different situations."
journal_title,Statistics and Computing
article_title,Robust clustering tools based on optimal transportation
keyword,"['Cluster prototypes\xa0', None, 'Trimmed barycenter\xa0', 'Robust aggregation\xa0', 'Wasserstein distance\xa0', 'Monge–Kantorovich problem\xa0', 'Transport maps\xa0', 'Trimmed distributions\xa0', 'Parallelized inference\xa0', 'Bragging\xa0', 'Subragging\xa0', None, 'Primary 62H30\xa0', '62G35\xa0', 'Secondary 62G20\xa0', '62P99\xa0']"
history,"['2018-01-12', '2016-11-29', '2018-01-05']"
abstract,"Abstract A robust clustering method for probabilities in Wasserstein space is introduced. This new ‘trimmed k-barycenters’ approach relies on recent results on barycenters in Wasserstein space that allow intensive computation, as required by clustering algorithms to be feasible. The possibility of trimming the most discrepant distributions results in a gain in stability and robustness, highly convenient in this setting. As a remarkable application, we consider a parallelized clustering setup in which each of m units processes a portion of the data, producing a clustering report, encoded as k probabilities. We prove that the trimmed k-barycenter of the \(m\times k\) reports produces a consistent aggregation which we consider the result of a ‘wide consensus’. We also prove that a weighted version of trimmed k-means algorithms based on k-barycenters in the space of Wasserstein keeps the descending character of the concentration step, guaranteeing convergence to local minima. We illustrate the methodology with simulated and real data examples. These include clustering populations by age distributions and analysis of cytometric data."
journal_title,Statistics and Computing
article_title,Bayesian nonparametric spectral density estimation using B-spline priors
keyword,"['B-spline prior\xa0', 'Bernstein polynomial prior\xa0', 'Whittle likelihood\xa0', 'Spectral density estimation\xa0', 'Bayesian nonparametrics\xa0', 'LIGO\xa0', 'Gravitational waves\xa0', 'Sunspot cycle\xa0']"
history,"['2018-01-12', '2016-09-06', '2017-12-12']"
abstract,"Abstract We present a new Bayesian nonparametric approach to estimating the spectral density of a stationary time series. A nonparametric prior based on a mixture of B-spline distributions is specified and can be regarded as a generalization of the Bernstein polynomial prior of Petrone (Scand J Stat 26:373–393, 1999a; Can J Stat 27:105–126, 1999b) and Choudhuri et al. (J Am Stat Assoc 99(468):1050–1059, 2004). Whittle’s likelihood approximation is used to obtain the pseudo-posterior distribution. This method allows for a data-driven choice of the number of mixture components and the location of knots. Posterior samples are obtained using a Metropolis-within-Gibbs Markov chain Monte Carlo algorithm, and mixing is improved using parallel tempering. We conduct a simulation study to demonstrate that for complicated spectral densities, the B-spline prior provides more accurate Monte Carlo estimates in terms of \(L_1\)-error and uniform coverage probabilities than the Bernstein polynomial prior. We apply the algorithm to annual mean sunspot data to estimate the solar cycle. Finally, we demonstrate the algorithm’s ability to estimate a spectral density with sharp features, using real gravitational wave detector data from LIGO’s sixth science run, recoloured to match the Advanced LIGO target sensitivity."
journal_title,Statistics and Computing
article_title,A probabilistic model for the numerical solution of initial value problems
keyword,"['Initial value problems\xa0', 'Nordsieck methods\xa0', 'Runge–Kutta methods\xa0', 'Filtering\xa0', 'Gaussian processes\xa0', 'Markov processes\xa0', 'Probabilistic numerics\xa0', '60H30\xa0', '62M05\xa0', '65C20\xa0', '65L05\xa0', '65L06\xa0']"
history,"['2018-01-08', '2017-01-25', '2017-12-12']"
abstract,"Abstract We study connections between ordinary differential equation (ODE) solvers and probabilistic regression methods in statistics. We provide a new view of probabilistic ODE solvers as active inference agents operating on stochastic differential equation models that estimate the unknown initial value problem (IVP) solution from approximate observations of the solution derivative, as provided by the ODE dynamics. Adding to this picture, we show that several multistep methods of Nordsieck form can be recasted as Kalman filtering on q-times integrated Wiener processes. Doing so provides a family of IVP solvers that return a Gaussian posterior measure, rather than a point estimate. We show that some such methods have low computational overhead, nontrivial convergence order, and that the posterior has a calibrated concentration rate. Additionally, we suggest a step size adaptation algorithm which completes the proposed method to a practically useful implementation, which we experimentally evaluate using a representative set of standard codes in the DETEST benchmark set."
journal_title,Statistics and Computing
article_title,Erratum to: Stability of noisy Metropolis–Hastings
keyword,[]
history,"['2018-01', '2017-05-17']"
abstract,None
journal_title,Statistics and Computing
article_title,Bootstrap bias corrections for ensemble methods
keyword,"['Bagging\xa0', 'Ensemble methods\xa0', 'Bias correction\xa0', 'Bootstrap\xa0']"
history,"['2018-01', '2016-11-30', '2016-05-30', '2016-11-20']"
abstract,"Abstract This paper examines the use of a residual bootstrap for bias correction in machine learning regression methods. Accounting for bias is an important obstacle in recent efforts to develop statistical inference for machine learning. We demonstrate empirically that the proposed bootstrap bias correction can lead to substantial improvements in both bias and predictive accuracy. In the context of ensembles of trees, we show that this correction can be approximated at only double the cost of training the original ensemble. Our method is shown to improve test set accuracy over random forests by up to 70% on example problems from the UCI repository."
journal_title,Statistics and Computing
article_title,Inference and rare event simulation for stopped Markov processes via reverse-time sequential Monte Carlo
keyword,"['Intractable likelihood\xa0', 'Rare event simulation\xa0', 'Sequential Monte Carlo\xa0', 'Stopped Markov process\xa0', 'Time reversal\xa0', '62M05\xa0', '60J20\xa0', '60J22\xa0']"
history,"['2018-01', '2017-01-24', '2016-07-13', '2017-01-03']"
abstract,"Abstract We present a sequential Monte Carlo algorithm for Markov chain trajectories with proposals constructed in reverse time, which is advantageous when paths are conditioned to end in a rare set. The reverse time proposal distribution is constructed by approximating the ratio of Green’s functions in Nagasawa’s formula. Conditioning arguments can be used to interpret these ratios as low-dimensional conditional sampling distributions of some coordinates of the process given the others. Hence, the difficulty in designing SMC proposals in high dimension is greatly reduced. Empirically, our method outperforms an adaptive multilevel splitting algorithm in three examples: estimating an overflow probability in a queueing model, the probability that a diffusion follows a narrowing corridor, and the initial location of an infection in an epidemic model on a network."
journal_title,Statistics and Computing
article_title,Bootstrap methods for stationary functional time series
keyword,"['Maximum entropy\xa0', 'Functional principal component analysis\xa0', 'Functional autoregressive process\xa0', 'Functional kernel regression\xa0', 'Long-run covariance\xa0', 'Plug-in bandwidth\xa0', '62G09\xa0', '62H10\xa0', '62M10\xa0']"
history,"['2018-01', '2016-10-08', '2016-02-15', '2016-10-03']"
abstract,"Abstract Bootstrap methods for estimating the long-run covariance of stationary functional time series are considered. We introduce a versatile bootstrap method that relies on functional principal component analysis, where principal component scores can be bootstrapped by maximum entropy. Two other bootstrap methods resample error functions, after the dependence structure being modeled linearly by a sieve method or nonlinearly by a functional kernel regression. Through a series of Monte-Carlo simulation, we evaluate and compare the finite-sample performances of these three bootstrap methods for estimating the long-run covariance in a functional time series. Using the intraday particulate matter (\(\hbox {PM}_{10}\)) dataset in Graz, the proposed bootstrap methods provide a way of constructing the distribution of estimated long-run covariance for functional time series."
journal_title,Statistics and Computing
article_title,Multilevel particle filters: normalizing constant estimation
keyword,"['Filtering\xa0', 'Diffusions\xa0', 'Particle filter\xa0', 'Multilevel Monte Carlo\xa0']"
history,"['2018-01', '2016-11-07', '2016-05-16', '2016-10-25']"
abstract,"Abstract In this article, we introduce two new estimates of the normalizing constant (or marginal likelihood) for partially observed diffusion (POD) processes, with discrete observations. One estimate is biased but non-negative and the other is unbiased but not almost surely non-negative. Our method uses the multilevel particle filter of Jasra et al. (Multilevel particle lter, arXiv:1510.04977, 2015). We show that, under assumptions, for Euler discretized PODs and a given \(\varepsilon >0\) in order to obtain a mean square error (MSE) of \({\mathcal {O}}(\varepsilon ^2)\) one requires a work of \({\mathcal {O}}(\varepsilon ^{-2.5})\) for our new estimates versus a standard particle filter that requires a work of \({\mathcal {O}}(\varepsilon ^{-3})\). Our theoretical results are supported by numerical simulations."
journal_title,Statistics and Computing
article_title,Accurate and efficient numerical calculation of stable densities via optimized quadrature and asymptotics
keyword,"['Stable distributions\xa0', None, 'Generalized Gaussian quadrature\xa0', 'Infinitely divisible distributions\xa0', 'Numerical quadrature\xa0']"
history,"['2018-01', '2017-01-12', '2016-07-14', '2017-01-05']"
abstract,"Abstract Stable distributions are an important class of infinitely divisible probability distributions, of which two special cases are the Cauchy distribution and the normal distribution. Aside from a few special cases, the density function for stable distributions has no known analytic form and is expressible only through the variate’s characteristic function or other integral forms. In this paper, we present numerical schemes for evaluating the density function for stable distributions, its gradient, and distribution function in various parameter regimes of interest, some of which had no preexisting efficient method for their computation. The novel evaluation schemes consist of optimized generalized Gaussian quadrature rules for integral representations of the density function, complemented by asymptotic expansions near various values of the shape and argument parameters. We report several numerical examples illustrating the efficiency of our methods. The resulting code has been made available online."
journal_title,Statistics and Computing
article_title,Modelling the role of variables in model-based cluster analysis
keyword,"['Clusterwise linear regression\xa0', 'EM algorithm\xa0', 'Gaussian mixture model\xa0', 'Genetic algorithm\xa0', 'Multiple cluster structure\xa0', 'Variable selection\xa0']"
history,"['2018-01', '2017-01-12', '2016-03-24', '2017-01-04']"
abstract,"Abstract In the framework of cluster analysis based on Gaussian mixture models, it is usually assumed that all the variables provide information about the clustering of the sample units. Several variable selection procedures are available in order to detect the structure of interest for the clustering when this structure is contained in a variable sub-vector. Currently, in these procedures a variable is assumed to play one of (up to) three roles: (1) informative, (2) uninformative and correlated with some informative variables, (3) uninformative and uncorrelated with any informative variable. A more general approach for modelling the role of a variable is proposed by taking into account the possibility that the variable vector provides information about more than one structure of interest for the clustering. This approach is developed by assuming that such information is given by non-overlapped and possibly correlated sub-vectors of variables; it is also assumed that the model for the variable vector is equal to a product of conditionally independent Gaussian mixture models (one for each variable sub-vector). Details about model identifiability, parameter estimation and model selection are provided. The usefulness and effectiveness of the described methodology are illustrated using simulated and real datasets."
journal_title,Statistics and Computing
article_title,The stochastic topic block model for the clustering of vertices in networks with textual edges
keyword,"['Random graph models\xa0', 'Topic modeling\xa0', 'Textual edges\xa0', 'Clustering\xa0', 'Variational inference\xa0', '62F15\xa0', '62F86\xa0']"
history,"['2018-01', '2016-10-21', '2016-04-29', '2016-10-11']"
abstract,"Abstract Due to the significant increase of communications between individuals via social media (Facebook, Twitter, Linkedin) or electronic formats (email, web, e-publication) in the past two decades, network analysis has become an unavoidable discipline. Many random graph models have been proposed to extract information from networks based on person-to-person links only, without taking into account information on the contents. This paper introduces the stochastic topic block model, a probabilistic model for networks with textual edges. We address here the problem of discovering meaningful clusters of vertices that are coherent from both the network interactions and the text contents. A classification variational expectation-maximization algorithm is proposed to perform inference. Simulated datasets are considered in order to assess the proposed approach and to highlight its main features. Finally, we demonstrate the effectiveness of our methodology on two real-word datasets: a directed communication network and an undirected co-authorship network."
journal_title,Statistics and Computing
article_title,Optimal regular graph designs
keyword,"[None, None, 'Incomplete block design\xa0', 'Regular graphs\xa0', 'Regular graph design\xa0']"
history,"['2018-01', '2017-01-07', '2016-01-25', '2016-12-07']"
abstract,"Abstract A typical problem in optimal design theory is finding an experimental design that is optimal with respect to some criteria in a class of designs. The most popular criteria include the A- and D-criteria. Regular graph designs occur in many optimality results, and if the number of blocks is large enough, an A-optimal (or D-optimal) design is among them (if any exist). To explore the landscape of designs with a large number of blocks, we introduce extensions of regular graph designs. These are constructed by adding the blocks of a balanced incomplete block design repeatedly to the original design. We present the results of an exact computer search for the best regular graph designs and the best extended regular graph designs with up to 20 treatments v, block size \(k \le 10\) and replication r \(\le 10\) and \(r(k-1)-(v-1)\lfloor r(k-1)/(v-1)\rfloor \le 9\)."
journal_title,Statistics and Computing
article_title,On the generalization of the hazard rate twisting-based simulation approach
keyword,"['Naive Monte Carlo\xa0', 'Rare events\xa0', 'Importance sampling\xa0', 'Hazard rate twisting\xa0', 'Logarithmic efficient\xa0', 'Twisting parameter\xa0']"
history,"['2018-01', '2016-11-16', '2016-04-11', '2016-11-02']"
abstract,"Abstract Estimating the probability that a sum of random variables (RVs) exceeds a given threshold is a well-known challenging problem. A naive Monte Carlo simulation is the standard technique for the estimation of this type of probability. However, this approach is computationally expensive, especially when dealing with rare events. An alternative approach is represented by the use of variance reduction techniques, known for their efficiency in requiring less computations for achieving the same accuracy requirement. Most of these methods have thus far been proposed to deal with specific settings under which the RVs belong to particular classes of distributions. In this paper, we propose a generalization of the well-known hazard rate twisting Importance Sampling-based approach that presents the advantage of being logarithmic efficient for arbitrary sums of RVs. The wide scope of applicability of the proposed method is mainly due to our particular way of selecting the twisting parameter. It is worth observing that this interesting feature is rarely satisfied by variance reduction algorithms whose performances were only proven under some restrictive assumptions. It comes along with a good efficiency, illustrated by some selected simulation results comparing the performance of the proposed method with some existing techniques."
journal_title,Statistics and Computing
article_title,Vine copula approximation: a generic method for coping with conditional dependence
keyword,"['Compact set\xa0', 'Cross-validation\xa0', 'k-means clustering\xa0', 'Kullback–Leibler divergence\xa0', 'Weighted average\xa0', 'Locally weighted regression\xa0']"
history,"['2018-01', '2017-01-31', '2016-04-02', '2017-01-13']"
abstract,"Abstract Pair-copula constructions (or vine copulas) are structured, in the layout of vines, with bivariate copulas and conditional bivariate copulas. The main contribution of the current work is an approach to the long-standing problem: how to cope with the dependence structure between the two conditioned variables indicated by an edge, acknowledging that the dependence structure changes with the values of the conditioning variables. The changeable dependence problem, though recognized as crucial in the field of multivariate modelling, remains widely unexplored due to its inherent complication and hence is the motivation of the current work. Rather than resorting to traditional parametric or nonparametric methods, we proceed from an innovative viewpoint: approximating a conditional copula, to any required degree of approximation, by utilizing a family of basis functions. We fully incorporate the impact of the conditioning variables on the functional form of a conditional copula by employing local learning methods. The attractions and dilemmas of the pair-copula approximating technique are revealed via simulated data, and its practical importance is evidenced via a real data set."
journal_title,Statistics and Computing
article_title,Automatic specification of piecewise linear additive models: application to forecasting natural gas demand
keyword,"['Generalized additive models\xa0', 'Prediction\xa0', 'Natural gas demand\xa0', 'Short-term forecasting\xa0', 'Piecewise linear models\xa0', 'Nonlinear modeling\xa0']"
history,"['2018-01', '2017-01-25', '2016-07-22', '2017-01-05']"
abstract,"Abstract When facing any forecasting problem not only is accuracy on the predictions sought. Also, useful information about the underlying physics of the process and about the relevance of the forecasting variables is very much appreciated. In this paper, it is presented an automatic specification procedure for models that are based on additivity assumptions and piecewise linear regression. This procedure allows the analyst to gain insight about the problem by examining the automatically selected model, thus easily checking the validity of the forecast. Monte Carlo simulations have been run to ensure that the model selection procedure behaves correctly under weakly dependent data. Moreover, comparison over other well-known methodologies has been done to evaluate its accuracy performance, both in simulated data and in the context of short-term natural gas demand forecasting. Empirical results show that the accuracy of the proposed model is competitive against more complex methods such as neural networks."
journal_title,Statistics and Computing
article_title,Bayesian non-parametric modeling for integro-difference equations
keyword,"['Dirichlet process mixtures\xa0', 'Hamiltonian Markov chain Monte Carlo\xa0', 'Hermite polynomials\xa0', 'Spatial Dirichlet process\xa0']"
history,"['2018-01', '2016-12-08', '2016-02-23', '2016-11-25']"
abstract,"Abstract Integro-difference equations (IDEs) provide a flexible framework for dynamic modeling of spatio-temporal data. The choice of kernel in an IDE model relates directly to the underlying physical process modeled, and it can affect model fit and predictive accuracy. We introduce Bayesian non-parametric methods to the IDE literature as a means to allow flexibility in modeling the kernel. We propose a mixture of normal distributions for the IDE kernel, built from a spatial Dirichlet process for the mixing distribution, which can model kernels with shapes that change with location. This allows the IDE model to capture non-stationarity with respect to location and to reflect a changing physical process across the domain. We address computational concerns for inference that leverage the use of Hermite polynomials as a basis for the representation of the process and the IDE kernel, and incorporate Hamiltonian Markov chain Monte Carlo steps in the posterior simulation method. An example with synthetic data demonstrates that the model can successfully capture location-dependent dynamics. Moreover, using a data set of ozone pressure, we show that the spatial Dirichlet process mixture model outperforms several alternative models for the IDE kernel, including the state of the art in the IDE literature, that is, a Gaussian kernel with location-dependent parameters."
journal_title,Statistics and Computing
article_title,Estimating a sparse reduction for general regression in high dimensions
keyword,"['Inverse modeling\xa0', 'Model-free dimension reduction\xa0', 'Sparsity\xa0']"
history,"['2018-01', '2016-10-21', '2016-02-22', '2016-10-12']"
abstract,"Abstract Although the concept of sufficient dimension reduction that was originally proposed has been there for a long time, studies in the literature have largely focused on properties of estimators of dimension-reduction subspaces in the classical “small p, and large n” setting. Rather than the subspace, this paper considers directly the set of reduced predictors, which we believe are more relevant for subsequent analyses. A principled method is proposed for estimating a sparse reduction, which is based on a new, revised representation of an existing well-known method called the sliced inverse regression. A fast and efficient algorithm is developed for computing the estimator. The asymptotic behavior of the new method is studied when the number of predictors, p, exceeds the sample size, n, providing a guide for choosing the number of sufficient dimension-reduction predictors. Numerical results, including a simulation study and a cancer-drug-sensitivity data analysis, are presented to examine the performance."
journal_title,Statistics and Computing
article_title,Nonparametric maximum likelihood computation of a U-shaped hazard function
keyword,"['Algorithms\xa0', 'Lifetime and survival analysis\xa0', 'Nonparametric methods\xa0', 'Shape-restricted estimation\xa0', 'Numerical optimization\xa0']"
history,"['2018-01', '2017-01-18', '2015-11-12', '2017-01-05']"
abstract,"Abstract A new algorithm is presented and studied in this paper for fast computation of the nonparametric maximum likelihood estimate of a U-shaped hazard function. It successfully overcomes a difficulty when computing a U-shaped hazard function, which is only properly defined by knowing its anti-mode, and the anti-mode itself has to be found during the computation. Specifically, the new algorithm maintains the constant hazard segment, regardless of its length being zero or positive. The length varies naturally, according to what mass values are allocated to their associated knots after each updating. Being an appropriate extension of the constrained Newton method, the new algorithm also inherits its advantage of fast convergence, as demonstrated by some real-world data examples. The algorithm works not only for exact observations, but also for purely interval-censored data, and for data mixed with exact and interval-censored observations."
journal_title,Statistics and Computing
article_title,Large-scale kernel methods for independence testing
keyword,"['Independence testing\xa0', 'Large-scale kernel method\xa0', 'Hilbert–Schmidt independence criteria\xa0', 'Random Fourier features\xa0', 'Nyström method\xa0']"
history,"['2018-01', '2017-01-24', '2016-06-27', '2016-12-15']"
abstract,"Abstract Representations of probability measures in reproducing kernel Hilbert spaces provide a flexible framework for fully nonparametric hypothesis tests of independence, which can capture any type of departure from independence, including nonlinear associations and multivariate interactions. However, these approaches come with an at least quadratic computational cost in the number of observations, which can be prohibitive in many applications. Arguably, it is exactly in such large-scale datasets that capturing any type of dependence is of interest, so striking a favourable trade-off between computational efficiency and test performance for kernel independence tests would have a direct impact on their applicability in practice. In this contribution, we provide an extensive study of the use of large-scale kernel approximations in the context of independence testing, contrasting block-based, Nyström and random Fourier feature approaches. Through a variety of synthetic data experiments, it is demonstrated that our large-scale methods give comparable performance with existing methods while using significantly less computation time and memory."
journal_title,Statistics and Computing
article_title,Fitting monotone polynomials in mixed effects models
keyword,"['Monotone polynomials\xa0', 'Monotone regression\xa0', 'Mixed effects\xa0', 'Random effects\xa0', 'Shape constraints\xa0']"
history,"['2017-12-22', '2016-09-21', '2017-12-12']"
abstract,"Abstract We provide a method for fitting monotone polynomials to data with both fixed and random effects. In pursuit of such a method, a novel approach to least squares regression is proposed for models with functional constraints. The new method is able to fit models with constrained parameter spaces that are closed and convex, and is used in conjunction with an expectation–maximisation algorithm to fit monotone polynomials with mixed effects. The resulting mixed effects models have constrained mean curves and have the flexibility to include either unconstrained or constrained subject-specific curves. This new methodology is demonstrated on real-world repeated measures data with an application from sleep science. Code to fit the methods described in this paper is available online."
journal_title,Statistics and Computing
article_title,Generalized additive models with flexible response functions
keyword,"['Flexible response function\xa0', 'Generalized additive model\xa0', 'Monotonic P-spline\xa0', 'Single index model\xa0']"
history,"['2017-12-20', '2017-04-26', '2017-12-12']"
abstract,"Abstract Common generalized linear models depend on several assumptions: (i) the specified linear predictor, (ii) the chosen response distribution that determines the likelihood and (iii) the response function that maps the linear predictor to the conditional expectation of the response. Generalized additive models (GAM) provide a convenient way to overcome the restriction to purely linear predictors. Therefore, the covariates may be included as flexible nonlinear or spatial functions to avoid potential bias arising from misspecification. Single index models, on the other hand, utilize flexible specifications of the response function and therefore avoid the deteriorating impact of a misspecified response function. However, such single index models are usually restricted to a linear predictor and aim to compensate for potential nonlinear structures only via the estimated response function. We will show that this is insufficient in many cases and present a solution by combining a flexible approach for response function estimation using monotonic P-splines with additive predictors as in GAMs. Our approach is based on maximum likelihood estimation and also allows us to provide confidence intervals of the estimated effects. To compare our approach with existing ones, we conduct extensive simulation studies and apply our approach on two empirical examples, namely the mortality rate in São Paulo due to respiratory diseases based on the Poisson distribution and credit scoring of a German bank with binary responses."
journal_title,Statistics and Computing
article_title,Correction to: Inferring large graphs using $$\ell _{1}$$ℓ1-penalized likelihood
keyword,[]
history,['2017-12-08']
abstract,None
journal_title,Statistics and Computing
article_title,Deep Gaussian mixture models
keyword,"['Unsupervised classification\xa0', 'Mixtures of factor analyzers\xa0', 'Stochastic EM algorithm\xa0']"
history,"['2017-12-01', '2017-11-18', '2017-11-25']"
abstract,"Abstract Deep learning is a hierarchical inference method formed by subsequent multiple layers of learning able to more efficiently describe complex relationships. In this work, deep Gaussian mixture models (DGMM) are introduced and discussed. A DGMM is a network of multiple layers of latent variables, where, at each layer, the variables follow a mixture of Gaussian distributions. Thus, the deep mixture model consists of a set of nested mixtures of linear models, which globally provide a nonlinear model able to describe the data in a very flexible way. In order to avoid overparameterized solutions, dimension reduction by factor models can be applied at each layer of the architecture, thus resulting in deep mixtures of factor analyzers."
journal_title,Statistics and Computing
article_title,Best linear estimation via minimization of relative mean squared error
keyword,"['Biased linear estimator\xa0', 'Smallest relative mean squared error\xa0', 'Ridge regression\xa0', 'Ordinary least squares\xa0']"
history,"['2017-11-30', '2017-03-30', '2017-11-20']"
abstract,"Abstract We propose methods to construct a biased linear estimator for linear regression which optimizes the relative mean squared error (MSE). Although there have been proposed biased estimators which are shown to have smaller MSE than the ordinary least squares estimator, our construction is based on the minimization of relative MSE directly. The performance of the proposed methods is illustrated by a simulation study and a real data example. The results show that our methods can improve on MSE, particularly when there exists correlation among the predictors."
journal_title,Statistics and Computing
article_title,Asymptotic normality of extensible grid sampling
keyword,"['Asymptotic normality\xa0', 'Hilbert’s space filling curve\xa0', 'Van der Corput sequence\xa0', 'Randomized quasi-Monte Carlo\xa0', 'Extensible grid sampling\xa0']"
history,"['2017-11-29', '2017-08-03', '2017-11-25']"
abstract,"Abstract Recently, He and Owen (J R Stat Soc Ser B 78(4):917–931, 2016) proposed the use of Hilbert’s space filling curve (HSFC) in numerical integration as a way of reducing the dimension from \(d>1\) to \(d=1\). This paper studies the asymptotic normality of the HSFC-based estimate when using one-dimensional stratification inputs. In particular, we are interested in using scrambled van der Corput sequence in any base \(b\ge 2\) with sample sizes of the form \(n=b^m\), for which the sampling scheme is extensible in the sense of multiplying the sample size by a factor of b. We show that the estimate has an asymptotic normal distribution for functions in \(C^1([0,1]^d)\), excluding the trivial case of constant functions. The asymptotic normality also holds for discontinuous functions under mild conditions. Previously, it was only known that scrambled (0, m, d)-net quadratures enjoy the asymptotic normality for smooth enough functions, whose mixed partial gradients satisfy a Hölder condition. As a by-product, we find lower bounds for the variance of the HSFC-based estimate. Particularly, for non-trivial functions in \(C^1([0,1]^d)\), the lower bound is of order \(n^{-1-2/d}\), which matches the rate of the upper bound established in He and Owen (2016)."
journal_title,Statistics and Computing
article_title,Double-Parallel Monte Carlo for Bayesian analysis of big data
keyword,"['Embarrassingly parallel\xa0', 'Divide-and-combine\xa0', 'MCMC\xa0', 'Pop-SAMC\xa0', 'Subset posterior aggregation\xa0']"
history,"['2017-11-27', '2017-04-22', '2017-11-17']"
abstract,"Abstract This paper proposes a simple, practical, and efficient MCMC algorithm for Bayesian analysis of big data. The proposed algorithm suggests to divide the big dataset into some smaller subsets and provides a simple method to aggregate the subset posteriors to approximate the full data posterior. To further speed up computation, the proposed algorithm employs the population stochastic approximation Monte Carlo algorithm, a parallel MCMC algorithm, to simulate from each subset posterior. Since this algorithm consists of two levels of parallel, data parallel and simulation parallel, it is coined as “Double-Parallel Monte Carlo.” The validity of the proposed algorithm is justified mathematically and numerically."
journal_title,Statistics and Computing
article_title,Langevin diffusions on the torus: estimation and applications
keyword,"['Circular data\xa0', 'Directional statistics\xa0', 'Likelihood\xa0', 'Protein structure\xa0', 'Stochastic Differential Equation\xa0', 'Wrapped normal\xa0', '60J60\xa0', '62M05\xa0', '62H11\xa0']"
history,"['2017-11-21', '2017-05-21', '2017-11-07']"
abstract,"Abstract We introduce stochastic models for continuous-time evolution of angles and develop their estimation. We focus on studying Langevin diffusions with stationary distributions equal to well-known distributions from directional statistics, since such diffusions can be regarded as toroidal analogues of the Ornstein–Uhlenbeck process. Their likelihood function is a product of transition densities with no analytical expression, but that can be calculated by solving the Fokker–Planck equation numerically through adequate schemes. We propose three approximate likelihoods that are computationally tractable: (i) a likelihood based on the stationary distribution; (ii) toroidal adaptations of the Euler and Shoji–Ozaki pseudo-likelihoods; (iii) a likelihood based on a specific approximation to the transition density of the wrapped normal process. A simulation study compares, in dimensions one and two, the approximate transition densities to the exact ones, and investigates the empirical performance of the approximate likelihoods. Finally, two diffusions are used to model the evolution of the backbone angles of the protein G (PDB identifier 1GB1) during a molecular dynamics simulation. The software package sdetorus implements the estimation methods and applications presented in the paper."
journal_title,Statistics and Computing
article_title,Efficient $$\hbox {SMC}^2$$SMC2 schemes for stochastic kinetic models
keyword,"['Auxiliary particle filter (APF)\xa0', 'Bayesian inference\xa0', 'Markov jump process (MJP)\xa0', 'Sequential Monte Carlo (SMC)\xa0', 'Stochastic kinetic model (SKM)\xa0']"
history,"['2017-11-10', '2017-04-10', '2017-11-02']"
abstract,"Abstract Fitting stochastic kinetic models represented by Markov jump processes within the Bayesian paradigm is complicated by the intractability of the observed-data likelihood. There has therefore been considerable attention given to the design of pseudo-marginal Markov chain Monte Carlo algorithms for such models. However, these methods are typically computationally intensive, often require careful tuning and must be restarted from scratch upon receipt of new observations. Sequential Monte Carlo (SMC) methods on the other hand aim to efficiently reuse posterior samples at each time point. Despite their appeal, applying SMC schemes in scenarios with both dynamic states and static parameters is made difficult by the problem of particle degeneracy. A principled approach for overcoming this problem is to move each parameter particle through a Metropolis-Hastings kernel that leaves the target invariant. This rejuvenation step is key to a recently proposed \(\hbox {SMC}^2\) algorithm, which can be seen as the pseudo-marginal analogue of an idealised scheme known as iterated batch importance sampling. Computing the parameter weights in \(\hbox {SMC}^2\) requires running a particle filter over dynamic states to unbiasedly estimate the intractable observed-data likelihood up to the current time point. In this paper, we propose to use an auxiliary particle filter inside the \(\hbox {SMC}^2\) scheme. Our method uses two recently proposed constructs for sampling conditioned jump processes, and we find that the resulting inference schemes typically require fewer state particles than when using a simple bootstrap filter. Using two applications, we compare the performance of the proposed approach with various competing methods, including two global MCMC schemes."
journal_title,Statistics and Computing
article_title,Auxiliary variables for Bayesian inference in multi-class queueing networks
keyword,"['Queueing networks\xa0', 'Continuous-time Markov chains\xa0', 'Uniformization\xa0', 'Markov chain Monte Carlo\xa0', 'Slice sampler\xa0']"
history,"['2017-11-08', '2017-03-08', '2017-10-30']"
abstract,"Abstract Queueing networks describe complex stochastic systems of both theoretical and practical interest. They provide the means to assess alterations, diagnose poor performance and evaluate robustness across sets of interconnected resources. In the present paper, we focus on the underlying continuous-time Markov chains induced by these networks, and we present a flexible method for drawing parameter inference in multi-class Markovian cases with switching and different service disciplines. The approach is directed towards the inferential problem with missing data, where transition paths of individual tasks among the queues are often unknown. The paper introduces a slice sampling technique with mappings to the measurable space of task transitions between the service stations. This can address time and tractability issues in computational procedures, handle prior system knowledge and overcome common restrictions on service rates across existing inferential frameworks. Finally, the proposed algorithm is validated on synthetic data and applied to a real data set, obtained from a service delivery tasking tool implemented in two university hospitals."
journal_title,Statistics and Computing
article_title,Dynamic stochastic block models: parameter estimation and detection of changes in community structure
keyword,"['Stochastic block model\xa0', 'Autoregressive dynamic network\xa0', 'Reversible-jump MCMC\xa0', 'Continuous-time network\xa0']"
history,"['2017-11-02', '2017-03-06', '2017-10-30']"
abstract,"Abstract The stochastic block model (SBM) is widely used for modelling network data by assigning individuals (nodes) to communities (blocks) with the probability of an edge existing between individuals depending upon community membership. In this paper, we introduce an autoregressive extension of the SBM, based on continuous-time Markovian edge dynamics. The model is appropriate for networks evolving over time and allows for edges to turn on and off. Moreover, we allow for the movement of individuals between communities. An effective reversible-jump Markov chain Monte Carlo algorithm is introduced for sampling jointly from the posterior distribution of the community parameters and the number and location of changes in community membership. The algorithm is successfully applied to a network of mice."
journal_title,Statistics and Computing
article_title,Non-parametric maximum likelihood estimation of interval-censored failure time data subject to misclassification
keyword,"['Interval-censored data\xa0', 'NPMLE\xa0', 'Misclassification\xa0', 'Directional derivatives\xa0']"
history,"['2017-11', '2016-09-29', '2015-06-23', '2016-09-19']"
abstract,"Abstract The paper considers non-parametric maximum likelihood estimation of the failure time distribution for interval-censored data subject to misclassification. Such data can arise from two types of observation scheme; either where observations continue until the first positive test result or where tests continue regardless of the test results. In the former case, the misclassification probabilities must be known, whereas in the latter case, joint estimation of the event-time distribution and misclassification probabilities is possible. The regions for which the maximum likelihood estimate can only have support are derived. Algorithms for computing the maximum likelihood estimate are investigated and it is shown that algorithms appropriate for computing non-parametric mixing distributions perform better than an iterative convex minorant algorithm in terms of time to absolute convergence. A profile likelihood approach is proposed for joint estimation. The methods are illustrated on a data set relating to the onset of cardiac allograft vasculopathy in post-heart-transplantation patients."
journal_title,Statistics and Computing
article_title,Functional principal component analysis of spatially correlated data
keyword,"['Functional data analysis\xa0', 'Spatial correlation\xa0', 'Conditioning\xa0', 'Principal components\xa0', 'Smoothing\xa0', 'consistency\xa0']"
history,"['2017-11', '2016-10-04', '2016-03-16', '2016-09-21']"
abstract,"Abstract This paper focuses on the analysis of spatially correlated functional data. We propose a parametric model for spatial correlation and the between-curve correlation is modeled by correlating functional principal component scores of the functional data. Additionally, in the sparse observation framework, we propose a novel approach of spatial principal analysis by conditional expectation to explicitly estimate spatial correlations and reconstruct individual curves. Assuming spatial stationarity, empirical spatial correlations are calculated as the ratio of eigenvalues of the smoothed covariance surface Cov\((X_i(s),X_i(t))\) and cross-covariance surface Cov\((X_i(s), X_j(t))\) at locations indexed by i and j. Then a anisotropy Matérn spatial correlation model is fitted to empirical correlations. Finally, principal component scores are estimated to reconstruct the sparsely observed curves. This framework can naturally accommodate arbitrary covariance structures, but there is an enormous reduction in computation if one can assume the separability of temporal and spatial components. We demonstrate the consistency of our estimates and propose hypothesis tests to examine the separability as well as the isotropy effect of spatial correlation. Using simulation studies, we show that these methods have some clear advantages over existing methods of curve reconstruction and estimation of model parameters."
journal_title,Statistics and Computing
article_title,Bayesian regularisation in geoadditive expectile regression
keyword,"['Asymmetric normal distribution\xa0', 'Bayesian semiparametric regression\xa0', 'Expectile regression\xa0', 'Markov chain Monte Carlo simulation\xa0', 'Markov random fields\xa0', 'P-splines\xa0', 'Spike and slab priors\xa0']"
history,"['2017-11', '2016-09-19', '2015-12-20', '2016-09-06']"
abstract,"Abstract Regression modelling beyond the mean of the response has found a lot of attention in the last years. Expectile regression is a special and computationally convenient case of this type of models where expectiles offer a quantile-like characterisation of the complete distribution and include the mean as a special case. In the frequentist framework, expectile regression could be combined with covariate effects of quite different forms and in particular nonlinear and spatial effects. We propose Bayesian expectile regression based on the asymmetric normal distribution as an auxiliary likelihood to allow for the additional inclusion of Bayesian regularisation priors for covariates with linear effects. Proposal densities based on iteratively weighted least squares updates for the resulting Markov chain Monte Carlo simulation algorithm are developed and evaluated in both simulations and an application. A special focus of the simulations lies on the evaluation of coverage properties of the Bayesian credible bands and the quantification of the detrimental effect arising from the misspecification of the auxiliary likelihood."
journal_title,Statistics and Computing
article_title,A Bayesian nonparametric Markovian model for non-stationary time series
keyword,"['Autoregressive models\xa0', 'Bayesian nonparametrics\xa0', 'Dirichlet process mixtures\xa0', 'Markov chain Monte Carlo\xa0', 'Non-stationarity\xa0', 'Time series\xa0']"
history,"['2017-11', '2016-10-07', '2015-08-20', '2016-09-02']"
abstract,"Abstract Stationary time series models built from parametric distributions are, in general, limited in scope due to the assumptions imposed on the residual distribution and autoregression relationship. We present a modeling approach for univariate time series data, which makes no assumptions of stationarity, and can accommodate complex dynamics and capture non-standard distributions. The model for the transition density arises from the conditional distribution implied by a Bayesian nonparametric mixture of bivariate normals. This results in a flexible autoregressive form for the conditional transition density, defining a time-homogeneous, non-stationary Markovian model for real-valued data indexed in discrete time. To obtain a computationally tractable algorithm for posterior inference, we utilize a square-root-free Cholesky decomposition of the mixture kernel covariance matrix. Results  from simulated data suggest that the model is able to recover challenging transition densities and non-linear dynamic relationships. We also illustrate the model on time intervals between eruptions of the Old Faithful geyser. Extensions to accommodate higher order structure and to develop a state-space model are also discussed."
journal_title,Statistics and Computing
article_title,A wavelet lifting approach to long-memory estimation
keyword,"['Hurst exponent\xa0', 'Irregular sampling\xa0', 'Long-range dependence\xa0', 'Wavelets\xa0']"
history,"['2017-11', '2016-09-03', '2016-05-23', '2016-08-12']"
abstract,"Abstract Reliable estimation of long-range dependence parameters is vital in time series. For example, in environmental and climate science such estimation is often key to understanding climate dynamics, variability and often prediction. The challenge of data collection in such disciplines means that, in practice, the sampling pattern is either irregular or blighted by missing observations. Unfortunately, virtually all existing Hurst parameter estimation methods assume regularly sampled time series and require modification to cope with irregularity or missing data. However, such interventions come at the price of inducing higher estimator bias and variation, often worryingly ignored. This article proposes a new Hurst exponent estimation method which naturally copes with data sampling irregularity. The new method is based on a multiscale lifting transform exploiting its ability to produce wavelet-like coefficients on irregular data and, simultaneously, to effect a necessary powerful decorrelation of those coefficients. Simulations show that our method is accurate and effective, performing well against competitors even in regular data settings. Armed with this evidence our method sheds new light on long-memory intensity results in environmental and climate science applications, sometimes suggesting that different scientific conclusions may need to be drawn."
journal_title,Statistics and Computing
article_title,The locally Gaussian density estimator for multivariate data
keyword,"['Multivariate nonparametric density estimation\xa0', 'Curse of dimensionality\xa0', 'Local likelihood\xa0']"
history,"['2017-11', '2016-10-05', '2015-11-29', '2016-09-19']"
abstract,"Abstract It is well known that the Curse of Dimensionality causes the standard Kernel Density Estimator to break down quickly as the number of variables increases. In non-parametric regression, this effect is relieved in various ways, for example by assuming additivity or some other simplifying structure on the interaction between variables. This paper presents the Locally Gaussian Density Estimator (LGDE), which introduces a similar idea to the problem of density estimation. The LGDE is a new method for the non-parametric estimation of multivariate probability density functions. It is based on preliminary transformations of the marginal observation vectors towards standard normality, and a simplified local likelihood fit of the resulting distribution with standard normal marginals. The LGDE is introduced, and asymptotic theory is derived. In particular, it is shown that the LGDE converges at a speed that does not depend on the dimension. Examples using real and simulated data confirm that the new estimator performs very well on finite sample sizes."
journal_title,Statistics and Computing
article_title,A comparison of centring parameterisations of Gaussian process-based models for Bayesian computation using MCMC
keyword,"['Bayesian inference\xa0', 'Gibbs sampler\xa0', 'Hierarchical models\xa0', 'Rate of convergence\xa0', 'Spatial data\xa0']"
history,"['2017-11', '2016-09-14', '2016-02-18', '2016-08-30']"
abstract,"Abstract Markov chain Monte Carlo (MCMC) algorithms for Bayesian computation for Gaussian process-based models under default parameterisations are slow to converge due to the presence of spatial- and other-induced dependence structures. The main focus of this paper is to study the effect of the assumed spatial correlation structure on the convergence properties of the Gibbs sampler under the default non-centred parameterisation and a rival centred parameterisation (CP), for the mean structure of a general multi-process Gaussian spatial model. Our investigation finds answers to many pertinent, but as yet unanswered, questions on the choice between the two. Assuming the covariance parameters to be known, we compare the exact rates of convergence of the two by varying the strength of the spatial correlation, the level of covariance tapering, the scale of the spatially varying covariates, the number of data points, the number and the structure of block updating of the spatial effects and the amount of smoothness assumed in a Matérn covariance function. We also study the effects of introducing differing levels of geometric anisotropy in the spatial model. The case of unknown variance parameters is investigated using well-known MCMC convergence diagnostics. A simulation study and a real-data example on modelling air pollution levels in London are used for illustrations. A generic pattern emerges that the CP is preferable in the presence of more spatial correlation or more information obtained through, for example, additional data points or by increased covariate variability."
journal_title,Statistics and Computing
article_title,Hierarchical Bayesian level set inversion
keyword,"['Inverse problems for interfaces\xa0', 'Level set inversion\xa0', 'Hierarchical Bayesian methods\xa0']"
history,"['2017-11', '2016-09-21', '2016-01-13', '2016-09-09']"
abstract,"Abstract The level set approach has proven widely successful in the study of inverse problems for interfaces, since its systematic development in the 1990s. Recently it has been employed in the context of Bayesian inversion, allowing for the quantification of uncertainty within the reconstruction of interfaces. However, the Bayesian approach is very sensitive to the length and amplitude scales in the prior probabilistic model. This paper demonstrates how the scale-sensitivity can be circumvented by means of a hierarchical approach, using a single scalar parameter. Together with careful consideration of the development of algorithms which encode probability measure equivalences as the hierarchical parameter is varied, this leads to well-defined Gibbs-based MCMC methods found by alternating Metropolis–Hastings updates of the level set function and the hierarchical parameter. These methods demonstrably outperform non-hierarchical Bayesian level set methods."
journal_title,Statistics and Computing
article_title,Hamiltonian Monte Carlo acceleration using surrogate functions with random bases
keyword,"['Markov chain Monte Carlo\xa0', 'Hamiltonian dynamics\xa0', 'Surrogate method\xa0', 'Random bases\xa0']"
history,"['2017-11', '2016-09-13', '2015-09-16', '2016-08-30']"
abstract,"Abstract For big data analysis, high computational cost for Bayesian methods often limits their applications in practice. In recent years, there have been many attempts to improve computational efficiency of Bayesian inference. Here we propose an efficient and scalable computational technique for a state-of-the-art Markov chain Monte Carlo methods, namely, Hamiltonian Monte Carlo. The key idea is to explore and exploit the structure and regularity in parameter space for the underlying probabilistic model to construct an effective approximation of its geometric properties. To this end, we build a surrogate function to approximate the target distribution using properly chosen random bases and an efficient optimization process. The resulting method provides a flexible, scalable, and efficient sampling algorithm, which converges to the correct target distribution. We show that by choosing the basis functions and optimization process differently, our method can be related to other approaches for the construction of surrogate functions such as generalized additive models or Gaussian process models. Experiments based on simulated and real data show that our approach leads to substantially more efficient sampling algorithms compared to existing state-of-the-art methods."
journal_title,Statistics and Computing
article_title,A second-order iterated smoothing algorithm
keyword,"['Iterated smoothing\xa0', 'Sequential Monte Carlo\xa0', 'State space model\xa0', 'Hidden Markov model\xa0', 'Parameter estimation\xa0']"
history,"['2017-11', '2016-10-15', '2015-08-19', '2016-10-03']"
abstract,"Abstract Simulation-based inference for partially observed stochastic dynamic models is currently receiving much attention due to the fact that direct computation of the likelihood is not possible in many practical situations. Iterated filtering methodologies enable maximization of the likelihood function using simulation-based sequential Monte Carlo filters. Doucet et al. (2013) developed an approximation for the first and second derivatives of the log likelihood via simulation-based sequential Monte Carlo smoothing and proved that the approximation has some attractive theoretical properties. We investigated an iterated smoothing algorithm carrying out likelihood maximization using these derivative approximations. Further, we developed a new iterated smoothing algorithm, using a modification of these derivative estimates, for which we establish both theoretical results and effective practical performance. On benchmark computational challenges, this method beat the first-order iterated filtering algorithm. The method’s performance was comparable to a recently developed iterated filtering algorithm based on an iterated Bayes map. Our iterated smoothing algorithm and its theoretical justification provide new directions for future developments in simulation-based inference for latent variable models such as partially observed Markov process models."
journal_title,Statistics and Computing
article_title,Fast and robust estimators of variance components in the nested error model
keyword,"['Clustered data\xa0', 'Linear mixed model\xa0', 'Random effects\xa0', 'Robust fitting\xa0', 'Variance estimation\xa0']"
history,"['2017-11', '2016-10-17', '2016-02-23', '2016-09-30']"
abstract,"Abstract Usual fitting methods for the nested error linear regression model are known to be very sensitive to the effect of even a single outlier. Robust approaches for the unbalanced nested error model with proved robustness and efficiency properties, such as M-estimators, are typically obtained through iterative algorithms. These algorithms are often computationally intensive and require robust estimates of the same parameters to start the algorithms, but so far no robust starting values have been proposed for this model. This paper proposes computationally fast robust estimators for the variance components under an unbalanced nested error model, based on a simple robustification of the fitting-of-constants method or Henderson method III. These estimators can be used as starting values for other iterative methods. Our simulations show that they are highly robust to various types of contamination of different magnitude."
journal_title,Statistics and Computing
article_title,Segmental dynamic factor analysis for time series of curves
keyword,"['Functional time series\xa0', 'Visualization and forecasting\xa0', 'Mixture of regressions\xa0', 'Dynamic factor analysis\xa0', 'Variational EM\xa0', 'Condition monitoring\xa0']"
history,"['2017-11', '2016-10-03', '2015-09-27', '2016-09-21']"
abstract,"Abstract A new approach is introduced in this article for describing and visualizing time series of curves, where each curve has the particularity of being subject to changes in regime. For this purpose, the curves are represented by a regression model including a latent segmentation, and their temporal evolution is modeled through a Gaussian random walk over low-dimensional factors of the regression coefficients. The resulting model is nothing else than a particular state-space model involving discrete and continuous latent variables, whose parameters are estimated across a sequence of curves through a dedicated variational Expectation-Maximization algorithm. The experimental study conducted on simulated data and real time series of curves has shown encouraging results in terms of visualization of their temporal evolution and forecasting."
journal_title,Statistics and Computing
article_title,Approximations for weighted Kolmogorov–Smirnov distributions via boundary crossing probabilities
keyword,"['Boundary crossing\xa0', None, 'Gene set enrichment analysis\xa0', '62G10\xa0', '60J65\xa0']"
history,"['2017-11', '2016-09-15', '2016-03-03', '2016-09-02']"
abstract,"Abstract A statistical application to Gene Set Enrichment Analysis implies calculating the distribution of the maximum of a certain Gaussian process, which is a modification of the standard Brownian bridge. Using the transformation into a boundary crossing problem for the Brownian motion and a piecewise linear boundary, it is proved that the desired distribution can be approximated by an n-dimensional Gaussian integral. Fast approximations are defined and validated by Monte Carlo simulation. The performance of the method for the genomics application is discussed."
journal_title,Statistics and Computing
article_title,Automated selection of r fo r the r la rgest o rde r statistics app roach with adjustment fo r sequential testing
keyword,"['Entropy\xa0', 'Generalized extreme value\xa0', 'Goodness-of-fit\xa0', 'Multiplier bootstrap\xa0', 'Score test\xa0', 'Sequential testing\xa0']"
history,"['2017-11', '2016-10-05', '2016-02-05', '2016-08-17']"
abstract,"Abstract The r largest order statistics approach is widely used in extreme value analysis because it may use more information from the data than just the block maxima. In practice, the choice of r is critical. If r is too large, bias can occur; if too small, the variance of the estimator can be high. The limiting distribution of the r largest order statistics, denoted by GEV\(_r\), extends that of the block maxima. Two specification tests are proposed to select r sequentially. The first is a score test for the GEV\(_r\) distribution. Due to the special characteristics of the GEV\(_r\) distribution, the classical chi-square asymptotics cannot be used. The simplest approach is to use the parametric bootstrap, which is straightforward to implement but computationally expensive. An alternative fast weighted bootstrap or multiplier procedure is developed for computational efficiency. The second test uses the difference in estimated entropy between the GEV\(_r\) and GEV\(_{r-1}\) models, applied to the r largest order statistics and the \(r-1\) largest order statistics, respectively. The asymptotic distribution of the difference statistic is derived. In a large scale simulation study, both tests held their size and had substantial power to detect various misspecification schemes. A new approach to address the issue of multiple, sequential hypotheses testing is adapted to this setting to control the false discovery rate or familywise error rate. The utility of the procedures is demonstrated with extreme sea level and precipitation data."
journal_title,Statistics and Computing
article_title,Composable models for online Bayesian analysis of streaming data
keyword,"['Bayesian\xa0', 'Dynamic models\xa0', 'Online analysis\xa0', 'Particle filtering\xa0', 'MCMC\xa0']"
history,"['2017-10-31', '2016-09-21', '2017-09-22']"
abstract,"Abstract Data is rapidly increasing in volume and velocity and the Internet of Things (IoT) is one important source of this data. The IoT is a collection of connected devices (things) which are constantly recording data from their surroundings using on-board sensors. These devices can record and stream data to the cloud at a very high rate, leading to high storage and analysis costs. In order to ameliorate these costs, the data is modelled as a stream and analysed online to learn about the underlying process, perform interpolation and smoothing and make forecasts and predictions. Conventional state space modelling tools assume the observations occur on a fixed regular time grid. However, many sensors change their sampling frequency, sometimes adaptively, or get interrupted and re-started out of sync with the previous sampling grid, or just generate event data at irregular times. It is therefore desirable to model the system as a partially and irregularly observed Markov process which evolves in continuous time. Both the process and the observation model are potentially non-linear. Particle filters therefore represent the simplest approach to online analysis. A functional Scala library of composable continuous time Markov process models has been developed in order to model the wide variety of data captured in the IoT."
journal_title,Statistics and Computing
article_title,Optimal Bayesian estimators for latent variable cluster models
keyword,"['Bayesian clustering\xa0', 'Cluster analysis\xa0', 'Greedy optimisation\xa0', 'Latent variable models\xa0', 'Markov chain Monte Carlo\xa0']"
history,"['2017-10-31', '2017-03-23', '2017-10-20']"
abstract,"Abstract In cluster analysis interest lies in probabilistically capturing partitions of individuals, items or observations into groups, such that those belonging to the same group share similar attributes or relational profiles. Bayesian posterior samples for the latent allocation variables can be effectively obtained in a wide range of clustering models, including finite mixtures, infinite mixtures, hidden Markov models and block models for networks. However, due to the categorical nature of the clustering variables and the lack of scalable algorithms, summary tools that can interpret such samples are not available. We adopt a Bayesian decision theoretical approach to define an optimality criterion for clusterings and propose a fast and context-independent greedy algorithm to find the best allocations. One important facet of our approach is that the optimal number of groups is automatically selected, thereby solving the clustering and the model-choice problems at the same time. We consider several loss functions to compare partitions and show that our approach can accommodate a wide range of cases. Finally, we illustrate our approach on both artificial and real datasets for three different clustering models: Gaussian mixtures, stochastic block models and latent block models for networks."
journal_title,Statistics and Computing
article_title,Maximum likelihood estimation for incomplete multinomial data via the weaver algorithm
keyword,"['Bradley–Terry model\xa0', 'Contingency table\xa0', 'Count data\xa0', 'Density estimation\xa0', 'Incomplete multinomial model\xa0', 'Plackett–Luce model\xa0', 'Random partition\xa0', 'Ranking\xa0', 'Weaver algorithm\xa0', '62F07\xa0', '65K10\xa0', '62G07\xa0']"
history,"['2017-10-27', '2017-03-28', '2017-10-14']"
abstract,"Abstract In a multinomial model, the sample space is partitioned into a disjoint union of cells. The partition is usually immutable during sampling of the cell counts. In this paper, we extend the multinomial model to the incomplete multinomial model by relaxing the constant partition assumption to allow the cells to be variable and the counts collected from non-disjoint cells to be modeled in an integrated manner for inference on the common underlying probability. The incomplete multinomial likelihood is parameterized by the complete-cell probabilities from the most refined partition. Its sufficient statistics include the variable-cell formation observed as an indicator matrix and all cell counts. With externally imposed structures on the cell formation process, it reduces to special models including the Bradley–Terry model, the Plackett–Luce model, etc. Since the conventional method, which solves for the zeros of the score functions, is unfruitful, we develop a new approach to establishing a simpler set of estimating equations to obtain the maximum likelihood estimate (MLE), which seeks the simultaneous maximization of all multiplicative components of the likelihood by fitting each component into an inequality. As a consequence, our estimation amounts to solving a system of the equality attainment conditions to the inequalities. The resultant MLE equations are simple and immediately invite a fixed-point iteration algorithm for solution, which is referred to as the weaver algorithm. The weaver algorithm is short and amenable to parallel implementation. We also derive the asymptotic covariance of the MLE, verify main results with simulations, and compare the weaver algorithm with an MM/EM algorithm based on fitting a Plackett–Luce model to a benchmark data set."
journal_title,Statistics and Computing
article_title,The locally stationary dual-tree complex wavelet model
keyword,"['Locally stationary wavelet\xa0', 'Random fields\xa0', 'Dual-tree complex wavelets\xa0', 'Stationarity detection\xa0']"
history,"['2017-10-26', '2017-10-15', '2017-10-20']"
abstract,"Abstract We here harmonise two significant contributions to the field of wavelet analysis in the past two decades, namely the locally stationary wavelet process and the family of dual-tree complex wavelets. By combining these two components, we furnish a statistical model that can simultaneously access benefits from these two constructions. On the one hand, our model borrows the debiased spectrum and auto-covariance estimator from the locally stationary wavelet model. On the other hand, the enhanced directional selectivity is obtained from the dual-tree complex wavelets over the regular lattice. The resulting model allows for the description and identification of wavelet fields with significantly more directional fidelity than was previously possible. The corresponding estimation theory is established for the new model, and some stationarity detection experiments illustrate its practicality."
journal_title,Statistics and Computing
article_title,"Anisotropy of Hölder Gaussian random fields: characterization, estimation, and application to image textures"
keyword,"['Hölder regularity\xa0', 'Anisotropy\xa0', 'Fractional Brownian field\xa0', 'Quadratic variations\xa0', 'Texture analysis\xa0', 'Photographic paper\xa0']"
history,"['2017-10-24', '2016-12-19', '2017-10-20']"
abstract,"Abstract The characterization and estimation of the Hölder regularity of random fields has long been an important topic of Probability theory and Statistics. This notion of regularity has also been widely used in image analysis to measure the roughness of textures. However, such a measure is rarely sufficient to characterize textures as it does not account for their directional properties (e.g., isotropy and anisotropy). In this paper, we present an approach to further characterize directional properties associated with the Hölder regularity of random fields. Using the spectral density, we define a notion of asymptotic topothesy which quantifies directional contributions of field high-frequencies to the Hölder regularity. This notion is related to the topothesy function of the so-called anisotropic fractional Brownian fields, but is defined in a more generic framework of intrinsic random fields. We then propose a method based on multi-oriented quadratic variations to estimate this asymptotic topothesy. Eventually, we evaluate this method on synthetic data and apply it for the characterization of historical photographic papers."
journal_title,Statistics and Computing
article_title,Trajectory inference and parameter estimation in stochastic models with temporally aggregated data
keyword,"['Linear noise approximation\xa0', 'Stochastic systems biology\xa0', 'Time aggregation\xa0', 'Kalman filter\xa0']"
history,"['2017-10-24', '2017-05-03', '2017-09-22']"
abstract,"Abstract Stochastic models are of fundamental importance in many scientific and engineering applications. For example, stochastic models provide valuable insights into the causes and consequences of intra-cellular fluctuations and inter-cellular heterogeneity in molecular biology. The chemical master equation can be used to model intra-cellular stochasticity in living cells, but analytical solutions are rare and numerical simulations are computationally expensive. Inference of system trajectories and estimation of model parameters from observed data are important tasks and are even more challenging. Here, we consider the case where the observed data are aggregated over time. Aggregation of data over time is required in studies of single cell gene expression using a luciferase reporter, where the emitted light can be very faint and is therefore collected for several minutes for each observation. We show how an existing approach to inference based on the linear noise approximation (LNA) can be generalised to the case of temporally aggregated data. We provide a Kalman filter (KF) algorithm which can be combined with the LNA to carry out inference of system variable trajectories and estimation of model parameters. We apply and evaluate our method on both synthetic and real data scenarios and show that it is able to accurately infer the posterior distribution of model parameters in these examples. We demonstrate how applying standard KF inference to aggregated data without accounting for aggregation will tend to underestimate the process noise and can lead to biased parameter estimates."
journal_title,Statistics and Computing
article_title,A new algorithm to estimate monotone nonparametric link functions and a comparison with parametric approach
keyword,"['Generalized linear model\xa0', 'Monotone link functions\xa0', 'P-spline\xa0', 'Single index model\xa0', 'Skewed link functions\xa0']"
history,"['2017-10-20', '2016-11-15', '2017-10-14']"
abstract,"Abstract The generalized linear model (GLM) is a class of regression models where the means of the response variables and the linear predictors are joined through a link function. Standard GLM assumes the link function is fixed, and one can form more flexible GLM by either estimating the flexible link function from a parametric family of link functions or estimating it nonparametically. In this paper, we propose a new algorithm that uses P-spline for nonparametrically estimating the link function which is guaranteed to be monotone. It is equivalent to fit the generalized single index model with monotonicity constraint. We also conduct extensive simulation studies to compare our nonparametric approach for estimating link function with various parametric approaches, including traditional logit, probit and robit link functions, and two recently developed link functions, the generalized extreme value link and the symmetric power logit link. The simulation study shows that the link function estimated nonparametrically by our proposed algorithm performs well under a wide range of different true link functions and outperforms parametric approaches when they are misspecified. A real data example is used to illustrate the results."
journal_title,Statistics and Computing
article_title,On parallelizable Markov chain Monte Carlo algorithms with waste-recycling
keyword,"['Weighted samples\xa0', 'Markov chain Monte Carlo\xa0', 'Rao–Blackwellization\xa0', 'Parallel computation\xa0', 'Effective sample size\xa0', 'Estimation efficiency\xa0']"
history,"['2017-10-11', '2017-09-21', '2017-10-06']"
abstract,"Abstract Parallelizable Markov chain Monte Carlo (MCMC) generates multiple proposals and parallelizes the evaluations of the likelihood function on different cores at each MCMC iteration. Inspired by Calderhead (Proc Natl Acad Sci 111(49):17408–17413, 2014), we introduce a general ‘waste-recycling’ framework for parallelizable MCMC, under which we show that using weighted samples from waste-recycling is preferable to resampling in terms of both statistical and computational efficiencies. We also provide a simple-to-use criteria, the generalized effective sample size, for evaluating efficiencies of parallelizable MCMC algorithms, which applies to both the waste-recycling and the vanilla versions. A moment estimator of the generalized effective sample size is provided and shown to be reasonably accurate by simulations."
journal_title,Statistics and Computing
article_title,Markov chain Monte Carlo with the Integrated Nested Laplace Approximation
keyword,"['Bayesian Lasso\xa0', 'INLA\xa0', 'MCMC\xa0', 'Missing values\xa0', 'Spatial models\xa0', 'Mixture models\xa0']"
history,"['2017-10-06', '2017-01-26', '2017-09-22']"
abstract,"Abstract The Integrated Nested Laplace Approximation (INLA) has established itself as a widely used method for approximate inference on Bayesian hierarchical models which can be represented as a latent Gaussian model (LGM). INLA is based on producing an accurate approximation to the posterior marginal distributions of the parameters in the model and some other quantities of interest by using repeated approximations to intermediate distributions and integrals that appear in the computation of the posterior marginals. INLA focuses on models whose latent effects are a Gaussian Markov random field. For this reason, we have explored alternative ways of expanding the number of possible models that can be fitted using the INLA methodology. In this paper, we present a novel approach that combines INLA and Markov chain Monte Carlo (MCMC). The aim is to consider a wider range of models that can be fitted with INLA only when some of the parameters of the model have been fixed. We show how new values of these parameters can be drawn from their posterior by using conditional models fitted with INLA and standard MCMC algorithms, such as Metropolis–Hastings. Hence, this will extend the use of INLA to fit models that can be expressed as a conditional LGM. Also, this new approach can be used to build simpler MCMC samplers for complex models as it allows sampling only on a limited number of parameters in the model. We will demonstrate how our approach can extend the class of models that could benefit from INLA, and how the R-INLA package will ease its implementation. We will go through simple examples of this new approach before we discuss more advanced applications with datasets taken from the relevant literature. In particular, INLA within MCMC will be used to fit models with Laplace priors in a Bayesian Lasso model, imputation of missing covariates in linear models, fitting spatial econometrics models with complex nonlinear terms in the linear predictor and classification of data with mixture models. Furthermore, in some of the examples we could exploit INLA within MCMC to make joint inference on an ensemble of model parameters."
journal_title,Statistics and Computing
article_title,Calibrating covariate informed product partition models
keyword,"['High-dimensional covariate space\xa0', 'Prediction\xa0', 'Covariate-based clustering\xa0', 'Mixture of experts\xa0', 'Random partition models\xa0']"
history,"['2017-10-06', '2016-11-23', '2017-09-22']"
abstract,"Abstract Covariate informed product partition models incorporate the intuitively appealing notion that individuals or units with similar covariate values a priori have a higher probability of co-clustering than those with dissimilar covariate values. These methods have been shown to perform well if the number of covariates is relatively small. However, as the number of covariates increase, their influence on partition probabilities overwhelm any information the response may provide in clustering and often encourage partitions with either a large number of singleton clusters or one large cluster resulting in poor model fit and poor out-of-sample prediction. This same phenomenon is observed in Bayesian nonparametric regression methods that induce a conditional distribution for the response given covariates through a joint model. In light of this, we propose two methods that calibrate the covariate-dependent partition model by capping the influence that covariates have on partition probabilities. We demonstrate the new methods’ utility using simulation and two publicly available datasets."
journal_title,Statistics and Computing
article_title,Multiple change points detection and clustering in dynamic networks
keyword,"['Dynamic networks\xa0', 'Non-homogeneous Poisson point processes\xa0', 'Stochastic block model\xa0', 'Variational EM\xa0', 'PELT\xa0']"
history,"['2017-09-26', '2017-01-09', '2017-09-12']"
abstract,"Abstract The increasing amount of data stored in the form of dynamic interactions between actors necessitates the use of methodologies to automatically extract relevant information. The interactions can be represented by dynamic networks in which most existing methods look for clusters of vertices to summarize the data. In this paper, a new framework is proposed in order to cluster the vertices while detecting change points in the intensities of the interactions. These change points are key in the understanding of the temporal interactions. The model used involves non-homogeneous Poisson point processes with cluster-dependent piecewise constant intensity functions and common discontinuity points. A variational expectation maximization algorithm is derived for inference. We show that the pruned exact linear time method, originally developed for change points detection in univariate time series, can be considered for the maximization step. This allows the detection of both the number of change points and their location. Experiments on artificial and real datasets are carried out, and the proposed approach is compared with related methods."
journal_title,Statistics and Computing
article_title,Erratum to: Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC
keyword,[]
history,"['2017-09', '2016-10-18']"
abstract,None
journal_title,Statistics and Computing
article_title,Approximate computations for binary Markov random fields and their use in Bayesian models
keyword,"['Approximate inference\xa0', 'Bayesian analysis\xa0', 'Discrete Markov random fields\xa0', 'Image analysis\xa0', 'Pseudo-Boolean functions\xa0', 'Spatial data\xa0', 'Variable elimination algorithm\xa0']"
history,"['2017-09', '2016-08-29', '2015-04-08', '2016-07-12']"
abstract,"Abstract Discrete Markov random fields form a natural class of models to represent images and spatial datasets. The use of such models is, however, hampered by a computationally intractable normalising constant. This makes parameter estimation and a fully Bayesian treatment of discrete Markov random fields difficult. We apply approximation theory for pseudo-Boolean functions to binary Markov random fields and construct approximations and upper and lower bounds for the associated computationally intractable normalising constant. As a by-product of this process we also get a partially ordered Markov model approximation of the binary Markov random field. We present numerical examples with both the pairwise interaction Ising model and with higher-order interaction models, showing the quality of our approximations and bounds. We also present simulation examples and one real data example demonstrating how the approximations and bounds can be applied for parameter estimation and to handle a fully Bayesian model computationally."
journal_title,Statistics and Computing
article_title,Multiscale local polynomial decompositions using bandwidths as scales
keyword,"['Local polynomial\xa0', 'Wavelet\xa0', 'Multiscale\xa0', 'Sparsity\xa0']"
history,"['2017-09', '2016-08-20', '2016-04-29', '2016-08-11']"
abstract,"Abstract The multiscale local polynomial transform, developped in this paper, combines the benefits from local polynomial smoothing with sparse multiscale decompositions. The contribution of the paper is twofold. First, it focusses on the bandwidths used throughout the transform. These bandwidths operate as user controlled scales in a multiscale analysis, which is explained to be of particular interest in the case of nonequispaced data. The paper presents both a likelihood based optimal bandwidth selection and a fast, heuristic approach. The second contribution of the paper is the combination of local polynomial smoothing with orthogonal prefilters, similar to Daubechies’ wavelet filters, but defined on irregularly spaced covariate values."
journal_title,Statistics and Computing
article_title,Quasi-random numbers for copula models
keyword,"['Quasi-random numbers\xa0', 'Copulas\xa0', 'Conditional distribution method\xa0', 'Marshall–Olkin algorithm\xa0', 'Tail events\xa0', 'Risk measures\xa0', '62H99\xa0', '65C60\xa0']"
history,"['2017-09', '2016-08-05', '2015-09-11', '2016-07-23']"
abstract,"Abstract The present work addresses the question how sampling algorithms for commonly applied copula models can be adapted to account for quasi-random numbers. Besides sampling methods such as the conditional distribution method (based on a one-to-one transformation), it is also shown that typically faster sampling methods (based on stochastic representations) can be used to improve upon classical Monte Carlo methods when pseudo-random number generators are replaced by quasi-random number generators. This opens the door to quasi-random numbers for models well beyond independent margins or the multivariate normal distribution. Detailed examples (in the context of finance and insurance), illustrations and simulations are given and software has been developed and provided in the R packages copula and qrng."
journal_title,Statistics and Computing
article_title,"Multiple Monte Carlo testing, with applications in spatial point processes"
keyword,"['Boolean model test\xa0', 'Envelope test\xa0', 'Extreme rank ordering\xa0', 'Goodness-of-fit test\xa0', 'Multi-type point process\xa0', 'Rank envelope test\xa0', 'Superposition hypothesis\xa0', '62G10\xa0', '62H15\xa0']"
history,"['2017-09', '2016-07-21', '2015-08-07', '2016-07-04']"
abstract,"Abstract The rank envelope test (Myllymäki et al. in J R Stat Soc B, doi: 10.1111/rssb.12172, 2016) is proposed as a solution to the multiple testing problem for Monte Carlo tests. Three different situations are recognized: (1) a few univariate Monte Carlo tests, (2) a Monte Carlo test with a function as the test statistic, (3) several Monte Carlo tests with functions as test statistics. The rank test has correct (global) type I error in each case and it is accompanied with a p-value and with a graphical interpretation which determines subtests and distances of the used test function(s) which lead to the rejection at the prescribed significance level of the test. Examples of null hypotheses from point process and random set statistics are used to demonstrate the strength of the rank envelope test. The examples include goodness-of-fit test with several test functions, goodness-of-fit test for a group of point patterns, test of dependence of components in a multi-type point pattern, and test of the Boolean assumption for random closed sets. A power comparison to the classical multiple testing procedures is given."
journal_title,Statistics and Computing
article_title,ABC Shadow algorithm: a tool for statistical analysis of spatial patterns
keyword,"['Approximate Bayesian computation\xa0', 'Computational methods in Markov chains\xa0', 'Maximum likelihood estimation\xa0', 'Point processes\xa0', 'Spatial pattern analysis\xa0']"
history,"['2017-09', '2016-07-12', '2015-08-31', '2016-06-29']"
abstract,"Abstract This paper presents an original ABC algorithm, ABC Shadow, that can be applied to sample posterior densities that are continuously differentiable. The proposed algorithm solves the main condition to be fulfilled by any ABC algorithm, in order to be useful in practice. This condition requires enough samples in the parameter space region, induced by the observed statistics. The algorithm is tuned on the posterior of a Gaussian model which is entirely known, and then, it is applied for the statistical analysis of several spatial patterns. These patterns are issued or assumed to be outcomes of point processes. The considered models are: Strauss, Candy and area-interaction."
journal_title,Statistics and Computing
article_title,Multi-dimensional functional principal component analysis
keyword,"['Fast Fourier transform\xa0', 'Functional and longitudinal data\xa0', 'GPU-parallelization\xa0', 'Local linear smoother\xa0', 'PM 2.5 data\xa0', 'Random projection\xa0']"
history,"['2017-09', '2016-06-29', '2015-11-01', '2016-06-18']"
abstract,"Abstract Functional principal component analysis is one of the most commonly employed approaches in functional and longitudinal data analysis and we extend it to analyze functional/longitudinal data observed on a general d-dimensional domain. The computational issues emerging in the extension are fully addressed with our proposed solutions. The local linear smoothing technique is employed to perform estimation because of its capabilities of performing large-scale smoothing and of handling data with different sampling schemes (possibly on irregular domain) in addition to its nice theoretical properties. Besides taking the fast Fourier transform strategy in smoothing, the modern GPGPU (general-purpose computing on graphics processing units) architecture is applied to perform parallel computation to save computation time. To resolve the out-of-memory issue due to large-scale data, the random projection procedure is applied in the eigendecomposition step. We show that the proposed estimators can achieve the classical nonparametric rates for longitudinal data and the optimal convergence rates for functional data if the number of observations per sample is of the order \((n/ \log n)^{d/4}\). Finally, the performance of our approach is demonstrated with simulation studies and the fine particulate matter (PM 2.5) data measured in Taiwan."
journal_title,Statistics and Computing
article_title,Exact Bayesian inference for off-line change-point detection in tree-structured graphical models
keyword,"['Change-point detection\xa0', 'Exact Bayesian inference\xa0', 'Graphical model\xa0', 'Multivariate time-series\xa0', 'Spanning tree\xa0']"
history,"['2017-09', '2016-08-11', '2016-03-25', '2016-07-30']"
abstract,"Abstract We consider the problem of change-point detection in multivariate time-series. The multivariate distribution of the observations is supposed to follow a graphical model, whose graph and parameters are affected by abrupt changes throughout time. We demonstrate that it is possible to perform exact Bayesian inference whenever one considers a simple class of undirected graphs called spanning trees as possible structures. We are then able to integrate on the graph and segmentation spaces at the same time by combining classical dynamic programming with algebraic results pertaining to spanning trees. In particular, we show that quantities such as posterior distributions for change-points or posterior edge probabilities over time can efficiently be obtained. We illustrate our results on both synthetic and experimental data arising from biology and neuroscience."
journal_title,International Journal of Automotive Technology
article_title,Design Optimization of the Cowl Cross Bar - Light Cowl Cross Bar Satisfying 5 Performances -
keyword,"['Cowl cross bar\xa0', 'Cross car beam\xa0', 'NVH\xa0', 'Crash\xa0', 'Durability\xa0', 'Steering response\xa0', 'Topology\xa0']"
history,"['2018-06', '2018-04-06', '2017-10-13', '2017-11-28', '2017-11-28']"
abstract,"Abstract Nowadays, more lightweight designs is the key goal of all major automotive industries. One of the main sections for more lightweight automotive area is the Cowl cross bar (CCB) assemblies. A cowl cross bar supports a steering system, airbag module, audio, instrument panel and air conditioning system. The CCB integrates these components into the cockpit module and connects to the body. So the CCB must meet the 5 performance requirements, ① NVH requirement to minimize the vibration, ② Crash performance for less deflection, ③ Steering response requirement for steer predictability, ④ Durability performance like the fatigue life and ⑤ Supporting rigidity for the components. In this study, a new methodology for the optimum CCB design is proposed to obtain a more lightweight design considering 5 targeted requirements. At first, for NVH and Steering response performance, 3-steps of optimization was fulfilled in sequence of (1) Size optimization and mounting position, (2) Case studies about the various types of brackets and (3) Shape optimization using the topology. The proposed design and optimization framework was verified whether it could meet the crash, durability and stiffness requirements. The final optimal CCB would be applied to the new platforms of the Hyundai-Kia motors."
journal_title,International Journal of Automotive Technology
article_title,Experimental Investigation of Impacts of Injection Timing and Pressure on Combustion and Particulate Matter Emission in a Spray-Guided GDI Engine
keyword,"['GDI engine\xa0', 'Injection timing\xa0', 'Injection pressure\xa0', 'Combustion\xa0', 'Particulate matter\xa0']"
history,"['2018-06', '2018-04-06', '2017-06-09', '2017-09-04', '2017-09-22']"
abstract,"Abstract A detailed investigation of the impact of injection timing and injection pressure on combustion and particles of a spray-guided GDI engine was conducted, under different engine operating conditions. The results indicated that, more proportion of large particles were emitted when increasing engine load, and the peak of accumulation mode particles moved toward smaller size when rising engine speed. With retarding the injection timing, the in-cylinder pressure and heat release rate rose first and then dropped at 2000 rpm, but they continuously rose at lower or higher speed conditions. The total particles concentration curves at all cases showed a trend of U-shape, and the corresponding timing of the lowest particles concentration advanced as the engine speed or load increased. The minimum value of emitted particles first rose and then fell when increasing load at 2000 rpm conditions, and it continuously rose when increasing speed at 40 Nm conditions. Generally, injection pressure did no sensitively affect combustion process except that it showed a relatively strong impact at low load conditions. However, particulate matter could be effectively inhibited by elevating fuel pressure from 5.5 to 11.5 MPa at all cases. In detail, the total particles concentration continuously fell at low speed and mid speed-high load cases, but it showed a rose trend when further increase fuel injection pressure at mid speed-low load and high-speed conditions."
journal_title,International Journal of Automotive Technology
article_title,Wet Single Clutch Engagement Behaviors in the Dual-Clutch Transmission System
keyword,"['Wet clutch engagement\xa0', 'Dual clutch\xa0', 'Shudder\xa0', 'Torque transfer\xa0', 'Modified Reynolds equation\xa0']"
history,"['2018-06', '2018-04-06', '2017-06-23', '2017-09-22', '2017-11-08']"
abstract,"Abstract A frictional torque was generated by a lubricated slip contact between a wet clutch pad and a steel separator during a wet clutch engagement. It is necessary to understand the generation of frictional torque to improve the performance of the frictional torque transfer and the durability of the wet clutch system. The analytical modeling of wet clutch torque transfer considers the effects of surface roughness, permeability, the elastic modulus of the frictional material, lubricant viscosity, temperature, etc. Experimental apparatus for wet clutch engagement was designed for the measurement of frictional torque transfer during wet clutch engagement. The experimental results were compared with the analytical results under various operational conditions for the verification of the theoretical analysis to evaluate the performance of the wet clutch system. Some correlations were investigated between the experimental and analytical results. We found that computation by analytical modeling can predict the effects of oil temperature, applied force, and slip speed, as well as engagement period and frictional torque transfer shapes."
journal_title,International Journal of Automotive Technology
article_title,Sequential Approximate Optimization of MacPherson Strut Suspension for Minimizing Side Load by Using Progressive Meta-Model Method
keyword,"['MacPherson strut suspension\xa0', 'Side load\xa0', 'Flexible multi-body dynamics\xa0', 'Progressive meta-model\xa0', 'Radial basis function\xa0']"
history,"['2018-06', '2018-04-06', '2017-06-12', '2017-09-27', '2017-11-07']"
abstract,"Abstract In a MacPherson strut suspension, the side load is inevitably generated and it causes friction at the damper reducing riding comfort. In this paper, to solve this problem, progressive meta-model based sequential approximate optimization (SAO) is performed to minimize the side load. To calculate the side load, a wheel travel analysis is performed by using flexible multi-body dynamics (FMBD) model of suspension, which can consider both finite element method (FEM) and multi-body dynamics (MBD). In the optimal design process, meta-model is generated by using extracted sampling points and radial basis function (RBF) method. As a result of optimal design, spring setting positions that minimize the side load are obtained and by using optimal spring setting positions, the suspension FMBD model was constructed."
journal_title,International Journal of Automotive Technology
article_title,Injection Characteristics of Palm Methyl Ester Blended with Diesel Using Zuech’s Chamber
keyword,"['Palm methyl ester\xa0', 'Injection characteristics\xa0', 'Injector diameter\xa0', 'Injector pressure\xa0', 'Zuench’s chamber\xa0']"
history,"['2018-06', '2018-04-06', '2017-08-01', '2017-09-25', '2017-10-12']"
abstract,"Abstract This research attempts to characterize the injection of palm biodiesel blended with diesel in a Zuech’s chamber. Thailand conventional diesel (mandated blend of biodiesel at 5 % or B5), palm biodiesel (B100) and four other biodiesel blends ratios (B20, B40, B60 and B80) were investigated with single hole injector of 140 and 200 μm diameters, injection pressure of 40 MPa to 160 MPa, constant back pressure of 4.5 MPa and energize time of 2.5 ms. The results show that increasing biodiesel blending ratios leads to longer injection delay, larger injection pressure drop, smaller injection quantity discharge coefficient (Cd) and shorter injection duration. With increasing biodiesel blending ratio, high Cavitation number from biodiesel viscosity decreases Reynolds number. Increasing injector diameter from 140 μm to 200 μm has reduced injection delay, increased fuel injection quantity, discharge coefficient and remaining injection duration. The increasing of injection pressure were improve, injection delay, injection duration, injection quantity and discharge coefficient until injection pressure 120 MPa. In addition at injection pressure over 120 MPa are decrease injection quantity and discharge coefficient, it effect form the cavitation phenomena. Increasing of viscosity, density, Bulk modulus and sound velocity were effect to increase injection delay, with reduce injection quantity, injection duration and pressure drop during injection process."
journal_title,International Journal of Automotive Technology
article_title,Transient Dynamic Characteristics of a Non-Pneumatic Mechanical Elastic Wheel Rolling Over a Ditch
keyword,"['Non-pneumatic wheel\xa0', 'Mechanical elastic wheel\xa0', 'Transient dynamic characteristic\xa0', 'Explicit finite element analysis\xa0']"
history,"['2018-06', '2018-04-06', '2017-08-02', '2017-11-11', '2017-11-16']"
abstract,"Abstract The transient dynamic characteristic of a tire, which has a significant effect on vehicle handling stability and ride comfort, is difficult to study in detail because of its highly non-linear behavior. In this study, the transient dynamic characteristics of a non-pneumatic wheel, called the mechanical elastic wheel (MEW), which was rolling over a ditch were investigated by the explicit dynamic finite element (FE) method. A three-dimensional FE model of MEW considering geometric nonlinearity, material nonlinearity and large contact deformation between the wheel and the road, was established. For the validation of the accuracy and reliability of the FE model of MEW, the simulation and the experimental results of the radial stiffness and footprint of MEW were compared and analyzed. A dynamic simulation of the validated FE model of MEW rolling over a ditch was conducted using the ABAQUS/Explicit program. The equivalent stress and the contact stress generated during the process of the rolling MEW impacting the ditch were studied in detail. The effect of the rolling speed on the transient dynamic characteristics was also analyzed based on the simulation results. The simulation results could provide guidance for the optimization of the MEW structure and vehicle dynamics."
journal_title,International Journal of Automotive Technology
article_title,Iterative Learning Control Algorithm for Feedforward Controller of EGR and VGT Systems in a CRDI Diesel Engine
keyword,"['Diesel engine control\xa0', 'Learning control\xa0', 'EGR\xa0', 'VGT\xa0', 'Iterative learning control\xa0', 'Transient control\xa0']"
history,"['2018-06', '2018-04-06', '2017-09-22', '2017-11-04', '2017-11-14']"
abstract,"Abstract The modern diesel engines equip the exhaust gas recirculation (EGR) system to suppress the NOx emissions. In addition, the variable geometric turbocharger (VGT) system is installed to improve the drivability and fuel efficiency. These EGR and VGT systems have cross-coupled behavior because they interact with the intake and the exhaust manifolds. Furthermore, the turbocharger time delay, gas flow dynamics through EGR pipe cause the nonlinearity characteristics. These nonlinear multi-input-multi-output characteristics cause the degradation of control accuracy, especially during the transient condition. In order to improve the control accuracy, this study proposes an iterative learning control (ILC) algorithm for feedforward controller of EGR and VGT systems. The feedforward controller obtains the values about EGR and VGT actuators using the previous control results in predefined transient states. The ILC algorithm consists of a PD-type learning function and a low-pass filter. The control gains of learning function are determined to guarantee the convergence of learning results. In addition, the low-pass filter is designed for robustness against plant disturbance. The proposed control algorithm was validated by engine experiment which repeated predefined transient states. The error was reduced by 15 % according to the gain. As a result, the proposed algorithm is affordable for improving the transient control performance."
journal_title,International Journal of Automotive Technology
article_title,Nonlinear Model-Based Multivariable Control for Air & Charging System of Diesel Engine with Short and Long Route EGR Valves
keyword,"['Model-based\xa0', 'Control\xa0', 'Multivariable\xa0', 'Air charge\xa0', 'Feedback linearization\xa0']"
history,"['2018-06', '2018-04-06', '2017-01-23', '2017-08-30', '2017-10-16']"
abstract,"Abstract The objective of this study is to investigate a nonlinear model-based multivariable (MIMO, Multi Input Multi Output) technique to decouple actuators interaction and to reduce the calibration effort, while increasing control performances, above all in transient conditions, and robustness with respect to model uncertainties and system parameter variations. The presented control technique is based on the development of a nonlinear dynamical physical model of the diesel air and charging system. Feedback Linearization control is then applied to decouple actuators’ interactions and compensate for nonlinearities. A new set of virtual inputs are defined inverting the system differential equations. Relation among the new virtual inputs and the outputs is purely linear and decoupled, meaning that each virtual input affects linearly only one output. Moreover, a linear control block is added to guarantee transient and steady state performances and closed loop robustness. The proposed control approach has been validated through small diesel engine dyno and vehicle activities. Transient test bench maneuvers show that the control is able to coordinate the actuators in order to fulfill the targets and to guarantee similar performances in different operating points. In addition the robustness to environmental changes has been demonstrated by vehicle tests at different ambient conditions."
journal_title,International Journal of Automotive Technology
article_title,Morphological Change and Number-Size Distributions of Particulate Matter (PM) from a Diesel Generator Operated with Wood Pyrolysis Oil-Butanol Blended Fuel
keyword,"['Wood Pyrolysis Oil (WPO)\xa0', 'n-butanol\xa0', 'Blended fuel\xa0', 'Diesel generator\xa0', 'Exhaust particles\xa0', 'Morphology analysis\xa0']"
history,"['2018-06', '2018-04-06', '2017-06-14', '2017-08-15', '2017-10-24']"
abstract,"Abstract This report details our experimental study investigating particulate matter (PM) emissions from a diesel generator fueled with wood pyrolysis oil (WPO)–butanol blended fuel for electricity generation. Particle number-size distributions and PM mass concentrations from diesel, n-butanol, and WPO-butanol blended fuels were investigated via aerosol measurements using a fast mobility particle sizer and an aerosol monitor with three generator outputs (0, 3.3, and 6.6 kWe). For the n-butanol and WPO-blended fuels, the total number concentrations of exhaust particles were higher than that of conventional diesel combustion; however, the PM mass was observed to be nearly zero for all the engine operating conditions due to the higher number concentration in the nuclei mode. The morphology of the exhaust particles was investigated by analyzing transmission electron microscopy (TEM) micrographs. The morphology of the particles was drastically changed according to the test fuels and engine loads. Two types of particles were observed, including soot and coke shaped particles. These results were directly related to the immaturity of incipient soot particles due to the different physical properties and chemical compositions of the fuels."
journal_title,International Journal of Automotive Technology
article_title,Dynamics Analysis of Torsional Vibration Induced by Clutch and Gear Set in Automatic Transmission
keyword,"['Powertrain\xa0', 'Transmission\xa0', 'Planetary gear backlash\xa0', 'Clutch engagement\xa0']"
history,"['2018-06', '2018-04-06', '2017-03-14', '2017-06-29', '2017-07-22']"
abstract,"Abstract The torsional vibration generated during clutch engagement directly affects the shifting quality of automatic transmissions, where the noise source stems from both the clutch and the gear set. To predict the dynamical response and driveline oscillation, a comprehensive mathematical model of the vehicle powertrain equipped with automatic transmission is developed with consideration of nonlinearities in the clutch and the planetary gear set. For the clutch, the dynamics of stickslip is described for the transition between the slipping to locked states. The gear backlash model is used to analyze the rattle noise of the planetary gear set. Based on extensive powertrain simulations for the clutch engagement process, the magnitude of vibration propagation in the driveline are predicted to identify the primary factors of noise generation."
journal_title,International Journal of Automotive Technology
article_title,Vehicle Dynamic Control for In-Wheel Electric Vehicles Via Temperature Consideration of Braking Systems
keyword,"['In-wheel electric vehicle\xa0', 'Vehicle dynamic control\xa0', 'Friction braking system\xa0', 'In-wheel motor\xa0']"
history,"['2018-06', '2018-04-06', '2017-05-11', '2017-09-11', '2017-09-24']"
abstract,"Abstract −Vehicle dynamic control (VDC) systems play an important role with regard to vehicle stability and safety when turning. VDC systems prevent vehicles from spinning or slipping when cornering sharply by controlling vehicle yaw moment, which is generated by braking forces. Thus, it is important to control braking forces depending on the driving conditions of the vehicle. The required yaw moment to stabilize a vehicle is calculated through optimal control and a combination of braking forces used to generate the calculated yaw moment. However, braking forces can change due to frictional coefficients being affected by variations in temperature. This can cause vehicles to experience stability problems due an improper yaw moment being applied to the vehicle. In this paper, a brake temperature estimator based on the finite different method (FDM) was proposed with a friction coefficient estimator in order to solve this problem. The developed braking characteristic estimation model was used to develop a VDC cooperative control algorithm using hydraulic braking and the regenerative braking of an in-wheel motor. Performance simulations of the developed cooperative control algorithm were performed through cosimulation with MATLAB/Simulink and CarSim. From the simulation results, it was verified that vehicle stability was ensured despite any changes in the braking characteristics due to brake temperatures."
journal_title,International Journal of Automotive Technology
article_title,Performance Evaluation of Ball CVT and Comparison with Half Toroidal CVT
keyword,"['Ball CVT\xa0', 'Half toroidal CVT\xa0', 'Traction\xa0', 'Efficiency\xa0', 'Spin loss\xa0']"
history,"['2018-06', '2018-04-06', '2017-09-26', '2017-10-30', '2017-11-01']"
abstract,"Abstract This study aims at finding an analytical model of ball continuously variable transmission (B-CVT) behavior and performance, based on the existing model of the half-toroidal traction drive. The geometrical and kinematical aspects of this model have been found. Then, force-moment equilibrium equations have been applied for a B-CVT. The contact behavior has been modeled using the isothermal elastohydrodynamic lubrication (EHL) theory, and spin and relative slip losses have been estimated for this CVT. Finally, the overall efficiencies of the B-CVT have been analyzed and compared with the halftoroidal traction drive. This study results have shown that B-CVT has higher torque efficiency and lower speed efficiency in comparison with half-toroidal CVT. Also, it has shown that the adjustment of axial forces in B-CVT leads to higher efficiency in lower input torques."
journal_title,International Journal of Automotive Technology
article_title,Slope Shift Strategy for Automatic Transmission Vehicles Based on the Road Gradient
keyword,"['Automatic transmission vehicle\xa0', 'Vehicle dynamics\xa0', 'Shift problems on hilly roads\xa0', 'Intelligent shift strategy on slopes\xa0', 'Simulation analysis\xa0']"
history,"['2018-06', '2018-04-06', '2017-07-31', '2017-10-24', '2017-11-24']"
abstract,"Abstract Motivated by the development of high-precision digital maps for advanced driver assistance system (ADAS) in recent years, this study provides a new approach to solve the problems of the conventional automatic transmission vehicle travelling on sloping roads. Based on vehicle dynamics, shift problems on hilly roads are analyzed. A novel intelligent shift strategy is proposed, which consists of a dynamic shift schedule for the uphill, a safety shift schedule for the downhill, and a comprehensive economical shift schedule for the gentle slopes. A set of driver-in-loop co-simulation tests was conducted in a driving simulator that is equipped with a MATLAB/Simulink dynamics simulation platform. The test results verified the effectiveness of the new intelligent shift strategy. With the road information provided by a high-precision digital map, busy shifting can be eliminated, and improved dynamic performance can be achieved for a vehicle travelling on the uphill roads; undesired upshift can be prevented, and engine traction resistance can be used to relieve the load of braking system when a vehicle travelling on the downhill roads; also, fuel consumption can be reduced for a vehicle travelling on a gently sloped road. Consequently, this novel intelligent shift strategy offers a reliable and effective solution for improving a vehicle’s driving performance on a hilly road."
journal_title,International Journal of Automotive Technology
article_title,Load and Load Dependent Friction Identification and Compensation of Electronic Non-Circular Gear Brake System
keyword,"['Load dependent friction\xa0', 'Friction model identification\xa0', 'EMB\xa0', 'Electronic non-circular gear brake\xa0']"
history,"['2018-06', '2018-04-06', '2016-11-16', '2017-04-05', '2017-05-31']"
abstract,"Abstract Control of the electronic non-circular gear brake (ENGB) involves challenges, including the non-linear variation of loads and the effect of friction, which is dependent upon load. The controller must be designed based on modelling information in order to enhance control performance. This study performed model identification of the ENGB system using a DOB-based model identification method. By employing the nearest neighbor search method, the even-odd disturbance was separated without the influence of hysteresis even in situations with low control precision. The accuracy of the resulting ENGB system model was validated through experiments. The self-energizing effect due to friction between the brake disc and pad within the mechanical system was also validated."
journal_title,International Journal of Automotive Technology
article_title,Development of Headform Impactor Finite Element Model Considering the Hyperelastic and Viscoelastic Responses of Rubber
keyword,"['HIC (Head Injury Criteria)\xa0', 'Headform impactor\xa0', 'Rubber modeling\xa0', 'Hyperelasticity\xa0', 'Viscoelasticity\xa0']"
history,"['2018-06', '2018-04-06', '2017-02-13', '2017-07-19', '2017-12-14']"
abstract,"Abstract To evaluate and analyze the pedestrian injury risk of automobiles, the finite element models of headform impactors are used. In this study, a modeling method that can accurately estimate the peak of the headform impactor impact pulse and head injury criterion (HIC) was developed. The headform impactor skin has the characteristics of both hyperelasticity and viscoelasticity. Therefore, compression tests, stress relaxation tests, and rheometer tests were conducted, and the hyperelastic and viscoelastic models were developed. The models were combined and used in the finite element analysis. The new headform impactor model was verified to accurately estimate the peak of impact pulse and HIC at the certification test of the headform impactor."
journal_title,International Journal of Automotive Technology
article_title,Carbon Deposit Incineration During Engine Flameout Using Non-Thermal Plasma Injection
keyword,"['Diesel particulate filter\xa0', 'Exhaust waste heat\xa0', 'Carbon deposition\xa0', 'Regeneration\xa0', 'Non-thermal plasma\xa0', 'Heat durability\xa0']"
history,"['2018-06', '2018-04-06', '2017-08-28', '2017-11-03', '2017-11-06']"
abstract,"Abstract In order to investigate the influence of initial regeneration temperatures on diesel particulate filter (DPF) regeneration, an experimental study of DPF regeneration was implemented using a dielectric barrier discharge (DBD) reactor, aided by exhaust waste heat after engine flameout. DPF trapping characteristics and carbon deposit mass were discussed to facilitate further data analysis and calculation. DPF regeneration was then investigated by comparison analysis of deposit removal mass, backpressure drop, and internal temperature change. The results revealed that a large amount of particulate matter (PM) was deposited in DPF with a high filtration efficiency of about 90 %. The deposit removal rate and percentage drop of the backpressure both maximized at the initial temperature of 100 °C. During DPF regeneration, the sharp rise of internal temperature indicated vigorous PM incineration and high CO2 emission. The results successfully demonstrated DPF regeneration using non-thermal plasma injection during engine flameout, and prominent heat durability was achieved in this method."
journal_title,International Journal of Automotive Technology
article_title,Development of the Lane Keeping Control System Using State-Varying Surface for Vulnerable Road Users
keyword,"['Lane Keeping Assist (LKA)\xa0', 'Integrated control\xa0', 'Fuzzy model\xa0', 'Sliding Mode Control (SMC)\xa0', 'Active Front Steering (AFS)\xa0', 'Brake Torque Vectoring (BTV)\xa0']"
history,"['2018-06', '2018-04-06', '2017-07-03', '2017-09-27', '2017-09-27']"
abstract,"Abstract This paper proposes a new Lane Keeping Assist (LKA) system based on the integrated control strategy with AFS and BTV. To be specific, the steering controller calculates the gear ratio of AFS to align with the target lane whereas the braking controller determines differential brake pressure using Sliding Mode Control (SMC) theory according to the state-varying sliding surface with Fuzzy model. In recent years, auto industries have produced the lane keeping applications to prevent lane departure caused by drivers’ distractions or drowsiness. To also prevent wrist injury in drivers while steering, current LKA systems limit the output values of steering-wheel assist torque. This limiting mechanism, however, can cause a problem that cannot follow a road curvature when an older driver overexerts an inappropriate control effort. A new LKA system of the AFS and BTV integrated controller has since been drafted to solve this problem, and validated its performance in regards to the test conditions given with various driver models."
journal_title,International Journal of Automotive Technology
article_title,From Offline to Adaptive Online Energy Management Strategy of Hybrid Vehicle Using Pontryagin’s Minimum Principle
keyword,"['Optimal control\xa0', 'Heavy hybrid vehicle\xa0', 'Energy management\xa0', 'Pontryagin’s minimum principle\xa0']"
history,"['2018-06', '2018-04-06', '2017-04-25', '2017-08-25', '2017-09-30']"
abstract,"Abstract This paper details the development of an energy management strategy (EMS) for real-time control of a multi hybrid plug-in electric bus. The energy management problem has been formulated as an optimal control problem in order to minimize the fuel consumption of the bus drivetrain for a typical day of operation. Considering the physical characteristics of the studied hybrid electric bus and its well-known daily tour, the Pontryagin’s minimum principle (PMP) is firstly used as the mean to obtain offline optimal EMS. Afterward, in order to adapt the proposed strategy for real-time implementation, the proposed control parameters are adapted online using feedback from the battery state of energy (SOE) which allows us to accurately control the battery SOE in the presence of wide range of uncertainties. The work proposed in this paper is conducted on a dedicated high-fidelity dynamical model of the hybrid bus, that was developed on MATLAB/TruckMaker software. The performance evaluation of the proposed strategy is carried out using a normalized driving cycles to represent different driving scenarios. Obtained results show that among the investigated methods, it is reasonable to conclude that the proposed adaptive online strategy based on PMP is the most suitable to design the targeted EMS."
journal_title,International Journal of Automotive Technology
article_title,Lateral Collision Avoidance Robust Control of Electric Vehicles Combining a Lane-Changing Model Based on Vehicle Edge Turning Trajectory and a Vehicle Semi-Uncertainty Dynamic Model
keyword,"['Lateral Collision Avoidance (CA) system\xa0', 'Lane-changing model\xa0', 'Semi-Uncertainty Dynamic Model (SUDM)\xa0', 'Vehicle Edge Turning Trajectory (VETT)\xa0']"
history,"['2018-04', '2018-02-27', '2016-05-09', '2017-05-13', '2017-10-29']"
abstract,"Abstract This paper presents a new control scheme for lateral collision avoidance (CA) systems to improve the safety of four-in-wheel-motor-driven electric vehicles (FIWMD-EVs). There are two major contributions in the design of lateral CA systems. The first contribution is a new lane-changing model based on vehicle edge turning trajectory (VETT) to make vehicle adapt to different driving roads and conform to drivers’ characteristic, in addition to ensure vehicle steering safety. The second contribution is vehicle semi-uncertainty dynamic model (SUDM), which is SISO model. The problem of stability performance without the information on sideslip angle is solved by the proposed SUDM. Based on the proposed VETT and SUDM, the lateral CA system can be designed with H∞ robust controller to restrain the effect of uncertainties resulting from parameter perturbation and lateral wind disturbance. Single and mixed driving cycles simulation experiments are carried out with CarSim to demonstrate the effectiveness in control scheme, simplicity in structure for lateral CA system based on the proposed VETT and SUDM."
journal_title,International Journal of Automotive Technology
article_title,Mean Value WGT Diesel Engine Calibration Model for Effective Simulation Research
keyword,"['Waste Gate Turbocharger (WGT)\xa0', 'Diesel engine\xa0', 'Engine calibration\xa0', 'Mean value model\xa0', 'Exhaust Gas Recirculation (EGR)\xa0', 'Fuel consumption\xa0']"
history,"['2018-04', '2018-02-27', '2016-10-20', '2017-08-17', '2017-09-29']"
abstract,"Abstract Recently, to improve vehicle fuel economy, as well as the performance of internal combustion engines, optimized system matching between a vehicle’s drivetrain and engine has become a very important technical issue. For this reason, the need for simulation research on engine and vehicle performance improvement has increased. But in general, since both engine simulation and vehicle simulation require initial engine calibration map input, a simple engine calibration method is required for the efficient configuration of various virtual engine calibration map setups. On this background, in this study, an example of waste gate turbocharger (WGT) cooled — exhaust gas recirculation (EGR) Diesel engine calibration using a test-based mean value engine model is presented as a suitable engine calibration map setting method. Also, the feasibility of an engine calibration model is confirmed through various engine tests. Using the simple model presented here, it is possible for diverse engine operating conditions and engine performance maps to be acquired."
journal_title,International Journal of Automotive Technology
article_title,Design Optimization of a Rear Independent Suspension for the Korean Light Tactical Vehicle
keyword,"['Tactical vehicle\xa0', 'Independent suspension\xa0', 'Kriging model\xa0', 'CMA-ES\xa0', 'Durability\xa0']"
history,"['2018-04', '2018-02-27', '2017-04-13', '2017-07-21', '2017-09-05']"
abstract,"Abstract Steering and suspension handle the direction of a vehicle according to the driver’s intentions and control the disturbance from the road surface while supporting the vehicle body. The static and dynamic characteristics of two systems are critical factors for the ride comfort and the directional stability. In the layout stage, the hard points of steering and suspension systems are determined. In the next design stage, the detailed design of the system, including gearboxes, springs, shock absorbers, and control links, is carried out. While the optimal hard points of a suspension are determined at the precedent design, interference with other peripheral components should be carefully examined in the detailed design process. In the case of the design point change should be made to avoid the interference, subsequent position and shape changes of the link mechanism are required. Therefore, there is a need to examine the optimization of suspension compliance characteristics with chassis design changes and the durability performance of the modified design. This study proposes an integrated analysis method for the design optimization and the durability evaluation of such optimized design specifications of the rear independent suspension for a military vehicle."
journal_title,International Journal of Automotive Technology
article_title,Investigation of Occupant Lower Extremity Injures under Various Overlap Frontal Crashes
keyword,"['Lower extremity\xa0', 'Axial force\xa0', 'Bending moment\xa0', 'Frontal crash\xa0', 'Finite elements\xa0']"
history,"['2018-04', '2018-02-27', '2017-01-05', '2017-08-07', '2017-10-16']"
abstract,"Abstract ObjectiveWith widely usage of restraint system, fatal injuries to occupants have been largely limited while non-fatal lower extremity injuries have not been effectively improved. The present study aims to investigate occupant lower extremity injuries under realistic impact environments.Methods A biofidelic lower extremity model, a dummy model and a car cab model were combined to set up a realistic impact environment. Three typical frontal impact groups were simulated. Occupant global lower kinematics, long bone axial force and bending moment were presented to in-depth investigate lower extremity injury mechanism and tolerance.Results Various overlap frontal impacts cause totally different lower extremity kinematics in the combination of structural invasion and restraint system effects. The femur fracture occurred at a small axial force of 7.57 kN combing a substantial bending moment peak of 172 Nm. Ankle joint injuries were found in 100 % and 25 % overlap impacts that present large tibial axial force and joint rotation angle.Conclusions Overall results indicate that a coupling threshold of femur axial force and bending moment is of rationality to predict global femur fracture. The ankle joint injury occurrence is significantly related to the coupling effects of tibia axial force and excessive self-kinematics."
journal_title,International Journal of Automotive Technology
article_title,Structural Optimization for Roof Crush Test Using an Enforced Displacement Method
keyword,"['Roof crush test\xa0', 'Structural optimization\xa0', 'FMVSS 216\xa0']"
history,"['2018-04', '2018-02-27', '2017-04-03', '2017-06-28', '2017-07-17']"
abstract,"Abstract A roof crush test has been utilized to reduce passengers’ injuries from a vehicle rollover. The Federal Motor Vehicle Safety Standards (FMVSS) 216 and the Insurance Institute for Highway Safety (IIHS) perform actual vehicle tests and evaluate the vehicle’s ratings. Nonlinear dynamic response structural optimization can be employed not only for achievement of a high rating but also minimization of the weight. However, the technique needs a huge computation time and cost because many nonlinear dynamic response analyses are required in the time domain. A novel method is proposed for nonlinear dynamic response structural optimization regarding the roof crush test. The process of the proposed method repeats the analysis domain and the design domain until the convergence criteria are satisfied. In the analysis domain, the roof crush test is simulated using a high fidelity model of nonlinear dynamic finite element analysis. In the design domain, a low fidelity model of linear static response structural optimization is utilized with enforced displacements that come from the analysis domain. Correction factors are employed to compensate the differences between a nonlinear dynamic analysis response and a linear static analysis response with enforced displacement. A full-scale vehicle problem is optimized with a constraint on the rigid wall force from the analysis in the design domain."
journal_title,International Journal of Automotive Technology
article_title,Numerical Analysis of the Mixture Formation in a Two-Stroke Wall-Guided LPG DI Engine for Extended-Range Electric Vehicle
keyword,"['LPG\xa0', 'Extended-range electric vehicle\xa0', 'Two-stroke direct injection engine\xa0', 'Wall-guided combustion system\xa0', 'Numerical simulation\xa0']"
history,"['2018-04', '2018-02-27', '2017-05-12', '2017-07-13', '2017-07-16']"
abstract,"Abstract The use of automotive LPG characteristics which are easy to evaporate vaporization and carry. The paper presents a design of extended-range electric vehicle for wall-guided two stroke LPG engine with direct injection combustion system. Based on the modified vehicle LPG spray model, a database describing the characteristics of vehicle LPG fuel was built and imported into the CFD software. And the accuracy of the model is verified by the Schlieren experimental results. The concentration and velocity field of the mixture in the cylinder under different load conditions are numerically analyzed. The analyzed result indicated that the start injection time θ = 60°–70°CA BTDC under part load condition, the plug electrode near the gathering of a richer mixture is easy to be fired at spark ignition time, the obvious formation of mixture in cylinder is formed and the overall air-fuel ratio is above 40: 1. The start-transition working condition and large load conditions in the piston moves upward before closing the exhaust port to start injection LPG. The optimized LPG injection start time θ ensures that the fresh gas is locked in the cylinder when the exhaust port is closed (63°CA ABDC). In the ignition time of the spark plug, an ideal homogeneous mixture in the cylinder is realized."
journal_title,International Journal of Automotive Technology
article_title,Hierarchical Scheme of Vehicle Detection and Tracking in Nighttime Urban Environment
keyword,"['Vehicle detection\xa0', 'Nighttime vehicle detection\xa0', 'Detection and tracking\xa0', 'Taillight detection\xa0', 'ADAS\xa0']"
history,"['2018-04', '2018-02-27', '2016-12-19', '2017-07-07', '2017-08-10']"
abstract,"Abstract In this paper, we propose a novel hierarchical scheme for detection and tracking of vehicles using a vehicle-mounted camera in nighttime under urban environment, where a vehicle can be represented by a pair of taillights and various types of lights are commonplace. The proposed scheme, therefore, mainly focuses on devising robust detection and pairing of taillights in spite of their inherent diversity and continuous transformation in appearance. Thus the appearance symmetry, which many conventional methods rely on, for paring is not guaranteed to be available all the times. Each of the three layers in the scheme is devised to identify a vehicle from individual lights and clutters detected in a hierarchical manner. Robust detection of a pair of taillights, which can be regarded as a vehicle, is sought by successive groupings of the components in a layer and checking not only the intra-layer but the inter-layer relations between them. A structural Kalman filter is employed to maintain the temporal consistency in the motion of the components and their relations as well. Exploiting such relational information increases accuracy in tracking of individual components by reducing effects from fluctuation in positions and shapes, and eventually compensating possible failures in detection of them. As a result, the proposed scheme achieves enhancement in detection and tracking of vehicles in nighttime as proven by experiments on videos including crowded urban traffic scenes."
journal_title,International Journal of Automotive Technology
article_title,Model Predictive Coordinated Control for Dual-Mode Power-Split Hybrid Electric Vehicle
keyword,"['Hybrid electric vehicle\xa0', 'Coordinated control\xa0', 'Fuel economy\xa0', 'Model predictive control\xa0', 'Fast MPC method\xa0']"
history,"['2018-04', '2018-02-27', '2016-12-23', '2017-08-05', '2017-08-20']"
abstract,"Abstract Power-split hybrid electric vehicles (HEVs) have great potential fuel efficiency and have attracted extensive research attention with regard to their control system. The coordinated controller in HEV plays an important role in tracking the optimal state reference generated by the energy management strategy (EMS), so as to reach the desired fuel efficiency. Meanwhile, the coordinated controller also has a significant impact on driving performance. To improve its performance, the design of a model predictive control (MPC) based coordinated controller in power-split HEV is presented. First, a non-linear, time-varying constrained control oriented transmission model of a dual-mode power-split HEV is formulated to describe this control problem. Then, to solve this problem, the non-linear part in the transmission model is linearised, and a linear MPC is used to obtain the control signals for the motors and engine at each time step. To meet the requirements of real-time computation, a fast MPC method is also applied to reduce the online computation effort. Simulations and experiments demonstrate the effectiveness of the proposed MPC-based coordinated controller."
journal_title,International Journal of Automotive Technology
article_title,Investigation on Spray Behavior and NOx Conversion Characteristic of a Secondary Injector for a Lean NOx Trap Catalyst
keyword,"['Diesel engine\xa0', 'HC-LNT catalyst\xa0', 'After-treatment\xa0', 'Spray behavior\xa0', 'RMS image\xa0', 'Secondary injector\xa0']"
history,"['2018-04', '2018-02-27', '2017-03-24', '2017-05-29', '2017-08-07']"
abstract,"Abstract Lean NOx trap (LNT) catalyst has been used to reduce NOx emissions from diesel engines. The LNT absorbs NOx in lean condition and discharges N2 by reducing NOx in rich conditions. Thus, it is necessary to make exhaust gas lean or rich conditions for controlling LNT system. For making a rich condition, a secondary injector was adopted to inject a diesel fuel into the exhaust pipe. In the case of secondary injector, the behavior of spray is easily affected by high temperature (i.e., 250 ∼ 350 °C) occurred in the exhaust manifold. Therefore, it is needed to investigate the spray behavior of diesel fuel injected into an exhaust manifold, as well as the conversion characteristics for a lean NOx trap of a diesel engine with LNT catalyst. The characteristics of exhaust emissions in NEDC (New European Driving Cycle) mode were analyzed and spray behaviors were visualized in various exhaust gas conditions. The results show that as the exhaust gas mass flow increases, the spray cone angle becomes broad and the fuel is directed to the flow field. Besides, the cone angle of spray is decreased by centrifugal force caused in exhaust gas flow field. In addition, the effects of nozzle installation degree, injection quantity, and exhaust gas flow on NOx conversion performance were clarified."
journal_title,International Journal of Automotive Technology
article_title,Performance Design of an Exhaust Superheater for Waste Heat Recovery of Construction Equipment
keyword,"['Excavator\xa0', 'Construction equipment\xa0', 'Waste heat recovery system\xa0', 'Rankine cycle\xa0', 'Superheater\xa0', 'Heat recovery\xa0', 'Spiral tube\xa0']"
history,"['2018-04', '2018-02-27', '2017-01-10', '2017-08-10', '2017-09-29']"
abstract,"Abstract Although fuel cost has been the largest portion of annual operating costs of construction equipment, it is possible to save the energy and reduce cost using fuel economy enhancement technology. In this study, an organic Rankine cycle is applied to an excavator in order to recover waste heat, reproduce it into electrical energy, and consequently reduce the fuel consumption by 10 %. A design process was carried out to develop an exhaust gas superheater that recovers the waste heat from exhaust gas through a composite-dimensional thermal flow analysis. A one-dimensional code was developed to perform a size design for the exhaust gas superheater. The ranges for the major design parameters were determined to satisfy the target of the heat recovery, as well as the pressure drop at both fluid sides. Performance analysis was done through onedimensional design code results, which were compared with three-dimensional CFD analysis. By utilizing a 3D commercial code, the arrangement of the tubes was selected and the working fluid pressure drop was reduced through a detailed layout design. The design procedure was verified by a performance evaluation of the prototype, which yielded only a 7 % tolerance in heat recovery."
journal_title,International Journal of Automotive Technology
article_title,Modeling of Double Lane Change Maneuver of Vehicles
keyword,"['Driver assistance systems\xa0', 'Lateral vehicle dynamics\xa0', 'Double-lane-change maneuver\xa0', 'ANFIS\xa0']"
history,"['2018-04', '2018-02-27', '2017-04-17', '2017-05-29', '2017-08-06']"
abstract,"Abstract Lane change maneuver is one of most riskiest driving tasks. In order to increase the safety level of the vehicles during this maneuver, design of lane change assist systems which are based on dynamics behavior of driver-vehicle unit is necessary. Therefore, modeling of the maneuver is the first step to design the driver assistance system. In this paper, a novel method for modeling of lateral motion of vehicles in the standard double-lane-change (DLC) maneuver is proposed. A neuro-fuzzy model is suggested consisting of both the vehicle orientation and its lateral position. The inputs of the model are the current orientation, lateral position and steering wheel angle, while the predicted lateral position and orientation of the vehicle are the outputs. The efficiency of the proposed method is verified using both simulation results and experimental tests. The simulation and experimental maneuvers are performed in different velocities. It is shown that the proposed method can effectively reduce the undesirable effects of environmental disturbances and is significantly more accurate in comparisons with the results in the recent available papers. This method can be used to personalize the advanced driver assistance systems."
journal_title,International Journal of Automotive Technology
article_title,Effects of Test Conditions on Fuel Economy of Gasoline-Powered Vehicle
keyword,"['Fuel economy\xa0', 'Battery SOC\xa0', 'Cooling fan\xa0', 'Soaking time\xa0', 'Laboratory temperature\xa0']"
history,"['2018-04', '2018-02-27', '2017-05-23', '2017-08-20', '2017-09-07']"
abstract,"Abstract In this study, the influence on fuel economy testing of gasoline-powered vehicles is evaluated for various test conditions (e.g., laboratory temperature, soaking time, cooling fan, battery charge state, and driving mode tracking). It showed a difference in fuel economy results of approximately 3 % between low (88 %) and high (99 %) battery state of charge conditions because the alternator saving function has a positive effect on fuel economy. Fuel economy testing with laboratory temperature changes gave a slight reduction at 21 °C and slight increase at 29 °C. The cooling fan changes had an almost negligible effect on fuel consumption. The largest fuel economy result varied by 5.2 % in the soft, standard, and rough driving conditions."
journal_title,International Journal of Automotive Technology
article_title,Mixed Harmonic Runnable Scheduling for Automotive Software on Multi-Core Processors
keyword,"['AUTOSAR\xa0', 'Interrupt\xa0', 'Multi-core\xa0', 'Runnable\xa0', 'Scheduling\xa0', 'Load balancing\xa0']"
history,"['2018-04', '2018-02-27', '2016-10-25', '2017-07-06', '2017-08-28']"
abstract,"Abstract The performance of automotive electronic control units (ECUs) has improved following the development of multi-core processors. These processors facilitate fast computing performance without increasing clock speed. System developers partition automotive application runnables to have parallelizability and avoid interference between various software modules. To improve the performance of such systems, an efficient scheduler is necessary. In this regard, for multi-core ECUs, the automotive open system architecture (AUTOSAR) suggests partitioned static priority scheduling for parallelized software. In the AUTOSAR approach, clustering and partitioning of runnables for specific cores becomes difficult, but there is no exact criterion followed for partitioning the runnables. Consequently, cores are not balanced against loads, and under contingency conditions, there is a chance that tasks will miss deadlines. In this study, we address this problem by exploring a mixed harmonic runnable scheduling algorithm that includes partitioned scheduling. We tested this algorithm using high load conditions under contingency consequences, and we evaluated it using models of periodic runnables, periodic interrupts, and event-triggered interrupts. The performance parameters considered in this paper are balancing performance and the deadline missing rate. Our results indicate that the proposed algorithm can contribute toward improving the functional safety of vehicles."
journal_title,International Journal of Automotive Technology
article_title,Real Time Detection and Classification of Arrow Markings in Urban Streets
keyword,"['Arrow markings classification\xa0', 'Urban localization\xa0']"
history,"['2018-04', '2018-02-27', '2016-12-26', '2017-07-08', '2017-09-14']"
abstract,"Abstract For highly automated driving in urban regions it is essential to know the precise position of the car. Furthermore it is important to understand the surrounding context in complex situations, e.g. multilane crossings and turn lanes. To understand those situations there is not only the task to detect the lane border, but to detect the painted information inside the lane. The paper is facing and evaluating two methods to classify this additional lane information. Therefore the images from five cameras mounted around the car are used. Four of them with fisheye lenses. The methods have in common, that the input images are transformed into a bird view projection. First introduced method is to extract contours from the transformed images and collect geometrical features and Fourier coefficients. The second introduced way, is to calculate histograms of oriented gradients and use it as input for the classification step. Both classification approaches are implemented and evaluated as multiclass and single class detectors for each arrow type. Furthermore, the classification results from a support vector machine and random forest were faced for this classification problem. The results from the multiclass detectors are evaluated and presented in form of confusion matrices. With the introduced approaches a high detection confidence could be achieved, proofed with validation datasets and in practical use."
journal_title,International Journal of Automotive Technology
article_title,Reliability of Nanofluid Concentration on the Heat Transfer Augmentation in Engine Radiator
keyword,"['Sizing\xa0', 'Radiator\xa0', 'Heat transfer enhancement\xa0', 'Concentration ratio\xa0', 'Nanofluids\xa0']"
history,"['2018-04', '2018-02-27', '2016-09-29', '2017-07-06', '2017-09-27']"
abstract,"Abstract Nanofluids, the fluid suspensions of nanomaterial, became a promising fluid that is invoked when heat transfer increase is required. Using of nanofluids as a coolant in the engine radiators is a crucial topic for the thermal engines manufactrers due to the expected enhancement in the cooling process. In this study, Two nanofluids (Al2O3/water and CuO/water) flowing in a flat tube of radiator are investigated numerically to evaluate thermal and flow performance. The resizing process for the radiator is performed by using nanofluid instead of water flow. A significant reduction in the radiator volume is achieved due to marked improvement in the heat transfer performance while, the required pumping power after this reduction in the volume is increased over that needed for base fluid. The normalized heat transfer (heat transfer to the pumping power) is found to be a function of both Reynolds number and nanofluid concentration ratio while the ratio of the normalized heat transfer is found to be dependent only on the nanofluid concentration ratio. These dependencies are formulated as general correlations."
journal_title,International Journal of Automotive Technology
article_title,Numerical Study for Brake Squeal by Machining Patterns on Frictional Surface
keyword,"['Automotive brake\xa0', 'Squeal\xa0', 'Modal analysis\xa0', 'Machining pattern\xa0', 'Finite element method\xa0']"
history,"['2018-04', '2018-02-27', '2017-05-23', '2017-08-29', '2017-09-18']"
abstract,"Abstract Automotive brake noise has become a stubborn problem as automotive cars achieve higher driving torques, since that the increased torque induces the generation of severe noise dissipation during brake operation. Moreover, the global brake tuning market for achieving higher performance of the vehicle has expanded recently. The need to control the noise grows more in this connection. The tuning brake kits have employed cross-drilled and slotted machining pattern on the surface of the rotor. These designs have advantages to improve air ventilation, temperature control, and surface cleaning of brake pad. However, the effects of modal frequency by patterned rotor surfaces are rarely discussed, even if it is highly related with brake squeal phenomenon. Therefore, this study deals with the relationship between patterned surfaces and brake squeal through the numerical methods. The commercial software of a finite element analysis is employed for calculation by varying geometric design factors of each rotor pattern. As a result, the cross-drilled machining patterns are concluded to be an influential factor for in-plane mode frequency while the slotted patterns have more leverage for out-of-plane mode frequency."
journal_title,International Journal of Automotive Technology
article_title,Design and Evaluation of Robust Cooperative Adaptive Cruise Control Systems in Parameter Space
keyword,"['Cooperative adaptive cruise control\xa0', 'Parameter space control system design\xa0', 'D-stability\xa0']"
history,"['2018-04', '2018-02-27', '2017-02-13', '2017-06-20', '2017-07-20']"
abstract,"Abstract This paper is on the design of cooperative adaptive cruise control systems for automated driving of platoons of vehicles in the longitudinal direction. Longitudinal models of vehicles with simple dynamics, an uncertain first order time constant and vehicle to vehicle communication with a communication delay are used in the vehicle modeling. A robust parameter space approach is developed and applied to the design of the cooperative adaptive cruise control system. D-stability is chosen as the robust performance goal and the feedback PD controller is designed in controller parameter space to achieve this D-stability goal for a range of possible longitudinal dynamics time constants and different values of time gap. Preceding vehicle acceleration is sent to the ego vehicle using vehicle to vehicle communication and a feedforward controller is used in this inter-vehicle loop to improve performance. Simulation results of an eight vehicle platoon of heterogeneous vehicles are presented and evaluated to demonstrate the efficiency of the proposed design method. Also, the proposed method is compared with a benchmark controller and the feedback only controller. Time gap regulation and string stability are used to assess performance and the effect of the vehicle to vehicle communication frequency on control system performance is also investigated."
journal_title,International Journal of Automotive Technology
article_title,Selection of Actuator Combination in Integrated Chassis Control Using Taguchi Method
keyword,"['Integrated chassis control\xa0', 'Taguchi method\xa0', 'Electronic stability control\xa0', 'Active front steering\xa0', 'Active rear steering\xa0', 'Weighted pseudo-inverse control allocation\xa0']"
history,"['2018-04', '2018-02-27', '2017-01-20', '2017-08-01', '2017-08-01']"
abstract,"Abstract This paper presents a method to select the actuator combination in integrated chassis control using Taguchi method. Electronic stability control (ESC), active front and rear steering (AFS/ARS) are used as an actuator, which is needed to generate a control tire force. After computing the control yaw moment in the upper-level controller, it is distributed into the control tire forces, generated by ESC, AFS and ARS in the lower-level controller. In this paper, the weighted pseudo-inverse control allocation (WPCA) with variable weights is used to determine the control tire forces of each actuator. Taguchi method is adopted for sensitivity analysis on variable weights of WPCA in terms of the control performances such as the maneuverability and the lateral stability. For sensitivity analysis, simulation is performed on a vehicle simulation package, CarSim. From sensitivity analysis, the most effective actuator combination is selected."
journal_title,International Journal of Automotive Technology
article_title,Development of a self-driving car that can handle the adverse weather
keyword,"['Autonomous driving\xa0', 'Path planning\xa0', 'Obstacle detection\xa0', 'Lane detection\xa0', 'Adverse weather\xa0']"
history,"['2018-02', '2017-10-03', '2016-12-01', '2017-06-13', '2017-07-17']"
abstract,"Abstract Lane and road recognition are essential for self-driving where GPS solution is inaccurate due to the signal block or multipath in an urban environment. Vision based lane or road recognition algorithms have been studied extensively, but they are not robust to changes in weather or illumination due to the characteristic of the sensor. Lidar is a sensor for measuring distance, but it also contains intensity information. The road mark on the road is made to look good with headlight at night by using a special paint with good reflection on the light. With this feature, road marking can be detected with lidar even in the case of changes in illumination due to the rain or shadow. In this paper, we propose equipping autonomous cars with sensor fusion algorithms intended to operate in a different weather conditions. The proposed algorithm was applied to the self-driving car EureCar (KAIST) in order to test its feasibility for real-time use."
journal_title,International Journal of Automotive Technology
article_title,"Schlieren, Shadowgraph, Mie-scattering visualization of diesel and gasoline sprays in high pressure/high temperature chamber under GDCI engine low load condition"
keyword,"['Spray\xa0', 'Gasoline\xa0', 'Diesel\xa0', 'Mie-scattering\xa0', 'Schlieren\xa0', 'Shadowgraph\xa0']"
history,"['2018-02', '2017-10-03', '2016-12-23', '2017-03-07', '2017-04-26']"
abstract,"Abstract Three visualization methods, Schlieren, Shadowgraph, and Mie-scattering, were applied to compare diesel and gasoline spray structures in a constant volume chamber. Fuels were injected into a high pressure/high temperature chamber under the same in-cylinder pressure and temperature conditions of low load in a GDCI (gasoline direct injection compression ignition) engine. Two injection pressures (40 MPa and 80 MPa), two ambient pressures (4.2 MPa and 1.7 MPa), and two ambient temperatures (908 K and 677 K) were use. The images from the different methods were overlapped to show liquid and vapor phases more clearly. Vapor developments of the two fuels were similar; however, different liquid developments were seen. At the same injection pressure and ambient temperature, gasoline liquid propagated more quickly and disappeared more rapidly than diesel liquid phase. At the low ambient temperature and pressure condition, gasoline and diesel sprays with higher injection pressures showed longer liquid lengths due to higher spray momentum. At the higher ambient temperature condition, the gasoline liquid length was shorter for the higher injection pressure. Higher volatility of gasoline is the main reason for this shorter liquid length under higher injection pressure and higher ambient temperature conditions. For a design of GDCI engine, it is necessary to understand the higher volatility of gasoline."
journal_title,International Journal of Automotive Technology
article_title,Belief and fuzzy theories for driving behavior assessment in case of accident scenarios
keyword,"['Advanced driver assistance system\xa0', 'Driver-vehicle-environment system\xa0', 'Fuzzy inference systems\xa0', 'Belief theory\xa0', 'Driver behavior\xa0']"
history,"['2018-02', '2017-10-03', '2016-09-29', '2017-04-26', '2017-06-23']"
abstract,"Abstract The estimation of the overspeed risk before the accident is among the main goals of this paper. The proposed method uses the Energy Equivalent Speed (EES) to assess the severity of an eventual accident. However, the driver behavior evaluation should take into account the parameters related to the Driver, the Vehicle and the Environment (DVE) system. For this purpose, this paper considers a two-level strategy to predict the global risk of an event using the Dempster-Shafer Theory (DST) and the Fuzzy Theory (FT). This paper presents two methods to develop the Expert Model-based Basic Probability Assignment (EM based BPA), which is the most important task in the DST. The first one is based on the accident statistics and the second method deals with the relationship between the Fuzzy and Belief measurements. The experimental data is collected by one driver using our test vehicle and a Micro-intelligent Black Box (Micro-iBB) to collect the driving data. The sensitivity of the developed models is analysed. Our main evaluation concerns the Usage Based Insurance (UBI) applications based on the driving behavior. So, the obtained masses over the defined referential subsets in the DST are used as a score to compute the driver’s insurance premium."
journal_title,International Journal of Automotive Technology
article_title,Development of twin-chamber on-wheel resonator for tire cavity noise
keyword,"['Road noise\xa0', 'Tire cavity noise\xa0', 'Device\xa0', 'Resonator\xa0', 'Wheel rim\xa0']"
history,"['2018-02', '2017-10-03', '2016-12-23', '2017-05-23', '2017-06-12']"
abstract,"Abstract Tire cavity noise is a noise which produces reverberations. Given the ringing in the ears that it causes vehicle occupants, it has long been one of the main road noise issues. For the countermeasure against tire cavity noise, since drastic solution is still more difficult for the downstream measure against a body system with the increase of big weight, its device in the tire cavity of the countermeasure against the origin is the most effective for a light weight and drastic solution. Some reduction devices of tire cavity noise have come to be commercialized in recent years. As a commercialization example, what equipped the tire inside surface with the noise absorbing material, and the thing which equipped roadwheel with the resonator are developed. However, application of these devices is limited to some of tires and high-class vehicle types from cost restrictions, and at present, it does not result in technical generalization and has not diffused through it so much. Since the new structure which reduces weight and cost by 50 % or more was suggested towards generalization of the Helmholtz resonator technology which is a flexible device which can equip roadwheel and does not limit a tire brand and commercial production was realized, this paper introduces that theoretical background and realization structure. And this device has been successfully applied to mass-production models on the market."
journal_title,International Journal of Automotive Technology
article_title,Model-based automatic test case generation for automotive embedded software testing
keyword,"['Software testing\xa0', 'Test case generation\xa0', 'Model-based development\xa0', 'Unified Modeling Language (UML)\xa0', 'Integration testing\xa0', 'Power window switch module\xa0', 'Approval testing\xa0', 'Hardware testing\xa0']"
history,"['2018-02', '2017-10-03', '2016-10-04', '2017-04-10', '2017-06-23']"
abstract,"Abstract We propose a method to automatically generate software and hardware test cases from a UML model developed through a model-based development process. Where languages such as source-code languages are used within the model, input and expected values for each test case are generated using a custom parser. As a next step, unit test cases are combined to generate integration test cases using a bottom-up approach. Then these cases are converted into hardware test cases for approval testing of embedded systems, using XQuery and hardware mapping tables. We demonstrate this process by applying it to the power window switch module of a Hyundai Santa Fe vehicle. Our approach provides an automatic testing procedure for embedded systems developed by model-based methods, and generates test cases efficiently using a recombination of signals. In conclusion, our proposed method could help reduce the resources needed for test case generation from software to hardware."
journal_title,International Journal of Automotive Technology
article_title,Investigation of objective parameters for acceptance evaluation of automatic lane change system
keyword,"['Driver/Passenger acceptance\xa0', 'Acceptance evaluation\xa0', 'Objectification\xa0', 'ADAS (Advanced Driver Assistant System)\xa0', 'Automatic lane change system\xa0']"
history,"['2018-02', '2017-10-03', '2017-04-25', '2017-06-21', '2017-07-21']"
abstract,"Abstract Recently, with increased interest in high levels of automated driving systems such as automatic lane change system, the need for reliable assessment methods of driver acceptance has arisen. Because the acceptance depends on the individual, the assessment of the acceptance can only be based on an individual’s personal attitude, expectations, and experiences. Accordingly, subjective evaluation methods have mostly been utilized to assess the acceptance of newly developed advanced driver assistance systems. In this study, an investigation of the effects of vehicle dynamic behavior and the traffic environment on driver acceptance is conducted to provide an objective evaluation method of driver acceptance for an automatic lane change system. In order to conduct the investigation, a specific experimental program is designed and a massive database, including information on interaction behaviors between drivers, a vehicle and the traffic environment is constructed with a selected group of 19 drivers. Then, 21 parameters and their descriptive statistics for an objective evaluation index are presented to illustrate the analysis results. The results of this research can be important not only for an objective evaluation of the acceptance, but can also be expanded to suggest design criteria for control of advanced and automated driving assistance systems."
journal_title,International Journal of Automotive Technology
article_title,Influence of temperature on the tyre rolling resistance
keyword,"['Tyres\xa0', 'Rolling resistance\xa0', 'Temperature\xa0', 'Measuring standard\xa0']"
history,"['2018-02', '2017-10-03', '2016-01-11', '2016-10-29', '2017-04-11']"
abstract,"Abstract Temperature is a very important factor controlling rolling resistance of road vehicle tyres. There are at least three different temperatures that may be considered as important factors controlling thermal conditions of the rolling tyre. The most common measure of the thermal conditions during tyre rolling is ambient air temperature. The other two are: pavement temperature and “tyre” temperature. Tyre temperature is the most difficult to establish, as temperatures of different parts of rolling tyres differ considerably, thus there is a problem to obtain representative values. In the authors’ opinion, air temperature is the most universal and reliable parameter to measure. The article presents results obtained in the Technical University of Gdańsk during laboratory and road measurements of different car tyres rolling on different pavements. The knowledge of rolling resistance characteristics is important for modelling car dynamics as well as fuel consumption. It is also necessary to establish proper test conditions in the future standardized on-road method of measuring rolling resistance. The results indicate that generally each tyre and pavement combination is influenced by the air temperature in a unique way, but at the same it is possible to propose some general influence factors that may be used to normalize measurements to the standard temperature of 25 °C."
journal_title,International Journal of Automotive Technology
article_title,Effect of operating parameters on diesel/propane dual fuel premixed compression ignition in a diesel engine
keyword,"['Diesel engine\xa0', 'Dual-fuel combustion\xa0', 'GIE (Gross Indicated thermal Efficiency)\xa0', None, 'PCCI (Premixed Charge Compression Ignition)\xa0', 'RCCI (Reactivity Controlled Compression Ignition)\xa0']"
history,"['2018-02', '2017-10-03', '2017-03-23', '2017-06-16', '2017-07-16']"
abstract,"Abstract In this research, the effects of three operating parameters (Diesel injection timing, propane ratio, and exhaust gas recirculation (EGR) rates) in a diesel-propane dual fuel combustion were investigated. The characteristics of dual-fuel combustion were analyzed by engine parameters, such as emission levels (Nitrogen oxides (NOx) and particulate matter (PM)), gross indicated thermal efficiency (GIE) and gross IMEP Coefficient of Variance (CoV). Based on the results, improving operating strategies of the four main operating points were conducted for dual-fuel PCCI combustion with restrictions on the emissions and the maximum pressure rise rate. The NOx emission was restricted to below 0.21 g/kWh in terms of the indicated specific NOx (ISNOx), PM was restricted to under 0.2 FSN, and the maximum pressure rise rate (MPRR) was restricted to 10 bar/deg. Dual-fuel PCI combustion can be available with low NOx, PM emission and the maximum pressure rise rate in relatively low load condition. However, exceeding of PM and MPRR regulation was occurred in high load condition, therefore, design of optimal piston shape for early diesel injection and modification of hardware optimizing for dual-fuel combustion should be taken into consideration."
journal_title,International Journal of Automotive Technology
article_title,Gasket life criteria at low temperatures adopting proportional compensation for loss of flexibility and conformability
keyword,"['Gasket\xa0', 'Life criteria\xa0', 'Low temperature\xa0', 'Recovery\xa0', 'Conformability\xa0']"
history,"['2018-02', '2017-10-03', '2016-08-31', '2017-05-30', '2017-06-08']"
abstract,"Abstract In the automobile industry, the service life of gaskets is defined as the time until which a released gasket recovers 60 % of the original compression. It was observed that the recovery curves of gaskets were highly nonlinear at high temperatures, and relatively nonlinear at temperatures above the room temperature. However, it was also noted that the recovery curves of the gaskets at temperatures below room temperature exhibited linearity with respect to the ln(time). Automotive manufacturers demand gasket life criteria that exceed a specific time or the entire life of a car. In the case of gaskets used at lower temperatures, since materials encounter losses in its flexibility and conformability, the definition of service life specifying a 60 % recovery may not be sufficiently safe to eliminate possible leakages. In this study, new gasket life criteria that could be used at low temperatures were proposed. The new criteria were proposed based on the change in Young’s modulus of the gasket material in order to conserve the sealing capability."
journal_title,International Journal of Automotive Technology
article_title,Allocation control algorithms design and comparison based on distributed drive electric vehicles
keyword,"['Allocation control\xa0', 'Efficiency matrix\xa0', 'Stability control\xa0', 'Distributed drive electric vehicle\xa0']"
history,"['2018-02', '2017-10-03', '2017-01-09', '2017-06-16', '2017-06-19']"
abstract,"Abstract For a distributed drive electric vehicle (DDEV) which is equipped with redundant actuators, allocation control is a key technique. Three different allocation control algorithms are designated with fixed efficiency matrix, dynamic efficiency matrix, and direct yaw moment distribution, respectively. All these algorithms are applied in a vehicle stability control system with hierarchical control structure and evaluated from three aspects, namely, control precision, real-time characteristics, and control energy. Comparison results demonstrate that the algorithm with dynamic efficiency matrix has the best comprehensive performance, which is also validated in field tests based on a DDEV equipped with four motors."
journal_title,International Journal of Automotive Technology
article_title,Influence of the geometric parameters of the vehicle frontal profile on the pedestrian’s head accelerations in case of accidents
keyword,"['Collision\xa0', 'Crash-test\xa0', 'Dummy\xa0', 'Ideal vehicle profile\xa0', 'Linear acceleration\xa0', 'Angular acceleration\xa0', 'Mesh\xa0', 'Pedestrian\xa0', 'Virtual model\xa0']"
history,"['2018-02', '2017-10-03', '2016-12-23', '2017-05-29', '2017-06-16']"
abstract,"Abstract The goal of this paper is to determine how the geometry of the vehicle’s frontal profile is influencing the pedestrian’s head accelerations (linear and angular) in car-to-pedestrian accidents. In order to achieve this goal, a virtual multibody dummy of the pedestrian was developed and multiple simulations of accidents were performed using vehicles with different frontal profile geometry, from different classes. The type of accidents considered is characteristic for urban areas and occur at relatively low speed (around 30 km/h) when an adult pedestrian is struck from the rear and the head acceleration variation are the measurement of the accident severity. In the accident simulation 3D meshes were applied on the geometry of the vehicles, in order to define the contact surface with the virtual dummy, similar with real vehicles. The validation of the virtual pedestrian dummy was made by performing two crash-tests with a real dummy, using the same conditions as in the simulations. The measured accelerations in the tests were the linear and angular accelerations of the head during the impact, and these were compared with the ones from the simulations. After validating the virtual model of the car-to-pedestrian accident, we were able to perform multiple simulations with different vehicle shapes. These simulations are revealing how the geometric parameters of the vehicle’s frontal profile are influencing the head acceleration. This paper highlights the main geometric parameters of the frontal profile design that influence the head injury severity and the way that the vehicles can be improved by modifying these parameters. The paper presents an approach to determine the “friendliness” of the vehicle’s frontal profile in the car-to-pedestrian collision."
journal_title,International Journal of Automotive Technology
article_title,Hydraulic control system design for a PHEV considering motor thermal management
keyword,"['Plug-in hybrid electric vehicle\xa0', 'Hydraulic control system\xa0', 'Motor cooling\xa0', 'Thermal equivalent circuit model\xa0', 'Energy consumption\xa0']"
history,"['2018-02', '2017-10-03', '2017-02-24', '2017-05-29', '2017-06-15']"
abstract,"Abstract In this paper, a design method for a PHEV hydraulic control system was proposed considering motor thermal management. Dynamic models of the target PHEV were developed including the hydraulic system, which consists of one mechanical and one electric oil pump. The required motor cooling flow was designed based on the motor temperature, which was obtained from a one-dimensional thermal equivalent circuit model including the heat source and oil spray cooling. Combining the PHEV powertrain model, hydraulic control system model, and the motor thermal model including the cooling system, an integrated simulator was developed for the target PHEV. Using the integrated simulator, the temperatures of MG1 and MG2 were investigated for various motor cooling flow rates when the PHEV underwent a highway driving cycle. The energy consumption of the hydraulic control system was also evaluated. It was found from the simulation results that a hydraulic control system of the target PHEV could be designed that satisfied the required flow for the motor cooling, lubrication and brake control using the design procedure proposed in this study."
journal_title,International Journal of Automotive Technology
article_title,System power loss optimization of electric vehicle driven by front and rear induction motors
keyword,"['Front-and-rear-motor-drive electric vehicle\xa0', 'Induction motor\xa0', 'Power loss optimization\xa0', 'Motor loss model\xa0', 'Temperature difference correction\xa0']"
history,"['2018-02', '2017-10-03', '2017-02-07', '2017-07-02', '2017-07-05']"
abstract,"Abstract Power loss optimization aiming at the high-efficiency drive of front-and-rear-induction-motor-drive electric vehicle (FRIMDEV) as an effective way to improve energy efficiency and extend driving range is of high importance. Different from the traditional look-up table method of motor efficiency, power loss optimization of the dual- motor system based on the loss mechanism of induction motor (IM) is proposed. First of all, based on the power loss characteristic of FRIMDEV from battery to wheels, the torque distribution optimization model aiming at the minimum system power loss is put forward. Secondly, referring to d-q axis equivalent model of IM, the power loss functions of the dual-IM system are modeled. Then, the optimal torque distribution coefficient (β o) between the two IMs is derived, and the theoretical switching condition (T sw) between the single- and dual-motor-drive mode (SMDM and DMDM) is confirmed. Finally, a dual-motor test platform is developed. The derived torque distribution strategy is verified. The influence of motor temperature on β o and T sw are tested, and the correction models based on temperature difference are proposed. Based on the system power loss analysis, it can be confirmed that, under low load conditions, the SMDM takes priority over the DMDM, and the controller of the idling motor should be shut down to avoid the additional excitation loss. While under middle to high load conditions, even torque distribution (β o = 0.5) is preferred if the temperature difference between the two IMs is small; otherwise, β o should be corrected based on dual-motor temperatures. The theoretical T sw derived without dealing with temperature difference is a function only of motor speed, while temperature difference correction of it should be conducted in actual operations based on motor resistance changing with temperature."
journal_title,International Journal of Automotive Technology
article_title,Similarity of the measured NIC of a BioRID II dummy in car-to-car rear end impact and sled experiments
keyword,"['Rear-end collision\xa0', 'NIC\xa0', 'BioRID II dummy\xa0', 'Car-to-car impact experiment\xa0', 'Sled experiment\xa0']"
history,"['2018-02', '2017-10-03', '2016-12-02', '2017-05-09', '2017-06-11']"
abstract,"Abstract The Japan New Car Assessment Program (J-NCAP) evaluates the performance of cars in terms of protection against whiplash injuries in rear-end collisions. In the test protocol, a simplified triangular acceleration is applied to the sled. This study clarifies whether biofidelic rear-impact dummy II (BioRID II) measurements obtained for simplified triangular acceleration reflect car-to-car rear-end impacts in real-world accidents in Japan. We conducted a car-to-car rear-end impact experiment and a simplified-triangular-acceleration sled test. Our results indicate that the time series of dummy responses were approximately consistent in the two test conditions. The neck injury criterion (NIC) and maximum acceleration of the head and T1 measured using the BioRID II dummy were similar in the car-to-car and sled experiments. This revealed that the J-NCAP test protocol using simplified triangular acceleration reflects the car-to-car rear-end impact experiment using Japanese cars, in terms of the NIC and maximum acceleration of the head and T1."
journal_title,International Journal of Automotive Technology
article_title,Adaptive feedforward control of a steer-by-wire system by online parameter estimator
keyword,"['Steer-by-wire\xa0', 'Online parameter estimator\xa0', 'Feedforward control\xa0']"
history,"['2018-02', '2017-10-03', '2016-12-28', '2017-03-19', '2017-06-12']"
abstract,"Abstract The tracking control of the steer-by-wire (SBW) system to achevie desired steering motion is the core issue for the design of algorithm. Most of model-based tracking control assumed the constant parameters without the consideration of dynamic characteristics. The external disturbances and model nonlinearities can bring uncertainties of the system parameters. To reduce the influence of parameter uncertainties, an online estimator by output error identification method is proposed to estimate the dynamic parameters of a SBW system. Meanwhile, the parameter gradient projection method is applied to eliminate the parameter drift, while a full order state observer is developed to weaken the effects of noise disturbance during the parameter identification. Since the sensitivity of parameter uncertainties for the feedforward control, the online estimator is incorporated into the control model and improve the controlled robustness. The proposed adaptive feedforward controller is conducted by the real-time experiments to show the tracking performance."
journal_title,International Journal of Automotive Technology
article_title,Dynamics characteristics analysis and control of FWID EV
keyword,"['Four-wheel-independently-drive electric vehicles (FWID EV)\xa0', 'Dynamics characteristics\xa0', 'Powertrain energy efficiency\xa0', 'Vehicle stability, Dynamics control\xa0']"
history,"['2018-02', '2017-10-03', '2016-04-18', '2017-05-14', '2017-08-13']"
abstract,"Abstract Compared with internal combustion engine (ICE) vehicles, four-wheel-independently-drive electric vehicles (FWID EV) have significant advantages, such as more controlled degree of freedom (DOF), higher energy efficiency and faster torque response of an electric motor. The influence of these advantages and other characteristics on vehicle dynamics control need to be evaluated in detail. This paper firstly analyzed the dynamics characteristics of FWID EV, including the feasible region of vehicle global force, the improvement of powertrain energy efficiency and the time-delays of electric motor torque in the direct yaw moment feedback control system. In this way, the influence of electric motor output power limit, road friction coefficient and the wheel torque response on the stability control, as well as the impact of motor idle loss on the torque distribution method were illustrated clearly. Then a vehicle dynamics control method based on the vehicle stability state was proposed. In normal driving condition, the powertrain energy efficiency can be improved by torque distribution between front and rear wheels. In extreme driving condition, the electric motors combined with the electro-hydraulic braking system were employed as actuators for direct yaw moment control. Simulation results show that dynamics control which take full advantages of the more controlled freedom and the motor torque response characteristics improve the vehicle stability better than the control based on the hydraulic braking system of conventional vehicle. Furthermore, some road tests in a real vehicle were conducted to evaluate the performance of proposed control method."
journal_title,International Journal of Automotive Technology
article_title,Tire wear estimation based on nonlinear lateral dynamic of multi-axle steering vehicle
keyword,"['Tire wear\xa0', 'Multi-axle steering vehicle\xa0', 'Nonlinear model\xa0', 'Lateral dynamic\xa0', 'Toe angle\xa0']"
history,"['2018-02', '2017-10-03', '2017-03-20', '2017-06-30', '2017-07-11']"
abstract,"Abstract This paper presents a novel nonlinear dynamic model of a multi-axle steering vehicle to estimate the lateral wear amount of tires. Firstly, a 3DOF nonlinear vehicle dynamic model is developed, including dynamic models of the hydropneumatic suspension, tire, steering system and toe angle. The tire lateral wear model is then built and integrated into the developed vehicle model. Based on the comparison of experimental and simulation results, the nonlinear model is proved to be better than a linear model for the tire wear calculation. In addition, the effects of different initial toe angles on tire wear are analyzed. As simulation results shown, the impact of the dynamic toe angle on the tire wear is significant. The tire wear amount will be much larger than that caused by normal wear if the initial toe angle increases to 1° - 1.5°. The results also suggest that the proposed nonlinear model is of great importance in the design and optimazation of vehicle parameters in order to reduce the tire wear."
journal_title,International Journal of Automotive Technology
article_title,Flame propagation model for a rotary Atkinson cycle SI engine
keyword,"['Turbulent flame\xa0', 'Jet entrainment\xa0', 'Internal combustion engine\xa0', 'Rotary engine\xa0']"
history,"['2018-02', '2017-10-03', '2017-01-02', '2017-06-05', '2017-06-10']"
abstract,"Abstract The rotary Atkinson cycle engine includes two modes of combustion: combustion initiation and propagation in ignition chamber and then flame jet entrainment and propagation in expansion chamber. The turbulent flame propagation model is a predictive model for SI engines which could be developed for this type of combustion for the rotary Atkinson engine similar to the congenital engine with pre-chamber; in split combustion chamber SI engines, small amount of fuel is burned in pre-chamber while the fuel burned in ignition chamber of rotary Atkinson cycle is considerable. In this study a mathematical modeling of spherical flame propagation inside ignition chamber and new combined conical flame and spherical flame propagation model of a new two-stroke Atkinson cycle SI engine will be presented. The mathematical modeling is carried out using two-zone combustion analysis and the model also is validated against experimental tests and compared with previous study using non-predictive Weibe function model."
journal_title,International Journal of Automotive Technology
article_title,Integrated approach to an optimal automotive timing chain system design
keyword,"['Timing chain system\xa0', 'Design process\xa0', 'Dynamic analysis\xa0', 'Structural analysis\xa0', 'Topology optimization\xa0']"
history,"['2017-12', '2017-08-05', '2016-11-22', '2017-05-10', '2017-06-05']"
abstract,"Abstract Ensuring engine efficiency is a crucial issue for automotive manufacturers. Several manufacturers focus on reducing the time taken to develop and introduce brand new vehicles to the market. Thus, a synergic approach including various simulations is generally adopted to achieve a development schedule and to reduce the cost of physical tests. This study involved proposing a design process that is very useful in the preliminary development stage through effective support from simulations. This type of simulation-based design process is effective in developing timing chain drives; the use of this process, based on results from multiple trials, showed improvements in performance including low friction and vibration, improved durability, and cost-effective part design when compared to conventional processes. This study proposes an integrated approach to the preliminary design of an automotive timing chain system. The approach involves structural and dynamic analyses. The details of the design process are described by using the case of a virtual engine. This study conducted and summarized a dynamic and structural analysis as well as topological optimization to describe a process to obtain optimal results. The results of this study indicated the following improvements in overall performance factors: 12.1 % improvement in transmission error, 10.1 % reduction in chain tension, 46 % reduction in tensioner arm weight, and 11 % reduction in transversal displacement."
journal_title,International Journal of Automotive Technology
article_title,Development of algorithms for commercial vehicle mass and road grade estimation
keyword,"['Road grade\xa0', 'Vehicle mass\xa0', 'Kalman filter\xa0', 'Recursive least square\xa0', 'Forgetting factor\xa0']"
history,"['2017-12', '2017-08-05', '2016-07-06', '2017-02-26', '2017-04-26']"
abstract,"Abstract Estimation algorithms for road slope angle and vehicle mass are presented for commercial vehicles. It is well known that vehicle weight and road grade significantly affect the longitudinal motion of a commercial vehicle. However, it is very difficult to measure the weight and road slope angle in real time because of lack of sensor technology. In addition, the total weight of a commercial vehicles varies depending on the freight. In this study, the road grade and vehicle mass estimation algorithms are proposed using the RLS (Recursive Least Square) method and only the in-vehicle sensors. The proposed algorithms are verified in experiments using a commercial vehicle under various conditions."
journal_title,International Journal of Automotive Technology
article_title,Operating strategy for gasoline/diesel dual-fuel premixed compression ignition in a light-duty diesel engine
keyword,"['Diesel\xa0', 'Dual fuel combustion\xa0', 'Gasoline\xa0', 'Nitrogen oxides\xa0', 'Particulate matter\xa0', 'Premixed Compression Ignition (PCI)\xa0']"
history,"['2017-12', '2017-08-05', '2017-01-03', '2017-02-20', '2017-02-27']"
abstract,"Abstract Environmental problems have become a major issue for diesel engine development. Although emission aftertreatment systems such as DPFs (diesel particulate filters), LNTs (lean NOx traps) and SCR (selective catalytic reduction) have been used in diesel vehicles, the manufacturing cost increase caused by this equipment can be hard to be control. Thus, it is better for engine emissions to be reduced by improving the combustion system. A dual-fuel combustion concept is a recommended method to improve a combustion system and effectively reduce emissions. Low reactivity fuel including gasoline and natural gas, which was supplied to the intake port by the FPI (port fuel injector), improved the premixed air-fuel mixture conditions before ignition. Additionally, a small amount of high reactivity fuel, in this case diesel, was injected into the cylinder directly as an ignition source. This dual-fuel combustion promises lower levels of NOx (nitrogen oxide) and PM (particulate matter) emissions due to the elimination of local rich regions in the cylinder. However, it is challenging to control the dual-fuel combustion because the combustion stability and efficiency deteriorate due to the lack of ignition source and reactivity. Thus, it is important to establish an appropriate dual-fuel operating strategy to achieve stable, high efficiency and low emission operation. As a result of this research, a detailed operating method of dual-fuel PCI (premixed compression ignition) was introduced in detail at a low speed and low load condition by using a single cylinder diesel engine. Engine operating parameters including the gasoline ratio, a diesel injection strategy consisting of multiple injectors and timing, the EGR (exhaust gas recirculation) rate and the intake pressure were controlled to satisfy the low ISNOx (indicated specific NOx) and PM emissions levels (0.21 g/kWh and 0.1 FSN, 0.040 g/kWh, respectively) as per the EURO-6 regulation without any after-treatment systems. The results emphasized that a well-constructed dual-fuel PCI operating strategy showed low NOx and PM emissions and high GIE (gross indicated fuel conversion efficiency) with excellent combustion stability."
journal_title,International Journal of Automotive Technology
article_title,Development of a valve and optimization of a tube for self-inflating tire
keyword,"['UHP (Ultra-High-Performance) tire\xa0', 'Self inflating\xa0', 'Safety\xa0', 'Eco-friendly tire\xa0', 'FSI (Fluid-Structure Interaction)\xa0']"
history,"['2017-12', '2017-08-05', '2016-11-01', '2017-01-20', '2017-04-17']"
abstract,"Abstract Worldwide, the tire market requires safe and eco-friendly tires. In this study, a self-inflating tire (SIT) was studied and manufactured. Self-inflating tire refers to a technique for maintaining appropriate tire pressure. An internal regulator senses when tire inflation pressure has dropped below the set air pressure. The tire boosts air through the valve when rolling and compressed air enters into the tire. This procedure keeps the tire air pressure at an appropriate level and increases tire safety. In this study, a regulator was used as a negative-pressure system. A check valve was selected the minute flow check valve depending on the shape of the configured system. In addition, the material of the tube was developed with excellent physical properties and resistances (elastic rebound, working temperature, etc.) owing to its complete compression and restoration. A tube performance tester was developed and a computer aided engineering (CAE) model was modeled for comparison with the test results. Using the tester and model, it was possible to optimize the shape of the tube and regulator. Finally, the reliability of the study was verified through the prototype test. The developed equipment and systems can be used for the manufacture of high-performance and safe tires."
journal_title,International Journal of Automotive Technology
article_title,Development of hydrogen-compressed natural gas blend engine for heavy duty vehicles
keyword,"['HCNG\xa0', 'Lean combustion\xa0', 'Stoichiometric\xa0', 'EGR\xa0', None]"
history,"['2017-12', '2017-08-05', '2016-12-12', '2017-04-26', '2017-05-29']"
abstract,"Abstract Natural gas fuel, as an alternative energy source of transportation, has been used widely since it has an advantage of low emission levels. However, new technologies are required in order to meet the reinforced emission regulations. For this purpose, research into the development of hydrogen-compressed natural gas (HCNG) blend engine was carried out to evaluate its feasibility and emission characteristics. The Engine Research Department at the Korea Institute of Machinery and Materials carried out a large number of tests based on various parameter changes that could affect the performance and emission of HCNG engine in different operating conditions. An earlier stage of the research project focused on the lean combustion of a HCNG engine for heavy duty vehicles to meet the EURO-VI standards. An 11-L/6-cylinder CNG engine was used for the test. The effects of the excess air ratio change were assessed based on various content ratios of hydrogen in the natural gas fuel. In the later part of the HCNG research, a stoichiometric mixture operation was suggested to meet reinforced emission regulation without requiring a De-NOx system. Additionally, an exhaust gas recirculation (EGR) system was introduced for the purpose of improving thermal efficiency and durability. The optimal operating conditions were selected to achieve the best thermal efficiency to meet the required emission levels. In this paper, we demonstrate that a HCNG engine can achieve a significant decrease in NOx emissions, as compared to that of a CNG engine, while meeting the requirements of the EURO-VI standards during a transient mode cycle test. EGR can suppress the weakness of stoichiometric mixture combustion strategy, such as the deterioration of the durability and thermal efficiency, while the emission level can be lowered with the use of a three-way catalyst. The possibility of further reduction of emissions and CO2 with EGR was evaluated to access practical application of a HCNG engine in the field. From that evaluation, the HCNG engine with stoichiometric mixture operation for heavy duty vehicles was developed. The emission levels of HCNG engine were 50 % lower when compared to the EURO-VI standards with a greater than 10 % decrease in CO2 compared to that of a natural gas engine."
journal_title,International Journal of Automotive Technology
article_title,Multidisciplinary design optimization for front structure of an electric car body-in-white based on improved Collaborative Optimization method
keyword,"['Multidisciplinary design optimization\xa0', 'Improved collaborative optimization\xa0', 'Car body\xa0', 'Crashworhtiness\xa0', 'Finite element analysis\xa0']"
history,"['2017-12', '2017-08-05', '2016-08-09', '2017-02-05', '2017-03-25']"
abstract,"Abstract In this investigation, an Improved Collaborative Optimization (ICO) method based Multidisciplinary Design Optimization (MDO) framework for front structure of an electric car body-in-white (BIW) is presented. ICO method based on 1-norm and dynamic flabby coefficient, which shows relatively high efficiency and accuracy, is first proposed here and prepared to conduct MDO in this work. Finite element analysis (FEA) results of the baseline design for an integral battery electric car body structure show that its front part needs to be optimized designed in the consideration of full-lap frontal crashworthiness. Selecting the thicknesses of 5 components, with global mass and free basic frequency constraints, a multidisciplinary size optimization problem is implemented using both ICO and standard CO methods combined with OLHS technique, metamodel and SQL algorithm. Optimal scheme based on ICO method is preferred and selected for its better performance compared with result calculated by standard CO method. The energy absorption of redesigned front body structure is finally raised by 14.2 % with 55 iterations."
journal_title,International Journal of Automotive Technology
article_title,Effect of UWS injection at low exhaust gas temperature on NOx removal efficiency of diesel engine
keyword,"[None, 'Urea SCR (Selective Catalytic Reduction)\xa0', 'UWS (Urea Water Solution)\xa0', 'NRTC (Non Road Transient Cycle)\xa0']"
history,"['2017-12', '2017-08-05', '2017-01-17', '2017-04-20', '2017-04-20']"
abstract,"Abstract Urea-SCR systems have been widely used in diesel vehicles according to the strengthened NOx (Nitrogen Oxides) emission standard. The NOx removal efficiencies of the latest well optimized urea-SCR system are above 90 % at moderate exhaust gas temperature of 250 ~ 450 °C. However, a large amount of NOx is emitted from diesel vehicles at cold start or urban driving conditions, when the exhaust gas temperature is not high enough for SCR catalyst activation. Although many researchs have been stuied to improve NOx conversion efficiency at these low temperature conditions, it is still one of important technical issues. In this study, the effect of UWS injection at low exhaust gas temperature conditions is studied. This study uses a 3.4 L diesel engine equipped with a commertial urea SCR system. As a result, it is found that about 5 % of NOx removal efficiency is improved in the NRTC test when UWS injection starts at the SCR inlet temperature of 150 °C compared to 200 °C. It is also found that urea deposits can be formed on the wall of exhaust pipe, when the local wall temperature is lower than temperature of urea decomposition."
journal_title,International Journal of Automotive Technology
article_title,Analytical description of ride comfort and optimal damping of cushion-suspension for wheel-drive electric vehicles
keyword,"['Wheel-drive electric vehicles\xa0', 'Coupling effects\xa0', 'Comfort evaluation\xa0', 'Initial design\xa0']"
history,"['2017-12', '2017-08-05', '2017-02-07', '2017-03-05', '2017-04-10']"
abstract,"Abstract To provide initial design values of seat cushion and chassis suspension damping for wheel-drive electric vehicles (WDEVs), this paper presents an analytical estimation method and a practical damping parameters design method. Firstly, two formulae of the human body vertical acceleration in terms of the power spectrum density (PSD) and the root mean square (RMS) are deduced for WDEVs. Then, the coupling effects of the key vehicle parameters on ride comfort are revealed. Finally, with a practical example, the damping parameters of the cushion and the suspension are initially designed and analyzed. The results show that when every 10.0 kg increases for motor mass, the optimal damping values of the cushion and the suspension should be reduced by about 15.0 Ns/m and 50.0 Ns/m, respectively. However, the RMS acceleration increases 0.017 m/s2 with a decrease of 2.5 % for ride comfort."
journal_title,International Journal of Automotive Technology
article_title,Coupled thermo-mechanical analysis and shape optimization for reducing uneven wear of brake pads
keyword,"['Coupled thermo-mechanical analysis\xa0', 'Contact pressure distribution\xa0', 'Uneven wear\xa0', 'Shape optimization\xa0', 'Brake dynamometer test\xa0']"
history,"['2017-12', '2017-08-05', '2017-02-10', '2017-03-21', '2017-05-10']"
abstract,"Abstract In vehicle braking systems, the non-uniform contact pressure distribution on the brake pad is a major cause of uneven wear. The experimental approach of the wear phenomenon is the time consuming and costly. For this reason, a threedimensional finite element (FE) model of a brake system is presented for numerical simulation in this paper. A coupled thermo-mechanical analysis is carried out to confirm the non-uniform contact pressure distribution. A correlation between the non-uniform contact pressure and uneven wear is confirmed by measuring the amount of wear in the brake pad. The shape optimization of the brake pad is performed to reduce the uneven wear. In addition, the simulation results, such as natural frequency and temperature, are compared to experimental results."
journal_title,International Journal of Automotive Technology
article_title,Direct tire force generation algorithm based on non-iterative nonlinear inverse tire model
keyword,"['Inverse tire model\xa0', 'Extended brush model\xa0', 'Direct force generation\xa0', 'Chassis control\xa0']"
history,"['2017-12', '2017-08-05', '2016-11-01', '2017-04-03', '2017-05-01']"
abstract,"Abstract The function of vehicle dynamics control system is adjusting the yaw moment, the longitudinal force and lateral force of a vehicle body through several chassis systems, such as brakes, steering and suspension. Individual systems such as ESC, AFS and 4WD can be used to achieve desired performance by controlling actuator variables. However, integrated chassis control systems that have multiple objectives may not simply achieve the desired performance by controlling the actuators directly. Usually those systems determine the required tire forces in an upper level controller and a lower level controller regulates the tire forces through the actuators. The tire force is controlled in a recursive way based on vehicle state measurement, which may not be sufficient for fast response. For immediate force tracking, we introduce a direct tire force generation method that uses a nonlinear inverse tire model, a pseudo-inverse model of vehicle dynamics and the relationship between longitudinal force and brake pressure."
journal_title,International Journal of Automotive Technology
article_title,Design of emergency braking algorithm for pedestrian protection based on multi-sensor fusion
keyword,"['Emergency braking\xa0', 'AEBS\xa0', 'Pedestrian\xa0', 'Sensor fusion\xa0', 'Decision making\xa0', 'Target tracking\xa0']"
history,"['2017-12', '2017-08-05', '2016-09-29', '2017-01-29', '2017-04-14']"
abstract,"Abstract Globally, safety has become an increasingly important issue in the automotive industry. In an attempt to reduce traffic fatalities, UNECE launched a new EU Road Safety Program which aims to decrease the number of road deaths by half by 2020. AEB (Autonomous Emergency Braking) is a very effective active safety system intended to reduce fatalities. This study involves the design of a multi-sensor data fusion strategy and decision-making algorithm for AEB pedestrian. Possible collision avoidance scenarios according to the EuroNCAP protocol are analyzed and a robust pedestrian tracking strategy is proposed. The performance of the AEB system is enhanced by using a braking model to predict the collision avoidance time and by designing the system activation zone according to the relative speed and possible distance required to stop for pedestrians. The AEB activation threshold requires careful consideration. The test results confirm the advantages of the proposed algorithm, the performance of which is described in this paper."
journal_title,International Journal of Automotive Technology
article_title,Mathematical model validated by a crash test for studying the occupant’s kinematics and dynamics in a cars’ frontal collision
keyword,"['Safety\xa0', 'Collision\xa0', 'Occupant\xa0', 'Mathematical model\xa0', 'Kinetic energy\xa0', 'Potential energy\xa0', 'Crash test\xa0', 'Dummy\xa0']"
history,"['2017-12', '2017-08-05', '2017-02-07', '2017-03-19', '2017-04-06']"
abstract,"Abstract The aim of the paper was to determine the kinematic parameters that influence the occupant injury risk through a mathematical model. The developed model is a 2D model composed of 4 bodies (2 vehicles, thorax and head). The head and thorax are interconnected with a rotation joint and a torsion spring meant to stiffen the relative movement between the bodies. The thorax is connected with the vehicle body by a linear spring meant to simulate the seatbelt stiffness. The model was solved using Lagrange principle and the validation of the model was made through a crash test performed using the same initial conditions and comparing the obtained values of the displacement, velocity and acceleration parameters with the ones obtained with the mathematical model. The head and torso were chosen due to the fact that they are the common parts of the body that get injured, especially the head with the change of 80 % to cause fatal injury in car’s frontal collision. Once the model was validated, the stiffness of the seatbelt was modified in order to determine the behavior of the occupant in case of car frontal collisions. When the seatbelt stiffness was reduced, the occupant displacement and velocity increased, while by increasing the stiffness, these parameters decreased. The values of the developed model presented a high degree of similarity with the results obtained from the crash test with an error of 10 %. This model can be used by engineers to easily asses the occupant injury risk in case of vehicle frontal collisions."
journal_title,International Journal of Automotive Technology
article_title,Application of iterative learning control in tracking a Dubin’s path in parallel parking
keyword,"['Parallel parking\xa0', 'Dubin’s path\xa0', 'Iterative learning control\xa0', 'Steering control\xa0']"
history,"['2017-12', '2017-08-05', '2016-10-21', '2017-05-11', '2017-05-15']"
abstract,"Abstract Intelligent parking assist systems will soon be available for most vehicles on the market. Many optimal parking trajectories and control strategies have been proposed for reverse parking. However, most of these require intensive computation, causing difficulties in practical use. This paper makes use of a classical path planning method to find the shortest parking path, and establishes the possibility of integrating iterative learning control (ILC) to exploit the capability of learning from experience to track the designed path. The effectiveness of the ILC structure is demonstrated by simulation and experiments. Tracking performance is shown to be much improved by using a simple learning control law."
journal_title,International Journal of Automotive Technology
article_title,Comparative investigation on the aerodynamic effects of combined use of underbody drag reduction devices applied to real sedan
keyword,"['Computational fluid dynamics\xa0', 'Aerodynamic drag\xa0', 'Underbody drag reduction device\xa0', 'Undercover\xa0', 'Under-fin\xa0', 'Side air dam\xa0']"
history,"['2017-12', '2017-08-05', '2016-10-06', '2017-02-22', '2017-05-10']"
abstract,"Abstract To reduce the aerodynamic drag, the performance of the underbody aerodynamic drag reduction devices was evaluated based on the actual shape of a sedan-type vehicle. An undercover, under-fin, and side air dam were used as the underbody aerodynamic drag reduction devices. In addition, the effects of the interactions based on the combination of the aerodynamic drag reduction devices were investigated. A commercial sedan-type vehicle was selected as a reference model and its shape was modeled in detail. Aerodynamic drag was analyzed by computational fluid dynamics at a general driving speed on highway of 120 km/h. The undercover reduced the slipstream area through the attenuation of the longitudinal vortex pair by enhancing the up-wash of underflow, thereby reducing the aerodynamic drag by 8.4 %. The under-fin and side air dam showed no reduction in aerodynamic drag when they were solely attached to the actual complex shape of the underbody. Simple aggregation of the effects of aerodynamic drag reduction by the individual device did not provide the accurate performance of the combined aerodynamic drag reduction devices. An additional aerodynamic drag reduction of 2.1 % on average was obtained compared to the expected drag reduction, which was due to the synergy effect of the combination."
journal_title,International Journal of Automotive Technology
article_title,Lubricating performance of carbon nanotubes in internal combustion engines – engine test results for CNT enriched oil
keyword,"['Combustion engines\xa0', 'Carbon nanotubes\xa0', 'Engine oil\xa0', 'Friction\xa0']"
history,"['2017-12', '2017-08-05', '2016-07-18', '2017-01-12', '2017-03-15']"
abstract,"Abstract The main purpose of this research is to reduce friction losses by adding carbon nanotubes to engine oil. Extremely favorable tribological properties of carbon nanotubes have been extensively studied on the microscopic scale and using tribometers, have not yet been verified in the engine. Enriching oil with nanotubes can lead to significant, exceeding 7 %, reduction in the motoring torque of the engine at low crankshaft rotational speed. The phenomena associated with the dispersion of carbon nanotubes in the engine are stated and discussed. It has been shown that the oil shear during normal operation of the engine can effectively improve the dispersion of nanotubes. At the same time the oil filtration system removes agglomerates of nanotubes very quickly."
journal_title,International Journal of Automotive Technology
article_title,Vehicle stability control based on driver’s emergency alignment intention recognition
keyword,"['Emergent obstacle avoidance\xa0', ""Driver's EA intention recognition\xa0"", 'Reference model modification\xa0', 'Stability control\xa0']"
history,"['2017-12', '2017-08-05', '2016-12-23', '2017-03-25', '2017-05-10']"
abstract,"Abstract In this work, the reference model modification strategy for vehicle stability control based on driver's intention recognition under emergent obstacle avoidance situation was proposed. First the conflicts between the driver's emergency alignment (EA) intention and vehicle response characteristics were analyzed in critical emergent obstacle avoidance situation. Second combining steering wheel angle and its speed, the driver's EA intention was recognized. The reference model modification strategy based on steering operation index (SOI) was presented. Then a LQR model following controller with tire cornering stiffness adaption was used to generate direct yaw moment for tracking modified reference yaw rate and reference sideslip angle. Finally based on the four-in-wheel-motor-drive (FIWMD) electric vehicles (EV), double lane change and slalom tests were conducted to compare the results using modified reference model with the results using normal reference model. The experimental tests have proved the effectiveness of the reference model modification strategy based on driver's intention recognition."
journal_title,International Journal of Automotive Technology
article_title,Approximate optimal AUTOSAR software components deploying approach for automotive E/E system
keyword,"['AUTOSAR\xa0', 'Component deploying\xa0', 'Communication network\xa0', 'Load balance\xa0', 'Clustering algorithm\xa0']"
history,"['2017-12', '2017-08-05', '2016-03-25', '2016-07-21', '2017-05-02']"
abstract,"Abstract The AUTOSAR has been developed as the worldwide standard for automotive E/E software systems, making the electronic components of different suppliers to be employed universally. However, as the number of component-based applications in modern automotive embedded systems grows rapidly and the hardware topology becomes increasingly complex, deploying such large number of components in automotive distributed system in manual way is over-dependent on experience of engineers which in turn is time consuming. Furthermore, the resource limitation and scheduling analysis make the problems more complex for developers to find out an approximate optimal deploying approach in system integration. In this paper, we propose a novel method to deploy the AUTOSAR components onto ECUs with the following features. First, a clustering algorithm is designed for deploying components automatically within relatively low time complexity. Second, a fitness function is designed to balance the ECUs load. The goal of our approach is to minimize the communication cost over all the runnable entities while meeting all corresponding timing constraints and balancing all the ECUs load. The experiment results show that our approach is efficient and has well performance by comparing with other existing methods in specific and synthetic data set."
journal_title,International Journal of Automotive Technology
article_title,Cyclist target and test setup for evaluation of cyclist-autonomous emergency braking
keyword,"['Autonomous emergency braking\xa0', 'Cyclist safety\xa0', 'Euro NCAP\xa0']"
history,"['2017-12', '2017-08-05', '2017-01-06', '2017-04-28', '2017-05-08']"
abstract,"Abstract From 2018, Autonomous Emergency Braking (AEB) systems dedicated to avoid or mitigate passenger car-tocyclist collisions will be considered in the safety assessment by Euro NCAP. To test such systems, appropriate equipment has been developed in a project called CATS “Cyclist-AEB Testing System”, that has run between April 2014 and August 2016. Moreover, a proposal for the most relevant test scenarios was set up. The objective of the project was to provide proof to Euro NCAP of the relevance of the proposed test scenarios and of the feasibility of practical implementation of the scenarios and test setup. The process regarding the selection, verification and validation of test scenarios is described. The cooperation between 17 industrial partners (car manufacturers and automotive suppliers) in the CATS project has stimulated the harmonization and acceptance of the protocol, target and test setup. The process and intermediate results including the used methodology, have been reviewed by the German Federal Highway Research Institute (BASt) and have been shared on a regular basis during the project with stakeholders in Europe, Japan and the USA. Euro NCAP already indicated to consider the results of the CATS project as the main input to draft the test protocol, including scenarios and target for Cyclist-AEB systems in 2018 and 2020."
journal_title,International Journal of Automotive Technology
article_title,Numerical study of the early injection parameters on wall wetting characteristics of an HCCI diesel engine using early injection strategy
keyword,"['Computational Fluid Dynamics (CFD)\xa0', 'Early injection parameters\xa0', 'Wall wetting characteristics\xa0', 'Mixture formation\xa0', 'Emissions\xa0']"
history,"['2017-10', '2017-07-09', '2016-10-04', '2017-01-16', '2017-02-27']"
abstract,"Abstract Wall wetting in the early injection period has been proved to be unavoidable in the HCCI (Homogeneous charge compression ignition) diesel engine using early injection strategy, which directly affects in-cylinder fuel-air mixture formation. In this study, the effects of the early injection parameters (injection timing, injection angle and injection pressure) on wall wetting characteristics of an HCCI diesel engine using early injection strategy have been numerically investigated. The variations of maximum wall film mass, evaporated wall film mass and residual wall film mass have been summarized. The concept of MHI (Mixture Homogenous Index) is introduced to evaluate the homogeneity of fuel-air mixture in the wall wetting region. In additions, the effects of the early injection parameters on the HC (Hydrocarbon Compounds) and CO (Carbon Monoxide) emissions have also been discussed. Results  showed that in order to decrease the HC and CO emission caused by wall wetting as low as possible, it was better to increase the injection pressure and to advance the injection timing. The most effective method was to narrow the injection angle, In addition, the impingement target should be considered for choosing the injection timing and injection angle, and the impingement target of the piston bowl lip was recommended due to the enhancement of the atomization and the higher surface temperature."
journal_title,International Journal of Automotive Technology
article_title,Two-phase evaporative battery thermal management technology for EVs/HEVs
keyword,"['Lithium battery\xa0', 'Fuzzy controlled electrom-compressor\xa0', 'EMC controlled expansion valve\xa0', 'Energy efficient\xa0']"
history,"['2017-10', '2017-07-09', '2014-06-03', '2015-01-29', '2015-02-11']"
abstract,Abstract Electric vehicle’s motor draws power from battery to meet its power demand in different road profiles. Battery high discharged currents are causes of warming battery’s cells. The temperature of 40 ºC and above reduces battery life span. The rationale of fuzzy controlled evaporative battery thermal management system (EC-BThMS) development from this study is to control the battery temperature in the range of 20 ~ 40 ºC both in charging/discharging modes. The proposed system has been developed with estimating the total cooling loads and thermal behavior of the battery cells. A fuzzy controlling system has been introduced with the EC-BThMS to control the electro-compressor and the expansion valve based on the response of battery temperature sensors.A battery pack of 8.6 kWh equipped EV has been operated with 60 km/h on 0 % gradient and 40 km/h on 5 % gradient in IIUM campus while 130 km/h on 0 % gradient and 50 km/h on 3.67 % gradient in Malaysia International Formula circuit to study the battery temperature profile and percentage of battery power saving. Comparison has been made on the performance of EC-BThMS with air cooling battery thermal management system (AC-BThMS) by using same vehicle. Result shows that EC-BThMS can save energy 17.69 % more than AC-BThM 1 and 23 % more than AC-BThM 2.
journal_title,International Journal of Automotive Technology
article_title,Control strategy for clutch engagement during mode change of plug-in hybrid electric vehicle
keyword,"['Plug-in hybrid electric vehicle\xa0', 'Engine clutch\xa0', 'Mode change\xa0', 'Drivability\xa0', 'Energy efficiency\xa0']"
history,"['2017-10', '2017-07-09', '2016-08-31', '2017-02-02', '2017-02-08']"
abstract,"Abstract The plug-in hybrid electric vehicle (PHEV) has various driving modes used in both internal combustion engine and electric motors. The EV mode uses only an electric motor and the HEV mode uses both an engine and an electric motor. Specifically, when the PHEV of a pre-transmission parallel hybrid structure performs mode changing, its engine clutch is either engaged or disengaged, which is important in terms of ride comfort. In this paper, to enhance the mode changing process for the clutch engagement, a PHEV performance simulator is developed using MATLAB/Simulink based on system dynamics and experiment data. Vehicle driving analysis is carried out of the control logic and properties of the mode changing. A compensated torque is applied during the mode change. This results in the rapid speed synchronization with the clutch although the trade-off relationship of the mode change. In addition, the mode changing is conducted through the transmission shifting process to rapidly synchronize with speed. The control strategy implemented in this study is shown to improve the drivability and energy efficiency of a PHEV."
journal_title,International Journal of Automotive Technology
article_title,Effective method for knock signal denoising in internal combustion engine
keyword,"['Knock detection\xa0', 'Knock sensor\xa0', 'Non-local Mean method\xa0', 'Spark ignition turbocharged engine\xa0']"
history,"['2017-10', '2017-07-09', '2016-10-11', '2016-12-24', '2017-03-05']"
abstract,"Abstract Uncontrolled expansion of combustion wave in spark ignited internal combustion engine causes knock effect which seriously degrades efficiency and lifetime of the engine. Thus, accurate knock detection and control are essential for obtaining a desired performance from the engine. Usually, knock sensor is used to detect this phenomenon but it has limited accuracy especially at engine high-speed rotations because of natural vibration and external noises. In this study an effective method based on Non-Local Mean (NLM) algorithm has been proposed to improve the knock detection accuracy. This method is evaluated based on four different indicators and four engine cylinders. The results show 52.9 % improvement in knock detection. Also feasibility of real time execution of this method based on embedded hardware has been studied."
journal_title,International Journal of Automotive Technology
article_title,Occupant injury risk analysis at NASS/CDS database
keyword,"['NASS/CDS\xa0', 'Airbag\xa0', 'Seat belt\xa0', 'Inner trim\xa0', 'Injury source\xa0']"
history,"['2017-10', '2017-07-09', '2016-08-05', '2016-10-10', '2016-12-07']"
abstract,"Abstract Injury information for vehicle occupants from the body regions of the head, thorax, abdomen, and upper and lower extremities, due to the restraints and interior parts of the vehicle, were extracted from the 2009 ~ 2012 NASS/CDS database. For those cases with high occurrence frequency, a detailed and comprehensive data analysis was performed to find the relationship between the accident, occupant, vehicle, and injury data. A numerical frontal impact sled model with the Hybrid III dummy and the GHBMC human body model was constructed to simulate and identify those injury risks according to NASS/CDS. Among the 5,734 injuries to the aforementioned body regions from frontal crashes are, listed by frequency of occurrence, the lower extremity (27.8 %), upper extremity (21.3 %), thorax (15.1 %), face (10.9 %), spine (8.7 %), head (7.3 %), and abdomen (6.9 %). The main injury sources to the head were the windshield, side structure, and steering wheel. For the thorax and abdomen they were the seat belt and steering wheel. For the lower extremity it was the instrument panel. The main injury patterns for the head were the concussion and the contusion. For the thorax they were vessel laceration and lung contusion. For the abdomen they were laceration and contusion of the organs. For the lower extremity they were bone fracture and ligament rupture. The steering wheel and seat positions were main factors affecting head and thorax injury risks. From the sled impact simulation, high injury risks of the head and thorax were assessed respectively at conditions of steering column tilt down and rear most seat position, which correlated well with the findings from the NASS/CDS data analysis."
journal_title,International Journal of Automotive Technology
article_title,Clamping force estimation based on hysteresis modeling for electro-mechanical brakes
keyword,"['Electro-Mechanical Brake (EMB)\xa0', 'Clamping force\xa0', 'Kissing point\xa0', 'Hysteresis\xa0', 'Estimation\xa0']"
history,"['2017-10', '2017-07-09', '2016-04-21', '2016-12-14', '2016-12-30']"
abstract,"Abstract The Electro-Mechanical Brake (EMB) is anticipated by research communities and car manufacturers to be the future adopted brake system due to its advantages. However, to be competitively priced, the high cost load cell of EMB, which measures the clamping force to a disk, should be replaced by a clamping force estimation algorithm. For this purpose, a new clamping force estimator, compatible with readily available sensors, is proposed in this paper. This estimator determines the kissing point where the brake pads start to come into contact with the disk, and generates the characteristic curve of the polynomial function between the clamping force and the motor angle. Periodically updating the characteristic curve can enhance robustness to the pad’s changing thickness. Also, the model includes a description of the hysteresis of the clamping force in the overall algorithm, which prevents the estimation performance from decreasing in the transient state. The performance of the propose algorithm was validated by comparison with measured values on a developed EMB test bench."
journal_title,International Journal of Automotive Technology
article_title,Comparison of fuel efficiency and exhaust emissions between the aged and new DPF systems of Euro 5 diesel passenger car
keyword,"['Diesel\xa0', 'DPF (Diesel Particulate Filter)\xa0', 'PM (Particulate Matter)\xa0', 'Regeneration\xa0', 'Lubricant additive\xa0']"
history,"['2017-10', '2017-07-09', '2016-09-13', '2016-12-26', '2017-02-13']"
abstract,"Abstract This study was conducted to examine the impact of aged and new DPF systems of the Euro 5 diesel passenger car on fuel efficiency and exhaust emissions. Test diesel vehicle used in this study was equipped with diesel oxidation catalyst (DOC) and diesel particulate filter (DPF) as aftertreatment systems, and satisfied the Euro-5 emissions standard. The displacement volume of engine was 1.6 L and the cumulative mileage was 167,068 km before the test. The FTP-75 test procedure was used, and the time resolved and weight based exhaust emissions of total hydrocarbon (THC), carbon monoxide (CO) and nitrogen oxides (NOx) were measured. The results show that the vehicle with the new DPF system has lower emissions of THC, CO and NOx than the aged one, and fuel efficiency also increased about 5 percent. The aged DPF system had higher backpressure due to the particulate matter (mostly in the form of ash) accumulated in the DPF. As was shown in the analysis using X-CT (X-ray computer tomography), the aged DPF system had particulate matter (PM) accumulated to a length of 46.6 mm. In addition, a component analysis of PM through XRF (X-ray fluorescence) analysis found that 50 % or more of the components consisted of the P, S, Ca, and Zn."
journal_title,International Journal of Automotive Technology
article_title,Shape optimization of a torsion beam axle for improving vehicle handling performance
keyword,"['Torsion beam axle\xa0', 'Handling performance\xa0', 'Shape optimization\xa0', 'Vehicle suspension system\xa0']"
history,"['2017-10', '2017-07-09', '2016-08-09', '2017-01-21', '2017-02-16']"
abstract,"Abstract In this study, shape optimization was conducted for a vehicle’s rear suspension torsion beam to improve its dynamic handling performance. To determine the design variables affecting the vehicle roll characteristics, a sensitivity analysis was conducted using the result of a Taguchi experiment with 6 factors in 8 runs. The upper and lower-flange lengths and web thickness of the torsion beam section, as well as the vertical height difference between the inner and outer of torsion beams, were determined as design variables through sensitivity analysis of the opposite wheel travel test for optimization of the torsion beam axle. The Box–Behnken experimental design with 4 factors and 27 runs was performed using the selected design variables and by performing opposite wheel travel analysis according to the experimental design, and the response surface functions of the roll stiffness, roll steer coefficient, roll center height, and mass of the torsion beam were generated. Using these response functions, shape optimization was conducted for the torsion beam of the rear suspension system. Dynamic performance analysis was performed by applying the optimized H-shaped torsion beam to the rear suspension of the vehicle dynamics model, and it was validated that the dynamic response performance of the optimized vehicle was improved."
journal_title,International Journal of Automotive Technology
article_title,Enhancement of aerodynamic performance through high pressure relief in the engine room for passenger car using cfd technique
keyword,"['Small passenger car\xa0', 'High pressure\xa0', 'Aerodynamic performance\xa0', 'Wheel house liner\xa0', 'Numerical analysis\xa0']"
history,"['2017-10', '2017-07-09', '2016-03-11', '2016-09-17', '2017-11-06']"
abstract,Abstract High pressure acting on the vehicle’s body plays an important role in deciding the aerodynamic drag. An idea has been suggested to enhance the aerodynamic performance for small passenger car by relieving the high pressure in the engine room. The high pressure inside the engine room can be released to the outside of the vehicle through a hole perforated on the wheel house liner. About 1 % of the drag coefficient can be improved with the 1.88 % of the radiator air mass flow rate increment by installing the top hole with slots on the wheel house liner. Flow simulations are performed at the driving velocity of 110 km/h with the moving wall condition of the same velocity. The tire is rotating to catch more precise flow physics around a tire and wheelhouse liner.
journal_title,International Journal of Automotive Technology
article_title,MPC-BASED steering control for backward-driving vehicle using stereo vision
keyword,"['Stereo vision\xa0', 'Autonomous driving\xa0', 'Backward driving\xa0', 'Model predictive control\xa0']"
history,"['2017-10', '2017-07-09', '2016-05-23', '2016-11-27', '2017-03-09']"
abstract,"Abstract We propose a steering control algorithm for autonomous backward driving in a narrow corridor. Passable spaces are detected using a stereo camera, and the steering angle is controlled by a model predictive controller (MPC). For passable space detection, an UV-disparity map is calculated from the original disparity map. Information regarding passable spaces collected by the stereo camera is used in steering control. Backward driving requires the driver’s preemptive actions, which can be learned by experience because of the non-intuitive responses (the initial motion of the vehicle is opposite to the driver’s steering angle input). This occurs because a backward-driving vehicle is a non-minimum phase system. One of the most popular steering control algorithms is Stanley method, which is based on the feedback of lateral displacement error and heading angle error. The method is very intuitive and works well for forward driving, but it exhibits significant undershoot for backward driving cases. Furthermore, the method does not explicitly consider any constraints on control inputs and states. We designed a steering controller based on the MPC technique that requires future information but can handle constraints explicitly. Because we have near-future information from the stereo camera under limited passable spaces, MPC can be effectively implemented. We performed several simulations and experiments to show the performance and superiority of the suggested method over a simple feedback-based control algorithm."
journal_title,International Journal of Automotive Technology
article_title,Numerical modeling and dynamic simulation of automotive power window system with a single regulator
keyword,"['Vehicle power window system\xa0', 'Door glass position error\xa0', 'Door glass dynamic simulation\xa0']"
history,"['2017-10', '2017-07-09', '2017-03-23', '2017-05-12', '2017-05-18']"
abstract,"Abstract Door glass position errors that occur when an automobile door glass goes up and down not only reduce the basic performance of the door glass in terms of sound- and water-proofing, but also decrease the life span of the glass run and belt. Thus, there is a need for understanding the dynamic behavior of a door glass in order to reduce these errors. In this research, we analyzed the door glass behavior by developing a dynamic numerical analysis model for a single rail regulator type of door glass lifting system. We modeled the glass run and belt lip load as a non-linear spring-damper system to reflect changes in the lip load caused by door glass position errors in the analysis. We also introduced local coordinate systems to find door glass position errors during the lifting process. By using our model, the time spent on the up and down motions, the current, and the lifting resistance could be predicted with 4 %, 11 %, 3 % and 4 % of error, respectively, comparing with the test data. We confirmed the effects of imbalances and boundary conditions in the load and moment which occur during the door glass lifting process. We also found that the lip reaction force, coefficient of friction, overlap length and position of the lift line cause door glass position errors."
journal_title,International Journal of Automotive Technology
article_title,Numerical method for simulating tire rolling noise by the concept of periodically exciting contact force
keyword,"['Tire rolling noise\xa0', 'Periodically exciting contact force\xa0', 'Stationary tire\xa0', 'Tire body vibration\xa0', 'Normal velocity extraction\xa0', 'Acoustic analysis\xa0', 'Sound pressure and power\xa0']"
history,"['2017-10', '2017-07-09', '2017-01-03', '2017-02-24', '2017-03-11']"
abstract,"Abstract For the numerical simulation of tire rolling noise, an important subject is the extraction of normal velocity data of the tire surface that are essential for the acoustic analysis. In the current study, a concept of periodically exciting contact force is introduced to effectively extract the tire normal velocity data. The ground contact pressure within contact patch that is obtained by the static tire contact analysis is periodically applied to the whole tread surface of stationary tire. The periodically exciting contact forces are sequentially applied with a time delay corresponding to the tire rolling speed. The tire vibration is analyzed by the mode superposition in the frequency domain, and the acoustic analysis is performed by commercial BEM code. The proposed method is illustrated through the numerical experiment of 3-D smooth tire model and verified from the comparison with experiment, and furthermore the acoustical responses are investigated to the tire rolling speed."
journal_title,International Journal of Automotive Technology
article_title,Robust control for four-wheel-independent-steering electric vehicle with steer-by-wire system
keyword,"['Four wheel independent steering\xa0', 'Steer by wire\xa0', 'Robust control\xa0', 'Sliding mode control\xa0', 'Extended Kalman filter\xa0']"
history,"['2017-10', '2017-07-09', '2016-07-25', '2016-11-21', '2017-03-09']"
abstract,"Abstract A four-wheel-independent-steering (4WIS) electric vehicle (EV) with steer-by-wire (SBW) system is proposed in this paper. The fast terminal sliding mode controller (FTSMC) is designed for the SBW system to suppress external disturbances. Taking unstructured and structured uncertainties into consideration, a robust controller is designed for the 4WIS EV utilizing μ synthesis approach and the controller order reduction is implemented based on Hankel-Norm approximation. Since sideslip angle is the feedback signal of robust controller and it is hard to measure, the extended Kalman filter (EKF) is employed to estimate sideslip angle. To evaluate the vehicle performance with the designed control system, step and sinusoidal steering maneuvers are simulated and analyzed. Simulation results show that the designed control system have good tracking ability, strong robust stability and good robust performance to improve vehicle stability and handing performance."
journal_title,International Journal of Automotive Technology
article_title,On the experimental analysis of single input single output control of yaw rate and sideslip angle
keyword,"['Electric vehicle\xa0', 'Torque-vectoring\xa0', 'Variable tire-road friction\xa0', 'Sideslip angle\xa0', 'Experiments\xa0']"
history,"['2017-10', '2017-07-09', '2016-09-12', '2017-01-07', '2017-02-13']"
abstract,"Abstract Electric vehicles with individually controlled drivetrains allow torque-vectoring, which improves vehicle safety and drivability. This paper investigates a new approach to the concurrent control of yaw rate and sideslip angle. The proposed controller is a simple single input single output (SISO) yaw rate controller, in which the reference yaw rate depends on the vehicle handling requirements, and the actual sideslip angle. The sideslip contribution enhances safety, as it provides a corrective action in critical situations, e.g., in case of oversteer during extreme cornering on a low friction surface. The proposed controller is experimentally assessed on an electric vehicle demonstrator along two maneuvers on surfaces with significantly varying tire-road friction coefficient. Different longitudinal locations of the sideslip angle used as control variable are compared during the experiments. Results  show that: i) the proposed SISO approach provides significant improvements with respect to the vehicle without torque-vectoring, and the controlled vehicle with a reference yaw rate solely based on the handling requirements for high-friction maneuvering; and ii) the control of the rear axle sideslip angle provides better performance than the control of the sideslip angle at the center of gravity."
journal_title,International Journal of Automotive Technology
article_title,Coordinated collision avoidance for connected vehicles using relative kinetic energy density
keyword,"['Connected vehicle\xa0', 'Coordinated Collision Avoidance (CCA)\xa0', 'Total relative kinetic energy density\xa0', 'Model Predictive Control (MPC)\xa0']"
history,"['2017-10', '2017-07-09', '2016-07-14', '2017-01-18', '2017-02-17']"
abstract,"Abstract Vehicular collision often leads to serious casualties and traffic congestion, and the consequences are worse for multiple-vehicle collision. Many previous works on collision avoidance have only focused on the case for two consecutive vehicles using on-board sensors, which ignored the influence on upstream traffic flow. This paper proposes a novel coordinated collision avoidance (CCA) strategy for connected vehicles, which has potential to avoid collision and smooth the braking behaviors of multiple vehicles, leading to an improvement of traffic smoothness. Specifically, model predictive control (MPC) framework is used to formulate the CCA into an optimization problem, where the objective is to minimize the total relative kinetic energy density (RKED) among connected vehicles. Monte Carlo simulations are used to demonstrate the effectiveness of proposed CCA strategy by comparison with other two strategies. Among all the three control strategies, the RKED based control strategy shows the best performance of collision avoidance, including the best crash prevention rates (99.2 % on dry asphalt road and 90.5 % on wet asphalt road) and the best control of distance headways between vehicles."
journal_title,International Journal of Automotive Technology
article_title,Modeling and control of engine starting for a full hybrid electric vehicle based on system dynamic characteristics
keyword,"['Hybrid electric vehicle\xa0', 'Dual clutch transmissions\xa0', 'Modeling\xa0', 'Simulation\xa0', 'Experiment\xa0']"
history,"['2017-10', '2017-07-09', '2016-10-28', '2017-02-06', '2017-02-17']"
abstract,"Abstract This paper focuses on the dynamic modeling and control of engine starting for a Full Hybrid Electric Vehicle (FHEV) consisting of an Integrated Starter Generator (ISG) and Dual Clutch Transmissions (DCTs). The dynamic characteristics of the engine, the ISG motor and the main clutch are analyzed respectively. The dynamic models of the main components of the powertrain system are also established taking the system dynamic characteristics into consideration. The FHEV dynamic model of engine starting during electric driving mode has been investigated in detail. The coordinated control strategy of engine starting has been proposed based on the powertrain system dynamic characteristics. The simulation for the engine starting control during electric driving mode has been performed based on the Matlab/Simulink platform. The simulation results show that the proposed control strategy satisfies the requirements of response and smoothness during engine starting process. Furthermore, a bench test has been carried out to analyze the system characteristics during engine starting process. The test data is highly agreeable to the simulation data and the effectiveness of engine starting control strategy is validated by the comparison between simulation results and the test data."
journal_title,International Journal of Automotive Technology
article_title,Development of a method for the identification and engineering design of endless fiber reinforced composites
keyword,"['Multi-material design\xa0', 'Fiber reinforced plastics\xa0', 'Anisotropy\xa0', 'Systematic engineering and design\xa0']"
history,"['2017-10', '2017-07-09', '2016-10-19', '2017-02-15', '2017-03-08']"
abstract,"Abstract The main objective of this paper is to introduce a novel method to develop a multi-material body-in-white concept with composite material or hybrid material system. A new method based on the work of Durst (2008) is presented, which works basically in three steps. In the first step, the anisotropy of the components is analyzed to pre-evaluate the potential of FRP-suitable parts. In the second step, the predominating orientation of every finite element is determined and clustered to get a first impression of an appropriate laminate architecture. In the last step, a suitable design with a preliminary stacking sequence is calculated. To prove the feasibility of this method, it has been applied to simple flat coupons and a body-in-white component to show that the method leads to reasonable results."
journal_title,International Journal of Automotive Technology
article_title,"Optimization of power management among an engine, battery and ultra-capacitor for a series HEV: A dynamic programming application"
keyword,"['Power management optimization\xa0', 'Dynamic programming\xa0', 'Backward simulation\xa0', 'Fuel economy\xa0', 'Series hybrid electric vehicle\xa0']"
history,"['2017-10', '2017-07-09', '2016-05-16', '2016-11-12', '2017-01-22']"
abstract,"Abstract In a hybrid electric vehicle (HEV) system, it is an important issue on how to distribute the output power from multiple power generating components to operate a vehicle more efficiently. Many studies have been conducted on how to manage multiple power sources of a vehicle based on various optimization theories. In this study, an algorithm to calculate the optimization of a series HEV that has three power generating components, engine, battery and ultra-capacitor, is developed based on dynamic programming. Normally dynamic programming is applied to the optimization of power management and components sizing by estimating potential fuel economy for electrified vehicle such as HEV, Plug-in HEV or Fuelcell HEV. In contrast with most objective systems that have only two power generating components, the system in this study has three power sources. Since the system has three power sources, the number of state and control variables of optimization problem increases. Therefore the number of calculations increases unreasonably. To decrease the number and time of calculations, a new electric model that contains the both characteristics of battery and ultra-capacitor is developed with some assumptions. In comparison with the optimization algorithm which follows the theory of DP with no assumptions, the results from the newly developed algorithm has 1.04 % discrepancy in terms of fuel economy, even though the calculation time decreases to 4400 times less."
journal_title,International Journal of Automotive Technology
article_title,Decoupled self-tuning PI controller for an idling stop system applied to scooters
keyword,"['Idling stop system\xa0', 'Scooter\xa0', 'Self-tuning\xa0', 'PI controller\xa0', 'Integrated starter generator\xa0']"
history,"['2017-08', '2017-05-24', '2016-07-25', '2016-10-22', '2016-11-25']"
abstract,"Abstract This paper is aimed to propose a decoupled self-tuning proportional plus integral (PI) controller with simple law for an idling stop system applied to scooters. An integrated starter generator (ISG) of the idling stop system is designed with a high efficiency permanent magnet synchronous motor (PMSM). The PMSM used as an ISG must have a high torque characteristic to ensure that the engine can be accelerated up to firing speed. A conventional and useful control algorithm named PI control is unable to handle motor current very well for dynamic load, parametric variation, and external disturbance, especially in a vehicle application. Therefore, a robust algorithm for current control in an ISG is proposed. The decoupled selftuning PI controller based on the Lyapunov stability theorem is utilized to guarantee the control performance. Numerical simulations demonstrate the effectiveness of the proposed control algorithm. Experimental results show that the engine of a 150 cm3 scooter can be cranked to reach firing speed by a ISG within 0.1−0.2 second. The proposed method is simple, robust, as well as stable for idling stop system, and can be effectively implemented."
journal_title,International Journal of Automotive Technology
article_title,Objective evaluation of the sound quality of the warning sound of electric vehicles with a consideration of the masking effect: Annoyance and detectability
keyword,"['Annoyance\xa0', 'Detectability\xa0', 'Electric vehicle\xa0', 'Masking effect\xa0', 'Sound quality\xa0', 'Whine index\xa0']"
history,"['2017-08', '2017-05-24', '2016-12-23', '2017-03-05', '2017-04-05']"
abstract,"Abstract This study developed a method to evaluate the sound quality of the warning sound masked by background noise considering the masking effect. The warning sound of an electric vehicle is required by law for the safety of pedestrians. Therefore, the warning sound becomes an additional noise pollution source if it is designed as an annoyance. On the other hand, if the sound is designed with a low sound pressure level, pedestrians will not recognize the approach of vehicle due to background noise. To avoid nose pollution and permit the detectability of an approaching vehicle, a method for evaluating the annoyance and detectability of an electric vehicle is required. In this paper, the whine index evaluating the whine sound masked by the background was developed and used as a sound metric. This metric was employed for the development of an annoyance index and detectability index for electric vehicles."
journal_title,International Journal of Automotive Technology
article_title,Flow measurements in the exhaust system of a motorized engine
keyword,"['Exhaust system\xa0', 'Stereo particle image velocimetry\xa0', 'Oxygen sensor\xa0']"
history,"['2017-08', '2017-05-24', '2016-04-05', '2016-08-23', '2016-11-28']"
abstract,"Abstract Stereo Particle Image Velocimetry (SPIV) is used to measure the highly turbulent flow in the upstream region of the catalytic converter for a four stroke IC engine. These experiments are conducted for a motorized engine to investigate the feasibility of using SPIV for exhaust flow measurements in a firing IC engine in our future research. The results obtained here can also be used for validation of the CFD models. The measured flow is highly three dimensional, non-uniform with large magnitudes of turbulence indicating recirculating flow structures. These structures show signatures of jet flows coming out of the exhaust valves at all exhaust crank angles. The triangular shape and location for the end face of each exhaust runner pipe, the length and geometry of the runners also affect the flow mixing process upstream of the catalytic converter contributing to the complexity of this flow. Although majority of the exhaust flow passes through the catalytic converter, some will recirculate due to impingement of the exhaust jets on the surface of the catalyst."
journal_title,International Journal of Automotive Technology
article_title,Reduction of preview distance in lane-keeping control
keyword,"['Vehicle dynamics\xa0', 'Driver model\xa0', 'Lane-keeping assistance system\xa0', 'Autonomous driving\xa0']"
history,"['2017-08', '2017-05-24', '2016-06-14', '2016-12-12', '2016-12-27']"
abstract,"Abstract Lane marker detection is indispensable for a lane-keeping-control algorithm. However, it is impossible to detect lane markers when the curvature of the lane the vehicle is travelling on is large or when there is another car in front of the vehicle with short distance. For lane marker detection, it is desirable to set a preview point close to the vehicle. Therefore, by analyzing the block diagram of driver-vehicle system, we propose a method to reduce preview distance without lane tracking performance deterioration by increasing preview points from the conventional one point to two points. Furthermore, it is revealed that driving along a corner with constant curvature without steady-state deviation and arbitrary design of tracking dynamic characteristics become possible by increasing preview points."
journal_title,International Journal of Automotive Technology
article_title,Gain-scheduled EGR control algorithm for light-duty diesel engines with static-gain parameter modeling
keyword,"['Diesel engine\xa0', 'Exhaust gas recirculation\xa0', 'Variable geometry turbocharger\xa0', 'Skogestad internal model control\xa0', 'Linear parameter varying\xa0', 'Gain scheduling\xa0']"
history,"['2017-08', '2017-05-24', '2016-01-25', '2016-07-24', '2017-01-10']"
abstract,"Abstract This paper presents a model-based gain scheduling algorithm of a PI-based EGR controller for light-duty diesel engines. In order to capture nonlinear characteristic of the EGR system, we have proposed a new scheduling variable to illustrate the static-gain of the plant model as a linear function. The proposed scheduling variable is composed of the air-tofuel ratio of the exhaust gas and the pressure ratio between the exhaust and intake manifolds. Using the scheduling variable, a static-gain model achieved 0.94 of the R-squared value with 810 of steady-state measurements which include key engine operating conditions. Based on the model of the static-gain parameter, the gains of the PI controller are decided by Skogestad internal model control (SIMC) tuning rule in real-time. Through various scenarios of engine experiments, the proposed gain scheduling algorithm represented that the PI gains were successfully adapted according to the changes of the engine operating conditions."
journal_title,International Journal of Automotive Technology
article_title,Reduction of engine emissions via a real-time engine combustion control with an egr rate estimation model
keyword,"['EGR estimation\xa0', 'Model-based control\xa0', 'Closed-loop control\xa0', 'Exhaust emission transient condition\xa0']"
history,"['2017-08', '2017-05-24', '2016-08-30', '2016-12-13', '2017-01-06']"
abstract,"Abstract Vehicle emissions regulations are becoming increasingly severe and remain a principal issue for vehicle manufacturers. Since, WLTP (Worldwide harmonized Light vehicles Test Procedures) and RDE (real driving emission) regulations have been recently introduced, the engine operating conditions have been rapidly changed during the emission tests. Significantly more emissions are emitted during transient operation conditions compared to those at steady state operation conditions. For a diesel engine, combustion control is one of the most effective approaches to reduce engine exhaust emissions, particularly during the transient operation. The concern of this paper is about reducing emissions using a closed loop combustion control system which includes a EGR rate estimation model. The combustion control system calculates the angular position where 50 % of the injected fuel mass is burned (MFB50) using in-cylinder pressure for every cycle. In addition, the fuel injection timing is changed to make current MFB50 follow the target values. The EGR rate can be estimated by using trapped air mass and in-cylinder pressure when the intake valves are closed. When the EGR rate is different from the normal steady conditions, the target of MFB50 and the fuel injection timing are changed. The accuracy of the model is verified through engine tests, as well as the effect of combustion control. The peaks in NO level was decreased during transient conditions after adoption of the EGR model-based closed loop combustion control system."
journal_title,International Journal of Automotive Technology
article_title,Fracture loci of DP980 steel sheet for auto-body at intermediate strain rates
keyword,"['DP980\xa0', 'Ductile fracture\xa0', 'Fracture mechanism\xa0', 'Strain rate\xa0', 'Fracture criterion\xa0']"
history,"['2017-08', '2017-05-24', '2016-11-28', '2016-12-13', '2016-12-14']"
abstract,"Abstract This paper introduces the effect of the strain rate on the ductile fracture of DP980 1.2t steel sheet. Tensile tests of DP980 sheet are performed at a range of strain rates from 0.001 s−1 to 100 s−1 with three different shapes of specimens: the diagonally notched specimen for the in-plane shear test; the dog bone specimen for the uniaxial tension test; and grooved specimen for the plane strain tension test. To trace the strain on the surface of the specimen, 2-D digital image correlation (DIC) technique is adopted to encompass the remarkable transition of the fracture characteristics including the fracture strain, loading path and strain rate sensitivity. The negative stain rate sensitivity is observed on the equivalent strain to fracture which corresponds to the experimental results at low strain rate ranging from 0.001 s−1 to 0.1 s−1. The transition of thermal condition from isothermal to adiabatic comes into play to increase the equivalent strain to fracture at the intermediate strain rate from 0.01 s−1 to 1 s−1. The fracture loci incorporating with the Lou-Huh ductile fracture criterion are developed to identify the strain rate effect in the wide regime of triaxiality."
journal_title,International Journal of Automotive Technology
article_title,Topologically optimized shape of CFRP front lower control ARM
keyword,"['Topology optimization\xa0', 'Lower control arm\xa0', 'Carbon fiber reinforced plastic\xa0', 'Mean-field homogenization\xa0']"
history,"['2017-08', '2017-05-24', '2016-08-17', '2016-12-21', '2017-01-02']"
abstract,"Abstract This study shows topology optimization of lower control arm (LCA), made of carbon fiber reinforced plastic (CFRP), that was originally composed of aluminum alloy. By mean-field homogenization (MFH) method, averaged mechanical properties of CFRP are applied to FEM analyses of 3D LCA model. The design target is to reduce the LCA weight while satisfying the multiple constraints including required stiffness and durability conditions at the same time. As a result, authors propose the new design of CFRP LCA with 30 % weight reduction compared to Al alloy LCA."
journal_title,International Journal of Automotive Technology
article_title,Dynamic model of supercritical Organic Rankine Cycle waste heat recovery system for internal combustion engine
keyword,"['Dynamic model\xa0', 'Finite volume\xa0', 'Organic rankine cycle\xa0', 'Supercritical evaporator\xa0', 'Transient heat source\xa0', 'Waste heat recovery\xa0']"
history,"['2017-08', '2017-05-24', '2016-06-28', '2016-11-09', '2016-11-30']"
abstract,"Abstract The supercritical Organic Rankine Cycle (ORC) for the Waste Heat Recovery (WHR) from Internal Combustion (IC) engines has been a growing research area in recent years, driven by the aim to enhance the thermal efficiency of the ORC and engine. Simulation of a supercritical ORC-WHR system before a real-time application is important as high pressure in the system may lead to concerns about safety and availability of components. In the ORC-WHR system, the evaporator is the main contributor to thermal inertia of the system and is considered to be the critical component since the heat transfer of this device influences the efficiency of the system. Since the thermo-physical properties of the fluid at supercritical pressures are dependent on temperature, it is necessary to consider the variations in properties of the working fluid. The wellknown Finite Volume (FV) discretization method is generally used to take those property changes into account. However, a FV model of the evaporator in steady state condition cannot be used to predict the thermal inertia of the cycle when it is subjected to transient heat sources. In this paper, a dynamic FV model of the evaporator has been developed and integrated with other components in the ORC-WHR system. The stability and transient responses along with the performance of the ORC-WHR system for the transient heat source are investigated and are also included in this paper."
journal_title,International Journal of Automotive Technology
article_title,Design and validation of an electro-hydraulic brake system using hardware-in-the-loop real-time simulation
keyword,"['Electric booster\xa0', 'Electro-hydralic brake\xa0', 'Sliding mode control\xa0', 'Motor control\xa0', 'Pedal feel\xa0', 'Real-time simulation\xa0']"
history,"['2017-08', '2017-05-24', '2016-03-07', '2016-07-22', '2017-01-09']"
abstract,"Abstract This paper presents a novel electric booster (E-booster) that exibits superior performance advantages over traditional vacuum boosters. The proposed E-booster, consisting of an electric motor and a ball screw assembly, is designed for electro-hydraulic brake (EHB) systems to meet relevant requirements for electric vehicles and active safety technologies. A mathematical model for an EHB system is generated to determine the desired values of the parameters for the E-booster prototype using numerical simulation in MATLAB. Simulation results of the EHB system with the virtual E-booster demonstrate the feasibility and effectiveness of the innovative technique. Built upon the results derived from the numerical simualtions, an integrated algorithm based on the Kalman filter and a sliding mode control technique is designed to control the E-booster motor and to implement the brake booster function. A hardware-in-the-loop (HIL) real-time simulation system equipped with the E-booster prototype is developed. HIL real-time simulations are conducted to evaluate the proposed algorithm. The HIL real-time simulation results demonstrate that the proposed algorithm generates booster brake forces fast, and forces the ball nut to track the push rod well to ensure comfortable brake pedal feel."
journal_title,International Journal of Automotive Technology
article_title,Application of the reverse 3D scanning method to evaluate the wear of forging tools divided on two selected areas
keyword,"['Forging process\xa0', 'Destructive phenomena\xa0', 'Durability of tools\xa0', 'Scanning\xa0', 'Hybrid layers\xa0']"
history,"['2017-08', '2017-05-24', '2016-09-30', '2016-11-21', '2016-11-26']"
abstract,"Abstract This study is focused on tools used in the industrial hot forging process of a front wheel forging (eventually–gear wheel) manufactured for the automotive industry. Four different variants were applied for the tools: 2 die inserts were coated with two different hybrid layers (GN + PVD type), i.e. AlCrTiN and AlCrTiSiN, one insert was only nitrided, and one was pad welded, to improve tool durability. The tool wear was analysed and represented by the material degradation on the working surface, based on the 3D scanning and the material growth of the periodically collected forgings. Additionally, the scanned tools were divided into two areas, in which it was found, based on the reliminary analysis, that various degradation mechanisms are predominant. Microstructural and hardness measurements of the analyzed tools were also performed. Based on the results, it was found that, in the central part of the die insert (area A), thermo-mechanical fatigue and wear occurred, while in the area of the bridge insert (area B), only abrasive wear could be observed. For these areas (A and B), the loss of material was determined separately. In area A for the inserts with hybrid layer GN+AlCrTiSiN and gas nitrided, an intensive increase of wear took place, which was not observed for the pad welded and GN+AlCrTiN layer insert, for which, together with the increase of the forging number, a proportional growth of the loss of material occurred. In area B the weakest results were obtained for the insert with GN+AlCrTiSiN layer, while wear of other die inserts grew similar and proportional."
journal_title,International Journal of Automotive Technology
article_title,Optical device for measuring the injectors opening in common rail systems
keyword,"['Common rail\xa0', 'Injector\xa0', 'Diesel engine\xa0', 'Optical sensor\xa0', 'Displacement measurement\xa0']"
history,"['2017-08', '2017-05-24', '2015-11-18', '2016-12-14', '2017-01-02']"
abstract,"Abstract Since the needle displacement exerts a fundamental influence on the operation of Common Rail injection systems, accurate measurements of the control piston position can be crucial for a more thorough analysis of the behaviour of injectors, in particular when multiple injections are employed. Eddy current sensors have traditionally been used in lab activities to measure the control piston position inside injectors; apart from the high cost, the scientific literature clearly shows their inadequacy, which is mainly due to the presence of electromagnetic disturbance: the current pulse, which controls the opening of the injector, generates electromagnetic fields which strongly affect the acquisition of data. Many attempts have recently been made either to solve the interference occurring during such measurements or to propose alternative displacement transducers whose operation is not influenced by electromagnetic interference. In this paper, a new device for measuring the injector opening is proposed: it is an optical transducer characterized both by simple and very cheap construction and by a reliable physical principle for measuring the control piston lift. The reliability of the proposed sensor is assessed by a thorough experimental campaign and by comparing the experimental results with the numerical predictions achieved by a Common Rail injector model. Since the assembly of the optical sensor does not affect the injector operation, it can efficiently be used both for experimental tests and for on-board diagnosis and monitoring of the injector operation."
journal_title,International Journal of Automotive Technology
article_title,Novel electronic braking system design for EVS based on constrained nonlinear hierarchical control
keyword,"['Electric vehicle\xa0', 'Constrained active-set SQP algorithm\xa0', 'Parameters identification\xa0', 'Nonlinear sliding mode control\xa0', 'Hierarchical Control\xa0']"
history,"['2017-08', '2017-05-24', '2016-07-04', '2016-10-18', '2016-12-22']"
abstract,"Abstract Both environment protection and energy saving have attracted more and more attention in the electric vehicles (EVs) field. In fact, regarding control performance, electric motor has more advantages over conventional internal combustion engine. To decouple the interaction force between vehicle and various coordinating and integrating active control subsystems and estimate the real-time friction force for Advanced Emergency Braking System (AEBS), this paper’s primary intention is uniform distribution of longitudinal tire-road friction force and control strategy for a Novel Anti-lock Braking System (Nov- ABS) which is designed to estimate and track not only any tire-road friction force, but the maximum tire-road friction force, based on the Anti-Lock Braking System (ABS). The longitudinal tire-road friction force is computed through real-time measurement of breaking force and angular acceleration of wheels. The Magic Formula Tire Model can be expressed by the reference model. The evolution of the tire-road friction is described by the constrained active-set SQP algorithm with regard to wheel slip, and as a result, it is feasible to identify the key parameters of the Magic Formula Tire Model. Accordingly, Inverse Quadratic Interpolation method is a proper way to estimate the desired wheel slip in regards to the reference of tireroad friction force from the top layer. Then, this paper adapts the Nonlinear Sliding Mode Control method to construct proposed Nov-ABS. According to the simulation results, the objective control strategy turns out to be feasible and satisfactory."
journal_title,International Journal of Automotive Technology
article_title,Wave propagation in head on bonnet impact: Material and design issues
keyword,"['Impact\xa0', 'Wave propagation\xa0', 'Pedestrian safety\xa0', 'Bonnet design\xa0', 'Material selection\xa0']"
history,"['2017-08', '2017-05-24', '2016-06-09', '2016-11-29', '2017-01-12']"
abstract,"Abstract Head on bonnet impact is becoming more and more important in automotive design as regulations on pedestrian safety become more demanding. Despite the relatively low amount of energy involved, these impacts are truly dynamic phenomena as the event duration is comparable with the traveling time of the different wavefronts generated by the impact. In this paper, we show that we can build up a simplified model for the impact based on wave propagation analysis. Using this model, we can analyze head acceleration on existing bonnets or predict it on new ones. Head acceleration in a bonnet impact can thus be estimated over the whole area of the bonnet with a few minutes of CPU."
journal_title,International Journal of Automotive Technology
article_title,Development of a backflow simulation program for automotive body assemblies
keyword,"['Overflow\xa0', 'Watertight\xa0', 'Leak\xa0', 'Gap\xa0', 'Octree\xa0']"
history,"['2017-08', '2017-05-24', '2016-07-11', '2016-10-22', '2016-11-16']"
abstract,"Abstract Most car body parts are manufactured using thin plates to reduce their weight, and completed assemblies typically have numerous spaces. Because cars are not designed to be completely watertight, rain or wash water may leak into the interior spaces of the assembly through gaps or inlets. When water enters a space and is not drained sufficiently, it can fill the space and overflow into unexpected channels, causing severe problems such as part corrosion and electric shock. In our research, based on a decomposition model representation, we have developed a program to graphically simulate all possible flows within the interior spaces between car parts. Our program can simulate the locations of outlets and overflow channels into unexpected regions, and thus help designers verify the effectiveness of their designs before manufacturing, which can therefore reduce the development time and costs. In particular, since the program can simulate overflow when a car in both horizontal and inclined positions, it can prevent possible design errors by engineers who are accustomed to designing cars only in a horizontal orientation. Our developed method can also be applied to aircraft and ship designs."
journal_title,International Journal of Automotive Technology
article_title,Schedule construction under precedence constraints in flexray in-vehicle networks
keyword,"['FlexRay\xa0', 'Distributed embedded systems\xa0', 'Message scheduling\xa0', 'Precedence constraints\xa0']"
history,"['2017-08', '2017-05-24', '2016-06-09', '2016-09-02', '2016-11-22']"
abstract,"Abstract As embedded time-triggered applications have widely replaced mechanical systems in modern automobiles, holistic scheduling of tasks and messages of such applications on in-vehicle networks has become a critical issue. For offering QoS (Quality of Service) guarantees, the holistic schedule must satisfy numerous constraints such as protocol specifications, delay constraints and precedence constraints between tasks schedules and messages transmissions. Existing approaches to this problem search through a vast design space of all possible joint task and message schedules. This leads to a high complexity and limits the scalability of such approaches for scheduling the large scale systems. To cope with this problem, we propose an approach that divides the holistic scheduling problem to two sub-problems: the sub-problem of message scheduling and the sub-problem of task scheduling, while precedence relations and end-to-end information passing between task instances and messages are preserved and the end-to-end deadlines are guaranteed. This helps to reduce the workload on the problem solvers and improves efficiency and scalability. In the first sub-problem, our approach optimizes scheduling the set of messages and allocates time windows for scheduling each task with respect to precedence constraints, end-to-end deadlines and FlexRay protocol specifications. The length of each time window helps to preserve the respective tasks schedulability and to provide flexibility for both task and message scheduling. The objective is defined with respect to extensibility issues. In the second sub-problem, our approach optimizes schedule of the set of tasks with respect to their allocated time windows and timing constraints. The objective is defined with respect to latency issues. We optimize the solution to each sub-problem using Mixed Integer Linear Programming optimization framework. Performance evaluations show that, compared with existing holistic scheduling approaches, our approach is more scalable and obtains better solutions in a reasonable amount of time."
journal_title,International Journal of Automotive Technology
article_title,Combustion characteristics of hydrotreated vegetable oil – diesel blend under EGR and supercharged conditions
keyword,"['Hydrotreated Vegetable Oil (HVO)\xa0', 'Heat release rate\xa0', 'Exhaust Gas Recirculation (EGR)\xa0', 'Supercharged\xa0', 'Two-color method\xa0']"
history,"['2017-08', '2017-05-24', '2016-10-11', '2016-11-30', '2016-12-12']"
abstract,"Abstract This paper investigates the effects of Hydrotreated vegetable oil-diesel blend to combustion characteristics under various ambient oxygen concentrations and ambient pressure. Combustion characteristics were investigated using heat release rate analysis, two color method, soot concentration measurement and NOx concentration measurement. The experiments were carried out on a rapid compression expansion machine to simulate the ambient condition of a CI engine at TDC. Synthetic gas with oxygen concentrations of 21 %, 15 % and 10 % were used to simulate EGR conditions. A single hole injector was used with five different fuels: commercial diesel, HVO-commercial diesel blends and HVO. The results showed that increasing HVO blending percentages decreased ignition delay, flame temperature, soot concentration and NOx concentration. Heat release at oxygen concentration of 10 % dramatically dropped due to a shortened ignition delay, which resulted in less combustion. A decreased oxygen concentration from applied EGR conditions not only increased ignition delay, heat release, flame temperature and NOx concentration, but also increased soot concentration. A combination of EGR and supercharged conditions by increasing ambient pressure and decreasing oxygen concentrations resulted in increased heat release, decreased flame temperature, ignition delay and soot concentration, compared to EGR conditions."
journal_title,International Journal of Automotive Technology
article_title,Torque control allocation based on constrained optimization with regenerative braking for electric vehicles
keyword,"['Electric vehicle\xa0', 'Control allocation\xa0', 'Tire slip power\xa0', 'Optimal regenerative braking\xa0']"
history,"['2017-08', '2017-05-24', '2016-10-04', '2016-11-30', '2016-12-03']"
abstract,"Abstract This paper proposes a constrained optimization-based torque control allocation method aimed to improve energy efficiency, and thus, driving range for electric vehicles. In the proposed method, the cost function is defined not only to achieve desired yaw moment for vehicle handling and stability, but also to minimize power losses for energy efficiency. The particular attention is paid to the power losses due to tire slips both longitudinally and laterally. The constraints are also set based on thorough investigation on various causes of power disppation such that the torque is allocated with restraint to use regenerative braking in its maximum capacity. The proposed control allocation method has been tested and verified to be effective on energy efficiency improvement through both simulation and experiment under various driving maneuvers."
journal_title,International Journal of Automotive Technology
article_title,Erratum to: New tension mechanism for high-speed tensile testing machine
keyword,[]
history,"['2017-06', '2017-04-01']"
abstract,None
journal_title,International Journal of Automotive Technology
article_title,Lumped mass-spring model construction for crash analysis using full frontal impact test data
keyword,"['Lumped mass-spring model\xa0', 'SISAME\xa0', 'Frontal impact\xa0', 'NCAP\xa0', None, 'Chest g’s\xa0']"
history,"['2017-06', '2017-04-01', '2015-04-30', '2016-07-23', '2016-12-07']"
abstract,"Abstract Lumped Mass-Spring (LMS) model is simple but very effective for the design study of vehicle crashworthiness and occupant safety. To construct the LMS model, the SISAME software and the NHTSA test data were used. Using the SISAME, the weights of mass elements and the load-paths of spring elements were optimally and directly extracted from the test data. Among the various types of spring, the segmented inelastic type of spring was effective for the vehicle crash analysis. In this study, to obtain the occupant injuries such as HIC15 and 3 ms Chest g’s, the LMS model containing the occupant model consisted of the head, chest and pelvis was developed and validated. The modeling for the chest deflection and neck injuries was not considered in this study because of the modeling difficulties and the limitation of the SISAME software. The simulation results of occupants showed good agreements with the test results. The modeling idea for the occupant was simple but very effective."
journal_title,International Journal of Automotive Technology
article_title,Hydraulic retarders for heavy vehicles: Analysis of fluid mechanics and computational fluid dynamics on braking torque and temperature rise
keyword,"['Hydraulic retarder\xa0', 'Heavy-duty vehicles\xa0', 'Temperature rise\xa0', 'Braking torque\xa0', 'Mathematical model\xa0']"
history,"['2017-06', '2017-04-01', '2015-11-18', '2016-09-05', '2016-10-08']"
abstract,"Abstract Hydraulic retarders are auxiliary braking devices that reduce the velocity of a vehicle, particularly when a vehicle is driven downhill. Such velocity reduction could reduce the potential risk caused by brake failure caused by the service brake working for a long time and the temperature of the brake shoe becomes extremely high. This paper introduces the construction of the hydraulic retarder and proposes two mathematical models for the hydraulic retarder. The first mathematical model is deduced by using fluid mechanics, which is used to analyze the mechanism of how braking torque is produced and the key factors that can influence the value of the braking torque. The second mathematical model is deduced by using thermodynamics, which is used to quantify the heat produced by the hydraulic retarder. This research emphasizes that the flow rate and the average velocity of the working fluid in the working chamber mainly determine the braking torque of the hydraulic retarder. The flow rate into and out of the working chamber determines the temperature rise of the working fluid. Computational fluid dynamics (CFD) simulations are conducted with the Reynolds-averaged Navier-Stokes (RANS) and Shear Stress Transport (SST) turbulent models. Experiments are carried out to justify the two mathematical models and the CFD simulations. The results show that the mathematical models are capable of describing the force analysis and energy conversion of the hydraulic retarder and SST is more accurate for CFD simulation and the error is within 6 %."
journal_title,International Journal of Automotive Technology
article_title,Design of ferrite magnet CFSM to improve speed response of EPS system
keyword,"['Concentrated Flux Synchronous Motor (CFSM)\xa0', 'Damping ratio\xa0', 'Electric Power Steering (EPS)\xa0', 'Electromechanical undamped natural frequency\xa0', 'Ferrite magnet\xa0', 'Speed response characteristic\xa0', 'Mass moment of inertia\xa0']"
history,"['2017-06', '2017-04-01', '2016-03-03', '2016-11-09', '2016-11-16']"
abstract,"Abstract This paper deals with the speed response characteristic of the concentrated flux synchronous motor (CFSM) using ferrite magnets for the electric power steering (EPS) system. To analyze the response characteristic of the CFSM, an analytical method using the electromechanical undamped natural frequency and damping ratio based on the transfer function is proposed. By using the method, the speed response according to the variations of the shape of the permanent magnets (PMs) and rotor core is analyzed. It was analyzed under the conditions of the constant volume of the PMs as well as the constant diameter of the rotor. By using the proposed analysis method, the improved model is desgined based on the initial model fulfilling the required specifications. Finally, the torque and speed response characteristics of two motors are simulated through the finite element analysis (FEA) and MATLAB Simulink."
journal_title,International Journal of Automotive Technology
article_title,Numerical analysis and experimental study on the performance optimization of cold storage heat exchanger integrated with evaporator
keyword,"['Cold storage heat exchanger\xa0', 'Cold storage\xa0', 'Coldness release\xa0', 'Evaporator\xa0', 'Fuel economy\xa0', 'ISG\xa0', 'Latent heat\xa0', 'Numerical simulation\xa0', 'Phase change material\xa0', 'Thermal comfort\xa0']"
history,"['2017-06', '2017-04-01', '2015-11-24', '2016-05-13', '2016-09-05']"
abstract,"Abstract The ISG (Idle Stop and Go) systems are commonly used in modern automobiles because they are economical and environmental friendly technology. However, when a vehicle stops, the air-conditioning system stops, resulting in thermal discomfort to passengers in the cabin. This paper examines a cold storage heat-exchanger (CSH) integrated with an evaporator. The position of the cold storage parts inside a heat exchanger was analyzed through numerical simulations using FLUENT to create an adequate design for a CSH. The CSH performance was then examined with various airflow volumes and optimized experimentally in terms of the refrigerant flow circuit and fin density in the heat exchanger. Next, an experiment on the coldness release performance of the CSH was conducted in the air-conditioning system. The cold storage system with optimized CSH experiment resulted in lower air discharge temperatures (3.5 °C ~ 4.9 °C) than current air-conditioning systems, and delayed the warm-up by approximately 155 seconds to reach 18 °C temperature of air discharge. For this study, the CSH is an effective solution for the ISG-applied vehicles with less investment by transforming current air-conditioners’ structures more effectively."
journal_title,International Journal of Automotive Technology
article_title,Characteristic analysis of vehicle rollover accidents: Rollover scenarios and prediction/warning
keyword,"['Rollover accidents\xa0', 'Scenarios\xa0', 'Accident seriousness\xa0', 'Velocity\xa0', 'Rollover criteria\xa0', 'Prediction\xa0']"
history,"['2017-06', '2017-04-01', '2016-05-26', '2016-07-29', '2016-10-28']"
abstract,"Abstract Rollover accidents are relatively more serious than other types of accidents, so it is important that the safety device functions appropriately. For the safety device to work correctly, a rollover criteria system which can predict a rollover is needed. To Figure out the characteristics of rollover, NASS-CDS was used to statistically analyze the seriousness of accident and passenger injuries in various rollover situations. Typical scenarios for each rollover type were established by referring to the test criteria of NHTSA. Rollovers can be largely categorized into tripped or un-tripped rollover depending on the situation, but there is no method for estimating the velocity of the car in each situation. This paper suggests methods for estimating the car velocity through finding the relationship between car velocity and quarter turns by performing repetitive simulation in established typical scenarios. Additionally, simple physical models for rollover were developed and each model was analyzed to find the rollover criteria for each type. The rollover criteria were verified by simulating various rollover situations. The rollover criteria suggested would be helpful in predicting a rollover and appropriately activating the safety device."
journal_title,International Journal of Automotive Technology
article_title,Aerodynamic study of a generic car model with wheels and underbody diffuser
keyword,"['Automobile\xa0', 'Underbody diffuser\xa0', 'Aerodynamics\xa0']"
history,"['2017-06', '2017-04-01', '2015-06-15', '2016-09-22', '2016-11-29']"
abstract,"Abstract Being a continuous subject of research, this study presents new aspects regarding the relevance of underbody diffusers in road vehicle aerodynamics. Using a generic car model on wheels as a reference, the effect of the wheels on the body fitted with an underbody diffuser was studied, where the diffuser length and angle were varied within ranges which are applicable for hatchback passenger cars. The results show that the vortices which originate from the rear wheelhouses have a major impact on the aerodynamics of the underbody diffuser, which results in increasing of drag and lift of the body. For cases studied, the average drag and lift increment due to the addition of wheels were (ΔcD)mean = 0.058, respectively (ΔcL)mean = 0.243. The lift of the body on wheels decreases with both diffuser length and diffuser angle, and there are situations when it may become negative as for a body without wheels. The results show also the possibility to reach a minimum drag according with normalised diffuser length."
journal_title,International Journal of Automotive Technology
article_title,Development of knowledge based body structure concept design model
keyword,"['Body structure design\xa0', 'Knowledge based design\xa0', 'Conceptual design\xa0', 'What-if design\xa0', 'Cross-section database\xa0']"
history,"['2017-06', '2017-04-01', '2016-02-12', '2016-08-10', '2016-09-23']"
abstract,"Abstract The purpose of this study is to propose a concept design process for an automotive body structure using technical information on the major joints and members of vehicles. First, in order to collect the technical information on major joints and members, 17 vehicles were selected using benchmark data. The collected technical information for the selected vehicles was the cross sectional shapes of each joint and member which were used for the analysis of joint stiffness, crashworthiness and static stiffness of the member to make a database along with cross section properties. This study applied a ‘What If Study’ technique to perform a concept design of an automotive body using the analyzed information and selected cross section meeting the design objectives. The criteria for the selection of the cross section were defined by subdividing the defined design objectives of an automotive body structure and constraints into members and joints. In order to configure an analysis model of an automotive body structure using the selected cross section, a shape parametric model was used and static stiffness, dynamic stiffness and crashworthiness were assessed to evaluate the configured automotive body structure. The evaluation result showed that the crashworthiness and static/dynamic stiffness were improved compared to an existing body structure. In addition, the weight of the body structure was reduced. Through this study, the process that can rapidly and effectively derive and evaluate the concept design of an automotive body structure was defined. It is expected that, henceforth, this process will be helpful for the study of automotive body structures."
journal_title,International Journal of Automotive Technology
article_title,Simulation of mixed gas formation for a spray-wall complex guided LPG direct injection engine
keyword,"['LPG\xa0', 'Spray-wall complex guided\xa0', 'Direct injection engine\xa0', 'Air-fuel ratio\xa0', 'Simulation\xa0']"
history,"['2017-06', '2017-04-01', '2016-07-14', '2016-10-10', '2016-11-03']"
abstract,"Abstract To obtain an ultralean air-fuel ratio and to reduce engine-out NOX and HC emissions induced by the richer mixture near the spark plug, a spray and wall complex guided combustion system has been developed by utilizing the fuel characteristics of LPG. The new combustion system configuration is optimized by using a commercial CFD code, FIRE V2013, and the reliability of the system has been experimentally demonstrated by Plane Laser-Induced Fluorescence (PLIF). The mixture formation in the new combustion system under part load (2,000 rpm) is numerically simulated. With an injection timing of 40°CA BTDC, the LPG spray which is injected from two upper holes, reaches the ignition point, and the other part of the LPG spray which is injected from the bottom hole, is directed to the ignition point through the vertical vortices at the same time. At the ignition timing of about 20°CA BTDC, the two-part mixtures have been shown to form a stable and richer stratified mixture around the ignition point, and the maximum global air-fuel ratio reaches to 60: 1."
journal_title,International Journal of Automotive Technology
article_title,Lateral handling improvement with dynamic curvature control for an independent rear wheel drive EV
keyword,"['Direct yaw-moment control\xa0', 'Dynamic curvature\xa0', 'Stability\xa0', 'Handling\xa0']"
history,"['2017-06', '2017-04-01', '2015-08-07', '2015-12-19', '2016-06-27']"
abstract,"Abstract The integrated longitudinal and lateral dynamic motion control is important for four wheel independent drive (4WID) electric vehicles. Under critical driving conditions, direct yaw moment control (DYC) has been proved as effective for vehicle handling stability and maneuverability by implementing optimized torque distribution of each wheel, especially with independent wheel drive electric vehicles. The intended vehicle path upon driver steering input is heavily depending on the instantaneous vehicle speed, body side slip and yaw rate of a vehicle, which can directly affect the steering effort of driver. In this paper, we propose a dynamic curvature controller (DCC) by applying a the dynamic curvature of the path, derived from vehicle dynamic state variables; yaw rate, side slip angle, and speed of a vehicle. The proposed controller, combined with DYC and wheel longitudinal slip control, is to utilize the dynamic curvature as a target control parameter for a feedback, avoiding estimating the vehicle side-slip angle. The effectiveness of the proposed controller, in view of stability and improved handling, has been validated with numerical simulations and a series of experiments during cornering engaging a disturbance torque driven by two rear independent in-wheel motors of a 4WD micro electric vehicle."
journal_title,International Journal of Automotive Technology
article_title,Logical control approach to fuel efficiency optimization for commuting vehicles
keyword,"['Fuel efficiency improvement\xa0', 'Gearshift strategy\xa0', 'Stochastic logic dynamical system\xa0', 'Finite horizon optimization\xa0', 'Commuting vehicles\xa0']"
history,"['2017-06', '2017-04-01', '2015-10-05', '2016-08-08', '2016-11-29']"
abstract,"Abstract A novel gearshift control approach for improving the fuel efficiency of the conventional commuting vehicles is addressed in this paper, where the optimization problem for gear control is formulated in the framework of stochastic logical dynamic system. By extracting the stochastic features of the driver acceleration intention in the specific route, the Markov process model is deduced and then applied for the optimization algorithm. Based on the logical system framework, the finite horizon optimization problem is solved by means of the algebraic expression of the dynamic programming algorithm with a lower computational complexity, thereby resulting in an optimal gearshift decision law in statistical sense. The software simulation and engine-in-the-loop based experiment results demonstrate the better fuel economy performance can be achieved by the proposed logic control scheme."
journal_title,International Journal of Automotive Technology
article_title,Model-based fault detection and isolation in automotive yaw moment control system
keyword,"['Fault detection and isolation\xa0', 'Actuator-plant system\xa0', 'Automotive yaw moment control\xa0', 'Robust observer\xa0', 'Adaptive observer\xa0']"
history,"['2017-06', '2017-04-01', '2016-01-11', '2016-08-05', '2016-10-28']"
abstract,"Abstract This paper presents a model-based fault detection and isolation technique for automotive yaw moment control system. For this purpose, a novel fault detection and isolation algorithm for a class of actuator-plant systems is proposed. Compared with the existing fault detection and isolation techniques that can only isolate a target fault or require multiple observers to isolate multiple faults, a unique strength of the proposed algorithm is its ability to isolate faults at the component level solely based on the residuals generated by a single observer. The validity of the proposed algorithm, applied to automotive yaw moment control system, is investigated via a simulation study based on a realistic vehicle dynamics model. The results suggest that the proposed algorithm can isolate the component subject to fault while effectively handling two perennial nuisances: sensitivity to disturbances and false alarms due to uncertainties."
journal_title,Journal of Archaeological Research
article_title,"Correction to: Urbanization in Iron Age Europe: Trajectories, Patterns, and Social Dynamics"
keyword,[]
history,"['2018-06', '2018-03-02']"
abstract,None
journal_title,Journal of Archaeological Research
article_title,New Research on the Late Prehistoric Coastal Polities of Northern Peru
keyword,"['North coast\xa0', 'Late Intermediate period\xa0', 'Chimú\xa0', 'Lambayeque\xa0', 'Sicán\xa0', 'Casma\xa0']"
history,"['2018-06', '2017-08-05']"
abstract,"Abstract Previously, the Chimú empire was thought to have dominated the north coast of Peru during the Late Intermediate period, virtually to the exclusion of other polities. However, new research on sites from this period has not only changed perspectives on the Chimú, but also shed light on two other important coastal polities: the Lambayeque/Sicán and the Casma, providing insights with the potential to reshape our understanding of the development of urbanism and the Andean state. This article presents a critical summary of recent literature, fieldwork, and discoveries. Analyses of these new data address a wide range of topics that can be loosely grouped into four major areas: complexity in political organization and the geopolitical landscape, variations in the urban environment, the intensification of trade and exchange, and dynamic expressions of religion and ideology. The latest interpretation of the north coast Late Intermediate period is a story of three major, competing polities that were eventually subsumed under one."
journal_title,Journal of Archaeological Research
article_title,"Astronomy, Architecture, and Landscape in Prehispanic Mesoamerica"
keyword,"['Mesoamerica\xa0', 'Archaeology\xa0', 'Archaeoastronomy\xa0', 'Architecture\xa0', 'Urbanism\xa0', 'Orientations\xa0']"
history,"['2018-06', '2017-08-09']"
abstract,"Abstract This article synthesizes recent advances in the study of astronomy and worldview in architectural and urban planning in Mesoamerica. Throughout most of this cultural area, the practice of orienting civic and ceremonial buildings followed similar principles, although regional and time-dependent variations are present. Analysis of alignment data has revealed the existence of distinct and widespread orientation groups; most refer to sunrises and sunsets on particular dates, although two groups can be related to lunar and Venus extremes. Astronomically relevant directions frequently dominate considerable parts of urban layouts. The orientation and the location of important buildings often were conditioned by astronomical criteria and beliefs about specific landscape features; particularly notable are structures that were aligned to prominent mountaintops on the local horizon. Based on a variety of contextual data, I interpret the uses and significance of orientations in terms of agricultural concerns, cosmological concepts, and political ideology. I outline the evolution of orientation practices, drawing attention to pan-Mesoamerican trends, regional patterns, and diffusion processes."
journal_title,Journal of Archaeological Research
article_title,"Urbanization in Iron Age Europe: Trajectories, Patterns, and Social Dynamics"
keyword,"['Urbanization\xa0', 'Temperate Europe\xa0', 'Iron Age\xa0', None, 'Open settlements\xa0', None]"
history,"['2018-06', '2017-08-17']"
abstract,"Abstract The development of the first urban centers is one of the most fundamental phenomena in the history of temperate Europe. New research demonstrates that the earliest cities developed north of the Alps between the sixth and fifth centuries BC as a consequence of processes of demographic growth, hierarchization, and centralization that have their roots in the immediately preceding period. However, this was an ephemeral urban phenomenon, which was followed by a period of crisis characterized by the abandonment of major centers and the return to more decentralized settlement patterns. A new trend toward urbanization occurred in the third and second centuries BC with the appearance of supra-local sanctuaries, open agglomerations, and finally the fortified oppida. Late Iron Age settlement patterns and urban trajectories were much more complex than traditionally thought and included manifold interrelations between open and fortified sites. Political and religious aspects played a key role in the development of central places, and in many cases the oppida were established on locations that already had a sacred character as places for rituals and assemblies. The Roman conquest largely brought to an end Iron Age urbanization processes, but with heterogeneous results of both abandonment and disruption and also continuity and integration."
journal_title,Journal of Archaeological Research
article_title,Geoarchaeology in China: Historical Trends and Future Prospects
keyword,"['Geoarchaeology\xa0', 'China\xa0', 'History of science\xa0', 'Scientific archaeology\xa0']"
history,['2018-03-05']
abstract,"Abstract Over the past century, the integration of earth science methods and concepts into archaeology has fundamentally changed the nature of archaeological inquiry to include studies that focus on archaeological site formation processes, landscape evolution, and human–environmental interactions. However, the development of geoarchaeology—the interdisciplinary field of earth science and archaeology—was not an inevitability; rather, it was mediated through individuals and institutions. We attempt to isolate core institutional components that facilitated the integration of earth science and archaeology by discussing the development of a geoarchaeological research tradition outside a Western context. Here, we examine the historical trends and future prospects of geoarchaeological research in China. As archaeology becomes more global and diverse, understanding the factors that have historically combined the fields of earth science and archaeology is a necessary prerequisite for catalyzing interdisciplinary research. We argue that China’s increasingly flexible research culture, greater access to scientific methods, and long history of international and interdisciplinary collaboration have contributed to the expansion of the geoarchaeological community. In conclusion, we suggest that institutional flexibility, international exchanges, and training across disciplines are essential ingredients that foster interdisciplinary research in archaeological inquiry."
journal_title,Journal of Archaeological Research
article_title,"Looking Forward, Looking Back"
keyword,[]
history,"['2018-03', '2017-11-23']"
abstract,None
journal_title,Journal of Archaeological Research
article_title,Different Trajectories in State Formation in Greater Mesopotamia: A View from Arslantepe (Turkey)
keyword,"['State formation\xa0', 'Greater Mesopotamia\xa0', 'Political economy\xa0', 'Social hierarchies\xa0', 'Urbanization\xa0', 'Arslantepe palace\xa0']"
history,"['2018-03', '2017-06-28']"
abstract,"Abstract Long-term excavations at Arslantepe, Malatya (Turkey), have revealed the development, in the fourth millennium BC, of a precocious palatial system with a monumental building complex, sophisticated bureaucracy, and a strong centralization of economic and political power in a nonurban site. This paper reconsiders, in comparative terms, the main features and organization of the earliest states in Greater Mesopotamia. By looking at the social and economic foundations of the emergence of hierarchies and unequal relations, the dynamics and degrees of urbanization, and the role of ideology, I highlight the common aspects and the diversified trajectories of state formation and outcomes in three main core regions—southern Mesopotamia, northern Mesopotamia, and Upper Euphrates valley."
journal_title,Journal of Archaeological Research
article_title,Ancient Biological Invasions and Island Ecosystems: Tracking Translocations of Wild Plants and Animals
keyword,"['Invasive species\xa0', 'Historical ecology\xa0', 'Interdisciplinary methods\xa0', 'Anthropocene\xa0', 'Environmental archaeology\xa0']"
history,"['2018-03', '2017-06-30']"
abstract,"Abstract Biological invasions are one of the great threats to Earth’s ecosystems and biodiversity in the Anthropocene. However, species introductions and invasions extend deep into the human past, with the translocation of both wild and domestic species around the world. Here, we review the human translocation of wild plants and animals to the world’s islands. We focus on establishing criteria used to differentiate natural from human-assisted dispersals and the differences between non-native and invasive species. Our study demonstrates that, along with a suite of domesticates, ancient people transported numerous wild plants and animals to islands and helped shape ecosystems in ways that have important ramifications for modern conservation, restoration, and management."
journal_title,Journal of Archaeological Research
article_title,Studying Figurines
keyword,"['Mesoamerica\xa0', 'Households\xa0', 'Everyday life\xa0', 'Animation\xa0', 'Practice\xa0', 'Performance\xa0', 'Ancestors\xa0']"
history,['2018-02-28']
abstract,"Abstract Earlier generations of Mesoamerican scholars created figurine types and chronologies, laying the foundation for today’s archaeologists who have been linking figurines to household archaeology, gender studies, performance, materiality, embodiment, animism, political economy, agency, and identity. Scholars are establishing a figurine’s life history from clay procurement to manufacture, manipulation, and circulation; assessing the changes over time in the meaning and function of handmade and mold-made figurines; reembedding figurines into the dynamic, social, and animate world from which they emanated; and linking figurines to associated artifacts in the house, courtyards, caches, burials, and neighborhood middens."
journal_title,Journal of Archaeological Research
article_title,“Every Tradesman Must Also Be a Merchant”: Behavioral Ecology and Household-Level Production for Barter and Trade in Premodern Economies
keyword,"['Exchange\xa0', 'Barter\xa0', 'Trade\xa0', 'Central place foraging\xa0', 'Missing-markets\xa0', 'Economic anthropology\xa0', 'Human behavioral ecology\xa0']"
history,['2018-02-28']
abstract,"Abstract While archaeologists now have demonstrated that barter and trade of material commodities began in prehistory, theoretical efforts to explain these findings are just beginning. We adapt the central place foraging model from behavioral ecology and the missing-market model from development economics to investigate conditions favoring the origins of household-level production for barter and trade in premodern economies. Interhousehold exchange is constrained by production, travel and transportation, and transaction costs; however, we predict that barter and trade become more likely as the number and effect of the following factors grow in importance: (1) local environmental heterogeneity differentiates households by production advantages; (2) preexisting social mechanisms minimize transaction costs; (3) commodities have low demand elasticity; (4) family size, gender role differentiation, or seasonal restrictions on household production lessen opportunity costs to participate in exchange; (5) travel and transportation costs are low; and (6) exchange opportunities entail commodities that also can function as money. Population density is not a direct cause of exchange but is implicated inasmuch as most of the factors we identify as causal at the household level become more salient as population density increases. We review archaeological, ethnohistoric, and ethnographic evidence for premodern marketing, observing that the model assumptions, variables, and predictions generally receive preliminary support. Overall, we argue that case study and comparative investigation of the origins of marketing will benefit from explicit modeling within the framework of evolutionary anthropology."
journal_title,Journal of Archaeological Research
article_title,"Northwest Mexico: The Prehistory of Sonora, Chihuahua, and Neighboring Areas"
keyword,"['Casas Grandes\xa0', 'Cerro de Trincheras\xa0', 'Huatabampo\xa0', 'Paquimé\xa0', 'Río Sonora\xa0', 'Serrana\xa0', 'Trincheras\xa0']"
history,"['2017-12', '2017-02-10']"
abstract,"Abstract This article surveys research in Northwest Mexico (Sonora and Chihuahua), with an emphasis on the Early Agricultural period to the Late Prehistoric period. Middle range societies that are diverse in scale and organization characterize this region. Significant advancements in our understanding of these societies have been made in recent years, but substantial challenges remain in building interpretative frameworks that account for both regional diversity and incorporate macroscale interactions. Topics covered in this review include the adoption of agriculture, population movements, bases of social differentiation, and interactions between organizationally disparate groups. These issues demonstrate the relevance of the Northwest to research on the organization of middle range societies."
journal_title,Journal of Archaeological Research
article_title,Foodways Archaeology: A Decade of Research from the Southeastern United States
keyword,"['Feasts\xa0', 'Gender\xa0', 'Socioeconomic status\xa0', 'Food security\xa0']"
history,"['2017-12', '2017-02-15']"
abstract,"Abstract Interest in the study of foodways through an archaeological lens, particularly in the American Southeast, is evident in the abundance of literature on this topic over the past decade. Foodways as a concept includes all of the activities, rules, and meanings that surround the production, harvesting, processing, cooking, serving, and consumption of food. We study foodways and components of foodways archaeologically through direct and indirect evidence. The current synthesis is concerned with research themes in the archaeology of Southeastern foodways, including feasting, gender, social and political status, and food insecurity. In this review, I explore the information that can be learned from material remains of the foodstuffs themselves and the multiple lines of evidence that can help us better understand the meanings, rituals, processes, and cultural meanings and motivations of foodways."
journal_title,Journal of Archaeological Research
article_title,Paleoenvironmental Reconstruction from Faunal Remains: Ecological Basics and Analytical Assumptions
keyword,"['Ecological tolerances\xa0', 'Paleoclimate\xa0', 'Paleoenvironmental reconstruction\xa0', 'Paleozoology\xa0', 'Taxonomic identification\xa0', 'Zooarchaeology\xa0']"
history,"['2017-12', '2017-02-10']"
abstract,"Abstract Paleozoologists have long used taxa represented by ancient faunal remains to reconstruct paleoenvironments. Those ancient environments were the selective contexts in which hominin biological and cultural evolution took place. Knowing about those particularistic selective environments and how organisms responded to them is increasingly seen as critically important to identifying both how biota will respond to future (to some degree anthropogenically driven) environmental change, and biological conservation and management applications that will ensure sustainability of ecological resources and services. Reconstructing paleoenvironments requires knowledge of species’ ecological tolerances, geographic ranges, habitats, environments, and niches. It also requires assumptions that extant species had the same ecological tolerances in the past as they do today and that changes in taxonomic composition or abundances reflect environmental change rather than sampling or taphonomic factors. Greater knowledge of ecological processes as well as increased analytical sophistication in paleozoology is providing increasingly rigorous and detailed insights to paleoenvironments."
journal_title,Journal of Archaeological Research
article_title,Early Complex Society on the North and Central Peruvian Coast: New Archaeological Discoveries and New Insights
keyword,"['Andean archaeology\xa0', 'Coastal Peru\xa0', 'Iconography and society\xa0', 'Emergent complexity\xa0', 'Chavín\xa0', 'Sechín Alto polity\xa0']"
history,['2017-11-27']
abstract,"Abstract Archaeological data from the north and central Peruvian coast are presented here as a means to explore key themes relating to social complexity, including complex society and its origins, newly resolved chronological issues, the relationship between iconography and society, and the definition of a new culture. Focusing on an early time span, from ca. 3000 to 200 cal BC, we identify key questions about the trajectory through which early Andean complexity developed, and we discuss new ideas about the chronological placement of Cerro Sechín and Chavín de Huántar. We also use an intertextual approach to study the iconography of the complex Sechín Alto polity and as a means to demonstrate duality, social hierarchy, and the origin of symbols within the society’s iconography. Finally, we highlight a newly described polity, centered in the Nepeña Valley, that is important because its urban traits presage later cultural complexity and because the recognition of this polity demonstrates the potential for similar discoveries of comparable small polities."
journal_title,Journal of Archaeological Research
article_title,NEARCHOS. Networked Archaeological Open Science: Advances in Archaeology Through Field Analytics and Scientific Community Sharing
keyword,"['Digital archaeology\xa0', 'Open access\xa0', 'Data sharing\xa0', 'Cyber-infrastructure\xa0', 'Archaeological method and theory\xa0']"
history,['2017-11-13']
abstract,"Abstract The full release and circulation of excavation results often takes decades, thus slowing down progress in archaeology to a degree not in keeping with other scientific fields. The nonconformity of released data for digital processing also requires vast and costly data input and adaptation. Archaeology should face the cognitive challenges posed by digital environments, changing in scope and rhythm. We advocate the adoption of a synergy between recording techniques, field analytics, and a collaborative approach to create a new epistemological perspective, one in which research questions are constantly redefined through real-time, collaborative analysis of data as they are collected and/or searched for in an excavation. Since new questions are defined in science discourse after previous results have been disseminated and discussed within the scientific community, sharing evidence in remote with colleagues, both in the process of field collection and subsequent study, will be a key innovative feature, allowing a complex and real-time distant interaction with the scholarly community and leading to more rapid improvements in research agendas and queries."
journal_title,Journal of Archaeological Research
article_title,“Elephants for Want of Towns”: Archaeological Perspectives on West African Cities and Their Hinterlands
keyword,"['West Africa\xa0', 'Cities\xa0', 'Hinterlands\xa0', 'Urbanism\xa0', 'Long-distance trade\xa0', 'Multiscalar\xa0']"
history,['2017-11-10']
abstract,"Abstract Sub-Saharan Africa has long been seen as lacking the potential for autochthonous urban development, and Near Eastern and European contact provided ready explanations for the emergence of precolonial cities across the continent. In the past few decades, the pace of archaeological work on African cities has accelerated, and archaeologists have increasingly deployed a functional model of the city, in which cities are defined in relation to broader hinterlands rather than particular traits. As a result, deeply rooted urban traditions have been identified in all corners of the continent. Despite the antiquity of urban traditions across Africa, however, long-distance forces clearly had wide-reaching impacts on urban developmental trajectories, and proponents of the functional model have yet to explain the specific role of long-distance forces in the process of urbanization. This review examines how multiscalar forces shaped urban trajectories in West Africa, specifically. I examine how local political entrepreneurs took advantage of the opportunities provided by local, interregional, and global forces, resulting in a heterogeneous set of urban traditions across West Africa, ranging from trading entrepôts to regional capitals. Throughout I emphasize how local agency articulated with multiscalar social and economic forces, transforming the nature of regional integration, economic specialization, and the materialization of social difference, defining qualities of urban life."
journal_title,Journal of Archaeological Research
article_title,Archaeology and Inka Origins
keyword,"['Inka\xa0', 'Empire\xa0', 'Historiography\xa0', 'State formation\xa0']"
history,['2017-10-17']
abstract,"Abstract The recent proliferation of Andean archaeological research presents new interpretive opportunities for reconstructing different aspects of Inka origins. Early colonial historiography reveals that “Inka origins” refers to multiple aspects of the past, including the first appearance of Andean people, Inca ancestors, and the imperial title. The intellectual history of Inka archaeology demonstrates the lasting influence of Spanish colonial interpretive values, even with the gradual introduction of new scientific methods during the 20th century. Since 1970, significant advances in the archaeology of Cuzco, the Inka capital region, and other parts of the Andes have established an independent database that highlights the long-term and regional aspect of Inka origins, as well as areas where interpretive questions remain. The shift from colonial chronicles to archaeological data improves the accuracy of reconstructions of Inka origins, but it also raises some epistemological questions for the future relationships between history and archaeology in the study of ancient empires."
journal_title,Journal of Archaeological Research
article_title,Archaeological Studies of Cooking and Food Preparation
keyword,"['Cooking\xa0', 'Food preparation\xa0', 'Cuisine\xa0', 'Practice\xa0', 'Agency\xa0', 'Gender\xa0']"
history,['2017-10-06']
abstract,"Abstract Foodways have been a component of archaeological research for decades. However, cooking and food preparation, as specific acts that could reveal social information about life beyond the kitchen, only became a focus of archaeological inquiry more recently. A review of the literature on cooking and food preparation reveals a shift from previous studies on subsistence strategies, consumption, and feasting. The new research is different because of the social questions that are asked, the change in focus to preparation and production rather than consumption, and the interest in highlighting marginalized people and their daily experiences. The theoretical perspectives the literature addresses revolve around practice, agency, and gender. As a result, this new focus of archaeological research on cooking and preparing food is grounded in anthropology."
journal_title,Journal of Archaeological Research
article_title,"Caracol, Belize, and Changing Perceptions of Ancient Maya Society"
keyword,"['Urbanism\xa0', 'Maya\xa0', 'Mesoamerica\xa0', 'Epigraphy\xa0', 'Classic period\xa0']"
history,"['2017-09', '2016-12-30']"
abstract,"Abstract Archaeological research at Caracol, an ancient Maya site that was rediscovered in 1937, has become a major resource in the interpretation and understanding of the ancient Maya. Caracol, in west-central Belize, is situated in a subtropical region once characterized as being unsuitable for the development or maintenance of complex societies, yet it is one of the largest, if not the largest Classic period Maya site in the southern Maya Lowlands, home to over 100,000 people at its height between AD 600 and 700. The investigations at Caracol underscore the utility of long-term archaeological projects incorporating large-scale settlement study that combine excavation with varied research designs and the use of a contextual approach. By employing Maya epigraphic history, traditional archaeology, and modern technology like LiDAR, research at Caracol details the rise, maintenance, and fall of an ancient Maya city, affording a large window into ancient Maya lifeways. Archaeological work provides evidence of sustainable agriculture, a market economy, city planning that included a road system, the impact of warfare on the site’s inhabitants, the sociopolitical status of women, the role that archaeology can play in refining written history, and the significance of commemorating the cyclical passage of time to the ancient Maya. This article summarizes archaeological research efforts at the site by the Caracol Archaeological Project over the last three decades."
journal_title,Journal of Archaeological Research
article_title,"Emergent Complexity, Changing Landscapes, and Spheres of Interaction in Southeastern South America During the Middle and Late Holocene"
keyword,"['South America\xa0', 'Río de la Plata\xa0', 'Early Formative\xa0', 'Emergent complexity\xa0', 'Landscapes\xa0', 'Community patterns\xa0', None]"
history,"['2017-09', '2016-12-30']"
abstract,"Abstract Newly created academic programs at Brazilian universities have provided the impetus for new archaeological projects in southeastern South America during the last two decades. The new data are changing our views on emergent social complexity, natural and human-induced transformation of the landscape, and transcontinental expansions and cultural interactions across the Río de la Plata basin during the Middle and Late Holocene. We concentrate on six major archaeological traditions/regions: the Sambaquis, the Pantanal, the Constructores de Cerritos, the Tupiguarani, the Southern Proto-Jê, and the middle and lower Paraná River. Diverse and autonomous complex developments exhibit distinct built landscapes in a region previously thought of as marginal compared with cultural developments in the Andes or Mesoamerica. The trajectories toward increased sociopolitical complexity flourished in very different and changing environmental conditions. While some groups were pushed to wetland areas during a drier mid-Holocene, others took advantage of the more humid Late Holocene climate to intensively manage Araucaria forests. The start of the second millennium AD was a critical period marked by an increased number of archaeological sites, the construction of ceremonial architecture, and the intensification of landscape transformation; it also was marked by the rapid expansion of influences from outside the La Plata basin. The Amazonian Tupiguarani and Arawak newcomers brought with them significant changes in technologies and social and political structures, as well as novel landscape management practices."
journal_title,Journal of Archaeological Research
article_title,Trade and Power in Ancient Egypt: Middle Egypt in the Late Third/Early Second Millennium BC
keyword,"['Ancient states\xa0', 'Local powers\xa0', 'Middle Egypt\xa0', 'Middle Bronze Age\xa0', 'Mobile populations\xa0', 'Trade\xa0']"
history,"['2017-06', '2016-10-18']"
abstract,"Abstract Middle Egypt provides a unique insight into the organization of power, politics, economy, and culture at the turn of the third millennium BC. The apparently easy integration of this region into the reunified monarchy of king Mentuhotep II (2055–2004 BC) was possible because the interests and the local lineages of potentates were preserved. Trade and access and/or control of international exchange networks were important sources of wealth and power then. And Middle Egypt appears as a crossroads of diverse populations, as a hub of political and economic power, as a crucial node of exchanges through the Nile Valley, and as a power center whose rulers provided support to the monarchy in exchange of local autonomy and considerable political influence at the Court. In the new conditions of early second millennium, potentates from Middle Egypt succeeded in occupying a unique advantageous position, not matched elsewhere in Egypt, because of the concentration of wealth, trade routes, new technologies, political power, and autonomy in the territories they ruled."
journal_title,Journal of Archaeological Research
article_title,Bioarchaeology and the Skeletons of the Pre-Columbian Maya
keyword,"['Maya\xa0', 'Demography\xa0', 'Health\xa0', 'Diet\xa0', 'Mobility\xa0', 'Embodiment\xa0', 'Violence\xa0', 'Ritual practice\xa0']"
history,"['2017-06', '2016-10-19']"
abstract,"Abstract This review explores the past two decades of research on ancient Maya skeletons. The focus is on how this work has contributed to our understanding of health, diet, social change, inequality, migration and mobility, war, violence, and ritual practice, with special attention given to recent methodological developments and debates in the bioarchaeology of the Maya. This review essay highlights the most recent findings in the bioarchaeology of the Maya and how those results were achieved. The essay concludes with suggestions for future research and highlights areas of potential collaboration that have been underutilized to address broader anthropological questions."
journal_title,Journal of Archaeological Research
article_title,Erratum to: Household Archaeology in Polynesia: Historical Context and New Directions
keyword,[]
history,"['2017-03', '2016-10-21']"
abstract,None
journal_title,Journal of Archaeological Research
article_title,Political Economies of Predynastic Egypt and the Formation of the Early State
keyword,"['State formation\xa0', 'Predynastic\xa0', 'Naqada culture\xa0', 'Abydos\xa0', 'Invention of writing\xa0']"
history,"['2017-03', '2016-08-31']"
abstract,"Abstract Considered one of the world’s earliest examples of a pristine state, the ancient Egyptian state arose by ca. 3000 BC. State formation in Egypt became a focus of much research in the 1970s and 1980s, as investigations of the Predynastic period in Egypt, when complex society arose there, began to uncover new evidence of the indigenous roots of this phenomenon. More recently, archaeological investigations in the Delta as well as continued work in southern Egypt have provided new evidence for the changes that took place in the fourth millennium BC. But the specific events and processes involved in this major sociopolitical and economic transformation and the resultant state still remain incompletely understood. To better understand the problem in Egypt, this study looks at the contrasting polities in fourth millennium BC Egypt and Nubia from the perspective of the political economy and the strategies to power proposed by the dual-processual theory, which also helps elucidate processes of state formation and the type of early state that developed there. The territorial expansionist model helps explain where and when this state first emerged."
journal_title,Journal of Archaeological Research
article_title,Local and “Global” Perspectives on the Middle Woodland Southeast
keyword,"['Southeastern United States\xa0', 'Middle Woodland\xa0', 'Hopewell\xa0', 'Monumentality\xa0', 'Interaction\xa0']"
history,"['2017-03', '2016-08-03']"
abstract,"Abstract During the Middle Woodland period, from 200 BC to AD 600, southeastern societies erected monuments, interacted widely, and produced some of the most striking material culture of the pre-Columbian era, but these developments are often overshadowed by the contemporaneous florescence of Hopewell culture in Ohio. I argue that the demonstrable material links between the Middle Woodland Southeast and Midwest demand that we cease to analyze these regional archaeological records in isolation and adopt multiscalar perspectives on the social fields that emerged from and impacted local Middle Woodland societies. In synthesizing recent research on Middle Woodland settlement, monumentality, interaction, and social organization, I make explicit comparisons between the Middle Woodland Southeast and Ohio Hopewell, revealing both commonalities and contrasts. New methodological approaches in the Southeast, including geophysical survey techniques, Bayesian chronological modeling, and high-resolution provenance analyses, promise to further elucidate site-specific histories and intersite connectivity. By implementing theoretical frameworks that simultaneously consider these local and global dimensions of Middle Woodland sociality, we may establish the southeastern Middle Woodland period as an archaeological context capable of elucidating the deep history of the Eastern Woodlands as well as long-standing issues surrounding middle-range societies."
journal_title,Journal of Archaeological Research
article_title,The Egyptian Predynastic and State Formation
keyword,"['State formation\xa0', 'Social complexity\xa0', 'Neo-evolutionary theory\xa0', 'Practice theory\xa0', 'Kingship\xa0', 'Predynastic Egypt\xa0']"
history,"['2016-12', '2016-03-01']"
abstract,"Abstract When the archaeology of Predynastic Egypt was last appraised in this journal, Savage (2001a, p. 101) expressed optimism that “a consensus appears to be developing that stresses the gradual development of complex society in Egypt.” The picture today is less clear, with new data and alternative theoretical frameworks challenging received wisdom over the pace, direction, and nature of complex social change. Rather than an inexorable march to the beat of the neo-evolutionary drum, primary state formation in Egypt can be seen as a more syncopated phenomenon, characterized by periods of political experimentation and shifting social boundaries. Notably, field projects in Sudan and the Egyptian Delta together with new dating techniques have set older narratives of development into broader frames of reference. In contrast to syntheses that have sought to measure abstract thresholds of complexity, this review of the period between c. 4500 BC and c. 3000 BC transcends analytical categories by adopting a practice-based examination of multiple dimensions of social inequality and by considering how the early state may have become a lived reality in Egypt around the end of the fourth millennium BC."
journal_title,Journal of Archaeological Research
article_title,Household Archaeology in Polynesia: Historical Context and New Directions
keyword,"['Social variability\xa0', 'Status\xa0', 'Gender\xa0', 'Domestic ritual\xa0', 'Site proxemics\xa0', 'House society\xa0']"
history,"['2016-12', '2016-02-23']"
abstract,"Abstract This review highlights archaeological investigations of precontact and historic house sites in Polynesia, a region noted for its diversity of chiefdoms in terms of scale and elaboration. Anthropological and historical perceptions of the Polynesian household have shifted over time, influencing the ways in which the household has been defined in archaeology. Early research emphasized houses as a unit of study within settlement pattern archaeology and as a means of delineating formal variability between sites and communities. Current studies stress a more holistic view of the household as a nexus of economic, social, and ritual activities. Diverse theoretical perspectives, such as the analytical concept of house societies, feminist archaeologies, landscape approaches, and agent-based models, have led to new archaeological approaches engaged with both the material and the nonmaterial aspects of the house and, in particular, how social relations structure the household. Current prominent themes include functional identification of house sites, understanding social variability, articulation of the household with the community, and comparative analyses of social complexity."
journal_title,Journal of Archaeological Research
article_title,"Assembling the Iron Age Levant: The Archaeology of Communities, Polities, and Imperial Peripheries"
keyword,"['Empire\xa0', 'Ethnicity\xa0', 'Middle East\xa0', 'State\xa0']"
history,"['2016-12', '2016-03-05']"
abstract,"Abstract Archaeological research on the Iron Age (1200–500 BC) Levant, a narrow strip of land bounded by the Mediterranean Sea and the Arabian Desert, has been balkanized into smaller culture historical zones structured by modern national borders and disciplinary schools. One consequence of this division has been an inability to articulate broader research themes that span the wider region. This article reviews scholarly debates over the past two decades and identifies shared research interests in issues such as ethnogenesis, the development of territorial polities, economic intensification, and divergent responses to imperial interventions. The broader contributions that Iron Age Levantine archaeology offers global archaeological inquiry become apparent when the evidence from different corners of the region is assembled."
journal_title,Journal of Archaeological Research
article_title,"Household Craft Production in the Prehispanic Urban Setting of Mayapán, Yucatan, Mexico"
keyword,"['Multicrafting\xa0', 'Political economy\xa0', 'Postclassic Maya\xa0', 'Household archaeology\xa0', 'Urbanism\xa0', 'Market exchange\xa0']"
history,"['2016-09', '2016-02-02']"
abstract,"Abstract 
The complexity of the organization of craft production mirrors multiple aspects of the larger political economies of premodern states. At the late Maya urban center of Mayapán, variation in the social contexts of crafting within a single settlement defies simple classificatory models that once held sway in the literature of nonWestern state societies. Most surplus crafters were independent and affluent commoners; notable exceptions include artisans working under direct elite supervision or elites who were directly engaged in crafting. Although household workshops concentrated around the city’s epicenter, others were dispersed across the site in unassuming residential neighborhoods or near outlying monumental groups. We consider the significance of pronounced household and regional economic interdependencies founded on well-developed surplus crafting practices, imported raw materials, market exchange, and tribute obligations at Mayapán. As for other premodern states, craft production also gave rise to greater opportunities for wealth differentiation within the commoner class. Producers in this urban political capital contributed in significant ways to a stable political economy by supplying goods that were required at all levels of the social hierarchy."
journal_title,Journal of Archaeological Research
article_title,Pacific Islands Ichthyoarchaeology: Implications for the Development of Prehistoric Fishing Studies and Global Sustainability
keyword,"['Pacific Islands\xa0', 'Ichthyoarchaeology\xa0', 'Zooarchaeology\xa0', 'Historical ecology\xa0', 'Fisheries management\xa0']"
history,"['2016-09', '2016-02-02']"
abstract,"Abstract The Pacific Islands—consisting of culturally diverse Melanesia, Micronesia, and Polynesia—is the ideal region to investigate the development of prehistoric fishing studies, as nowhere else on Earth is there such environmental contrasts among island types and their marine environments. We review the ichthyoarchaeological literature for the Pacific and assess developments in recovery methods, reference collections, taxonomic identifications, quantification, taphonomy and site-formation processes, ethnoarchaeology, approaches to diet and subsistence reconstructions, sustainability, and the importance of applied zooarchaeology for fisheries management and conservation. Ichthyoarchaeologists are beginning to work more closely with resource managers, fisheries biologists, policy makers, and indigenous communities to produce holistic studies of conservation management, resource sustainability, and assessments of human impacts on marine ecosystems over centuries to millennial time scales."
journal_title,Journal of Archaeological Research
article_title,New World Paleoethnobotany in the New Millennium (2000–2013)
keyword,"['Paleoethnobotany\xa0', 'Archaeobotany\xa0', 'Plants\xa0', 'Macrobotanical analysis\xa0', 'Microbotanical analysis\xa0', 'New World\xa0']"
history,"['2016-06', '2015-11-28']"
abstract,"Abstract This article evaluates the current state of paleoethnobotany since Hastorf’s 1999 review published in this journal. We discuss advances in methods, ancient subsistence reconstructions, the origins and intensification of agriculture, and how plants inform on issues of political economy and identity. Significant methodological developments in the extraction, identification, and analysis of starch grains and phytoliths have led to advancements in our knowledge of early plant domestication and the transition to food production. Paleoethnobotanists increasingly are using more complex quantitative techniques to characterize their data, which have resulted in more nuanced interpretations of plants that fall within the purview of social archaeology and allow us to address issues related to gender, identity, and ritual practice."
journal_title,Journal of Archaeological Research
article_title,Recognizing and Moving on from a Failed Paradigm: The Case of Agricultural Landscapes in Anglo-Saxon England c. AD 400–800
keyword,"['Anglo-Saxon\xa0', 'Landscape\xa0', 'Agriculture\xa0', 'Migration\xa0', 'Property rights\xa0', 'Governance\xa0']"
history,"['2016-06', '2015-11-28']"
abstract,"Abstract A central preoccupation for archaeologists is how and why material culture changes. One of the most intractable examples of this problem can be found between AD 400 and 800 in the enigmatic transformation of sub-Roman into Anglo-Saxon England. That example lies at the heart of this review, explored through the case of the agricultural economy. Although the ideas critically examined below relate specifically to early medieval England, they represent themes of universal interest: the role of migration in the transformation of material culture, politics, and economy in a post-imperial world, the significance of “core” and “periphery” in evolving polities, ethnogenesis as a strategy in kingdom building, property rights as a lens for investigating cultural change, and the relationship between hierarchical political structures and collective forms of governance. The first part of my argument proposes a structured response to paradigmatic stalemate by identifying and testing each underlying assumption, premise, and interpretative framework. The recognition of any fallacies, false premises, and flawed arguments might assist with an overall evaluation of the continuing utility of a discourse—whether it has life in it yet, or should be set aside. In either case, the recognition of its structure should enable arguments to be developed that do not lead into a disciplinary cul-de-sac, prevented by the orthodoxy from exploring new avenues for research. In the second part of the review, I deliberately adopt a starting point outside the limits of the current discourse. Freed from the confines of the conventional consensus, I experiment with an alternative “bottom-up” approach to change in early medieval England that contrasts with conventional “top-down” arguments. I focus in particular on how rights over agricultural property—especially collective rights—and the forms of governance implied by them may assist in illuminating the roles of tradition and transformation in effecting cultural change."
journal_title,Journal of Archaeological Research
article_title,"Bioarchaeology and Kinship: Integrating Theory, Social Relatedness, and Biology in Ancient Family Research"
keyword,"['Bioarchaeology\xa0', 'Biodistance\xa0', 'Family\xa0', 'Kinship\xa0', 'Relatedness\xa0', 'Social identity\xa0']"
history,"['2016-03', '2015-08-01']"
abstract,"Abstract Theoretical developments in sociocultural anthropology have transformed the study of kinship. Here, we review these theoretical developments, consider their influence on bioarchaeological kinship research, and propose an alternative framework for studying relatedness in antiquity. We find that broader, more flexible conceptions of relatedness have grown increasingly prevalent in 21st-century bioarchaeology, but kinship research largely continues to emphasize methodological improvement and identification of biological kin in archaeological contexts. By approaching kinship as a multiscalar dimension of social identity, bioarchaeologists can leverage complex conceptions of relatedness with diverse types of data to gain nuanced perspectives on family-based social organization in the past."
journal_title,Journal of Archaeological Research
article_title,Teotihuacan
keyword,"['Urbanism\xa0', 'Mesoamerica\xa0', 'State formation\xa0', 'Collapse\xa0', 'Classic period\xa0']"
history,"['2016-03', '2015-08-04']"
abstract,"Abstract Teotihuacan in the northeastern Basin of Mexico was an unusually large and influential early city and state. This article reviews recent research trends in Teotihuacan from its founding and explosive growth ca. 100 BC into the largest city in Mesoamerica. Biogenetics provide details of how immigration fueled the city’s growth and shaped its multiethnic composition and link Teotihuacan to other parts of the central highlands and more distant regions. Urban theory highlights the importance of neighborhoods and how their composition changed. Collective aspects of irrigation, markets, warfare and the military, and ideology encouraged the development of Teotihuacan’s corporate governance. Although Teotihuacan politically dominated central Mexico, its control over the regional economy was not as centralized. Beyond its hinterland, Teotihuacan’s foreign relations were a mosaic of trade diasporas, diplomatic exchanges, pilgrimages, emulation, and strategic direct interventions of limited duration. As its foreign influence retracted, Teotihuacan faced challenges from its hinterlands and intermediate elites and factions that culminated in the burning and desecration of the urban center. The Epiclassic saw the change from Teotihuacan’s regional state to city-states and confederations. Although much reduced in size, Postclassic Teotihuacan retained an enormous legacy that subsequent states sought for their historical validation."
journal_title,Journal of Archaeological Research
article_title,"The Osteological Paradox 20 Years Later: Past Perspectives, Future Directions"
keyword,"['Paleopathology\xa0', 'Bioarchaeology\xa0', 'Ancient health\xa0', 'Demography\xa0', 'Sample bias\xa0', 'Mortality\xa0', 'Morbidity\xa0']"
history,"['2015-12', '2015-03-17']"
abstract,"Abstract 
More than 20 years ago, Wood et al. (Curr Anthropol 33:343–370, 1992) published “The Osteological Paradox: Problems of Inferring Prehistoric Health from Skeletal Samples,” in which they challenged bioarchaeologists to consider the effects of heterogeneous frailty and selective mortality on health inferences in past populations. Here, we review the paper’s impact on bioarchaeology and paleopathology, focusing on recent advancements in studies of ancient health. We find the paper is often cited but infrequently engaged in a meaningful way. Despite an initial decade of limited progress, numerous researchers are now addressing components of the Paradox in more informed ways. We identify four areas of fruitful research: (1) intrasite, contextual perspectives, (2) subadults, (3) associating stress markers with demographic phenomena, and (4) skeletal lesion-formation processes. Although often seen as a problematic assumption, understanding the sources of heterogeneous frailty within human populations is a worthy research question in and of itself, and one that clearly links past and present health research within a global framework."
journal_title,Journal of Archaeological Research
article_title,"Earth Systems, Human Agency, and the Anthropocene: Planet Earth in the Human Age"
keyword,"['Human–environmental impacts\xa0', 'Planetary boundaries\xa0', 'Global change\xa0', 'Archaeology\xa0']"
history,"['2015-12', '2015-08-01']"
abstract,"Abstract A proposal to designate a new geological epoch of our own making—the Anthropocene—is being considered by the International Commission on Stratigraphy (ICS), part of the International Union of Geological Sciences. Based on a set of formal criteria, there is growing consensus for a Holocene–Anthropocene boundary set at some point in the last 200 years. A number of scientists have questioned the utility of such a designation because it overlooks the millennia-long history of human impacts on the planet and fails to focus on the causes of human domination of the Earth in favor of the effects. I review these debates and synthesize a variety of proposals for an Anthropocene beginning 10,000 years ago to as little as 50. I then review a number of parallel debates focused less on the geosciences and more on the political, social, and institutional implications of the Anthropocene. I demonstrate how and why formal ICS criteria for the designation of geological time units may be inadequate for effectively meeting the underlying rationale for designating a human-induced geological epoch and the role it is currently and, potentially, will continue to play in the court of public opinion."
journal_title,Journal of Archaeological Research
article_title,The Pig and the Chicken in the Middle East: Modeling Human Subsistence Behavior in the Archaeological Record Using Historical and Animal Husbandry Data
keyword,"['Pig\xa0', 'Food prohibition\xa0', 'Chicken\xa0', 'Human subsistence\xa0', 'Middle East\xa0', 'Egypt\xa0']"
history,"['2015-12', '2015-03-13']"
abstract,"Abstract The role of the pig in the subsistence system of the Middle East has a long and, in some cases, poorly understood history. It is a common domesticated animal in earlier archaeological sites throughout the Middle East. Sometime in the first millennium, BC pig use declined, and subsequently it became prohibited in large areas of the Middle East. The pig is an excellent source of protein, but because of low mobility and high water needs, it is difficult to move long distances. While common in sites, the pig is rarely mentioned in texts. In contrast, the use of cattle, sheep, and goats is extensively documented. In the human subsistence system of the arid and semiarid areas of the Middle East, the pig was a household-based protein resource that was not of interest to the central authority. Sometime in the late second or first millennium BC, the chicken was introduced into the Middle East. The chicken is an even more ideal household-based protein resource and, like the pig, is rarely mentioned in texts. In arid and semiarid areas of the Middle East, the pig and the chicken compete for food and labor in the human subsistence system. I hypothesize that in arid and semiarid areas of the Middle East, the chicken largely replaced the pig because the chicken is a more efficient source of protein, it produces a secondary product, the egg, and it is a smaller package; hence, a family can consume one in a day or two. This made the pig redundant and available for use in other human systems. The pig, however, never disappeared from the diet of humans in the Middle East."
journal_title,Journal of Archaeological Research
article_title,A Comparison of Niche Construction Theory and Diet Breadth Models as Explanatory Frameworks for the Initial Domestication of Plants and Animals
keyword,"['Agricultural origins\xa0', 'Domestication\xa0', 'Diet breadth model\xa0', 'Optimal foraging theory\xa0', 'Niche construction theory\xa0', 'Human behavioral ecology\xa0']"
history,"['2015-09', '2015-02-21']"
abstract,"Abstract The initial domestication of plants and animals and the subsequent emergence of agricultural economies in different world regions represent a major evolutionary transition in human history. Here, two alternative and antithetical explanatory frameworks for initial domestication are compared—one based on diet breadth modeling and the other on niche construction theory. This side-by-side comparison of these two alternative explanations follows them through the basic sequence of stages involved in the scientific method: hypothesis formulation, plausibility consideration, and actual testing of the two hypothetical explanations by measuring their relative strengths with the available archaeological and paleoenvironmental data from two independent centers of domestication in the Americas—eastern North America and the Neotropics. Although focused on the question of initial domestication, this comparative analysis also addresses the broader issues of the appropriate role of theory in the development of hypotheses of past human behavior and the proper use of the scientific method in archaeological inference. Explanations based on diet breadth modeling are found to have a number of conceptual, theoretical, and methodological flaws; approaches based on niche construction theory are far better supported by the available evidence in the two regions considered."
journal_title,Journal of Archaeological Research
article_title,Current Research on the Historical Development of Northern Iroquoian Societies
keyword,"['North America\xa0', 'Great Lakes\xa0', 'Iroquoian societies\xa0', 'Multiscalar approaches\xa0', 'Settlement archaeology\xa0', 'Communities\xa0']"
history,"['2015-09', '2015-02-14']"
abstract,"Abstract The archaeological record of Northern Iroquoian peoples contributes to global questions about ethnogenesis, the emergence of settled village life, agricultural intensification, the development of complex organizational structures, and processes of cultural and colonial entanglement. In the last decade, the rapid accumulation of data and the application of contemporary theoretical perspectives have led to significant advances in Iroquoian archaeology, including new insights about how demographic, ecological, and cultural processes intersect at multiple temporal and spatial scales. Internal and external factors accelerated processes of cultural change, particularly during periods of conflict, coalescence, and encroachment. This review considers the historical development of Northern Iroquoian societies from the beginning of the Late Woodland through the colonial era. The dynamism of the settlement landscape is highlighted, together with the fluidity of sociopolitical identities."
journal_title,Journal of Archaeological Research
article_title,Is it Intensification Yet? Current Archaeological Perspectives on the Evolution of Hunter-Gatherer Economies
keyword,"['Intensification\xa0', 'Hunter-gatherer\xa0', 'Efficiency\xa0', 'Cultural evolution\xa0']"
history,"['2015-06', '2014-11-05']"
abstract,"Abstract Originally designed to explain causes of increased productivity in agricultural systems, the concept of intensification has become widely linked to hunter-gatherer archaeology. Worldwide, recent applications show that progress has been made with regard to recognizing, describing, and modeling the declining foraging efficiency predicted by traditional intensification models that take into account confounding factors like taphonomy, environmental change, and differential foraging goals. Less progress has been made in explaining intensification due to problems of identifying primacy in the environmental, demographic, technological, and social mechanisms that lead to increased production. These problems are confounded by imprecise usage of the concept “intensification,” which runs the gamut from behaviors that either increase or decrease efficiency as the means of increasing productivity. Resolving these problems hinges on unpacking the very concept of intensification as currently applied to hunter-gatherer archaeology. This requires much greater specificity with regard to efficiency and adherence to a Boserupian perspective that declining efficiency marks intensification processes. Alternative modes of increasing production that do not necessarily entail declining efficiency—specialization, diversification, and innovation—also must be taken into account to explain the evolution of hunter-gatherer economies."
journal_title,Journal of Archaeological Research
article_title,A Mosaic of Adaptation: The Archaeological Record for Mesoamerica’s Archaic Period
keyword,"['Neolithic revolution\xa0', 'Horticulture\xa0', '2200\xa0cal. BC event\xa0', 'Mesoamerica\xa0']"
history,"['2015-06', '2014-11-19']"
abstract,"Abstract Mesoamerica’s Archaic period lasted for seven millennia beginning at the end of the Younger Dryas (~8000 cal. BC). The end of this period was uneven, with the earliest ceramic-using villagers documented at 1900 cal. BC, but not until the end of the second millennium BC in the Maya lowlands. Food production progressively increased in Mesoamerica between 8000 and 1000 cal. BC but did not significantly alter a mixed foraging–horticultural adaptation. During the third and fourth millennia BC, sedentism increased around permanent sources of water with dependable aquatic resources, such as the lakes in the Basin of Mexico and the estuaries of the Gulf coast and the Soconusco region on the Pacific coast. A mosaic of different adaptations was created, with more mobile peoples inhabiting the dry highland valleys of Mexico and Guatemala and much of the Maya lowlands. I argue that the ultimate cause of both the beginning and the end of the Archaic period was a return to wet, warm, and more stable environmental conditions after the Younger Dryas and the three-century-long 2200 cal. BC “event.” Ultimate climatic causes, however, provide only a limited understanding of the past, whereas proximate causes provide a more complete picture of where, when, and how food production, sedentism, and ceramic use developed. The archaeological record provides the complex and regionally varied evidence to reconstruct the proximate processes that saw Mesoamerican peoples transform from small groups of dispersed foragers to sedentary food producers who laid the foundation on which later Mesoamerican civilizations were built."
journal_title,Journal of Archaeological Research
article_title,Middle Preclassic Interregional Interaction and the Maya Lowlands
keyword,"['Maya lowlands\xa0', 'Middle Preclassic\xa0', 'Anthropomorphic figurines\xa0', 'Emerging complexity\xa0']"
history,"['2015-03', '2014-08-28']"
abstract,"Abstract The lowland Mayas are seldom mentioned in discussions of early Mesoamerican interactions, which commonly focus on the Gulf coast Olmecs. But such connections are evidenced by the occurrence of anthropomorphic fired-clay figurines and other artifacts (including obsidian, greenstone, bark beaters, and shell), reviewed herein. Figurines co-occur with a distinctive architectural complex in the southern lowlands but are absent in the north; other artifacts are variably present north–south and east–west. These goods relate to the development of societal complexity and cosmopolitical power, and helped support the roles of nascent elites, particularly in linkages with ancestors. Their variable distributions suggest that the lowland Mayas participated, but selectively, in early interaction spheres."
journal_title,Journal of Archaeological Research
article_title,Ancestral Pueblo Archaeology: The Value of Synthesis
keyword,"['Ancestral Pueblo archaeology\xa0', 'North America\xa0', 'Neolithic/Formative societies\xa0', 'Macroregional approaches\xa0']"
history,"['2015-03', '2014-08-27']"
abstract,"Abstract Archaeologists working in the Ancestral Pueblo region of the American Southwest have documented variability in sociopolitical and economic complexity, landscape use, community organization, mobility, and violence at a wide range of temporal and spatial scales from AD 500–1700. Recent studies have a strong synthetic orientation, employ methods that track material culture, mobility, and social networks at macroregional scales, and benefit from a renewed engagement with indigenous peoples. Much of this research relies on integrating vast amounts of data from numerous academic and cultural resource management projects and demonstrates the promise of an archaeology that relies on the cumulative acquisition and sharing of data. Given the scale and depth of this research, Ancestral Pueblo archaeology is an exceptional comparative case for archaeologists considering similar processes, especially at fine temporal and wide geographical scales, in ancient farming societies across the globe."
journal_title,Journal of Archaeological Research
article_title,Erratum to: The Earliest States in China: A Long-term Trajectory Approach
keyword,[]
history,"['2014-12', '2014-04-24']"
abstract,None
journal_title,Journal of Archaeological Research
article_title,Alternative Complexities: The Archaeology of Pastoral Nomadic States
keyword,"['States\xa0', 'Complexity\xa0', 'Nomads\xa0', 'Pastoralism\xa0']"
history,"['2014-12', '2014-04-02']"
abstract,"Abstract Almost a century of systematic anthropological research on pastoral nomads has produced significant data and theory for understanding these mobile societies. Substantially less attention has been devoted to complex sociopolitical organization among pastoral nomadic groups and, in particular, to the large-scale polities referred to as nomadic confederations, states, or sometimes empires. This article reviews established ideas for how and why complex organization emerged among nomadic groups and then considers these ideas in the context of recent archaeological theory on statehood and new material evidence for pastoral nomadic prehistory. Revised conceptions of both the state and the nomad suggest that pastoral nomadic polities represent alternative forms of complex organization that were different from classic Old World states but still quite complex in unexpected ways. These organizational differences resulted from the mobile and flexible politics practiced among herding peoples and gave rise to regional polities based on spatial networking, distributed authority, and innovations in transport and exchange."
journal_title,Journal of Archaeological Research
article_title,The Earliest States in China: A Long-term Trajectory Approach
keyword,"['Chinese archaeology\xa0', 'State development\xa0', 'Long-term trajectory approach\xa0', 'Early states in North China\xa0', 'Longshan\xa0', 'Erlitou\xa0', 'Erligang\xa0']"
history,"['2014-12', '2014-03-28']"
abstract,"Abstract The origins, development, and makeup of early state societies in China have long been a favorite topic of research, though there has recently been an upsurge of attention among archaeologists in China and abroad. Research has been dominated by the identification of the Erlitou site from the early second millennium BC as the center of the earliest state in China, sometimes identified with the Xia Dynasty. Recently, several scholars have employed neo-evolutionary criteria for the identification of Erlitou society as China’s earliest state in an attempt to provide objective criteria for the traditional historiographical narrative. Overarching social and ecological models of cultural change have been severely criticized by anthropological archaeologists, and many archaeologists studying the development of ancient societies prefer to focus on individual case studies or specific institutions rather than on the state. In contrast to recent archaeological scholarship that has called for its total abandonment, we find the “state” a useful concept for understanding local trajectories as well as cross-cultural comparisons. In this article we suggest a way of incorporating the warnings against simplistic overarching models while maintaining the notion of rapid sociopolitical change associated with state formation. Based on an analysis of the long-term trajectory, we identify, in north China, two phases of rapid transformations: the first, starting around 2500 BC, when several unstable regional states evolved and declined, and the second, around 1600 BC, when an intraregional state, usually identified with the historical Shang, rapidly evolved."
journal_title,Journal of Archaeological Research
article_title,"Archaeology of Trade in the Western Indian Ocean, 300 BC–AD 700"
keyword,"['Western Indian Ocean\xa0', 'Trade\xa0', 'Exchange\xa0', 'Connectivity\xa0', 'Identity\xa0', 'Early Historic period\xa0', 'Pre-Islamic period\xa0', 'Classical period\xa0', 'Late antiquity\xa0']"
history,"['2014-12', '2014-04-02']"
abstract,"Abstract In the millennium after 300 BC, the western Indian Ocean emerged as a main hub of Old World exchange. Study of this commerce long depended on separate regional archaeologies and a handful of literary sources with Western/Roman bias. A recent surge in scholarly interest has led to a vast increase in data that has fostered a more balanced understanding of the commercial, human, and material aspects of ancient Indian Ocean trade. This review summarizes recent research on the topic and assesses its significance to wider scholarly debates on scale, organization, connectivity, agency, and social cohesion in ancient trade and exchange."
journal_title,Journal of Archaeological Research
article_title,Contributions of GIS and Satellite-based Remote Sensing to Landscape Archaeology in the Middle East
keyword,"['Middle East\xa0', 'Archaeological landscape\xa0', 'GIS\xa0', 'Satellite remote sensing\xa0', 'Ancient Near East\xa0']"
history,"['2014-09', '2014-01-18']"
abstract,"Abstract This article explores the coevolution of landscape approaches and geospatial tools in Middle Eastern archaeology. From the first aerial reconnaissance programs, archaeologists recognized the value of a view from above to address overarching human–environmental questions that underpin regional historical narratives. The diversity and density of visible remains in the landscape of the Middle East has required an integrative approach, encompassed in the perspective of landscape as a static artifact, landscape as built features, landscape as a system, and landscape as a dynamic construct, which cuts across modern political boundaries. Recent advances in geospatial tools and datasets have enabled archaeologists to make significant progress on four long-standing questions of how to (1) best document and manage rapidly disappearing ancient landscapes, (2) understand landscape formation processes, (3) identify and interpret economic, environmental, and social influences that result in long-term settlement and land use patterns, and (4) recognize and contextualize the interplay between environment and human agency in the evolution of ancient economies and transformations in socio-organizational complexity."
journal_title,Journal of Archaeological Research
article_title,Historical Archaeologies of the American West
keyword,"['American West\xa0', 'Historical archaeology\xa0', 'Aridity\xa0', 'Colonialism\xa0', 'Diaspora\xa0', 'Industrial capitalism\xa0', 'Global change\xa0', 'Landscape transformation\xa0', 'Migration\xa0']"
history,"['2014-09', '2014-01-19']"
abstract,"Abstract Historical archaeology in western North America includes a vast collection of research that underscores the region’s dynamic cultural heritage. Here, I review a sample of the literature related to this research and organize them into four conceptual themes: colonialism and postcolonialism, landscape transformation, migration and diaspora, and industrial capitalism. I conclude that the future of historical archaeology in the West will be grounded in research that integrates these themes. As the region continues to experience human dilemmas related to issues such as balancing resource extraction with sustainable conservation and lingering issues of colonialism, these archaeologies have value for transcending the nature–culture divide and for understanding the ways in which humanity can navigate pressing issues relevant to our modern world, including vulnerability, risks, adaptation, resilience, and sustainability."
journal_title,Journal of Archaeological Research
article_title,Deconstructing the Lapita Cultural Complex in the Bismarck Archipelago
keyword,"['Island Southeast Asia\xa0', 'New Guinea\xa0', 'Bismarck Archipelago\xa0', 'Lapita Cultural Complex\xa0', 'Migration\xa0', 'Interaction\xa0', 'Geographic mobility\xa0']"
history,"['2014-06', '2013-11-22']"
abstract,"Abstract Within the Pacific Islands, the archaeological phenomenon called the Lapita Cultural Complex is widely regarded as first appearing in the Bismarck Archipelago of Papua New Guinea and then spreading southward. This complex supposedly represents the sudden arrival of migrants from Island Southeast Asia with new technologies, foreign languages, and a different worldview. We question these interpretations and the assumptions behind them and suggest instead that current evidence supports the introduction of new cultural traits over several centuries, rather than the sudden intrusion of foreign migrants."
journal_title,Journal of Archaeological Research
article_title,Using Pyrotechnology: Fire-related Features and Activities with a Focus on the African Middle Stone Age
keyword,"['Southern Africa\xa0', 'Middle Stone Age\xa0', 'Pyrotechnology\xa0', 'Hearths\xa0']"
history,"['2014-06', '2013-11-22']"
abstract,"Abstract Pyrotechnology was important in prehistory and has been a research topic for decades, in particular, the origins of controlled and habitual use of fire. The earliest putative evidence of fire use is from the African sites of Swartkrans (1,500,000–1,000,000 years ago) and Koobi Fora (1,500,000 years ago). In contrast, researchers working with European sites debate whether habitual use of fire occurred before 400,000 years ago. This paper provides a brief introduction to early fire use and then focuses on the African Middle Stone Age. Published evidence on fire use is available for 34 sites in southern Africa. Combustion features yield much evidence about human behavior, not only in regard to technical skills but also concerning social activities. Several activities using fire, symbolic behavior, spatial structuring, and group size in the Middle Stone Age are inferred from bone and lithic data, ash discard, site maintenance, and hearth size. The current status of knowledge on Middle Stone Age pyrotechnology demonstrates the benefits of applying new methodological approaches, facilitates comparisons with earlier and later archaeological periods, and is an important reminder of the benefits of a multidisciplinary approach."
journal_title,Journal of Archaeological Research
article_title,"Historical Archaeology, Contact, and Colonialism in Oceania"
keyword,"['Historical archaeology\xa0', 'Colonialism\xa0', 'Oceania\xa0', 'Australasia\xa0', 'Indigenous archaeology\xa0']"
history,"['2014-03', '2013-08-03']"
abstract,"Abstract The archaeology of colonialism can destabilize orthodox historical narratives because of its critical engagement with multiple lines of evidence, revealing ways that different perspectives can complement or contradict what was assumed to be known about the past. In Oceania, archaeology that blends evidence from landscapes, sites, and artifacts with written documents as well as oral traditions reveals the role of indigenous people in shaping colonial encounters across the region over the last five centuries. The challenge lies with how to interpret this material in terms of ongoing struggles over land, resources, and identity in the region today, encapsulated by the tension between global and local."
journal_title,Journal of Archaeological Research
article_title,Exploring Adaptive Variation among Hunter-gatherers with Binford’s Frames of Reference
keyword,"['Hunter-gatherer\xa0', 'Variation\xa0', 'Frames of reference\xa0', 'Ethnographic\xa0']"
history,"['2014-03', '2013-07-30']"
abstract,"Abstract The most significant change in hunter-gatherer studies has been the shift from expecting hunter-gatherers to have similar properties wherever they are found to recognizing that hunter-gatherer adaptations should vary along many different dimensions. Although archaeologists approach research with different goals, there is remarkable convergence in our knowledge about hunter-gatherers past and present. The ethnographic record of recent hunter-gatherers reveals enormous variation along several dimensions. The specific combinations of characteristics displayed among hunter-gatherers are not infinitely variable but cluster as distinctive “system states” (following Binford, Constructing frames of reference: an analytical method for archaeological theory building using ethnographic and environmental data sets, 2001) that pattern with both environmental and demographic variables at a global scale. Frames of reference based on these generalizations have implications for what archaeologists should expect for hunter-gatherers in different environmental settings, and also for how they should change over time if regional population density generally increases. Recognizing that patterns of variation at the regional scale are different from those at the global scale, I propose a hierarchical strategy for developing expectations for variation among prehistoric hunter-gatherers that can both situate the research locale with respect to global patterns of variation and acknowledge important dimensions of variation in habitat structure that are likely to condition regional variation in hunter-gatherer mobility, subsistence, and social organization."
journal_title,Journal of Archaeological Research
article_title,Patterns of War in the Andes from the Archaic to the Late Horizon: Insights from Settlement Patterns and Cranial Trauma
keyword,"['Andes\xa0', 'Warfare\xa0', 'Settlement patterns\xa0', 'Skeletal trauma\xa0']"
history,"['2013-12', '2013-03-27']"
abstract,"Abstract Over the pre-Columbian sequence, Andean warfare ranged greatly in intensity. This review combines published information on cranial trauma and settlement patterns, which often align and clarify each other, to make an initial assessment of how severely Andean populations were affected by war over time and space. The data speak to a number of major topics in the archaeology of warfare, such as the origin of war, contrasts in state militarism, and changes in the practice of war related to social organization. Although there is considerable regional variation, two large-scale “waves” of escalated conflict that are clearly supported by the cranial trauma and settlement pattern data occurred in the Final Formative (late Early Horizon, 400 BC–AD 100) and the Late Intermediate period (AD 1000–1400)."
journal_title,Journal of Archaeological Research
article_title,Approaches to the Archaeology of Ethnogenesis: Past and Emergent Perspectives
keyword,"['Ethnogenesis\xa0', 'Ethnicity\xa0', 'Archaeology\xa0', 'Identity\xa0', 'Theory\xa0']"
history,"['2013-12', '2013-03-08']"
abstract,"Abstract Recently, interest in the archaeology of ethnogenesis has surged. This renewed interest stems from innovations in the historical study of ethnogenesis, theoretical shifts favoring multidirectional agency, and relevant contemporary sociopolitical debates. Theoretical problems surrounding the appropriateness of the social science concept of “ethnicity,” however, have made the comparative study of ethnogenesis difficult. Drawing from past and emergent perspectives adds renewed vigor to comparative studies of ethnogenesis. A methodology that integrates the different types of theory can resolve the theoretical tensions in the archaeological study of ethnogenesis."
journal_title,Journal of Archaeological Research
article_title,"Lasting Monuments and Durable Institutions: Labor, Urbanism, and Statehood in Northern Vietnam and Beyond"
keyword,"['Monumentality\xa0', 'Urbanism\xa0', 'State formation\xa0', 'Vietnamese civilization\xa0', 'Southeast Asia\xa0']"
history,"['2013-09', '2013-02-01']"
abstract,"Abstract Archaeological research on monumentality, early urbanism, and emergent statehood in Southeast Asia and Vietnam has grown dramatically in recent years, and our understanding of social evolution in Southeast Asia has moved beyond traditional models of Sinicization and Indianization. Although many researchers recognize the significance of the historic and classical states of the first and second millennia AD, the seeds of statehood and urbanism can be seen in a moated settlement pattern during the first millennium BC. The largest in this category of Iron Age settlements, the heavily fortified Co Loa site in Vietnam’s Red River Valley, is emblematic of a tradition of settlements marked by earthworks and moat systems. The scale and extent of Co Loa’s massive earthen rampart system, involving a complex construction enterprise, reflect planning and implementation by a highly centralized, multigenerational, and institutionalized authority. Dating to the last centuries BC, Co Loa represents one of the earlier ancient state-level societies in Vietnam and the wider Southeast Asian region. Ultimately, the durability of Co Loa’s institutions of power and governance is suggested by the nature of its rampart system and construction process, and a package of variables contributed to emergent complexity. In particular, the presence of a monumental system of defensive works, combined with other archaeological markers for intraregional competition and violence, underscores the potential role of warfare and physical coercion in the course of political centralization."
journal_title,Journal of Archaeological Research
article_title,Paleolithic Art: A Cultural History
keyword,"['Paleolithic art\xa0', 'Cave art\xa0', 'Portable art\xa0', 'Art history\xa0', 'Pleistocene imagery\xa0', 'Globalization\xa0']"
history,"['2013-09', '2013-01-24']"
abstract,"Abstract In this article we review the history of the terms and ideas that have been used to conceptualize Paleolithic art since the end of the 19th century. Between 1900 and 1970, prehistoric representations were typically divided into two main groups: parietal art (including rock and cave art) and portable (or mobiliary) art. This classification gave rise to asymmetrical attitudes about Paleolithic images. In particular, many portable and nonfigurative representations were overlooked while a small number of cave paintings were praised for their realism. Although the portable/parietal division has remained a popular divide among archaeologists, in the last 30 years increasing numbers of specialists have crossed the boundaries established by these categories. They have developed new frameworks within which more kinds of images are meaningfully approached and incorporated into the analysis of Paleolithic art and symbolism. The emergence of new approaches to Pleistocene imagery is the result of a number of interrelated processes, including the globalization of Paleolithic art studies, the impact of new discoveries, and the development of new approaches to art, images, and symbolism."
journal_title,Journal of Archaeological Research
article_title,Reevaluating What We Know About the Histories of Maize in Northeastern North America: A Review of Current Evidence
keyword,"[None, 'Domesticated landscapes\xa0', 'Shifting-balance theory\xa0', 'Agricultural evolution\xa0', 'Paleoethnobotany\xa0']"
history,"['2013-06', '2012-12-14']"
abstract,"Abstract The adoption of maize in northeastern North America is often seen as a catalyst for the development of settled village life. In this review we develop a theoretical framework centered on shifting-balance theory (SBT) and domesticated landscapes through which to understand the context for the adoption of maize agriculture in the Northeast. We review micro- and macrobotanical evidence and stable carbon isotope data from various sources to reevaluate maize histories and adoption trajectories. These data are coupled with contributions of subregionally significant predecessor plants, such as those constituting the Eastern Agricultural Complex, and wild rice. We find no evidence for rapid transitions to settled village life as a result of maize adoption. Maize was grown for centuries before settled village agricultural systems evolved. It was grown for a sufficiently long time that the potential for local selection leading to Northern Flint is a viable working hypothesis. We call for a refocusing of research questions and a systematic application of contemporary techniques as a means by which to strengthen future inferences based on comparative information sets."
journal_title,Journal of Archaeological Research
article_title,The Archaeology of Food and Social Inequality in the Andes
keyword,"['Archaeology of food\xa0', 'Agriculture\xa0', 'Social inequality\xa0', 'Social complexity\xa0', 'Andes\xa0']"
history,"['2013-06', '2013-01-10']"
abstract,"Abstract A comparative examination of food practices is useful for assessing the nature of diverse forms of social inequality. This article examines three key contexts in which to evaluate the relationship between social differentiation and food practices in the Andes: early complex societies, pre-Columbian states and nonstate complex societies, and colonial societies. A review of these distinct contexts suggests that social and subsistence change may follow different rhythms and that food-related differentiation, just like other forms of social differentiation, is neither consistently augmented in a scalar fashion in relation to “degrees” of social complexity, nor is it in all cases a direct indicator of economic inequality."
journal_title,Journal of Archaeological Research
article_title,"The Chinese Upper Paleolithic: Geography, Chronology, and Techno-typology"
keyword,"['China\xa0', 'Upper Paleolithic\xa0', 'Techno-typology\xa0']"
history,"['2013-03', '2012-08-24']"
abstract,"Abstract This article reviews the archaeology and chronology of the Chinese Upper Paleolithic and the human fossils attributed to this period. The onset of the Upper Paleolithic in China dates to ca. 35,000–30,000 years ago and is marked by the appearance of a few body decorations and well-shaped bone tools that were added to stone tool assemblages, including core-and-flake tools in North China and cobble tools in South China. The proliferation of blade assemblages in northwest China is interpreted as the cultural impact or the physical presence of bearers of blade industries from western Eurasia. The ensuing appearance of microblade assemblages in North China by 23,000–22,000 years ago reflects the use of local siliceous crystalline nodules by a population that recognized the advantages of this raw material. At that time in South China, prehistoric artisans continued to shape their stone objects from the available flat river cobbles. During the later part of the Chinese Upper Paleolithic (ca. 21,000–10,000 BP), foragers also made bone tools, antler objects, pottery, and shell tools, which laid the technological foundations for the early Neolithic period. One difficulty in this research is that human fossils are rare. Few are well dated and morphological, cultural, and biological interpretations are hotly debated. Our review attempts to facilitate the understanding of a poorly known period in Chinese archaeology and its place in human cultural evolution."
journal_title,Journal of Archaeological Research
article_title,Recent Advances in Mixtec Archaeology
keyword,"['Urbanism\xa0', 'Ethnohistory\xa0', 'Households\xa0', 'Regional studies\xa0', 'Mesoamerica\xa0']"
history,"['2013-03', '2012-08-11']"
abstract,"Abstract Current research in the Mixteca region of Mexico has revealed that Formative communities were as populous as in other Mesoamerican regions. Evidence of emerging social complexity is associated with the use of and access to luxury items of foreign style and/or manufacture. Research efforts draw from indigenous models to interpret data and investigate urbanism. Regional and environmental approaches, household studies, and ethnohistory are integrated to study ethnic diversity and the complex history of human occupation. The politics associated with cultural resource management and community archaeology in the Mixteca also are discussed."
journal_title,Journal of Archaeological Research
article_title,The Archaeology of Food and Social Diversity
keyword,"['Food\xa0', 'Economics\xa0', 'Politics\xa0', 'Ideology\xa0']"
history,"['2012-12', '2012-05-03']"
abstract,"Abstract This article reviews current archaeological research on the interactions between food and intrasocietal diversity. Today’s archaeology of food and diversity is theoretically diverse but generally views food as biologically necessary and cognitively prominent material culture that plays an active role in constructing and negotiating social distinctions. Areal foci in the literature include Europe, Southwest Asia, Mesoamerica, the U.S. Southwest, and the Andes; thematic emphases include economic, status, ethnic, gender, and religious distinctions. Methodological issues that must be considered when assessing the social implications of food remains include not only the contexts and characters of specific samples but also the integration of multiple data sets that may all differ with respect to their taphonomic histories and the aspects of food behavior they reflect."
journal_title,Journal of Archaeological Research
article_title,Recent Landscape Archaeology in South America
keyword,"['Landscape\xa0', 'South America\xa0', 'Built environment\xa0', 'Settlement patterns\xa0']"
history,"['2012-12', '2012-05-01']"
abstract,"Abstract South American archaeologists use the term landscape to analyze a broad range of relationships. Examples include intensive agriculture and political power, myth and place, and climate change and cultural development. Landscape archaeology is necessarily spatial analysis, but scholars work at different scales and use different methods. This essay highlights the influence of geography, anthropology, and new methodologies on four definitions of landscape: ecological habitat, built environment, a stage for performance, and integrating subsistence and settlement. In a number of cases, landscape archaeologists, stakeholders, and researchers from different traditions work at different scales to meaningfully share information, clarify their differences, and compare their analyses and conclusions."
journal_title,Journal of Archaeological Research
article_title,Inner Asian States and Empires: Theories and Synthesis
keyword,"['Empires\xa0', 'States\xa0', 'Inner Asia\xa0', 'Pastoralism\xa0']"
history,"['2012-09', '2012-01-11']"
abstract,"Abstract By 200 B.C. a series of expansive polities emerged in Inner Asia that would dominate the history of this region and, at times, a very large portion of Eurasia for the next 2,000 years. The pastoralist polities originating in the steppes have typically been described in world history as ephemeral or derivative of the earlier sedentary agricultural states of China. These polities, however, emerged from local traditions of mobility, multiresource pastoralism, and distributed forms of hierarchy and administrative control that represent important alternative pathways in the comparative study of early states and empires. The review of evidence from 15 polities illustrates long traditions of political and administrative organization that derive from the steppe, with Bronze Age origins well before 200 B.C. Pastoralist economies from the steppe innovated new forms of political organization and were as capable as those based on agricultural production of supporting the development of complex societies."
journal_title,Journal of Archaeological Research
article_title,Nothing Lasts Forever: Environmental Discourses on the Collapse of Past Societies
keyword,"['Collapse\xa0', 'Determinism\xa0', 'Environment\xa0', 'Narrative\xa0', 'Resilience\xa0']"
history,"['2012-09', '2012-01-11']"
abstract,"Abstract The study of the collapse of past societies raises many questions for the theory and practice of archaeology. Interest in collapse extends as well into the natural sciences and environmental and sustainability policy. Despite a range of approaches to collapse, the predominant paradigm is environmental collapse, which I argue obscures recognition of the dynamic role of social processes that lie at the heart of human communities. These environmental discourses, together with confusion over terminology and the concepts of collapse, have created widespread aporia about collapse and resulted in the creation of mixed messages about complex historical and social processes."
journal_title,Journal of Archaeological Research
article_title,Ethnoarchaeology and the Organization of Lithic Technology
keyword,"['Stone tools\xa0', 'Ethnoarchaeology\xa0', 'Organization of technology\xa0', 'Chaîne opératoire\xa0', 'Sequence of reduction\xa0']"
history,"['2012-06', '2012-01-07']"
abstract,"Abstract Although the modern production and use of stone tools is rare, ethnoarchaeological research on this subject has provided important perspectives on methodological approaches to archaeological lithic analysis. Recent ethnoarchaeological research on lithics frequently takes the form of “cautionary tales,” warning against the primacy of functional variables most commonly invoked by lithic analysts. I argue that lithic ethnoarchaeology would benefit from a comparative organizational framework for explaining variation in patterns of stone tool use that takes into account the predictability and redundancy of the location and timing of technological activities. Understanding the underlying causes of modern patterns of stone tool use, in turn, offers a framework for exploring sources of lithic technological variation in the archaeological record. I also argue that technological analytical perspectives, such as the chaîne opératoire and sequence of reduction approaches, can benefit from the insights gained through lithic ethnoarchaeological research, helping us define important analytical concepts and identify appropriate units of analysis."
journal_title,Journal of Archaeological Research
article_title,The Elusive Maya Marketplace: An Archaeological Consideration of the Evidence
keyword,"['Maya\xa0', 'Marketplace\xa0', 'Market economy\xa0', 'Mesoamerica\xa0', 'Trade\xa0']"
history,"['2012-06', '2012-01-04']"
abstract,"Abstract The modeling of ancient Maya economies has been a dynamic area of archaeological research in the past few decades, but in most cases there has been little attention on how goods actually changed hands. Through an overview of the literature, this paper considers marketplace exchange as one mechanism of distribution. Researchers have proposed a number of physical features and artifact characteristics that may be expected in association with marketplace activity, and new methods of data collection have been offered that can be used to build a case for marketplace exchange. What remains is the challenge of developing strategies to identify ancient Maya marketplaces convincingly through archaeological excavation."
journal_title,Journal of Archaeological Research
article_title,Where East Meets West: The Formative in Mexico’s Central Highlands
keyword,"['Mesoamerica\xa0', 'Formative period\xa0', 'Social complexity\xa0', 'Interregional interaction\xa0']"
history,"['2012-03', '2011-08-12']"
abstract,"Abstract Mexico’s Central Highlands form one of Mesoamerica’s fundamental cultural seams, a point of overlap between two traditions, one to the east and the other to the west. Although this area is usually included in the west, it can be more productively viewed as an interface, the physical space where people, goods, and ideas passed from one side to the other, and thus it holds many keys for our understanding of emerging social complexity in Mesoamerica. In reviewing the last two decades of Formative period (1500 BC–AD 100) research in this crucial territory, we focus on themes that reveal the variation and dynamism of interregional interaction, including the formation of regional traditions, exchange systems, and foreign “influence,” and others that help contextualize the events and processes of that time, like household studies and environmental degradation. We stress that this part of Mexico is undergoing relentless development so time is of the essence if we are to broaden our perspectives on social evolution in the Central Highlands. This issue cannot be resolved by rescue and salvage work because it requires long-term, interdisciplinary projects to unravel multifaceted problems."
journal_title,Journal of Archaeological Research
article_title,"The Archaeology of Tula, Hidalgo, Mexico"
keyword,"['Tula\xa0', 'Tollan\xa0', 'Toltec\xa0', 'Cities\xa0', 'Urbanism\xa0', 'Archaeology\xa0', 'Mesoamerica\xa0']"
history,"['2012-03', '2011-08-12']"
abstract,"Abstract The site of Tula, Hidalgo, Mexico, is well known for its distinctive architecture and sculpture that came to light in excavations initiated some 70 years ago. Less well known is the extensive corpus of archaeological research conducted over the past several decades, revealing a city that at its height covered an area of c. 16 km2 and incorporated a remarkably diverse landscape of hills, plains, alluvial valleys, and marsh. Its dense, urban character is evident in excavations at over 22 localities that uncovered complex arrangements of residential compounds whose nondurable architecture left relatively few surface traces. Evidence of craft production includes lithic and ceramic production loci in specific sectors of the ancient city. Tula possessed a large and densely settled hinterland that apparently encompassed the surrounding region, including most of the Basin of Mexico, and its area of direct influence appears to have extended to the north as far as San Luís Potosí. Tula is believed to have originated as the center of a regional state that consolidated various Coyotlatelco polities and probably remnants of a previous Teotihuacan-controlled settlement system. Its pre-Aztec history exhibits notable continuity in settlement, ceramics, and monumental art and architecture. The nature of the subsequent Aztec occupation supports ethnohistorical and other archaeological evidence that Tula’s ruins were what the Aztecs called Tollan."
journal_title,Journal of Archaeological Research
article_title,A Tale of Two Migrations: Reconciling Recent Biological and Archaeological Evidence for the Pleistocene Peopling of the Americas
keyword,"['Peopling\xa0', 'Colonization\xa0', 'Migration\xa0', 'Americas\xa0', 'New World\xa0']"
history,"['2011-12', '2011-03-12']"
abstract,"Abstract This article synthesizes the 2000s-era “peopling of the Americas” data drawn from molecular biology, osteology, and archaeology. Collectively, they suggest that colonization proceeded in two pulses, both originating in western Beringia, and before that, south-central and southeastern Siberia. The first pulse occurred circa 16 k–15 k cal. B.P. by watercraft along the coast of Beringia and western North and South America. The second took place 1,000 years later and involved proto-Clovis hunter-gatherers who used the ice-free corridor as a conduit south. At least eight North American sites dating as far back as the Last Glacial Maximum suggest that the peopling picture may eventually need to change to accommodate an earlier than previously thought migration through the ice-free corridor. For now, the data are not strong enough to support this scenario, but they are tantalizingly close."
journal_title,Journal of Archaeological Research
article_title,Cave Art in Context: Methods for the Analysis of the Spatial Organization of Cave Sites
keyword,"['Prehistoric cave art\xa0', 'Spatial organization\xa0', 'Landscape archaeology\xa0', 'Use of caves\xa0']"
history,"['2011-12', '2011-03-10']"
abstract,"Abstract Investigations of prehistoric cave art have long neglected the surrounding context: space, archaeological objects, and imprints. As a result, an integrative structural approach that analyzes cave art as part of an anthropomorphized landscape has not been available. This article draws on urban planning and the physiology of the human eye to provide an innovative archaeospatial analysis of cave sites. A set of relevant features from the caves of Bédeilhac, Fontanet, and Le Portel was selected and defined (light zone, chamber type, path network, mode of movement, and available space). An analysis of the prehistoric remains in the caves allows the reconstruction of different concentrations of human activities (cave art, archaeological objects, and imprints). The projection of these concentrations onto the structured map of the caves results in four types of locations: drawing location, supply location, drawing location with substantial activities, and drawing location with consumption activities. This approach opens new avenues for the archaeological perception of caves and their inhabitants: Upper Paleolithic humans were very familiar with caves and probably followed a master plan during their stay in the dark."
journal_title,Journal of Archaeological Research
article_title,World-Systems Analysis and Archaeology: Continuing the Dialogue
keyword,"['World-systems analysis\xa0', 'World-systems theory\xa0', 'Intersocietal interaction\xa0', 'Sociocultural evolution\xa0', 'Social change\xa0', 'Incorporation\xa0', 'Negotiated peripherality\xa0']"
history,"['2011-09', '2010-12-17']"
abstract,"Abstract Many archaeologists have used world-systems analysis in precapitalist settings. Some have criticized it; others have dismissed it out of hand. Critiques include that it was developed for the “modern” world, that it is overly economistic, that it neglects individual actors, and that it inappropriately uses modern analyses in ancient settings. Although there is some validity to these charges when applied to Wallerstein’s original formulation, most are misdirected. The critiques are rooted in inattention to the last three decades of work on world-systems, especially modifications made with the explicit intention to make world-systems analysis useful in precapitalist settings. Newer comparative versions of world-systems analysis were initially developed to better understand the evolution of world-systems that gave rise to the modern world-system. These new advances are useful for the study of interregional interactions and long-term development. Archaeologists are well placed to contribute to the further development of world-systems analysis; they can shed light on ancient world-systemic processes and the origins of the modern world-system, provide empirical backing for hypotheses, and raise new theoretical and empirical questions."
journal_title,Journal of Archaeological Research
article_title,The Archaeology of Native Societies in the Chesapeake: New Investigations and Interpretations
keyword,"['Chesapeake\xa0', 'Woodland period\xa0', 'Contact period\xa0', 'Descendant communities\xa0']"
history,"['2011-09', '2010-12-15']"
abstract,"Abstract Archaeological studies of Native American societies in the Chesapeake have recently incorporated a broader range of interpretive frames, including those that emphasize historical contingency and social interaction rather than cultural ecology and cultural materialism. New evidence of Woodland-period population movements, persistent places, and cycles of social ranking has prompted historically oriented interpretations that foreground particular configurations of ideology, tradition, ritual, and agency. Contact-period studies have demonstrated that native strategies of the colonial period were rooted in precontact social landscapes. Contemporary American Indians are also reclaiming their pasts in ways that challenge archaeological practices and further broaden perspectives on the Chesapeake past."
journal_title,Journal of Archaeological Research
article_title,Recent Advances in Moche Archaeology
keyword,"['Moche\xa0', 'Chronology\xa0', 'Urbanism and state formation\xa0', 'Iconography\xa0', 'Collapse\xa0']"
history,"['2011-06', '2010-11-17']"
abstract,"Abstract The discovery of the royal tombs at Sipán in 1987 propelled Moche archaeology to the forefront of Andean studies. In the last decade, the study of Moche political organization and ideology through public architecture, cultural remains, funerary patterns, and iconography has forced the revision of previous conceptions about Moche state formation, urbanism, and the functioning of this complex society. Major advances in iconography, internal organization of urban centers, temples and domestic architecture, craft production, and mortuary patterns are embedded in a new chronology that supports a longer development and a more gradual collapse. The recognition of Moche as the first state in South America is still valid, but its monolithic character is rejected in favor of several autonomous polities. The number and size of potential Moche states are currently debated, as is the role of warfare and ideology in Moche state formation."
journal_title,Journal of Archaeological Research
article_title,Advances in the Household Archaeology of Highland Mesoamerica
keyword,"['Household\xa0', 'Domestic\xa0', 'Archaeology\xa0', 'Mexico\xa0']"
history,"['2011-06', '2010-11-06']"
abstract,"Abstract Recent investigations and reconsideration of households in the Mesoamerican highlands illustrate the central role of domestic spheres of interaction to the broader cultural dynamics of the region over four millennia. Methodological advances in the analysis of past houses permit more sophisticated social reconstructions of the spaces and activities that constituted domestic life for the diverse peoples of the region. Current studies highlight the economic interdependence and diversification of households, their strategic flexibility in affiliation, the integrative ritual practices undertaken within domestic spaces, the material correlates of prestige competition between households, and the manner in which households articulated with a larger social universe."
journal_title,Journal of Archaeological Research
article_title,Dwellers by the Sea: Native American Adaptations along the Southern Coasts of Eastern North America
keyword,"['Archaeology\xa0', 'Ethnohistory\xa0', 'Coastal\xa0', 'Southeastern U.S.\xa0']"
history,"['2011-03', '2010-07-14']"
abstract,"Abstract This comparative synthesis examines archaeological and ethnohistoric data pertaining to Native American coastal adaptations along the southern coasts of the eastern United States. We consider the totality of experiences of people living along coasts, examining such issues as technological innovation, environmental variability and change as it relates to site visibility, the built environment, the use of coastal food resources, the nature of complex coastal Calusa and Guale polities, and European contact. We link our topical discussions to broader issues in anthropology, arguing that the archaeology of southern coasts has much to contribute to our understanding of worldwide adaptations to coastal environments and broad-scale shifts in the trajectories of human societies."
journal_title,Journal of Archaeological Research
article_title,Early African America: Archaeological Studies of Significance and Diversity
keyword,"['African-American archaeology\xa0', 'Slavery\xa0', 'Resistance\xa0', 'Cultural heritage\xa0']"
history,"['2011-03', '2010-07-15']"
abstract,"Abstract This article examines archaeological studies of the cultural heritage and social dynamics of African descendant populations in the United States and Canada from AD 1400 through 1865. European colonial enterprises expanded in Africa and the Americas during that time span, effecting an accompanying movement of free and captive Africans into North America. Archaeological investigations of early African America are remarkable for the diversity of analytic scales and research questions pursued. This diversity of research efforts has yielded a highly productive, interdisciplinary expansion of knowledge concerning African diaspora histories."
journal_title,Journal of Archaeological Research
article_title,The Archaeology of Historic Battlefields: A History and Theoretical Development in Conflict Archaeology
keyword,"['Geographic Information System\xa0', 'Mass Grave\xa0', 'Archaeological Record\xa0', 'Archaeological Investigation\xa0', 'Terrain Analysis\xa0']"
history,"['2011-03', '2010-07-14']"
abstract,"Abstract In the last two and a half decades there have been many advances in the technology available to archaeologists. As new technologies have been used to challenge previously held hypotheses and expand the capabilities of current research, they also have assisted the expansion of archaeology to include conflict archaeology. Although there has been a long history of interest in the material remains of conflict, it is only recently that the necessary tools, methodology, and theoretical approaches have been combined to allow serious scientific contributions to the holistic study of past human conflict. This article provides an overview of the origins of conflict archaeology and research that has helped consolidate the subfield into its present form. We examine the current state of conflict studies and consider what lies ahead for conflict archaeology."
journal_title,Journal of Archaeological Research
article_title,"Household Archaeology in the Southeastern United States: History, Trends, and Challenges"
keyword,"['Households\xa0', 'Southeastern United States\xa0', 'Status\xa0', 'Identity\xa0', 'Agency\xa0', 'Ritual\xa0', 'Production\xa0']"
history,"['2010-12', '2010-03-30']"
abstract,"Abstract This review highlights archaeological investigations of prehistoric and historic households in southeastern North America. There are a number of inherent challenges to the archaeology of households in the region, including generally poor preservation and a long history of relatively insubstantial domestic architecture. An appraisal of the historical development of household archaeology developed slowly in the Southeast, largely in reaction to trends in other areas of the world. Over the last decade, however, southeastern archaeologists have been at the vanguard of the application of new approaches to households. From an early focus on generalizable patterns of domestic activities and behavior, researchers increasingly view households as historical constructs situated within larger landscapes. Prominent areas of concern include enduring issues such as status variation, production, and consumption but also newer themes such as gender, identity and ethnicity, agency and power, and ritual and symbolism. Some of the most innovative studies explore the intersections of these topics. Conceptual and methodological challenges remain, but the household endures as a practical and productive focus of analysis and interpretation for southeastern archaeologists more than 30 years after household research in the area began."
journal_title,Journal of Archaeological Research
article_title,"Cycles of Civilization in Northern Mesopotamia, 4400–2000 BC"
keyword,"['Mesopotamia\xa0', 'Complex society\xa0', 'Urbanism\xa0', 'Collapse\xa0']"
history,"['2010-12', '2010-03-24']"
abstract,"Abstract The intensification of fieldwork in northern Mesopotamia, the upper region of the Tigris-Euphrates basin, has revealed two cycles of expansion and reduction in social complexity between 4400 and 2000 BC. These cycles include developments in social inequality, political centralization, craft production and economic specialization, agropastoral land use, and urbanization. Contrary to earlier assessments, many of these developments proceeded independently from the polities in southern Mesopotamia, although not in isolation. This review considers recent data from excavations and surveys in northern Iraq, northeastern Syria, and southeastern Turkey with particular attention to how they are used to construct models of early urban polities."
journal_title,Journal of Archaeological Research
article_title,Everything Old Is New Again: Recent Approaches to Research on the Archaic Period in the Western United States
keyword,"['Western North America\xa0', 'Archaic period\xa0', 'Hunters and gatherers\xa0', 'Early agriculture\xa0']"
history,"['2010-09', '2010-02-03']"
abstract,"Abstract There are regional differences in how archaeologists conduct their research on the Archaic period. The rich array of techniques and approaches used to examine this period in the West include human behavioral ecology and other evolutionary perspectives, technological style and aspects of practice theory, neuropsychological theory, and more. Recent research in the Great Basin, Southwest, Great Plains, Columbia-Fraser Plateau, and coastal California is surveyed to highlight commonalities and differences in the questions asked of the archaeological data and in the techniques that are used."
journal_title,Journal of Archaeological Research
article_title,Recent Developments in the Archaeology of Southwestern China
keyword,"['China\xa0', 'Neolithic\xa0', 'Bronze Age\xa0', 'Dian culture\xa0', 'Southeast Asia\xa0', 'Dong Son culture\xa0']"
history,"['2010-09', '2010-02-05']"
abstract,"Abstract Archaeology of ancient China’s periphery has traditionally been examined through the historiographic lens of Chinese textual sources. Social developments in the periphery are often explained in relation to accounts of migration from “core” regions of China. Setting conventional paradigms and textual sources aside, this article examines prehistoric developments in southwestern China in conjunction with broader trends in Southeast Asia. This comparative approach reveals that the development of bronze metallurgy in southwestern China parallels trends observed among Neolithic communities in Southeast Asia. Using recent data and a reassessment of radiocarbon dates for the Bronze Age, I propose that sociopolitical complexity emerged in southwestern China as part of a multiregional phenomenon that had its beginning with the formalization of trade networks during the Neolithic period."
journal_title,Journal of Archaeological Research
article_title,Landscape and Environment: Insights from the Prehispanic Central Andes
keyword,"['Andes\xa0', 'Environment\xa0', 'Landscape\xa0', 'Peru\xa0']"
history,"['2010-09', '2010-02-02']"
abstract,"Abstract Attention to human–environment relationships in the central Andes has a long history. Although the area is not a neat microcosm of the globe, wholly representative of worldwide trends in the archaeology of human–environment interactions, it has been the site of both seminal investigations in archaeology and a substantial body of recent work that investigates themes of broad archaeological relevance. Specifically, central Andean environments have been variously conceived as structuring, modified, and sacred. These approaches to some extent reflect broad trends in archaeology, while also suggesting directions in which the archaeology of human–environment interactions is moving and highlighting archaeology’s relevance to discussions of contemporary human–environment interactions. This article characterizes concepts that are key for describing central Andean environments and considers the ways in which the particular ecology of the central Andes has informed archaeological research in the region. The example of the central Andes highlights the importance of understanding environments as dynamic, considering both geomorphic and anthropogenic contributors to that dynamism, and examining both ecological (“environment”) and ideological (“landscape”) implications of archaeological landscapes."
journal_title,Journal of Archaeological Research
article_title,The Archaeological Study of Spanish Colonialism in the Americas
keyword,"['Spanish colonialism\xa0', 'Archaeology\xa0', 'Identity\xa0', 'Missions\xa0']"
history,"['2010-06', '2009-12-31']"
abstract,"Abstract Spanish colonial archaeology has undergone a fundamental shift since the Columbian Quincentenary due to the adoption of a bottom-up understanding of colonialism that emphasizes the analysis of local phenomena in a global context and the active ways in which people negotiated the processes set in motion by the conquest. This review examines five key research foci: culture change and identity, missionization, bioarchaeology, economics, and investigations of the colonial core. It ends with a consideration of ongoing challenges posed by the archaeology of colonialism, particularly the relationship of the individual to broader social processes and the emerging role of comparison."
journal_title,Journal of Archaeological Research
article_title,Twenty-First-Century Historical Archaeology
keyword,"['Historical archaeology\xa0', 'Scale\xa0', 'Capitalism\xa0', 'Inequality\xa0', 'Heritage and memory\xa0']"
history,"['2010-06', '2009-12-24']"
abstract,"Abstract The practice of historical archaeology has exploded over the past two decades, and especially since 2000. Methodological advances and new theoretical insights mean that archaeological research requires periodic evaluation, and this overview builds on the work of three earlier assessors of the discipline. Here, I concentrate on four areas of research currently being pursued by historical archaeologists: analytical scale, capitalism, social inequality, and heritage and memory. I conclude that historical archaeologists have made major strides in understanding the modern world and that future research promises to offer diverse perspectives that will deepen our appreciation for how the past influences the present."
journal_title,Journal of Archaeological Research
article_title,New Perspectives in Mississippian Archaeology
keyword,"['Archaeology\xa0', 'North America\xa0', 'Prehistoric\xa0', 'Mississippian\xa0']"
history,"['2010-03', '2009-08-21']"
abstract,"Abstract In recent years the pace of research on the late prehistoric Mississippian societies of eastern North America has accelerated. New data, methods, and theoretical goals are changing perspectives in Mississippian archaeology. Regional overviews and site syntheses provide unprecedented insights into the Mississippian phenomenon at local, regional, and continental scales. Traditional culture history, processualism, historical processualism, iconography, and neo-Darwinian archaeology are active theoretical orientations. Important research focuses on variability in Mississippian sociopolitical formations over time, organizational diversity among contemporaneous societies, and sources of political power. The new historicism and iconography place agency, identity, origins, factionalism, ideology, and meaning at the center of culture change, while many processualists continue to focus on developmental histories, economy, and control of material resources. Advances in physical and chemical analyses and the availability of remote sensing techniques are changing how Mississippian archaeology is conducted and expanding the kinds of data that are recovered. These diverse interests, methods, and goals have created considerable eclecticism in Mississippian archaeology."
journal_title,Journal of Archaeological Research
article_title,Recent Research in Western Mexican Archaeology
keyword,"['Mesoamerica\xa0', 'Mortuary practices\xa0', 'Social complexity\xa0', 'Human ecology\xa0', 'Empire\xa0', 'Migration\xa0']"
history,"['2010-03', '2009-09-02']"
abstract,"Abstract Western Mexico is vast and geographically diverse and has received far less attention compared to other areas of Mesoamerica. Research over the past decade allows the definition of four major subregions characterized by cultural factors and distinct historical trajectories. A large proportion of the research in western Mexico is still culture-historical in nature, oriented toward establishing chronologies and relationships between regions. But along with a number of recent efforts toward synthesis and consolidation, current theoretical research contributes to the study of mortuary patterns and social organization, alternative forms of social complexity, agricultural intensification, empire formation, state involvement in the economy, human-land relationships, and the interlocking relationship between migration and sociopolitical reorganization."
journal_title,Journal of Archaeological Research
article_title,"Unity and Diversity in the European Iron Age: Out of the Mists, Some Clarity?"
keyword,"['Iron Age\xa0', 'Europe\xa0', 'Colonialism\xa0', 'Political development\xa0', 'Ethnicity\xa0', 'Identity\xa0', 'Religion\xa0', 'Paradigm shift\xa0']"
history,"['2009-12', '2009-05-14']"
abstract,"Abstract While some researchers continue to focus fruitfully on traditional issues, in recent years new perspectives, some strongly revisionist, have developed within European Iron Age archaeology, moving it from a long-static state into a rapidly changing milieu. Studies of colonialism, imperialism, and interaction have undergone sequential shifts into new territory, while topics related to sacred activity, political apparatuses, and the ruler-subject relationship have undergone substantial reworking. Perspectives absent from earlier literature have emerged: gender, age, ethnicity, and identity, and interpretations employing theories of practice, agency, landscape, and embodiment have emerged, mirroring broader disciplinary shifts. An overarching trend sees Iron Age Europe as a series of interactive societies with both broad similarities and sharp regional, even local, differences, moving through time and ever-changing relationships, influences, and trajectories. The collision of traditional and revisionist scholarship has produced debate, some heated, but has improved and invigorated the field."
journal_title,Journal of Archaeological Research
article_title,Household Archaeology in the Andes
keyword,"['Domestic archaeology\xa0', 'Residential archaeology\xa0', 'Household archaeology\xa0', 'Andes\xa0']"
history,"['2009-09', '2009-03-27']"
abstract,"Abstract Data from domestic contexts can be used to address significant anthropological research questions. Archaeological investigations in the Andes (areas once incorporated into the Inka empire, including northwestern Argentina, highland Bolivia, northern Chile, Ecuador, and Peru), like many parts of the world, rely on ethnohistory and ethnography to interpret the archaeological remains of domestic areas and make inferences about households. In this review I describe the ideas about Andean households that archaeologists are using and how domestic remains are being examined to infer social, economic, and political processes. Household archaeology in the Andes requires ethnoarchaeology and theory-building in order to understand the complex social dynamics at the foundation of ancient Andean societies."
journal_title,Journal of Archaeological Research
article_title,New Developments in the Use of Spatial Technology in Archaeology
keyword,"['Geographic information systems\xa0', 'Laser mapping\xa0', 'Remote sensing\xa0', 'Geophysical survey\xa0']"
history,"['2009-09', '2009-03-27']"
abstract,"Abstract Spatial technology is integral to how archaeologists collect, store, analyze, and represent information in digital data sets. Recent advances have improved our ability to look for and identify archaeological remains and have increased the size and complexity of our data sets. In this review we outline trends in visualization, data management, archaeological prospecting, modeling, and spatial analysis, as well as key advances in hardware and software. Due to developments in education, information technology, and landscape archaeology, the implementation of spatial technology has begun to move beyond superficial applications and is no longer limited to environmental deterministic approaches. In the future, spatial technology will increasingly change archaeology in ways that will enable us to become better practitioners, scholars, and stewards."
journal_title,Journal of Archaeological Research
article_title,Hopewell Archaeology: A View from the Northern Woodlands
keyword,"['Archaeology\xa0', 'North America\xa0', 'Northern Woodland\xa0', 'Hopewell\xa0']"
history,"['2009-06', '2009-01-10']"
abstract,"Abstract A tremendous amount of research on Hopewellian societies in the Northern Woodlands of the United States has been conducted within the last decade. This article summarizes the main themes and directions of that current research and presents a general model of Hopewellian societies. Local communities appear to have been small in size and relatively sedentary; sets of these communities shared a greater sense of cultural identity within a lineage and possibly clan organization, with each riverine drainage system occupied by a mosaic of lineages. Each in turn was spatially centered on specific clusters of religious, nonresidential public architecture. Alliances were based on a number of historically shifting variables, including religion, kinship, politics, and economics. It is suggested that future research continue existing methodologies and analyses and consider new ecological, genetic, and ideological research as a means of adding greater local historic nuance to this general model of Hopewellian societies."
journal_title,Journal of Archaeological Research
article_title,"Zooarchaeology in Complex Societies: Political Economy, Status, and Ideology"
keyword,"['Zooarchaeology\xa0', 'Complex societies\xa0', 'Economy\xa0', 'Ritual\xa0']"
history,"['2009-06', '2009-01-10']"
abstract,"Abstract The zooarchaeology of complex societies provides insights into the interrelated social and economic relationships that people and animals created. I present a synthesis of zooarchaeological research published since the early 1990s that addresses political economy, status distinctions, and the ideological and ritual roles of animals in complex cultures. I address current approaches and applications as well as theoretical shifts in zooarchaeological practice. Research indicates there is great variability across space and time in how past peoples used animals to generate economic surplus, to establish status differentiation within societies, and to create symbolic meaning through sacrifices, offerings, and in feasts. The study of human/animal interactions in complex societies can contribute to fundamental questions of broad relevance regarding political and social life."
journal_title,Journal of Archaeological Research
article_title,Historical Archaeology of Indigenous Culture Change in Mesoamerica
keyword,"['Historical archaeology\xa0', 'Mesoamerica\xa0', 'Postconquest\xa0', 'Indigenous societies\xa0', 'Rural settlements\xa0', 'Material culture\xa0', 'Interaction\xa0', 'Culture change\xa0']"
history,"['2009-12', '2009-05-14']"
abstract,"Abstract This essay outlines recent archaeological research on post-Columbian (c. A.D. 1500–1925) indigenous sites in Mexico and Central America. Historical archaeology is a growing field in Mesoamerica, and over the last 20 years investigations of native culture change have increased, especially in rural areas. Contemporary research contributes new insights on indigenous responses to Spanish colonization over a long period. This work also is reassessing chronologies and examining the diversity of indigenous behavior from late preconquest to historic times. Indigenous adaptations to culture contact and social change are characterized by three general stages: conquest, colonization, and independence. Although I do draw on other regions, the focus of the article is the Maya area and Central America, where more investigations have taken place."
journal_title,Journal of Archaeological Research
article_title,The Neolithic Macro-(R)evolution: Macroevolutionary Theory and the Study of Culture Change
keyword,"['Macroevolution\xa0', 'Evolutionary archaeology\xa0', 'Neolithic\xa0', 'Near East\xa0']"
history,"['2009-03', '2008-09-23']"
abstract,"Abstract The macroevolutionary approach in archaeology represents the most recent example in a long tradition of applying principles of biological evolution to the study of culture change. Archaeologists working within this paradigm see macroevolutionary theory as an effective response to the shortcomings of neo-Darwinian biological evolution for studying cultural evolution. Rather than operating at the level of individual traits, macroevolutionary archaeologists emphasize the role of hierarchical processes in culture change. While neo-Darwinian archaeologists disavow any element of human intent in culture change, to macroevolutionary archaeologists human agency is a key component of cultural evolution that allows cultures to respond to pressures more quickly and with greater degree of flexibility and directedness than found in biological evolution. Major culture change, when it happens, is likely to be rapid, even revolutionary, with periods of rapid change separated by periods of relative stasis of actively maintained stability. The emergence of Neolithic cultures has long been recognized as one of two periods of major revolutionary culture change in human prehistory. Here I examine the record for the Near East, tracing the empirical record for the origin of agriculture in this region, as well as other demographic, social, and ideological components of Neolithic emergence. While the empirical record from the Near East subscribes in a general way to basic principles of macroevolutionary theory, cultural evolution cannot be understood through appeal to principles of biological evolution alone, whether based in macroevolutionary theory or neo-Darwinianism. Instead, the key role of human agency in culture change distinguishes cultural evolution from biological evolution and requires a more pluralistic and less doctrinaire appeal to multiple models of change based in both the biological and social sciences."
journal_title,Journal of Archaeological Research
article_title,"The Analysis of Stone Tool Procurement, Production, and Maintenance"
keyword,"['Lithic technology\xa0', 'Artifact curation\xa0', 'Reduction sequences\xa0', 'Artifact life history\xa0']"
history,"['2009-03', '2008-09-19']"
abstract,"Abstract Researchers who analyze stone tools and their production debris have made significant progress in understanding the relationship between stone tools and human organizational strategies. Stone tools are understood to be morphologically dynamic throughout their use-lives; the ever-changing morphology of stone tools is intimately associated with the needs of tool users. It also has become apparent to researchers that interpretations of lithic analysis are more productive when the unique contexts and situations for which lithic artifacts were made, used, modified, and ultimately discarded are considered. This article reviews the recent literature on stone tool production with an emphasis on raw material procurement, manufacturing techniques, and tool maintenance processes as they relate to adaptive strategies of toolmakers and users."
journal_title,Journal of Archaeological Research
article_title,"The Archaeology of Trading Systems, Part 1: Towards a New Trade Synthesis"
keyword,"['Trade\xa0', 'Trading systems\xa0', 'Traders\xa0', 'Archaeology\xa0', 'Exchange\xa0', 'Interaction\xa0', 'Economic history\xa0', 'Economic anthropology\xa0']"
history,"['2008-12', '2008-04-09']"
abstract,"Abstract After almost three centuries of investigations into the question of what it means to be human and the historical processes of becoming human, archaeologists have amassed a huge volume of data on prehistoric human interactions. One of the largest data sets available is on the global distribution and exchange of materials and commodities. What still remains insufficiently understood is the precise nature of these interactions and their role in shaping the diverse cultures that make up the human family as we know it. A plethora of theoretical models combined with a multitude of methodological approaches exist to explain one important aspect of human interaction—trade—and its role and place in shaping humanity. We argue that trade parallels political, religious, and social processes as one of the most significant factors to have affected our evolution. Here we review published literature on archaeological approaches to trade, including the primitivist-modernist and substantivist-formalist-Marxist debates. We also discuss economic, historical, and ethnographic research that directly addresses the role of traders and trade in both past and contemporary societies. In keeping with the complexities of interaction between trade and other aspects of human behavior, we suggest moving away from the either/or perspective or strong identification with any particular paradigm and suggest a return to the middle through a combinational approach to the study of trade in past societies."
journal_title,Journal of Archaeological Research
article_title,New Directions in Bioarchaeology: Recent Contributions to the Study of Human Social Identities
keyword,"['Archaeology\xa0', 'Physical anthropology\xa0', 'Osteology\xa0', 'Human remains\xa0']"
history,"['2008-12', '2008-04-11']"
abstract,"Abstract As a discipline that bridges the biological and social sciences, bioarchaeology has much to contribute to a contextualized and theoretically sophisticated understanding of social identities. Here, we discuss the growing methodological sophistication of bioarchaeology and highlight new developments in osteological age and sex estimation, paleodemography, biodistance analysis, biogeochemistry, and taphonomy, particularly anthropologie de terrain. We then discuss how these methodological developments, when united with social theory, can elucidate social identities. More specifically, we highlight past and future bioarchaeological work on disability and impairment, gender identity, identities of age and the life course, social identity and body modification, embodiment, and ethnic and community identities."
journal_title,Journal of Archaeological Research
article_title,Regional Settlement Pattern Studies
keyword,"['Archaeology\xa0', 'Regions\xa0', 'Survey\xa0', 'Communities\xa0']"
history,"['2008-09', '2008-03-08']"
abstract,"Abstract This is a critical review of regional settlement pattern archaeology published in the last decade. The regional approach proves to be highly productive of new ideas and lasting results. Cultural resource/heritage databases are increasingly important. Notable advances have been made in regional studies of Paleolithic and Holocene foragers, the reciprocal relations between Neolithic communities and their regional societies, and in understanding states and empires. There are new research potentials in comparisons, macroregional analysis, long-term change, and alternative pathways. Research designs should specify systematic coverage at the regional scale and carry out spatial analysis in which social groups are the primary focus."
journal_title,Journal of Archaeological Research
article_title,Multiregional Perspectives on the Archaeology of the Andes During the Late Intermediate Period (c. A.D. 1000–1400)
keyword,"['Late Intermediate period (LIP)\xa0', 'Settlement patterns\xa0', 'Architecture\xa0', 'Mortuary treatment\xa0', 'Material culture\xa0', 'Complexity\xa0', 'Political economy\xa0', 'Ethnicity\xa0']"
history,"['2008-09', '2008-03-25']"
abstract,"Abstract During the Late Intermediate period (LIP, c. A.D. 1000–1400), the central Andes experienced the decline of the Wari and Tiwanaku states, as well as processes of state formation, regional population growth, and competition culminating in the imperial expansion of the Chimú and Inka polities. The LIP holds the potential to link the archaeological features of early Andean states with the material signatures of the later ones, providing a critical means of contextualizing the intergenerational continuities and breaks in state structures and imperial strategies. The recent proliferation of LIP research and the completion of a number of regional studies permit the overview of six LIP regions and the comparison of highland and lowland patterns of political and economic organization, social complexity, and group identity."
journal_title,Journal of Archaeological Research
article_title,Siberia at the Last Glacial Maximum: Environment and Archaeology
keyword,[]
history,"['2008-06', '2008-02-14']"
abstract,None
journal_title,Journal of Archaeological Research
article_title,Aegean Prehistory as World Archaeology: Recent Trends in the Archaeology of Bronze Age Greece
keyword,"['Archaeology\xa0', 'Greece\xa0', 'Bronze Age\xa0', 'Aegean prehistory\xa0']"
history,"['2008-06', '2007-11-20']"
abstract,"Abstract This article surveys archaeological work of the last decade on the Greek Bronze Age, part of the broader discipline known as Aegean prehistory. Naturally, the literature is vast, so I focus on a set of topics that may be of general interest to non-Aegeanists: chronology, regional studies, the emergence and organization of archaic states, ritual and religion, and archaeological science. Greek Bronze Age archaeology rarely appears in the comparative archaeological literature; accordingly, in this article I place this work in the context of world archaeology, arguing for a reconsideration of the potential of Aegean archaeology to provide enlightening comparative material."
journal_title,Journal of Archaeological Research
article_title,Siberia at the Last Glacial Maximum: Environment and Archaeology
keyword,"['Last Glacial Maximum\xa0', 'Paleoenvironment\xa0', 'Upper Paleolithic\xa0', 'Human adaptation\xa0', 'Siberia\xa0', 'Russian Far East\xa0', 'Northern Eurasia\xa0']"
history,"['2008-06', '2008-01-12']"
abstract,"Abstract This article focuses on the presence of humans in Siberia and the Russian Far East at the coldest time of the Late Pleistocene, called the Last Glacial Maximum (LGM) and dated to c. 20,000–18,000 rcbp. Reconstruction of the LGM environment of Siberia, based on the latest models and compilations, provides a background for human existence in this region. Most of Siberia and the Russian Far East at c. 20,000–18,000 rcbp was covered by tundra and cool steppe, with some forest formations in the river valleys. Climate was much colder and drier than it is today. Eighteen Upper Paleolithic sites in Siberia are radiocarbon dated strictly to the LGM, and at least six of them, located in southern parts of western and eastern Siberia and the Russian Far East, have solid evidence of occupation during that time span. It seems clear that southern Siberia was populated by humans even at the height of the LGM, and that there was no dramatic decline or complete disappearance of humans in Siberia at that time. The degree of human adaptation to periglacial landscapes in the mid-Upper Paleolithic of northern Eurasia was quite high; humans coped with the cold and dry environmental conditions using microblade technology, artificial shelters, tailored clothes, and megafaunal bones as fuel."
journal_title,Journal of Archaeological Research
article_title,Studies of Gender in the Prehispanic Americas
keyword,"['Gender\xa0', 'Prehispanic\xa0', 'Americas\xa0', 'Identity\xa0']"
history,"['2008-03', '2007-09-09']"
abstract,"Abstract In the past ten years archaeologists have produced a vast literature on the study of gender in the prehispanic New World. This review defines key concepts, identifies three major themes within this tradition—gender in native cosmologies, intersections of gender and the body, and studies of work and specialization—and explores the significant contributions of engendered archaeology to the broader field. Final suggestions for linkages with queer studies and indigenous feminism point the way to where this field might develop productive new avenues of research."
journal_title,Journal of Archaeological Research
article_title,The Archaeology of Regions: From Discrete Analytical Toolkit to Ubiquitous Spatial Perspective
keyword,"['Regional analysis\xa0', 'Settlement patterns\xa0', 'Spatial analysis\xa0', 'Archaeological method and theory\xa0', 'Geographic information systems\xa0']"
history,"['2008-03', '2007-09-26']"
abstract,"Abstract In the 1970s and 1980s, regional analysis was an influential part of archaeological research, providing a discrete set of geographical tools inspired by a processual epistemological and interpretive perspective. With the advent of new technologies, new methods, and new paradigms, archaeological research on regional space has undergone significant changes. This article reviews the state of regional archaeology, beginning with a consideration of its history and a discussion of the fundamental issues facing regional investigations before focusing on developments over the last several years. On one hand, the diversification of archaeological theory has created new paradigms for thinking about human relationships with one another and with the physical environment across regional space; in this regard, historical ecology, landscape archaeology, and evolutionary theory have been particularly influential in recent years. This has led to a corresponding diversification of the traditional methods of regional analysis. Most notably, the advent of powerful digital technologies has introduced new tools, especially those from the geographic information sciences, that build on the quantitative methods of past approaches. The investigation of regional data is no longer based on a discrete toolkit of simple mathematical and graphical procedures for representing spatial relationships. Instead, regional archaeology has matured into a diversity of multiscalar spatial and geostatistical techniques that inform many areas of archaeological inquiry."
journal_title,Journal of Archaeological Research
article_title,Recent Research in the Southern Highlands and Pacific Coast of Mesoamerica
keyword,"['Mesoamerica\xa0', 'Guatemala\xa0', 'Mexico\xa0', 'Maya\xa0', 'Sociopolitical evolution\xa0', 'State formation\xa0', 'Collapse\xa0']"
history,"['2007-12', '2007-08-25']"
abstract,"Abstract Recent research on the southern highlands and Pacific Coast of Mesoamerica has investigated topics of interest to all archaeologists. Although best known for studies on the development of early social complexity, research in the region also has addressed hunter/gatherer subsistence patterns, early sedentism, the origins of food production, the development of the state, migration, the construction of social identity, political economy, and the collapse of complex societies. Research has accelerated in the past ten years, fueled by efforts of scholars from a number of disciplines. Recent paleo-ecological studies have provided much needed data for understanding human social action against the backdrop of the natural environment, while the region also has been the scene for testing numerous innovative theories of social change. Studies of identity and its manifestation in material culture have been especially productive."
journal_title,Journal of Archaeological Research
article_title,What Maya Collapse? Terminal Classic Variation in the Maya Lowlands
keyword,"['Maya\xa0', 'Collapse\xa0', 'Terminal Classic–Early Postclassic\xa0']"
history,"['2007-12', '2007-08-17']"
abstract,"Abstract Interest in the lowland Maya collapse is stronger than ever, and there are now hundreds of studies that focus on the era from approximately A.D. 750 to A.D. 1050. In the past, scholars have tended to generalize explanations of the collapse from individual sites and regions to the lowlands as a whole. More recent approaches stress the great diversity of changes that occurred across the lowlands during the Terminal Classic and Early Postclassic periods. Thus, there is now a consensus that Maya civilization as a whole did not collapse, although many zones did experience profound change."
journal_title,Journal of Archaeological Research
article_title,Advances in Polynesian Prehistory: A Review and Assessment of the Past Decade (1993–2004)
keyword,"['Polynesia\xa0', 'Complex societies\xa0', 'Exchange\xa0', 'Paleoecology\xa0', 'Household archaeology\xa0', 'Pacific Islands\xa0']"
history,"['2007-09', '2007-08-04']"
abstract,"Abstract The pace of archaeological research in Polynesia has intensified in recent years, resulting in more than 500 new literature citations over the past decade. Fieldwork has continued in such previously well-studied archipelagoes as Tonga and Samoa in Western Polynesia, and Hawai’i and New Zealand in Eastern Polynesia, and has expanded into previously neglected islands including Niue, the Equatorial Islands, the Austral Islands, and Mangareva. The emergence of Ancestral Polynesian culture out of its Eastern Lapita predecessor is increasingly well understood, and the chronology of Polynesian dispersal and expansion into Eastern Polynesia has engaged several researchers. Aside from these fundamental issues of origins and chronology, major research themes over the past decade include (1) defining the nature, extent, and timing of long-distance interaction spheres, particularly in Eastern Polynesia; (2) the impacts of human colonization and settlement on island ecosystems; (3) variation in Polynesian economic systems and their transformations over time; and (4) sociopolitical change, especially as viewed through the lens of household or microscale archaeology. Also noteworthy is the rapidly evolving nature of interactions between archaeologists and native communities, a critical aspect of archaeological practice in the region."
journal_title,Journal of Archaeological Research
article_title,Cultural Transmission Theory and the Archaeological Record: Providing Context to Understanding Variation and Temporal Changes in Material Culture
keyword,"['Cultural transmission\xa0', 'Evolutionary archaeology\xa0', 'Artifact variation\xa0']"
history,"['2007-09', '2007-08-04']"
abstract,"Abstract Cultural transmission (CT) is implicit in many explanations of culture change. Formal CT models were defined by anthropologists 30 years ago and have been a subject of active research in the social sciences in the ensuing years. Although increasing in popularity in recent years, CT has not seen extensive use in archaeological research, despite the quantitative rigor of many CT models and the ability to create testable hypotheses. Part of the reason for the slow adoption, we argue, has been the continuing focus on change in central tendency and mode in archaeology, instead of change in dispersion or variance. Yet archaeological research provides an excellent data source for exploring processes of CT. We review CT research in the anthropological sciences and outline the benefits and drawbacks of this theoretical framework for the study of material culture. We argue that CT can shed much light on our understandings of why material technology changes over time, including explanations of differential rates of change among different technologies. We further argue that transmission processes are greatly affected by the content, context, and mode of transmission and fundamentally structure variation in material culture. Including ideas from CT can provide greater context for explaining and understanding changes in the variation of artifacts over time. Finally, we outline what we feel should be the goals of CT research in archaeology in the coming years."
journal_title,Journal of Archaeological Research
article_title,Fortifications and Enclosures in European Prehistory: A Cross-Cultural Perspective
keyword,"['Fortifications\xa0', 'Enclosures\xa0', 'Warfare\xa0', 'Europe\xa0', 'Neolithic\xa0', 'Bronze Age\xa0', 'Copper Age\xa0']"
history,"['2007-06', '2007-05-12']"
abstract,"Abstract This article reviews recent research into the archaeological interpretation and investigation of fortifications and enclosures during the Neolithic and Bronze Age in Europe. Recent methodological, technological, and cultural developments have expanded our understanding of the temporal, spatial, and formal variability of these features on the landscape. Interpretations of this variability also have varied with different theoretical trends in the discipline. We advocate a cross-cultural approach that focuses on the occurrence of enclosures and fortifications over the long term at the continental scale. Such a macroscalar approach complements interpretive frameworks at the regional and microregional scales. The geographic and temporal distribution of these features indicates that social institutions associated with principles of segmentation and substitutability became formalized and tethered to the landscape during the Neolithic."
journal_title,Journal of Archaeological Research
article_title,Evolutionary Foraging Models in Zooarchaeological Analysis: Recent Applications and Future Challenges
keyword,"['Zooarchaeology\xa0', 'Foraging models\xa0', 'Behavioral ecology\xa0']"
history,"['2007-06', '2007-05-24']"
abstract,"Abstract The last few decades have witnessed a rapid rise in the use of foraging models derived from behavioral ecology to explain and predict temporal and spatial differences in faunal assemblages. Although these models build on conventional ideas about utility firmly embedded in zooarchaeological analyses, when cast in an evolutionary framework these ideas produce some of the most sophisticated and elegant interpretations of archaeofaunas to date. In this article I review the methodological and practical strengths and weaknesses of current zooarchaeological applications of foraging models. Recent applications of foraging models to the zooarchaeological record reveal important variability in human-prey interactions across time and space. Case-specific applications generate theoretical and methodological advances that augment and are complementary to model building in allied fields. Recent applications also identify shortcomings in the underlying assumptions and rationale of some foraging models that mirror past and on-going discussions in anthropology and biology. I discuss how these shortcomings can fruitfully direct future applications and research in foraging economics."
journal_title,Journal of Archaeological Research
article_title,The Emergence of Ornaments and Art: An Archaeological Perspective on the Origins of “Behavioral Modernity”
keyword,"['Art\xa0', 'Modern humans\xa0', 'Neandertals\xa0', 'Ornaments\xa0']"
history,"['2007-03', '2007-01-30']"
abstract,"Abstract The earliest known personal ornaments come from the Middle Stone Age of southern Africa, c. 75,000 years ago, and are associated with anatomically modern humans. In Europe, such items are not recorded until after 45,000 radiocarbon years ago, in Neandertal-associated contexts that significantly predate the earliest evidence, archaeological or paleontological, for the immigration of modern humans; thus, they represent either independent invention or acquisition of the concept by long-distance diffusion, implying in both cases comparable levels of cognitive capability and performance. The emergence of figurative art postdates c. 32,000 radiocarbon years ago, several millennia after the time of Neandertal/modern human contact. These temporal patterns suggest that the emergence of “behavioral modernity” was triggered by demographic and social processes and is not a species-specific phenomenon; a corollary of these conclusions is that the corresponding genetic and cognitive basis must have been present in the genus Homo before the evolutionary split between the Neandertal and modern human lineages."
journal_title,Journal of Archaeological Research
article_title,Baffles and Bastions: The Universal Features of Fortifications
keyword,"['Ancient fortifications\xa0', 'Warfare\xa0', 'Prehistoric enclosures\xa0', 'Pre-gunpowder weapons\xa0', 'Symbolism\xa0', 'Warfare\xa0']"
history,"['2007-03', '2007-03-05']"
abstract,"Abstract This article discusses several universal features of fortifications and distinguishes those features that are unequivocally military in function. The evidence adduced includes the features of known historic fortifications, relevant prescriptions by ancient military authors, and geometry. The archaeologically visible features that are universally used in military defenses are V-sectioned ditches, “defended” (especially baffled) gates, and bastions. It is also noted that ritual, ceremonial, or any other peaceful activities conducted within an enclosure having these architectural features does not preclude its obvious military function."
journal_title,Journal of Archaeological Research
article_title,"Craft Production, Exchange, and Political Power in the Pre-Incaic Andes"
keyword,"['Craft production\xa0', 'Exchange\xa0', 'Power\xa0', 'Materialization\xa0', 'Andes\xa0']"
history,"['2006-12', '2006-11-03']"
abstract,"Abstract This article explores the relationship between craft production, exchange, and power in the pre-Incaic Andes, with a focus on recent archaeological evidence from Chavín, Nasca, Tiwanaku, Wari, and Moche. I argue that craft production and exchange in concert with materialized ideologies played vital roles in the development of political power in the Andes. In later state societies, craft production, exchange, and materialization were critical in maintaining and legitimizing established political power."
journal_title,Journal of Archaeological Research
article_title,Recent Trends in Theorizing Prehispanic Mesoamerican Economies
keyword,"['Mesoamerica\xa0', 'Political economy\xa0', 'Agency\xa0', 'Ritual economy\xa0']"
history,"['2006-12', '2006-11-02']"
abstract,"Abstract Theoretical frames for modeling prehispanic Mesoamerican economies have been informed mostly by political economy or agency approaches. Political economy models examine the ways in which power is constructed and exercised through the manipulation of material transfers, mainly production and distribution. Research along these lines emphasizes regional redistribution, wealth and staple finance, debt and reciprocity, and regional integration through core/periphery relations. Agency models, on the other hand, explore the social aspects of manufacture, circulation, and consumption to infer the processes by which power is negotiated and contested. Work using this framework focuses on the manner by which meaning and value are assigned to, and become fixed in, social valuables, as well as the moral and emotional dimensions of allocation and consumption. Political economy and agency approaches are converging in Mesoamerican research to forge a new, hybrid theoretical construct, “ritual economy,” which strikes a balance between formalist and substantivist views by considering the ways that belief systems articulate with economic systems in the management of meanings and the shaping of interpretations."
journal_title,Journal of Archaeological Research
article_title,Current Research on the Gulf Coast of Mexico
keyword,"['Mesoamerica\xa0', 'Gulf Coast\xa0', 'Archaeology\xa0', 'Current research\xa0']"
history,"['2006-09', '2006-10-03']"
abstract,"Abstract The Gulf Coast of Mesoamerica is a culturally and environmentally heterogeneous area that encompasses the lowlands along the Gulf of Mexico as well as rugged inland highlands. Blessed with a wealth of valued resources and a favorable geographical setting, the pre-Hispanic Gulf Coast played a critical role as a cultural and economic crossroads, and its cultures contributed vital elements to other Mesoamerican traditions. Gulf Coast archaeology currently is experiencing the most active period in its history. This recent research underscores the diversity and dynamism of the area's cultures and environment. An enormous expansion of settlement pattern studies reveals considerable diversity in sociopolitical organization, urbanism, and human–land relationships. A second important trend focuses on documenting and understanding variation in craft production and exchange systems. A third is the continuing emphasis on interregional interaction through all time periods. These three foci merge in a growing interest in variation and change in Gulf Coast political economies. Future research will need to incorporate theoretical perspectives that focus on the generation of cultural variation, including agency-based models of technological choice and political economy, as well as those, like Darwinian approaches, that emphasize the differential persistence of variation."
journal_title,Journal of Archaeological Research
article_title,Engendered and Feminist Archaeologies of the Recent and Documented Pasts
keyword,"['Historical archaeology\xa0', 'Gender\xa0', 'Feminism\xa0', 'Social identity\xa0']"
history,"['2006-09', '2006-09-21']"
abstract,"Abstract Engendered and feminist archaeologies in historical archaeology have developed in complementary ways to those in nonhistorical archaeologies but with distinct methodological issues and sources of data. This article discusses the development of engendered and feminist archaeologies that use textual sources, the continuing themes that characterize this body of work, and the state of the field today. The article concludes with a discussion of future directions for practitioners to pursue."
journal_title,Journal of Archaeological Research
article_title,The Archaeology of South Asian Cities
keyword,"['Archaeology\xa0', 'South Asia\xa0', 'Urbanism\xa0', 'Social complexity\xa0', 'Warfare\xa0']"
history,"['2006-06', '2006-06-16']"
abstract,"Abstract Urbanism in the Indian subcontinent occurred in three distinct time periods in which cultural cohesion over large regions is archaeologically demonstrated through the architecture and artifacts of social, ritual, and economic activity. In the Indus (2500–1900 B.C.) and Early Historic (3rd century B.C. to 4th century A.D.) periods, cities were not necessarily tied to political territories or guided by strong political leaders, but by the Medieval period (after the 9th century A.D.), urban zones were the base for political growth, warfare, and aggrandizement. The comparison of these three eras is undertaken within a framework for defining cities that balances quantitative criteria such as population size and areal extent with two types of qualitative criteria: internal specialization on the basis of materials found within archaeological sites, and external specialization on the basis of data recovered through regional analysis. Cities from the three eras also are evaluated from the perspective of the ordinary inhabitant through the examination of the social, religious, and economic factors that prompted and rewarded urban residence. While the Indus and Early Historic cities were attractive because of the networks of opportunity found there, Medieval cities additionally benefitted from a “push” factor as ordinary inhabitants allied themselves to urban areas in times of political stress and uncertainty."
journal_title,Journal of Archaeological Research
article_title,Behavioral Ecology and Archaeology
keyword,"['Evolutionary ecology\xa0', 'Optimal foraging\xa0', 'Hominin life history\xa0', 'Costly signaling\xa0', 'Hereditary inequality\xa0']"
history,"['2006-06', '2006-06-13']"
abstract,"Abstract Behavioral ecology is the study of adaptive behavior in relation to social and environmental circumstances. Analysts working from this perspective hold that the reproductive strategies and decision-making capacities of all living organisms—including humans—are shaped by natural selection. Archaeologists have been using this proposition in the study of past human behavior for more than 30 years. Significant insights on variation in prehistoric human subsistence, life history, social organization, and their respective fossil and archaeological consequences have been among the more important results."
journal_title,Journal of Archaeological Research
article_title,"New World States and Empires: Politics, Religion, and Urbanism"
keyword,"['archaeology\xa0', 'complex societies\xa0', 'states\xa0', 'New World\xa0', 'cultural evolution\xa0']"
history,"['2006-03', '2006-05-06']"
abstract,"The past decade has seen a veritable explosion in archaeological research on complex societies in Latin America. In 1993, Smith published an overview of research to that date; this article is one of two bringing that summary up to the present. Our first article, New World states and empires: Economic and social organization (Smith and Schreiber, 2005), dealt with issues regarding economic and social organization. The present article tackles political organization and dynamics, religion, urbanism, and settlement patterns. We also review recent research in the context of various theoretical perspectives, some traditional, some more contemporary, including approaches to history and process, cultural evolution, agency-based models, linguistic prehistory, migration theory, and the relationship between environmental change and cultural events. Our discussion blends empirical findings, methodological advances, and theoretical perspectives."
journal_title,Journal of Archaeological Research
article_title,Surveys and Mesoamerican Archaeology: The Emerging Macroregional Paradigm
keyword,"['survey\xa0', 'settlement patterns\xa0', 'concordant change\xa0', 'Mexico\xa0']"
history,"['2006-03', '2006-05-06']"
abstract,"This article is a review of regional archaeological surveys in Mexico, emphasizing published full-coverage surveys from the last 20 years. The geographic focus is non-Maya Mexico terminating at the Tropic of Cancer. The temporal focus is the 3000-year period from the earliest settled villages to the Spanish conquest (A.D. 1521), with emphasis on long-term evolutionary trajectories. The main argument is that explanations of regional-scale settlement patterns are proving to be incomplete now that archaeologists are confronted with site distributions on the macroregional scale. Implications of the emerging macroregional paradigm are discussed for current debates in Mesoamerican archaeology."
journal_title,Agriculture and Human Values
article_title,Kenneth McGill: Global inequality: anthropological insights
keyword,[]
history,"['2018-06', '2017-06-26', '2017-06-15']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Devra I. Jarvis, T. Hodgkin, A.H.D. Brown, J. Tuxill, I. Lopez Noriega, M. Smale, and B. Sthapit: Crop genetic diversity in the field and on the farm: principles and applications in research practices"
keyword,[]
history,"['2018-06', '2017-06-26', '2017-06-20']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Randall A. Bluffstone and Elizabeth J. Z. Robinson (eds.): Forest tenure reform in Asia and Africa: local control for improved livelihoods, forest management, and carbon sequestration"
keyword,[]
history,"['2018-06', '2017-06-19', '2017-06-15']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Ottavio Quirico and Mouloud Boumghar (eds.): Climate change and human rights: an international and comparative law perspective
keyword,[]
history,"['2018-06', '2017-10-09', '2017-09-12']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Todd LeVasseur, Pramod Parajuli and Norman Wirzba (eds.): Religion and sustainable agriculture: world spiritual traditions and food ethics"
keyword,[]
history,"['2018-06', '2017-10-27', '2017-09-18']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Ruerd Ruben, Paul Hoebink (eds.): Coffee certification in East Africa: impact on farmers, families and cooperatives"
keyword,[]
history,"['2018-06', '2017-06-19', '2017-06-10']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Books received
keyword,[]
history,"['2018-06', '2018-02-26']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Peter Poschen: Decent work, green jobs and the sustainable economy: solutions for climate change and sustainable development"
keyword,[]
history,"['2018-06', '2017-06-30', '2017-05-26']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Farmland loss and concern in the Treasure Valley
keyword,"['Farmland preservation\xa0', 'Farmland use change\xa0', 'Policy\xa0', 'Rural–urban continuum\xa0', 'Urbanization\xa0', 'Western United States\xa0']"
history,"['2018-06', '2018-01-20', '2017-12-19']"
abstract,"Abstract Structural changes in the agriculture and food system have resulted in larger but fewer farms, while increasing populations in urban areas have pushed development into rural areas. Despite these changes, little research has examined the concern of individuals with regards to loss of farmland and how this may vary based on geography. Building on Bell’s argument that the rural–urban continuum still exists and remains an important part of rural residents’ identity, in this article we examine residents’ concern over loss of farmland as a result of urban growth. We pay particularly close attention to urban–rural differences over concern with loss of farmland. Utilizing survey data collected from over 400 households in the Treasure Valley, a region of the western United States, our results indicate that rural residents show greater levels of concern with farmland loss when compared to their urban counterparts."
journal_title,Agriculture and Human Values
article_title,"Do advisors perceive climate change as an agricultural risk? An in-depth examination of Midwestern U.S. Ag advisors’ views on drought, climate change, and risk management"
keyword,"['Adaptation\xa0', 'Health belief model\xa0', 'Protection motivation theory\xa0', 'Drought\xa0', 'Qualitative\xa0']"
history,"['2018-06', '2017-10-09', '2017-09-08']"
abstract,"Abstract Through the lens of the Health Belief Model and Protection Motivation Theory, we analyzed interviews of 36 agricultural advisors in Indiana and Nebraska to understand their appraisals of climate change risk, related decision making processes and subsequent risk management advice to producers. Most advisors interviewed accept that weather events are a risk for US Midwestern agriculture; however, they are more concerned about tangible threats such as crop prices. There is not much concern about climate change among agricultural advisors. Management practices that could help producers adapt to climate change were more likely to be recommended by conservation and Extension advisors, while financial and crop advisors focused more upon season-to-season decision making (e.g., hybrid seeds and crop insurance). We contend that the agricultural community should integrate long-term thinking as part of farm decision making processes and that agricultural advisors are in a prime position to influence producers. In the face of increasing extreme weather events, climatologists and advisors should work more closely to reach a shared understanding of the risks posed to agriculture by climate change."
journal_title,Agriculture and Human Values
article_title,"Traditional beneficiaries: trade bans, exemptions, and morality embodied in diets"
keyword,"['Food\xa0', 'Trade\xa0', 'Nutrition transition\xa0', 'Economic sociology\xa0', 'Seal\xa0']"
history,"['2018-06', '2018-01-13', '2017-11-14']"
abstract,"Abstract Research on the nutrition transition often treats dietary changes as an outcome of increased trade and urban living. The Northern Food Crisis presents a puzzle since it involves hunger and changing diets, but coincides with a European ban on trade in seal products. I look to insights from economic sociology and decolonizing scholarship to make sense of the ban on seal products and its impacts. I examine how trade arrangements enact power imbalances in ways that are not always obvious. I explain how the ban’s exemption for Inuit-produced seal goods explicitly aims to protect Inuit from the harshness of capitalism and preserve their traditions. In this respect, the Northern Food Crisis is an embodiment of European visions of who Inuit are expected to be and how they are supposed to act in the global economy."
journal_title,Agriculture and Human Values
article_title,Off to market: but which one? Understanding the participation of small-scale farmers in short food supply chains—a Hungarian case study
keyword,"['Local food systems\xa0', 'Farmers’ markets\xa0', 'Discrete choice model\xa0', 'Transaction Cost Theory\xa0', 'Hungary\xa0']"
history,"['2018-06', '2017-10-23', '2017-09-22']"
abstract,"Abstract The research described in this paper was designed to identify the factors that influence the importance small-scale farmers place on different marketing channels of short food supply chains. The focus concerns two entirely different types of market that are present in the bigger cities in Hungary: ‘conventional’ markets where there are no restrictions on locality but the farmer-market relationship is based on binding contracts, and newly-emergent farmers’ markets at which only local growers can sell ad hoc, using their own portable facilities. Results  are based on a survey that was conducted in 2013 among 156 Hungarian market oriented farmer-vendors at different types of market and confirm that different markets are visited by different types of farmers. Farmers who favour conventional markets are typically less educated, operate on smaller scales and are more committed to their chosen markets via long-term contracts (which reduce the probability of their trying other outlets). The preference for farmers’ markets is stronger with farmers who are more open to cooperation, have specific investment plans for developing their farms and among those who are specifically looking to directly interact with their customers to avoid middlemen. The relevance of the findings is highlighted by the ongoing Short Food Supply Chain Thematic Sub-programme in the present European Union financing period; farmers’ profiles in any given marketing channel must be understood if short food supply chains are to be effectively promoted. Different types of small-scale farmers will benefit from different supporting frameworks, interventions, and initiatives."
journal_title,Agriculture and Human Values
article_title,Extending ethical consumerism theory to semi-legal sectors: insights from recreational cannabis
keyword,"['Political consumerism\xa0', 'Sustainability\xa0', 'Marijuana\xa0', 'Cannabis\xa0', 'Fair trade\xa0', 'Illegal\xa0']"
history,"['2018-06', '2017-08-28', '2017-08-12']"
abstract,"Abstract Ethical consumerism theory aims to describe, explain, and evaluate the ways in which producers and consumers use the market to support social and environmental values. The literature draws insights from empirical studies of sectors that largely take place on the legal market, such as textiles and agri-food. This paper takes a first step toward theorizing ethical consumerism in semi-legal sectors where market activities occur legally and illegally. How does extant theory extend to sectors such as sex work, cigarettes, and recreational drugs? This study draws on the case of recreational cannabis (marijuana) in Portland, OR (USA). Data from 33 interviews, structured fieldwork at 64 dispensaries, and the US Census Bureau American Community Survey are analyzed using qualitative, quantitative, and spatial methods. The findings are compared to 12 suggestions that emerge from the literature on fair trade, organics, alternative agriculture, and political consumerism. I argue that not all ethical consumerism theory extends to semi-legal sectors. Cannabis closely resembles theoretical expectations in terms of supply/demand, prioritization of ethical issues, and pervasiveness of false claims, but differs in terms of who organizes, which types of strategies are pursued, and how ethical products are framed. The differences stem from several pervasive stigmas about cannabis. I also argue that the stigmas that set cannabis apart from other (more legal sectors) and present challenges to ethical consumerism in cannabis are directly related to the War on Drugs. These insights suggest that prohibition (and its lingering effects) can inhibit the emergence of ethical consumerism."
journal_title,Agriculture and Human Values
article_title,Participatory Guarantee Systems (PGS) in Mexico: a theoretic ideal or everyday practice?
keyword,"['Participatory Guarantee Systems\xa0', 'Mexico\xa0', 'Organic certification\xa0', 'Organic agriculture\xa0', 'Farmers’ markets\xa0']"
history,"['2018-06', '2017-12-19', '2017-11-22']"
abstract,"Abstract Third-party certification (TPC), the most common organic certification system, has faced growing criticism in recent years. This has led to the development of alternative certification systems, most of which can be classed as Participatory Guarantee Systems (PGS). PGS have been promoted as a more suitable, cheaper and less bureaucratic alternative to TPC for local markets and are associated with additional benefits such as empowering smallholder farmers, facilitating farmer-to-farmer learning and enhancing food security and sovereignty. PGS have spread rapidly in the past few years, but studies suggest that they are facing numerous challenges that, if not addressed, may jeopardise these benefits. Using the example of three Mexican PGS initiatives, this paper explores the main challenges faced by PGS, specifically those predominantly found in producer-run PGS initiatives. Based on producer and consumer surveys, semi-structured and informal interviews, and participant and non-participant observation, the key challenges that emerged were continuous implementation of the certification process, time constraints, personal conflicts and conflict avoidance. The paper further argues that the requirements for PGS recognition under the Mexican Law for Organic Products may also threaten the continued existence of PGS and suggests that mechanisms for managing conflicts, incentivising PGS participation and mitigating opportunity costs are key if PGS are to continue to develop."
journal_title,Agriculture and Human Values
article_title,How knowledge deficit interventions fail to resolve beginning farmer challenges
keyword,"['Land access\xa0', 'Beginning farmers\xa0', 'Beginning Farmer and Rancher Development Program\xa0', 'Knowledge deficit model\xa0', 'Agricultural policy\xa0', 'Land tenure\xa0']"
history,"['2018-06', '2017-10-07', '2017-09-20']"
abstract,"Abstract Beginning farmer initiatives like the USDA’s Beginning Farmer and Rancher Development Program (BFRDP), farm incubators, and small-scale marketing innovations offer new entrant farmers agricultural training, marketing and business assistance, and farmland loans. These programs align with alternative food movement goals to revitalize the anemic U.S. small farm sector and repopulate landscapes with socially and environmentally diversified farms. Yet even as these initiatives seek to support prospective farmers with tools for success through a knowledge dissemination model, they remain mostly individualistic and entrepreneurial measures that overlook structural barriers to productive and economic success within U.S. agriculture. Analysis of the BFRDP’s funding history and discourse reveals a “knowledge deficit” based program focused on the technical rather than the structural aspects of beginning farming. This is contrasted with qualitative analysis of beginning farmer experiences in California’s Central Coast region. The discrepancies between the farmer experiences and national structure of the BFRDP program ultimately reveal a policy mismatch between the needs of some beginning farmers and the programs intended to support them."
journal_title,Agriculture and Human Values
article_title,Crop diversity in homegardens of southwest Uganda and its importance for rural livelihoods
keyword,"['Agrobiodiversity\xa0', 'Human ecology\xa0', 'Smallholder farmers\xa0', 'Traditional farming\xa0']"
history,"['2018-06', '2017-10-16', '2017-09-28']"
abstract,"Abstract Homegardens are traditional food systems that have been adapted over generations to fit local cultural and ecological conditions. They provide a year-round diversity of nutritious foods for smallholder farming communities in many regions of the tropics and subtropics. In southwestern Uganda, homegardens are the primary source of food, providing a diverse diet for rural marginalized poor. However, national agricultural development plans as well as economic and social pressures threaten the functioning of these homegardens. The implications of these threats are difficult to evaluate, because the structure and functions of the homegardens are not well understood. The aim of the study was to identify patterns and influencing factors in the diversity of homegardens by documenting the floristic diversity and its interactions with spatial, environmental and socio-economic factors. A geographically and socially focused assessment of floristic diversity in 102 randomly selected homegardens in three districts of southwest Uganda was conducted along a deforestation gradient following a human ecology conceptual framework and testing multiple quantitative hypotheses regarding the above mentioned factors. A merged mixed-method approach was followed to provide context and feedback regarding quantitative findings. Results  show a high total richness of 209 (mean 26.8 per homegarden) crop species (excluding weeds and ornamentals) dominated by food species, which constituted 96 percent of individuals and 44 percent of all species. Forest-edge homegardens maintained higher plant diversity compared to homegardens in deforested areas and near degraded wetlands. Multiple linear regression models indicated elevation, location, homegarden size, distance to market, additional land ownership (outside the homegarden) and livestock ownership as significant predictors of crop diversity. Cluster analysis of species densities revealed four garden types: ‘diverse tree gardens’, ‘small forest-edge gardens’, ‘large, old, species-rich gardens’, and ‘large, annual-dominated herb gardens’, with 98% correct classification. Location, elevation, and garden size were also important determinants in the cluster assignment. We conclude that the diversity of the studied homegardens may be changing as part of adaptive traditional practices and in response to external drivers. The identified patterns illustrate the importance of homegardens for rural livelihoods and may offer some ways to support farmers to maintain these systems as relevant mechanisms for development in Uganda."
journal_title,Agriculture and Human Values
article_title,Cooptation or solidarity: food sovereignty in the developed world
keyword,"['Food ethics\xa0', 'Food sovereignty\xa0', 'Food justice\xa0', 'Solidarity\xa0']"
history,"['2018-06', '2017-08-23', '2017-08-16']"
abstract,"Abstract This paper builds on previous research about the potential downsides of food sovereignty activism in relatively wealthy societies by developing a three-part taxonomy of harms that may arise in such contexts. These are direct opposition, false equivalence, and diluted goals and methods. While this paper provides reasons to resist complacency about wealthy-world food sovereignty, we are optimistic about the potential for food sovereignty in wealthy societies, and we conclude by describing how wealthy-world food sovereignty can be a location of either transnational solidarity or (at least) nonharmful forms of cooptation."
journal_title,Agriculture and Human Values
article_title,Socio-economic research on genetically modified crops: a study of the literature
keyword,"['Socio-economic impacts\xa0', 'Genetically modified crops\xa0', 'Research methods\xa0']"
history,"['2018-06', '2017-12-09', '2017-11-22']"
abstract,"Abstract The importance of socio-economic impacts (SEI) from the introduction and use of genetically modified (GM) crops is reflected in increasing efforts to include them in regulatory frameworks. Aiming to identify and understand the present knowledge on SEI of GM crops, we here report the findings from an extensive study of the published international scientific peer-reviewed literature. After applying specified selection criteria, a total of 410 articles are analysed. The main findings include: (i) limited empirical research on SEI of GM crops in the scientific literature; (ii) the main focus of the majority of the published research is on a restricted set of monetary economic parameters; (iii) proportionally, there are very few empirical studies on social and non-monetary economic aspects; (iv) most of the research reports only short-term findings; (v) the variable local contexts and conditions are generally ignored in research methodology and analysis; (vi) conventional agriculture is the commonly used comparator, with minimal consideration of other substantially different agricultural systems; and (vii) there is the overall tendency to frame the research upon not validated theoretical assumptions, and to over-extrapolate small-scale and short-term specific results to generalized conclusions. These findings point to a lack of empirical and comprehensive research on SEI of GM crops for possible use in decision-making. Broader questions and improved methodologies, assisted by more rigorous peer-review, will be required to overcome current research shortcomings."
journal_title,Agriculture and Human Values
article_title,Drawing lines in the cornfield: an analysis of discourse and identity relations across agri-food networks
keyword,"['Agri-food networks\xa0', 'Power\xa0', 'Discourse\xa0', 'Identity\xa0', 'Conventional agriculture\xa0', 'Alternative food movements (AFM)\xa0']"
history,"['2018-06', '2017-10-25', '2017-10-12']"
abstract,"Abstract In this article, I analyze discourse and identity relations within so-called ‘conventional’ agri-food networks as well as how the conventional sphere perceives, constructs and responds to alternative food movements in Canada. The paper is structured around three primary research questions: (1) How are conventional actors understanding conditions, changes, and challenges within conventional networks? (2) How do conventional actors apply this understanding in advancing conventional interests and discourses, and defending conventional networks? (3) How do conventional actors and discourse construct AFMs? For this research, I draw from survey, focus group, and in-depth interview data alongside text analysis from online sources. I elucidate the interests and motivations behind the identities, stories and messages emerging from the conventional sphere. I conclude that relationship building and communication between diverse agri-food actors may help to expand the range of agricultural knowledge, philosophies and solutions available to farmers, especially those whom are currently quite divided."
journal_title,Agriculture and Human Values
article_title,Civic seeds: new institutions for seed systems and communities—a 2016 survey of California seed libraries
keyword,"['California\xa0', 'Community science\xa0', 'Food gardens\xa0', 'Seed library\xa0', 'Seed system\xa0', 'Urban agriculture\xa0']"
history,"['2018-06', '2017-09-19', '2017-08-24']"
abstract,"Abstract Seed libraries (SLs) are institutions that support the creation of semi-formal seed systems, but are often intended to address larger issues that are part of the “food movement” in the global north. Over 100 SLs are reported present in California. I describe a functional framework for studying and comparing seed systems, and use that to investigate the social and biological characteristics of California SLs in 2016 and how they are contributing to alternative seed systems based on interviews with 45 SL managers. At a minimum, SLs function as new seed distribution institutions founded and overseen by dedicated, values-driven individuals and groups with goals including education, seed access, local adaptation, biodiversity conservation, community-building, and human health. Annually about 4776 people borrow seeds from, and 238 people return seeds to the SLs in this study, that operate through over 17,000 hours of work/year. These SLs distribute approximately 6456 packets of seed annually, mostly of commercial seeds from small seed companies, but some SLs emphasize local and culturally meaningful seeds. The significance of a 6% seed return rate depends on SL goals and can be investigated once appropriate indicators for those goals are identified and documented. Beyond distribution, the seed system functions accomplished by SLs differ, and all can have consequences for the processes shaping the diversity and adaptation of their crops. The SLs engaged in seed system functions beyond distribution are new forms of socially-motivated community science, poised to develop biological and social innovations reflecting their values and interests."
journal_title,Agriculture and Human Values
article_title,Can sustainability auditing be indigenized?
keyword,"['Audit culture\xa0', 'Indigenous\xa0', 'Indigenous knowledge\xa0', 'Instrumentation\xa0', 'Māori\xa0', 'Market assurance\xa0', 'Standardization\xa0', 'Sustainability\xa0', 'Sustainable agriculture\xa0']"
history,"['2018-06', '2017-10-10', '2017-06-10']"
abstract,"Abstract Although there are different approaches to sustainability auditing, those considered authoritative use scientific indicators and instruments to measure and predict the impact of organizational operations on socio-ecological systems. Such approaches are biased because they can only measure phenomena whose features lend themselves to quantification, control, and observation directly with the instruments produced by technology. This technocratic bias is a product of the mechanistic worldview, which presumes that all components of socio-ecological systems are identifiable, discrete, and material. In contrast to the mechanistic worldview, indigenous people use animist familial representations. In the case of New Zealand Māori a family tree (whakapapa) is used to represent socio-ecological systems. This is a flexible conception, which views socio-ecological systems as both composites made up of interlinking causally-connected parts but also as reciprocating systems that have intangible elements such as consciousness, emotion, and agency. The technocratic approach is ontologically incapable of incorporating intangible elements to such a degree we consider that it incompatible with animist approaches. It is not, however, epistemologically-incongruous for indigenous peoples because of the flexible hybridity of their worldview. This worldview provides a broad moral framework, which avoids discrediting subjectivity and reducing socio-ecological systems to only their instrumental value. Finally, we conclude that the indigenous approach has much to offer the field of sustainability auditing, given that it provides a moral framework, and insight into building assessment systems upon abductive reasoning."
journal_title,Agriculture and Human Values
article_title,Seeing below the surface: making soil processes visible to Ugandan smallholder farmers through a constructivist and experiential extension approach
keyword,"['Agricultural extension\xa0', 'Experiential learning\xa0', 'Soil fertility management\xa0', 'Uganda\xa0', 'Smallholder farmers\xa0']"
history,"['2018-06', '2017-10-16', '2017-10-07']"
abstract,"Abstract Ugandan smallholder farmers need to feed a growing population, but their efforts are hampered by declining soil fertility rates. Agricultural extension can facilitate farmers’ access to new practices and technologies, yet farmers are understandably often hesitant to adopt new behaviors. New knowledge assimilation is an important component of behavior change that is often overlooked or poorly addressed by current extension efforts. We implemented a Fertility Management Education Program (FMEP) in central Uganda to investigate smallholder farmers’ existing soil knowledge and their assimilation of new scientific concepts into their knowledge framework. Qualitative data were collected through participant observation, farmer interviews, and focus groups, and coded for using a priori and emergent themes. Our exploration revealed some notable similarities between farmers’ soil knowledge and scientific concepts, particularly in regards to soil health concepts, a discovery that could facilitate communication between extension agents and farmers. However, certain scientific concepts are either unknown to farmers or discordant with existing soil knowledge; these concepts are unlikely to be assimilated by farmers without convincing and concerted extension efforts. Importantly, we found that the combination of new scientific knowledge and hands-on experimentation with novel practices gave farmers far greater confidence in implementing improved soil management practices. Our study provides evidence that extension programs should engage directly with farmers’ existing soil knowledge to develop their understanding of key biological concepts and confidence in implementing improved practices."
journal_title,Agriculture and Human Values
article_title,Moving away from technocratic framing: agroecology and food sovereignty as possible alternatives to alleviate rural malnutrition in Bangladesh
keyword,"['Agroecology\xa0', 'Biodiversity\xa0', 'Capitalist agriculture\xa0', 'Food security\xa0', 'Food sovereignty\xa0', 'Malnutrition\xa0', 'Bangladesh\xa0']"
history,"['2018-06', '2017-12-12', '2017-12-01']"
abstract,"Abstract Bangladesh continues to experience stubbornly high levels of rural malnutrition amid steady economic growth and poverty reduction. The policy response to tackling malnutrition shows an overwhelmingly technocratic bias, which depoliticizes the broader question of how the agro-food regime is structured. Taking an agrarian and human rights-based approach, this paper argues that rural malnutrition must be analyzed as symptomatic of a deepening agrarian crisis in which the obsession with productivity increases and commercialization overrides people’s democratic right to culturally appropriate, good, nutritious food. Using qualitative insights from a case study of three villages, this research illustrates how agricultural modernization and commercialization reproduce rural malnutrition by degrading local biodiversity and the rural poor’s access to nutrient-rich diets. In so doing, it undermines the official discourse’s simplistic and literal reading of malnutrition as a pathological health condition resulting from the mere absence of certain micronutrients in the human body, and thus questions the adequacy of the proposed solutions. Instead, this research suggests that solving malnutrition in large part involves facilitating the rural poor’s access to nutritious diets through democratizing and reorganizing the agriculture sector in a manner that is eco-friendly and unconstrained by market imperatives. It cautiously advances agroecology and food sovereignty as possible alternatives, while recognizing that overcoming the challenges agrarian class conflict, gender disparity and urban–rural divide pose would not be easy."
journal_title,Agriculture and Human Values
article_title,"Images of work, images of defiance: engaging migrant farm worker voice through community-based arts"
keyword,"['Migrant farm workers\xa0', 'Theatre of the Oppressed\xa0', 'Seasonal Agricultural Worker Program\xa0', 'Guest worker programs\xa0', 'Unfree labour\xa0', 'Canada\xa0']"
history,"['2018-03-29', '2018-03-23']"
abstract,"Abstract This article addresses a stated need within the food justice movement scholarship to increase the attention paid to the political socialization of hired farm hands in industrial agriculture. In Canada, tackling the problem of farm worker equity has particular social and political contours related to the Canadian horticultural industry’s reliance on a state-managed migrant agricultural labour program designed to fill the sector’s labour market demands. As Canada’s Seasonal Agricultural Worker Program (SAWP) produces relations of ‘unfree labour’, engaging migrant farm workers in social movement initiatives can be particularly challenging. Critical educational interventions designed to encourage migrant farm workers’ contribution to contemporary social movements in Canada must therefore confront the socio-cultural obstacles that constrict migrant farm workers’ opportunities to participate as full members of their communities. In this article, I argue that social justice oriented approaches to community-based arts can provide a means for increasing the social movement contributions of farm workers employed through managed labour migration schema such as Canada’s SAWP."
journal_title,Agriculture and Human Values
article_title,Decoupling from international food safety standards: how small-scale indigenous farmers cope with conflicting institutions to ensure market participation
keyword,"['Small-scale producers\xa0', 'Institutional logics\xa0', 'Food safety regulations\xa0', 'Local food systems\xa0', 'School feeding programs\xa0', 'Bolivia\xa0']"
history,"['2018-03-21', '2018-03-09']"
abstract,"Abstract Although inclusion in formal value chains extends the prospect of improving the livelihoods of rural small-scale producers, such a step is often contingent on compliance with internationally-promoted food safety standards. Limited research has addressed the challenges this represents for small rural producers who, grounded in culturally-embedded food safety conceptions, face difficulties in complying. We address this gap here through a multiple case study involving four public school feeding programs that source meals from local rural providers in the Bolivian Altiplan. Institutional logics theory is used to describe public food safety regulations and to compare them to food safety conceptions in the local indigenous Aymara rural setting. We identify a value-based conflict that leads to non-compliance of formal food safety rules that jeopardizes the participation of small farmers in the market. These include: (1) partial adoption of formal rules; (2) selective adoption of convenient rules; and (3) ceremonial adoption to avoid compliance. Decoupling strategies allow local actors to largely disregard the formal food safety regulations while accommodating traditional cultural practices and continuing to access the market. However, these practices put the long-term sustainability of the farmers’ participation in potentially favorable opportunities at risk."
journal_title,Agriculture and Human Values
article_title,Peter Dauvergne: Environmentalism of the rich
keyword,[]
history,"['2018-03', '2017-06-26', '2017-05-19']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Carlisle, Liz: Lentil underground: renegade farmers and the future of food in America"
keyword,[]
history,"['2018-03', '2017-06-06', '2017-05-02']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Amanda Kennedy and Jonathan Liljeblad (eds.): Food systems governance: challenges for justice, equality and human rights"
keyword,[]
history,"['2018-03', '2017-06-15', '2017-06-09']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Alex V. Barnard: Freegans: diving into the wealth of food waste in America
keyword,[]
history,"['2018-03', '2017-06-06', '2017-04-17']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Ndongo S. Sylla: The Fair Trade scandal: marketing poverty to benefit the rich
keyword,[]
history,"['2018-03', '2017-07-31', '2017-05-22']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Books received
keyword,[]
history,"['2018-03', '2017-12-12']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Richa Kumar: Rethinking revolutions: soyabean, choupals, and the changing countryside in Central India"
keyword,[]
history,"['2018-03', '2017-06-06', '2017-04-24']"
abstract,None
journal_title,Agriculture and Human Values
article_title,""" We are a business, not a social service agency."" Barriers to widening access for low-income shoppers in alternative food market spaces"
keyword,"['Food justice\xa0', 'Food security\xa0', 'Farmers’ markets\xa0', 'Poverty\xa0', 'Food access\xa0', 'Alternative food networks\xa0']"
history,"['2018-03', '2017-07-04', '2017-06-13']"
abstract,"Abstract Alternative food networks are emerging in opposition to industrial food systems, but are criticized as being exclusive, since customers’ ability to patronize these market spaces is premised upon their ability to pay higher prices for what are considered the healthiest, freshest foods. In response, there is growing interest in widening the demographic profile given access to these alternative foods. This research asks: what barriers do alternative food businesses face in providing access and inclusion for low income consumers? Surveys and interviews with 45 alternative food businesses in British Columbia, Canada uncovered five key barriers. The findings indicate that the barriers are symptomatic of structural issues in the Canadian food and social welfare systems. Although opportunities exist for business operators to widen access for low income shoppers, these alone cannot meaningfully ameliorate food-access inequality. Rather, these barriers underscore issues of income-disparity, poverty, and food-access inequality more broadly, and require structural and societal change to rectify."
journal_title,Agriculture and Human Values
article_title,Changes in Ghanaian farming systems: stagnation or a quiet transformation?
keyword,"['Agriculture\xa0', 'Intensification\xa0', 'Farming systems\xa0', 'Stagnation\xa0', 'Transformation\xa0', 'Green Revolution\xa0', 'Ghana\xa0', 'Africa south of the Sahara\xa0']"
history,"['2018-03', '2017-05-02', '2017-04-03']"
abstract,"Abstract This research was designed to understand better the patterns of agricultural intensification and transformation occurring in Africa south of the Sahara using the Ghanaian case. The paper examines changes in farming systems and the role of various endogenous and exogenous factors in driving the conversion of arable lands to agricultural uses in four villages within two agro-ecologically distinct zones of Ghana: the Guinea Savannah and Transition zones. Using historical narratives and land-cover maps supplemented with quantitative data at regional levels, the research shows that farming has intensified in the villages, as farmers increased their farm size in response to factors such as population growth, market access, and changing rural lifestyle. The overall trend suggests a gradual move toward intensification through increasing use of labor-saving technologies rather than land-saving inputs—a pattern that contrasts with Asia’s path to its Green Revolution. The findings in this paper provide evidence of the dynamism occurring in African farming systems; hence, they point toward a departure from stagnation narratives that have come to prevail in the debate on agricultural transformation and intensification in Africa south of the Sahara. We conclude that it is essential for future research to expand the scope of this work, while policies should focus on lessons learned from these historical processes of genuine change and adaptation."
journal_title,Agriculture and Human Values
article_title,Farm to school in British Columbia: mobilizing food literacy for food sovereignty
keyword,"['Food sovereignty\xa0', 'Food literacy\xa0', 'Farm to school\xa0']"
history,"['2018-03', '2017-07-18', '2017-07-03']"
abstract,"Abstract Farm to school programs have been positioned as interventions that can support goals of the global food sovereignty movement, including strengthening local food production systems, improving food access and food justice for urban populations, and reducing distancing between producers and consumers. However, there has been little assessment of how and to what extent farm to school programs can actually function as a mechanism leading to the achievement of food sovereignty. As implemented in North America, farm to school programs encompass activities not only related to school food procurement, but also to the development of student knowledge and skills under the framework of food literacy. Research on farm to school initiatives has largely been conducted in countries with government-supported national school feeding programs; this study examines farm to school organizing in Canada, where there is no national student nutrition program. Using qualitative fieldwork and document analysis, we investigate the farm to school movement in British Columbia, in a context where civil society concerns related to education and health have been the main vectors of farm to school mobilization. Our analysis suggests that, despite limited institutional infrastructure for school meals, the British Columbia farm to school movement has contributed toward realizing goals of food sovereignty through two main mechanisms: advocacy for institutional procurement of local and sustainable foods and mobilizing food literacy for increased public engagement with issues of social justice and equity in food systems."
journal_title,Agriculture and Human Values
article_title,Hiding hunger: food insecurity in middle America
keyword,"['Asset Vulnerability Framework\xa0', 'Community based research\xa0', 'Poverty shaming\xa0']"
history,"['2018-03', '2017-07-28', '2017-07-20']"
abstract,"Abstract This is a community based research project using a case study of 20 people living in middle America who are food insecure, but do not use food pantries. The participants’ rate of actual hunger is twice that of food insecure community members who use food pantries. Since most of the participants are not poor, the Asset Vulnerability Framework (AVF) is used to classify causes of food insecurity. The purpose of the study is to identify why participants are food insecure and why they do not use food pantries. Findings reveal that the participants restrict the quality and quantity of food eaten as a strategy to manage their budget. Following AVF, this strategy allows them to offset lower returns to labor assets, cover rising costs of human capital investment, protect their two most important productive assets of housing and transportation, and compensate for household relationships that increase their vulnerability. In addition, food insecurity itself inhibited social capital formation, further increasing vulnerability. The main reasons the participants do not use food pantries is to protect their social capital assets: almost all of the participants hid their hunger from colleagues, friends, relatives, and even the people they lived with. The participants described fear of societal shaming and blaming as motivations for hiding their hunger. However, using food pantries could reduce their food insecurity. Therefore, there was a feedback loop between food insecurity and social capital: food insecurity reduced social capital and efforts to protect social capital prevented participants from improving food security by using food pantries."
journal_title,Agriculture and Human Values
article_title,Metropolitan farmers markets in Minneapolis and Vienna: a values-based comparison
keyword,"['Metropolitan farmers markets\xa0', 'Values\xa0', 'Minneapolis\xa0', 'Vienna\xa0']"
history,"['2018-03', '2017-05-22', '2017-05-01']"
abstract,"Abstract Farmers markets (FMs) have traditionally served as a space for farmers to sell directly to consumers. Recently, many FMs in the US and other regions have experienced a renaissance. This article compares the different value sets embedded in the rules and norms of two metropolitan FM regions—Minneapolis, Minnesota and in Vienna, Austria. It uses a values-based framework that reflects the relationships among FM operating structures (OS) and their values reflected by the key FM participants—i.e., farmer/vendors, consumers and market managers. The framework allows us to focus on two very contrasting value sets of metropolitan FM regions in (1) presenting and discussing the values found and embedded in the two metropolitan market regions; (2) illustrating how the values found are embodied as rules and norms in each FM region; (3) considering the alignment or not of FM participant values with their corresponding FM values; and (4) the differences and commonalities as well as the benefits and challenges of the two market regions. In contrasting metropolitan FMs we explain that FM value sets are complex and differ among and within FM participant groups and are dependent on their respective OS. We show that contrasting two metropolitan FM regions can be useful in understanding beneficial and disadvantageous relationships between the values and structures of, and in FMs, and specifically in examining institutional impediments such as governance. Thus we illustrate the possibilities and limitations of values for and within metropolitan FMs."
journal_title,Agriculture and Human Values
article_title,Indigenous worldviews and Western conventions: Sumak Kawsay and cocoa production in Ecuadorian Amazonia
keyword,"[None, 'Indigenous worldviews\xa0', 'Convention theory\xa0', 'Subaltern relations\xa0', 'Agrofood chains\xa0', 'Cocoa\xa0']"
history,"['2018-03', '2017-06-24', '2017-06-13']"
abstract,"Abstract This article explores the role of conventions in the normalization of cocoa production in Ecuadorian Amazonia. Convention theory provides key theoretical tools for understanding coordination among agents. However, conventions must be understood as cultural constructions with a strong Eurocentric background that must be substantially modified in originally non-European contexts. A creative application of convention theory can partially overcome bifurcation among Western and non-Western rationalities. First, it shows that Western values and forms of coordination are heterogeneous, conflictive and opposing. Second, it provides key insight for understanding the transformation of subaltern subjectivities generated from non-Western rationalities that are closely associated with subjugated knowledges. Third, in applying the concept of compromise, it allows one to understand cognitive hybridization and coordination among indigenous and Western agents and thus the complexities of processes of resistance, subversion and empowerment carried by indigenous communities. This article is focused on how cocoa production in Ecuadorian Amazonia serves as an example of the confluence and coordination of indigenous (using the concept of “Good Living” or Sumak Kawsay) and Western conventions. The assertion of Sumak Kawsay is understood as a relevant transformation of Ecuadorian post-colonial relations. It is shown that relevant industrial upgrading processes are justified by, among others, Sumak Kawsay repertoires. Additionally, dialogue on knowledge and compromise among conventions, and especially concerning Sumak Kawsay and the market, have been key facets shaping the development of a differentiated quality strand that has promoted relevant changes in the subaltern positioning of indigenous farmers in the cocoa commodity chain."
journal_title,Agriculture and Human Values
article_title,Governing large-scale farmland acquisitions in Québec: the conventional family farm model questioned
keyword,"['Land governance\xa0', 'Family farm\xa0', 'Food regime\xa0', 'Food sovereignty\xa0', 'Canada\xa0', 'Québec\xa0']"
history,"['2018-03-01', '2018-02-12']"
abstract,"Abstract This article argues that the definition of land grabs in public debate is a politically contested process with profound normative consequences for policy recommendations regarding the future of the family farm model. To substantiate this argument, I first explore how different definitions of land grabbing bring into focus different kinds of actors and briefly survey the history of land grabbing in Canada. I then introduce the public debate about land grabbing in Québec and discuss its evolution from its beginning in 2009 up until the provincial public inquiry on land grabs in March 2015. Here, I make critical observations regarding each participant’s position, showing how different definitions of land grabbing has significant implications for policy recommendation and the promotion of different agricultural business models. More specifically, I emphasize how these discussions crucially fail to consider indigenous people’s land rights and ignore the constraints imposed by the corporate food regime on family farms. I conclude by suggesting that the adoption of a food sovereignty approach to land governance helps redirect attention to these important issues and provide insight into imagining more sustainable alternative models of agriculture."
journal_title,Agriculture and Human Values
article_title,Sustainable palm oil as a public responsibility? On the governance capacity of Indonesian Standard for Sustainable Palm Oil (ISPO)
keyword,"['Governance capacity\xa0', 'Palm oil\xa0', 'ISPO\xa0', 'Public certification\xa0', 'Sustainability standards\xa0']"
history,"['2018-03', '2017-07-31', '2017-07-11']"
abstract,"Abstract This paper is motivated by the observation that Southern governments start to take responsibility for a more sustainable production of agricultural commodities as a response to earlier private initiatives by businesses and non-governmental organizations (NGOs). Indonesia is one of the leading countries in this respect, with new public sustainability regulations on coffee, cocoa and palm oil. Based on the concept of governance capacity, the paper develops an evaluation tool to answer the question whether the new public regulation on sustainable palm oil (ISPO) may become a viable alternative to private regulation. ISPO embraces a tremendous governance challenge as thousands of companies and millions of smallholder farmers are expected to participate. It is concluded that, although ISPO has initiated a process of change, it has not yet developed its full potential. The main reason regards ISPO’s rather loose problem definition, weak authority of the implementing organization, and the fact that the reliability of ISPO is still too low to convince (parts) of the global market. ISPO may therefore face difficulties in meeting its own targets and solving palm-oil related problems, such as deforestation, biodiversity loss, greenhouse gas emissions, and social conflicts between big plantations and local communities. The main governance challenge regards combining a more authoritative implementation mechanism with a convincing balance between sustainability objectives and economic interests of the sector."
journal_title,Agriculture and Human Values
article_title,"Beyond polarization: using Q methodology to explore stakeholders’ views on pesticide use, and related risks for agricultural workers, in Washington State’s tree fruit industry"
keyword,"['Q methodology\xa0', 'Pesticide safety\xa0', 'Polarization\xa0', 'Stakeholders\xa0']"
history,"['2018-03', '2017-06-30', '2017-06-15']"
abstract,"Abstract Controversies in food and agriculture abound, with many portrayed as conflicts between polarized viewpoints. Framing such controversies as dichotomies, however, can at times obscure what might be a plurality of views and potential common ground on the subject. We used Q methodology to explore stakeholders’ views about pesticide safety, agricultural worker exposure, and human health concerns in the tree fruit industry of central Washington State. Using a purposive sample of English and Spanish-speaking agricultural workers, industry representatives, state agencies, educators, and advocates (n = 41), participants sorted 45 statements on pesticide use and perceived human safety risks in the tree fruit industry in 2011. We used PQMethod 2.33 statistical software program to identify viewpoints, based on differences between how participants sorted the statements. The results revealed three distinct viewpoints among 38 sorters that explained 52 percent of the variance. The viewpoints included the: (1) skeptics (n = 22) who expressed concern over the environmental and human health impacts of pesticide use; (2) acceptors (n = 10) who acknowledged inherent risks for using pesticides but saw the risks as known, small and manageable; and (3) incrementalists (n = 6) who prioritized opportunities to introduce human capital and technological improvements to increase agricultural worker safety. We then brought representatives with these different viewpoints together to analyze the results of the Q study, and to brainstorm mutually acceptable improvements to health and safety in tree fruit orchards. In describing and analyzing this case study, we argue that Q methodology can serve as one potentially effective tool for collaborative work, in this case facilitating a process of orchard safety improvements despite perceived stakeholder polarization."
journal_title,Agriculture and Human Values
article_title,Farmers’ perceptions of coexistence between agriculture and a large scale coal seam gas development
keyword,"['Landscape aesthetics\xa0', 'Place identity\xa0', 'Land use change\xa0', 'Off-farm income\xa0', 'Coal bed methane\xa0']"
history,"['2018-03', '2017-06-13', '2017-05-18']"
abstract,"Abstract The Coal Seam Gas (CSG) extraction industry is developing rapidly within the Surat Basin in southern Queensland, Australia, with licenses already approved for tenements covering more than 24,000 km2. Much of this land is used for a broad range of agricultural purposes and the need for coexistence between the farm and gas industries has been the source of much conflict. Whilst much research has been undertaken into the environmental and economic impacts of CSG, little research has looked into the issues of coexistence between farmers and the CSG industry in the shared space that is a farm business, a home and a resource extraction network. We conducted three workshops with farmers from across a broad region undergoing CSG development to explore farmers’ perceptions of some of the issues arising from large scale land use change. Workshops explored the importance of place identity and landscape aesthetics for farmers, farmers’ acceptance and coping with change, and possible benefits from off-farm income. We found that farmers believed that place identity was not well understood by CSG staff from non-rural backgrounds and that farmers struggled to explain some concerns because of the different way they interpreted their landscape. Furthermore, high staff turnover, and the extensive use of contractors also impacted on communications. These factors were the cause of much frustration and farmers felt that this has led to severe impacts on mental health and wellbeing. Farmers felt that a change in culture within the CSG companies will be required if engagement with farmers is to improve and that efforts to employ local people in these communications was helping this. The workshops also identified a range of issues perceived by farmers arising from increased traffic volumes, impacts to mental health and wellbeing, place identity and loss of water resources for farmers. Finally, it was suggested that scientists and agricultural industry groups will need to work closely with farmers to develop understanding of these emerging issues and to develop solutions that are timely and relevant."
journal_title,Agriculture and Human Values
article_title,Why is meat so important in Western history and culture? A genealogical critique of biophysical and political-economic explanations
keyword,"['Meat\xa0', 'Agricultural history\xa0', 'Environmental history\xa0', 'Sustainability\xa0', 'Nutrition\xa0', 'Culture\xa0', 'Consumption\xa0']"
history,"['2018-03', '2017-06-07', '2016-09-13']"
abstract,"Abstract How did meat emerge to become such an important feature in Western society? In both popular and academic literatures, biophysical and political-economic factors are often cited as the reason for meat’s preeminent status. In this paper, we perform a comprehensive investigation of these claims by reviewing the available evidence on the political-economic and biophysical features of meat over the long arc of Western history. We specifically focus on nine critical epochs: the Paleolithic (200,000 YA—10,000 YA), early to late Neolithic (10,000 YA—2500 BCE), antiquity (2500 BCE—550 CE), ancient Israel and early Christian societies (1550 BCE—379 CE), medieval Europe (476 CE—1400 CE), early modern Europe (1400–1800), colonial America (1607–1776), the American frontier (1776–1890), and the modern industrial era (1890—present). We find that except under conditions of environmental scarcity, the meaning and value of meat cannot be attributed to intrinsic biophysical value or to the political-economic actors who materially benefit from it. Rather, meat’s status reflects the myriad cultural contexts in which it is socially constructed in people’s everyday lives, particularly with respect to religious, gender, communal, racial, national, and class identity. By deconstructing the normalized/naturalized materialist assumptions circling around meat consumption, this paper clears a space for a more nuanced appreciation of the role that culture has played in the legitimation of meat, and by extension, the possibility of change."
journal_title,Agriculture and Human Values
article_title,Contested fields: an analysis of anti-GMO politics on Hawai’i Island
keyword,"['Hawai’i\xa0', 'Agricultural biotechnology\xa0', 'Anti-GMO activism\xa0', 'Agrarian politics\xa0', 'Food sovereignty\xa0']"
history,"['2018-03', '2017-07-07', '2017-06-24']"
abstract,"Abstract This paper details the evolution of activism against genetically modified organisms on the Big Island of Hawai’i. It offers an explanation for the ability of rural residents on the Big Island to pass anti-GMO legislation while other states and communities have tried and failed. I argue that the Big Island’s recent anti-GMO legislative success is due to the articulation of interests and actions between settlers to Hawai’i and Native Hawaiian community members seeking to protect Native Hawaiian rights. Tracing the history of the anti-GMO movement on Big Island highlights the unique circumstances that facilitated the passage of this bill, and is also significant for making sense of the potential future trajectories of anti-GMO-related food sovereignty movements elsewhere."
journal_title,Agriculture and Human Values
article_title,A climate for commerce: the political agronomy of conservation agriculture in Zambia
keyword,"['Conservation agriculture\xa0', 'Climate smart agriculture\xa0', 'Green revolution\xa0', 'Political agronomy\xa0', 'Norway\xa0', 'Zambia\xa0']"
history,"['2018-03', '2017-09-09', '2017-08-02']"
abstract,"Abstract The promotion of conservation agriculture (CA) for smallholders in sub-Saharan Africa is subject to ongoing scholarly and public debate regarding the evidence-base and the agenda-setting power of involved stakeholders. We undertake a political analysis of CA in Zambia that combines a qualitative case study of a flagship CA initiative with a quantitative analysis of a nationally representative dataset on agricultural practices. This analysis moves from an investigation of the knowledge politics to a study of how the political agendas of the actors involved are shaping agrarian practices. From its initial focus on CA as soil conservation and sustainable agriculture, the framing of the initiative has evolved to accommodate shifting trends in the policy arena. In tandem with the increased focus on climate adaptation, we see an increased emphasis on private sector-led modernisation. The initiative has shifted its target group from the poorest smallholders to prospective commercial farmers, and has forged connections between its farmer-to-farmer extension network and private input suppliers and service providers. The link between CA and input intensification is reflected in national statistics as a significantly higher usage of herbicides, pesticides and mineral fertilizer on fields under CA tillage compared to other fields. We argue that the environmental and participation agendas are used to buttress CA as an environmentally and socially sustainable agricultural development strategy, while the prevailing practice is the result of a common vision for a private sector-led agricultural development shared between the implementing organisation, the donor and international organisations promoting a new green revolution in Africa."
journal_title,Agriculture and Human Values
article_title,"Reconnecting through local food initiatives? Purpose, practice and conceptions of ‘value’"
keyword,"['Short food supply chains\xa0', 'Producer consumer re-connection\xa0', 'Local food\xa0', 'Local food initiatives\xa0', 'Value proposition\xa0']"
history,"['2018-03', '2017-05-19', '2017-04-06']"
abstract,"Abstract Reconnection between producers and consumers is often presented as an integral part of the local food narrative. However, questions can arise as to whether local food producers and their food purchasers align in mindset and the value proposition that underpins their involvement. This paper draws on interview data collected from producers and consumers participating in direct-sell meat operations to explore so-called value propositions between these two actors in local food initiatives (LFIs) in Southwestern Ontario, Canada. We suggest that because producers and consumers value their participation and associated ‘reconnection’ for different reasons and experience practical limitations in satisfying diverse expectations, the ‘reconnection’ metaphor is complex and contingent—especially at the level of the individual. The findings suggest that new roles, realities and beliefs for each party in regard to marketing, customer relations, distribution, and (in)convenience might predispose participants to be in favor of other arrangements (without direct contact) if they became more readily available and were capable of guaranteeing both profitability for the producer and healthy foods for the consumer."
journal_title,Agriculture and Human Values
article_title,Routine inertia and reactionary response in animal health best practice
keyword,"['Animal health\xa0', 'Technology adoption\xa0', 'Attitudes\xa0', 'Behaviour\xa0', 'Mixed methods\xa0']"
history,"['2018-03', '2017-07-28', '2017-07-03']"
abstract,"Abstract Animal health is a key factor affecting the economic efficiency of the dairy industry. Improvements in animal health are also of relevance to society more broadly, given important implications for animal welfare, food safety and quality. Although the economic gains of best practice with regard to animal health have been well documented, many farmers are not adopting optimal herd management techniques. This paper utilises nationally representative farm-level data from Ireland for 2013 to identify drivers and barriers to the adoption of best practice with regard to on-farm mastitis management. Exploratory factor analysis is used to derive measures of farmers’ attitudes towards animal health and mastitis and econometric techniques are employed to empirically assess the influence of these on the uptake of beneficial herd health management practices. A number of focus groups were also undertaken to complement the analysis. This paper concludes that farmers’ attitudes towards animal health are not a key driver in the uptake of best practice, although perceived disease risk is of relevance. A number of interesting issues arise in identifying barriers to the uptake of best practice, these include the possibility of routine inertia, i.e., farmers do not deviate from the routine developed around mastitis prevention until there is an indication of infection, as well as constraints around the availability of labour and time. Farmer behaviour with respect to mastitis management can thus be considered as reactionary as opposed to precautionary. This research highlights the valuable role of the extension agent but concludes that engagement around knowledge transfer and technology adoption is particularly complex."
journal_title,Agriculture and Human Values
article_title,Stacking functions: identifying motivational frames guiding urban agriculture organizations and businesses in the United States and Canada
keyword,"['Food justice\xa0', 'Framing\xa0', 'Motivations\xa0', 'Non-profit organizations\xa0', 'Survey\xa0', 'Urban gardens\xa0']"
history,"['2018-03', '2017-04-04', '2017-03-22']"
abstract,"Abstract While a growing body of scholarship identifies urban agriculture’s broad suite of benefits and drivers, it remains unclear how motivations to engage in urban agriculture (UA) interrelate or how they differ across cities and types of organizations. In this paper, we draw on survey responses collected from more than 250 UA organizations and businesses from 84 cities across the United States and Canada. Synthesizing the results of our quantitative analysis of responses (including principal components analysis), qualitative analysis of textual data excerpted from open-ended responses, and a review of existing literature, we describe six motivational frames that appear to guide organizations and businesses in their UA practice: Entrepreneurial, Sustainable Development, Educational, Eco-Centric, DIY Secessionist, and Radical. Identifying how practitioners stack functions and frame their work is a first step in helping to differentiate the diverse and often contradictory efforts transforming urban food environments. We demonstrate that a wide range of objectives drive UA and that political orientations and discourses differ by geography, organizational type and size, and funding regime. These six paradigms provide a basic framework for understanding UA that can guide more in-depth studies of the gap between intentions and outcomes, while helping link historically and geographically specific insights to wider social and political economic processes."
journal_title,Agriculture and Human Values
article_title,Social capital dimensions in household food security interventions: implications for rural Uganda
keyword,"['Food access\xa0', 'Bonding social capital\xa0', 'Linking social capital\xa0', 'Human capital\xa0', 'Sub-Saharan Africa\xa0']"
history,"['2018-03', '2017-06-12', '2017-05-31']"
abstract,"Abstract We demonstrate that social capital is associated with positive food security outcomes, using survey data from 378 households in rural Uganda. We measured food security with the Household Food Insecurity Access Scale. For social capital, we measured cognitive and structural indicators, with principal components analysis used to identify key factors of the concept for logistic regression analysis. Households with bridging and linking social capital, characterized by membership in groups, access to information from external institutions, and observance of norms in groups, tended to be more food secure. Households with cognitive social capital, characterized by observance of generalized norms and mutual trust, were also more food secure than others. However, we established that social capital is, by itself, insufficient. It needs to be complemented with human capital enhancement. We recommend that development interventions which focus on strengthening community associations and networks to enhance food security should support activities which enhance cognitive social capital and human capital skills. Such activities include mutual goal setting, trust building and clear communication among actors. Education efforts for community members, both formal and non-formal, should also be supported such that they potentially strengthen social capital to improve food security in rural Uganda."
journal_title,Agriculture and Human Values
article_title,"Valerie Imbruce: From farm to Canal Street, Chinatown’s alternative food network in the global marketplace"
keyword,[]
history,"['2018-02-26', '2018-02-14']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Claudia Bieling and Tobias Plieninger (eds): The science and practice of landscape stewardship
keyword,[]
history,"['2018-02-21', '2018-02-14']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"James F. Hancock: Plantation crops, plunder and power – evolution and exploitation"
keyword,[]
history,"['2018-02-20', '2018-02-14']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Predicting youth participation in urban agriculture in Malaysia: insights from the theory of planned behavior and the functional approach to volunteer motivation
keyword,"['Functional approach\xa0', 'Theory of planned behavior\xa0', 'Urban agriculture\xa0', 'Volunteer motivation\xa0', 'Youth participation\xa0']"
history,"['2018-02-16', '2018-02-12']"
abstract,"Abstract This study examines factors associated with the decision of Malaysian youth to participate in a voluntary urban agriculture program. Urban agriculture has generated significant interest in developing countries to address concerns over food security, growing urbanization and employment. While an abundance of data shows attracting the participation of young people in traditional agriculture has become a challenge for many countries, few empirical studies have been conducted on youth motivation to participate in urban agriculture programs, particularly in non-Western settings. Drawing on the theories of planned behavior and the functional approach to volunteer motivation, we surveyed 890 students from a public university in Malaysia about their intention to join a new urban agriculture program. Hierarchical regression findings indicated that the strongest predictor of participation was students’ attitude toward urban agriculture, followed by subjective norms, career motives and perceived barriers to participation. The findings from this study may provide useful information to the university program planners in Malaysia in identifying mechanisms for future students’ involvement in the program."
journal_title,Agriculture and Human Values
article_title,Teaching the territory: agroecological pedagogy and popular movements
keyword,"['Agroecological education\xa0', 'Peasant-to-peasant\xa0', 'Social movements\xa0', 'Pedagogical mediators\xa0']"
history,"['2018-02-15', '2018-02-07']"
abstract,"Abstract This contribution traces the parallel development of two distinct approaches to peasant agroecological education: the peasant-to-peasant horizontal method that disseminated across Mesoamerica and the Caribbean beginning in the 1970s, and the political-agroecological training schools of combined consciousness-building and skill-formation that have been at the heart of the educational processes of member organizations of La Via Campesina since the 1990s. Applying a theoretical framework that incorporates territorial struggle, agroecology and popular education, we examine spatial and organizational aspects of each of these models for peasant education and movement-building. Recognizing that the models, their respective contexts, and the dialectical relationships therein have been in constant evolution, we share findings on the movement-place as a territorial system with socio-historical subjectivity, that is, peasant movements as territorially-embedded, collective historical actors. This leads to some conclusions in moving past educational theory that has centered upon individual subjects, and approaching a conception of territory as a subject of learning processes."
journal_title,Agriculture and Human Values
article_title,Fairness in alternative food networks: an exploration with midwestern social entrepreneurs
keyword,"['Fair food\xa0', 'Alternative food networks\xa0', 'Local food\xa0', 'Agricultural ethics\xa0']"
history,"['2018-02-14', '2018-02-06']"
abstract,"Abstract The notion of fairness is frequently invoked in the context of food and agriculture, whether in terms of a fair marketplace, fair treatment of workers, or fair prices for consumers. In 2009, the Kellogg Foundation named fairness as one of four key characteristics of a “good” food system. The concept of fairness, however, is difficult to define and measure. The purpose of this study is to explore the notion of fairness, particularly as it is understood within alternative food dialogues. Specifically, we wanted to answer the question of how alternative food entrepreneurs who are working to actualize fairness within local food networks understand this abstract notion. Using a multiple case study approach, the research for this project draws on semi-structured interviews that were conducted with key stakeholders in four alternative food businesses throughout the Midwest."
journal_title,Agriculture and Human Values
article_title,Organic intimacy: emotional practices at an organic store
keyword,"['Organic food\xa0', 'Ethnography\xa0', 'Emotions\xa0', 'Intimacy\xa0', 'Affects\xa0', 'Consumption\xa0', 'Narrative\xa0', 'Retail\xa0', 'Rhythm\xa0', 'Emotional labor\xa0']"
history,"['2018-01-31', '2018-01-19']"
abstract,"Abstract The article tells the story of the rise and fall of the organic store Yggdrasill in Iceland. That story features humble founders, caring customers, dedicated staff, as well as anonymous investment funds, and it describes the conversion of organics from a niche market to mainstream consumption. Through an ethnographic account of everyday life at the organic store, the article analyzes how intimacy within the modern food chain is established through emotional practices. Staff and customers share feelings of reciprocity, not only towards organic producers, but also towards each other through acts of selling and buying organic products, forming intimate attachment and creating trust to counter the fears and anonymity of the modern food chain. Drawing on theories of affect and emotional practices and combining ethnography with narrative analysis, the article explores the role of emotions and how the doing of emotions makes organic food consumption meaningful within the industrial food system."
journal_title,Agriculture and Human Values
article_title,“It’s hard to be strategic when your hair is on fire”: alternative food movement leaders’ motivation and capacity to act
keyword,"['Food systems\xa0', 'Alternative food movement\xa0', 'Food governance\xa0', 'Strategic capacity\xa0', 'Michigan\xa0']"
history,"['2018-01-30', '2018-01-22']"
abstract,"Abstract Despite decades of struggle against the industrial food system, academics still question the impact of the alternative food movement. We consider what food movement leaders themselves say about their motivation to act and their capacity to scale up their impact. Based on semi-structured interviews with 27 food movement leaders in Michigan, our findings complicate the established academic narratives that revolve around notions of prefigurative and oppositional politics, and suggest pragmatic strategies that could scale up the pace and scope of food movement impacts. In contrast to the apolitical perspective some scholars see guiding alternative food movements, local leaders we interviewed see the food system from a structural-political lens. Though some see strength in fragmentation, most are not under the illusion that they can work alone and aspire to build their collective strength further. Concerns about organizational survival and conflicting views about the goals of the food movement, however, present ongoing challenges. Ultimately, we argue that there is a middle ground food movement leaders can walk between prefigurative and oppositional politics, one that still attempts to intentionally change the state, while also maintaining the inventiveness that can come from autonomous, grassroots initiatives. Specifically, interviewees suggested that increased strategic capacity around policy advocacy, critical food systems education, and negotiation could help them extend cross-movement networks and mainstream more equitable food policies, while continuing to experiment with customized solutions."
journal_title,Agriculture and Human Values
article_title,Creating a governable reality: analysing the use of quantification in shaping Australian wheat marketing policy
keyword,"['Quantification\xa0', 'Governmentality\xa0', 'Technologies of performance\xa0', 'Audit\xa0', 'Policy analysis\xa0', 'Wheat\xa0']"
history,"['2018-01-25', '2018-01-12']"
abstract,"Abstract This paper analyses Australian policy makers’ use of quantification and technologies of government to implement the project of Australian wheat export market liberalisation. I draw upon policy documents to analyse how quantification has been used to construct a simplified, governable conception of the wheat industry. Policy makers, I suggest, acted upon this constructed reality through assemblages of technologies such as performance objectives, audit, cost-benefit analysis and econometric modelling to facilitate wheat export market deregulation. In addition, this paper shows how quantification was used to delegitimise the social consequences of deregulation and marginalise farmers’ opposition to this shift. Thus, the erasure of the social world enabled policy makers to construct economic objectives such as efficiency and productivity as serving the national interest."
journal_title,Agriculture and Human Values
article_title,"On (not) knowing where your food comes from: meat, mothering and ethical eating"
keyword,"['Childhood\xa0', 'Consumption\xa0', 'Ethical eating\xa0', 'Meat\xa0', 'Mothering\xa0']"
history,"['2018-01-24', '2018-01-12']"
abstract,"Abstract Knowledge is a presumed motivator for changed consumption practices in ethical eating discourse: the consumer learns more about where their food comes from and makes different consumption choices. Despite intuitive appeal, scholars are beginning to illuminate the limits of knowledge-focused praxis for ethical eating. In this paper, we draw from qualitative interviews and focus groups with Toronto mothers to explore the role of knowledge in conceptions of ethical foodwork. While the goal of educating children about their food has become central to Canadian and American discourses of “good” mothering, we identify a paradoxical maternal expectation surrounding meat consumption: (1) to raise informed child consumers who know where their food comes from, and (2) to protect children from the harsh realities of animal slaughter. Rather than revealing the story behind the meat on a child’s plate, mothers seek to shield children from knowledge of meat production. Our analysis of the child consumer contributes to ethical eating scholarship and illuminates a larger paradox surrounding knowledge of meat in an industrialized food system. In the practice of feeding children, mothers confront the visceral discomforts of meat consumption; their reactions speak to discordant feelings involved with eating meat in a setting far-removed from the lives and deaths of animals. Ultimately, the paper illustrates the limits of consumer-focused strategies for food-system change that call on individual mothers to educate young consumers and protect childhood innocence, all while getting ethically-sourced meals on the table."
journal_title,Agriculture and Human Values
article_title,Alessandro Bonanno and Lawrence Busch (eds): Handbook of the international political economy of agriculture and food
keyword,[]
history,"['2017-12-06', '2017-11-10']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Call for abstracts: the agroecological prospect: the politics of integrating food and farming with values and the land
keyword,[]
history,"['2017-12', '2017-10-25']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Aya Hirata Kimura: Radiation brain moms and citizen scientists: the gender politics of food contamination after Fukushima
keyword,[]
history,"['2017-12', '2017-04-25', '2017-04-17']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Paul B. Thompson, From field to fork: food ethics for everyone"
keyword,[]
history,"['2017-12', '2017-05-01', '2017-04-24']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Courtney Marie Dowdall and Ryan J. Klotz: Pesticides and global health: Understanding agrochemical dependence and investing in sustainable solutions
keyword,[]
history,"['2017-12', '2017-04-03', '2017-03-28']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Books received
keyword,[]
history,"['2017-12', '2017-09-04']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Michael Marder: Grafts: writings on plants
keyword,[]
history,"['2017-12', '2017-04-20', '2017-04-17']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Anne Bellows, Flavio Valente, Stefanie Lemke & María Daniela Núnez Burbano de Lara (eds): Gender, nutrition, and the human right to adequate food: toward an inclusive framework"
keyword,[]
history,"['2017-12', '2017-04-25', '2017-04-12']"
abstract,None
journal_title,Agriculture and Human Values
article_title,"Garrett M. Broad: More than just food, food justice and community change"
keyword,[]
history,"['2017-12', '2017-05-01', '2017-04-24']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Connor J. Fitzmaurice and Brian J. Gareau: Organic futures: struggling for sustainability on the small farm
keyword,[]
history,"['2017-12', '2017-05-09', '2017-05-02']"
abstract,None
journal_title,Agriculture and Human Values
article_title,John Crowe Ransom: Land! The case for an agrarian economy
keyword,[]
history,"['2017-12', '2017-04-25', '2017-04-17']"
abstract,None
journal_title,Agriculture and Human Values
article_title,A quantitative analysis of food movement convergence in four Canadian provinces
keyword,"['Alternative food movement\xa0', 'Local food systems\xa0', 'Neoliberalisation\xa0', 'Convergence\xa0', 'Quantitative methods\xa0']"
history,"['2017-12', '2017-02-14', '2017-01-23']"
abstract,"Abstract Whether the food movement is most likely to transform the food system through ‘alternative’ or ‘oppositional’ initiatives has been the focus of considerable scholarly debate. Alternative initiatives are widespread but risk reinforcing the conventional food system by supporting neoliberal discourse and governance mechanisms, including localism, consumer choice, entrepreneurialism and self-help. While oppositional initiatives such as political advocacy have the potential for system-wide change, the current neoliberal political and ideological context dominant in Canada poses difficulties for initiatives that explicitly oppose the conventional food system. As such, some argue that the food movement requires convergence between alternative and oppositional initiatives. In this paper, we investigate convergence using survey results from 143 food movement organizations in four Canadian provinces. Results  based on cluster analysis and descriptive statistics on organizational discourse, activities and visions of sustainable food systems demonstrate convergence around neoliberal discourse and governance mechanisms. Localism and consumer education characteristics are particularly prominent, with a majority of respondents describing their organizations as ‘local’, engaging in consumer education activities, and stating the importance of consumer education activities, indicating convergence around alternative, rather than oppositional, initiatives. While convergence around these discourse and strategies may limit the transformative potential of the food system when interpreted as neoliberalisation of the movement, such a reading does not demonstrate their full potential, as survey results also indicate trends of transformative visions of change and political engagement, particularly at the municipal level. This research demonstrates that the movement can work simultaneously within, and opposed to, the conventional food system, and provides understanding of both neoliberal leanings and the politics of the possible of the food movement."
journal_title,Agriculture and Human Values
article_title,"Producing space, cultivating community: the story of Prague´s new community gardens"
keyword,"['Community gardens\xa0', 'Urban agriculture\xa0', 'Community involvement\xa0', 'Czechia\xa0']"
history,"['2017-12', '2017-04-03', '2017-03-09']"
abstract,"Abstract This paper aims to fill the gap in literature concerning community gardens in post-communist countries by focusing on the situation in Prague, Czechia. It introduces Prague′s newly emerged community gardens and presents the results of a first representative survey of these gardens. Information was gathered about eleven of the sixteen larger community gardens and the data were collected by semi-structured interviews with the managers of the particular gardens. The paper compares the Czech community gardens as representatives of civic agriculture forms in post-communist countries with their counterparts (mainly those in the North America) and stresses their similarities and differences. The results show that the new community gardens reflect much of what can be seen elsewhere in terms of spatial and organizational design, as well as reasons for starting them, motivations for participation and some of the challenges experienced. However, in contrast to many community gardens in the USA, Canada and UK that focus on food and nutrition provision, in Prague the community is more of a priority than food and the other mentioned benefits. The paper shows that different activities, events and functions make gardens important hubs of their communities and potential tools of further community involvement and social change."
journal_title,Agriculture and Human Values
article_title,CSA shareholder food lifestyle behaviors: a comparison across consumer groups
keyword,"['Community supported agriculture\xa0', 'Food lifestyle behaviors\xa0', 'Political ecologies of health\xa0']"
history,"['2017-12', '2017-02-20', '2017-02-06']"
abstract,"Abstract Community supported agriculture (CSA) programs are transforming the way people relate to food and agriculture. Many researchers have considered the transformative potential of CSAs on economic, social, and environmental relations. They illustrate how participants are embedded in broader political economic transformations. The same focus, however, has not been given to CSAs’ transformative impact on individual shareholders—especially in terms of their relationship to food and health. We draw together literatures from behavioral economics, econometrics, and political ecology to evaluate the potential impacts of CSA participation on food lifestyle behaviors. Using primary data drawn from a survey of four groups with distinct food acquisition environments, we compare respondents’ self-assessed food-related behaviors along three different categories: (1) produce versus processed food consumption, (2) food away from home consumption, and (3) food acquisition and interest in nutrition. By documenting between-group differences, we confirm that shareholders display significant absolute differences to other groups along numerous indicators related to the above-stated categories and in general assessments of health. These differences correspond directionally to behaviors public health officials identify as correlated to beneficial health outcomes. We conclude by theorizing how the food environments delineated by a CSA exchange relationship provide unique reflexive opportunities for participants to develop diverse food-related skills and behaviors."
journal_title,Agriculture and Human Values
article_title,Nature–gender relations within a social-ecological perspective on European multifunctional agriculture: the case of agrobiodiversity
keyword,"['Multifunctionality\xa0', 'Agrobiodiversity\xa0', 'Societal relations to nature\xa0']"
history,"['2017-12', '2016-12-05', '2016-11-18']"
abstract,"Abstract We view agrobiodiversity as a social-ecological phenomenon and, therefore, an example of nature–gender relations within agrarian change, including social, economic, political and technical changes in agriculture and rural areas. As a result of the industrialization of agriculture, nature–gender relations in the field of agrobiodiversity have become characterized by separation processes such as conservation versus use or subsistence versus commodity production. We argue that the sustainable development paradigm, as currently implemented in European Common Agricultural Policy through the concept of multifunctionality, does not necessarily overcome separation tendencies and lead towards integration, despite its claim to bring together different ecological, economic and social needs. In our paper we critically reflect this observation and develop a theory-based analytical framework at the interface of nature and gender relations. For analytical purposes we distinguish between three different agrarian structures (pre-industrialized, industrialized and multifunctional) and focus on the development of two separation tendencies within them and their effects on agrobiodiversity. Concerning nature, we discuss the effects of separating agrobiodiversity conservation and use. With regard to gender, we discuss the separation of subsistence and commodity production. Against this background, we claim for new rural economic rationalities characterized by processes whose qualitative, material and value dimensions maintain agrobiodiversity."
journal_title,Agriculture and Human Values
article_title,"Formal and informal relations to rice seed systems in Kerala, India: agrobiodiversity as a gendered social-ecological artifact"
keyword,"['Seed systems\xa0', 'Agrobiodiversity\xa0', 'Gender-nature relationship\xa0']"
history,"['2017-12', '2016-12-05', '2016-11-15']"
abstract,"Abstract Agrobiodiversity is an evident outcome of a long-lasting human–nature relationship, as the continuous use, conservation and management of crops has resulted in biological as well as cultural diversity of seeds and breeds. This paper aims to understand the interlocking of formal and informal seed supply routes by considering the dynamic flow of seeds within networks across the intersections of gender, ethnicity and age in South India as social categories structuring human–nature relations. This changing relationship under formal and informal institutional settings has consequences on performance for men and women in rice seed systems. Undertaking an empirical analysis of the organization of seed management and exchange, we seek to shed light on the gendered organization of agrobiodiversity as a social network. The study builds on Net-Map interviews conducted in 2012, embedded in the larger BioDIVA project in the district of Wayanad in Kerala, India. Based on network analysis, the interactive method employed has enabled identification of important actors in the seed system and the characteristics of their relationships. We look into the gendered structure of information exchange regarding seed varieties and actual seed transactions, while also examining clusters of actors collaborating regarding seed supply. Finally, we identify the institutional gap concerning seed sources left by formal and informal institutions, like the availability of varieties. We show how informal and formal seed systems coexist and overlap due to actors moving between systems and argue that the degree and areas of overlap are shaped by gendered human–nature relations."
journal_title,Agriculture and Human Values
article_title,Which livestock production claims matter most to consumers?
keyword,"['Livestock production claims\xa0', 'Best-worst scaling\xa0', 'Consumer preference\xa0', 'Labeling\xa0']"
history,"['2017-12', '2017-02-27', '2017-01-31']"
abstract,"Abstract Consumers are becoming increasingly interested in how their food is produced. Many studies have focused on consumers’ preferences and willingness-to-pay for specific production-related claims (labels) on food products. However, few studies have asked consumers to rank the importance of different production claims. In this study, we use a best-worst scaling approach to have consumers rank the importance of seven common production claims used on food products. Rankings are obtained across four product types: beef, milk, chicken, and eggs. Results  of the study show that consumers often prefer specific components of more encompassing claims (e.g., animals were not treated with growth hormones, no GMOs used in production) as opposed to the broader, more encompassing claim itself (such as product is certified organic). The majority of preference shares were captured by the top three claims, though the order of these preferences appears to vary for meat and non-meat animals."
journal_title,Agriculture and Human Values
article_title,Non-GMO vs organic labels: purity or process guarantees in a GMO contaminated landscape
keyword,"['GMO\xa0', 'Organic\xa0', 'Standards\xa0', 'Labels\xa0', 'Transparency\xa0', 'Environmental governance\xa0', 'Agrifood system\xa0']"
history,"['2017-12', '2017-03-22', '2017-01-23']"
abstract,"Abstract Since 2010, demand for non-GMO food products has grown dramatically. Two non-GMO labels dominate the market: USDA Organic and the Non-GMO Project Verified (the Project). However, the non-GMO status of Organic is not obvious from the label and many consumers are unaware of this. As sales of products carrying the Project’s non-GMO label have exploded, concern has increased among some Organic proponents that demand for non-GMO threatens the organic market. In response, both sides are seeking to build legitimacy and authority for their label by emphasizing the value of their standards for determining a food product’s non-GMO status within a GMO contaminated agrifood system. Drawing on in-depth interviews with key informants with knowledge of non-GMO standards and labels, we examine the knowledge systems, discourses and actors that proponents of the Project and USDA Organic privilege in their effort to legitimize their standards. Here, the Project emphasizes its application of technoscientific norms, especially thresholds and testing, which they argue provide the best means for preventing GMO contamination and helping consumers find (relative) non-GMO ‘purity’. In contrast, proponents of Organic favor a process standard that excludes GMOs, arguing that non-GMO ‘purity’ is unrealistic in today’s agrifood system that is widely contaminated by GMOs and where mandatory testing would unnecessarily harm organic producers. We conclude that tensions between the two groups are unlikely to be easily reconciled since these two distinct marketing labels rely on different knowledge and verification claims to vie for consumers and increase market share."
journal_title,Agriculture and Human Values
article_title,Environmental justice and care: critical emancipatory contributions to sustainability discourse
keyword,"['Environmental justice\xa0', 'Feminist economics\xa0', 'Sustainability to come\xa0']"
history,"['2017-12', '2016-12-05', '2016-11-17']"
abstract,"Abstract Sustainability has become a powerful discourse, guiding the efforts of various stakeholders to find strategies for dealing with current and future social-ecological crises. To overcome the latter, we argue that sustainability discourse needs to be based on a critical-emancipatory conceptualization. Therefore, we engage two such approaches—environmental justice approaches informed by a plural understanding of justice and feminist political economy ones focusing on care—and their analytical potential for productive critique of normative assumptions in the dominant sustainability discourse. Both of these approaches highlight aspects of sustainability that are particularly relevant today. First, although sustainable development was conceptualized from the outset based upon a twofold notion of justice (intra- and intergenerational), the integration of justice in the dominant sustainability discourse and praxis often manifests merely as a normative aspiration. Meanwhile, the environmental justice and care approaches offer conceptualizations of justice that can act as a powerful lever and as transformation-strategy. Second, the dominant sustainability discourse largely remains within a neoliberal economic framework that continues to promote economic growth as the means to reach prosperity while neglecting the bases of every economy: care work and nature. Its focus lies solely on paid work and the market economy. By integrating (a) social and ecological ‘reproductivity’ (unpaid care and subsistence work as well as nature) and (b) democratic processes for just distribution of environmental burdens and benefits, as well as participatory equity in relevant decision making, feminist political economy and environmental justice approaches offer substantial strategies towards building humane, just and caring societies."
journal_title,Agriculture and Human Values
article_title,Dualisms shaping human-nature relations: discovering the multiple meanings of social-ecological change in Wayanad
keyword,"['Agrarian change\xa0', 'Feminist political ecology\xa0', 'Kerala\xa0']"
history,"['2017-12', '2016-11-28', '2016-11-17']"
abstract,"Abstract This paper reflects on the impacts of agrarian change and social reorganisation on gender-nature relations through the lens of an indigenous group named the Kuruma in South India. Building upon recent work of feminist political ecology, I uncover a number of dualisms attached to the gender-nature nexus and put forward that gender roles are constituted by social relations which need to be analysed with regard to the transformative potential of gender-nature relations. Three main themes are at the centre of the empirical inquiry: gender subjectivities, rural off-farm employment and the human-nature nexus. I seek to show that, first, the production of gendered subjectivities cannot be simplified through essentialist assumptions that romanticise women’s relationships with nature; second, off-farm employment strategies both reinforce the social hierarchy in gender and contradict the Kuruma’s moral economies; and, finally, environmental and agrarian change redefine the use of agrobiodiversity and are related to ideas on progressive versus nonprogressive cultivation practices. The research is informed by qualitative research methods and offers a conceptual approach to the deconstruction of gender-nature relations from a poststructuralist feminist perspective."
journal_title,Agriculture and Human Values
article_title,"The rise of food banks and the challenge of matching food assistance with potential need: towards a spatially specific, rapid assessment approach"
keyword,"['Food security\xa0', 'Food assistance\xa0', 'Food justice\xa0', 'Poverty\xa0', 'Food environments\xa0', 'Geographic information systems (GIS)\xa0', 'Decision support\xa0']"
history,"['2017-12', '2017-04-10', '2017-03-14']"
abstract,"Abstract In the United States, food banks served an estimated 46 million people in 2015. A combination of government policy reforms and political economic trends contributed to the rising numbers of individuals relying on private food assistance in the US, the United Kingdom and other high-income countries. Although researchers frequently map urban food environments, this project is one of the first to map private food assistance and potential need at the census-tract scale. We utilize Geographic Information Systems, demographic data, and food assistance locations to develop a rapid assessment tool that could support food banks, pantries, soup kitchens, and government agencies that seek to answer the question of whether people with the greatest need have food distribution sites in close proximity. We define access based on distance and then calculate potential food insecurity using either poverty rates or a food insecurity index. We apply these methods in a case study analysis of Santa Clara County, California. Our findings suggest that food assistance distribution locations match the areas of potential need in more than 80% of urban census tracts. However, there are several potentially underserved locations and populations that could benefit from new food assistance operations. The poverty and index-based approaches show significant spatial overlap in mapped areas of high food insecurity and low access. The poverty only approach produces a higher estimate of food insecurity rates, is easier to calculate, and draws attention to the need to address poverty as a root cause of hunger."
journal_title,Agriculture and Human Values
article_title,"Gender and sustainable livelihoods: linking gendered experiences of environment, community and self"
keyword,"['Feminist political ecology\xa0', 'Nature/culture\xa0', 'Bolsena\xa0']"
history,"['2017-12', '2016-11-22', '2016-11-15']"
abstract,"Abstract In this essay I explore the economic, social, environmental and cultural changes taking place in Bolsena, Italy, where agricultural livelihoods have rapidly diminished in the last two decades. I examine how gender dynamics have shifted with the changing values and livelihoods of Bolsena through three women’s narratives detailing their gendered experiences of environment, community and self. I reflect on these changes with Sabrina, who is engaged in a feminist community-based organization; Anna, who is running an alternative wine bar; and Isabella, a jeweler, who is engaged in ecofeminist practices. My analysis is based on concepts developed by feminist political ecology: specifically, the theory of rooted networks from Dianne Rocheleau, Donna Haraway’s concept of naturecultures (and the work of J. K. Gibson-Graham on new economic imaginaries emerging from the politics of place. I aim to think with, reflect upon and provoke from the “otherwise”, taking into account the lived relations entwining nature and gender. My article looks at the interconnections of gender, environment and livelihoods, attentive to the daily needs, embodied interactions and labours of these three women as part of a reappropriation, reconstruction and reinvention of Bolsena’s lifeworld. By listening to the stories of their everyday lives and struggles, I show the dynamic potential of the politics of place and the efforts to build diverse economies and more ethical economic and ecological relationships based on gender-aware subjectivities and values."
journal_title,Agriculture and Human Values
article_title,"Millets, milk and maggi: contested processes of the nutrition transition in rural India"
keyword,"['South Asia\xa0', 'Nutrition transition\xa0', 'Ethnographic methods\xa0', 'Agriculture\xa0', 'Food cultures\xa0']"
history,"['2017-12', '2017-03-22', '2017-03-07']"
abstract,"Abstract The nutrition transition—a process of dietary change that describes the shift to calorie-dense, higher fat and protein diets from cereal based ones—is happening in India. This paper argues that relatively little is known about the nature of nutrition transition in India. This is a result of both a lack of adequate and timely data and a consequence of national and state-level statistics, which render an incomplete and potentially misleading picture of how these processes are unfolding in local contexts. This may be especially true in India where very little ethnographic research has documented the dual edges of nutrition transitions. Analyzing data collected from the Kumaon Hills, Uttarakhand in 2013, this paper suggests the ways in which aspects of the nutrition transition have developed unevenly over space and time. In particular, while new types of calorie dense foods have infiltrated these rural, remote areas, the process has been uneven and fraught with contestation due to preexisting social practices. More troubling is the evidence that though incomes are rising, the predicted increases in high value, protein rich foods may actually be declining. This paper concludes by arguing that the widely influential nutrition transition literature needs look to ethnographic and in-depth qualitative methods to form better policies relevant to the contingencies of dietary and epidemiological change."
journal_title,Agriculture and Human Values
article_title,Understanding the organization of sharing economy in agri-food systems: evidence from alternative food networks in Valencia
keyword,"['Sharing economy\xa0', 'Organization theory\xa0', 'Consumer groups\xa0', 'Community gardens\xa0', 'Case study\xa0']"
history,"['2017-12', '2017-03-15', '2017-02-06']"
abstract,"Abstract Despite the proliferation of sharing economy initiatives in agri-food systems, the recent literature has still not unravelled what sharing exactly entails from an organizational standpoint. In light of this knowledge gap, this study aims to understand which resources are shared, and how, in a heterogeneous set of sharing economy initiatives in the context of food and agriculture. Specifically, this study compares the organization of various forms of alternative food networks (AFNs), which are recognized to be frugal forms of sharing economy initiatives (i.e., locally based, small-scale and with limited use of information technology), in terms of leadership, bureaucracy, shared resources and participants’ engagement. Data from a comparative case study across 18 AFNs identify five sharing economy models of AFNs with distinctive shared resources and organizational mechanisms: consumer groups; commercial community gardens; as well as network-based, privately owned and publicly owned self-consumption community gardens. These models also display notable differences in terms of their origins, participants’ goals and constraints which, to some extent, may be associated to the nature of their organization. Findings inform policy-makers, AFNs’ leaders and stakeholders—especially those seeking to support innovative models towards sustainable transitions—on how to tailor institutional norms and develop networks to meet the heterogeneous needs of different typologies of sharing economy initiatives in agri-food systems."
journal_title,Agriculture and Human Values
article_title,Introduction to the symposium on feminist perspectives on human–nature relations
keyword,[]
history,"['2017-12', '2016-11-24', '2016-11-18']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Get real: an analysis of student preference for real food
keyword,"['Willingness-to-pay\xa0', 'Real food challenge\xa0', 'Contingent valuation\xa0', 'University dining\xa0', 'Student values\xa0', 'Credence attribute\xa0']"
history,"['2017-12', '2017-04-11', '2017-03-18']"
abstract,"Abstract The Real Food Challenge is a national student movement in the United States (U.S.) that aims to shift $1 billion—roughly 20%—of college and university food budgets across the country towards local, ecologically sound, fair, and humane food sources—what they call “real” food—by 2020. The University of Vermont (UVM) was the fifth university in the U.S. to sign the Real Food Campus Commitment, pledging to shift at least 20% of its own food budget towards “real” food by 2020. In order to examine student preference for “real” food on the UVM campus, we analyzed a survey of 904 undergraduate students that used contingent valuation to evaluate students’ willingness-to-pay (WTP) for the “real” attribute. We found that a majority of students are willing to pay a positive premium for “real” food. Furthermore, we found that student characteristics and attitudes significantly influence WTP. Specifically, gender, residency, college, and attitudes about price and origin of food are significant predictors of WTP."
journal_title,Agriculture and Human Values
article_title,AFHVS 2017 presidential address
keyword,"['Public research\xa0', 'Commercial science\xa0', 'Public interest\xa0', 'Food and agricultural research and development\xa0']"
history,"['2017-12', '2017-08-31', '2017-08-23']"
abstract,"Abstract As efforts to commercialize university research outputs continue, critics charge that universities and university scientists are failing to live up to their public-interest purpose. In this paper, I discuss the distinctions between public-interest and private-interest research institutions and how commercialization of university science may be undermining the public interest. I then use Jürgen Habermas’s concept of communicative action as the foundation for efforts to establish public spaces for ethical deliberation among scientists and university administrators. Such ethical deliberation is necessary to facilitate discussion on whether public-interest science should be the research university’s primary purpose and what institutional rules and resources are needed to honor that purpose."
journal_title,Agriculture and Human Values
article_title,"Exclusions in inclusive programs: state-sponsored sustainable development initiatives amongst the Kurichya in Kerala, India"
keyword,"['Gender\xa0', 'Agrobiodiversity\xa0', 'Feminist political ecology (FPE)\xa0']"
history,"['2017-12', '2016-11-23', '2016-11-15']"
abstract,"Abstract We critically discuss the impact of sustainable development initiatives in Kerala, India, on biodiversity and on women farmers in the matrilineal Adivasi community of the Kurichya-tribe in Wayanad. By contextualizing development programs regarding the specifically gendered access to land, division of labor, distribution of knowledge and decision-making power, we situate our analysis within the theoretical framework of feminist political ecology. We first outline women’s gaining of social and political space in local self-government institutions (Panchayath) and then critically discuss the impacts of women’s farming groups (Joint Liability Groups: JLGs). Decentralization and development programs have aimed at empowering women and reducing poverty through improved food security. However, little success has materialized, as patriarchal power structures concerning decision-making processes as well as control over the most valuable resources (land and rice) and traditional knowledge have been maintained. Whereas women’s self-help groups (Kudumbasree) in Kerala have enhanced their position, women’s farming groups (JLGs), by contrast, have brought little betterment. In some cases they have even downsized women’s management and knowledge of resources related to agriculture and do not integrate or enhance Kurichya women’s knowledge. As some women are now introducing high-yielding rice seeds and fertilizer and as it is impossible for them to control land and get access to traditional rice seeds—the domain of men—we contest the notion of women being considered the preservers of agrobiodiversity. We argue, rather, that the construction and transformation of ecological traditional knowledge is highly dependent on the gendered multi-scaled power structures of state and community."
journal_title,Agriculture and Human Values
article_title,"Howard Markel, The Kelloggs: The Battling Brothers of Battle Creek"
keyword,[]
history,"['2017-11-14', '2017-11-03']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Susan Futrell: Good apples: behind every bite
keyword,[]
history,"['2017-11-02', '2017-09-25']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Anabel Ford and Ronald Nigh: The Maya forest garden: eight millennia of sustainable cultivation of the tropical woodlands
keyword,[]
history,"['2017-10-28', '2017-10-26']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Pamela Mason and Tim Lang: Sustainable diets: how ecological nutrition can transform consumption and the food system
keyword,[]
history,"['2017-10-16', '2017-09-12']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Andrew Fisher: Big hunger: the unholy alliance between corporate America and anti-hunger groups
keyword,[]
history,"['2017-10-06', '2017-09-23']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Lisa F. Clark: The changing politics of organic food in North America
keyword,[]
history,"['2017-09', '2017-02-14', '2017-01-04']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Elspeth Probyn. Eating the Ocean
keyword,[]
history,"['2017-09', '2017-01-05', '2016-12-19']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Peter Jackson: Anxious appetites
keyword,[]
history,"['2017-09', '2016-11-01', '2016-10-25']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Books received
keyword,[]
history,"['2017-09', '2017-08-09']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Kristin Reynolds and Nevin Cohen: beyond the Kale—urban agriculture and social justice activism in New York City
keyword,[]
history,"['2017-09', '2016-12-15', '2016-12-02']"
abstract,None
journal_title,Agriculture and Human Values
article_title,From food security to food wellbeing: examining food security through the lens of food wellbeing in Nepal’s rapidly changing agrarian landscape
keyword,"['Food wellbeing\xa0', 'Agrarian change\xa0', 'Food security\xa0', 'Small-scale agriculture\xa0', 'Nepal\xa0']"
history,"['2017-09', '2016-10-18', '2016-10-07']"
abstract,"Abstract This paper argues that existing food security and food sovereignty approaches are inadequate to fully understand contradictory human development, nutrition, and productivity trends in Nepalese small-scale agriculture. In an attempt to bridge this gap, we developed a new food wellbeing approach that combines insights from food security, food sovereignty, and social wellbeing perspectives. We used the approach to frame 65 semi-structured interviews in a cluster of villages in Kaski district in the mid-hills of Nepal on various aspects of food security, agriculture, off-farm livelihood opportunities, and women’s wellbeing. Our results indicate that context-specific subjective and social relational factors highlighted by the food wellbeing approach are key to understanding a paradox of increased food security, yet decreasing sustainability of small-scale agriculture. Increased levels of male out-migration and opportunities for local off-farm work have increased local capacity to purchase food. The positive consequences for food security are indicated by evidence that households with non-farm income sources had better food sufficiency, absorption capacity, nutritional quality, and stability of food supply. These off-farm employment opportunities have also led to the greater involvement of low caste groups and women in small-scale agriculture. This has been empowering for both groups and led to an increase in wellbeing, particularly for those women who have become de facto heads of household. Yet, small landholdings, persistent patterns of unequal and absentee land ownership, sharecropping, women’s overwork, and the aspirations of low caste farmers and women away from agriculture are simultaneously driving the erosion of local small-scale agricultural productivity and ecological sustainability."
journal_title,Agriculture and Human Values
article_title,Dietary regimes and the nutrition transition: bridging disciplinary domains
keyword,"['Nutrition transition\xa0', 'Dietary regimes\xa0', 'Food regimes\xa0', 'Food environments\xa0', 'Degradation of food\xa0']"
history,"['2017-09', '2016-11-01', '2016-10-06']"
abstract,"Abstract The nutrition transition concept developed by Popkin has gained wide currency within the nutritional sciences literature as a way of understanding population wide changes to diet and energy balance and their related health outcomes in society. It offers a useful template of different nutritional patterns societies progress through, but it has not provided a comprehensive understanding of the why and how of dietary change. Building on insights from the literature on food regimes in the social sciences, this paper argues the concept of dietary regimes can augment the nutrition transition model and can serve as a bridge between social and health sciences around nutrition and dietary change. The political economy analysis of the dietary regime approach provides insights into the historical degradation of food and the diffusion of nutrient-poor products throughout food environments today. It also engages analysis of the key actors shaping food environments and diets in the industrial era. The dietary regime approach can provide fruitful directions with respect to concrete policy options to address the major issue of population wide weight gain that the nutrition transition model has sought to confront in recent iterations."
journal_title,Agriculture and Human Values
article_title,"Governments, grassroots, and the struggle for local food systems: containing, coopting, contesting and collaborating"
keyword,"['Alternative food systems\xa0', 'Food safety regulations\xa0', 'Governmentality\xa0', 'North America\xa0', 'Politics of possibility\xa0', 'Subjectivities\xa0']"
history,"['2017-09', '2016-11-29', '2016-11-18']"
abstract,"Abstract Local sustainable food systems have captured the popular imagination as a progressive, if not radical, pillar of a sustainable food future. Yet these grassroots innovations are embedded in a dominant food regime that reflects productivist, industrial, and neoliberal policies and institutions. Understanding the relationship between these emerging grassroots efforts and the dominant food regime is of central importance in any transition to a more sustainable food system. In this study, we examine the encounters of direct farm marketers with food safety regulations and other government policies and the role of this interface in shaping the potential of local food in a wider transition to sustainable agri-food systems. This mixed methods research involved interview and survey data with farmers and ranchers in both the USA and Canada and an in-depth case study in the province of Manitoba. We identified four distinct types of interactions between government and farmers: containing, coopting, contesting, and collaborating. The inconsistent enforcement of food safety regulations is found to contain progressive efforts to change food systems. While government support programs for local food were helpful in some regards, they were often considered to be inadequate or inappropriate and thus served to coopt discourse and practice by primarily supporting initiatives that conform to more mainstream approaches. Farmers and other grassroots actors contested these food safety regulations and inadequate government support programs through both individual and collective action. Finally, farmers found ways to collaborate with governments to work towards mutually defined solutions. While containing and coopting reflect technologies of governmentality that reinforce the status quo, both collaborating and contesting reflect opportunities to affect or even transform the dominant regime by engaging in alternative economic activities as part of the ‘politics of possibility’. Developing a better understanding of the nature of these interactions will help grassroots movements to create effective strategies for achieving more sustainable and just food systems."
journal_title,Agriculture and Human Values
article_title,Sociocultural tensions and wicked problems in sustainable agriculture education
keyword,"['Wicked problems\xa0', 'Sustainable agriculture education\xa0', 'Identity\xa0', 'Sociocultural tensions\xa0']"
history,"['2017-09', '2016-11-12', '2016-10-14']"
abstract,"Abstract Future practitioners of sustainable agriculture and agroecology must have the capacity to address the wicked problems in the food system to make progress toward sustainability. Undergraduate sustainable agriculture students from a variety of backgrounds may struggle with the question, is the challenging and complex work of addressing wicked problems of agroecology for me? Our case study investigated sociocultural tensions associated with identity encountered when wicked problems teaching units were integrated into the Advanced Practices of Sustainable Agriculture course at a large, Midwestern Land Grant University. The research and course employed a four-part framework that focused on (1) attending to individual needs and identities, (2) facilitating practice-based and community-based learning, (3) engaging in problems situated in regional contexts, and (4) supporting awareness of local and global political and ecological issues. Researchers used a community of practice theoretical lens, and focused on the sociocultural tensions that may have impacted individual and community identity formation. Two wicked problems teaching units are described by drawing upon documentation and audio recordings from planning meetings, course sessions, student and instructor interviews, and course artifacts. Vignettes were constructed to situate four interrelated types of sociocultural tensions encountered by instructors and students. These tensions reflected forces at the individual, community, local, and global levels which interact to influence learners’ capacity to become full participants in sustainable agriculture. The study fills a gap related to affective dimensions of learning like identity in agroecology education. Dilemmas and implications related to identity, pedagogy, and epistemology are discussed."
journal_title,Agriculture and Human Values
article_title,Beyond food security: women’s experiences of urban agriculture in Cape Town
keyword,"['Urban agriculture\xa0', 'Gender\xa0', 'Livelihood\xa0', 'Social capital\xa0', 'Cape Town\xa0', 'NGO\xa0']"
history,"['2017-09', '2017-02-14', '2017-01-16']"
abstract,"Abstract Urban agriculture is an important source of food and income throughout Africa. The majority of cultivators on the continent are women who use urban agriculture to provide for their family. Much research on urban agriculture in Africa focuses on the material benefits of urban agriculture for women, but a smaller body of literature considers its social and psychological empowering effects. The present study seeks to contribute to this debate by looking at the ways in which urban agriculture empowers women on the Cape Flats, a region of Cape Town where urban agriculture is supported by nongovernmental organisations (NGOs). Based on interviews with cultivators, the findings show that NGO-run urban agriculture projects not only aid food security, but also help women to develop supportive networks that unlock benefits across the personal, social and economic spectrum."
journal_title,Agriculture and Human Values
article_title,A new era of civil rights? Latino immigrant farmers and exclusion at the United States Department of Agriculture
keyword,"['Immigrant farming\xa0', 'Race in agriculture\xa0', 'Latino farmers\xa0', 'United States Department of Agriculture (USDA)\xa0']"
history,"['2017-09', '2016-11-10', '2016-11-04']"
abstract,"Abstract In this article we investigate how Latino immigrant farmers in the Mid-Atlantic region of the United States navigate United States Department of Agriculture (USDA) programs, which necessitate standardizing farming practices and an acceptance of bureaucracy for participation. We show how Latino immigrant farmers’ agrarian norms and practices are at odds with the state’s requirement for agrarian standardization. This interview-based study builds on existing historical analyses of farmers of color in the United States, and the ways in which their farming practices and racialized identities are often unseen by and illegible to the state. This disjuncture leads to the increased racial exclusion of immigrant farmers from USDA opportunities. Such exclusions impede the transition to a “new era of civil rights,” as has been proclaimed by USDA leadership. Although efforts to address institutionalized racism on a national level may be genuine, they have failed to acknowledge this schism between rural Latino immigrants and the state, thereby inhibiting a meaningful transition in the fields, and continuing a legacy of unequal access to agrarian opportunities for non-white immigrant farmers."
journal_title,Agriculture and Human Values
article_title,"What’s good for the soil is good for the soul: scientific farming, environmental subjectivities, and the ethics of stewardship in southwestern Oklahoma"
keyword,"['Conservation\xa0', 'Agricultural modernism\xa0', 'Subjectivities\xa0', 'Great Plains\xa0']"
history,"['2017-09', '2016-11-18', '2016-10-25']"
abstract,"Abstract Based on 10 months of mixed ethnographic and archival research, this study is concerned with ways in which contemporary agro-environmental subjectivities and practices in a southwestern Oklahoma farming community are rooted in the massive state-level interventions of the New Deal era and their successors. We are likewise concerned with how those interventions have become interdigitated with moral discourses and community ethics, as simultaneous expressions of both farmers’ identities and the systems of power in which they practice farming. Through historic and ethnographic evidence, we demonstrate the ways in which the localization of American agricultural conservation and the attendant, edificatory role of resource bureaucracies have shaped contemporary practices and ideologies of natural resource stewardship among conventional farmers and ranchers."
journal_title,Agriculture and Human Values
article_title,Navigating the tensions and agreements in alternative food and sustainability: a convention theoretical perspective on alternative food retail
keyword,"['Alternative food networks\xa0', 'Justification\xa0', 'Food retail\xa0', 'Convention theory\xa0', 'Hybridity\xa0', 'Sustainability\xa0']"
history,"['2017-09', '2016-10-17', '2016-09-29']"
abstract,"Abstract Concerns about the unsustainability of the conventional food system have promoted interest in alternative food networks (AFNs), which are typically conceptualized through their differences from conventional food networks. Real-life AFNs, however, tend to show some similarities to the conventional food system. This hybridity has caused some criticism, but also, increasingly, calls for a more open examination of AFNs. Indeed, AFNs can be seen as relational to and shaped by the prevailing food system, for example the expectations the conventional system has promoted among consumers. In this paper, through a multiple case study of nine alternative food retailers, we examine the negotiation of acceptable practice in AFNs and the challenges encountered in trying to do things alternatively. We employ convention theory, which encourages a view of action as socially negotiated and situational, and acknowledges plural legitimate notions of worth in guiding and justifying actions. Our findings show a plurality of ideals in the domain of AFNs and a complex navigation between the retailers’ own expressed ideals and considerations and perceived consumer expectations. The retailers’ justification of actions highlights several areas of tension in AFN practice, helping also to understand the challenges in adopting sustainable practices. While responding to consumer expectations sometimes involved adopting more conventional practices, the retailers also challenged consumers on certain issues. Our findings also show how even market-oriented AFNs may take radically alternative courses of action. The study supports the broader argument for examining all food networks in an open way, focusing on actual sustainability outcomes."
journal_title,Agriculture and Human Values
article_title,“You can’t manage with your heart”: risk and responsibility in farm to school food safety
keyword,"['Farm to School\xa0', 'Local food\xa0', 'Child nutrition\xa0', 'Food safety\xa0', 'Risk\xa0', 'Responsibility\xa0']"
history,"['2017-09', '2016-12-22', '2016-11-30']"
abstract,"Abstract Farm to School (FTS) programs aim to connect school children with local foods, to promote a synergistic relationship between local farmers, child nutrition and education goals, and community development. Drawing from 18 months of ethnographic research with a regional FTS project and interviews with child nutrition program operators (POs) implementing FTS across Georgia, we identify perceptions of food safety as an emerging barrier in efforts to bring local foods into schools. Conducting a thematic analysis of data related to food safety, we find that FTS participation may be hindered by discourses and perceptions of safety risks attributed to local foods—and to local produce in particular. We argue that this results, paradoxically, from a core tenant of FTS and other local food movements: forging personal relationships with farmers, through which POs confront the transparency of local food production, in contrast to the opacity of food procured through standard supply chains. Faced with unfamiliar production practices, and responsibilized to protect students as “at risk” subjects, POs may decide that buying local food is “not worth the risk.”"
journal_title,Agriculture and Human Values
article_title,Internet-enabled access to alternative food networks: A comparison of online and offline food shoppers and their differing interpretations of quality
keyword,"['Alternative food networks\xa0', 'Internet retail\xa0', 'Conventions theory\xa0', 'Access equity\xa0']"
history,"['2017-09', '2017-02-02', '2017-01-06']"
abstract,"Abstract Online food retail has the potential to broaden access to systems of food provision which promote social and environmental quality attributes. This possibility is explored using data from a survey of 365 consumers who purchased food either via internet retailers of local and organic food, or via farmers’ markets, in Vancouver, Canada and Melbourne, Australia. Survey results are analyzed using principal component and regression techniques and interpreted via the theoretical framework of conventions theory. Key findings show that while online retailers of local organic food are not currently attracting more resource constrained consumers, they do appeal to a similar, although broader, array of quality conventions. This research provides new insights into the challenges and opportunities associated with increasing consumer access to alternative food networks, as well as adding to the small number of quantitative studies in the conventions theory literature."
journal_title,Agriculture and Human Values
article_title,Identifying attributes of food system sustainability: emerging themes and consensus
keyword,"['Food systems\xa0', 'Sustainability\xa0', 'Food security\xa0', 'Socio-ecological systems\xa0']"
history,"['2017-09', '2016-11-15', '2016-10-31']"
abstract,"Abstract Achieving food system sustainability is one of the more pressing challenges of this century. Over the last decades, experts from diverse disciplines and intellectual traditions have worked to document the critical threats to food system sustainability and to define an appropriate agenda for action. Nevertheless, these efforts have tended to focus selectively on only a few components of the food system or have tended to be framed in particular discourses. Depending on the point of departure, what aspects of the food system are considered threatened, and what must be sustained, can differ greatly between perspectives. In this article, we draw from systems-thinking and social-ecological systems concepts to focus on the underlying process-related attributes that could support a more sustainable food system. We then examine the support for specific system attributes in six different knowledge domains addressing sustainable agriculture and food. From this review, we identify five system attributes—diversity, modularity, transparency, innovation and congruence—that are repeatedly featured in the different knowledge domains as critical aspects of food system sustainability. We argue that in the face of considerable complexity and high uncertainty, these attributes can serve as a guide to conceptualizing food system choices adaptively and iteratively."
journal_title,Agriculture and Human Values
article_title,Invoices on scraps of paper: trust and reciprocity in local food systems
keyword,"['Local food systems\xa0', 'Trust\xa0', 'Farm-to-retail\xa0', 'Economic sociology\xa0', 'Power\xa0']"
history,"['2017-09', '2016-10-17', '2016-09-28']"
abstract,"Abstract One of the many claims about the value of local food is that local food exchanges generate trust between producers and consumers. To what degree is this actually the case and how does such trust develop? Drawing on interview and fieldwork data in one local food system in the Northeastern U.S., I show how local food participants (particularly farms and food retailers) build trust and reciprocity with one another in order to mitigate the challenges imposed by the conventional system. This trust and reciprocity builds primarily through three mechanisms: reliable, positive relationships; demonstrations of good will toward one another; and a shared understanding of the value of locally-oriented food. Through these mechanisms, local food operators are able to build a healthy, stable local food system, able to better resist the pressures of the conventional system in which it must continually operate."
journal_title,Agriculture and Human Values
article_title,Scientific boundary work and food regime transitions: the double movement and the science of food safety regulation
keyword,"['Food regimes\xa0', 'Science\xa0', 'Scientific communities\xa0', 'Food safety\xa0', 'Polanyi\xa0', 'Regulation\xa0']"
history,"['2017-09', '2016-12-01', '2016-11-18']"
abstract,"Abstract What role do science and scientists play in the transition between food regimes? Scientific communities are integral to understanding political struggle during food regime transitions in part due to the broader scientization of politics since the late 1800s. While social movements contest the rules of the game in explicitly value-laden terms, scientific communities make claims to the truth based on boundary work, or efforts to mark some science and scientists as legitimate while marking others as illegitimate. In doing so, scientific communities attempt to establish and maintain the privileged position of science in contests over policy. In this paper, we situate scientific boundary work within its world historical context in order to ask two key questions: (1) how does scientific boundary work vary across food regimes; and, in turn, (2) what role does scientific boundary work play in the political contestation that drives transitions between food regimes? We explore these questions through the case of one scientific community—the AOAC (Association of Official Analytical Communities)—involved in food safety regulation across the British, US, and corporate food regimes. We argue that scientific boundary work is shaped by historically specific patterns of social conflict within food regimes and, in particular, the double-movement dynamics that Polanyi (The great transformation: the political and economic origins of our times. Boston: Beacon, 1957[1944]) theorizes. Moreover, as scientific communities reconstruct their internal rules, norms, and procedures to claim their own legitimacy in relation to prevailing forms of social conflict, they also reshape who sets scientific agendas and thus the knowledge available for making new rules within periods of food regime transition. To elaborate this argument in theoretical terms, we build on recent efforts to integrate a neo-Polanyian perspective into food regime analysis and link this to research on scientific boundary work by scholars in science and technology studies."
journal_title,Agriculture and Human Values
article_title,Improving farmers markets and challenging neoliberalism in Argentina
keyword,"['Sustainable agriculture\xa0', 'Farmers markets\xa0', 'Capitalism\xa0', 'Law\xa0', 'Policy\xa0', 'Latin America\xa0']"
history,"['2017-09', '2017-02-07', '2017-01-16']"
abstract,"Abstract Although typically invisible, neoliberal policies and ideologies are often at the root of why farmers markets struggle to offer affordable prices for consumers, sufficient income for farmers, and expand socially and environmentally sustainable food systems. Argentinian ferias francas, a variation on farmers markets, offer a unique case to examine how they may be designed to alleviate these issues by challenging neoliberalism through legislative mechanisms. Ferias francas emerged as an explicitly anti-neoliberal, grassroots response to Argentina’s expansion of neoliberal agricultural policies that stimulated global agribusiness and displaced small-scale farmers. Organizers partnered with municipal, provincial, and national governments to develop legislation to support small-scale farmers and to make the network of ferias competitive with global agribusiness. I ask, how can organizers expand farmers markets’ potential to fulfill the social and environmental goals of agri-food movements, given neoliberal capitalism’s constraints and contradictions? I analyze feria legislation by situating it in its social and historical context, and comparing legislative mechanisms to core elements of neoliberalism in the economy and in the everyday mentalities of agri-food activists. I find that mechanisms such as setting prices lower than neighboring supermarkets and establishing uniform prices for feria goods contest some aspects of neoliberalism. However, the ferias also reproduce neoliberalism, and are still subject to the price standards set under the global neoliberal agroeconomy, raising questions about their prospects for sustainability under neoliberal capitalism. This analysis of feria legislation makes neoliberalism’s influence on farmers markets visible and highlights legislative mechanisms that address some of its harmful effects."
journal_title,Agriculture and Human Values
article_title,"Contradictions, consequences and the human toll of food safety culture"
keyword,"['Food safety\xa0', 'California\xa0', 'Culture\xa0', 'Moral economy\xa0', 'Labor\xa0']"
history,"['2017-09', '2017-02-06', '2017-01-10']"
abstract,"Abstract In an intensifying climate of scrutiny over food safety, the food industry is turning to “food safety culture” as a one-size-fits-all solution to protect both consumers and companies. This strategy focuses on changing employee behavior from farm to fork to fit a universal model of bureaucratic control; the goal is system-wide cultural transformation in the name of combatting foodborne illness. Through grounded fieldwork centered on the case of a regional wholesale produce market in California, we examine the consequences of this bureaucratization of food safety power on the everyday routines and lived experiences of people working to grow, pack, and deliver fresh produce. We find that despite rhetoric promising a rational and universal answer to food safety, fear and frustration over pervasive uncertainty and legal threats can produce cynicism, distrust, and fragmentation among agrifood actors. Furthermore, under the cover of its public health mission to prevent foodborne illness, food safety culture exerts a new moral economy that sorts companies and employees into categories of ‘good’ and ‘bad’ according to an abstracted calculation of ‘riskiness’ along a scale from safe to dangerous. We raise the concern that ‘safety’ is usurping other deeply held values and excluding cultural forms and experiential knowledges associated with long-standing food-ways. The long-term danger, we conclude, is that this uniform and myopic response to real risks of foodborne illness will not lead to a holistically healthy or sustainable agrifood system, but rather perpetuate a spiraling cycle of crisis and reform that carries a very real human toll."
journal_title,Agriculture and Human Values
article_title,How global is my local milk? Evaluating the first-order inputs of “local” milk in Hawai‘i
keyword,"['Local food\xa0', 'Dairy\xa0', 'Hawai‘i\xa0', 'Sustainable food systems\xa0', 'Food labeling\xa0', 'Made in America\xa0']"
history,"['2017-09', '2016-11-21', '2016-11-03']"
abstract,"Abstract “Local food” is gaining in popularity, particularly within a rising alternative food movement, yet it remains an ambiguous term. We use an illustrative example—the case of “local milk” in Hawai‘i—to demonstrate this point. We evaluate ""localness"" by measuring the origins of production inputs by economic value and physical mass–an approach that is akin to the Made in America standard. The innovative method we propose is easily replicable to other food products or locations worldwide. We find that most first order production related inputs are obtained from non-local sources. Our findings are significant to the local food debate because a focus beyond the point of production to upstream inputs in the life cycle of a food item can push towards a re-framing what local means both in Hawai‘i and beyond. In particular, our findings suggest that production system type, as opposed to location of production end-point, might have a greater impact on the degree of localness of a product. Looking forward, a shift in focus towards production system characteristics may help researchers make headway in exploring the environmental and economic effects of local food."
journal_title,Agriculture and Human Values
article_title,When technology is more than instrumental: How ethical concerns in EU agriculture co-evolve with the development of GM crops
keyword,"['Agriculture, technology, values\xa0', 'Technological mediation\xa0', 'Agricultural system\xa0', 'Genetically modified crops (GMOs)\xa0', 'Morality and ethics\xa0', 'Confirmative mediation\xa0', 'Disruptive mediation\xa0']"
history,"['2017-09', '2016-10-24', '2016-10-03']"
abstract,"Abstract Being more than mere passive objects used at human will, technologies co-determine the values and structures that shape the EU agricultural system. Technologies (in use) actively shape human interpretation, human action and co-shape our moral standards and routines. It is therefore important to account for the moral significance of agricultural technologies when characterising the structures in place within EU agriculture as well as when trying to understand why a particular agricultural technology is favoured or strongly opposed. From this perspective on technology, an interesting question to pose, is how, within their current use context, genetically modified (GM) crops mediate human interpretation and human practice? This technology is of particular interest, because after more than 30 years, the debate on GM crops is still profound and highly polarised within EU society. Yet, too often, this debate is devalued as being irrational or irrelevant, while we show in this article, based on a technological mediation analysis, how ethical concerns about agricultural practices have co-evolved with the technological development of GM crops. This qualifies public debate on GM crops in the EU as both legitimate and relevant, as, from this perspective on technology, it can be seen as an important way to both characterise and discuss how EU agriculture is and should be organised. Analysing technology in terms of the myriad ways in which it mediates the relationship between humans and their world, further allows us to make some suggestions about how to broaden the ongoing EU discussion beyond the current dichotomous Yes/No framing."
journal_title,Agriculture and Human Values
article_title,Books received
keyword,[]
history,"['2017-06', '2017-02-27']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Catherine Phillips: Saving more than seeds: practices and politics of seed saving
keyword,[]
history,"['2017-06', '2016-11-01', '2016-10-25']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Marianne Krasny and Keith G. Tidball: Civic ecology: adaptation and transformation from the ground up
keyword,[]
history,"['2017-06', '2016-10-18', '2016-10-06']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Daniel R. Block and Howard B. Rosing: Chicago: a food biography
keyword,[]
history,"['2017-06', '2016-10-26', '2016-10-14']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Brian K. Obach: Organic struggle: the movement for sustainable agriculture in the United States
keyword,[]
history,"['2017-06', '2016-10-26', '2016-10-06']"
abstract,None
journal_title,Agriculture and Human Values
article_title,Gesine Gerhard: Nazi hunger politics
keyword,[]
history,"['2017-06', '2016-10-27', '2016-10-11']"
abstract,None
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Shallow water modeling of rolling pad instability in liquid metal batteries
keyword,"['Liquid metal battery\xa0', 'Magnetohydrodynamics\xa0', 'Interfacial instability\xa0', 'Shallow water model\xa0']"
history,"['2018-06', '2018-03-31', '2017-12-27', '2018-03-25']"
abstract,"Abstract Magnetohydrodynamically induced interface instability in liquid metal batteries is analyzed. The batteries are represented by a simplified system in the form of a rectangular cell, in which strong vertical electric current flows through three horizontal layers: the layer of a heavy metal at the bottom, the layer of a light metal at the top, and the layer of electrolyte in the middle. A new two-dimensional nonlinear model based on the conservative shallow water approximation is derived and utilized in a numerical study. It is found that in the case of small density difference between the electrolyte and one of the metals, the instability closely resembles the rolling pad instability observed earlier in the aluminum reduction cells. When the two electrolyte-metal density differences are comparable, the dynamics of unstable systems is more complex and characterized by interaction between two nearly synchronized or nearly anti-synchronized interfacial waves."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Full-order optimal compensators for flow control: the multiple inputs case
keyword,"['Flow control\xa0', 'Optimization\xa0', 'Stability analysis\xa0']"
history,"['2018-06', '2018-03-22', '2017-01-29', '2018-03-13']"
abstract,"Abstract Flow control has been the subject of numerous experimental and theoretical works. We analyze full-order, optimal controllers for large dynamical systems in the presence of multiple actuators and sensors. The full-order controllers do not require any preliminary model reduction or low-order approximation: this feature allows us to assess the optimal performance of an actuated flow without relying on any estimation process or further hypothesis on the disturbances. We start from the original technique proposed by Bewley et al. (Meccanica 51(12):2997–3014, 2016.  https://doi.org/10.1007/s11012-016-0547-3), the adjoint of the direct-adjoint (ADA) algorithm. The algorithm is iterative and allows bypassing the solution of the algebraic Riccati equation associated with the optimal control problem, typically infeasible for large systems. In this numerical work, we extend the ADA iteration into a more general framework that includes the design of controllers with multiple, coupled inputs and robust controllers (\(\mathcal {H}_{\infty }\) methods). First, we demonstrate our results by showing the analytical equivalence between the full Riccati solutions and the ADA approximations in the multiple inputs case. In the second part of the article, we analyze the performance of the algorithm in terms of convergence of the solution, by comparing it with analogous techniques. We find an excellent scalability with the number of inputs (actuators), making the method a viable way for full-order control design in complex settings. Finally, the applicability of the algorithm to fluid mechanics problems is shown using the linearized Kuramoto–Sivashinsky equation and the Kármán vortex street past a two-dimensional cylinder."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Artificial eigenmodes in truncated flow domains
keyword,"['Global instability\xa0', 'Non-reflecting boundary conditions\xa0', 'Jets\xa0']"
history,"['2018-06', '2017-12-14', '2017-04-14', '2017-11-25']"
abstract,"Abstract Whenever linear eigenmodes of open flows are computed on a numerical domain that is truncated in the streamwise direction, artificial boundary conditions may give rise to spurious pressure signals that are capable of providing unwanted perturbation feedback to upstream locations. The manifestation of such feedback in the eigenmode spectrum is analysed here for two simple configurations. First, explicitly prescribed feedback in a Ginzburg–Landau model is shown to produce a spurious eigenmode branch, named the ‘arc branch’, that strongly resembles a characteristic family of eigenmodes typically present in open shear flow calculations. Second, corresponding mode branches in the global spectrum of an incompressible parallel jet in a truncated domain are examined. It is demonstrated that these eigenmodes of the numerical model depend on the presence of spurious forcing of a local \(k^+\) instability wave at the inflow, caused by pressure signals that appear to be generated at the outflow. Multiple local \(k^+\) branches result in multiple global eigenmode branches. For the particular boundary treatment chosen here, the strength of the pressure feedback from the outflow towards the inflow boundary is found to decay with the cube of the numerical domain length. It is concluded that arc branch eigenmodes are artefacts of domain truncation, with limited value for physical analysis. It is demonstrated, for the example of a non-parallel jet, how spurious feedback may be reduced by an absorbing layer near the outflow boundary."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,"Effects of confinement, geometry, inlet velocity profile, and Reynolds number on the asymmetry of opposed-jet flows"
keyword,"['Counterflow configuration\xa0', 'Numerical simulations\xa0', 'Quasi- one-dimensional modeling\xa0', 'Bifurcation\xa0']"
history,"['2018-06', '2018-04-02', '2017-07-28', '2018-03-25']"
abstract,"Abstract The opposed-jet counterflow configuration is widely used to measure fundamental flame properties that are essential targets for validating chemical kinetic models. The main and key assumption of the counterflow configuration in laminar flame experiments is that the flow field is steady and quasi-one-dimensional. In this study, experiments and numerical simulations were carried out to investigate the behavior and controlling parameters of counterflowing isothermal air jets for various nozzle designs, Reynolds numbers, and surrounding geometries. The flow field in the jets’ impingement region was analyzed in search of instabilities, asymmetries, and two-dimensional effects that can introduce errors when the data are compared with results of quasi-one-dimensional simulations. The modeling involved transient axisymmetric numerical simulations along with bifurcation analysis, which revealed that when the flow field is confined between walls, local bifurcation occurs, which in turn results in asymmetry, deviation from the one-dimensional assumption, and sensitivity of the flow field structure to boundary conditions and surrounding geometry. Particle image velocimetry was utilized and results revealed that for jets of equal momenta at low Reynolds numbers of the order of 300, the flow field is asymmetric with respect to the middle plane between the nozzles even in the absence of confining walls. The asymmetry was traced to the asymmetric nozzle exit velocity profiles caused by unavoidable imperfections in the nozzle assembly. The asymmetry was not detectable at high Reynolds numbers of the order of 1000 due to the reduced sensitivity of the flow field to boundary conditions. The cases investigated computationally covered a wide range of Reynolds numbers to identify designs that are minimally affected by errors in the experimental procedures or manufacturing imperfections, and the simulations results were used to identify conditions that best conform to the assumptions of quasi-one-dimensional modeling."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Solitary wave solutions and their interactions for fully nonlinear water waves with surface tension in the generalized Serre equations
keyword,"['Serre equations\xa0', 'Solitary waves\xa0', 'Surface tension\xa0', 'Peakons\xa0', '35Q35\xa0', '74J30\xa0', '92C35\xa0']"
history,"['2018-06', '2018-04-04', '2017-11-20', '2018-03-25']"
abstract,"Abstract Some effects of surface tension on fully nonlinear, long, surface water waves are studied by numerical means. The differences between various solitary waves and their interactions in subcritical and supercritical surface tension regimes are presented. Analytical expressions for new peaked traveling wave solutions are presented in the dispersionless case of critical surface tension. Numerical experiments are performed using a high-accurate finite element method based on smooth cubic splines and the four-stage, classical, explicit Runge–Kutta method of order 4."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Improvement of double-buffer problem in LES–RANS interface region by introducing an anisotropy-resolving subgrid-scale model
keyword,"['Turbulence\xa0', 'Large eddy simulation\xa0', 'Anisotropy-resolving SGS model\xa0', 'Hybrid LES/RANS model\xa0', 'Interface region\xa0']"
history,"['2018-06', '2018-02-07', '2017-09-08', '2018-01-29']"
abstract,"Abstract The “double-buffer problem” has been regarded as a crucial concern for the strategy behind the hybrid large eddy simulation (LES)/Reynolds-averaged Navier–Stokes (RANS) model (or HLR model, for short). Such models are likely to show unphysical mean-velocity distributions in the LES–RANS interface region, where “super-streak structures” also appear that look like low-speed streaks generated in the near-wall region of wall turbulence. To overcome this difficulty, the stochastic backscatter model, in which the vortex structures in the interface region are divided into smaller scales, holds promise due to the effect of random source term imposed in the momentum equation. Although this method is effective, several parameters must be prescribed and their specification process is arbitrary and ambiguous. An alternative advanced HLR model has been proposed, in which an anisotropy-resolving subgrid-scale (SGS) model was adopted in the LES region as well as a one-equation nonlinear eddy viscosity model in the RANS region. Previous investigations indicated that this HLR model did not exhibit or, at least, largely reduced the “double-buffer problem” in the mean-velocity distribution, with no special treatment being applied. The main purpose of the present study is to reveal why this HLR model improves the predictive performance in the LES–RANS interface region. Specifically, we focus on the role of the extra anisotropic term introduced in the SGS model, finding that it plays an important role in enhancing vortex structures in the interface region, leading to a considerable improvement in model performance."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Drag reduction and thrust generation by tangential surface motion in flow past a cylinder
keyword,"['Drag reduction\xa0', 'Sensitivity\xa0', 'Bluff body flow\xa0']"
history,"['2018-06', '2018-03-26', '2016-04-21', '2017-11-25']"
abstract,"Abstract Sensitivity of drag to tangential surface motion is calculated in flow past a circular cylinder in both two- and three-dimensional conditions at Reynolds number \(\textit{Re} \le 1000\). The magnitude of the sensitivity maximises in the region slightly upstream of the separation points where the contour lines of spanwise vorticity are normal to the cylinder surface. A control to reduce drag can be obtained by (negatively) scaling the sensitivity. The high correlation of sensitivities of controlled and uncontrolled flow indicates that the scaled sensitivity is a good approximation of the nonlinear optimal control. It is validated through direct numerical simulations that the linear range of the steady control is much higher than the unsteady control, which synchronises the vortex shedding and induces lock-in effects. The steady control injects angular momentum into the separating boundary layer, stabilises the flow and increases the base pressure significantly. At \(\textit{Re}=100\), when the maximum tangential motion reaches 50% of the free-stream velocity, the vortex shedding, boundary-layer separation and recirculation bubbles are eliminated and 32% of the drag is reduced. When the maximum tangential motion reaches 2.5 times of the free-stream velocity, thrust is generated and the power savings ratio, defined as the ratio of the reduced drag power to the control input power, reaches 19.6. The mechanism of drag reduction is attributed to the change of the radial gradient of spanwise vorticity (\(\partial _{r} \hat{\zeta }\)) and the subsequent accelerated pressure recovery from the uncontrolled separation points to the rear stagnation point."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Effects of geometric modulation and surface potential heterogeneity on electrokinetic flow and solute transport in a microchannel
keyword,"['Surface modulation\xa0', 'Electroosmotic flow\xa0', 'Nernst–Planck equations\xa0', 'Navier–Stokes equations\xa0', 'Mixing efficiency\xa0']"
history,"['2018-04', '2017-12-07', '2017-02-14', '2017-11-25']"
abstract,"Abstract A numerical investigation is performed on the electroosmotic flow (EOF) in a surface-modulated microchannel to induce enhanced solute mixing. The channel wall is modulated by placing surface-mounted obstacles of trigonometric shape along which the surface potential is considered to be different from the surface potential of the homogeneous part of the wall. The characteristics of the electrokinetic flow are governed by the Laplace equation for the distribution of external electric potential; the Poisson equation for the distribution of induced electric potential; the Nernst–Planck equations for the distribution of ions; and the Navier–Stokes equations for fluid flow simultaneously. These nonlinear coupled set of governing equations are solved numerically by a control volume method over the staggered system. The influence of the geometric modulation of the surface, surface potential heterogeneity and the bulk ionic concentration on the EOF is analyzed. Vortical flow develops near a surface modulation, and it becomes stronger when the surface potential of the modulated region is in opposite sign to the surface potential of the homogeneous part of the channel walls. Vortical flow also depends on the Debye length when the Debye length is in the order of the channel height. Pressure drop along the channel length is higher for a ribbed wall channel compared to the grooved wall case. The pressure drop decreases with the increase in the amplitude for a grooved channel, but increases for a ribbed channel. The mixing index is quantified through the standard deviation of the solute distribution. Our results show that mixing index is higher for the ribbed channel compared to the grooved channel with heterogeneous surface potential. The increase in potential heterogeneity in the modulated region also increases the mixing index in both grooved and ribbed channels. However, the mixing performance, which is the ratio of the mixing index to pressure drop, reduces with the rise in the surface potential heterogeneity."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Effective particle size from molecular dynamics simulations in fluids
keyword,"['Particle size\xa0', 'Molecular dynamics\xa0', 'Hydrodynamic flow\xa0', 'Particle–wall interactions\xa0']"
history,"['2018-04', '2017-12-08', '2016-12-19', '2017-11-25']"
abstract,"Abstract We report molecular dynamics simulations designed to investigate the effective size of colloidal particles suspended in a fluid in the vicinity of a rigid wall where all interactions are defined by smooth atomic potential functions. These simulations are used to assess how the behavior of this system at the atomistic length scale compares to continuum mechanics models. In order to determine the effective size of the particles, we calculate the solvent forces on spherical particles of different radii as a function of different positions near and overlapping with the atomistically defined wall and compare them to continuum models. This procedure also then determines the effective position of the wall. Our analysis is based solely on forces that the particles sense, ensuring self-consistency of the method. The simulations were carried out using both Weeks–Chandler–Andersen and modified Lennard-Jones (LJ) potentials to identify the different contributions of simple repulsion and van der Waals attractive forces. Upon correction for behavior arising the discreteness of the atomic system, the underlying continuum physics analysis appeared to be correct down to much less than the particle radius. For both particle types, the effective radius was found to be \(\sim 0.75\sigma \), where \(\sigma \) defines the length scale of the force interaction (the LJ diameter). The effective “hydrodynamic” radii determined by this means are distinct from commonly assumed values of \(0.5\sigma \) and \(1.0\sigma \), but agree with a value developed from the atomistic analysis of the viscosity of such systems."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Asymptotics for moist deep convection I: refined scalings and self-sustaining updrafts
keyword,"['Moist atmospheric flows\xa0', 'Multiscale asymptotics\xa0', 'Matched asymptotic expansions\xa0', 'Hot towers\xa0', 'Cumulonimbus clouds\xa0']"
history,"['2018-04', '2017-10-05', '2017-04-14', '2017-08-22']"
abstract,"Abstract Moist processes are among the most important drivers of atmospheric dynamics, and scale analysis and asymptotics are cornerstones of theoretical meteorology. Accounting for moist processes in systematic scale analyses therefore seems of considerable importance for the field. Klein and Majda (Theor Comput Fluid Dyn 20:525–551, 2006) proposed a scaling regime for the incorporation of moist bulk microphysics closures in multiscale asymptotic analyses of tropical deep convection. This regime is refined here to allow for mixtures of ideal gases and to establish consistency with a more general multiple scales modeling framework for atmospheric flows. Deep narrow updrafts, the so-called hot towers, constitute principal building blocks of larger scale storm systems. They are analyzed here in a sample application of the new scaling regime. A single quasi-one-dimensional upright columnar cloud is considered on the vertical advective (or tower life cycle) time scale. The refined asymptotic scaling regime is essential for this example as it reveals a new mechanism for the self-sustainance of such updrafts. Even for strongly positive convectively available potential energy, a vertical balance of buoyancy forces is found in the presence of precipitation. This balance induces a diagnostic equation for the vertical velocity, and it is responsible for the generation of self-sustained balanced updrafts. The time-dependent updraft structure is encoded in a Hamilton–Jacobi equation for the precipitation mixing ratio. Numerical solutions of this equation suggest that the self-sustained updrafts may strongly enhance hot tower life cycles."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Control of a three-dimensional turbulent shear layer by means of oblique vortices
keyword,"['Backward-facing step\xa0', 'Sweep\xa0', 'Three-dimensional flows\xa0', 'Free shear layers\xa0', 'Flow control\xa0', 'Large-eddy simulation\xa0']"
history,"['2018-04', '2017-12-02', '2017-02-10', '2017-11-09']"
abstract,"Abstract The effect of local forcing on the separated, three-dimensional shear layer downstream of a backward-facing step is investigated by means of large-eddy simulation for a Reynolds number based on the step height of 10,700. The step edge is either oriented normal to the approaching turbulent boundary layer or swept at an angle of \(40^\circ \). Oblique vortices with different orientation and spacing are generated by wavelike suction and blowing of fluid through an edge parallel slot. The vortices exhibit a complex three-dimensional structure, but they can be characterized by a wavevector in a horizontal section plane. In order to determine the step-normal component of the wavevector, a method is developed based on phase averages. The dependence of the wavevector on the forcing parameters can be described in terms of a dispersion relation, the structure of which indicates that the disturbances are mainly convected through the fluid. The introduced vortices reduce the size of the recirculation region by up to 38%. In both the planar and the swept case, the most efficient of the studied forcings consists of vortices which propagate in a direction that deviates by more than \(50^\circ \) from the step normal. These vortices exhibit a spacing in the order of 2.5 step heights. The upstream shift of the reattachment line can be explained by increased mixing and momentum transport inside the shear layer which is reflected in high levels of the Reynolds shear stress \(-\rho \overline{u'v'}\). The position of the maximum of the coherent shear stress is found to depend linearly on the wavelength, similar to two-dimensional free shear layers."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Stochastic growth of cloud droplets by collisions during settling
keyword,"['Stochastic collisional growth\xa0', 'Droplet clustering\xa0', 'Drizzle formation\xa0', 'Gravitational settling\xa0']"
history,"['2018-04', '2017-12-11', '2017-04-06', '2017-10-04']"
abstract,"Abstract In the last stage of droplet growth in clouds which leads to drizzle formation, larger droplets begin to settle under gravity and collide and coalesce with smaller droplets in their path. In this article, we shall deal with the simplified problem of a large drop settling amidst a population of identical smaller droplets. We present an expression for the probability that a given large drop suffers a given number of collisions, for a general statistically homogeneous distribution of droplets. We hope that our approach will serve as a valuable tool in dealing with droplet distribution in real clouds, which has been found to deviate from the idealized Poisson distribution due to mechanisms such as inertial clustering."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Leading-edge flow criticality as a governing factor in leading-edge vortex initiation in unsteady airfoil flows
keyword,"['LESP\xa0', 'LEV\xa0', 'Vortex dynamics\xa0', 'Unsteady aerodynamics\xa0', 'Low Reynolds number\xa0', 'Flow separation\xa0']"
history,"['2018-04', '2017-08-14', '2016-10-10', '2017-07-26']"
abstract,"Abstract A leading-edge suction parameter (LESP) that is derived from potential flow theory as a measure of suction at the airfoil leading edge is used to study initiation of leading-edge vortex (LEV) formation in this article. The LESP hypothesis is presented, which states that LEV formation in unsteady flows for specified airfoil shape and Reynolds number occurs at a critical constant value of LESP, regardless of motion kinematics. This hypothesis is tested and validated against a large set of data from CFD and experimental studies of flows with LEV formation. The hypothesis is seen to hold except in cases with slow-rate kinematics which evince significant trailing-edge separation (which refers here to separation leading to reversed flow on the aft portion of the upper surface), thereby establishing the envelope of validity. The implication is that the critical LESP value for an airfoil–Reynolds number combination may be calibrated using CFD or experiment for just one motion and then employed to predict LEV initiation for any other (fast-rate) motion. It is also shown that the LESP concept may be used in an inverse mode to generate motion kinematics that would either prevent LEV formation or trigger the same as per aerodynamic requirements."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Validation of numerical solvers for liquid metal flow in a complex geometry in the presence of a strong magnetic field
keyword,"['Numerical validation\xa0', 'Magnetohydrodynamics\xa0', 'Fusion blankets\xa0', 'Strong magnetic fields\xa0']"
history,"['2018-04', '2017-11-14', '2017-01-23', '2017-10-17']"
abstract,"Abstract Following the magnetohydrodynamic (MHD) code validation and verification proposal by Smolentsev et al. (Fusion Eng Des 100:65–72, 2015), we perform code to code and code to experiment comparisons between two computational solvers, FLUIDYN and HIMAG, which are presently considered as two of the prospective CFD tools for fusion blanket applications. In such applications, an electrically conducting breeder/coolant circulates in the blanket ducts in the presence of a strong plasma-confining magnetic field at high Hartmann numbers, \(\textit{Ha}\) (\(\textit{Ha}^2\) is the ratio between electromagnetic and viscous forces) and high interaction parameters, \(\textit{N}\) (\(\textit{N}\) is the ratio of electromagnetic to inertial forces). The main objective of this paper is to provide the scientific and engineering community with common references to assist fusion researchers in the selection of adequate computational means to be used for blanket design and analysis. As an initial validation case, the two codes are applied to the classic problem of a laminar fully developed MHD flows in a rectangular duct. Both codes demonstrate a very good agreement with the analytical solution for \(\textit{Ha}\) up to 15, 000. To address the capabilities of the two codes to properly resolve complex geometry flows, we consider a case of three-dimensional developing MHD flow in a geometry comprising of a series of interconnected electrically conducting rectangular ducts. The computed electric potential distributions for two flows (Case A) \(\textit{Ha}=515\), \(\textit{N}=3.2\) and (Case B) \(\textit{Ha}=2059\), \(\textit{N}=63.8\) are in very good agreement with the experimental data, while the comparisons for the MHD pressure drop are still unsatisfactory. To better interpret the observed differences, the obtained numerical data are analyzed against earlier theoretical and experimental studies for flows that involve changes in the relative orientation between the flow and the magnetic field."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Iterative control of Görtler vortices via local wall deformations
keyword,"['Boundary layer control\xa0', 'Görtler vortices\xa0', 'Asymptotic methods\xa0']"
history,"['2018-02', '2017-06-26', '2016-12-03', '2017-06-14']"
abstract,"Abstract Görtler vortices develop along concave walls as a result of the imbalance between the centrifugal force and radial pressure gradient. In this study, we introduce a simple control strategy aimed at reducing the growth rate of Görtler vortices by locally modifying the surface geometry in spanwise and streamwise directions. Such wall deformations are accounted in the boundary region equations by using a Prandtl transform of dependent and independent variables. The vortex energy is then controlled via a classical proportional control algorithm for which either the wall-normal velocity or the wall shear stress serves as the control variable. Our numerical results indicate that the control algorithm is quite effective in minimizing the wall shear stress."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,CFD study on rise and deformation characteristics of buoyancy-driven spheroid bubbles in stagnant Carreau model non-Newtonian fluids
keyword,"['Spheroid\xa0', 'Bubble\xa0', 'Carreau fluid\xa0', 'Deformation\xa0', 'Rise velocity\xa0', 'Viscosity distribution\xa0']"
history,"['2018-02', '2017-06-06', '2016-07-08', '2017-05-15']"
abstract,"Abstract The bubbles are almost ubiquitous in many chemical and processing industries; and many of the polymeric solutions obey non-Newtonian rheological characteristics. Therefore, in this work the rise and deformation characteristics of spheroid bubbles in Carreau model non-Newtonian fluids are numerically investigated using a level set method. To demonstrate the validity of the moving bubble interface, the present simulations are compared with existing numerical and experimental results available in the literature; and for these comparisons, the computational geometries are considered same as reported in corresponding literatures. The present bubble deformation characteristics are satisfactorily agreeing with their literature counterparts. After establishing the validity of the numerical solution procedure, the same method is applied to obtain the deformation characteristics of an air bubble in Carreau model non-Newtonian fluids. Further, the results in terms of the volume fraction images, streamlines, and viscosity profiles around the deforming bubbles are presented as function of the bubble rise time."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A computational investigation of the finite-time blow-up of the 3D incompressible Euler equations based on the Voigt regularization
keyword,"['Euler–Voigt\xa0', 'Navier–Stokes–Voigt\xa0', 'Inviscid regularization\xa0', 'Turbulence models\xa0', None, 'Blow-up criterion for Euler\xa0', '35Q30\xa0', '76A10\xa0', '76B03\xa0', '76D03\xa0', '76F20\xa0', '76F55\xa0', '76F65\xa0', '76W05\xa0']"
history,"['2018-02', '2017-04-29', '2016-07-07', '2017-04-11']"
abstract,"Abstract We report the results of a computational investigation of two blow-up criteria for the 3D incompressible Euler equations. One criterion was proven in a previous work, and a related criterion is proved here. These criteria are based on an inviscid regularization of the Euler equations known as the 3D Euler–Voigt equations, which are known to be globally well-posed. Moreover, simulations of the 3D Euler–Voigt equations also require less resolution than simulations of the 3D Euler equations for fixed values of the regularization parameter \(\alpha >0\). Therefore, the new blow-up criteria allow one to gain information about possible singularity formation in the 3D Euler equations indirectly, namely by simulating the better-behaved 3D Euler–Voigt equations. The new criteria are only known to be sufficient criterion for blow-up. Therefore, to test the robustness of the inviscid-regularization approach, we also investigate analogous criteria for blow-up of the 1D Burgers equation, where blow-up is well known to occur."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Effects of deformability of RBCs on their dynamics and blood flow passing through a stenosed microvessel: an immersed boundary-lattice Boltzmann approach
keyword,"['Red blood cell deformation\xa0', 'Microvessel\xa0', 'Flow resistance\xa0', 'Stenosis\xa0', 'Immersed boundary method\xa0', 'Lattice Boltzmann method\xa0']"
history,"['2018-02', '2017-07-13', '2016-10-11', '2017-06-14']"
abstract,"Abstract In this paper, the motion of high deformable (healthy) and low deformable (sick) red blood cells in a microvessel with and without stenosis is simulated using a combined lattice Boltzmann-immersed boundary method. The RBC is considered as neo-Hookean elastic membrane with bending resistance. The motion and deformation of the RBC under different values of the Reynolds number are evaluated. In addition, the variations of blood flow resistance and time-averaged pressure due to the motion and deformation of the RBC are assessed. It was found that a healthy RBC moves faster than a sick one. The apparent viscosity and blood flow resistance are greater for the case involving the sick RBC. Blood pressure at the presence of stenosis and low deformable RBC increases, which is thought of as the reason of many serious diseases including cardiovascular diseases. As the Re number increases, the RBC deforms further and moves easier and faster through the stenosis. The results of this study were compared to the available experimental and numerical results, and good agreements were observed."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Effect of viscosity ratio on the motion of drops flowing on an inclined surface
keyword,"['Drops\xa0', 'Reynolds number\xa0', 'Viscosity ratio\xa0', 'Inclination angle\xa0', 'Fluctuation energy\xa0']"
history,"['2018-02', '2017-06-28', '2016-09-27', '2017-06-14']"
abstract,"Abstract The flow of two-dimensional drops on an inclined channel is studied by numerical simulations at finite Reynolds numbers. The effect of viscosity ratio on the behaviour of the two-phase medium is examined. The flow is driven by the acceleration due to gravity, and there is no pressure gradient along the flow direction. An implicit version of the finite difference/front-tracking method was developed and used in the present study. The lateral migration of a drop is studied first. It is found that the equilibrium position of a drop moves away from the channel floor as the viscosity ratio increases. However, the trend reverses beyond a certain viscosity ratio. Simulations with 40 drops in a relatively large channel show that there exists a limiting viscosity ratio where the drops behave like solid particles, and the effect of internal circulation of drops becomes negligible. This limiting condition resembles the granular flow regime except that the effect of interstitial fluid is present. The limiting viscosity ratio depends on the flow conditions (80 for \(Re=10\), and 200 for \(Re=20\)). There are two peaks in the areal fraction distribution of drops across the channel which is different from granular flow regime. It is also found that the peak in areal fraction distribution of drops moves away from the channel floor as the inclination angle of the channel increases."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Diffusional growth of cloud particles: existence and uniqueness of solutions
keyword,"['Parabolic partial differential equations\xa0', 'Ordinary differential equations\xa0', 'Diffusion phenomena\xa0', 'Cloud physics\xa0']"
history,"['2018-02', '2017-06-08', '2017-02-03', '2017-05-29']"
abstract,"Abstract Diffusional growth of cloud particles is commonly described by a coupled system of parabolic equations and ordinary differential equations. The Dirichlet boundary condition for the parabolic equation is obtained from the solution of the ordinary differential equations, but this solution itself depends on the solution of the parabolic equations. We first present the governing equations describing diffusional growth of cloud particles. In a second step, we consider a simplified model problem, motivated by the diffusional growth equations. The main difference between the simplified model problem and the diffusional growth equations consists in neglecting the dependence of the domain for the parabolic equations on the solution. For the model problem, we show unique solvability using a fixed point method. Finally, we discuss application of the main result for the model problem to the diffusional growth equations and illustrate these equations with the help of a numerical solution."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Pure axial flow of viscoelastic fluids in rectangular microchannels under combined effects of electro-osmosis and hydrodynamics
keyword,"['Microfluidics\xa0', 'Rectangular microchannels\xa0', 'Electro-osmosis\xa0', 'Viscoelastic fluids\xa0', 'PTT model\xa0']"
history,"['2018-02', '2017-04-10', '2016-01-26', '2017-03-06']"
abstract,"Abstract This paper presents an analysis of the combined electro-osmotic and pressure-driven axial flows of viscoelastic fluids in a rectangular microchannel with arbitrary aspect ratios. The rheological behavior of the fluid is described by the complete form of Phan-Thien–Tanner (PTT) model with the Gordon–Schowalter convected derivative which covers the upper convected Maxwell, Johnson–Segalman and FENE-P models. Our numerical simulation is based on the computation of 2D Poisson–Boltzmann, Cauchy momentum and PTT constitutive equations. The solution of these governing nonlinear coupled set of equations is obtained by using the second-order central finite difference method in a non-uniform grid system and is verified against 1D analytical solution of the velocity profile with less than 0.06% relative error. Also, a parametric study is carried out to investigate the effect of channel aspect ratio (width to height), wall zeta potential and the Debye–Hückel parameter on 2D velocity profile, volumetric flow rate and the Poiseuille number in the mixed EO/PD flows of viscoelastic fluids with different Weissenberg numbers. Our results show that, for low channel aspect ratios, the previous 1D analytical models underestimate the velocity profile at the channel half-width centerline in the case of favorable pressure gradients and overestimate it in the case of adverse pressure gradients. The results reveal that the inapplicability of the Debye–Hückel approximation at high zeta potentials is more significant for higher Weissenberg number fluids. Also, it is found that, under the specified values of electrokinetic parameters, there is a threshold for velocity scale ratio in which the Poiseuille number is approximately independent of channel aspect ratio."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Error sensitivity to refinement: a criterion for optimal grid adaptation
keyword,"['Grid adaptation\xa0', 'Error estimation\xa0', 'Adjoint\xa0', 'Sensitivity\xa0']"
history,"['2017-12', '2016-11-02', '2016-02-23', '2016-10-19']"
abstract,"Abstract Most indicators used for automatic grid refinement are suboptimal, in the sense that they do not really minimize the global solution error. This paper concerns with a new indicator, related to the sensitivity map of global stability problems, suitable for an optimal grid refinement that minimizes the global solution error. The new criterion is derived from the properties of the adjoint operator and provides a map of the sensitivity of the global error (or its estimate) to a local mesh refinement. Examples are presented for both a scalar partial differential equation and for the system of Navier–Stokes equations. In the last case, we also present a grid-adaptation algorithm based on the new estimator and on the \(FreeFem++\) software that improves the accuracy of the solution of almost two order of magnitude by redistributing the nodes of the initial computational mesh."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Erratum to: Error sensitivity to refinement: a criterion for optimal grid adaptation
keyword,[]
history,"['2017-12', '2017-04-13']"
abstract,None
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Special issue on global flow instability and control
keyword,"['Global linear instability\xa0', 'Flow control\xa0', 'Transition\xa0', 'Turbulence\xa0']"
history,"['2017-12', '2017-10-05']"
abstract,"Abstract This special issue is the second on the topic of “Global Flow Instability and Control,” following the first in 2011. As with the previous special issue, the participants of the last two symposia on Global Flow Instability and Control, held in Crete, Greece, were invited to submit publications. These papers were peer reviewed according to the standards of the journal, and this issue represents a snapshot of the progress since 2011. In this preface, a sampling of important developments in the field since the first issue is discussed. A synopsis of the papers in this issue is given in that context."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,The flow past a freely rotating sphere
keyword,"['Freely moving bodies\xa0', 'Fluid–structure interactions\xa0', 'Weakly nonlinear expansion\xa0']"
history,"['2017-12', '2016-08-23', '2016-02-22', '2016-08-05']"
abstract,"Abstract We consider the flow past a sphere held at a fixed position in a uniform incoming flow but free to rotate around a transverse axis. A steady pitchfork bifurcation is reported to take place at a threshold \(Re^\mathrm{OS}=206\) leading to a state with zero torque but nonzero lift. Numerical simulations allow to characterize this state up to \(Re\approx 270\) and confirm that it substantially differs from the steady-state solution which exists in the wake of a fixed, non-rotating sphere beyond the threshold \(Re^\mathrm{SS}=212\). A weakly nonlinear analysis is carried out and is shown to successfully reproduce the results and to give substantial improvement over a previous analysis (Fabre et al. in J Fluid Mech 707:24–36, 2012). The connection between the present problem and that of a sphere in free fall following an oblique, steady (OS) path is also discussed."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Lattice Boltzmann methods for global linear instability analysis
keyword,"['Lattice Boltzmann methods\xa0', 'Complex geometries\xa0', 'Global instability analysis\xa0', 'Flow control\xa0']"
history,"['2017-12', '2016-11-25', '2016-04-13', '2016-11-04']"
abstract,"Abstract Modal global linear instability analysis is performed using, for the first time ever, the lattice Boltzmann method (LBM) to analyze incompressible flows with two and three inhomogeneous spatial directions. Four linearization models have been implemented in order to recover the linearized Navier–Stokes equations in the incompressible limit. Two of those models employ the single relaxation time and have been proposed previously in the literature as linearization of the collision operator of the lattice Boltzmann equation. Two additional models are derived herein for the first time by linearizing the local equilibrium probability distribution function. Instability analysis results are obtained in three benchmark problems, two in closed geometries and one in open flow, namely the square and cubic lid-driven cavity flow and flow in the wake of the circular cylinder. Comparisons with results delivered by classic spectral element methods verify the accuracy of the proposed new methodologies and point potential limitations particular to the LBM approach. The known issue of appearance of numerical instabilities when the SRT model is used in direct numerical simulations employing the LBM is shown to be reflected in a spurious global eigenmode when the SRT model is used in the instability analysis. Although this mode is absent in the multiple relaxation times model, other spurious instabilities can also arise and are documented herein. Areas of potential improvements in order to make the proposed methodology competitive with established approaches for global instability analysis are discussed."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Reducing the pressure drag of a D-shaped bluff body using linear feedback control
keyword,"['Bluff body aerodynamics\xa0', 'Flow control\xa0', 'Linear feedback control\xa0', 'Drag reduction\xa0']"
history,"['2017-12', '2017-01-18', '2016-02-09', '2017-01-03']"
abstract,"Abstract The pressure drag of blunt bluff bodies is highly relevant in many practical applications, including to the aerodynamic drag of road vehicles. This paper presents theory revealing that a mean drag reduction can be achieved by manipulating wake flow fluctuations. A linear feedback control strategy then exploits this idea, targeting attenuation of the spatially integrated base (back face) pressure fluctuations. Large-eddy simulations of the flow over a D-shaped blunt bluff body are used as a test-bed for this control strategy. The flow response to synthetic jet actuation is characterised using system identification, and controller design is via shaping of the frequency response to achieve fluctuation attenuation. The designed controller successfully attenuates integrated base pressure fluctuations, increasing the time-averaged pressure on the body base by 38%. The effect on the flow field is to push the roll-up of vortices further downstream and increase the extent of the recirculation bubble. This control approach uses only body-mounted sensing/actuation and input–output model identification, meaning that it could be applied experimentally."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Adjoint optimization of natural convection problems: differentially heated cavity
keyword,"['Adjoint optimization\xa0', 'Natural convection\xa0', 'Differentially heated cavity\xa0', 'Arnoldi method\xa0', 'Power iterations\xa0']"
history,"['2017-12', '2016-06-11', '2016-02-25', '2016-05-19']"
abstract,"Abstract Optimization of natural convection-driven flows may provide significant improvements to the performance of cooling devices, but a theoretical investigation of such flows has been rarely done. The present paper illustrates an efficient gradient-based optimization method for analyzing such systems. We consider numerically the natural convection-driven flow in a differentially heated cavity with three Prandtl numbers (\(Pr=0.15{-}7\)) at super-critical conditions. All results and implementations were done with the spectral element code Nek5000. The flow is analyzed using linear direct and adjoint computations about a nonlinear base flow, extracting in particular optimal initial conditions using power iteration and the solution of the full adjoint direct eigenproblem. The cost function for both temperature and velocity is based on the kinetic energy and the concept of entransy, which yields a quadratic functional. Results  are presented as a function of Prandtl number, time horizons and weights between kinetic energy and entransy. In particular, it is shown that the maximum transient growth is achieved at time horizons on the order of 5 time units for all cases, whereas for larger time horizons the adjoint mode is recovered as optimal initial condition. For smaller time horizons, the influence of the weights leads either to a concentric temperature distribution or to an initial condition pattern that opposes the mean shear and grows according to the Orr mechanism. For specific cases, it could also been shown that the computation of optimal initial conditions leads to a degenerate problem, with a potential loss of symmetry. In these situations, it turns out that any initial condition lying in a specific span of the eigenfunctions will yield exactly the same transient amplification. As a consequence, the power iteration converges very slowly and fails to extract all possible optimal initial conditions. According to the authors’ knowledge, this behavior is illustrated here for the first time."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Linear instability in the wake of an elliptic wing
keyword,"['Elliptic wing\xa0', 'Trailing vortex system\xa0', 'Global linear instability\xa0']"
history,"['2017-12', '2016-07-09', '2016-03-02', '2016-06-14']"
abstract,"Abstract Linear global instability analysis has been performed in the wake of a low aspect ratio three-dimensional wing of elliptic cross section, constructed with appropriately scaled Eppler E387 airfoils. The flow field over the airfoil and in its wake has been computed by full three-dimensional direct numerical simulation at a chord Reynolds number of \(Re_{c}=1750\) and two angles of attack, \(\mathrm{{AoA}}=0^\circ \) and \(5^\circ \). Point-vortex methods have been employed to predict the inviscid counterpart of this flow. The spatial BiGlobal eigenvalue problem governing linear small-amplitude perturbations superposed upon the viscous three-dimensional wake has been solved at several axial locations, and results were used to initialize linear PSE-3D analyses without any simplifying assumptions regarding the form of the trailing vortex system, other than weak dependence of all flow quantities on the axial spatial direction. Two classes of linearly unstable perturbations were identified, namely stronger-amplified symmetric modes and weaker-amplified antisymmetric disturbances, both peaking at the vortex sheet which connects the trailing vortices. The amplitude functions of both classes of modes were documented, and their characteristics were compared with those delivered by local linear stability analysis in the wake near the symmetry plane and in the vicinity of the vortex core. While all linear instability analysis approaches employed have delivered qualitatively consistent predictions, only PSE-3D is free from assumptions regarding the underlying base flow and should thus be employed to obtain quantitative information on amplification rates and amplitude functions in this class of configurations."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Global stability behaviour for the BEK family of rotating boundary layers
keyword,"['Rotating flows\xa0', 'Boundary layer stability\xa0', 'Global stability\xa0', 'Vorticity-based simulation\xa0']"
history,"['2017-12', '2016-09-02', '2016-06-10', '2016-08-05']"
abstract,"Abstract Numerical simulations were conducted to investigate the linear global stability behaviour of the Bödewadt, Ekman, von Kármán (BEK) family of flows, for cases where a disc rotates beneath an incompressible fluid that is also rotating. This extends the work reported in recent studies that only considered the rotating-disc boundary layer with a von Kármán configuration, where the fluid that lies above the boundary layer remains stationary. When a homogeneous flow approximation is made, neglecting the radial variation of the basic state, it can be shown that linearised disturbances are susceptible to absolute instability. We shall demonstrate that, despite this prediction of absolute instability, the disturbance development exhibits globally stable behaviour in the BEK boundary layers with a genuine radial inhomogeneity. For configurations where the disc rotation rate is greater than that of the overlying fluid, disturbances propagate radially outwards and there is only a convective form of instability. This replicates the behaviour that had previously been documented when the fluid did not rotate beyond the boundary layer. However, if the fluid rotation rate is taken to exceed that of the disc, then the propagation direction reverses and disturbances grow while convecting radially inwards. Eventually, as they approach regions of smaller radii, where stability is predicted according to the homogeneous flow approximation, the growth rates reduce until decay takes over. Given sufficient time, such disturbances can begin to diminish at every radial location, even those which are positioned outwards from the radius associated with the onset of absolute instability. This leads to the confinement of the disturbance development within a finitely bounded region of the spatial–temporal plane."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Spanwise effects on instabilities of compressible flow over a long rectangular cavity
keyword,"['Compressible cavity flow\xa0', 'Wake mode\xa0', 'Global stability analysis\xa0']"
history,"['2017-12', '2016-11-04', '2016-04-11', '2016-10-19']"
abstract,"Abstract The stability properties of two-dimensional (2D) and three-dimensional (3D) compressible flows over a rectangular cavity with length-to-depth ratio of \(L/D=6\) are analyzed at a free-stream Mach number of \(M_\infty =0.6\) and depth-based Reynolds number of \(Re_D=502\). In this study, we closely examine the influence of three-dimensionality on the wake mode that has been reported to exhibit high-amplitude fluctuations from the formation and ejection of large-scale spanwise vortices. Direct numerical simulation (DNS) and bi-global stability analysis are utilized to study the stability characteristics of the wake mode. Using the bi-global stability analysis with the time-averaged flow as the base state, we capture the global stability properties of the wake mode at a spanwise wavenumber of \(\beta =0\). To uncover spanwise effects on the 2D wake mode, 3D DNS are performed with cavity width-to-depth ratio of \(W/D=1\) and 2. We find that the 2D wake mode is not present in the 3D cavity flow with \(W/D=2\), in which spanwise structures are observed near the rear region of the cavity. These 3D instabilities are further investigated via bi-global stability analysis for spanwise wavelengths of \(\lambda /D=0.5{-}2.0\) to reveal the eigenspectra of the 3D eigenmodes. Based on the findings of 2D and 3D global stability analysis, we conclude that the absence of the wake mode in 3D rectangular cavity flows is due to the release of kinetic energy from the spanwise vortices to the streamwise vortical structures that develops from the spanwise instabilities."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,The linearized pressure Poisson equation for global instability analysis of incompressible flows
keyword,"['Global linear instability\xa0', 'Matrix-forming\xa0', 'Collocated grids\xa0', 'Pressure boundary conditions\xa0']"
history,"['2017-12', '2017-05-16', '2016-04-10', '2017-04-27']"
abstract,"Abstract The linearized pressure Poisson equation (LPPE) is used in two and three spatial dimensions in the respective matrix-forming solution of the BiGlobal and TriGlobal eigenvalue problem in primitive variables on collocated grids. It provides a disturbance pressure boundary condition which is compatible with the recovery of perturbation velocity components that satisfy exactly the linearized continuity equation. The LPPE is employed to analyze instability in wall-bounded flows and in the prototype open Blasius boundary layer flow. In the closed flows, excellent agreement is shown between results of the LPPE and those of global linear instability analyses based on the time-stepping nektar++, Semtex and nek5000 codes, as well as with those obtained from the FreeFEM++ matrix-forming code. In the flat plate boundary layer, solutions extracted from the two-dimensional LPPE eigenvector at constant streamwise locations are found to be in very good agreement with profiles delivered by the NOLOT/PSE space marching code. Benchmark eigenvalue data are provided in all flows analyzed. The performance of the LPPE is seen to be superior to that of the commonly used pressure compatibility (PC) boundary condition: at any given resolution, the discrete part of the LPPE eigenspectrum contains converged and not converged, but physically correct, eigenvalues. By contrast, the PC boundary closure delivers some of the LPPE eigenvalues and, in addition, physically wrong eigenmodes. It is concluded that the LPPE should be used in place of the PC pressure boundary closure, when BiGlobal or TriGlobal eigenvalue problems are solved in primitive variables by the matrix-forming approach on collocated grids."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Minimal gain marching schemes: searching for unstable steady-states with unsteady solvers
keyword,"['Linear stability analysis\xa0', 'Numerical analysis\xa0', 'Gain reduction\xa0', 'Unstable spectra\xa0', 'Stationary and oscillatory disturbances\xa0', 'Truncation error\xa0']"
history,"['2017-12', '2017-03-07', '2016-02-15', '2017-02-22']"
abstract,"Abstract Reference solutions are important in several applications. They are used as base states in linear stability analyses as well as initial conditions and reference states for sponge zones in numerical simulations, just to name a few examples. Their accuracy is also paramount in both fields, leading to more reliable analyses and efficient simulations, respectively. Hence, steady-states usually make the best reference solutions. Unfortunately, standard marching schemes utilized for accurate unsteady simulations almost never reach steady-states of unstable flows. Steady governing equations could be solved instead, by employing Newton-type methods often coupled with continuation techniques. However, such iterative approaches do require large computational resources and very good initial guesses to converge. These difficulties motivated the development of a technique known as selective frequency damping (SFD) (Åkervik et al. in Phys Fluids 18(6):068102, 2006). It adds a source term to the unsteady governing equations that filters out the unstable frequencies, allowing a steady-state to be reached. This approach does not require a good initial condition and works well for self-excited flows, where a single nonzero excitation frequency is selected by either absolute or global instability mechanisms. On the other hand, it seems unable to damp stationary disturbances. Furthermore, flows with a broad unstable frequency spectrum might require the use of multiple filters, which delays convergence significantly. Both scenarios appear in convectively, absolutely or globally unstable flows. An alternative approach is proposed in the present paper. It modifies the coefficients of a marching scheme in such a way that makes the absolute value of its linear gain smaller than one within the required unstable frequency spectra, allowing the respective disturbance amplitudes to decay given enough time. These ideas are applied here to implicit multi-step schemes. A few chosen test cases shows that they enable convergence toward solutions that are unstable to stationary and oscillatory disturbances, with either a single or multiple frequency content. Finally, comparisons with SFD are also performed, showing significant reduction in computer cost for complex flows by using the implicit multi-step MGM schemes."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Three-dimensional instability analysis of boundary layers perturbed by streamwise vortices
keyword,"['Fluid dynamics\xa0', '3D boundary layer\xa0', 'BREs\xa0', 'Plane marching PSE\xa0', 'Streamwise vortices\xa0', 'Streamwise streaks\xa0']"
history,"['2017-12', '2016-08-02', '2016-02-25', '2016-07-17']"
abstract,"Abstract A parametric study is presented for the incompressible, zero-pressure-gradient flat-plate boundary layer perturbed by streamwise vortices. The vortices are placed near the leading edge and model the vortices induced by miniature vortex generators (MVGs), which consist in a spanwise-periodic array of small winglet pairs. The introduction of MVGs has been experimentally proved to be a successful passive flow control strategy for delaying laminar-turbulent transition caused by Tollmien–Schlichting (TS) waves. The counter-rotating vortex pairs induce non-modal, transient growth that leads to a streaky boundary layer flow. The initial intensity of the vortices and their wall-normal distances to the plate wall are varied with the aim of finding the most effective location for streak generation and the effect on the instability characteristics of the perturbed flow. The study includes the solution of the three-dimensional, stationary, streaky boundary layer flows by using the boundary region equations, and the three-dimensional instability analysis of the resulting basic flows by using the plane-marching parabolized stability equations. Depending on the initial circulation and positioning of the vortices, planar TS waves are stabilized by the presence of the streaks, resulting in a reduction in the region of instability and shrink of the neutral stability curve. For a fixed maximum streak amplitude below the threshold for secondary instability (SI), the most effective wall-normal distance for the formation of the streaks is found to also offer the most stabilization of TS waves. By setting a maximum streak amplitude above the threshold for SI, sinuous shear layer modes become unstable, as well as another instability mode that is amplified in a narrow region near the vortex inlet position."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Cluster-based control of a separating flow over a smoothly contoured ramp
keyword,"['Flow control\xa0', 'Markov model\xa0', 'Cluster analysis\xa0', 'Liouville equation\xa0', 'Flow separation\xa0', 'Feedback control\xa0']"
history,"['2017-12', '2017-01-17', '2016-02-14', '2016-12-21']"
abstract,"Abstract The ability to manipulate and control fluid flows is of great importance in many scientific and engineering applications. The proposed closed-loop control framework addresses a key issue of model-based control: The actuation effect often results from slow dynamics of strongly nonlinear interactions which the flow reveals at timescales much longer than the prediction horizon of any model. Hence, we employ a probabilistic approach based on a cluster-based discretization of the Liouville equation for the evolution of the probability distribution. The proposed methodology frames high-dimensional, nonlinear dynamics into low-dimensional, probabilistic, linear dynamics which considerably simplifies the optimal control problem while preserving nonlinear actuation mechanisms. The data-driven approach builds upon a state space discretization using a clustering algorithm which groups kinematically similar flow states into a low number of clusters. The temporal evolution of the probability distribution on this set of clusters is then described by a control-dependent Markov model. This Markov model can be used as predictor for the ergodic probability distribution for a particular control law. This probability distribution approximates the long-term behavior of the original system on which basis the optimal control law is determined. We examine how the approach can be used to improve the open-loop actuation in a separating flow dominated by Kelvin–Helmholtz shedding. For this purpose, the feature space, in which the model is learned, and the admissible control inputs are tailored to strongly oscillatory flows."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Saddle point of attachment in jet–crossflow interaction
keyword,"['Flow topology\xa0', 'Horseshoe vortex\xa0', 'Jet in crossflow\xa0', 'Juncture flow\xa0', 'Saddle point of attachment\xa0', 'Separation\xa0', 'Degeneration\xa0']"
history,"['2017-08', '2017-03-15', '2016-08-04', '2017-03-06']"
abstract,"Abstract Numerical simulation and theoretical analysis were performed to investigate the upstream topology of a jet–crossflow interaction. The numerical results were validated with mathematical theory as well as a juncture flow structure. The upstream critical point satisfies the condition of occurrence for a saddle point of attachment in the horseshoe vortex system. In addition to the classical topology led by a saddle point of separation, a new topology led by a saddle point of attachment was found for the first time in a jet–crossflow interaction. The degeneration of the critical point from separation to attachment is determined by the velocity ratio of the jet over the crossflow, and the boundary layer thickness of the flat plate. When the boundary layer thickness at the upstream edge of the jet is close to one diameter of the jet, the flow topology is led by a saddle point of attachment. Variation of the velocity ratio does not change the topology but the location of the saddle point. When the boundary layer thickness is less than 0.255 of the jet flow diameter, large velocity ratio can generate a saddle point of attachment without spiral horseshoe vortex; continuously decreasing the velocity ratio will change the flow topology to saddle point of the separation. The degeneration of the critical point from attachment to separation was observed."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Time-dependent modeling of oscillatory instability of three-dimensional natural convection of air in a laterally heated cubic box
keyword,"['Natural convection\xa0', 'Instability\xa0', 'Direct numerical simulation\xa0']"
history,"['2017-08', '2017-04-04', '2016-03-18', '2017-03-22']"
abstract,"Abstract Transition from steady to oscillatory buoyancy convection of air in a laterally heated cubic box is studied numerically by straight-forward time integration of Boussinesq equations using a series of gradually refined finite volume grids. Horizontal and spanwise cube boundaries are assumed to be either perfectly thermally conducting or perfectly thermally insulated, which results in four different sets of thermal boundary conditions. Critical Grashof numbers are obtained by interpolation of numerically extracted growth/decay rates of oscillation amplitude to zero. Slightly supercritical flow regimes are described by time-averaged flows, snapshots, and spatial distribution of the oscillation amplitude. Possible similarities and dissimilarities with two-dimensional instabilities in laterally heated square cavities are discussed. Break of symmetries and sub- or supercritical character of bifurcations are examined. Three consequent transitions from steady to the oscillatory regime, from the oscillatory to the steady regime, and finally to the oscillatory flow, are found in the case of perfectly insulated horizontal and spanwise boundaries. Arguments for grid and time-step independence of the results are given."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,On the odd and even secondary instabilities of Görtler vortices
keyword,"['Görtler vortices\xa0', 'Secondary instabilities\xa0', 'Odd and even mode\xa0', 'Spatial direct numerical simulation\xa0', 'Hydrodynamic instability\xa0']"
history,"['2017-08', '2017-04-03', '2016-10-20', '2017-03-21']"
abstract,"Abstract Boundary layer flows over concave wall can be unstable to disturbances giving rise to streamwise counter-rotating vortices known as Görtler vortices. These vortices in its nonlinear form are responsible for a strong distortion of the streamwise velocity profiles in the wall-normal and spanwise directions. The resulting inflectional velocity profiles are unstable to unsteady disturbances. These disturbances are called secondary instabilities and can develop into horseshoe vortices or a sinuous motion of the Görtler vortices. These types of secondary instabilities are known as even (varicose) and odd (sinuous) modes, respectively. Although many studies focused this subject, it has not been stated which mode dominates the transition process. In the present study the secondary instability of Görtler flow is investigated using high-order spatial numerical simulation. Multi-frequency unsteady disturbances are introduced with the same spanwise wavelength as the Görtler vortices, but different spanwise phases. Three different spanwise phases are used and the effect on the secondary instability is analyzed. Both, even and odd secondary instabilities are observed, according to the relative spanwise position of the unsteady disturbances. The growth analysis for each secondary crossplane instability mode is made using a temporal Fourier analysis and the physics is explored with the aid of the flow structures visualization. The results introducing disturbances that give rise to odd and even modes simultaneously show that, for the spanwise wavelength analyzed, the odd modes grow first and dominate the transition process."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Formation and behavior of counter-rotating vortex rings
keyword,"['Vortex rings\xa0', 'Vortex dynamics\xa0', 'Vortex interactions\xa0']"
history,"['2017-08', '2017-03-02', '2016-04-22', '2017-02-13']"
abstract,"Abstract Concentric, counter-rotating vortex ring formation by transient jet ejection between concentric cylinders was studied numerically to determine the effects of cylinder gap ratio, \(\frac{\Delta R}{R}\), and jet stroke length-to-gap ratio, \(\frac{L}{\Delta R}\), on the evolution of the vorticity and the trajectories of the resulting axisymmetric vortex pair. The flow was simulated at a jet Reynolds number of 1000 (based on \(\Delta R\) and the jet velocity), \(\frac{L}{\Delta R} \) in the range 1–20, and \(\frac{\Delta R}{R}\) in the range 0.05–0.25. Five characteristic flow evolution patterns were observed and classified based on \(\frac{L}{\Delta R} \) and \(\frac{\Delta R}{R}\). The results showed that the relative position, relative strength, and radii of the vortex rings during and soon after formation played a prominent role in the evolution of the trajectories of their vorticity centroids at the later time. The conditions on relative strength of the vortices necessary for them to travel together as a pair following formation were studied, and factors affecting differences in vortex circulation following formation were investigated. In addition to the characteristics of the primary vortices, the stopping vortices had a strong influence on the initial vortex configuration and effected the long-time flow evolution at low \(\frac{L}{\Delta R}\) and small \(\frac{\Delta R}{R}\). For long \(\frac{L}{\Delta R} \) and small \(\frac{\Delta R}{R}\), shedding of vorticity was sometimes observed and this shedding was related to the Kelvin–Benjamin variational principle of maximal energy for steadily translating vortex rings."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,De-biasing the dynamic mode decomposition for applied Koopman spectral analysis of noisy datasets
keyword,"['Data-driven dynamical systems\xa0', 'Koopman spectral analysis\xa0', 'Total least-squares\xa0', 'Sensor noise\xa0', 'Reduced-order model\xa0', 'Experimental fluid mechanics\xa0']"
history,"['2017-08', '2017-04-17', '2015-10-17', '2017-04-05']"
abstract,"Abstract The dynamic mode decomposition (DMD)—a popular method for performing data-driven Koopman spectral analysis—has gained increased popularity for extracting dynamically meaningful spatiotemporal descriptions of fluid flows from snapshot measurements. Often times, DMD descriptions can be used for predictive purposes as well, which enables informed decision-making based on DMD model forecasts. Despite its widespread use and utility, DMD can fail to yield accurate dynamical descriptions when the measured snapshot data are imprecise due to, e.g., sensor noise. Here, we express DMD as a two-stage algorithm in order to isolate a source of systematic error. We show that DMD’s first stage, a subspace projection step, systematically introduces bias errors by processing snapshots asymmetrically. To remove this systematic error, we propose utilizing an augmented snapshot matrix in a subspace projection step, as in problems of total least-squares, in order to account for the error present in all snapshots. The resulting unbiased and noise-aware total DMD (TDMD) formulation reduces to standard DMD in the absence of snapshot errors, while the two-stage perspective generalizes the de-biasing framework to other related methods as well. TDMD’s performance is demonstrated in numerical and experimental fluids examples. In particular, in the analysis of time-resolved particle image velocimetry data for a separated flow, TDMD outperforms standard DMD by providing dynamical interpretations that are consistent with alternative analysis techniques. Further, TDMD extracts modes that reveal detailed spatial structures missed by standard DMD."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Particle–boundary interaction in a shear-driven cavity flow
keyword,"['Particle–boundary interaction\xa0', 'Shear stress\xa0', 'Fully resolved simulation\xa0', 'DG-FEM\xa0', 'SPM\xa0', 'Particle accumulation\xa0', 'Limit cycle\xa0']"
history,"['2017-08', '2017-04-04', '2016-08-05', '2017-03-21']"
abstract,"Abstract The motion of a heavy finite-size tracer is numerically calculated in a two-dimensional shear-driven cavity. The particle motion is computed using a discontinuous Galerkin-finite-element method combined with a smoothed profile method resolving all scales, including the flow in the lubrication gap between the particle and the boundary. The centrifugation of heavy particles in the recirculating flow is counteracted by a repulsion from the shear-stress surface. The resulting limit cycle for the particle motion represents an attractor for particles in dilute suspensions. The limit cycles obtained by fully resolved simulations as a function of the particle size and density are compared with those obtained by one-way coupling using the Maxey–Riley equation and an inelastic collision model for the particle–boundary interaction, solely characterized by an interaction-length parameter. It is shown that the one-way coupling approach can faithfully approximate the true limit cycle if the interaction length is selected depending on the particle size and its relative density."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,On the stability of natural convection in a porous vertical slab saturated with an Oldroyd-B fluid
keyword,"['Natural convection\xa0', 'Vertical porous layer\xa0', 'Oldroyd-B fluid\xa0', 'Viscoelastic fluid\xa0']"
history,"['2017-06', '2016-11-10', '2016-04-16', '2016-11-01']"
abstract,"Abstract The stability of the conduction regime of natural convection in a porous vertical slab saturated with an Oldroyd-B fluid has been studied. A modified Darcy’s law is utilized to describe the flow in a porous medium. The eigenvalue problem is solved using Chebyshev collocation method and the critical Darcy–Rayleigh number with respect to the wave number is extracted for different values of physical parameters. Despite the basic state being the same for Newtonian and Oldroyd-B fluids, it is observed that the basic flow is unstable for viscoelastic fluids—a result of contrast compared to Newtonian as well as for power-law fluids. It is found that the viscoelasticity parameters exhibit both stabilizing and destabilizing influence on the system. Increase in the value of strain retardation parameter \(\Lambda _2 \) portrays stabilizing influence on the system while increasing stress relaxation parameter \(\Lambda _1\) displays an opposite trend. Also, the effect of increasing ratio of heat capacities is to delay the onset of instability. The results for Maxwell fluid obtained as a particular case from the present study indicate that the system is more unstable compared to Oldroyd-B fluid."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Numerical modeling of the impact pressure in a compressible liquid medium: application to the slap phase of the locomotion of a basilisk lizard
keyword,"['Weakly compressible\xa0', 'Navier–Stokes\xa0', 'Acoustic wave\xa0', 'Impact pressure\xa0']"
history,"['2017-06', '2017-02-06', '2016-07-12', '2017-01-23']"
abstract,"Abstract The forces acting on a solid body just at the time of impact on the surface of a medium with very low compressibility, such as water, can be quantified at acoustic time scales. This is necessary in wide range of applications varying from large-scale ship designs to the walking or running mechanisms of small creatures such as the basilisk lizard. In order to characterize such forces, a numerical model is developed in this study and is validated using analytical expressions of pressure as a function of the speed of sound-wave propagation in water. The computational results not only accurately match the analytical values but are also able to effectively capture the propagation of acoustic waves in water. The model is further applied to a case study wherein the impact impulse required by the basilisk lizard to assist in its walking on the water surface is evaluated. The numerical results are found to be in agreement with the closest available experimental data. The model and approach are thus proposed to evaluate impact forces for wide range of applications."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Use of natural instabilities for generation of streamwise vortices in a laminar channel flow
keyword,"['Vortex instability\xa0', 'Viscosity-driven instability\xa0', 'Mixing enhancement\xa0', 'Transverse grooves\xa0', 'Laminar channel flow\xa0']"
history,"['2017-06', '2016-12-19', '2016-06-26', '2016-12-01']"
abstract,"Abstract An analysis of pressure-gradient-driven flows in channels with walls modified by transverse ribs has been carried out. The ribs have been introduced intentionally in order to generate streamwise vortices through centrifugally driven instabilities. The cost of their introduction, i.e. the additional pressure losses, have been determined. Linear stability theory has been used to determine conditions required for the formation of the vortices. It has been demonstrated that there exists a finite range of rib wave numbers capable of creating vortices. Within this range, there exists an optimal wave number which results in the minimum critical Reynolds number for the specified rib amplitude. The optimal wave numbers marginally depend on the rib positions and amplitudes. As the formation of the vortices can be interfered with by viscosity-driven instabilities, the critical conditions for the onset of such instabilities have also been determined. The rib geometries which result in the vortex formation with the smallest drag penalty and without interference from the viscosity-driven instabilities have been identified."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Optimally growing boundary layer disturbances in a convergent nozzle preceded by a circular pipe
keyword,"['Boundary layers\xa0', 'Turbulence\xa0', 'Hydrodynamic stability\xa0', 'Parabolized stability equations\xa0']"
history,"['2017-06', '2017-03-01', '2016-05-07', '2017-02-09']"
abstract,"Abstract We report the findings from a theoretical analysis of optimally growing disturbances in an initially turbulent boundary layer. The motivation behind this study originates from the desire to generate organized structures in an initially turbulent boundary layer via excitation by disturbances that are tailored to be preferentially amplified. Such optimally growing disturbances are of interest for implementation in an active flow control strategy that is investigated for effective jet noise control. Details of the optimal perturbation theory implemented in this study are discussed. The relevant stability equations are derived using both the standard decomposition and the triple decomposition. The chosen test case geometry contains a convergent nozzle, which generates a Mach 0.9 round jet, preceded by a circular pipe. Optimally growing disturbances are introduced at various stations within the circular pipe section to facilitate disturbance energy amplification upstream of the favorable pressure gradient zone within the convergent nozzle, which has a stabilizing effect on disturbance growth. Effects of temporal frequency, disturbance input and output plane locations as well as separation distance between output and input planes are investigated. The results indicate that optimally growing disturbances appear in the form of longitudinal counter-rotating vortex pairs, whose size can be on the order of several times the input plane mean boundary layer thickness. The azimuthal wavenumber, which represents the number of counter-rotating vortex pairs, is found to generally decrease with increasing separation distance. Compared to the standard decomposition, the triple decomposition analysis generally predicts relatively lower azimuthal wavenumbers and significantly reduced energy amplification ratios for the optimal disturbances."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Influence of hydrodynamic slip on convective transport in flow past a circular cylinder
keyword,"['Bluff body flows\xa0', 'Convective transport\xa0', 'Hydrodynamic slip\xa0']"
history,"['2017-06', '2017-02-01', '2016-04-24', '2017-01-10']"
abstract,"Abstract The presence of a finite tangential velocity on a hydrodynamically slipping surface is known to reduce vorticity production in bluff body flows substantially while at the same time enhancing its convection downstream and into the wake. Here, we investigate the effect of hydrodynamic slippage on the convective heat transfer (scalar transport) from a heated isothermal circular cylinder placed in a uniform cross-flow of an incompressible fluid through analytical and simulation techniques. At low Reynolds (\({\textit{Re}}\ll 1\)) and high Péclet (\({\textit{Pe}}\gg 1\)) numbers, our theoretical analysis based on Oseen and thermal boundary layer equations allows for an explicit determination of the dependence of the thermal transport on the non-dimensional slip length \(l_s\). In this case, the surface-averaged Nusselt number, Nu transitions gradually between the asymptotic limits of \(Nu \sim {\textit{Pe}}^{1/3}\) and \(Nu \sim {\textit{Pe}}^{1/2}\) for no-slip (\(l_s \rightarrow 0\)) and shear-free (\(l_s \rightarrow \infty \)) boundaries, respectively. Boundary layer analysis also shows that the scaling \(Nu \sim {\textit{Pe}}^{1/2}\) holds for a shear-free cylinder surface in the asymptotic limit of \({\textit{Re}}\gg 1\) so that the corresponding heat transfer rate becomes independent of the fluid viscosity. At finite \({\textit{Re}}\), results from our two-dimensional simulations confirm the scaling \(Nu \sim {\textit{Pe}}^{1/2}\) for a shear-free boundary over the range \(0.1 \le {\textit{Re}}\le 10^3\) and \(0.1\le {\textit{Pr}}\le 10\). A gradual transition from the lower asymptotic limit corresponding to a no-slip surface, to the upper limit for a shear-free boundary, with \(l_s\), is observed in both the maximum slip velocity and the Nu. The local time-averaged Nusselt number \(Nu_{\theta }\) for a shear-free surface exceeds the one for a no-slip surface all along the cylinder boundary except over the downstream portion where unsteady separation and flow reversal lead to an appreciable rise in the local heat transfer rates, especially at high \({\textit{Re}}\) and Pr. At a Reynolds number of \(10^3\), the formation of secondary recirculating eddy pairs results in appearance of additional local maxima in \(Nu_{\theta }\) at locations that are in close proximity to the mean secondary stagnation points. As a consequence, Nu exhibits a non-monotonic variation with \(l_s\) increasing initially from its lowermost value for a no-slip surface and then decreasing before rising gradually toward the upper asymptotic limit for a shear-free cylinder. A non-monotonic dependence of the spanwise-averaged Nu on \(l_s\) is observed in three dimensions as well with the three-dimensional wake instabilities that appear at sufficiently low \(l_s\), strongly influencing the convective thermal transport from the cylinder. The analogy between heat transfer and single-component mass transfer implies that our results can directly be applied to determine the dependency of convective mass transfer of a single solute on hydrodynamic slip length in similar configurations through straightforward replacement of Nu and \({\textit{Pr}}\) with Sherwood and Schmidt numbers, respectively."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Identification of flow regimes around two staggered square cylinders by a numerical study
keyword,"['Staggered square cylinders\xa0', 'Vortex shedding\xa0', 'Flow regimes\xa0', 'Numerical simulation\xa0', 'Low Reynolds number\xa0']"
history,"['2017-06', '2017-02-27', '2016-01-23', '2017-02-13']"
abstract,"Abstract The flow over two square cylinders in staggered arrangement is simulated numerically at a fixed Reynolds number (\(Re =150\)) for different gap spacing between cylinders from 0.1 to 6 times a cylinder side to understand the flow structures. The non-inclined square cylinders are located on a line with a staggered angle of \(45^{\circ }\) to the oncoming velocity vector. All numerical simulations are carried out with a finite-volume code based on a collocated grid arrangement. The effects of vortex shedding on the various features of the flow field are numerically visualized using different flow contours such as \(\lambda _{2}\) criterion, vorticity, pressure and magnitudes of velocity to distinguish the distinctive flow patterns. By changing the gap spacing between cylinders, five different flow regimes are identified and classified as single body, periodic gap flow, aperiodic, modulated periodic and synchronized vortex shedding regimes. This study revealed that the observed multiple frequencies in global forces of the downstream cylinder in the modulated periodic regime are more properly associated with differences in vortex shedding frequencies of individual cylinders than individual shear layers reported in some previous works; particularly, both shear layers from the downstream cylinder often shed vortices at the same multiple frequencies. The maximum Strouhal number for the upstream cylinder is also identified at \({G}^{*}=1\) for aperiodic flow pattern. Furthermore, for most cases studied, the downstream cylinder experiences larger drag force than the upstream cylinder."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Influence of molecular diffusion on alignment of vector fields: Eulerian analysis
keyword,"['Passive vector\xa0', 'Scalar gradient\xa0', 'Molecular diffusion\xa0', 'Alignment properties\xa0']"
history,"['2017-04', '2016-11-25', '2016-05-24', '2016-11-18']"
abstract,"Abstract The effect of diffusive processes on the structure of passive vector and scalar gradient fields is investigated by analyzing the corresponding terms in the orientation and norm equations. Numerical simulation is used to solve the transport equations for both vectors in a two-dimensional, parameterized model flow. The study highlights the role of molecular diffusion in the vector orientation process and shows its subsequent action on the geometric features of vector fields."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Ground effects on separated laminar flows past an inclined flat plate
keyword,"['Flow separation\xa0', 'Surface shear stress\xa0', 'Wake\xa0', 'Vortex shedding\xa0']"
history,"['2017-04', '2016-10-17', '2016-02-02', '2016-09-30']"
abstract,"Abstract The appearance of a ground surface can play an important role in the flow structures for the flows past a flat plate. We conduct two-dimensional numerical simulations on viscous flows past a flat plate inclined at an angle of attack of \(20^\circ \) with ground effects using a finite-volume method. Results  show that the effects on the separated flow from the ground are highly dependent on the gap (G) between the plate and the ground. As the gap decreases, the strength of vortices generated from the trailing edge is restrained, which is consistent with experimental observations. Further decrease in the gap even eliminates the vortex shedding and yields a steady flow. It is also found that the flow between the gap can either be accelerated at large gap ratios (\({G/L >1}\), G is the gap, L is the plate length), or be decelerated at small gap ratios (\({G/L <1}\)). Furthermore, the numerical results show that the wake flow behind the plate can significantly change the distribution of surface shear stress on the ground. Specifically, the mean shear stress on the ground in the downstream region at a gap ratio \(G/L = 2.0\) is one order of magnitude larger than that at a small gap ratio \(G/L = 0.3\), and the length of the downstream region where the shear stress can be effectively changed is much larger than the plate length, which provides a guideline to manipulate the ground wall surface shear stress using an inclined plate in the vicinity of the wall."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Effective slip for flow through a channel bounded by lubricant-impregnated grooved surfaces
keyword,"['Lubricant-impregnated surface\xa0', 'Effective slip\xa0', 'Eigenfunction expansion\xa0', 'Front tracking method\xa0']"
history,"['2017-04', '2016-11-07', '2016-02-26', '2016-10-26']"
abstract,"Abstract This study aims to investigate effective slip arising from pressure-driven flow through a slit channel bounded by lubricant-impregnated grooved surfaces. The problem for flow over longitudinal grooves is solved analytically using the methods of domain decomposition and eigenfunction expansion, while that for flow over transverse grooves is solved numerically using the front tracking method. It is found that the effective slip length and the lubricant flow rate can depend strongly on the geometry of the microstructure, the direction of flow, and the lubricant viscosity. In particular, the effective slip can be effectively enhanced by increasing the thickness of a lubricating film atop the ribs. Under the same conditions, a flow that is parallel to the lubricant-impregnated grooves will have a larger effective slip, but also a larger lubricant flow rate, when compared with the case of flow normal to the grooves. It is also shown that, in the case of transverse grooves, because of the downward displacement of the interface between the working/lubricating fluids, the effective slip length and lubricant flow rate may vary non-monotonically with the groove depth."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,"Numerical investigation of mixed convection heat transfer from two isothermal circular cylinders in tandem arrangement: buoyancy, spacing ratio, and confinement effects"
keyword,"['Mixed convection\xa0', 'Tandem cylinders\xa0', 'Blockage ratio\xa0', 'Interference effects\xa0', 'Bimodal vortex shedding\xa0']"
history,"['2017-04', '2016-11-05', '2016-04-12', '2016-10-07']"
abstract,"Abstract This paper presents a two-dimensional numerical study for mixed convection in a laminar cross-flow with a pair of stationary equal-sized isothermal cylinders in tandem arrangement confined in a channel. The governing equations are solved using the control volume method on a nonuniform orthogonal Cartesian grid, and the immersed boundary method is employed to identify the cylinders placed in the flow field. The numerical scheme is first validated against standard cases of symmetrically confined isothermal circular cylinders in plane channels, and grid convergence tests were also examined. The objective of the present study was to investigate the influence of buoyancy and the blockage ratio constraint on the flow and heat transfer characteristics of the immersed cylinder array. Using a fixed Reynolds number based on cylinder diameter of \(Re_{D} = 200\), a fixed value of the Prandtl number of \(Pr = 7\), and a blockage ratio of \(D/H = 0.2\), all possible flow regimes are considered by setting the longitudinal spacing ratio (\(\sigma = L/D\)) between the cylinder axes to 2, 3, and 5 for values of the buoyancy parameter (Richardson number) in the range \(-1\le Ri\le 4\). The interference effects and complex flow features are presented in the form of mean and instantaneous velocity, vorticity, and temperature distributions. The results demonstrate how the buoyancy, spacing ratio, and wall confinement affect the wake structure and vortex dynamics. In addition, local and average heat transfer characteristics of both cylinders are comprehensively presented for a wide range in the parametric space."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,On the need of mode interpolation for data-driven Galerkin models of a transient flow around a sphere
keyword,"['Reduced-order modeling (ROM)\xa0', 'Galerkin projection\xa0', 'Dynamic mode decomposition (DMD)\xa0', 'Continuous mode interpolation\xa0', 'CFD\xa0']"
history,"['2017-04', '2016-09-12', '2016-01-23', '2016-08-31']"
abstract,"Abstract We present a low-dimensional Galerkin model with state-dependent modes capturing linear and nonlinear dynamics. Departure point is a direct numerical simulation of the three-dimensional incompressible flow around a sphere at Reynolds numbers 400. This solution starts near the unstable steady Navier–Stokes solution and converges to a periodic limit cycle. The investigated Galerkin models are based on the dynamic mode decomposition (DMD) and derive the dynamical system from first principles, the Navier–Stokes equations. A DMD model with training data from the initial linear transient fails to predict the limit cycle. Conversely, a model from limit-cycle data underpredicts the initial growth rate roughly by a factor 5. Key enablers for uniform accuracy throughout the transient are a continuous mode interpolation between both oscillatory fluctuations and the addition of a shift mode. This interpolated model is shown to capture both the transient growth of the oscillation and the limit cycle."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Rigorous theory for transient capillary imbibition in channels of arbitrary cross section
keyword,"['Time-dependent fluid penetration\xa0', 'Capillary action\xa0', 'Unsteady channel flow\xa0', 'Transient velocity profile\xa0', 'Eigenfunction expansion\xa0']"
history,"['2017-04', '2016-10-31', '2015-12-23', '2016-09-30']"
abstract,"Abstract This article addresses a classical fluid mechanics problem where the effect of capillary action on a column of viscous liquid is analyzed by quantifying its time-dependent penetrated length in a narrow channel. Despite several past studies, a rigorous mathematical formulation of this inherently unsteady process is still unavailable, because these existing works resort to a crucial assumption only valid for mildly transient systems. The approximate theories use an integral approach where the penetration is described by equating total force acting on the domain to rate of change of total momentum. However, while doing so, the viscous resistance under temporally varying condition is assumed to be same as the resistance created by a quasi-steady velocity profile. Thus, leading order error appears due to such approximation which can only be true when the variation in time is not strong enough causing negligible transient deviation in the hydrodynamic quantities. The present paper proposes a new way to solve this problem by considering the unsteady field itself as an unknown variable. Accordingly, the analysis applies an eigenfunction expansion of the flow with unknown time-dependent amplitudes which along with the unsteady intrusion length are calculated from a system of ordinary differential equations. A comparative exploration identifies the situation for which the integral approach and the rigorous technique based on eigenfunction expansion deviate from each other. It also reveals that the two methods differ substantially in short-time dynamics at the initial stage. Then, an asymptotic perturbation shows how the two sets of results should coincide in their long-time behavior. In this way, the findings will provide a comprehensive understanding of the physics behind the transport phenomenon."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A zonally symmetric model for the monsoon-Hadley circulation with stochastic convective forcing
keyword,"['Climate science\xa0', 'Reduced models\xa0', 'Monsoon\xa0', 'Hyperbolic equations\xa0', 'Numerical methods stochastic convection\xa0', 'Hadley circulation\xa0', '35L02\xa0', '65C20\xa0', '65C35\xa0', '65M08\xa0', '65M30\xa0', '65Z99\xa0', '86A10\xa0']"
history,"['2017-02', '2016-09-09', '2016-05-16', '2016-08-19']"
abstract,"Abstract Idealized models of reduced complexity are important tools to understand key processes underlying a complex system. In climate science in particular, they are important for helping the community improve our ability to predict the effect of climate change on the earth system. Climate models are large computer codes based on the discretization of the fluid dynamics equations on grids of horizontal resolution in the order of 100 km, whereas unresolved processes are handled by subgrid models. For instance, simple models are routinely used to help understand the interactions between small-scale processes due to atmospheric moist convection and large-scale circulation patterns. Here, a zonally symmetric model for the monsoon circulation is presented and solved numerically. The model is based on the Galerkin projection of the primitive equations of atmospheric synoptic dynamics onto the first modes of vertical structure to represent free tropospheric circulation and is coupled to a bulk atmospheric boundary layer (ABL) model. The model carries bulk equations for water vapor in both the free troposphere and the ABL, while the processes of convection and precipitation are represented through a stochastic model for clouds. The model equations are coupled through advective nonlinearities, and the resulting system is not conservative and not necessarily hyperbolic. This makes the design of a numerical method for the solution of this system particularly difficult. Here, we develop a numerical scheme based on the operator time-splitting strategy, which decomposes the system into three pieces: a conservative part and two purely advective parts, each of which is solved iteratively using an appropriate method. The conservative system is solved via a central scheme, which does not require hyperbolicity since it avoids the Riemann problem by design. One of the advective parts is a hyperbolic diagonal matrix, which is easily handled by classical methods for hyperbolic equations, while the other advective part is a nilpotent matrix, which is solved via the method of lines. Validation tests using a synthetic exact solution are presented, and formal second-order convergence under grid refinement is demonstrated. Moreover, the model is tested under realistic monsoon conditions, and the ability of the model to simulate key features of the monsoon circulation is illustrated in two distinct parameter regimes."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A numerical investigation into the effects of Reynolds number on the flow mechanism induced by a tubercled leading edge
keyword,"['Passive flow control\xa0', 'Leading-edge tubercles\xa0', 'Turbulent regime\xa0', 'Tubercles\xa0']"
history,"['2017-02', '2016-05-09', '2015-08-25', '2016-04-14']"
abstract,"Abstract Leading-edge modifications based on designs inspired by the protrusions on the pectoral flippers of the humpback whale (tubercles) have been the subject of research for the past decade primarily due to their flow control potential in ameliorating stall characteristics. Previous studies have demonstrated that, in the transitional flow regime, full-span wings with tubercled leading edges outperform unmodified wings at high attack angles. The flow mechanism associated with such enhanced loading traits is, however, still being investigated. Also, the performance of full-span tubercled wings in the turbulent regime is largely unexplored. The present study aims to investigate Reynolds number effects on the flow mechanism induced by a full-span tubercled wing with the NACA-0021 cross-sectional profile in the transitional and near-turbulent regimes using computational fluid dynamics. The analysis of the flow field suggests that, with the exception of a few different flow features, the same underlying flow mechanism, involving the presence of transverse and streamwise vorticity, is at play in both cases. With regard to lift-generation characteristics, the numerical simulation results indicate that in contrast to the transitional flow regime, where the unmodified NACA-0021 undergoes a sudden loss of lift, in the turbulent regime, the baseline foil experiences gradual stall and produces more lift than the tubercled foil. This observation highlights the importance of considerations regarding the Reynolds number effects and the stall characteristics of the baseline foil, in the industrial applications of tubercled lifting bodies."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Stability and modal analysis of shock/boundary layer interactions
keyword,"['Shock/boundary layer interactions\xa0', 'Global stability analysis\xa0', 'Dynamic mode decomposition\xa0']"
history,"['2017-02', '2016-06-02', '2015-11-23', '2016-05-16']"
abstract,"Abstract The dynamics of oblique shock wave/turbulent boundary layer interactions is analyzed by mining a large-eddy simulation (LES) database for various strengths of the incoming shock. The flow dynamics is first analyzed by means of dynamic mode decomposition (DMD), which highlights the simultaneous occurrence of two types of flow modes, namely a low-frequency type associated with breathing motion of the separation bubble, accompanied by flapping motion of the reflected shock, and a high-frequency type associated with the propagation of instability waves past the interaction zone. Global linear stability analysis performed on the mean LES flow fields yields a single unstable zero-frequency mode, plus a variety of marginally stable low-frequency modes whose stability margin decreases with the strength of the interaction. The least stable linear modes are grouped into two classes, one of which bears striking resemblance to the breathing mode recovered from DMD and another class associated with revolving motion within the separation bubble. The results of the modal and linear stability analysis support the notion that low-frequency dynamics is intrinsic to the interaction zone, but some continuous forcing from the upstream boundary layer may be required to keep the system near a limit cycle. This can be modeled as a weakly damped oscillator with forcing, as in the early empirical model by Plotkin (AIAA J 13:1036–1040, 1975)."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Excitation of unsteady Görtler vortices by localized surface nonuniformities
keyword,"['Boundary layer\xa0', 'Görtler vortices\xa0', 'Surface roughness\xa0', 'Surface vibrations\xa0', 'Receptivity\xa0', 'Instability\xa0', 'Optimal disturbances\xa0', 'Local modes\xa0']"
history,"['2017-02', '2016-08-25', '2015-04-28', '2016-08-05']"
abstract,"Abstract A combined theoretical and numerical analysis of an experiment devoted to the excitation of Görtler vortices by localized stationary or vibrating surface nonuniformities in a boundary layer over a concave surface is performed. A numerical model of generation of small-amplitude disturbances and their downstream propagation based on parabolic equations is developed. In the framework of this model, the optimal and the modal parts of excited disturbance are defined as solutions of initial-value problems with initial values being, respectively, the optimal disturbance and the leading local mode at the location of the source. It is shown that a representation of excited disturbance as a sum of the optimal part and a remainder makes it possible to describe its generation and downstream propagation, as well as to predict satisfactorily the corresponding receptivity coefficient. In contrast, the representation based on the modal part provides only coarse information about excitation and propagation of disturbance in the range of parameters under investigation. However, it is found that the receptivity coefficients estimated using the modal parts can be reinterpreted to preserve their practical significance. A corresponding procedure was developed. The theoretical and experimental receptivity coefficients are estimated and compared. It is found that the receptivity magnitudes grow significantly with the disturbance frequency. Variation of the span-wise scale of the nonuniformities affects weakly the receptivity characteristics at zero frequency. However, at high frequencies, the efficiency of excitation of Görtler vortices depends substantially on the span-wise scale."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,"Model of non-stationary, inhomogeneous turbulence"
keyword,"['Turbulence modeling\xa0', 'Inhomogeneous turbulence\xa0', 'Two-point modeling\xa0', 'Turbulent mixing\xa0', 'Non-stationary turbulence\xa0']"
history,"['2017-02', '2016-07-08', '2015-12-08', '2016-06-21']"
abstract,"Abstract We compare results from a spectral model for non-stationary, inhomogeneous turbulence (Besnard et al. in Theor Comp Fluid Dyn 8:1–35, 1996) with direct numerical simulation (DNS) data of a shear-free mixing layer (SFML) (Tordella et al. in Phys Rev E 77:016309, 2008). The SFML is used as a test case in which the efficacy of the model closure for the physical-space transport of the fluid velocity field can be tested in a flow with inhomogeneity, without the additional complexity of mean-flow coupling. The model is able to capture certain features of the SFML quite well for intermediate to long times, including the evolution of the mixing-layer width and turbulent kinetic energy. At short-times, and for more sensitive statistics such as the generation of the velocity field anisotropy, the model is less accurate. We propose two possible causes for the discrepancies. The first is the local approximation to the pressure-transport and the second is the a priori spherical averaging used to reduce the dimensionality of the solution space of the model, from wavevector to wavenumber space. DNS data are then used to gauge the relative importance of both possible deficiencies in the model."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Wall-modeled large eddy simulation of turbulent channel flow at high Reynolds number using the von Karman length scale
keyword,"['Turbulence model\xa0', 'The von Karman length scale\xa0', 'Wall-modeled large eddy simulation\xa0', 'Channel flow\xa0', 'Scale-adaptive simulation\xa0']"
history,"['2016-12', '2016-06-24', '2015-10-26', '2016-06-14']"
abstract,"Abstract The von Karman length scale is able to reflect the size of the local turbulence structure. However, it is not suitable for the near wall region of wall-bounded flows, for its value is almost infinite there. In the present study, a simple and novel length scale combining the wall distance and the von Karman length scale is proposed by introducing a structural function. The new length scale becomes the von Karman length scale once local unsteady structures are detected. The proposed method is adopted in a series of turbulent channel flows at different Reynolds numbers. The results show that the proposed length scale with the structural function can precisely simulate turbulence at high Reynolds numbers, even with a coarse grid resolution."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Drift due to two obstacles in different arrangements
keyword,"['Drift\xa0', 'Wakes\xa0', 'Complex function theory\xa0']"
history,"['2016-12', '2016-05-06', '2015-11-21', '2016-04-14']"
abstract,"Abstract We study the drift induced by the passage of two cylinders through an unbounded extent of inviscid incompressible fluid under the assumption that the flow is two dimensional and steady in the moving frame of reference. The goal is to assess how the resulting total particle drift depends on the parameters of the geometric configuration, namely the distance between the cylinders and their angle with respect to the direction of translation. This problem is studied by numerically computing, for different cylinder configurations, the trajectories of particles starting at various initial locations. The velocity field used in these computations is expressed in closed form using methods of the complex function theory, and the accuracy of calculations is carefully verified. We identify cylinder configurations which result in increased and decreased drift with respect to the reference case when the two cylinders are separated by an infinite distance. Particle trajectories shed additional light on the hydrodynamic interactions between the cylinders in configurations resulting in different drift values. This ensemble of results provides insights about the accuracy of models used to study biogenic transport."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Heat transfer enhancement of PCM melting in 2D horizontal elliptical tube using metallic porous matrix
keyword,"['Phase change\xa0', 'Lattice Boltzmann method\xa0', 'Porosity\xa0', 'Enthalpy\xa0', 'Elliptical cylinder\xa0']"
history,"['2016-12', '2016-07-12', '2016-01-06', '2016-06-29']"
abstract,"Abstract In this study, the melting process of ice as a phase-change material (PCM) saturated with a nickel–steel porous matrix inside a horizontal elliptical tube is investigated. Due to the low thermal conductivity of the PCM, it is motivated to augment the heat transfer performance of the system simultaneously by finding an optimum value of the aspect ratio and impregnating a metallic porous matrix into the base PCM. The lattice Boltzmann method with a double distribution function formulated based on the enthalpy method, is applied at the representative elementary volume scale under the local thermal equilibrium assumption between the PCM and porous matrix in the composite. While reducing or increasing the aspect ratio of the circular tubes leads to the expedited melting, the 90\(^{\circ }\) inclination of each elliptical tube in the case of the pure PCM melting does not affect the melting rate. With the reduction in the porosity, the effective thermal conductivity and melting rate in all tubes promoted. Although the natural convection is fully suppressed due to the significant flow blockage in the porous structure, the melting rates are generally increased in all cases."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,On the origins of vortex shedding in two-dimensional incompressible flows
keyword,"['Vortex splitting\xa0', 'Vortex shedding\xa0', 'Vortex shedding mechanism\xa0', 'Von Kármán vortex street\xa0']"
history,"['2016-12', '2016-04-26', '2015-04-30', '2016-04-14']"
abstract,"Abstract An exegesis of a novel mechanism leading to vortex splitting and subsequent shedding that is valid for two-dimensional incompressible, inviscid or viscous, and external or internal or wall-bounded flows, is detailed in this research. The mechanism, termed the vortex shedding mechanism (VSM) is simple and intuitive, requiring only two coincident conditions in the flow: (1) the existence of a location with zero momentum and (2) the presence of a net force having a positive divergence. Numerical solutions of several model problems illustrate causality of the VSM. Moreover, the VSM criteria is proved to be a necessary and sufficient condition for a vortex splitting event in any two-dimensional, incompressible flow. The VSM is shown to exist in several canonical problems including the external flow past a circular cylinder. Suppression of the von Kármán vortex street is demonstrated for Reynolds numbers of 100 and 400 by mitigating the VSM."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A statistical learning strategy for closed-loop control of fluid flows
keyword,"['Closed-loop control\xa0', 'Reinforcement learning\xa0', 'Machine learning\xa0']"
history,"['2016-12', '2016-04-21', '2015-06-11', '2016-03-31']"
abstract,"Abstract This work discusses a closed-loop control strategy for complex systems utilizing scarce and streaming data. A discrete embedding space is first built using hash functions applied to the sensor measurements from which a Markov process model is derived, approximating the complex system’s dynamics. A control strategy is then learned using reinforcement learning once rewards relevant with respect to the control objective are identified. This method is designed for experimental configurations, requiring no computations nor prior knowledge of the system, and enjoys intrinsic robustness. It is illustrated on two systems: the control of the transitions of a Lorenz’63 dynamical system, and the control of the drag of a cylinder flow. The method is shown to perform well."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Study of effect of a smooth hump on hypersonic boundary layer instability
keyword,"['Hypersonic\xa0', 'Boundary layer\xa0', 'Instability\xa0', 'Transition\xa0', 'Parabolized stability equations\xa0', 'Roughness Element\xa0']"
history,"['2016-12', '2016-05-27', '2015-08-14', '2016-05-05']"
abstract,"Abstract Effect of a two-dimensional smooth hump on linear instability of hypersonic boundary layer is studied by using parabolized stability equations. Linear evolution of mode S over a hump is analyzed for Mach 4.5 and 5.92 flat plate and Mach 7.1 sharp cone boundary layers. Mean flow for stability analysis is obtained by solving the parabolized Navier–Stokes equations. Hump with height smaller than local boundary layer thickness is considered. The case of flat plate and sharp cone without the hump are also studied to provide comparable data. For flat plate boundary layers, destabilization and stabilization effect is confirmed for hump located at upstream and downstream of synchronization point, respectively. Results  of parametric studies to examine the effect of hump height, location, etc., are also given. For sharp cone boundary layer, stabilization influence of hump is also identified for a specific range of frequency. Stabilization influence of hump on convective instability of mode S is found to be a possible cause of previous experimental observations of delaying transition in hypersonic boundary layers."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Computational analysis of vertical axis wind turbine arrays
keyword,"['Vertical axis wind turbines\xa0', 'Wind farms\xa0', 'Wake interactions\xa0']"
history,"['2016-10', '2016-03-15', '2015-09-11', '2016-02-14']"
abstract,"Abstract Canonical problems involving single, pairs, and arrays of vertical axis wind turbines (VAWTs) are investigated numerically with the objective of understanding the underlying flow structures and their implications on energy production. Experimental studies by Dabiri (J Renew Sustain Energy 3, 2011) suggest that VAWTs demand less stringent spacing requirements than their horizontal axis counterparts and additional benefits may be obtained by optimizing the placement and rotational direction of VAWTs. The flowfield of pairs of co-/counter-rotating VAWTs shows some similarities with pairs of cylinders in terms of wake structure and vortex shedding. When multiple VAWTs are placed in a column, the extent of the wake is seen to spread further downstream, irrespective of the direction of rotation of individual turbines. However, the aerodynamic interference between turbines gives rise to regions of excess momentum between the turbines which lead to significant power augmentations. Studies of VAWTs arranged in multiple columns show that the downstream columns can actually be more efficient than the leading column, a proposition that could lead to radical improvements in wind farm productivity."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Bifurcations of a creeping air–water flow in a conical container
keyword,"['Vortex breakdown\xa0', 'Rotating flow\xa0', 'Creeping flow\xa0', 'Bioreactors\xa0', 'Flow topology\xa0']"
history,"['2016-10', '2016-04-20', '2015-05-05', '2016-04-01']"
abstract,"Abstract This numerical study describes the eddy emergence and transformations in a slow steady axisymmetric air–water flow, driven by a rotating top disk in a vertical conical container. As water height \(H_{\mathrm{w}}\) and cone half-angle \(\beta \) vary, numerous flow metamorphoses occur. They are investigated for \(\beta =30^{\circ }, 45^{\circ }\), and \(60^{\circ }\). For small \(H_{\mathrm{w}}\), the air flow is multi-cellular with clockwise meridional circulation near the disk. The air flow becomes one cellular as \(H_{\mathrm{w}}\) exceeds a threshold depending on \(\beta \). For all \(\beta \), the water flow has an unbounded number of eddies whose size and strength diminish as the cone apex is approached. As the water level becomes close to the disk, the outmost water eddy with clockwise meridional circulation expands, reaches the interface, and induces a thin layer with anticlockwise circulation in the air. Then this layer expands and occupies the entire air domain. The physical reasons for the flow transformations are provided. The results are of fundamental interest and can be relevant for aerial bioreactors."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Model-based control of vortex shedding at low Reynolds numbers
keyword,"['Flow control\xa0', 'Fluid mechanics\xa0', 'Reduced-order model \xa0', 'Vortex shedding\xa0']"
history,"['2016-10', '2016-03-26', '2015-07-03', '2016-03-12']"
abstract,"Abstract Model-based feedback control of vortex shedding at low Reynolds numbers is considered. The feedback signal is provided by velocity measurements in the wake, and actuation is achieved using blowing and suction on the cylinder’s surface. Using two-dimensional direct numerical simulations and reduced-order modelling techniques, linear models of the wake are formed at Reynolds numbers between 45 and 110. These models are used to design feedback controllers using \(\mathcal {H}_\infty \) loop-shaping. Complete suppression of shedding is demonstrated up to Re \(=\) 110—both for a single-sensor arrangement and for a three-sensor arrangement. The robustness of the feedback controllers is also investigated by applying them over a range of off-design Reynolds numbers, and good robustness properties are seen. It is also observed that it becomes increasingly difficult to achieve acceptable control performance—measured in a suitable way—as Reynolds number increases."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Theoretical treatment of fluid flow for accelerating bodies
keyword,"['Fluid physics\xa0', 'Navier–Stokes equations\xa0', 'Arbitrary acceleration\xa0', 'Manoeuvre\xa0', 'Computational fluid dynamics\xa0', 'Non-inertial frame\xa0']"
history,"['2016-10', '2016-03-26', '2015-07-08', '2016-02-05']"
abstract,"Abstract Most computational fluid dynamics simulations are, at present, performed in a body-fixed frame, for aeronautical purposes. With the advent of sharp manoeuvre, which may lead to transient effects originating in the acceleration of the centre of mass, there is a need to have a consistent formulation of the Navier–Stokes equations in an arbitrarily moving frame. These expressions should be in a form that allows terms to be transformed between non-inertial and inertial frames and includes gravity, viscous terms, and linear and angular acceleration. Since no effects of body acceleration appear in the inertial frame Navier–Stokes equations themselves, but only in their boundary conditions, it is useful to investigate acceleration source terms in the non-inertial frame. In this paper, a derivation of the energy equation is provided in addition to the continuity and momentum equations previously published. Relevant dimensionless constants are derived which can be used to obtain an indication of the relative significance of acceleration effects. The necessity for using computational fluid dynamics to capture nonlinear effects remains, and various implementation schemes for accelerating bodies are discussed. This theoretical treatment is intended to provide a foundation for interpretation of aerodynamic effects observed in manoeuvre, particularly for accelerating missiles."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Free surface flow impact on a vertical wall: a numerical assessment
keyword,"['Fluid impact\xa0', 'Smoothed particle hydrodynamics\xa0', 'Volume of fluid\xa0', 'Fluid–structure interaction\xa0', 'Free surface flows\xa0']"
history,"['2016-10', '2016-03-18', '2015-08-12', '2016-02-25']"
abstract,"Abstract The sudden impact of a free surface flow upon a solid wall is a common occurrence in many situations in nature and technology. The design of marine structures is probably the most obvious example, but also river and dam hydraulics as well as the necessity of understanding flood and debris flow-induced damage have led to theoretical and experimental work on the mechanism of fluid slamming loads. This is therefore a very old and rich research field, which has not yet reached full maturity, so that semi-empirical methods in design practice are still the rule in many sectors. Up-to-date CFD technology with both Eulerian and Lagrangian approaches is employed to investigate highly non-stationary fluid impact on a solid wall. The development of the pressure wave produced by the impact is examined as it propagates and interacts with the fluid boundaries, as well as the subsequent build-up of high-pressure gradients of high fluid velocities. The geometry and the velocity field of the problem considered are very simple, but the results seem to provide new insight, in particular, into the connection between phenomena with different timescales."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Parallel data-driven decomposition algorithm for large-scale datasets: with application to transitional boundary layers
keyword,"['Parallel algorithms\xa0', 'Data decomposition\xa0', 'Computational fluid dynamics\xa0']"
history,"['2016-10', '2016-03-19', '2015-08-11', '2016-02-25']"
abstract,"Abstract Many fluid flows of engineering interest, though very complex in appearance, can be approximated by low-order models governed by a few modes, able to capture the dominant behavior (dynamics) of the system. This feature has fueled the development of various methodologies aimed at extracting dominant coherent structures from the flow. Some of the more general techniques are based on data-driven decompositions, most of which rely on performing a singular value decomposition (SVD) on a formulated snapshot (data) matrix. The amount of experimentally or numerically generated data expands as more detailed experimental measurements and increased computational resources become readily available. Consequently, the data matrix to be processed will consist of far more rows than columns, resulting in a so-called tall-and-skinny (TS) matrix. Ultimately, the SVD of such a TS data matrix can no longer be performed on a single processor, and parallel algorithms are necessary. The present study employs the parallel TSQR algorithm of (Demmel et al. in SIAM J Sci Comput 34(1):206–239, 2012), which is further used as a basis of the underlying parallel SVD. This algorithm is shown to scale well on machines with a large number of processors and, therefore, allows the decomposition of very large datasets. In addition, the simplicity of its implementation and the minimum required communication makes it suitable for integration in existing numerical solvers and data decomposition techniques. Examples that demonstrate the capabilities of highly parallel data decomposition algorithms include transitional processes in compressible boundary layers without and with induced flow separation."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,The effect of normal electric field on the evolution of immiscible Rayleigh-Taylor instability
keyword,"['Smoothed Particle Hydrodynamics\xa0', 'Rayleigh-Taylor Instability\xa0', 'Electrohydrodynamics\xa0']"
history,"['2016-10', '2016-04-19', '2015-07-22', '2016-03-14']"
abstract,"Abstract Manipulation of the Rayleigh-Taylor instability using an external electric field has been the subject of many studies. However, most of these studies are focused on early stages of the evolution. In this work, the long-term evolution of the instability is investigated, focusing on the forces acting on the interface between the two fluids. To this end, numerical simulations are carried out at various electric permittivity and conductivity ratios as well as electric field intensities using Smoothed Particle Hydrodynamics method. The electric field is applied in parallel to gravity to maintain unstable evolution. The results show that increasing top-to-bottom permittivity ratio increases the rising velocity of the bubble while hindering the spike descent. The opposite trend is observed for increasing top-to-bottom conductivity ratio. These effects are amplified at larger electric field intensities, resulting in narrower structures as the response to the excitation is non-uniform along the interface."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Visualization of three-dimensional incompressible flows by quasi-two-dimensional divergence-free projections in arbitrary flow regions
keyword,"['Incompressible flow\xa0', 'Flow visualization\xa0', 'Staggered grid\xa0']"
history,"['2016-08', '2016-02-24', '2015-08-26', '2016-02-10']"
abstract,"Abstract A visualization of three-dimensional incompressible flows by divergence-free quasi-two-dimensional projections of the velocity field onto three coordinate planes is revisited. An alternative and more general way to compute the projections is proposed. The approach is based on the Chorin projection combined with a SIMPLE-like iteration. Compared to the previous methodology based on divergence-free Galerkin–Chebyshev bases, this technique, formulated in general curvilinear coordinates, is applicable to any flow region and allows for faster computations. To illustrate this visualization method, examples in Cartesian and spherical coordinates, as well as post-processing of experimental 3D-PTV data, are presented."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Rayleigh–Bénard convection driven by a long wavelength heating
keyword,"['Rayleigh–Bénard convection\xa0', 'Spatially modulated heating\xa0', 'Long wavelength\xa0', 'Flow bifurcation\xa0']"
history,"['2016-08', '2016-02-02', '2014-10-07', '2015-12-04']"
abstract,"Abstract Natural convection in a two-dimensional horizontal layer has been investigated. The layer is confined between two parallel horizontal plates. The upper plate is kept isothermal, while the lower plate has an externally imposed, long wavelength, spatially sinusoidal heating with the amplitude expressed in terms of the Rayleigh number Ra and the wavelength characterized by the wave number α. Only steady-state flow structures and their bifurcations have been considered. The detailed analysis has been carried out for two Prandtl numbers, i.e. Pr = 0.7 and Pr = 7, and only small differences in the bifurcation diagrams have been observed. When Ra < Ra cr = 427, convection has a simple topology consisting of one pair of counter-rotating rolls per heating period. Secondary motion in the form of rolls aligned in the direction of the primary rolls and concentrated around the hot spots occurs for Ra > 427. When 427 < Ra < ∼470 and α < ∼0.14, the secondary motion is described by the supercritical pitchfork bifurcation. One of the branches of this bifurcation is associated with an odd number of secondary rolls per half wavelength, with rolls above the hot spots rotating in the direction opposite to the primary rolls. The other branch is associated with an even number of secondary rolls per half wavelength, with the rolls above the hot spots co-rotating with the primary rolls. The new rolls are pinched off in pairs when α decreases. When Ra > ∼470 and α > ~0.14, bifurcation assumes the form of “bifurcation from infinity”. The main branch is associated with one pair of rolls per heating period for α > 0.25. Decrease in α along this branch results in the formation of secondary rolls, with the rolls at the hot spot co-rotating with the primary rolls. The lower part of the other branch is associated with one pair of rolls per heating period in the limit α → 0. Increase in α results in pinching off a single roll which counter-rotates with respect to the primary roll at the hot spot."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,"Effect of boundary representation on viscous, separated flows in a discontinuous-Galerkin Navier–Stokes solver"
keyword,"['Discontinuous-Galerkin spectral element methods\xa0', 'High-order curved boundaries\xa0', ' Direct numerical simulation\xa0', 'Low Reynolds number airfoil flow\xa0']"
history,"['2016-08', '2016-03-30', '2015-03-23', '2016-03-04']"
abstract,"Abstract The effect of curved-boundary representation on the physics of the separated flow over a NACA 65(1)-412 airfoil is thoroughly investigated. A method is presented to approximate curved boundaries with a high-order discontinuous-Galerkin spectral element method for the solution of the Navier–Stokes equations. Multiblock quadrilateral element meshes are constructed with the grid generation software GridPro. The boundary of a NACA 65(1)-412 airfoil, defined by a cubic natural spline, is piecewise-approximated by isoparametric polynomial interpolants that represent the edges of boundary-fitted elements. Direct numerical simulation of the airfoil is performed on a coarse mesh and fine mesh with polynomial orders ranging from four to twelve. The accuracy of the curve fitting is investigated by comparing the flows computed on curved-sided meshes with those given by straight-sided meshes. Straight-sided meshes yield irregular wakes, whereas curved-sided meshes produce a regular Karman street wake. Straight-sided meshes also produce lower lift and higher viscous drag as compared with curved-sided meshes. When the mesh is refined by reducing the sizes of the elements, the lift decrease and viscous drag increase are less pronounced. The differences in the aerodynamic performance between the straight-sided meshes and the curved-sided meshes are concluded to be the result of artificial surface roughness introduced by the piecewise-linear boundary approximation provided by the straight-sided meshes."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Thermal convection in a liquid metal battery
keyword,"['Liquid metal battery\xa0', 'Convection\xa0', 'Instability\xa0']"
history,"['2016-08', '2015-12-11', '2015-07-31', '2015-11-25']"
abstract,"Abstract Generation of thermal convection flow in the liquid metal battery, a device recently proposed as a promising solution for the problem of the short-term energy storage, is analyzed using a numerical model. It is found that convection caused by Joule heating of electrolyte during charging or discharging is virtually unavoidable. It exists in laboratory prototypes larger than a few centimeters in size and should become much stronger in larger-scale batteries. The phenomenon needs further investigation in view of its positive (enhanced mixing of reactants) and negative (loss of efficiency and possible disruption of operation due to the flow-induced deformation of the electrolyte layer) effects."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,The flow external to a rotating torus
keyword,"['Boundary-layer collision\xa0', 'Radial jet\xa0', 'Rotating flow\xa0', 'Toroidal vortex\xa0', 'Absolute instability\xa0']"
history,"['2016-08', '2015-12-22', '2015-08-26', '2015-12-20']"
abstract,"Abstract Imparting a sudden rotation to a torus (or other symmetric smooth object) in an otherwise quiescent, viscous fluid serves to generate boundary layers at the object’s surface. These boundary layers are known to exhibit a finite-time singularity at the equator which manifests in a thickening of the boundary layer and subsequent development of an equatorial jet. Here we consider the post-collision flow dynamics, demonstrating that the equatorial jet serves to shed a finite amplitude toroidal vortex pair. The radial jet is also shown to develop an absolute instability at suitably high Reynolds numbers."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A RANS simulation toward the effect of turbulence and cavitation on spray propagation and combustion characteristics
keyword,"['CFD simulation\xa0', 'Spray propagation indication\xa0', 'Emission\xa0', 'Nozzle curvature radius\xa0', 'RANS\xa0']"
history,"['2016-08', '2016-03-12', '2014-07-12', '2016-02-29']"
abstract,"Abstract A multidimensional computational fluid dynamic code was developed and integrated with probability density function combustion model to give the detailed account of multiphase fluid flow. The vapor phase within injector domain is treated with Reynolds-averaged Navier–Stokes technique. A new parameter is proposed which is an index of plane-cut spray propagation and takes into account two parameters of spray penetration length and cone angle at the same time. It was found that spray propagation factor (SPI) tends to increase at lower r/d ratios, although the spray penetration tends to decrease. The results of SPI obtained by empirical correlation of Hay and Jones were compared with the simulation computation as a function of respective r/d ratio. Based on the results of this study, the spray distribution on plane area has proportional correlation with heat release amount, NO x  emission mass fraction, and soot concentration reduction. Higher cavitation is attributed to the sharp edge of nozzle entrance, yielding better liquid jet disintegration and smaller spray droplet that reduces soot mass fraction of late combustion process. In order to have better insight of cavitation phenomenon, turbulence magnitude in nozzle and combustion chamber was acquired and depicted along with spray velocity."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Numerical simulation of dielectric bubbles coalescence under the effects of uniform magnetic field
keyword,"['Magnetic field\xa0', 'Coalescence\xa0', 'Bubble pairs\xa0', 'Two-phase flow\xa0']"
history,"['2016-06', '2015-11-04', '2015-04-23', '2015-10-21']"
abstract,"Abstract In this research, the co-axial coalescence of a pair of gas bubbles rising in a viscous liquid column under the effects of an external uniform magnetic field is simulated numerically. Considered fluids are dielectric, and applied magnetic field is uniform. Effects of different strengths of magnetic field on the interaction of in-line rising bubbles and coalescence between them were investigated. For numerical modeling of the problem, a computer code was developed to solve the governing equations which are continuity, Navier–Stokes equation, magnetic field equation and level set and reinitialization of level set equations. The finite volume method is used for the discretization of the continuity and momentum equations using SIMPLE scheme where the finite difference method is used to discretization of the magnetic field equations. Also a level set method is used to capture the interface of two phases. The results are compared with available numerical and experimental results in the case of no-magnetic field effect which show a good agreement. It is found that uniform magnetic field accelerates the coalescence of the bubbles in dielectric fluids and enhances the rise velocity of the coalesced bubble."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Spreading dynamics of droplet on an inclined surface
keyword,"['Droplet\xa0', 'Spreading\xa0', 'Surface\xa0', 'Wettability\xa0', 'Lattice Boltzmann simulation\xa0']"
history,"['2016-06', '2015-12-29', '2015-04-12', '2015-11-26']"
abstract,"Abstract A three-dimensional unsteady theoretical model of droplet spreading process on an inclined surface is developed and numerically analyzed to investigate the droplet spreading dynamics via the lattice Boltzmann simulation. The contact line motion and morphology evolution for the droplet spreading on an inclined surface, which are, respectively, represented by the advancing/receding spreading factor and droplet wetted length, are evaluated and analyzed. The effects of surface wettability and inclination on the droplet spreading behaviors are examined. The results indicate that, dominated by gravity and capillarity, the droplet experiences a complex asymmetric deformation and sliding motion after the droplet comes into contact with the inclined surfaces. The droplet firstly deforms near the solid surface and mainly exhibits a radial expansion flow in the start-up stage. An evident sliding-down motion along the inclination is observed in the middle stage. And the surface-tension-driven retraction occurs during the retract stage. Increases in inclination angle and equilibrium contact angle lead to a faster droplet motion and a smaller wetted area. In addition, increases in equilibrium contact angle lead to a shorter duration time of the middle stage and an earlier entry into the retract stage."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A comparison of data reduction techniques for the aeroacoustic analysis of flow over a blunt flat plate
keyword,"['Aeroacoustic\xa0', 'Shedding\xa0', 'Flapping\xa0', 'LES\xa0', 'POD\xa0', 'DMD\xa0']"
history,"['2016-06', '2015-12-19', '2014-12-04', '2015-11-25']"
abstract,"Abstract A large eddy simulation of flow over a forward-facing plate is performed and the resulting database analyzed with respect to sound radiation. Aeroacoustic analysis motivates an initial data compression comprising eduction of the zeroth-order spanwise Fourier mode. The space–time structure of this component of the flow is then analyzed using POD and DMD in order to probe both the energetics and dynamics of the sound-producing flow skeleton. Both data processing techniques educe flapping and shedding modes and identify a nonlinear interaction between the two. POD shows the flapping mode to be energetically unimportant, while DMD highlights its dynamic importance. The difference mode—vortex shedding modulated by flapping of the separation bubble—is found to be the most acoustically important feature of the flow."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Interaction of two spark-generated bubbles near a confined free surface
keyword,"['Two bubbles\xa0', 'Interaction\xa0', 'Boundary element method\xa0', 'Confined free surface\xa0', 'Nozzle geometry\xa0']"
history,"['2016-06', '2015-11-07', '2014-12-20', '2015-10-27']"
abstract,"Abstract In this paper, the oscillation of two spark-generated bubbles placed on a vertical column in close proximity to a confined free surface is considered. The confined free surface is accorded by the top opening of different configurations. These configurations include (i) a centrally perforated horizontal flat plate (\({\theta=90^{\circ})}\), (ii) vertically placed cylinder (\({\theta=0^{\circ})}\) and (iii) nozzle (\({\theta >0^{\circ})}\). The main objective of the present work is to study the effects of key parameters such as the nozzle geometry, the locations of the energy input (i.e., initial position of the bubbles with respect to each other and relative to the free surface) on the dynamics of the two bubbles and the free surface. It was found that the lifetime of the upper bubble decreases from the vertical cylinder to the flat plate case. In addition, by reducing the inter-bubble distance, the lifetime of the upper bubble becomes longer and the repulsion between two bubbles during the expansion phase is stronger. Finally, by reducing the upper bubble-free surface distance, the repulsion between two bubbles during expansion phase increases, the tendency of the upper bubble to rebound and initiate another oscillation cycle decreases, and the amplitude of elevation of the free surface increases."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Computational study of bouncing and non-bouncing droplets impacting on superhydrophobic surfaces
keyword,"['Droplet impact dynamics\xa0', 'Superhydrophobic surface\xa0', 'Computational model\xa0', 'Finite element method\xa0', 'Bouncing\xa0', 'Non-bouncing\xa0', 'Dynamic wetting at contact line\xa0']"
history,"['2016-06', '2015-12-16', '2014-12-25', '2015-11-25']"
abstract,"Abstract We numerically investigate bouncing and non-bouncing of droplets during isothermal impact on superhydrophobic surfaces. An in-house, experimentally validated, finite element method-based computational model is employed to simulate the droplet impact dynamics and transient fluid flow within the droplet. The liquid–gas interface is tracked accurately in Lagrangian framework with dynamic wetting boundary condition at three-phase contact line. The interplay of kinetic, surface and gravitational energies is investigated via systematic variation of impact velocity and equilibrium contact angle. The numerical simulations demonstrate that the droplet bounces off the surface if the total droplet energy at the instance of maximum recoiling exceeds the initial surface and gravitational energy, otherwise not. The non-bouncing droplet is characterized by the oscillations on the free surface due to competition between the kinetic and surface energy. The droplet dimensions and shapes obtained at different times by the simulations are compared with the respective measurements available in the literature. Comparisons show good agreement of numerical data with measurements, and the computational model is able to reconstruct the bouncing and non-bouncing of the droplet as seen in the measurements. The simulated internal flow helps to understand the impact dynamics as well as the interplay of the associated energies during the bouncing and non-bouncing. A regime map is proposed to predict the bouncing and non-bouncing on a superhydrophobic surface with an equilibrium contact angle of 155°, using data of 86 simulations and the measurements available in the literature. We discuss the validity of the computational model for the wetting transition from Cassie to Wenzel state on micro- and nanostructured superhydrophobic surfaces. We demonstrate that the numerical simulation can serve as an important tool to quantify the internal flow, if the simulated droplet shapes match the respective measurements utilizing high-speed photography."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Erratum to: Toward numerical simulations of fluid–structure interactions for investigation of obstructive sleep apnea
keyword,[]
history,"['2016-04', '2015-11-09']"
abstract,None
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Numerical simulation of the non-Newtonian blood flow through a mechanical aortic valve
keyword,"['Non-Newtonian fluid\xa0', 'Hemolysis\xa0', 'Mechanical aortic valve\xa0']"
history,"['2016-04', '2015-11-12', '2015-01-12', '2015-10-07']"
abstract,"Abstract This work focuses on the comparison between Newtonian and non-Newtonian blood flows through a bileaflet mechanical heart valve in the aortic root. The blood, in fact, is a concentrated suspension of cells, mainly red blood cells, in a Newtonian matrix, the plasma, and consequently its overall behavior is that of a non-Newtonian fluid owing to the action of the cells’ membrane on the fluid part. The common practice, however, assumes the blood in large vessels as a Newtonian fluid since the shear rate is generally high and the effective viscosity becomes independent of the former. In this paper, we show that this is not always the case even in the aorta, the largest artery of the systemic circulation, owing to the pulsatile and transitional nature of the flow. Unexpectedly, for most of the pulsating cycle and in a large part of the fluid volume, the shear rate is smaller than the threshold level for the blood to display a constant effective viscosity and its shear thinning character might affect the system dynamics. A direct inspection of the various flow features has shown that the valve dynamics, the transvalvular pressure drop and the large-scale features of the flow are very similar for the Newtonian and non-Newtonian fluid models. On the other hand, the mechanical damage of the red blood cells (hemolysis), induced by the altered stress values in the flow, is larger for the non-Newtonian fluid model than for the Newtonian one."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Recent developments in multiphysics computational models of physiological flows
keyword,[]
history,"['2016-04', '2016-01-30']"
abstract,"Abstract A mini-symposium on computational modeling of fluid–structure interactions and other multiphysics in physiological flows was held at the 11th World Congress on Computational Mechanics in July 2014 in Barcelona, Spain. This special issue of Theoretical and Computational Fluid Dynamics contains papers from among the participants of the mini-symposium. The present paper provides an overview of the mini-symposium and the special issue."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Immersed boundary-finite element model of fluid–structure interaction in the aortic root
keyword,"['Aortic valve\xa0', 'Fluid–structure interaction\xa0', 'Immersed boundary method\xa0', 'Incompressible flow\xa0', 'Hyperelasticity\xa0', 'Finite element method\xa0', 'Finite difference method\xa0']"
history,"['2016-04', '2015-12-19', '2015-01-09', '2015-11-13']"
abstract,"Abstract It has long been recognized that aortic root elasticity helps to ensure efficient aortic valve closure, but our understanding of the functional importance of the elasticity and geometry of the aortic root continues to evolve as increasingly detailed in vivo imaging data become available. Herein, we describe a fluid–structure interaction model of the aortic root, including the aortic valve leaflets, the sinuses of Valsalva, the aortic annulus, and the sinotubular junction, that employs a version of Peskin’s immersed boundary (IB) method with a finite element description of the structural elasticity. As in earlier work, we use a fiber-based model of the valve leaflets, but this study extends earlier IB models of the aortic root by employing an incompressible hyperelastic model of the mechanics of the sinuses and ascending aorta using a constitutive law fit to experimental data from human aortic root tissue. In vivo pressure loading is accounted for by a backward displacement method that determines the unloaded configuration of the root model. Our model yields realistic cardiac output at physiological pressures, with low transvalvular pressure differences during forward flow, minimal regurgitation during valve closure, and realistic pressure loads when the valve is closed during diastole. Further, results from high-resolution computations indicate that although the detailed leaflet and root kinematics show some grid sensitivity, our IB model of the aortic root nonetheless produces essentially grid-converged flow rates and pressures at practical grid spacings for the high Reynolds number flows of the aortic root. These results thereby clarify minimum grid resolutions required by such models when used as stand-alone models of the aortic valve as well as when used to provide models of the outflow valves in models of left-ventricular fluid dynamics."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,From video to computation of biological fluid–structure interaction problems
keyword,"['Moving boundaries\xa0', 'Level sets\xa0', 'Optical flow\xa0', 'Morphing\xa0', 'Image-based modeling\xa0', 'Cartesian grid methods\xa0']"
history,"['2016-04', '2015-07-14', '2015-01-09', '2015-06-27']"
abstract,"Abstract This work deals with the techniques necessary to obtain a purely Eulerian procedure to conduct CFD simulations of biological systems with moving boundary flow phenomena. Eulerian approaches obviate difficulties associated with mesh generation to describe or fit flow meshes to body surfaces. The challenges associated with constructing embedded boundary information, body motions and applying boundary conditions on the moving bodies for flow computation are addressed in the work. The overall approach is applied to the study of a fluid–structure interaction problem, i.e., the hydrodynamics of swimming of an American eel, where the motion of the eel is derived from video imaging. It is shown that some first-blush approaches do not work, and therefore, careful consideration of appropriate techniques to connect moving images to flow simulations is necessary and forms the main contribution of the paper. A combination of level set-based active contour segmentation with optical flow and image morphing is shown to enable the image-to-computation process."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Effect of trabeculae and papillary muscles on the hemodynamics of the left ventricle
keyword,"['Hemodynamics\xa0', 'Left ventricle\xa0', 'Trabeculae\xa0', 'Papillary muscles\xa0', 'Immersed boundary method\xa0', 'Ventriculography\xa0']"
history,"['2016-04', '2015-05-07', '2015-01-12', '2015-04-24']"
abstract,"Abstract The impact of surface trabeculae and papillary muscles on the hemodynamics of the left ventricle (LV) is investigated using numerical simulations. Simulations of ventricular flow are conducted for two different models of the LV derived from high-resolution cardiac computed tomography (CT) scans using an immersed boundary method-based flow solver. One model comprises a trabeculated left ventricle (TLV) that includes both trabeculae and papillary muscles, while the second model has a smooth left ventricle that is devoid of any of these surface features. Results  indicate that the trabeculae and papillary muscles significantly disrupt the vortices that develop during early filling in the TLV model. Large recirculation zones are found to form in the wake of the papillary muscles; these zones enhance the blockage provided by the papillary muscles and create a path for the mitral jet to penetrate deeper into the ventricular apex during diastole. During systole, the trabeculae enhance the apical washout by ‘squeezing’ the flow from the apical region. Finally, the trabeculae enhance viscous dissipation rate of the ventricular flow, but this effect is not significant in the overall power budget."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Toward numerical simulations of fluid–structure interactions for investigation of obstructive sleep apnea
keyword,"['Fluid–structure interaction\xa0', 'Immersed boundary method\xa0', 'Biomedical flows\xa0']"
history,"['2016-04', '2015-10-13', '2015-01-30', '2015-09-30']"
abstract,"Abstract Obstructive sleep apnea (OSA) is a medical condition characterized by repetitive partial or complete occlusion of the airway during sleep. The soft tissues in the airway of OSA patients are prone to collapse under the low-pressure loads incurred during breathing. This paper describes efforts toward the development of a numerical tool for simulation of air–tissue interactions in the upper airway of patients with sleep apnea. A procedure by which patient-specific airway geometries are segmented and processed from dental cone-beam CT scans into signed distance fields is presented. A sharp-interface embedded boundary method based on the signed distance field is used on Cartesian grids for resolving the airflow in the airway geometries. For simulation of structure mechanics with large expected displacements, a cut-cell finite element method with nonlinear Green strains is used. The fluid and structure solvers are strongly coupled with a partitioned iterative algorithm. Preliminary results are shown for flow simulation inside the three-dimensional rigid upper airway of patients with obstructive sleep apnea. Two validation cases for the fluid–structure coupling problem are also presented."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Numerical investigation of fluid–particle interactions for embolic stroke
keyword,"['Hemodynamics\xa0', 'Embolic stroke\xa0', 'Fluid–particle coupling\xa0', 'Helicity\xa0', 'Collision\xa0']"
history,"['2016-04', '2015-07-09', '2015-02-02', '2015-06-27']"
abstract,"Abstract Roughly one-third of all strokes are caused by an embolus traveling to a cerebral artery and blocking blood flow in the brain. The objective of this study is to gain a detailed understanding of the dynamics of embolic particles within arteries. Patient computed tomography image is used to construct a three-dimensional model of the carotid bifurcation. An idealized carotid bifurcation model of same vessel diameters was also constructed for comparison. Blood flow velocities and embolic particle trajectories are resolved using a coupled Euler–Lagrange approach. Blood is modeled as a Newtonian fluid, discretized using the finite volume method, with physiologically appropriate inflow and outflow boundary conditions. The embolus trajectory is modeled using Lagrangian particle equations accounting for embolus interaction with blood as well as vessel wall. Both one- and two-way fluid–particle coupling are considered, the latter being implemented using momentum sources augmented to the discretized flow equations. It was observed that for small-to-moderate particle sizes (relative to vessel diameters), the estimated particle distribution ratio—with and without the inclusion of two-way fluid–particle momentum exchange—were found to be similar. The maximum observed differences in distribution ratio with and without the coupling were found to be higher for the idealized bifurcation model. Additionally, the distribution was found to be reasonably matching the volumetric flow distribution for the idealized model, while a notable deviation from volumetric flow was observed in the anatomical model. It was also observed from an analysis of particle path lines that particle interaction with helical flow, characteristic of anatomical vasculature models, could play a prominent role in transport of embolic particle. The results indicate therefore that flow helicity could be an important hemodynamic indicator for analysis of embolus particle transport. Additionally, in the presence of helical flow, and vessel curvature, inclusion of two-way momentum exchange was found to have a secondary effect for transporting small to moderate embolus particles—and one-way coupling could be used as a reasonable approximation, thereby causing substantial savings in computational resources."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Methodological inaccuracies in clinical aortic valve severity assessment: insights from computational fluid dynamic modeling of CT-derived aortic valve anatomy
keyword,"['Aortic stenosis\xa0', 'Computational fluid dynamics\xa0', 'In vivo\xa0', 'Pressure recovery\xa0', 'Anatomic orifice area\xa0', 'Effective orifice area\xa0', 'Computed tomography\xa0', 'Gorlin\xa0', 'Doppler echocardiography\xa0']"
history,"['2016-04', '2015-11-11', '2014-12-09', '2015-10-21']"
abstract,"Abstract Aortic stenosis is the most common valvular heart disease. Assessing the contribution of the valve as a portion to total ventricular load is essential for the aging population. A CT scan for one patient was used to create one in vivo tricuspid aortic valve geometry and assessed with computational fluid dynamics (CFD). CFD simulated the pressure, velocity, and flow rate, which were used to assess the Gorlin formula and continuity equation, current clinical diagnostic standards. The results demonstrate an underestimation of the anatomic orifice area (AOA) by Gorlin formula and overestimation of AOA by the continuity equation, using peak velocities, as would be measured clinically by Doppler echocardiography. As a result, we suggest that the Gorlin formula is unable to achieve the intended estimation of AOA and largely underestimates AOA at the critical low-flow states present in heart failure. The disparity in the use of echocardiography with the continuity equation is due to the variation in velocity profile between the outflow tract and the valve orifice. Comparison of time-averaged orifice areas by Gorlin and continuity with instantaneous orifice areas by planimetry can mask the errors of these methods, which is a result of the assumption that the blood flow is inviscid."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Comparative hemodynamics in an aorta with bicuspid and trileaflet valves
keyword,"['Bicuspid valve\xa0', 'Trileaflet valve\xa0', 'Fluid–structure interaction\xa0', 'Immersed boundary method\xa0', 'Finite element\xa0', 'Thin shell\xa0', 'Rotation-free approach\xa0']"
history,"['2016-04', '2015-09-28', '2015-02-14', '2015-08-24']"
abstract,"Abstract Bicuspid aortic valve (BAV) is a congenital heart defect that has been associated with serious aortopathies, such as aortic stenosis, aortic regurgitation, infective endocarditis, aortic dissection, calcific aortic valve and dilatation of ascending aorta. There are two main hypotheses to explain the increase prevalence of aortopathies in patients with BAV: the genetic and the hemodynamic. In this study, we seek to investigate the possible role of hemodynamic factors as causes of BAV-associated aortopathy. We employ the curvilinear immersed boundary method coupled with an efficient thin-shell finite-element formulation for tissues to carry out fluid–structure interaction simulations of a healthy trileaflet aortic valve (TAV) and a BAV placed in the same anatomic aorta. The computed results reveal major differences between the TAV and BAV flow patterns. These include: the dynamics of the aortic valve vortex ring formation and break up; the large-scale flow patterns in the ascending aorta; the shear stress magnitude, directions, and dynamics on the heart valve surfaces. The computed results are in qualitative agreement with in vivo magnetic resonance imaging data and suggest that the linkages between BAV aortopathy and hemodynamics deserve further investigation."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Code verification for unsteady 3-D fluid–solid interaction problems
keyword,"['Code verification\xa0', 'Method of manufactured solutions\xa0', 'Fluid solid interaction\xa0']"
history,"['2015-12', '2015-10-23', '2014-08-15', '2015-09-30']"
abstract,"Abstract This paper describes a procedure to synthesize Manufactured Solutions for Code Verification of an important class of Fluid–Structure Interaction (FSI) problems whose behaviors can be modeled as rigid body vibrations in incompressible fluids. We refer this class of FSI problems as Fluid–Solid Interaction problems, which can be found in many practical engineering applications. The methodology can be utilized to develop Manufactured Solutions for both 2-D and 3-D cases. We demonstrate the procedure with our numerical code. We present details of the formulation and methodology. We also provide the reasonings behind our proposed approach. Results  from grid and time step refinement studies confirm the verification of our solver and demonstrate the versatility of the simple synthesis procedure. In addition, the results also demonstrate that the modified decoupled approach to verify flow problems with high-order time-stepping schemes can be employed equally well to verify code for multi-physics problems (here, those of the Fluid–Solid Interaction) when the numerical discretization is based on the Method of Lines."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,3D computation of an incipient motion of a sessile drop on a rigid surface with contact angle hysteresis
keyword,"['Contact line\xa0', 'Pinning\xa0', 'Contact angle\xa0', 'Robin boundary condition\xa0']"
history,"['2015-12', '2015-08-29', '2014-12-14', '2015-08-17']"
abstract,"Abstract Contact line phenomena govern a large number of multiphase flows. A reliable description of the contact line dynamics is therefore essential for prediction of such flows. Well-known difficulties of computation of the wetting phenomena include the mesh dependence of the results caused by flow singularity near the contact line and accurate estimation of its propagating velocity. The present study deals with the computational problem arising from the discontinuity in the dependence of the dynamic contact angle on the propagation velocity, associated with the contact angle hysteresis. The numerical simulations are performed using the volume of fluid method. The boundary conditions in the neighborhood of the contact line are switched depending on the value of the computed current local contact angle between a propagating contact line and a pinning condition. The method is applied to the simulation of the deformation and incipient motion of a shedding drop. The model is validated by comparison of the numerical predictions with experimental data."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Start-up slip flow in a microchannel with a rectangular cross section
keyword,"['Slip flow\xa0', 'Microchannel\xa0', 'Lie group\xa0', 'Lattice Boltzmann\xa0', 'Nusselt number\xa0']"
history,"['2015-12', '2015-08-12', '2015-01-31', '2015-07-30']"
abstract,"Abstract The paper outlines results of the theoretical study of an incompressible fluid flow in a rectangular microchannel subject to a sudden time-dependent pressure drop. The momentum equation together with the independent and dependent variables was reduced to a self-similar form by means of the symmetry analysis. The problem was solved using two analytical approaches, the Fourier method and the method of eigenfunction decomposition, as well as numerically by means of the lattice Boltzmann method. The unsteady two-dimensional velocity profiles in the microchannel were predicted using the infinite series and validated against the numerical solution. As expected, the flow pattern asymptotically attains the fully developed state, which is reached more rapidly for smaller Knudsen numbers. The analytical solution yielded expressions for the calculation of the hydraulic resistance coefficient."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Solving turbulent diffusion flame in cylindrical frame applying an improved advective kinetics scheme
keyword,"['Turbulent flow\xa0', 'Non-premixed flame\xa0', 'Cylindrical frame\xa0', 'Finite volume\xa0', 'Finite element\xa0', 'Physical influence scheme\xa0']"
history,"['2015-12', '2015-10-06', '2015-02-06', '2015-09-16']"
abstract,"Abstract In this work, we derive a few new advective flux approximation expressions, apply them in a hybrid finite-volume-element (FVE) formulation, and solve the turbulent reacting flow governing equations in the cylindrical frame. To derive these advective-kinetic-based expressions, we benefit from the advantages of a physical influence scheme (PIS) basically, extend it to the cylindrical frame suitably, and approximate the required advective flux terms at the cell faces more accurately. The present numerical scheme not only respects the physics of flow correctly but also resolves the pressure–velocity coupling problem automatically. We also suggest a bi-implicit algorithm to solve the set of coupled turbulent reacting flow governing equations, in which the turbulence and chemistry governing equations are solved simultaneously. To evaluate the accuracy of new derived FVE–PIS expressions, we compare the current solutions with other available numerical solutions and experimental data. The comparisons show that the new derived expressions provide some more advantages over the past numerical approaches in solving turbulent diffusion flame in the cylindrical frame. Indeed, the current method and formulations can be used to solve and analyze the turbulent diffusion flames in the cylindrical coordinates very reliably."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Strong transient effects of the flow around a harmonically plunging NACA0012 airfoil at low Reynolds numbers
keyword,"['Transient effects\xa0', 'Deflected wake\xa0', 'Plunging NACA0012 airfoil\xa0', 'ALE methods\xa0']"
history,"['2015-12', '2015-09-19', '2015-02-04', '2015-08-24']"
abstract,"Abstract The flow pattern around a NACA0012 airfoil undergoing harmonic plunging motion corresponding to the deflected wake phenomenon reported by Jones and Platzer (Exp Fluids 46:799–810, 2009) is investigated in detail using direct numerical simulations. An arbitrary Lagrangian–Eulerian formulation based on an unstructured side-centered finite volume method is utilized in order to solve the incompressible unsteady Navier–Stokes equations. The Reynolds number is chosen to be 252, and the reduced frequency of plunging motion (k = 2π fc/U ∞) and the plunge amplitude non-dimensionalized with respect to chord are set to be 12.3 and 0.12, respectively, as in the experimental study of Jones and Platzer (2009). The present numerical simulations reveal a highly persistent transient effect, and it takes two orders of magnitude larger duration than the heave period to reach the time-periodic state. In addition, the three-dimensional simulation reveals that the flow field is three-dimensional for the parameters used herein. The calculation reproduces the deflected wake and shows a good agreement with the experimental wake pattern. The instantaneous vorticity contours, finite-time Lyapunov exponent fields and particle traces are presented along with the aerodynamic parameters including the lift and thrust coefficients."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Effects of kinematics on aerodynamic periodicity for a periodically plunging airfoil
keyword,"['Plunging airfoil\xa0', 'Vortex structure\xa0', 'Aerodynamic periodicity\xa0', 'Computational fluid dynamics\xa0']"
history,"['2015-12', '2015-10-12', '2014-06-19', '2015-09-29']"
abstract,"Abstract In conventional Micro-Air-Vehicle design inspired by insects, the periodical motion of flapping airfoil usually leads to generation of a periodical aerodynamic force. However, recent studies indicate that time courses of aerodynamic force and flow structure of a flapping airfoil may be non-periodical even though the airfoil undergoes a periodical motion. In this paper, a computational fluid dynamics analysis is employed to investigate the effects of some dimensionless variables, such as Reynolds number, plunging amplitude, advance ratio, and angle of attack, on the periodicity of the flow around a flapping airfoil. The governing equations in an inertial frame of reference are solved to obtain unsteady flow structure and aerodynamic behaviors of the airfoil. It is found in the results that the periodicity of the flow and aerodynamics is greatly dependent on Reynolds number and plunging amplitude. Under given conditions, the product of these two variables may be utilized as a criterion parameter to judge whether the time course of the flow is periodical or not. In addition, a new mechanism that accounts for the non-periodical flow is revealed to explain the flow of airfoil with pre-stall angle of attack."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Erratum to: A quantitative comparison between the flow factor approach model and the molecular dynamics simulation results for the flow of a confined molecularly thin fluid film
keyword,[]
history,"['2015-08', '2015-06-10']"
abstract,None
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A modified Darcy’s law
keyword,"['Urban flows\xa0', 'Porous media\xa0', 'Darcy’s law\xa0', 'Fractals\xa0', 'Immersed boundaries\xa0']"
history,"['2015-08', '2015-07-03', '2015-04-28', '2015-06-18']"
abstract,"Abstract An approach to describe the turbulent flow through a complex geometry (e.g., urban area) by means of an analogy to flows through porous media is presented. Therefore, a modification of the original Darcy’s law is proposed, and its application is tested in a prototype problem with an idealized complex geometry using large eddy simulations. The numerical results indicate the validity of the modified Darcy’s law for the chosen setup."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Theoretical analysis of three-dimensional bifurcated flow inside a diagonally lid-driven cavity
keyword,"['Diagonally lid-driven cavity\xa0', 'Oscillatory instability\xa0', None, None, 'Spontaneous symmetry breaking\xa0', 'Subcritical Hopf bifurcation\xa0']"
history,"['2015-08', '2015-05-09', '2014-10-05', '2015-04-28']"
abstract,"Abstract The instability mechanism of fully three-dimensional, highly separated, shear-driven confined flow inside a diagonally lid-driven cavity was investigated. The analysis was conducted on 1003 and 2003 stretched grids by a series of direct numerical simulations utilizing a standard second-order accuracy finite volume code, openFoam. The observed oscillatory instability was found to set in via a subcritical symmetry breaking Hopf bifurcation. Critical values of the Reynolds number Re cr = 2320 and the non-dimensional angular oscillating frequency \({\omega_{\rm cr}=0.249}\) for the transition from steady to oscillatory flow were accurately determined. An oscillatory regime of the bifurcated flow was analyzed in depth, revealing and characterizing the spontaneous symmetry breaking mechanism. Characteristic spatial patterns of the base flow and the main flow harmonic were determined for the velocity, vorticity and helicity fields. Lagrangian particle tracers were utilized to visualize the mixing phenomenon of the flow from both sides of the diagonal symmetry plane."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Rounding errors may be beneficial for simulations of atmospheric flow: results from the forced 1D Burgers equation
keyword,"['Inexact hardware\xa0', 'Stochastic parametrisation\xa0', 'Numerical precision\xa0', 'Turbulent closure\xa0', 'Ensemble methods\xa0']"
history,"['2015-08', '2015-06-20', '2015-02-16', '2015-05-27']"
abstract,"Abstract Inexact hardware can reduce computational cost, due to a reduced energy demand and an increase in performance, and can therefore allow higher-resolution simulations of the atmosphere within the same budget for computation. We investigate the use of emulated inexact hardware for a model of the randomly forced 1D Burgers equation with stochastic sub-grid-scale parametrisation. Results  show that numerical precision can be reduced to only 12 bits in the significand of floating-point numbers—instead of 52 bits for double precision—with no serious degradation in results for all diagnostics considered. Simulations that use inexact hardware on a grid with higher spatial resolution show results that are significantly better compared to simulations in double precision on a coarser grid at similar estimated computing cost. In the second half of the paper, we compare the forcing due to rounding errors to the stochastic forcing of the stochastic parametrisation scheme that is used to represent sub-grid-scale variability in the standard model setup. We argue that stochastic forcings of stochastic parametrisation schemes can provide a first guess for the upper limit of the magnitude of rounding errors of inexact hardware that can be tolerated by model simulations and suggest that rounding errors can be hidden in the distribution of the stochastic forcing. We present an idealised model setup that replaces the expensive stochastic forcing of the stochastic parametrisation scheme with an engineered rounding error forcing and provides results of similar quality. The engineered rounding error forcing can be used to create a forecast ensemble of similar spread compared to an ensemble based on the stochastic forcing. We conclude that rounding errors are not necessarily degrading the quality of model simulations. Instead, they can be beneficial for the representation of sub-grid-scale variability."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Simulation of flux expulsion and associated dynamics in a two-dimensional magnetohydrodynamic channel flow
keyword,"['Flux expulsion\xa0', 'Dynamic runaway\xa0', 'Magnetohydrodynamics\xa0', 'Field lines\xa0']"
history,"['2015-08', '2015-05-31', '2015-03-09', '2015-04-28']"
abstract,"Abstract We consider a plane channel flow of an electrically conducting fluid which is driven by a mean pressure gradient in the presence of an applied magnetic field that is streamwise periodic with zero mean. Magnetic flux expulsion and the associated bifurcation in such a configuration are explored using direct numerical simulations (DNS). The structure of the flow and magnetic fields in the Hartmann regime (where the dominant balance is through Lorentz forces) and the Poiseuille regime (where viscous effects play a significant role) are studied, and detailed comparisons to the existing one-dimensional model of Kamkar and Moffatt (J Fluid Mech 90:107–122, 1982) are drawn to evaluate the validity of the model. Comparisons show good agreement of the model with DNS in the Hartmann regime, but significant differences arising in the Poiseuille regime when nonlinear effects become important. The effects of various parameters like the magnetic Reynolds number, imposed field wavenumber etc. on the bifurcation of the flow are studied. Magnetic field line reconnections occurring during the dynamic runaway reveal a specific two-step pattern that leads to the gradual expulsion of flux in the core region."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Stability and capillary dynamics of circular vortex sheets
keyword,"['Circular vortex sheet\xa0', 'Stability\xa0', 'Surface tension\xa0', 'Capillary waves\xa0']"
history,"['2015-08', '2015-06-04', '2014-11-30', '2015-05-27']"
abstract,"Abstract We investigate the motion of circular vortex sheets with surface tension. A linear stability analysis shows that high modes of the circular vortex sheet are stabilized by surface tension, and the sheet is stable if surface tension is larger than a critical value. The modes of perturbations, n = 1 and 2, are always stable, regardless of surface tension, and the mode n = 3 is also stable for large surface tension. The numerical results show that a stable vortex sheet rotates and oscillates weakly. The oscillations of each mode of the interface mainly consist of two travelling waves of different frequencies in time. The amplitude and the period of the oscillation depend on the mode of the perturbation and surface tension. We also perform long-time computations for the unstable evolution of circular sheets. For a high Weber number, ripples are produced on the sheets, as well as pinching and self-intersection. It is found that the appearance of ripples is associated with the growth of noise. For an intermediate Weber number, the sheet evolves to an exotic structure with small spikes on the fingers, while for a low Weber number, it is nonlinearly stable."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Sessile drop deformations under an impinging jet
keyword,"['Laminar jet\xa0', 'Sessile drop\xa0', 'Free surface deformation\xa0', 'Finite-element method\xa0', 'Arc-length continuation\xa0']"
history,"['2015-08', '2015-06-04', '2014-09-28', '2015-05-27']"
abstract,"Abstract The problem of steady axisymmetric deformations of a liquid sessile drop on a flat solid surface under an impinging gas jet is of interest for understanding the fundamental behavior of free surface flows as well as for establishing the theoretical basis in process design for the Aerosol \({{\rm Jet}^{\circledR}}\) direct-write technology. It is studied here numerically using a Galerkin finite-element method, by computing solutions of Navier–Stokes equations. For effective material deposition in Aerosol \({{\rm Jet}^{\circledR}}\) printing, the desired value of Reynolds number for the laminar gas jet is found to be greater than ~500. The sessile drop can be severely deformed by an impinging gas jet when the capillary number is approaching a critical value beyond which no steady axisymmetric free surface deformation can exist. Solution branches in a parameter space show turning points at the critical values of capillary number, which typically indicate the onset of free surface shape instability. By tracking solution branches around turning points with an arc-length continuation algorithm, critical values of capillary number can be accurately determined. Near turning points, all the free surface profiles in various parameter settings take a common shape with a dimple at the center and bulge near the contact line. An empirical formula for the critical capillary number for sessile drops with \({45^{\circ}}\) contact angle is derived for typical ranges of jet Reynolds number and relative drop sizes especially pertinent to Aerosol \({{\rm Jet}^{\circledR}}\) printing."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,On the uncertainty quantification of the unsteady aerodynamics of 2D free falling plates
keyword,"['Falling plate\xa0', 'Fluttering\xa0', 'Tumbling\xa0', 'Uncertainty quantification\xa0', 'Stochastic analysis\xa0']"
history,"['2015-08', '2015-07-18', '2013-11-05', '2015-07-06']"
abstract,"Abstract The aim of this paper is to conduct a statistical analysis of the effects of the fillet radii on the dynamics of the falling plate using the nonintrusive spectral projection (NISP) method. The free fall of two-dimensional cards immersed in a fluid was studied using a deterministic and stochastic numerical approach. The motion is characterized by the fluid-body interaction described by coupling the Navier–Stokes and rigid body dynamic equations. The model’s predictions have been validated using both experimental and numerical data available in the literature. In the stochastic simulations, the fillet radius of the plate was considered a random variable characterized by a uniform probability density function introducing, in this way, some uncertainties in the plate’s trajectory. To take into account the uncertainties, we employed the NISP method based on polynomial chaos expansion. The analysis was focused on finding the ensemble mean trajectory and error bar for a confidence interval of 95 % for both tumbling and fluttering regimes."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A quantitative comparison between the flow factor approach model and the molecular dynamics simulation results for the flow of a confined molecularly thin fluid film
keyword,"['Molecularly thin fluid film\xa0', 'Couette flow\xa0', 'Poiseuille flow\xa0', 'Model\xa0']"
history,"['2015-06', '2015-04-17', '2014-11-08', '2015-04-01']"
abstract,"Abstract Quantitative comparisons were made between the flow factor approach model and the molecular dynamics simulation (MDS) results both of which describe the flow of a molecularly thin fluid film confined between two solid walls. Although these two approaches, respectively, calculate the flow of a confined molecularly thin fluid film by different ways, very good agreements were found between them when the Couette and Poiseuille flows, respectively, calculated from them were compared. It strongly indicates the validity of the flow factor approach model in modeling the flow of a confined molecularly thin fluid film."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A numerical study of the hole-tone phenomenon subjected to non-axisymmetric shape perturbations of the jet nozzle
keyword,"['Aeroacoustics\xa0', 'Self-sustained flow oscillations\xa0', 'Three-dimensional vortex method\xa0', 'Vortex sound\xa0', 'Boundary element method\xa0', 'Flow control\xa0']"
history,"['2015-06', '2015-02-13', '2014-02-10', '2015-01-29']"
abstract,"Abstract This paper presents a numerical analysis of the hole-tone phenomenon (Rayleigh’s bird-call), based on a three-dimensional discrete vortex method. Evaluation of the sound generated by the self-sustained flow oscillations is based on the Powell–Howe theory of vortex sound and a boundary integral/element method. While the fundamental problem can be modeled well under the assumption of axial symmetry, the purpose of employing a full three-dimensional model is to investigate the influence of non-axisymmetric perturbations of the jet on the sound generation (with a view to flow control). Experimentally, such perturbations can be applied at the jet nozzle via piezoelectric or electro-mechanical actuators, placed circumferentially inside the nozzle at its exit. In the mathematical/numerical model, this is simulated by wave motions of a deformable nozzle. Both standing and traveling (rotating) waves are considered. It is shown that a considerable reduction of the sound generation is possible."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,On the nonnormal–nonlinear interaction mechanism between counter-propagating Rossby waves
keyword,"['Counter-propagating Rossby waves\xa0', 'Linear nonnormal and nonlinear interactions\xa0', 'Geophysical fluid dynamics\xa0']"
history,"['2015-06', '2015-04-18', '2014-05-14', '2015-03-23']"
abstract,"Abstract The counter-propagating Rossby wave perspective to shear flow instability is extended here to the weakly nonlinear phase. The nonlinear action at a distance interaction mechanism between a pair of waves is identified and separated from the linear one. In the former, the streamwise velocity converges the far-field vorticity anomaly of the opposed wave, whereas in the latter, the cross-stream velocity advects the far-field mean vorticity. A truncated analytical model of two vorticity interfaces shows that higher harmonics generated by the nonlinear interaction act as a forcing on the nonnormal linear dynamics. Furthermore, an intrinsic positive feedback toward small-scale enstrophy results from the fact that higher harmonic pair of waves are generated in anti-phase configuration which is favored for nonnormal growth. Near marginal stability, the waves preserve their structure and numerical simulations of the weakly nonlinear interaction show wave saturation into finite amplitudes, in good agreement both with the fixed point solution of the truncated model, as well as with its corresponding weakly nonlinear Ginzburg–Landau amplitude equation."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A linear thermal stability analysis of discretized fluid equations
keyword,"['Convection\xa0', 'Linear stability analysis\xa0', 'Discretization error\xa0']"
history,"['2015-06', '2015-03-10', '2014-09-09', '2015-02-28']"
abstract,"Abstract The effects of discretization on the equations, and their solutions, describing Rayleigh–Bénard convection are studied through linear stability analysis and numerical integration of the discretized equations. Linear stability analyses of the discretized equations were conducted in the usual manner except that the assumed solution contained discretized components (e.g., spatial grid interval in the x direction, \({\Delta x}\)). As the resolution became infinitely high (\({\Delta x \rightarrow 0}\)), the solutions approached those obtained from the continuous equations. The wavenumber of the maximum growth rate increased with increasing \({\Delta x}\) until the wavenumber reached a minimum resolvable resolution, \({\pi \Delta x^{-1}}\). Therefore, the discretization of equations tends to reproduce higher-wavenumber structures than those predicted by the continuous equations. This behavior is counter intuitive and opposed to the expectation of \({\Delta x}\) leading to blurred simulated convection structures. However, when the analysis is conducted for discretized equations that are not combined into a single equation, as is the case for practically solved numerical models, the maximum growing wavenumber rather tends to decrease with increasing \({\Delta x}\) as intuitively expected. The degree of the decrease depends on the discretization accuracy of the first-order differentials. When the accuracy of the discretization scheme is of low order, the wavenumber monotonically decreases with increasing \({\Delta x}\). On the other hand, when higher-order schemes are used for the discretization, the wavenumber does increase with increasing \({\Delta x}\), a similar trend to that in the case of the single-discretized equation for smaller \({\Delta x}\)."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A new framework for simulating forced homogeneous buoyant turbulent flows
keyword,"['Buoyant mixing\xa0', 'Variable density turbulence\xa0', 'Numerical forcing\xa0']"
history,"['2015-06', '2015-05-06', '2014-09-27', '2015-04-10']"
abstract,"Abstract This work proposes a new simulation methodology to study variable density turbulent buoyant flows. The mathematical framework, referred to as homogeneous buoyant turbulence, relies on a triply periodic domain and incorporates numerical forcing methods commonly used in simulation studies of homogeneous, isotropic flows. In order to separate the effects due to buoyancy from those due to large-scale gradients, the linear scalar forcing technique is used to maintain the scalar variance at a constant value. Two sources of kinetic energy production are considered in the momentum equation, namely shear via an isotropic forcing term and buoyancy via the gravity term. The simulation framework is designed such that the four dimensionless parameters of importance in buoyant mixing, namely the Reynolds, Richardson, Atwood, and Schmidt numbers, can be independently varied and controlled. The framework is used to interrogate fully non-buoyant, fully buoyant, and partially buoyant turbulent flows. The results show that the statistics of the scalar fields (mixture fraction and density) are not influenced by the energy production mechanism (shear vs. buoyancy). On the other hand, the velocity field exhibits anisotropy, namely a larger variance in the direction of gravity which is associated with a statistical dependence of the velocity component on the local fluid density."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,"Pore-scale simulation of fluid flow passing over a porously covered square cylinder located at the middle of a channel, using a hybrid MRT-LBM–FVM approach"
keyword,"['Hybrid LBM–FVM\xa0', 'Porous media\xa0', 'Pore-scale simulation\xa0', 'Unsteady flow\xa0']"
history,"['2015-06', '2015-04-10', '2013-10-20', '2015-03-30']"
abstract,"Abstract A comprehensive study was performed to analyze the unsteady laminar flow characteristics around a porously covered, a fully porous, and a solid squared section cylinder located in the middle of a plane channel. In order to simulate fluid flow inside porous media and porous–fluid interface accurately (minimizing modeling error), the porous region was analyzed in pore scale, using LBM. Additionally, to minimize the LBM-related compressibility error through the porous region, a multi-block multiple relaxation time lattice Boltzmann method (MRT-LBM) was used. Also, to decrease CPU time, a Navier–Stokes flow solver, based on finite volume method and SIMPLE algorithm, was coupled with MRT-LBM to simulate flow around the porous obstacle. It should be noted that the flow inside the porous layer is in continuum regime, and hence, the no-slip boundary condition was used to treat the solid walls inside the porous media. In our simulations, we considered variations of porosity and Reynolds number ranging from 0.75 to 0.94 and from 60 to 240, respectively. The effects of porosity and Reynolds number on vortex pattern, mean drag coefficient, amplitude of lift coefficient, and Strouhal number were investigated. Comparison of our results with the ones obtained using Open FOAM, as well as published by others, shows the suitable accuracy of our computations. It is seen that at low Reynolds numbers or at low porosities, where the mean flow does not have large enough momentum to penetrate porous media, the resulting flow field and aerodynamic coefficients are relatively close for three different configurations used. However, as the flow Reynolds number or permeability increases, the mean flow penetrates easier into the porous media and thus provides different shedding characteristics and aerodynamic coefficients for different obstacle shapes."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Reynolds stress and the energy balance of a localized two-dimensional vortex in a uniform shear flow
keyword,"['Vortices\xa0', 'Shear flow\xa0', 'Kinetic energy\xa0', 'Reynolds stress\xa0', 'Kirchhoff vortex\xa0']"
history,"['2015-04', '2014-12-30', '2014-07-30', '2014-10-20']"
abstract,"Abstract Consideration is given to the kinetic energy balance of a localized two-dimensional vortex in unbounded space, subject to a uniform background shear flow. For this problem, a quadratic invariant based on the total flow can be constructed that consists of the sum of the vortex self-energy and the energy of interaction with the background flow. It is shown that an energy equation also may be written for the rate of change of vortex self-energy, relating this to the rate of working by the Reynolds stress. The stress integral is demonstrated to converge for a localized vortex of finite circulation, in contrast to the total kinetic energy. The two approaches to the energy balance are shown to be complementary, and the relation between the Reynolds stress and interaction energy is discussed. As an example, the integrated Reynolds stress is evaluated for a uniformly sheared elliptical (Kirchhoff) vortex. The stress integral includes far field contributions, indicating that appreciable exchange of energy with the external flow occurs well beyond the boundary of the vortex."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Waves in strong centrifugal fields: dissipationless gas
keyword,"['High-speed flow\xa0', 'Gas dynamics\xa0', 'General fluid mechanics\xa0', 'Rotating flows\xa0', 'Waves in rotating fluids\xa0']"
history,"['2015-04', '2015-02-18', '2014-08-14', '2015-02-03']"
abstract,"Abstract Linear waves are investigated in a rotating gas under the condition of strong centrifugal acceleration of the order 106 g realized in gas centrifuges for separation of uranium isotopes. Sound waves split into three families of the waves under these conditions. Dispersion equations are obtained. The characteristics of the waves strongly differ from the conventional sound waves on polarization, velocity of propagation and distribution of energy of the waves in space for two families having frequencies above and below the frequency of the conventional sound waves. The energy of these waves is localized in rarefied region of the gas. The waves of the third family were not specified before. They propagate exactly along the rotational axis with the conventional sound velocity. These waves are polarized only along the rotational axis. Radial and azimuthal motions are not excited. Energy of the waves is concentrated near the wall of the rotor where the density of the gas is largest."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,The LS-STAG immersed boundary method for non-Newtonian flows in irregular geometries: flow of shear-thinning liquids between eccentric rotating cylinders
keyword,"['Immersed boundary method\xa0', 'Cut-cell method\xa0', 'Incompressible flows\xa0', 'Non-Newtonian fluids\xa0', 'Eccentric Taylor–Couette flow\xa0']"
history,"['2015-04', '2015-02-17', '2014-01-27', '2015-01-20']"
abstract,"Abstract This paper presents the extension of a well-established immersed boundary/cut-cell method, the LS-STAG method (Cheny and Botella in J Comput Phys 229:1043–1076, 2010), to non-Newtonian flow computations in 2D irregular geometries. One of the distinguished features of our IB method is to use level-set techniques in the cut-cells near the irregular boundary, where accurate discretization is of paramount importance for stability and accuracy of the computations. For this purpose, we present here an accurate discretization of the velocity gradients and shear rate in the cut-cells that fits elegantly in the framework of the velocity–pressure–stress staggered arrangement and the special quadratures developed previously for viscoelastic flows. After assessing the accuracy of the discretization on a benchmark solution for power-law fluids, the LS-STAG code is applied to the flow of various shear-thinning xanthan solutions in a wide-gap, non-coaxial, Taylor–Couette reactor for which rheological characterization, experimental flow measurements (PIV) and FLUENT simulations have recently been performed in our group. Our numerical investigation will give new insight on the flow patterns (onset, size and position of the recirculation zone) and will firmly correlate them to global flow properties such as shear-thinning index, generalized Reynolds number and torque ratio at the cylinders."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Subgrid-scale turbulence in shock–boundary layer flows
keyword,"['Shock-boundary layer interactions\xa0', 'LES\xa0', 'Subgrid-scale turbulence\xa0', 'High-speed turbulent flows\xa0']"
history,"['2015-04', '2015-01-18', '2014-06-10', '2015-01-06']"
abstract,"Abstract Data generated by direct numerical simulation (DNS) for a Mach 2.75 zero-pressure gradient turbulent boundary layer interacting with shocks of different intensities are used for a priori analysis of subgrid-scale (SGS) turbulence and various terms in the compressible filtered Navier–Stokes equations. The numerical method used for DNS is based on a hybrid scheme that uses a non-dissipative central scheme in the shock-free turbulent regions and a robust monotonicity-preserving scheme in the shock regions. The behavior of SGS stresses and their components, namely Leonard, Cross and Reynolds components, is examined in various regions of the flow for different shock intensities and filter widths. The backscatter in various regions of the flow is found to be significant only instantaneously, while the ensemble-averaged statistics indicate no significant backscatter. The budgets for the SGS kinetic energy equation are examined for a better understanding of shock–tubulence interactions at the subgrid level and also with the aim of providing useful information for one-equation LES models. A term-by-term analysis of SGS terms in the filtered total energy equation indicate that while each term in this equation is significant by itself, the net contribution by all of them is relatively small. This observation is consistent with our a posteriori analysis."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,On the excitation of Görtler vortices by distributed roughness elements
keyword,"['Boundary layers\xa0', 'Gortler vortices\xa0', 'Receptivity\xa0']"
history,"['2015-04', '2015-01-29', '2014-07-29', '2015-01-09']"
abstract,"Abstract Görtler vortices evolve in boundary layers over concave surfaces as a result of the imbalance between centrifugal effects and radial pressure gradients. Depending on various geometrical and flow conditions, these vortices can significantly distort the baseline flow and lead to secondary instabilities and ultimately to transition. In this study, the growth of Görtler vortices excited by distributed roughness elements is analyzed using the solution to the nonlinear boundary region equations with upstream boundary conditions derived previously via an asymptotic analysis applied in the vicinity of the roughness elements. Generalized Rayleigh pressure equation derived based on the assumption that the baseline flow is a function of the transverse coordinates only is used to determine the growth rates associated with the secondary instabilities. Within the analysis, the roughness shape, height and diameter as well as the spanwise separation between the roughness elements are varied in the linear regime, while keeping the same Görtler number. It is found that bell-shaped distributed roughness elements are more likely to excite the Görtler instabilities than sharp-edge-type (e.g., cylindrical) roughness elements, and by increasing the roughness diameter, the strength of Görtler vortices associated with the bell-shaped roughness elements increases as expected, but the strength of Görtler vortices associated with cylindrical-shaped roughness elements decreases."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,A lattice Boltzmann-Saltation model and its simulation of aeolian saltation at porous fences
keyword,"['Lattice Boltzmann method\xa0', 'Saltation\xa0', 'Sand mass flux\xa0', 'Wind profile\xa0']"
history,"['2015-04', '2014-12-17', '2014-02-14', '2014-12-01']"
abstract,"Abstract This paper introduces a 2D lattice Boltzmann-Saltation (LBM-Saltation) model for numerical simulation of velocity profiles of windblown sand particles. The model is based on the LBM equations for transient, incompressible viscous flow. We first introduced a lattice Boltzmann subgrid model, which was used to predict the turbulent wind field. Two-way coupling was then used to describe the interaction between wind and the saltating sand particles. The correctness of the model was verified by comparing the simulated results of several important variables of wind-sand flow with that of experiment over a flat bed surface. To show the feasibility of this model with complex boundary conditions, we used it to simulate the wind-sand flow at porous wind fences and mainly discussed the particle velocity profiles. Single porous wind fence case was computed first and compared with the measurement. Two tandem porous wind fences cases were simulated next. Different distance and porosity of the fences were considered to quantitatively investigate the variation of the shelter effect. The simulated results achieved additional conclusions: The wind speed and the velocity of sand particles are obviously weakened because of the fence; reduction of the particle velocity by porous fence varies with the fence distance and porosity; the larger the distance or the porosity (significantly larger than the 0.3), the worse the shelter effect, and the weaker the reduction of particle velocity."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Suppression of vorticity in vortex and pipe flow interactions
keyword,"['Vortex flow\xa0', 'Instabilities\xa0', 'Lift-up mechanism\xa0']"
history,"['2015-04', '2015-01-28', '2014-07-24', '2015-01-12']"
abstract,"Abstract The interaction of a vortex and a pipe flow, modelled as the Lamb–Oseen vortex and the Poiseuille flow, respectively, is investigated by means of stability analyses and direct numerical simulations (DNS). From the distribution of the most unstable mode, it is observed that the instability is induced by the combination of the radial gradients of the base azimuthal and axial velocity components, e.g. an axial (or azimuthal) vorticity perturbation acts on the axial (or azimuthal) base velocity via a lift-up effect to generate axial (or azimuthal) velocity streaks, which are further stretched by the base azimuthal (or axial) velocity to create azimuthal (or axial) vorticity. This lift-up-stretch mechanism is confirmed in DNS of the model base flow initially perturbed by the most unstable mode. After nonlinear saturation, the perturbations decay since the flow no longer supports instability after sufficient radial mixing induced by the lift-up of the azimuthal and axial velocity components. These observations suggest that the vorticity outside the vortex core can be suppressed by instabilities if a streamwise boundary layer flow exists outside the core."
journal_title,Theoretical and Computational Fluid Dynamics
article_title,Moffatt eddies at an interface
keyword,"['Viscosity Ratio\xa0', 'Wall Angle\xa0', 'Water Side\xa0', 'Incline Wall\xa0', 'Driving Source\xa0']"
history,"['2014-12', '2014-10-30', '2014-03-30', '2014-10-10']"
abstract,"Abstract It is shown that an infinite set of eddies can develop near the interface–wall intersection in a two-fluid flow. A striking feature is that the eddy occurrence depends on from what side of the interface the flow is driven. In air–water flows where the viscosity ratio is 0.018, the eddies develop if a driving source is located on (i) the air side for \({\alpha  < 100.55^{\circ}}\), (ii) any side for \({100.55^{\circ}  < \alpha  < 146.55^{\circ}}\), and (iii) the water side for \({146.55^{\circ}  < \alpha  < 159.05^{\circ}}\), where \({\alpha}\) is the upper interface–wall angle."
journal_title,International Journal of Computer Vision
article_title,Defining the Pose of Any 3D Rigid Object and an Associated Distance
keyword,"['Pose\xa0', '3D rigid object\xa0', 'Symmetry\xa0', 'Distance\xa0', 'Metric\xa0', 'Average\xa0', 'Rotation\xa0', None, None, 'Object recognition\xa0']"
history,"['2018-06', '2017-11-24', '2016-09-23', '2017-10-31']"
abstract,"Abstract The pose of a rigid object is usually regarded as a rigid transformation, described by a translation and a rotation. However, equating the pose space with the space of rigid transformations is in general abusive, as it does not account for objects with proper symmetries—which are common among man-made objects. In this article, we define pose as a distinguishable static state of an object, and equate a pose to a set of rigid transformations. Based solely on geometric considerations, we propose a frame-invariant metric on the space of possible poses, valid for any physical rigid object, and requiring no arbitrary tuning. This distance can be evaluated efficiently using a representation of poses within a Euclidean space of at most 12 dimensions depending on the object’s symmetries. This makes it possible to efficiently perform neighborhood queries such as radius searches or k-nearest neighbor searches within a large set of poses using off-the-shelf methods. Pose averaging considering this metric can similarly be performed easily, using a projection function from the Euclidean space onto the pose space. The practical value of those theoretical developments is illustrated with an application of pose estimation of instances of a 3D rigid object given an input depth map, via a Mean Shift procedure."
journal_title,International Journal of Computer Vision
article_title,SDF-2-SDF Registration for Real-Time 3D Reconstruction from RGB-D Data
keyword,"['Signed distance field\xa0', 'Registration\xa0', '3D reconstruction\xa0', 'Camera tracking\xa0', 'Global optimization\xa0', 'RGB-D sensors\xa0']"
history,"['2018-06', '2017-12-18', '2017-06-24', '2017-11-20']"
abstract,"Abstract We tackle the task of dense 3D reconstruction from RGB-D data. Contrary to the majority of existing methods, we focus not only on trajectory estimation accuracy, but also on reconstruction precision. The key technique is SDF-2-SDF registration, which is a correspondence-free, symmetric, dense energy minimization method, performed via the direct voxel-wise difference between a pair of signed distance fields. It has a wider convergence basin than traditional point cloud registration and cloud-to-volume alignment techniques. Furthermore, its formulation allows for straightforward incorporation of photometric and additional geometric constraints. We employ SDF-2-SDF registration in two applications. First, we perform small-to-medium scale object reconstruction entirely on the CPU. To this end, the camera is tracked frame-to-frame in real time. Then, the initial pose estimates are refined globally in a lightweight optimization framework, which does not involve a pose graph. We combine these procedures into our second, fully real-time application for larger-scale object reconstruction and SLAM. It is implemented as a hybrid system, whereby tracking is done on the GPU, while refinement runs concurrently over batches on the CPU. To bound memory and runtime footprints, registration is done over a fixed number of limited-extent volumes, anchored at geometry-rich locations. Extensive qualitative and quantitative evaluation of both trajectory accuracy and model fidelity on several public RGB-D datasets, acquired with various quality sensors, demonstrates higher precision than related techniques."
journal_title,International Journal of Computer Vision
article_title,Separable Anisotropic Diffusion
keyword,"['Image segmentation\xa0', 'Partial differential equations\xa0', 'Anisotropic filtering\xa0', 'Nonlinear diffusion\xa0', 'Separable filters\xa0', 'Fast\xa0', 'High dimensional\xa0', 'Denoising\xa0']"
history,"['2018-06', '2018-01-05', '2017-05-03', '2017-12-23']"
abstract,"Abstract Anisotropic diffusion has many applications in image processing, but the high computational cost usually requires accuracy trade-offs in order to grant its applicability in practical problems. This is specially true when dealing with 3D images, where anisotropic diffusion should be able to provide interesting results for many applications, but the usual implementation methods greatly scale in complexity with the additional dimension. Here we propose a separable implementation of the most general anisotropic diffusion formulation, based on Gaussian convolutions, whose favorable computational complexity scales linearly with the number of dimensions, without any assumptions about specific parameterizations. We also present variants that bend the Gaussian kernels for improved results when dealing with highly anisotropic curved or sharp structures. We test the accuracy, speed, stability, and scale-space properties of the proposed methods, and present some results (both synthetic and real) which show their advantages, including up to 60 times faster computation in 3D with respect to the explicit method, improved accuracy and stability, and min–max preservation."
journal_title,International Journal of Computer Vision
article_title,RAW Image Reconstruction Using a Self-contained sRGB–JPEG Image with Small Memory Overhead
keyword,"['Radiometric calibration\xa0', 'In-camera image processing\xa0', 'Raw image reconstruction\xa0']"
history,"['2018-06', '2017-12-18', '2017-02-10', '2017-11-03']"
abstract,"Abstract Most camera images are saved as 8-bit standard RGB (sRGB) compressed JPEGs. Even when JPEG compression is set to its highest quality, the encoded sRGB image has been significantly processed in terms of color and tone manipulation. This makes sRGB–JPEG images undesirable for many computer vision tasks that assume a direct relationship between pixel values and incoming light. For such applications, the RAW image format is preferred, as RAW represents a minimally processed, sensor-specific RGB image that is linear with respect to scene radiance. The drawback with RAW images, however, is that they require large amounts of storage and are not well-supported by many imaging applications. To address this issue, we present a method to encode the necessary data within an sRGB–JPEG image to reconstruct a high-quality RAW image. Our approach requires no calibration of the camera’s colorimetric properties and can reconstruct the original RAW to within 0.5% error with a small memory overhead for the additional data (e.g., 128 KB). More importantly, our output is a fully self-contained 100% compliant sRGB–JPEG file that can be used as-is, not affecting any existing image workflow—the RAW image data can be extracted when needed, or ignored otherwise. We detail our approach and show its effectiveness against competing strategies."
journal_title,International Journal of Computer Vision
article_title,Hallucinating Compressed Face Images
keyword,"['Face hallucination\xa0', 'Super resolution\xa0', 'JPEG compression\xa0', 'Image denoising\xa0', 'Landmark points\xa0']"
history,"['2018-06', '2017-12-08', '2015-12-02', '2017-09-12']"
abstract,"Abstract A face hallucination algorithm is proposed to generate high-resolution images from JPEG compressed low-resolution inputs by decomposing a deblocked face image into structural regions such as facial components and non-structural regions like the background. For structural regions, landmarks are used to retrieve adequate high-resolution component exemplars in a large dataset based on the estimated head pose and illumination condition. For non-structural regions, an efficient generic super resolution algorithm is applied to generate high-resolution counterparts. Two sets of gradient maps extracted from these two regions are combined to guide an optimization process of generating the hallucination image. Numerous experimental results demonstrate that the proposed algorithm performs favorably against the state-of-the-art hallucination methods on JPEG compressed face images with different poses, expressions, and illumination conditions."
journal_title,International Journal of Computer Vision
article_title,Appreciation to IJCV Reviewers of 2017
keyword,[]
history,"['2018-05', '2018-02-19']"
abstract,None
journal_title,International Journal of Computer Vision
article_title,Dense Reconstruction of Transparent Objects by Altering Incident Light Paths Through Refraction
keyword,"['Reconstruction\xa0', 'Transparent object\xa0', 'Refraction\xa0', 'Light path\xa0']"
history,"['2018-05', '2017-09-30', '2017-04-25', '2017-09-15']"
abstract,"Abstract This paper addresses the problem of reconstructing the surface shape of transparent objects. The difficulty of this problem originates from the viewpoint dependent appearance of a transparent object, which quickly makes reconstruction methods tailored for diffuse surfaces fail disgracefully. In this paper, we introduce a fixed viewpoint approach to dense surface reconstruction of transparent objects based on refraction of light. We present a simple setup that allows us to alter the incident light paths before light rays enter the object by immersing the object partially in a liquid, and develop a method for recovering the object surface through reconstructing and triangulating such incident light paths. Our proposed approach does not need to model the complex interactions of light as it travels through the object, neither does it assume any parametric form for the object shape nor the exact number of refractions and reflections taken place along the light paths. It can therefore handle transparent objects with a relatively complex shape and structure, with unknown and inhomogeneous refractive index. We also show that for thin transparent objects, our proposed acquisition setup can be further simplified by adopting a single refraction approximation. Experimental results on both synthetic and real data demonstrate the feasibility and accuracy of our proposed approach."
journal_title,International Journal of Computer Vision
article_title,Do Semantic Parts Emerge in Convolutional Neural Networks?
keyword,"['CNNs for computer vision\xa0', 'Semantic object parts\xa0', 'Object class recognition\xa0', 'Analysis of CNNs\xa0']"
history,"['2018-05', '2017-10-17', '2016-10-05', '2017-10-05']"
abstract,"Abstract Semantic object parts can be useful for several visual recognition tasks. Lately, these tasks have been addressed using Convolutional Neural Networks (CNN), achieving outstanding results. In this work we study whether CNNs learn semantic parts in their internal representation. We investigate the responses of convolutional filters and try to associate their stimuli with semantic parts. We perform two extensive quantitative analyses. First, we use ground-truth part bounding-boxes from the PASCAL-Part dataset to determine how many of those semantic parts emerge in the CNN. We explore this emergence for different layers, network depths, and supervision levels. Second, we collect human judgements in order to study what fraction of all filters systematically fire on any semantic part, even if not annotated in PASCAL-Part. Moreover, we explore several connections between discriminative power and semantics. We find out which are the most discriminative filters for object recognition, and analyze whether they respond to semantic parts or to other image patches. We also investigate the other direction: we determine which semantic parts are the most discriminative and whether they correspond to those parts emerging in the network. This enables to gain an even deeper understanding of the role of semantic parts in the network."
journal_title,International Journal of Computer Vision
article_title,From Facial Expression Recognition to Interpersonal Relation Prediction
keyword,"['Facial expression recognition\xa0', 'Interpersonal relation\xa0', 'Deep convolutional network\xa0']"
history,"['2018-05', '2017-11-24', '2016-09-15', '2017-11-03']"
abstract,"Abstract Interpersonal relation defines the association, e.g., warm, friendliness, and dominance, between two or more people. We investigate if such fine-grained and high-level relation traits can be characterized and quantified from face images in the wild. We address this challenging problem by first studying a deep network architecture for robust recognition of facial expressions. Unlike existing models that typically learn from facial expression labels alone, we devise an effective multitask network that is capable of learning from rich auxiliary attributes such as gender, age, and head pose, beyond just facial expression data. While conventional supervised training requires datasets with complete labels (e.g., all samples must be labeled with gender, age, and expression), we show that this requirement can be relaxed via a novel attribute propagation method. The approach further allows us to leverage the inherent correspondences between heterogeneous attribute sources despite the disparate distributions of different datasets. With the network we demonstrate state-of-the-art results on existing facial expression recognition benchmarks. To predict inter-personal relation, we use the expression recognition network as branches for a Siamese model. Extensive experiments show that our model is capable of mining mutual context of faces for accurate fine-grained interpersonal prediction."
journal_title,International Journal of Computer Vision
article_title,Classification of Multi-class Daily Human Motion using Discriminative Body Parts and Sentence Descriptions
keyword,"['Hidden Markov model\xa0', 'Fisher vector\xa0', 'Multiple kernel learning\xa0', 'Motion classification\xa0', 'Multi-class\xa0', 'Sentence description\xa0']"
history,"['2018-05', '2017-11-10', '2016-08-14', '2017-10-05']"
abstract,"Abstract In this paper, we propose a motion model that focuses on the discriminative parts of the human body related to target motions to classify human motions into specific categories, and apply this model to multi-class daily motion classifications. We extend this model to a motion recognition system which generates multiple sentences associated with human motions. The motion model is evaluated with the following four datasets acquired by a Kinect sensor or multiple infrared cameras in a motion capture studio: UCF-kinect; UT-kinect; HDM05-mocap; and YNL-mocap. We also evaluate the sentences generated from the dataset of motion and language pairs. The experimental results indicate that the motion model improves classification accuracy and our approach is better than other state-of-the-art methods for specific datasets, including human–object interactions with variations in the duration of motions, such as daily human motions. We achieve a classification rate of 81.1% for multi-class daily motion classifications in a non cross-subject setting. Additionally, the sentences generated by the motion recognition system are semantically and syntactically appropriate for the description of the target motion, which may lead to human–robot interaction using natural language."
journal_title,International Journal of Computer Vision
article_title,Visual Tracking via Subspace Learning: A Discriminative Approach
keyword,"['Visual tracking\xa0', 'Discriminative subspace\xa0', 'Joint learning\xa0', 'Sparse representation\xa0', 'Low-rank approximation\xa0']"
history,"['2018-05', '2017-11-10', '2016-09-04', '2017-10-19']"
abstract,"Abstract Good tracking performance is in general attributed to accurate representation over previously obtained targets and/or reliable discrimination between the target and the surrounding background. In this work, a robust tracker is proposed by integrating the advantages of both approaches. A subspace is constructed to represent the target and the neighboring background, and their class labels are propagated simultaneously via the learned subspace. In addition, a novel criterion is proposed, by taking account of both the reliability of discrimination and the accuracy of representation, to identify the target from numerous target candidates in each frame. Thus, the ambiguity in the class labels of neighboring background samples, which influences the reliability of the discriminative tracking model, is effectively alleviated, while the training set still remains small. Extensive experiments demonstrate that the proposed approach outperforms most state-of-the-art trackers."
journal_title,International Journal of Computer Vision
article_title,No-Reference Image Quality Assessment for Image Auto-Denoising
keyword,"['Image quality assessment\xa0', 'Non-local means\xa0', 'Block matching\xa0', 'KNN searching\xa0']"
history,"['2018-05', '2017-11-17', '2015-11-23', '2017-11-02']"
abstract,"Abstract This paper proposes two new non-reference image quality metrics that can be adopted by the state-of-the-art image/video denoising algorithms for auto-denoising. The first metric is proposed based on the assumption that the noise should be independent of the original image. A direct measurement of this dependence is, however, impractical due to the relatively low accuracy of existing denoising method. The proposed metric thus tackles the homogeneous regions and highly-structured regions separately. Nevertheless, this metric is only stable when the noise level is relatively low. Most denoising algorithms reduce noise by (weighted) averaging repeated noisy measurements. As a result, another metric is proposed for high-level noise based on the fact that more noisy measurements will be required when the noise level increases. The number of measurements before converging is thus related to the quality of noisy images. Our patch-matching based metric proposes to iteratively find and add noisy image measurements for averaging until there is no visible difference between two successively averaged images. Both metrics are evaluated on LIVE2 (Sheikh et al. in LIVE image quality assessment database release 2: 2013) and TID2013 (Ponomarenko et al. in Color image database tid2013: Peculiarities and preliminary results: 2005) data sets using standard Spearman and Kendall rank-order correlation coefficients (ROCC), showing that they subjectively outperforms current state-of-the-art no-reference metrics. Quantitative evaluation w.r.t. different level of synthetic noisy images also demonstrates consistently higher performance over state-of-the-art non-reference metrics when used for image denoising."
journal_title,International Journal of Computer Vision
article_title,"Depth-Based Hand Pose Estimation: Methods, Data, and Challenges"
keyword,"['Hand pose\xa0', 'RGB-D sensor\xa0', 'Datasets\xa0', 'Benchmarking\xa0']"
history,"['2018-04-12', '2015-12-03', '2018-03-09']"
abstract,"Abstract Hand pose estimation has matured rapidly in recent years. The introduction of commodity depth sensors and a multitude of practical applications have spurred new advances. We provide an extensive analysis of the state-of-the-art, focusing on hand pose estimation from a single depth frame. To do so, we have implemented a considerable number of systems, and have released software and evaluation code. We summarize important conclusions here: (1) Coarse pose estimation appears viable for scenes with isolated hands. However, high precision pose estimation [required for immersive virtual reality and cluttered scenes (where hands may be interacting with nearby objects and surfaces) remain a challenge. To spur further progress we introduce a challenging new dataset with diverse, cluttered scenes. (2) Many methods evaluate themselves with disparate criteria, making comparisons difficult. We define a consistent evaluation criteria, rigorously motivated by human experiments. (3) We introduce a simple nearest-neighbor baseline that outperforms most existing systems. This implies that most systems do not generalize beyond their training sets. This also reinforces the under-appreciated point that training data is as important as the model itself. We conclude with directions for future progress."
journal_title,International Journal of Computer Vision
article_title,Multi-label Learning with Missing Labels Using Mixed Dependency Graphs
keyword,"['Multi-label learning\xa0', 'Missing labels\xa0', 'Mixed dependency graphs\xa0', 'Image annotation\xa0', 'Image retrieval\xa0']"
history,"['2018-04-06', '2017-07-19', '2018-03-28']"
abstract,"Abstract This work focuses on the problem of multi-label learning with missing labels (MLML), which aims to label each test instance with multiple class labels given training instances that have an incomplete/partial set of these labels (i.e., some of their labels are missing). The key point to handle missing labels is propagating the label information from the provided labels to missing labels, through a dependency graph that each label of each instance is treated as a node. We build this graph by utilizing different types of label dependencies. Specifically, the instance-level similarity is served as undirected edges to connect the label nodes across different instances and the semantic label hierarchy is used as directed edges to connect different classes. This base graph is referred to as the mixed dependency graph, as it includes both undirected and directed edges. Furthermore, we present another two types of label dependencies to connect the label nodes across different classes. One is the class co-occurrence, which is also encoded as undirected edges. Combining with the above base graph, we obtain a new mixed graph, called mixed graph with co-occurrence (MG-CO). The other is the sparse and low rank decomposition of the whole label matrix, to embed high-order dependencies over all labels. Combining with the base graph, the new mixed graph is called as MG-SL (mixed graph with sparse and low rank decomposition). Based on MG-CO and MG-SL, we further propose two convex transductive formulations of the MLML problem, denoted as MLMG-CO and MLMG-SL respectively. In both formulations, the instance-level similarity is embedded through a quadratic smoothness term, while the semantic label hierarchy is used as a linear constraint. In MLMG-CO, the class co-occurrence is also formulated as a quadratic smoothness term, while the sparse and low rank decomposition is incorporated into MLMG-SL, through two additional matrices (one is assumed as sparse, and the other is assumed as low rank) and an equivalence constraint between the summation of this two matrices and the original label matrix. Interestingly, two important applications, including image annotation and tag based image retrieval, can be jointly handled using our proposed methods. Experimental results on several benchmark datasets show that our methods lead to significant improvements in performance and robustness to missing labels over the state-of-the-art methods."
journal_title,International Journal of Computer Vision
article_title,On Unifying Multi-view Self-Representations for Clustering by Tensor Multi-rank Minimization
keyword,"['T-SVD\xa0', 'Tensor multi-rank\xa0', 'Multi-view features\xa0', 'Subspace clustering\xa0']"
history,"['2018-04-06', '2016-12-05', '2018-03-28']"
abstract,"Abstract In this paper, we address the multi-view subspace clustering problem. Our method utilizes the circulant algebra for tensor, which is constructed by stacking the subspace representation matrices of different views and then rotating, to capture the low rank tensor subspace so that the refinement of the view-specific subspaces can be achieved, as well as the high order correlations underlying multi-view data can be explored. By introducing a recently proposed tensor factorization, namely tensor-Singular Value Decomposition (t-SVD) (Kilmer et al. in SIAM J Matrix Anal Appl 34(1):148–172, 2013), we can impose a new type of low-rank tensor constraint on the rotated tensor to ensure the consensus among multiple views. Different from traditional unfolding based tensor norm, this low-rank tensor constraint has optimality properties similar to that of matrix rank derived from SVD, so the complementary information can be explored and propagated among all the views more thoroughly and effectively. The established model, called t-SVD based Multi-view Subspace Clustering (t-SVD-MSC), falls into the applicable scope of augmented Lagrangian method, and its minimization problem can be efficiently solved with theoretical convergence guarantee and relatively low computational complexity. Extensive experimental testing on eight challenging image datasets shows that the proposed method has achieved highly competent objective performance compared to several state-of-the-art multi-view clustering methods."
journal_title,International Journal of Computer Vision
article_title,What Makes Good Synthetic Training Data for Learning Disparity and Optical Flow Estimation?
keyword,"['Deep learning\xa0', 'Data generation\xa0', 'Synthetic ground truth\xa0', 'FlowNet\xa0', 'DispNet\xa0']"
history,"['2018-04-02', '2017-07-24', '2018-03-16']"
abstract,"Abstract The finding that very large networks can be trained efficiently and reliably has led to a paradigm shift in computer vision from engineered solutions to learning formulations. As a result, the research challenge shifts from devising algorithms to creating suitable and abundant training data for supervised learning. How to efficiently create such training data? The dominant data acquisition method in visual recognition is based on web data and manual annotation. Yet, for many computer vision problems, such as stereo or optical flow estimation, this approach is not feasible because humans cannot manually enter a pixel-accurate flow field. In this paper, we promote the use of synthetically generated data for the purpose of training deep networks on such tasks. We suggest multiple ways to generate such data and evaluate the influence of dataset properties on the performance and generalization properties of the resulting networks. We also demonstrate the benefit of learning schedules that use different types of data at selected stages of the training process."
journal_title,International Journal of Computer Vision
article_title,Looking at People Special Issue
keyword,[]
history,"['2018-04', '2018-01-31']"
abstract,None
journal_title,International Journal of Computer Vision
article_title,Prediction of Manipulation Actions
keyword,"['Online action recognition\xa0', 'Hand motions\xa0', 'Forces on the hand\xa0', 'Action prediction\xa0']"
history,"['2018-04', '2017-02-20', '2016-03-16', '2017-01-25']"
abstract,"Abstract By looking at a person’s hands, one can often tell what the person is going to do next, how his/her hands are moving and where they will be, because an actor’s intentions shape his/her movement kinematics during action execution. Similarly, active systems with real-time constraints must not simply rely on passive video-segment classification, but they have to continuously update their estimates and predict future actions. In this paper, we study the prediction of dexterous actions. We recorded videos of subjects performing different manipulation actions on the same object, such as “squeezing”, “flipping”, “washing”, “wiping” and “scratching” with a sponge. In psychophysical experiments, we evaluated human observers’ skills in predicting actions from video sequences of different length, depicting the hand movement in the preparation and execution of actions before and after contact with the object. We then developed a recurrent neural network based method for action prediction using as input image patches around the hand. We also used the same formalism to predict the forces on the finger tips using for training synchronized video and force data streams. Evaluations on two new datasets show that our system closely matches human performance in the recognition task, and demonstrate the ability of our algorithms to predict in real time what and how a dexterous action is performed."
journal_title,International Journal of Computer Vision
article_title,Dynamic Behavior Analysis via Structured Rank Minimization
keyword,"['Dynamic behavior analysis\xa0', 'Structured rank minimization\xa0', 'Linear time-invariant systems\xa0', 'Hankel matrix\xa0', 'Low-rank\xa0', 'Sparsity\xa0']"
history,"['2018-04', '2017-01-19', '2016-03-15', '2016-12-21']"
abstract,"Abstract Human behavior and affect is inherently a dynamic phenomenon involving temporal evolution of patterns manifested through a multiplicity of non-verbal behavioral cues including facial expressions, body postures and gestures, and vocal outbursts. A natural assumption for human behavior modeling is that a continuous-time characterization of behavior is the output of a linear time-invariant system when behavioral cues act as the input (e.g., continuous rather than discrete annotations of dimensional affect). Here we study the learning of such dynamical system under real-world conditions, namely in the presence of noisy behavioral cues descriptors and possibly unreliable annotations by employing structured rank minimization. To this end, a novel structured rank minimization method and its scalable variant are proposed. The generalizability of the proposed framework is demonstrated by conducting experiments on 3 distinct dynamic behavior analysis tasks, namely (i) conflict intensity prediction, (ii) prediction of valence and arousal, and (iii) tracklet matching. The attained results outperform those achieved by other state-of-the-art methods for these tasks and, hence, evidence the robustness and effectiveness of the proposed approach."
journal_title,International Journal of Computer Vision
article_title,Joint Estimation of Human Pose and Conversational Groups from Social Scenes
keyword,"['Head and body pose estimation\xa0', 'F-formation estimation\xa0', 'Semi-supervised learning\xa0', 'Convex optimization\xa0', 'Conversational groups\xa0', 'Video surveillance\xa0']"
history,"['2018-04', '2017-07-14', '2016-03-15', '2017-06-02']"
abstract,"Abstract Despite many attempts in the last few years, automatic analysis of social scenes captured by wide-angle camera networks remains a very challenging task due to the low resolution of targets, background clutter and frequent and persistent occlusions. In this paper, we present a novel framework for jointly estimating (i) head, body orientations of targets and (ii) conversational groups called F-formations from social scenes. In contrast to prior works that have (a) exploited the limited range of head and body orientations to jointly learn both, or (b) employed the mutual head (but not body) pose of interactors for deducing F-formations, we propose a weakly-supervised learning algorithm for joint inference. Our algorithm employs body pose as the primary cue for F-formation estimation, and an alternating optimization strategy is proposed to iteratively refine F-formation and pose estimates. We demonstrate the increased efficacy of joint inference over the state-of-the-art via extensive experiments on three social datasets."
journal_title,International Journal of Computer Vision
article_title,Toward Personalized Modeling: Incremental and Ensemble Alignment for Sequential Faces in the Wild
keyword,"['Face alignment\xa0', 'Personalized modeling\xa0', 'Incremental learning\xa0', 'Ensemble learning\xa0', 'Sparse coding\xa0']"
history,"['2018-04', '2017-02-15', '2016-02-16', '2017-02-02']"
abstract,"Abstract Fitting facial landmarks on unconstrained videos is a challenging task with broad applications. Both generic and joint alignment methods have been proposed with varying degrees of success. However, many generic methods are heavily sensitive to initializations and usually rely on offline-trained static models, which limit their performance on sequential images with extensive variations. On the other hand, joint methods are restricted to offline applications, since they require all frames to conduct batch alignment. To address these limitations, we propose to exploit incremental learning for personalized ensemble alignment. We sample multiple initial shapes to achieve image congealing within one frame, which enables us to incrementally conduct ensemble alignment by group-sparse regularized rank minimization. At the same time, incremental subspace adaptation is performed to achieve personalized modeling in a unified framework. To alleviate the drifting issue, we leverage a very efficient fitting evaluation network to pick out well-aligned faces for robust incremental learning. Extensive experiments on both controlled and unconstrained datasets have validated our approach in different aspects and demonstrated its superior performance compared with state of the arts in terms of fitting accuracy and efficiency."
journal_title,International Journal of Computer Vision
article_title,Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos
keyword,[]
history,"['2018-04', '2017-05-22', '2016-03-08', '2017-04-17']"
abstract,"Abstract Every moment counts in action recognition. A comprehensive understanding of human activity in video requires labeling every frame according to the actions occurring, placing multiple labels densely over a video sequence. To study this problem we extend the existing THUMOS dataset and introduce MultiTHUMOS, a new dataset of dense labels over unconstrained internet videos. Modeling multiple, dense labels benefits from temporal relations within and across classes. We define a novel variant of long short-term memory deep networks for modeling these temporal relations via multiple input and output connections. We show that this model improves action labeling accuracy and further enables deeper understanding tasks ranging from structured retrieval to action prediction."
journal_title,International Journal of Computer Vision
article_title,Space-Time Tree Ensemble for Action Recognition and Localization
keyword,"['Action recognition\xa0', 'Action localization\xa0', 'Space-time tree structure\xa0']"
history,"['2018-04', '2017-02-02', '2016-03-02', '2016-12-08']"
abstract,"Abstract Human actions are, inherently, structured patterns of body movements. We explore ensembles of hierarchical spatio-temporal trees, discovered directly from training data, to model these structures for action recognition and spatial localization. Discovery of frequent and discriminative tree structures is challenging due to the exponential search space, particularly if one allows partial matching. We address this by first building a concise action word vocabulary via discriminative clustering of the hierarchical space-time segments, which is a two-level video representation that captures both static and non-static relevant space-time segments of the video. Using this vocabulary we then utilize tree mining with subsequent tree clustering and ranking to select a compact set of discriminative tree patterns. Our experiments show that these tree patterns, alone, or in combination with shorter patterns (action words and pairwise patterns) achieve promising performance on three challenging datasets: UCF Sports, HighFive and Hollywood3D. Moreover, we perform cross-dataset validation, using trees learned on HighFive to recognize the same actions in Hollywood3D, and using trees learned on UCF-Sports to recognize and localize the similar actions in JHMDB. The results demonstrate the potential for cross-dataset generalization of the trees our approach discovers."
journal_title,International Journal of Computer Vision
article_title,Unconstrained Still/Video-Based Face Verification with Deep Convolutional Neural Networks
keyword,"['Deep learning\xa0', 'Face detection/association\xa0', 'Fiducial detection\xa0', 'Face verification\xa0', 'Metric learning\xa0']"
history,"['2018-04', '2017-07-01', '2016-03-14', '2017-06-10']"
abstract,"Abstract Over the last 5 years, methods based on Deep Convolutional Neural Networks (DCNNs) have shown impressive performance improvements for object detection and recognition problems. This has been made possible due to the availability of large annotated datasets, a better understanding of the non-linear mapping between input images and class labels as well as the affordability of GPUs. In this paper, we present the design details of a deep learning system for unconstrained face recognition, including modules for face detection, association, alignment and face verification. The quantitative performance evaluation is conducted using the IARPA Janus Benchmark A (IJB-A), the JANUS Challenge Set 2 (JANUS CS2), and the Labeled Faces in the Wild (LFW) dataset. The IJB-A dataset includes real-world unconstrained faces of 500 subjects with significant pose and illumination variations which are much harder than the LFW and Youtube Face datasets. JANUS CS2 is the extended version of IJB-A which contains not only all the images/frames of IJB-A but also includes the original videos. Some open issues regarding DCNNs for face verification problems are then discussed."
journal_title,International Journal of Computer Vision
article_title,Beyond Temporal Pooling: Recurrence and Temporal Convolutions for Gesture Recognition in Video
keyword,"['Gesture recognition\xa0', 'Deep neural networks\xa0']"
history,"['2018-04', '2016-10-04', '2016-02-11', '2016-09-20']"
abstract,"Abstract Recent studies have demonstrated the power of recurrent neural networks for machine translation, image captioning and speech recognition. For the task of capturing temporal structure in video, however, there still remain numerous open research questions. Current research suggests using a simple temporal feature pooling strategy to take into account the temporal aspect of video. We demonstrate that this method is not sufficient for gesture recognition, where temporal information is more discriminative compared to general video classification tasks. We explore deep architectures for gesture recognition in video and propose a new end-to-end trainable neural network architecture incorporating temporal convolutions and bidirectional recurrence. Our main contributions are twofold; first, we show that recurrence is crucial for this task; second, we show that adding temporal convolutions leads to significant improvements. We evaluate the different approaches on the Montalbano gesture recognition dataset, where we achieve state-of-the-art results."
journal_title,International Journal of Computer Vision
article_title,A Comprehensive Performance Evaluation of Deformable Face Tracking “In-the-Wild”
keyword,"['Deformable face tracking\xa0', 'Face detection\xa0', 'Model free tracking\xa0', 'Facial landmark localisation\xa0', 'Long-term tracking\xa0']"
history,"['2018-04', '2017-02-25', '2016-03-15', '2017-02-10']"
abstract,"Abstract Recently, technologies such as face detection, facial landmark localisation and face recognition and verification have matured enough to provide effective and efficient solutions for imagery captured under arbitrary conditions (referred to as “in-the-wild”). This is partially attributed to the fact that comprehensive “in-the-wild” benchmarks have been developed for face detection, landmark localisation and recognition/verification. A very important technology that has not been thoroughly evaluated yet is deformable face tracking “in-the-wild”. Until now, the performance has mainly been assessed qualitatively by visually assessing the result of a deformable face tracking technology on short videos. In this paper, we perform the first, to the best of our knowledge, thorough evaluation of state-of-the-art deformable face tracking pipelines using the recently introduced 300 VW benchmark. We evaluate many different architectures focusing mainly on the task of on-line deformable face tracking. In particular, we compare the following general strategies: (a) generic face detection plus generic facial landmark localisation, (b) generic model free tracking plus generic facial landmark localisation, as well as (c) hybrid approaches using state-of-the-art face detection, model free tracking and facial landmark localisation technologies. Our evaluation reveals future avenues for further research on the topic."
journal_title,International Journal of Computer Vision
article_title,Transferring Deep Object and Scene Representations for Event Recognition in Still Images
keyword,"['Event recognition\xa0', 'Deep learning\xa0', 'Transfer learning\xa0', 'Multitask learning\xa0']"
history,"['2018-04', '2017-09-13', '2016-03-31', '2017-09-01']"
abstract,"Abstract This paper addresses the problem of image-based event recognition by transferring deep representations learned from object and scene datasets. First we empirically investigate the correlation of the concepts of object, scene, and event, thus motivating our representation transfer methods. Based on this empirical study, we propose an iterative selection method to identify a subset of object and scene classes deemed most relevant for representation transfer. Afterwards, we develop three transfer techniques: (1) initialization-based transfer, (2) knowledge-based transfer, and (3) data-based transfer. These newly designed transfer techniques exploit multitask learning frameworks to incorporate extra knowledge from other networks or additional datasets into the fine-tuning procedure of event CNNs. These multitask learning frameworks turn out to be effective in reducing the effect of over-fitting and improving the generalization ability of the learned CNNs. We perform experiments on four event recognition benchmarks: the ChaLearn LAP Cultural Event Recognition dataset, the Web Image Dataset for Event Recognition, the UIUC Sports Event dataset, and the Photo Event Collection dataset. The experimental results show that our proposed algorithm successfully transfers object and scene representations towards the event dataset and achieves the current state-of-the-art performance on all considered datasets."
journal_title,International Journal of Computer Vision
article_title,Deep Multimodal Fusion: A Hybrid Approach
keyword,"['Deep learning\xa0', 'Conditional Restricted Boltzmann Machines\xa0', 'Hybrid\xa0', 'Generative\xa0', 'Discriminative\xa0', 'Multimodal fusion\xa0', 'Gesture recognition\xa0', 'Social interaction modeling\xa0']"
history,"['2018-04', '2017-02-20', '2016-02-16', '2017-02-06']"
abstract,"Abstract We propose a novel hybrid model that exploits the strength of discriminative classifiers along with the representation power of generative models. Our focus is on detecting multimodal events in time varying sequences as well as generating missing data in any of the modalities. Discriminative classifiers have been shown to achieve higher performances than the corresponding generative likelihood-based classifiers. On the other hand, generative models learn a rich informative space which allows for data generation and joint feature representation that discriminative models lack. We propose a new model that jointly optimizes the representation space using a hybrid energy function. We employ a Restricted Boltzmann Machines (RBMs) based model to learn a shared representation across multiple modalities with time varying data. The Conditional RBMs (CRBMs) is an extension of the RBM model that takes into account short term temporal phenomena. The hybrid model involves augmenting CRBMs with a discriminative component for classification. For these purposes we propose a novel Multimodal Discriminative CRBMs (MMDCRBMs) model. First, we train the MMDCRBMs model using labeled data by training each modality, followed by training a fusion layer. Second, we exploit the generative capability of MMDCRBMs to activate the trained model so as to generate the lower-level data corresponding to the specific label that closely matches the actual input data. We evaluate our approach on ChaLearn dataset, audio-mocap, as well as the Tower Game dataset, mocap-mocap as well as three multimodal toy datasets. We report classification accuracy, generation accuracy, and localization accuracy and demonstrate its superiority compared to the state-of-the-art methods."
journal_title,International Journal of Computer Vision
article_title,Subjects and Their Objects: Localizing Interactees for a Person-Centric View of Importance
keyword,"['Human-object interaction\xa0', 'Importance\xa0', 'Objectness\xa0']"
history,"['2018-04', '2016-10-28', '2016-03-15', '2016-09-20']"
abstract,"Abstract Understanding images with people often entails understanding their interactions with other objects or people. As such, given a novel image, a vision system ought to infer which other objects/people play an important role in a given person’s activity. However, existing methods are limited to learning action-specific interactions (e.g., how the pose of a tennis player relates to the position of his racquet when serving the ball) for improved recognition, making them unequipped to reason about novel interactions with actions or objects unobserved in the training data. We propose to predict the “interactee” in novel images—that is, to localize the object of a person’s action. Given an arbitrary image with a detected person, the goal is to produce a saliency map indicating the most likely positions and scales where that person’s interactee would be found. To that end, we explore ways to learn the generic, action-independent connections between (a) representations of a person’s pose, gaze, and scene cues and (b) the interactee object’s position and scale. We provide results on a newly collected UT Interactee dataset spanning more than 10,000 images from SUN, PASCAL, and COCO. We show that the proposed interaction-informed saliency metric has practical utility for four tasks: contextual object detection, image retargeting, predicting object importance, and data-driven natural language scene description. All four scenarios reveal the value in linking the subject to its object in order to understand the story of an image."
journal_title,International Journal of Computer Vision
article_title,Deep Expectation of Real and Apparent Age from a Single Image Without Facial Landmarks
keyword,"['Age estimation\xa0', 'Deep learning\xa0', 'CNN\xa0', 'Regression\xa0']"
history,"['2018-04', '2016-08-10', '2016-02-15', '2016-07-20']"
abstract,"Abstract In this paper we propose a deep learning solution to age estimation from a single face image without the use of facial landmarks and introduce the IMDB-WIKI dataset, the largest public dataset of face images with age and gender labels. If the real age estimation research spans over decades, the study of apparent age estimation or the age as perceived by other humans from a face image is a recent endeavor. We tackle both tasks with our convolutional neural networks (CNNs) of VGG-16 architecture which are pre-trained on ImageNet for image classification. We pose the age estimation problem as a deep classification problem followed by a softmax expected value refinement. The key factors of our solution are: deep learned models from large data, robust face alignment, and expected value formulation for age regression. We validate our methods on standard benchmarks and achieve state-of-the-art results for both real and apparent age estimation."
journal_title,International Journal of Computer Vision
article_title,Real-Time Accurate 3D Head Tracking and Pose Estimation with Consumer RGB-D Cameras
keyword,"['3d temporal tracking\xa0', 'Head pose estimation\xa0', 'Real time\xa0', 'Random forests\xa0', 'Multi camera\xa0']"
history,"['2018-04', '2017-02-02', '2016-03-15', '2017-01-03']"
abstract,"Abstract We demonstrate how 3D head tracking and pose estimation can be effectively and efficiently achieved from noisy RGB-D sequences. Our proposal leverages on a random forest framework, designed to regress the 3D head pose at every frame in a temporal tracking manner. One peculiarity of the algorithm is that it exploits together (1) a generic training dataset of 3D head models, which is learned once offline; and, (2) an online refinement with subject-specific 3D data, which aims for the tracker to withstand slight facial deformations and to adapt its forest to the specific characteristics of an individual subject. The combination of these works allows our algorithm to be robust even under extreme poses, where the user’s face is no longer visible on the image. Finally, we also propose another solution that utilizes a multi-camera system such that the data simultaneously acquired from multiple RGB-D sensors helps the tracker to handle challenging conditions that affect a subset of the cameras. Notably, the proposed multi-camera frameworks yields a real-time performance of approximately 8 ms per frame given six cameras and one CPU core, and scales up linearly to 30 fps with 25 cameras."
journal_title,International Journal of Computer Vision
article_title,Large Scale 3D Morphable Models
keyword,"['3D morphable models\xa0', 'Dense correspondence\xa0', 'Demographic-specific models\xa0']"
history,"['2018-04', '2017-04-08', '2016-03-15', '2017-03-24']"
abstract,"Abstract We present large scale facial model (LSFM)—a 3D Morphable Model (3DMM) automatically constructed from 9663 distinct facial identities. To the best of our knowledge LSFM is the largest-scale Morphable Model ever constructed, containing statistical information from a huge variety of the human population. To build such a large model we introduce a novel fully automated and robust Morphable Model construction pipeline, informed by an evaluation of state-of-the-art dense correspondence techniques. The dataset that LSFM is trained on includes rich demographic information about each subject, allowing for the construction of not only a global 3DMM model but also models tailored for specific age, gender or ethnicity groups. We utilize the proposed model to perform age classification from 3D shape alone and to reconstruct noisy out-of-sample data in the low-dimensional model space. Furthermore, we perform a systematic analysis of the constructed 3DMM models that showcases their quality and descriptive power. The presented extensive qualitative and quantitative evaluations reveal that the proposed 3DMM achieves state-of-the-art results, outperforming existing models by a large margin. Finally, for the benefit of the research community, we make publicly available the source code of the proposed automatic 3DMM construction pipeline, as well as the constructed global 3DMM and a variety of bespoke models tailored by age, gender and ethnicity."
journal_title,International Journal of Computer Vision
article_title,Confidence-Weighted Local Expression Predictions for Occlusion Handling in Expression Recognition and Action Unit Detection
keyword,"['Facial expressions\xa0', 'Action unit\xa0', 'Random forest\xa0', 'Occlusions\xa0', 'Autoencoder\xa0', 'Real-time\xa0']"
history,"['2018-04', '2017-04-08', '2016-02-11', '2017-04-03']"
abstract,"Abstract Fully-automatic facial expression recognition (FER) is a key component of human behavior analysis. Performing FER from still images is a challenging task as it involves handling large interpersonal morphological differences, and as partial occlusions can occasionally happen. Furthermore, labelling expressions is a time-consuming process that is prone to subjectivity, thus the variability may not be fully covered by the training data. In this work, we propose to train random forests upon spatially-constrained random local subspaces of the face. The output local predictions form a categorical expression-driven high-level representation that we call local expression predictions (LEPs). LEPs can be combined to describe categorical facial expressions as well as action units (AUs). Furthermore, LEPs can be weighted by confidence scores provided by an autoencoder network. Such network is trained to locally capture the manifold of the non-occluded training data in a hierarchical way. Extensive experiments show that the proposed LEP representation yields high descriptive power for categorical expressions and AU occurrence prediction, and leads to interesting perspectives towards the design of occlusion-robust and confidence-aware FER systems."
journal_title,International Journal of Computer Vision
article_title,Semi-supervised Region Metric Learning for Person Re-identification
keyword,"['Person re-identification\xa0', 'Semi-supervised learning\xa0', 'Imbalanced unlabeled data\xa0']"
history,"['2018-03-27', '2016-10-27', '2018-02-27']"
abstract,"Abstract In large-scale camera networks, label information for person re-identification is usually not available under a large amount of cameras due to expensive human labor efforts. Semi-supervised learning could be employed to train a discriminative classifier by using unlabeled data and unmatched image pairs (negatives) generated from non-overlapping camera views, but existing methods suffer from the problem of imbalanced unlabeled data. In this context, this paper proposes a novel semi-supervised region metric learning method to improve person re-identification performance under imbalanced unlabeled data. Firstly, instead of seeking for matched image pairs (positives) from the unlabeled data, we propose to estimate positive neighbors by label propagation with cross person score distribution alignment. Secondly, multiple positive regions are generated using sets of positive neighbors to learn a discriminative region-to-point metric. Experimental results demonstrate that the superiority of the proposed method over existing unsupervised, semi-supervised and person re-identification methods."
journal_title,International Journal of Computer Vision
article_title,"Combining Shape from Shading and Stereo: A Joint Variational Method for Estimating Depth, Illumination and Albedo"
keyword,"['Stereo reconstruction\xa0', 'Shape from Shading\xa0', 'Variational methods\xa0', 'Illumination estimation\xa0', 'Albedo estimation\xa0', 'Joint reasoning\xa0']"
history,"['2018-03-27', '2017-02-01', '2018-03-07']"
abstract,"Abstract Shape from shading (SfS) and stereo are two fundamentally different strategies for image-based 3-D reconstruction. While approaches for SfS infer the depth solely from pixel intensities, methods for stereo are based on a matching process that establishes correspondences across images. This difference in approaching the reconstruction problem yields complementary advantages that are worthwhile being combined. So far, however, most “joint” approaches are based on an initial stereo mesh that is subsequently refined using shading information. In this paper we follow a completely different approach. We propose a joint variational method that combines both cues within a single minimisation framework. To this end, we fuse a Lambertian SfS approach with a robust stereo model and supplement the resulting energy functional with a detail-preserving anisotropic second-order smoothness term. Moreover, we extend the resulting model in such a way that it jointly estimates depth, albedo and illumination. This in turn makes the approach applicable to objects with non-uniform albedo as well as to scenes with unknown illumination. Experiments for synthetic and real-world images demonstrate the benefits of our combined approach: They not only show that our method is capable of generating very detailed reconstructions, but also that joint approaches are feasible in practice."
journal_title,International Journal of Computer Vision
article_title,Sim4CV: A Photo-Realistic Simulator for Computer Vision Applications
keyword,"['Simulator\xa0', 'Unreal Engine 4\xa0', 'Object tracking\xa0', 'Autonomous driving\xa0', 'Deep learning\xa0', 'Imitation learning\xa0']"
history,"['2018-03-24', '2017-07-18', '2018-02-26']"
abstract,"Abstract We present a photo-realistic training and evaluation simulator (Sim4CV) (http://www.sim4cv.org) with extensive applications across various fields of computer vision. Built on top of the Unreal Engine, the simulator integrates full featured physics based cars, unmanned aerial vehicles (UAVs), and animated human actors in diverse urban and suburban 3D environments. We demonstrate the versatility of the simulator with two case studies: autonomous UAV-based tracking of moving objects and autonomous driving using supervised learning. The simulator fully integrates both several state-of-the-art tracking algorithms with a benchmark evaluation tool and a deep neural network architecture for training vehicles to drive autonomously. It generates synthetic photo-realistic datasets with automatic ground truth annotations to easily extend existing real-world datasets and provides extensive synthetic data variety through its ability to reconfigure synthetic worlds on the fly using an automatic world generation tool."
journal_title,International Journal of Computer Vision
article_title,Semantic Foggy Scene Understanding with Synthetic Data
keyword,"['Foggy scene understanding\xa0', 'Semantic segmentation\xa0', 'Object detection\xa0', 'Depth denoising and completion\xa0', 'Dehazing\xa0', 'Transfer learning\xa0']"
history,"['2018-03-23', '2017-07-25', '2018-02-26']"
abstract,"Abstract This work addresses the problem of semantic foggy scene understanding (SFSU). Although extensive research has been performed on image dehazing and on semantic scene understanding with clear-weather images, little attention has been paid to SFSU. Due to the difficulty of collecting and annotating foggy images, we choose to generate synthetic fog on real images that depict clear-weather outdoor scenes, and then leverage these partially synthetic data for SFSU by employing state-of-the-art convolutional neural networks (CNN). In particular, a complete pipeline to add synthetic fog to real, clear-weather images using incomplete depth information is developed. We apply our fog synthesis on the Cityscapes dataset and generate Foggy Cityscapes with 20,550 images. SFSU is tackled in two ways: (1) with typical supervised learning, and (2) with a novel type of semi-supervised learning, which combines (1) with an unsupervised supervision transfer from clear-weather images to their synthetic foggy counterparts. In addition, we carefully study the usefulness of image dehazing for SFSU. For evaluation, we present Foggy Driving, a dataset with 101 real-world images depicting foggy driving scenes, which come with ground truth annotations for semantic segmentation and object detection. Extensive experiments show that (1) supervised learning with our synthetic data significantly improves the performance of state-of-the-art CNN for SFSU on Foggy Driving; (2) our semi-supervised learning strategy further improves performance; and (3) image dehazing marginally advances SFSU with our learning strategy. The datasets, models and code are made publicly available."
journal_title,International Journal of Computer Vision
article_title,Robust Detection and Affine Rectification of Planar Homogeneous Texture for Scene Understanding
keyword,"['Homogeneous texture\xa0', 'Planar rectification\xa0', 'Invariant texture detection\xa0', 'Scene geometric layout\xa0', 'Scene classification\xa0', 'Deep features\xa0']"
history,"['2018-03-22', '2016-09-29', '2018-03-05']"
abstract,"Abstract Man-made environments tend to be abundant with planar homogeneous texture, which manifests as regularly repeating scene elements along a plane. In this work, we propose to exploit such structure to facilitate high-level scene understanding. By robustly fitting a texture projection model to optimal dominant frequency estimates in image patches, we arrive at a projective-invariant method to localize such generic, semantically meaningful regions in multi-planar scenes. The recovered projective parameters also allow an affine-ambiguous rectification in real-world images marred with outliers, room clutter, and photometric severities. Comprehensive qualitative and quantitative evaluations are performed that show our method outperforms existing representative work for both rectification and detection. The potential of homogeneous texture for two scene understanding tasks is then explored. Firstly, in environments where vanishing points cannot be reliably detected, or the Manhattan assumption is not satisfied, homogeneous texture detected by the proposed approach is shown to provide alternative cues to obtain a scene geometric layout. Second, low-level feature descriptors extracted upon affine rectification of detected texture are found to be not only class-discriminative but also complementary to features without rectification, improving recognition performance on the 67-category MIT benchmark of indoor scenes. One of our configurations involving deep ConvNet features outperforms most current state-of-the-art work on this dataset, achieving a classification accuracy of 76.90%. The approach is additionally validated on a set of 31 categories (mostly outdoor man-made environments exhibiting regular, repeating structure), being a subset of the large-scale Places2 scene dataset."
journal_title,International Journal of Computer Vision
article_title,Cluster Sparsity Field: An Internal Hyperspectral Imagery Prior for Reconstruction
keyword,"['Structured sparsity\xa0', 'Spatial similarity\xa0', 'Hyperspectral denoising\xa0', 'Compressive sensing\xa0']"
history,"['2018-03-21', '2016-09-28', '2018-03-08']"
abstract,"Abstract Hyperspectral images (HSIs) have significant advantages over more traditional image types for a variety of computer vision applications dues to the extra information available. The practical reality of capturing and transmitting HSIs however, means that they often exhibit large amounts of noise, or are undersampled to reduce the data volume. Methods  for combating such image corruption are thus critical to many HSIs applications. Here we devise a novel cluster sparsity field (CSF) based HSI reconstruction framework which explicitly models both the intrinsic correlation between measurements within the spectrum for a particular pixel, and the similarity between pixels due to the spatial structure of the HSI. These two priors have been shown to be effective previously, but have been always considered separately. By dividing pixels of the HSI into a group of spatial clusters on the basis of spectrum characteristics, we define CSF, a Markov random field based prior. In CSF, a structured sparsity potential models the correlation between measurements within each spectrum, and a graph structure potential models the similarity between pixels in each spatial cluster. Then, we integrate the CSF prior learning and image reconstruction into a unified variational framework for optimization, which makes the CSF prior image-specific, and robust to noise. It also results in more accurate image reconstruction compared with existing HSI reconstruction methods, thus combating the effects of noise corruption or undersampling. Extensive experiments on HSI denoising and HSI compressive sensing demonstrate the effectiveness of the proposed method."
journal_title,International Journal of Computer Vision
article_title,3D Interpreter Networks for Viewer-Centered Wireframe Modeling
keyword,"['3D skeleton\xa0', 'Single image 3D reconstruction\xa0', 'Keypoint estimation\xa0', 'Neural network\xa0', 'Synthetic data\xa0']"
history,"['2018-03-21', '2017-06-17', '2018-02-26']"
abstract,"Abstract Understanding 3D object structure from a single image is an important but challenging task in computer vision, mostly due to the lack of 3D object annotations to real images. Previous research tackled this problem by either searching for a 3D shape that best explains 2D annotations, or training purely on synthetic data with ground truth 3D information. In this work, we propose 3D INterpreter Networks (3D-INN), an end-to-end trainable framework that sequentially estimates 2D keypoint heatmaps and 3D object skeletons and poses. Our system learns from both 2D-annotated real images and synthetic 3D data. This is made possible mainly by two technical innovations. First, heatmaps of 2D keypoints serve as an intermediate representation to connect real and synthetic data. 3D-INN is trained on real images to estimate 2D keypoint heatmaps from an input image; it then predicts 3D object structure from heatmaps using knowledge learned from synthetic 3D shapes. By doing so, 3D-INN benefits from the variation and abundance of synthetic 3D objects, without suffering from the domain difference between real and synthesized images, often due to imperfect rendering. Second, we propose a Projection Layer, mapping estimated 3D structure back to 2D. During training, it ensures 3D-INN to predict 3D structure whose projection is consistent with the 2D annotations to real images. Experiments show that the proposed system performs well on both 2D keypoint estimation and 3D structure recovery. We also demonstrate that the recovered 3D information has wide vision applications, such as image retrieval."
journal_title,International Journal of Computer Vision
article_title,Image-Based Synthesis for Deep 3D Human Pose Estimation
keyword,"['Human 3D pose estimation\xa0', 'Data augmentation\xa0', 'CNN\xa0', 'Data synthesis\xa0']"
history,"['2018-03-19', '2017-07-25', '2018-02-26']"
abstract,"Abstract This paper addresses the problem of 3D human pose estimation in the wild. A significant challenge is the lack of training data, i.e., 2D images of humans annotated with 3D poses. Such data is necessary to train state-of-the-art CNN architectures. Here, we propose a solution to generate a large set of photorealistic synthetic images of humans with 3D pose annotations. We introduce an image-based synthesis engine that artificially augments a dataset of real images with 2D human pose annotations using 3D motion capture data. Given a candidate 3D pose, our algorithm selects for each joint an image whose 2D pose locally matches the projected 3D pose. The selected images are then combined to generate a new synthetic image by stitching local image patches in a kinematically constrained manner. The resulting images are used to train an end-to-end CNN for full-body 3D pose estimation. We cluster the training data into a large number of pose classes and tackle pose estimation as a K-way classification problem. Such an approach is viable only with large training sets such as ours. Our method outperforms most of the published works in terms of 3D pose estimation in controlled environments (Human3.6M) and shows promising results for real-world images (LSP). This demonstrates that CNNs trained on artificial images generalize well to real images. Compared to data generated from more classical rendering engines, our synthetic images do not require any domain adaptation or fine-tuning stage."
journal_title,International Journal of Computer Vision
article_title,Adaptive Correlation Filters with Long-Term and Short-Term Memory for Object Tracking
keyword,"['Object tracking\xa0', 'Adaptive correlation filters\xa0', 'Short-term memory\xa0', 'Long-term memory\xa0', 'Appearance model\xa0']"
history,"['2018-03-16', '2016-12-05', '2018-03-02']"
abstract,"Abstract Object tracking is challenging as target objects often undergo drastic appearance changes over time. Recently, adaptive correlation filters have been successfully applied to object tracking. However, tracking algorithms relying on highly adaptive correlation filters are prone to drift due to noisy updates. Moreover, as these algorithms do not maintain long-term memory of target appearance, they cannot recover from tracking failures caused by heavy occlusion or target disappearance in the camera view. In this paper, we propose to learn multiple adaptive correlation filters with both long-term and short-term memory of target appearance for robust object tracking. First, we learn a kernelized correlation filter with an aggressive learning rate for locating target objects precisely. We take into account the appropriate size of surrounding context and the feature representations. Second, we learn a correlation filter over a feature pyramid centered at the estimated target position for predicting scale changes. Third, we learn a complementary correlation filter with a conservative learning rate to maintain long-term memory of target appearance. We use the output responses of this long-term filter to determine if tracking failure occurs. In the case of tracking failures, we apply an incrementally learned detector to recover the target position in a sliding window fashion. Extensive experimental results on large-scale benchmark datasets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods in terms of efficiency, accuracy, and robustness."
journal_title,International Journal of Computer Vision
article_title,Synthesizing a Scene-Specific Pedestrian Detector and Pose Estimator for Static Video Surveillance
keyword,"['Training with synthetic data\xa0', 'Pedestrian detection\xa0', 'Pose estimation\xa0']"
history,"['2018-03-16', '2017-07-24', '2018-03-02']"
abstract,"Abstract We consider scenarios where we have zero instances of real pedestrian data (e.g., a newly installed surveillance system in a novel location in which no labeled real data or unsupervised real data exists yet) and a pedestrian detector must be developed prior to any observations of pedestrians. Given a single image and auxiliary scene information in the form of camera parameters and geometric layout of the scene, our approach infers and generates a large variety of geometrically and photometrically accurate potential images of synthetic pedestrians along with purely accurate ground-truth labels through the use of computer graphics rendering engine. We first present an efficient discriminative learning method that takes these synthetic renders and generates a unique spatially-varying and geometry-preserving pedestrian appearance classifier customized for every possible location in the scene. In order to extend our approach to multi-task learning for further analysis (i.e., estimating pose and segmentation of pedestrians besides detection), we build a more generalized model employing a fully convolutional neural network architecture for multi-task learning leveraging the “free"" ground-truth annotations that can be obtained from our pedestrian synthesizer. We demonstrate that when real human annotated data is scarce or non-existent, our data generation strategy can provide an excellent solution for an array of tasks for human activity analysis including detection, pose estimation and segmentation. Experimental results show that our approach (1) outperforms classical models and hybrid synthetic-real models, (2) outperforms various combinations of off-the-shelf state-of-the-art pedestrian detectors and pose estimators that are trained on real data, and (3) surprisingly, our method using purely synthetic data is able to outperform models trained on real scene-specific data when data is limited."
journal_title,International Journal of Computer Vision
article_title,"Correction to: Lie-X: Depth Image Based Articulated Object Pose Estimation, Tracking, and Action Recognition on Lie Groups"
keyword,[]
history,['2018-03-10']
abstract,None
journal_title,International Journal of Computer Vision
article_title,Augmented Reality Meets Computer Vision: Efficient Data Generation for Urban Driving Scenes
keyword,"['Synthetic training data\xa0', 'Data augmentation\xa0', 'Autonomous driving\xa0', 'Instance segmentation\xa0', 'Object detection\xa0']"
history,"['2018-03-07', '2017-07-29', '2018-02-26']"
abstract,"Abstract The success of deep learning in computer vision is based on the availability of large annotated datasets. To lower the need for hand labeled images, virtually rendered 3D worlds have recently gained popularity. Unfortunately, creating realistic 3D content is challenging on its own and requires significant human effort. In this work, we propose an alternative paradigm which combines real and synthetic data for learning semantic instance segmentation and object detection models. Exploiting the fact that not all aspects of the scene are equally important for this task, we propose to augment real-world imagery with virtual objects of the target category. Capturing real-world images at large scale is easy and cheap, and directly provides real background appearances without the need for creating complex 3D models of the environment. We present an efficient procedure to augment these images with virtual objects. In contrast to modeling complete 3D environments, our data augmentation approach requires only a few user interactions in combination with 3D models of the target object category. Leveraging our approach, we introduce a novel dataset of augmented urban driving scenes with 360 degree images that are used as environment maps to create realistic lighting and reflections on rendered objects. We analyze the significance of realistic object placement by comparing manual placement by humans to automatic methods based on semantic scene analysis. This allows us to create composite images which exhibit both realistic background appearance as well as a large number of complex object arrangements. Through an extensive set of experiments, we conclude the right set of parameters to produce augmented data which can maximally enhance the performance of instance segmentation models. Further, we demonstrate the utility of the proposed approach on training standard deep models for semantic instance segmentation and object detection of cars in outdoor driving scenarios. We test the models trained on our augmented data on the KITTI 2015 dataset, which we have annotated with pixel-accurate ground truth, and on the Cityscapes dataset. Our experiments demonstrate that the models trained on augmented imagery generalize better than those trained on fully synthetic data or models trained on limited amounts of annotated real data."
journal_title,International Journal of Computer Vision
article_title,Hierarchical Cellular Automata for Visual Saliency
keyword,"['Saliency detection\xa0', 'Hierarchical Cellular Automata\xa0', 'Deep contrast features\xa0', 'Bayesian framework\xa0']"
history,"['2018-02-23', '2017-05-21', '2017-12-26']"
abstract,"Abstract Saliency detection, finding the most important parts of an image, has become increasingly popular in computer vision. In this paper, we introduce Hierarchical Cellular Automata (HCA)—a temporally evolving model to intelligently detect salient objects. HCA consists of two main components: Single-layer Cellular Automata (SCA) and Cuboid Cellular Automata (CCA). As an unsupervised propagation mechanism, Single-layer Cellular Automata can exploit the intrinsic relevance of similar regions through interactions with neighbors. Low-level image features as well as high-level semantic information extracted from deep neural networks are incorporated into the SCA to measure the correlation between different image patches. With these hierarchical deep features, an impact factor matrix and a coherence matrix are constructed to balance the influences on each cell’s next state. The saliency values of all cells are iteratively updated according to a well-defined update rule. Furthermore, we propose CCA to integrate multiple saliency maps generated by SCA at different scales in a Bayesian framework. Therefore, single-layer propagation and multi-scale integration are jointly modeled in our unified HCA. Surprisingly, we find that the SCA can improve all existing methods that we applied it to, resulting in a similar precision level regardless of the original results. The CCA can act as an efficient pixel-wise aggregation algorithm that can integrate state-of-the-art methods, resulting in even better results. Extensive experiments on four challenging datasets demonstrate that the proposed algorithm outperforms state-of-the-art conventional methods and is competitive with deep learning based approaches."
journal_title,International Journal of Computer Vision
article_title,Scale-Free Registrations in 3D: 7 Degrees of Freedom with Fourier Mellin SOFT Transforms
keyword,"['Registration\xa0', 'Fourier-Mellin\xa0', 'SO(3)\xa0Fourier transform\xa0', 'Spherical harmonics\xa0', 'Multidimensional signal processing\xa0', 'Object recognition\xa0', 'Object modeling\xa0', 'Mapping\xa0']"
history,"['2018-02-23', '2016-06-10', '2018-01-18']"
abstract,"Abstract Fourier Mellin SOFT (FMS) as a novel method for global registration of 3D data is presented. It determines the seven degrees of freedom (7-DoF) transformation, i.e., the 6-DoF rigid motion parameters plus 1-DoF scale, between two scans, i.e., two noisy, only partially overlapping views on objects or scenes. It is based on a sequence of the 3D Fourier transform, the Mellin transform and the SO(3) Fourier transform. This combination represents a non-trivial complete 3D extension of the well known Fourier-Mellin registration for 2D images. It is accordingly based on decoupling rotation and scale from translation. First, rotation—which is the main challenge for the extension to 3D data - is tackled with a SO(3) Fourier Transform (SOFT) based on Spherical Harmonics. In a second step, scale is determined via a 3D Mellin transform. Finally, translation is calculated by Phase-Matching. Experiments are presented with simulated data sets for ground truth comparisons and with real world data including object recognition and localization in Magnetic Resonance Tomography (MRT) data, registration of 2.5D RGBD scans from a Microsoft Kinect with a scale-free 3D model generated by Multi-View Vision, and 3D mapping by registration of a sequence of consecutive scans from a low-cost actuated Laser Range Finder. The results show that the method is fast and that it can robustly handle partial overlap, interfering structures, and noise. It is also shown that the method is a very interesting option for 6-DoF registration, i.e., when scale is known."
journal_title,International Journal of Computer Vision
article_title,Predicting Foreground Object Ambiguity and Efficiently Crowdsourcing the Segmentation(s)
keyword,"['Salient object detection\xa0', 'Segmentation\xa0', 'Crowdsourcing\xa0']"
history,"['2018-02-05', '2017-04-28', '2018-01-07']"
abstract,"Abstract We propose the ambiguity problem for the foreground object segmentation task and motivate the importance of estimating and accounting for this ambiguity when designing vision systems. Specifically, we distinguish between images which lead multiple annotators to segment different foreground objects (ambiguous) versus minor inter-annotator differences of the same object. Taking images from eight widely used datasets, we crowdsource labeling the images as “ambiguous” or “not ambiguous” to segment in order to construct a new dataset we call STATIC. Using STATIC, we develop a system that automatically predicts which images are ambiguous. Experiments demonstrate the advantage of our prediction system over existing saliency-based methods on images from vision benchmarks and images taken by blind people who are trying to recognize objects in their environment. Finally, we introduce a crowdsourcing system to achieve cost savings for collecting the diversity of all valid “ground truth” foreground object segmentations by collecting extra segmentations only when ambiguity is expected. Experiments show our system eliminates up to 47% of human effort compared to existing crowdsourcing methods with no loss in capturing the diversity of ground truths."
journal_title,International Journal of Computer Vision
article_title,Label Propagation with Ensemble of Pairwise Geometric Relations: Towards Robust Large-Scale Retrieval of Object Instances
keyword,"['Image retrieval\xa0', 'Label propagation\xa0', 'Pairwise geometric relation\xa0', 'Reranking\xa0', 'Spatial verification\xa0']"
history,"['2018-01-31', '2016-07-12', '2018-01-06']"
abstract,"Abstract Spatial verification methods permit geometrically stable image matching, but still involve a difficult trade-off between robustness as regards incorrect rejection of true correspondences and discriminative power in terms of mismatches. To address this issue, we ask whether an ensemble of weak geometric constraints that correlates with visual similarity only slightly better than a bag-of-visual-words model performs better than a single strong constraint. We consider a family of spatial verification methods and decompose them into fundamental constraints imposed on pairs of feature correspondences. Encompassing such constraints leads us to propose a new method, which takes the best of existing techniques and functions as a unified Ensemble of pAirwise GEometric Relations (EAGER), in terms of both spatial contexts and between-image transformations. We also introduce a novel and robust reranking method, in which the object instances localized by EAGER in high-ranked database images are reissued as new queries. EAGER is extended to develop a smoothness constraint where the similarity between the optimized ranking scores of two instances should be maximally consistent with their geometrically constrained similarity. Reranking is newly formulated as two label propagation problems: one is to assess the confidence of new queries and the other to aggregate new independently executed retrievals. Extensive experiments conducted on four datasets show that EAGER and our reranking method outperform most of their state-of-the-art counterparts, especially when large-scale visual vocabularies are used."
journal_title,International Journal of Computer Vision
article_title,Learning Latent Representations of 3D Human Pose with Deep Neural Networks
keyword,"['3D human pose estimation\xa0', 'Structured prediction\xa0', 'Deep learning\xa0']"
history,"['2018-01-31', '2017-02-01', '2018-01-10']"
abstract,"Abstract Most recent approaches to monocular 3D pose estimation rely on Deep Learning. They either train a Convolutional Neural Network to directly regress from an image to a 3D pose, which ignores the dependencies between human joints, or model these dependencies via a max-margin structured learning framework, which involves a high computational cost at inference time. In this paper, we introduce a Deep Learning regression architecture for structured prediction of 3D human pose from monocular images or 2D joint location heatmaps that relies on an overcomplete autoencoder to learn a high-dimensional latent pose representation and accounts for joint dependencies. We further propose an efficient Long Short-Term Memory network to enforce temporal consistency on 3D pose predictions. We demonstrate that our approach achieves state-of-the-art performance both in terms of structure preservation and prediction accuracy on standard 3D human pose estimation benchmarks."
journal_title,International Journal of Computer Vision
article_title,Occlusion-Aware 3D Morphable Models and an Illumination Prior for Face Image Analysis
keyword,"['Face image analysis\xa0', 'Markov chain Monte Carlo\xa0', 'Morphable model\xa0', 'Generative models\xa0', 'Occlusion-aware model fitting\xa0', 'Inverse rendering\xa0', 'Robust illumination estimation\xa0', 'Illumination prior\xa0']"
history,"['2018-01-31', '2017-02-01', '2018-01-06']"
abstract,"Abstract Faces in natural images are often occluded by a variety of objects. We propose a fully automated, probabilistic and occlusion-aware 3D morphable face model adaptation framework following an analysis-by-synthesis setup. The key idea is to segment the image into regions explained by separate models. Our framework includes a 3D morphable face model, a prototype-based beard model and a simple model for occlusions and background regions. The segmentation and all the model parameters have to be inferred from the single target image. Face model adaptation and segmentation are solved jointly using an expectation–maximization-like procedure. During the E-step, we update the segmentation and in the M-step the face model parameters are updated. For face model adaptation we apply a stochastic sampling strategy based on the Metropolis–Hastings algorithm. For segmentation, we apply loopy belief propagation for inference in a Markov random field. Illumination estimation is critical for occlusion handling. Our combined segmentation and model adaptation needs a proper initialization of the illumination parameters. We propose a RANSAC-based robust illumination estimation technique. By applying this method to a large face image database we obtain a first empirical distribution of real-world illumination conditions. The obtained empirical distribution is made publicly available and can be used as prior in probabilistic frameworks, for regularization or to synthesize data for deep learning methods."
journal_title,International Journal of Computer Vision
article_title,Discriminative Correlation Filter Tracker with Channel and Spatial Reliability
keyword,"['Visual tracking\xa0', 'Correlation filters\xa0', 'Channel reliability\xa0', 'Constrained optimization\xa0']"
history,"['2018-01-08', '2017-03-28', '2017-12-23']"
abstract,"Abstract Short-term tracking is an open and challenging problem for which discriminative correlation filters (DCF) have shown excellent performance. We introduce the channel and spatial reliability concepts to DCF tracking and provide a learning algorithm for its efficient and seamless integration in the filter update and the tracking process. The spatial reliability map adjusts the filter support to the part of the object suitable for tracking. This both allows to enlarge the search region and improves tracking of non-rectangular objects. Reliability scores reflect channel-wise quality of the learned filters and are used as feature weighting coefficients in localization. Experimentally, with only two simple standard feature sets, HoGs and colornames, the novel CSR-DCF method—DCF with channel and spatial reliability—achieves state-of-the-art results on VOT 2016, VOT 2015 and OTB100. The CSR-DCF runs close to real-time on a CPU."
journal_title,International Journal of Computer Vision
article_title,Graph-Based Slice-to-Volume Deformable Registration
keyword,"['Slice-to-volume registration\xa0', 'Graphical models\xa0', 'Deformable registration\xa0', 'Discrete optimization\xa0']"
history,"['2018-01', '2017-08-22', '2016-08-30', '2017-08-07']"
abstract,"Abstract Deformable image registration is a fundamental problem in computer vision and medical image computing. In this paper we investigate the use of graphical models in the context of a particular type of image registration problem, known as slice-to-volume registration. We introduce a scalable, modular and flexible formulation that can accommodate low-rank and high order terms, that simultaneously selects the plane and estimates the in-plane deformation through a single shot optimization approach. The proposed framework is instantiated into different variants seeking either a compromise between computational efficiency (soft plane selection constraints and approximate definition of the data similarity terms through pair-wise components) or exact definition of the data terms and the constraints on the plane selection. Simulated and real-data in the context of ultrasound and magnetic resonance registration (where both framework instantiations as well as different optimization strategies are considered) demonstrate the potentials of our method."
journal_title,International Journal of Computer Vision
article_title,Baseline and Triangulation Geometry in a Standard Plenoptic Camera
keyword,"['Light field\xa0', 'Plenoptic\xa0', 'Camera\xa0', 'Microscope\xa0', 'Triangulation\xa0', 'Baseline\xa0', 'Distance\xa0', 'Estimation\xa0']"
history,"['2018-01', '2017-08-20', '2016-08-04', '2017-07-20']"
abstract,"Abstract In this paper, we demonstrate light field triangulation to determine depth distances and baselines in a plenoptic camera. Advances in micro lenses and image sensors have enabled plenoptic cameras to capture a scene from different viewpoints with sufficient spatial resolution. While object distances can be inferred from disparities in a stereo viewpoint pair using triangulation, this concept remains ambiguous when applied in the case of plenoptic cameras. We present a geometrical light field model allowing the triangulation to be applied to a plenoptic camera in order to predict object distances or specify baselines as desired. It is shown that distance estimates from our novel method match those of real objects placed in front of the camera. Additional benchmark tests with an optical design software further validate the model’s accuracy with deviations of less than ±0.33% for several main lens types and focus settings. A variety of applications in the automotive and robotics field can benefit from this estimation model."
journal_title,International Journal of Computer Vision
article_title,Efficient Label Collection for Image Datasets via Hierarchical Clustering
keyword,"['Efficient label collection\xa0', 'Hierarchical clustering\xa0', 'Image classification\xa0', 'Visual concept discovery\xa0']"
history,"['2018-01', '2017-08-24', '2016-07-08', '2017-08-07']"
abstract,"Abstract Raw visual data used to train classifiers is abundant and easy to gather, but lacks semantic labels that describe visual concepts of interest. These labels are necessary for supervised learning and can require significant human effort to collect. We discuss four labeling objectives that play an important role in the design of frameworks aimed at collecting label information for large training sets while maintaining low human effort: discovery, efficiency, exploitation and accuracy. We introduce a framework that explicitly models and balances these four labeling objectives with the use of (1) hierarchical clustering, (2) a novel interestingness measure that defines structural change within the hierarchy, and (3) an iterative group-based labeling process that exploits relationships between labeled and unlabeled data. Results  on benchmark data show that our framework collects labeled training data more efficiently than existing labeling techniques and trains higher performing visual classifiers. Further, we show that our resulting framework is fast and significantly reduces human interaction time when labeling real-world multi-concept imagery depicting outdoor environments."
journal_title,International Journal of Computer Vision
article_title,On the Beneficial Effect of Noise in Vertex Localization
keyword,"['Noising\xa0', 'Global vertices\xa0', 'Global curvature\xa0', 'Shape representation\xa0', 'Object recognition\xa0', 'Shape modeling\xa0', 'Incremental noising\xa0', 'Vertex localization\xa0']"
history,"['2018-01', '2017-09-19', '2016-04-24', '2017-07-07']"
abstract,Abstract A theoretical and experimental analysis related to the effect of noise in the task of vertex identification in unknown shapes is presented. Shapes are seen as real functions of their closed boundary. An alternative global perspective of curvature is examined providing insight into the process of noise-enabled vertex localization. The analysis reveals that noise facilitates in the localization of certain vertices. The concept of noising is thus considered and a relevant global method for localizing Global Vertices is investigated in relation to local methods under the presence of increasing noise. Theoretical analysis reveals that induced noise can indeed help localizing certain vertices if combined with global descriptors. Experiments with noise and a comparison to localized methods validate the theoretical results.
journal_title,International Journal of Computer Vision
article_title,Learning to Detect Good 3D Keypoints
keyword,"['3D Keypoint Detection\xa0', '3D Descriptors\xa0', 'Machine Learning\xa0', 'Surface Matching\xa0']"
history,"['2018-01', '2017-08-08', '2016-11-19', '2017-07-20']"
abstract,"Abstract The established approach to 3D keypoint detection consists in defining effective handcrafted saliency functions based on geometric cues with the aim of maximizing keypoint repeatability. Differently, the idea behind our work is to learn a descriptor-specific keypoint detector so as to optimize the end-to-end performance of the feature matching pipeline. Accordingly, we cast 3D keypoint detection as a classification problem between surface patches that can or cannot be matched correctly by a given 3D descriptor, i.e. those either good or not in respect to that descriptor. We propose a machine learning framework that allows for defining examples of good surface patches from the training data and leverages Random Forest classifiers to realize both fixed-scale and adaptive-scale 3D keypoint detectors. Through extensive experiments on standard datasets, we show how feature matching performance improves significantly by deploying 3D descriptors together with companion detectors learned by our methodology with respect to the adoption of established state-of-the-art 3D detectors based on hand-crafted saliency functions."
journal_title,International Journal of Computer Vision
article_title,Attentive Systems: A Survey
keyword,"['Attentive systems\xa0', 'Visual attention\xa0', 'Salient region/object detection\xa0', 'Interestingness\xa0', 'Scene understanding\xa0', 'Computer graphics\xa0', 'Image retargeting\xa0', 'Feature pooling\xa0', 'Multimedia\xa0', 'Compression\xa0']"
history,"['2018-01', '2017-09-15', '2015-07-21', '2017-09-01']"
abstract,"Abstract Visual saliency analysis detects salient regions/objects that attract human attention in natural scenes. It has attracted intensive research in different fields such as computer vision, computer graphics, and multimedia. While many such computational models exist, the focused study of what and how applications can be beneficial is still lacking. In this article, our ultimate goal is thus to provide a comprehensive review of the applications using saliency cues, the so-called attentive systems. We would like to provide a broad vision about saliency applications and what visual saliency can do. We categorize the vast amount of applications into different areas such as computer vision, computer graphics, and multimedia. Intensively covering 200+ publications we survey (1) key application trends, (2) the role of visual saliency, and (3) the usability of saliency into different tasks."
journal_title,International Journal of Computer Vision
article_title,Top-Down Neural Attention by Excitation Backprop
keyword,"['Convolutional neural network\xa0', 'Top-down attention\xa0', 'Selective tuning\xa0']"
history,"['2017-12-23', '2017-04-25', '2017-11-30']"
abstract,"Abstract We aim to model the top-down attention of a convolutional neural network (CNN) classifier for generating task-specific attention maps. Inspired by a top-down human visual attention model, we propose a new backpropagation scheme, called Excitation Backprop, to pass along top-down signals downwards in the network hierarchy via a probabilistic Winner-Take-All process. Furthermore, we introduce the concept of contrastive attention to make the top-down attention maps more discriminative. We show a theoretic connection between the proposed contrastive attention formulation and the Class Activation Map computation. Efficient implementation of Excitation Backprop for common neural network layers is also presented. In experiments, we visualize the evidence of a model’s classification decision by computing the proposed top-down attention maps. For quantitative evaluation, we report the accuracy of our method in weakly supervised localization tasks on the MS COCO, PASCAL VOC07 and ImageNet datasets. The usefulness of our method is further validated in the text-to-region association task. On the Flickr30k Entities dataset, we achieve promising performance in phrase localization by leveraging the top-down attention of a CNN model that has been trained on weakly labeled web images. Finally, we demonstrate applications of our method in model interpretation and data annotation assistance for facial expression analysis and medical imaging tasks."
journal_title,International Journal of Computer Vision
article_title,Guest Editorial: Best Papers from ICCV 2015
keyword,[]
history,"['2017-12', '2017-09-27']"
abstract,None
journal_title,International Journal of Computer Vision
article_title,Learning Image Representations Tied to Egomotion from Unlabeled Video
keyword,"['Feature Space\xa0', 'Convolutional Neural Network\xa0', 'Feature Learning\xa0', 'Temporal Coherence\xa0', 'Scene Recognition\xa0']"
history,"['2017-12', '2017-03-04', '2016-06-16', '2017-02-10']"
abstract,"Abstract Understanding how images of objects and scenes behave in response to specific egomotions is a crucial aspect of proper visual development, yet existing visual learning methods are conspicuously disconnected from the physical source of their images. We propose a new “embodied” visual learning paradigm, exploiting proprioceptive motor signals to train visual representations from egocentric video with no manual supervision. Specifically, we enforce that our learned features exhibit equivariance i.e., they respond predictably to transformations associated with distinct egomotions. With three datasets, we show that our unsupervised feature learning approach significantly outperforms previous approaches on visual recognition and next-best-view prediction tasks. In the most challenging test, we show that features learned from video captured on an autonomous driving platform improve large-scale scene recognition in static images from a disjoint domain."
journal_title,International Journal of Computer Vision
article_title,Ask Your Neurons: A Deep Learning Approach to Visual Question Answering
keyword,"['Computer vision\xa0', 'Scene understanding\xa0', 'Deep learning\xa0', 'Natural language processing\xa0', 'Visual turing test\xa0', 'Visual question answering\xa0']"
history,"['2017-12', '2017-08-29', '2016-04-30', '2017-06-22']"
abstract,"Abstract We propose a Deep Learning approach to the visual question answering task, where machines answer to questions about real-world images. By combining latest advances in image representation and natural language processing, we propose Ask Your Neurons, a scalable, jointly trained, end-to-end formulation to this problem. In contrast to previous efforts, we are facing a multi-modal problem where the language output (answer) is conditioned on visual and natural language inputs (image and question). We evaluate our approaches on the DAQUAR as well as the VQA dataset where we also report various baselines, including an analysis how much information is contained in the language part only. To study human consensus, we propose two novel metrics and collect additional answers which extend the original DAQUAR dataset to DAQUAR-Consensus. Finally, we evaluate a rich set of design choices how to encode, combine and decode information in our proposed Deep Learning formulation."
journal_title,International Journal of Computer Vision
article_title,How Good Is My Test Data? Introducing Safety Analysis for Computer Vision
keyword,"['Test data\xa0', 'Testing\xa0', 'Validation\xa0', 'Safety analysis\xa0', 'Hazard analysis\xa0', 'Stereo vision\xa0']"
history,"['2017-12', '2017-06-09', '2016-04-13', '2017-05-18']"
abstract,"Abstract Good test data is crucial for driving new developments in computer vision (CV), but two questions remain unanswered: which situations should be covered by the test data, and how much testing is enough to reach a conclusion? In this paper we propose a new answer to these questions using a standard procedure devised by the safety community to validate complex systems: the hazard and operability analysis (HAZOP). It is designed to systematically identify possible causes of system failure or performance loss. We introduce a generic CV model that creates the basis for the hazard analysis and—for the first time—apply an extensive HAZOP to the CV domain. The result is a publicly available checklist with more than 900 identified individual hazards. This checklist can be utilized to evaluate existing test datasets by quantifying the covered hazards. We evaluate our approach by first analyzing and annotating the popular stereo vision test datasets Middlebury and KITTI. Second, we demonstrate a clearly negative influence of the hazards in the checklist on the performance of six popular stereo matching algorithms. The presented approach is a useful tool to evaluate and improve test datasets and creates a common basis for future dataset designs."
journal_title,International Journal of Computer Vision
article_title,"Global, Dense Multiscale Reconstruction for a Billion Points"
keyword,"['3D reconstruction\xa0', 'Large scale\xa0', 'Finite element method\xa0', 'Adaptive grid\xa0', 'Depth map fusion\xa0']"
history,"['2017-12', '2017-06-03', '2016-04-16', '2017-05-17']"
abstract,"Abstract We present a variational approach for surface reconstruction from a set of oriented points with scale information. We focus particularly on scenarios with nonuniform point densities due to images taken from different distances. In contrast to previous methods, we integrate the scale information in the objective and globally optimize the signed distance function of the surface on a balanced octree grid. We use a finite element discretization on the dual structure of the octree minimizing the number of variables. The tetrahedral mesh is generated efficiently with a lookup table which allows to map octree cells to the nodes of the finite elements. We optimize memory efficiency by data aggregation, such that robust data terms can be used even on very large scenes. The surface normals are explicitly optimized and used for surface extraction to improve the reconstruction at edges and corners."
journal_title,International Journal of Computer Vision
article_title,Holistically-Nested Edge Detection
keyword,"['Edge detection\xa0', 'Convolutional neural networks\xa0', 'Boundary detection\xa0', 'Multi-scale learning\xa0', 'Fusion\xa0', 'Deep learning\xa0']"
history,"['2017-12', '2017-03-15', '2016-06-15', '2017-02-15']"
abstract,"Abstract We develop a new edge detection algorithm that addresses two important issues in this long-standing vision problem: (1) holistic image training and prediction; and (2) multi-scale and multi-level feature learning. Our proposed method, holistically-nested edge detection (HED), performs image-to-image prediction by means of a deep learning model that leverages fully convolutional neural networks and deeply-supervised nets. HED automatically learns rich hierarchical representations (guided by deep supervision on side responses) that are important in order to resolve the challenging ambiguity in edge and object boundary detection. We significantly advance the state-of-the-art on the BSDS500 dataset (ODS F-score of 0.790) and the NYU Depth dataset (ODS F-score of 0.746), and do so with an improved speed (0.4 s per image) that is orders of magnitude faster than some CNN-based edge detection algorithms developed before HED. We also observe encouraging results on other boundary detection benchmark datasets such as Multicue and PASCAL-Context."
journal_title,International Journal of Computer Vision
article_title,Mutual-Structure for Joint Filtering
keyword,"['Image filter\xa0', 'Mutual structure\xa0', 'Joint estimation\xa0', 'Depth refinement\xa0', 'Stereo matching\xa0']"
history,"['2017-12', '2017-06-03', '2016-04-16', '2017-05-18']"
abstract,"Abstract Previous joint/guided filters directly transfer structural information from the reference to the target image. In this paper, we analyze the major drawback—that is, there may be completely different edges in the two images. Simply considering all patterns could introduce significant errors. To address this issue, we propose the concept of mutual-structure, which refers to the structural information that is contained in both images and thus can be safely enhanced by joint filtering. We also use an untraditional objective function that can be efficiently optimized to yield mutual structure. Our method results in important edge preserving property, which greatly benefits depth completion, optical flow estimation, image enhancement, stereo matching, to name a few."
journal_title,International Journal of Computer Vision
article_title,Depth Sensing Using Geometrically Constrained Polarization Normals
keyword,"['Computational photography\xa0', 'Light transport\xa0', 'Depth sensing\xa0', 'Shape from polarization\xa0']"
history,"['2017-12', '2017-06-22', '2016-05-10', '2017-05-31']"
abstract,"Abstract Analyzing the polarimetric properties of reflected light is a potential source of shape information. However, it is well-known that polarimetric information contains fundamental shape ambiguities, leading to an underconstrained problem of recovering 3D geometry. To address this problem, we use additional geometric information, from coarse depth maps, to constrain the shape information from polarization cues. Our main contribution is a framework that combines surface normals from polarization (hereafter polarization normals) with an aligned depth map. The additional geometric constraints are used to mitigate physics-based artifacts, such as azimuthal ambiguity, refractive distortion and fronto-parallel signal degradation. We believe our work may have practical implications for optical engineering, demonstrating a new option for state-of-the-art 3D reconstruction."
journal_title,International Journal of Computer Vision
article_title,3D Time-Lapse Reconstruction from Internet Photos
keyword,"['Computational photography\xa0', 'Time-lapse\xa0', 'Internet photos\xa0']"
history,"['2017-12', '2017-03-21', '2016-04-18', '2017-02-15']"
abstract,"Abstract Given an Internet photo collection of a landmark, we compute a 3D time-lapse video sequence where a virtual camera moves continuously in time and space. While previous work assumed a static camera, the addition of camera motion during the time-lapse creates a very compelling impression of parallax. Achieving this goal, however, requires addressing multiple technical challenges, including solving for time-varying depth maps, regularizing 3D point color profiles over time, and reconstructing high quality, hole-free images at every frame from the projected profiles. Our results show photorealistic time-lapses of skylines and natural scenes over many years, with dramatic parallax effects."
journal_title,International Journal of Computer Vision
article_title,Automatic Registration of Images to Untextured Geometry Using Average Shading Gradients
keyword,"['Registration\xa0', '3D geometry\xa0', 'Gradients\xa0', 'Dense correspondence\xa0', 'Pose estimation\xa0']"
history,"['2017-12', '2017-06-06', '2016-05-19', '2017-05-18']"
abstract,"Abstract Many existing approaches for image-to-geometry registration assume that either a textured 3D model or a good initial guess of the 3D pose is available to bootstrap the registration process. In this paper we consider the registration of photographs to 3D models even when no texture information is available. This is very challenging as we cannot rely on texture gradients, and even shading gradients are hard to estimate since the lighting conditions are unknown. To that end, we propose average shading gradients, a rendering technique that estimates the average gradient magnitude over all lighting directions under Lambertian shading. We use this gradient representation as the building block of a registration pipeline based on matching sparse features. To cope with inevitable false matches due to the missing texture information and to increase robustness, the pose of the 3D model is estimated in two stages. Coarse pose hypotheses are first obtained from a single correct match each, subsequently refined using SIFT flow, and finally verified. We apply our algorithm to registering images of real-world objects to untextured 3D meshes of limited accuracy. Moreover, we show that registration can be performed even for paintings despite lacking photo-realism."
journal_title,International Journal of Computer Vision
article_title,Focal Flow: Velocity and Depth from Differential Defocus Through Motion
keyword,"['Depth\xa0', 'Optical flow\xa0', 'Defocus\xa0', 'Coded aperture\xa0', 'Ego-motion\xa0', 'Computational sensing\xa0']"
history,"['2017-11-13', '2017-04-24', '2017-10-19']"
abstract,"Abstract We present the focal flow sensor. It is an unactuated, monocular camera that simultaneously exploits defocus and differential motion to measure a depth map and a 3D scene velocity field. It does this using an optical-flow-like, per-pixel linear constraint that relates image derivatives to depth and velocity. We derive this constraint, prove its invariance to scene texture, and prove that it is exactly satisfied only when the sensor’s blur kernels are Gaussian. We analyze the inherent sensitivity of the focal flow cue, and we build and test a prototype. Experiments produce useful depth and velocity information for a broader set of aperture configurations, including a simple lens with a pillbox aperture."
journal_title,International Journal of Computer Vision
article_title,EMVS: Event-Based Multi-View Stereo—3D Reconstruction with an Event Camera in Real-Time
keyword,"['Multi-view stereo\xa0', 'Event cameras\xa0', 'Event-based vision\xa0', '3D reconstruction\xa0']"
history,"['2017-11-07', '2017-01-06', '2017-10-19']"
abstract,"Abstract Event cameras are bio-inspired vision sensors that output pixel-level brightness changes instead of standard intensity frames. They offer significant advantages over standard cameras, namely a very high dynamic range, no motion blur, and a latency in the order of microseconds. However, because the output is composed of a sequence of asynchronous events rather than actual intensity images, traditional vision algorithms cannot be applied, so that a paradigm shift is needed. We introduce the problem of event-based multi-view stereo (EMVS) for event cameras and propose a solution to it. Unlike traditional MVS methods, which address the problem of estimating dense 3D structure from a set of known viewpoints, EMVS estimates semi-dense 3D structure from an event camera with known trajectory. Our EMVS solution elegantly exploits two inherent properties of an event camera: (1) its ability to respond to scene edges—which naturally provide semi-dense geometric information without any pre-processing operation—and (2) the fact that it provides continuous measurements as the sensor moves. Despite its simplicity (it can be implemented in a few lines of code), our algorithm is able to produce accurate, semi-dense depth maps, without requiring any explicit data association or intensity estimation. We successfully validate our method on both synthetic and real data. Our method is computationally very efficient and runs in real-time on a CPU."
journal_title,International Journal of Computer Vision
article_title,Modeling Multi-object Configurations via Medial/Skeletal Linking Structures
keyword,"['Blum medial axis\xa0', 'Skeletal structures\xa0', 'Spherical axis\xa0', 'Whitney stratified sets\xa0', 'Medial and skeletal linking structures\xa0', 'Generic linking properties\xa0', 'Model configurations\xa0', 'Radial flow\xa0', 'Linking flow\xa0']"
history,"['2017-09', '2017-06-06', '2015-06-16', '2017-05-18']"
abstract,"Abstract We introduce a method for modeling a configuration of objects in 2D or 3D images using a mathematical “skeletal linking structure” which will simultaneously capture the individual shape features of the objects and their positional information relative to one another. The objects may either have smooth boundaries and be disjoint from the others or share common portions of their boundaries with other objects in a piecewise smooth manner. These structures include a special class of “Blum medial linking structures”, which are intrinsically associated to the configuration and build upon the Blum medial axes of the individual objects. We give a classification of the properties of Blum linking structures for generic configurations. The skeletal linking structures add increased flexibility for modeling configurations of objects by relaxing the Blum conditions and they extend in a minimal way the individual “skeletal structures” which have been previously used for modeling individual objects and capturing their geometric properties. This allows for the mathematical methods introduced for single objects to be significantly extended to the entire configuration of objects. These methods not only capture the internal shape structures of the individual objects but also the external structure of the neighboring regions of the objects. In the subsequent second paper (Damon and Gasparovic in Shape and positional geometry of multi-object configurations) we use these structures to identify specific external regions which capture positional information about neighboring objects, and we develop numerical measures for closeness of portions of objects and their significance for the configuration. This allows us to use the same mathematical structures to simultaneously analyze both the shape properties of the individual objects and positional properties of the configuration. This provides a framework for analyzing the statistical properties of collections of similar configurations such as for applications to medical imaging."
journal_title,International Journal of Computer Vision
article_title,"SDE: A Novel Selective, Discriminative and Equalizing Feature Representation for Visual Recognition"
keyword,"['Convolutional Neural Network\xa0', 'Feature learning\xa0', 'Pooling\xa0', 'Bag of Words\xa0', 'Bilevel optimization\xa0']"
history,"['2017-09', '2017-03-30', '2015-11-06', '2017-03-07']"
abstract,"Abstract Bag of Words (BoW) model and Convolutional Neural Network (CNN) are two milestones in visual recognition. Both BoW and CNN require a feature pooling operation for constructing the frameworks. Particularly, the max-pooling has been validated as an efficient and effective pooling method compared with other methods such as average pooling and stochastic pooling. In this paper, we first evaluate different pooling methods, and then propose a new feature pooling method termed as selective, discriminative and equalizing pooling (SDE). The SDE representation is a feature learning mechanism by jointly optimizing the pooled representations with the target of learning more selective, discriminative and equalizing features. We use bilevel optimization to solve the joint optimization problem. Experiments on seven benchmark datasets (including both single-label and multi-label ones) well validate the effectiveness of our framework. Particularly, we achieve the state-of-the-art fused results (mAP) of 93.21 and 93.97% on the PASCAL VOC2007 and VOC2012 datasets, respectively."
journal_title,International Journal of Computer Vision
article_title,DeepProposals: Hunting Objects and Actions by Cascading Deep Convolutional Layers
keyword,"['Object Proposals\xa0', 'Action proposals\xa0', 'Object detection\xa0', 'Action localization\xa0']"
history,"['2017-09', '2017-03-15', '2016-05-03', '2017-03-06']"
abstract,"Abstract In this paper, a new method for generating object and action proposals in images and videos is proposed. It builds on activations of different convolutional layers of a pretrained CNN, combining the localization accuracy of the early layers with the high informativeness (and hence recall) of the later layers. To this end, we build an inverse cascade that, going backward from the later to the earlier convolutional layers of the CNN, selects the most promising locations and refines them in a coarse-to-fine manner. The method is efficient, because (i) it re-uses the same features extracted for detection, (ii) it aggregates features using integral images, and (iii) it avoids a dense evaluation of the proposals thanks to the use of the inverse coarse-to-fine cascade. The method is also accurate. We show that DeepProposals outperform most of the previous object proposal and action proposal approaches and, when plugged into a CNN-based object detector, produce state-of-the-art detection performance."
journal_title,International Journal of Computer Vision
article_title,Uncovering the Temporal Context for Video Question Answering
keyword,"['Video sequence modeling\xa0', 'Video question answering\xa0', 'Video prediction\xa0', 'Cross-media\xa0']"
history,"['2017-09', '2017-07-13', '2016-07-18', '2017-07-04']"
abstract,"Abstract In this work, we introduce Video Question Answering in the temporal domain to infer the past, describe the present and predict the future. We present an encoder–decoder approach using Recurrent Neural Networks to learn the temporal structures of videos and introduce a dual-channel ranking loss to answer multiple-choice questions. We explore approaches for finer understanding of video content using the question form of “fill-in-the-blank”, and collect our Video Context QA dataset consisting of 109,895 video clips with a total duration of more than 1000 h from existing TACoS, MPII-MD and MEDTest 14 datasets. In addition, 390,744 corresponding questions are generated from annotations. Extensive experiments demonstrate that our approach significantly outperforms the compared baselines."
journal_title,International Journal of Computer Vision
article_title,Salient Object Subitizing
keyword,"['Salient object\xa0', 'Subitizing\xa0', 'Deep learning\xa0', 'Convolutional neural network\xa0']"
history,"['2017-09', '2017-04-12', '2016-07-10', '2017-04-03']"
abstract,"Abstract We study the problem of salient object subitizing, i.e. predicting the existence and the number of salient objects in an image using holistic cues. This task is inspired by the ability of people to quickly and accurately identify the number of items within the subitizing range (1–4). To this end, we present a salient object subitizing image dataset of about 14 K everyday images which are annotated using an online crowdsourcing marketplace. We show that using an end-to-end trained convolutional neural network (CNN) model, we achieve prediction accuracy comparable to human performance in identifying images with zero or one salient object. For images with multiple salient objects, our model also provides significantly better than chance performance without requiring any localization process. Moreover, we propose a method to improve the training of the CNN subitizing model by leveraging synthetic images. In experiments, we demonstrate the accuracy and generalizability of our CNN subitizing model and its applications in salient object detection and image retrieval."
journal_title,International Journal of Computer Vision
article_title,A Closed-Form Focus Profile Model for Conventional Digital Cameras
keyword,"['Focus measure\xa0', 'Focus profile\xa0', 'Camera model\xa0', 'Camera calibration\xa0', 'Depth of field\xa0']"
history,"['2017-09', '2017-06-06', '2016-07-31', '2017-05-29']"
abstract,"Abstract According to the thin lens model, the classic depth of field (DOF) is defined as the distance range at which objects in front of a camera are in focus. However, the thin lens poses important practical limitations for modeling the camera focus due to its dependence on internal parameters, such as the focal length, numerical aperture and effective pixel size. In this paper, a new model for describing the focus of conventional digital cameras is proposed. The focus is modeled as the energy of the point-spread-function of the imaging system and describes the joint effect of defocus, diffraction and digitization. Experiments conducted on different acquisition devices show that the proposed model conforms accurately to the behavior of real systems and outperforms the most similar alternatives in the state-of-the-art. In addition, in contrast to the classic DOF model, the proposed approach can be used to predict the changes in the focus of conventional digital cameras when changing focus, zoom, and aperture by means of a simple calibration process."
journal_title,International Journal of Computer Vision
article_title,The TPS Direct Transport: A New Method for Transporting Deformations in the Size-and-Shape Space
keyword,"['Geometric Morphometrics\xa0', 'Shape analysis\xa0', 'Inter-individual difference\xa0', 'Riemannian manifold\xa0', 'Deformation cycle\xa0', 'Parallel transport\xa0', 'Trajectory analysis\xa0', 'Thin plate spline\xa0']"
history,"['2017-09', '2017-07-01', '2016-10-03', '2017-06-13']"
abstract,"Abstract Modern shape analysis allows the fine comparison of shape changes occurring between different objects. Very often the classic machineries of generalized Procrustes analysis and principal component analysis are used in order to contrast the shape change occurring among configurations represented by homologous landmarks. However, if size and shape data are structured in different groups thus constituting different morphological trajectories, a data centering is needed if one wants to compare solely the deformation representing the trajectories. To do that, inter-individual variation must be filtered out. This maneuver is rarely applied in studies using simulated or real data. A geometrical procedure named parallel transport, that can be based on various connection types, is necessary to perform such kind of data centering. Usually, the Levi Civita connection is used for interpolation of curves in a Riemannian space. It can also be used to transport a deformation. We demonstrate that this procedure does not preserve some important characters of the deformation, even in the affine case. We propose a novel procedure called ‘TPS Direct Transport’ which is able to perfectly transport deformation in the affine case and to better approximate non affine deformation in comparison to existing tools. We recommend to center shape data using the methods described here when the differences in deformation rather than in shape are under study."
journal_title,International Journal of Computer Vision
article_title,LRA: Local Rigid Averaging of Stretchable Non-rigid Shapes
keyword,"['Non-rigid shapes\xa0', 'Metric invariants\xa0', 'Affine invariant\xa0', 'Averaging shapes\xa0', 'Shape space\xa0', 'Non-rigid statistics\xa0']"
history,"['2017-09', '2017-03-21', '2015-12-28', '2017-02-15']"
abstract,"Abstract We present a novel algorithm for generating the mean structure of non-rigid stretchable shapes. Following an alignment process, which supports local affine deformations, we translate the search of the mean shape into a diagonalization problem where the structure is hidden within the kernel of a matrix. This is the first step required in many practical applications, where one needs to model bendable and stretchable shapes from multiple observations."
journal_title,International Journal of Computer Vision
article_title,Discriminatively Learned Hierarchical Rank Pooling Networks
keyword,"['Rank pooling\xa0', 'Action recognition\xa0', 'Activity recognition\xa0', 'Convolutional neural networks\xa0']"
history,"['2017-09', '2017-06-24', '2016-09-13', '2017-06-13']"
abstract,"Abstract Rank pooling is a temporal encoding method that summarizes the dynamics of a video sequence to a single vector which has shown good results in human action recognition in prior work. In this work, we present novel temporal encoding methods for action and activity classification by extending the unsupervised rank pooling temporal encoding method in two ways. First, we present discriminative rank pooling in which the shared weights of our video representation and the parameters of the action classifiers are estimated jointly for a given training dataset of labelled vector sequences using a bilevel optimization formulation of the learning problem. When the frame level features vectors are obtained from a convolutional neural network (CNN), we rank pool the network activations and jointly estimate all parameters of the model, including CNN filters and fully-connected weights, in an end-to-end manner which we coined as end-to-end trainable rank pooled CNN. Importantly, this model can make use of any existing convolutional neural network architecture (e.g., AlexNet or VGG) without modification or introduction of additional parameters. Then, we extend rank pooling to a high capacity video representation, called hierarchical rank pooling. Hierarchical rank pooling consists of a network of rank pooling functions, which encode temporal semantics over arbitrary long video clips based on rich frame level features. By stacking non-linear feature functions and temporal sub-sequence encoders one on top of the other, we build a high capacity encoding network of the dynamic behaviour of the video. The resulting video representation is a fixed-length feature vector describing the entire video clip that can be used as input to standard machine learning classifiers. We demonstrate our approach on the task of action and activity recognition. We present a detailed analysis of our approach against competing methods and explore variants such as hierarchy depth and choice of non-linear feature function. Obtained results are comparable to state-of-the-art methods on three important activity recognition benchmarks with classification performance of 76.7% mAP on Hollywood2, 69.4% on HMDB51, and 93.6% on UCF101."
journal_title,International Journal of Computer Vision
article_title,Zero-Shot Visual Recognition via Bidirectional Latent Embedding
keyword,"['Zero-shot learning\xa0', 'Object recognition\xa0', 'Human action recognition\xa0', 'Supervised locality preserving projection\xa0', 'Landmark-based Sammon mapping\xa0', 'Multiple visual and semantic representations\xa0']"
history,"['2017-09', '2017-06-28', '2016-07-10', '2017-06-02']"
abstract,"Abstract Zero-shot learning for visual recognition, e.g., object and action recognition, has recently attracted a lot of attention. However, it still remains challenging in bridging the semantic gap between visual features and their underlying semantics and transferring knowledge to semantic categories unseen during learning. Unlike most of the existing zero-shot visual recognition methods, we propose a stagewise bidirectional latent embedding framework of two subsequent learning stages for zero-shot visual recognition. In the bottom–up stage, a latent embedding space is first created by exploring the topological and labeling information underlying training data of known classes via a proper supervised subspace learning algorithm and the latent embedding of training data are used to form landmarks that guide embedding semantics underlying unseen classes into this learned latent space. In the top–down stage, semantic representations of unseen-class labels in a given label vocabulary are then embedded to the same latent space to preserve the semantic relatedness between all different classes via our proposed semi-supervised Sammon mapping with the guidance of landmarks. Thus, the resultant latent embedding space allows for predicting the label of a test instance with a simple nearest-neighbor rule. To evaluate the effectiveness of the proposed framework, we have conducted extensive experiments on four benchmark datasets in object and action recognition, i.e., AwA, CUB-200-2011, UCF101 and HMDB51. The experimental results under comparative studies demonstrate that our proposed approach yields the state-of-the-art performance under inductive and transductive settings."
journal_title,International Journal of Computer Vision
article_title,Joint Image Denoising and Disparity Estimation via Stereo Structure PCA and Noise-Tolerant Cost
keyword,"['Stereo matching\xa0', 'Image denoising\xa0', 'Disparity estimation\xa0', 'Non-local means\xa0']"
history,"['2017-09', '2017-05-10', '2016-09-16', '2017-04-28']"
abstract,"Abstract Stereo cameras are now commonly available on cars and mobile phones. However, the captured images may suffer from low image quality under noisy conditions, producing inaccurate disparity. In this paper, we aim at jointly restoring a clean image pair and estimating the corresponding disparity. To this end, we propose a new joint framework that iteratively optimizes these two different tasks in a multiscale fashion. First, structure information between the stereo pair is utilized to denoise the images using a non-local means strategy. Second, a new noise-tolerant cost function is proposed for noisy stereo matching. These two terms are integrated into a multiscale framework in which cross-scale information is leveraged to further improve both denoising and stereo matching. Extensive experiments on datasets captured from indoor, outdoor, and low-light conditions show that the proposed method achieves superior performance than the state-of-the-art image denoising and disparity estimation methods. While it outperforms multi-image denoising methods by about 2 dB on average, it achieves a 50% error reduction over radiometric-change-robust stereo matching on the challenging KITTI dataset."
journal_title,International Journal of Computer Vision
article_title,Auto-Calibrated Gaze Estimation Using Human Gaze Patterns
keyword,"['Eye gaze estimation\xa0', 'Calibration free\xa0', 'Auto-calibration\xa0']"
history,"['2017-09', '2017-05-17', '2015-11-05', '2017-04-24']"
abstract,"Abstract We present a novel method to auto-calibrate gaze estimators based on gaze patterns obtained from other viewers. Our method is based on the observation that the gaze patterns of humans are indicative of where a new viewer will look at. When a new viewer is looking at a stimulus, we first estimate a topology of gaze points (initial gaze points). Next, these points are transformed so that they match the gaze patterns of other humans to find the correct gaze points. In a flexible uncalibrated setup with a web camera and no chin rest, the proposed method is tested on ten subjects and ten images. The method estimates the gaze points after looking at a stimulus for a few seconds with an average error below \(4.5^{\circ }\). Although the reported performance is lower than what could be achieved with dedicated hardware or calibrated setup, the proposed method still provides sufficient accuracy to trace the viewer attention. This is promising considering the fact that auto-calibration is done in a flexible setup , without the use of a chin rest, and based only on a few seconds of gaze initialization data. To the best of our knowledge, this is the first work to use human gaze patterns in order to auto-calibrate gaze estimators."
journal_title,International Journal of Computer Vision
article_title,Sentence Directed Video Object Codiscovery
keyword,"['Video\xa0', 'Object codiscovery\xa0', 'Sentences\xa0']"
history,"['2017-09', '2017-06-09', '2016-07-02', '2017-05-17']"
abstract,"Abstract Video object codiscovery can leverage the weak semantic constraint implied by sentences that describe the video content. Our codiscovery method, like other object codetection techniques, does not employ any pretrained object models or detectors. Unlike most prior work that focuses on codetecting large objects which are usually salient both in size and appearance, our method can discover small or medium sized objects as well as ones that may be occluded for part of the video. More importantly, our method can codiscover multiple object instances of different classes within a single video clip. Although the semantic information employed is usually simple and weak, it can greatly boost performance by constraining the hypothesized object locations. Experiments show promising results on three datasets: an average IoU score of 0.423 on a new dataset with 15 object classes, an average IoU score of 0.373 on a subset of CAD-120 with 5 object classes, and an average IoU score of 0.358 on a subset of MPII-Cooking with 7 object classes. Our result on this subset of MPII-Cooking improves upon those of the previous state-of-the-art methods by significant margins."
journal_title,International Journal of Computer Vision
article_title,Pose-Invariant Face Alignment via CNN-Based Dense 3D Model Fitting
keyword,"['Pose-invariant face alignment\xa0', 'CNN\xa0', 'Cascaded regressor\xa0', 'Dense model fitting\xa0', 'Mirrorability constraint\xa0']"
history,"['2017-09', '2017-04-19', '2016-06-12', '2017-04-06']"
abstract,"Abstract Pose-invariant face alignment is a very challenging problem in computer vision, which is used as a prerequisite for many facial analysis tasks, e.g., face recognition, expression recognition, and 3D face reconstruction. Recently, there have been a few attempts to tackle this problem, but still more research is needed to achieve higher accuracy. In this paper, we propose a face alignment method that aligns an image with arbitrary poses, by combining the powerful cascaded CNN regressors, 3D Morphable Model (3DMM), and mirrorability constraint. The core of our proposed method is a novel 3DMM fitting algorithm, where the camera projection matrix parameters and 3D shape parameters are estimated by a cascade of CNN-based regressors. Furthermore, we impose the mirrorability constraint during the CNN learning by employing a novel loss function inside the siamese network. The dense 3D shape enables us to design pose-invariant appearance features for effective CNN learning. Extensive experiments are conducted on the challenging large-pose face databases (AFLW and AFW), with comparison to the state of the art."
journal_title,International Journal of Computer Vision
article_title,End-to-End Learning of Deep Visual Representations for Image Retrieval
keyword,"['Deep learning\xa0', 'Instance-level retrieval\xa0', 'Visual search\xa0', 'Visual representation\xa0']"
history,"['2017-09', '2017-06-05', '2016-12-19', '2017-05-05']"
abstract,"Abstract While deep learning has become a key ingredient in the top performing methods for many computer vision tasks, it has failed so far to bring similar improvements to instance-level image retrieval. In this article, we argue that reasons for the underwhelming results of deep methods on image retrieval are threefold: (1) noisy training data, (2) inappropriate deep architecture, and (3) suboptimal training procedure. We address all three issues. First, we leverage a large-scale but noisy landmark dataset and develop an automatic cleaning method that produces a suitable training set for deep retrieval. Second, we build on the recent R-MAC descriptor, show that it can be interpreted as a deep and differentiable architecture, and present improvements to enhance it. Last, we train this network with a siamese architecture that combines three streams with a triplet loss. At the end of the training process, the proposed architecture produces a global image representation in a single forward pass that is well suited for image retrieval. Extensive experiments show that our approach significantly outperforms previous retrieval approaches, including state-of-the-art methods based on costly local descriptor indexing and spatial verification. On Oxford 5k, Paris 6k and Holidays, we respectively report 94.7, 96.6, and 94.8 mean average precision. Our representations can also be heavily compressed using product quantization with little loss in accuracy."
journal_title,International Journal of Computer Vision
article_title,Tubelets: Unsupervised Action Proposals from Spatiotemporal Super-Voxels
keyword,"['Action localization\xa0', 'Video representation\xa0', 'Action classification\xa0']"
history,"['2017-09', '2017-06-08', '2016-06-25', '2017-05-18']"
abstract,"Abstract This paper considers the problem of localizing actions in videos as sequences of bounding boxes. The objective is to generate action proposals that are likely to include the action of interest, ideally achieving high recall with few proposals. Our contributions are threefold. First, inspired by selective search for object proposals, we introduce an approach to generate action proposals from spatiotemporal super-voxels in an unsupervised manner, we call them Tubelets. Second, along with the static features from individual frames our approach advantageously exploits motion. We introduce independent motion evidence as a feature to characterize how the action deviates from the background and explicitly incorporate such motion information in various stages of the proposal generation. Finally, we introduce spatiotemporal refinement of Tubelets, for more precise localization of actions, and pruning to keep the number of Tubelets limited. We demonstrate the suitability of our approach by extensive experiments for action proposal quality and action localization on three public datasets: UCF Sports, MSR-II and UCF101. For action proposal quality, our unsupervised proposals beat all other existing approaches on the three datasets. For action localization, we show top performance on both the trimmed videos of UCF Sports and UCF101 as well as the untrimmed videos of MSR-II."
journal_title,International Journal of Computer Vision
article_title,Editorial Note
keyword,[]
history,"['2017-08', '2017-06-20']"
abstract,None
journal_title,International Journal of Computer Vision
article_title,Trajectory-Based Place-Recognition for Efficient Large Scale Localization
keyword,"['Localization\xa0', 'Loop-closure\xa0', 'Place recognition\xa0']"
history,"['2017-08', '2016-10-22', '2015-05-22', '2016-08-24']"
abstract,"Abstract Place recognition is a core competency for any visual simultaneous localization and mapping system. Identifying previously visited places enables the creation of globally accurate maps, robust relocalization, and multi-user mapping. To match one place to another, most state-of-the-art approaches must decide a priori what constitutes a place, often in terms of how many consecutive views should overlap, or how many consecutive images should be considered together. Unfortunately, such threshold dependencies limit their generality to different types of scenes. In this paper, we present a placeless place recognition algorithm using a novel match-density estimation technique that avoids heuristically discretizing the space. Instead, our approach considers place recognition as a problem of continuous matching between image streams, automatically discovering regions of high match density that represent overlapping trajectory segments. The algorithm uses well-studied statistical tests to identify the relevant matching regions which are subsequently passed to an absolute pose algorithm to recover the geometric alignment. We demonstrate the efficiency and accuracy of our methodology on three outdoor sequences, including a comprehensive evaluation against ground-truth from publicly available datasets that shows our approach outperforms several state-of-the-art algorithms for place recognition. Furthermore we compare our overall algorithm to the currently best performing system for global localization and show how we outperform the approach on challenging indoor and outdoor datasets."
journal_title,International Journal of Computer Vision
article_title,A TV Prior for High-Quality Scalable Multi-View Stereo Reconstruction
keyword,"['Multi-View Stereo\xa0', '3D Modeling\xa0', 'Scalable 3D Surface Reconstruction\xa0']"
history,"['2017-08', '2016-09-08', '2015-05-14', '2016-08-24']"
abstract,"Abstract We present a scalable multi-view stereo method able to reconstruct accurate 3D models from hundreds of high-resolution input images. Local fusion of disparity maps obtained with semi-global matching enables the reconstruction of large scenes that do not fit into main memory. Since disparity maps may vary widely in quality and resolution, careful modeling of the 3D errors is crucial. We derive a sound stereo error model based on disparity uncertainty, which can vary spatially from tenths to several pixels. We introduce a feature based on total variation that allows pixel-wise classification of disparities into different error classes. For each class, we learn a disparity error distribution from ground-truth data using expectation maximization. We present a novel method for stochastic fusion of data with varying quality by adapting a multi-resolution volumetric fusion process that uses our error classes as a prior and models surface probabilities via an octree of voxels. Conflicts during surface extraction are resolved using visibility constraints and preference for voxels at higher resolutions. Experimental results on several challenging large-scale datasets demonstrate that our method yields improved performance both qualitatively and quantitatively."
journal_title,International Journal of Computer Vision
article_title,Colour Helmholtz Stereopsis for Reconstruction of Dynamic Scenes with Arbitrary Unknown Reflectance
keyword,"['3D reconstruction\xa0', 'Dynamic scenes\xa0', 'Arbitrary BRDF\xa0', 'Helmholtz Stereopsis\xa0']"
history,"['2017-08', '2016-09-20', '2015-05-22', '2016-09-03']"
abstract,"Abstract Helmholtz Stereopsis is a powerful technique for reconstruction of scenes with arbitrary reflectance properties. However, previous formulations have been limited to static objects due to the requirement to sequentially capture reciprocal image pairs (i.e. two images with the camera and light source positions mutually interchanged). In this paper, we propose colour Helmholtz Stereopsis—a novel framework for Helmholtz Stereopsis based on wavelength multiplexing. To address the new set of challenges introduced by multispectral data acquisition, the proposed Colour Helmholtz Stereopsis pipeline uniquely combines a tailored photometric calibration for multiple camera/light source pairs, a novel procedure for spatio-temporal surface chromaticity calibration and a state-of-the-art Bayesian formulation necessary for accurate reconstruction from a minimal number of reciprocal pairs. In this framework, reflectance is spatially unconstrained both in terms of its chromaticity and the directional component dependent on the illumination incidence and viewing angles. The proposed approach for the first time enables modelling of dynamic scenes with arbitrary unknown and spatially varying reflectance using a practical acquisition set-up consisting of a small number of cameras and light sources. Experimental results demonstrate the accuracy and flexibility of the technique on a variety of static and dynamic scenes with arbitrary unknown BRDF and chromaticity ranging from uniform to arbitrary and spatially varying."
journal_title,International Journal of Computer Vision
article_title,Structure from Motion with Line Segments Under Relaxed Endpoint Constraints
keyword,"['Structure from motion\xa0', 'Line segments\xa0', 'Line segment matching\xa0', 'Visual odometry\xa0']"
history,"['2017-08', '2016-11-25', '2015-05-22', '2016-11-12']"
abstract,"Abstract We present a novel structure from motion pipeline, which estimates motion and wiry 3D structure from imaged line segments across multiple views. Although the position and orientation of line segments can be determined more accurately than point features, the instability of their endpoints and the fact that lines are not constrained by epipolar geometry diverted most research focus away to point-based methods. In our approach, we tackle the problem of instable endpoints by utilizing relaxed constraints on their positions, both during matching and as well in the following bundle adjustment stage. Furthermore, we gain efficiency in estimating trifocal image relations by decoupling rotation and translation. To this end, a novel linear solver for relative translation estimation given rotations from five line correspondences in three views is introduced. Extensive experiments on long image sequences show that our line-based structure from motion pipeline advantageously complements point-based methods, giving more meaningful 3D representation for indoor scenarios."
journal_title,International Journal of Computer Vision
article_title,Multi-view Performance Capture of Surface Details
keyword,"['Performance capture\xa0', 'Surface detail\xa0', 'Sums of Gaussian\xa0']"
history,"['2017-08', '2017-01-21', '2015-05-22', '2016-11-29']"
abstract,"Abstract This paper presents a novel approach to recover true fine surface detail of deforming meshes reconstructed from multi-view video. Template-based methods for performance capture usually produce a coarse-to-medium scale detail 4D surface reconstruction which does not contain the real high-frequency geometric detail present in the original video footage. Fine scale deformation is often incorporated in a second pass by using stereo constraints, features, or shading-based refinement. In this paper, we propose an alternative solution to this second stage by formulating dense dynamic surface reconstruction as a global optimization problem of the densely deforming surface. Our main contribution is an implicit representation of a deformable mesh that uses a set of Gaussian functions on the surface to represent the initial coarse mesh, and a set of Gaussians for the images to represent the original captured multi-view images. We effectively find the fine scale deformations for all mesh vertices, which maximize photo-temporal-consistency, by densely optimizing our model-to-image consistency energy on all vertex positions. Our formulation yields a smooth closed form energy with implicit occlusion handling and analytic derivatives. Furthermore, it does not require error-prone correspondence finding or discrete sampling of surface displacement values. We demonstrate our approach on a variety of datasets of human subjects wearing loose clothing and performing different motions. We qualitatively and quantitatively demonstrate that our technique successfully reproduces finer detail than the input baseline geometry."
journal_title,International Journal of Computer Vision
article_title,Real-Time Tracking of Single and Multiple Objects from Depth-Colour Imagery Using 3D Signed Distance Functions
keyword,"['Multi-object tracking\xa0', 'Depth tracking\xa0', 'RGB-D imagery\xa0', 'Signed distance functions\xa0', 'Real-time\xa0']"
history,"['2017-08', '2017-01-11', '2015-05-22', '2016-11-29']"
abstract,"Abstract We describe a novel probabilistic framework for real-time tracking of multiple objects from combined depth-colour imagery. Object shape is represented implicitly using 3D signed distance functions. Probabilistic generative models based on these functions are developed to account for the observed RGB-D imagery, and tracking is posed as a maximum a posteriori problem. We present first a method suited to tracking a single rigid 3D object, and then generalise this to multiple objects by combining distance functions into a shape union in the frame of the camera. This second model accounts for similarity and proximity between objects, and leads to robust real-time tracking without recourse to bolt-on or ad-hoc collision detection."
journal_title,International Journal of Computer Vision
article_title,Feedback and Surround Modulated Boundary Detection
keyword,"['Boundary detection\xa0', 'Surround modulation\xa0', 'Biologically-inspired vision\xa0']"
history,"['2017-07-27', '2017-01-06', '2017-07-11']"
abstract,"Abstract Edges are key components of any visual scene to the extent that we can recognise objects merely by their silhouettes. The human visual system captures edge information through neurons in the visual cortex that are sensitive to both intensity discontinuities and particular orientations. The “classical approach” assumes that these cells are only responsive to the stimulus present within their receptive fields, however, recent studies demonstrate that surrounding regions and inter-areal feedback connections influence their responses significantly. In this work we propose a biologically-inspired edge detection model in which orientation selective neurons are represented through the first derivative of a Gaussian function resembling double-opponent cells in the primary visual cortex (V1). In our model we account for four kinds of receptive field surround, i.e. full, far, iso- and orthogonal-orientation, whose contributions are contrast-dependant. The output signal from V1 is pooled in its perpendicular direction by larger V2 neurons employing a contrast-variant centre-surround kernel. We further introduce a feedback connection from higher-level visual areas to the lower ones. The results of our model on three benchmark datasets show a big improvement compared to the current non-learning and biologically-inspired state-of-the-art algorithms while being competitive to the learning-based methods."
journal_title,International Journal of Computer Vision
article_title,A Branch-and-Bound Framework for Unsupervised Common Event Discovery
keyword,"['Common event discovery\xa0', 'Synchrony discovery\xa0', 'Video indexing\xa0', 'Event detection\xa0', 'Human interaction\xa0', 'Unsupervised learning\xa0', 'Global optimization\xa0', 'Branch and bound\xa0', 'Bag-of-words\xa0']"
history,"['2017-07', '2017-02-09', '2016-06-03', '2017-01-12']"
abstract,"Abstract Event discovery aims to discover a temporal segment of interest, such as human behavior, actions or activities. Most approaches to event discovery within or between time series use supervised learning. This becomes problematic when relevant event labels are unknown, are difficult to detect, or not all possible combinations of events have been anticipated. To overcome these problems, this paper explores Common Event Discovery (CED), a new problem that aims to discover common events of variable-length segments in an unsupervised manner. A potential solution to CED is searching over all possible pairs of segments, which would incur a prohibitive quartic cost. In this paper, we propose an efficient branch-and-bound (B&B) framework that avoids exhaustive search while guaranteeing a globally optimal solution. To this end, we derive novel bounding functions for various commonality measures and provide extensions to multiple commonality discovery and accelerated search. The B&B framework takes as input any multidimensional signal that can be quantified into histograms. A generalization of the framework can be readily applied to discover events at the same or different times (synchrony and event commonality, respectively). We consider extensions to video search and supervised event detection. The effectiveness of the B&B framework is evaluated in motion capture of deliberate behavior and in video of spontaneous facial behavior in diverse interpersonal contexts: interviews, small groups of young adults, and parent-infant face-to-face interaction."
journal_title,International Journal of Computer Vision
article_title,Transductive Zero-Shot Action Recognition by Word-Vector Embedding
keyword,"['Zero-shot action recognition\xa0', 'Zero-shot learning\xa0', 'Semantic embedding\xa0', 'Semi-supervised learning\xa0', 'Transfer learning\xa0', 'Action recognition\xa0']"
history,"['2017-07', '2017-01-10', '2015-10-23', '2016-12-20']"
abstract,"Abstract The number of categories for action recognition is growing rapidly and it has become increasingly hard to label sufficient training data for learning conventional models for all categories. Instead of collecting ever more data and labelling them exhaustively for all categories, an attractive alternative approach is “zero-shot learning” (ZSL). To that end, in this study we construct a mapping between visual features and a semantic descriptor of each action category, allowing new categories to be recognised in the absence of any visual training data. Existing ZSL studies focus primarily on still images, and attribute-based semantic representations. In this work, we explore word-vectors as the shared semantic space to embed videos and category labels for ZSL action recognition. This is a more challenging problem than existing ZSL of still images and/or attributes, because the mapping between video space-time features of actions and the semantic space is more complex and harder to learn for the purpose of generalising over any cross-category domain shift. To solve this generalisation problem in ZSL action recognition, we investigate a series of synergistic strategies to improve upon the standard ZSL pipeline. Most of these strategies are transductive in nature which means access to testing data in the training phase. First, we enhance significantly the semantic space mapping by proposing manifold-regularized regression and data augmentation strategies. Second, we evaluate two existing post processing strategies (transductive self-training and hubness correction), and show that they are complementary. We evaluate extensively our model on a wide range of human action datasets including HMDB51, UCF101, Olympic Sports and event datasets including CCV and TRECVID MED 13. The results demonstrate that our approach achieves the state-of-the-art zero-shot action recognition performance with a simple and efficient pipeline, and without supervised annotation of attributes. Finally, we present in-depth analysis into why and when zero-shot works, including demonstrating the ability to predict cross-category transferability in advance."
journal_title,International Journal of Computer Vision
article_title,Visual Object Detection Using Cascades of Binary and One-Class Classifiers
keyword,"['Object detection\xa0', 'Rejection cascade\xa0', 'One-Class Classifier\xa0', 'Latent training\xa0']"
history,"['2017-07', '2017-01-11', '2014-11-08', '2016-12-23']"
abstract,"Abstract We describe an efficient approach to visual object detection that uses short cascades of asymmetric ‘one class’ classifiers to quickly reject negatives (windows not centered on an object of the desired class) within a sliding window framework. Current detectors typically use binary discriminants such as Support Vector Machines or Boosting to implement each stage of the cascade. These treat the positive and negative classes symmetrically. We argue that this is suboptimal because object detectors typically see a great many negative windows with extremely diverse contents and only a few positive ones with comparatively coherent contents. We show that asymmetric representations that focus on tightly modeling the extent of the rare, coherent positive class can lead to simpler classifiers and faster rejection. Our cascades use asymmetric classifiers based on simple convex models to progressively tighten the bound on the positive class. They typically start with a conventional linear SVM for initial pruning, followed by a cascade of linear distance-to-hyperplane and interior-of-hypersphere classifiers and finishing with a kernelized hypersphere classifier. We show that the resulting detectors have competitive performance on the Labeled Faces in the Wild dataset and state-of-the-art performance on the FDDB face detection, ESOGU face detection and INRIA Person datasets. The results on the PASCAL VOC 2007 dataset are also respectable given that they use neither object parts nor context. The one-class formulations provide significant reductions in classifier complexity relative to the corresponding two-class ones, making them suitable for real-world applications."
journal_title,International Journal of Computer Vision
article_title,Exemplar-Guided Similarity Learning on Polynomial Kernel Feature Map for Person Re-identification
keyword,"['Explicit polynomial kernel feature map\xa0', 'Exemplar-guided similarity function\xa0', 'Multiple visual cues\xa0', 'Similarity learning\xa0', 'Person re-identification\xa0']"
history,"['2017-07', '2017-02-13', '2015-09-10', '2017-01-20']"
abstract,"Abstract Person re-identification is a crucial problem for video surveillance, aiming to discover the correct matches for a probe person image from a set of gallery person images. To directly describe the image pair, we present a novel organization of polynomial kernel feature map in a high dimensional feature space to break down the variability of positive person pairs. An exemplar-guided similarity function is built on the map, which consists of multiple sub-functions. Each sub-function is associated with an “exemplar” image being responsible for a particular type of image pair, thus excels at separating the persons with similar appearance. We formulate a unified learning problem including a relaxed loss term as well as two kinds of regularization strategies particularly designed for the feature map. The corresponding optimization algorithm jointly optimizes the coefficients of all the sub-functions and selects the proper exemplars for a better discrimination. The proposed method is extensively evaluated on six public datasets, where we thoroughly analyze the contribution of each component and verify the generalizability of our approach by cross-dataset experiments. Results  show that the new method can achieve consistent improvements over state-of-the-art methods."
journal_title,International Journal of Computer Vision
article_title,Empowering Simple Binary Classifiers for Image Set Based Face Recognition
keyword,"['Image set classification\xa0', 'Binary to multi-class classification\xa0', 'Video based face recognition\xa0', 'Object recognition\xa0']"
history,"['2017-07', '2017-02-28', '2015-10-06', '2017-02-10']"
abstract,"Abstract Face recognition from image sets has numerous real-life applications including recognition from security and surveillance systems, multi-view camera networks and personal albums. An image set is an unordered collection of images (e.g., video frames, images acquired over long term observations and personal albums) which exhibits a wide range of appearance variations. The main focus of the previously developed methods has therefore been to find a suitable representation to optimally model these variations. This paper argues that such a representation could not necessarily encode all of the information contained in the set. The paper, therefore, suggests a different approach which does not resort to a single representation of an image set. Instead, the images of the set are retained in their original form and an efficient classification strategy is developed which extends well-known simple binary classifiers for the task of multi-class image set classification. Unlike existing binary to multi-class extension strategies, which require multiple binary classifiers to be trained over a large number of images, the proposed approach is efficient since it trains only few binary classifiers on very few images. Extensive experiments and comparisons with existing methods show that the proposed approach achieves state of the art performance for image set classification based face and object recognition on a number of challenging datasets."
journal_title,International Journal of Computer Vision
article_title,Crowd Behavior Analysis via Curl and Divergence of Motion Trajectories
keyword,"['Crowd behavior analysis\xa0', 'Curl\xa0', 'Divergence\xa0', 'Motion trajectories\xa0', 'Motion coding\xa0', 'Path integration\xa0']"
history,"['2017-07', '2017-03-13', '2015-10-08', '2017-02-21']"
abstract,"Abstract In the field of crowd behavior analysis, existing methods mainly focus on using local representations inspired by models found in other disciplines (e.g., fluid dynamics and social dynamics) to describe motion patterns. However, less attention is paid to exploiting motion structures (e.g., visual information contained in trajectories) for behavior analysis. In this paper, we consider both local characteristics and global structures of a motion vector field, and propose the Curl and Divergence of motion Trajectories (CDT) descriptors to describe collective motion patterns. To this end, a trajectory-based motion coding algorithm is designed to extract the CDT descriptors. For each motion vector field we construct its conjugate field, in which each vector is perpendicular to the counterpart in the original vector field. The trajectories in the motion and corresponding conjugate fields indicate the tangential and radial motion structures, respectively. By integrating curl (and divergence, respectively) along the tangential paths (and the radial paths, respectively), the CDT descriptors are extracted. We show that the proposed motion descriptors are scale- and rotation-invariant for effective crowd behavior analysis. For concreteness, we apply the CDT descriptors to identify five typical crowd behaviors (lane, clockwise arch, counterclockwise arch, bottleneck and fountainhead) with a pipeline including motion decomposition. Extensive experimental results on two benchmark datasets demonstrate the effectiveness of the CDT descriptors for describing and classifying crowd behaviors."
journal_title,International Journal of Computer Vision
article_title,Iterative Multiplicative Filters for Data Labeling
keyword,"['Labeling\xa0', 'Supervised partitioning\xa0', 'Multiplicative filter\xa0', 'Partitioning\xa0', 'Manifold-valued images\xa0']"
history,"['2017-07', '2017-02-17', '2016-04-29', '2017-02-01']"
abstract,"Abstract Based on an idea in Åström et al. (J Math ImagingVis, doi: 10.1007/s10851-016-0702-4, 2017) we propose a new iterative multiplicative filtering algorithm for label assignment matrices which can be used for the supervised partitioning of data. Starting with a row-normalized matrix containing the averaged distances between prior features and observed ones, the method assigns in a very efficient way labels to the data. We interpret the algorithm as a gradient ascent method with respect to a certain function on the product manifold of positive numbers followed by a reprojection onto a subset of the probability simplex consisting of vectors whose components are bounded away from zero by a small constant. While such boundedness away from zero is necessary to avoid an arithmetic underflow, our convergence results imply that they are also necessary for theoretical reasons. Numerical examples show that the proposed simple and fast algorithm leads to very good results. In particular we apply the method for the partitioning of manifold-valued images."
journal_title,International Journal of Computer Vision
article_title,Directed Acyclic Graph Continuous Max-Flow Image Segmentation for Unconstrained Label Orderings
keyword,"['Continuous max-flow\xa0', 'Image segmentation\xa0', 'Convex optimization\xa0', 'Variational optimization\xa0', 'ASETS\xa0']"
history,"['2017-07', '2017-02-17', '2015-11-30', '2017-02-01']"
abstract,"Abstract Label ordering, the specification of subset–superset relationships for segmentation labels, has been of increasing interest in image segmentation as they allow for complex regions to be represented as a collection of simple parts. Recent advances in continuous max-flow segmentation have widely expanded the possible label orderings from binary background/foreground problems to extendable frameworks in which the label ordering can be specified. This article presents Directed Acyclic Graph Max-Flow image segmentation which is flexible enough to incorporate any label ordering without constraints. This framework uses augmented Lagrangian multipliers and primal–dual optimization to develop a highly parallelized solver implemented using GPGPU. This framework is validated on synthetic, natural, and medical images illustrating its general applicability."
journal_title,International Journal of Computer Vision
article_title,"Lie-X: Depth Image Based Articulated Object Pose Estimation, Tracking, and Action Recognition on Lie Groups"
keyword,"['Depth images\xa0', 'Pose estimation\xa0', 'Fish\xa0', 'Mouse\xa0', 'Human hand\xa0', 'Lie group\xa0']"
history,"['2017-07', '2017-02-23', '2016-09-14', '2017-02-06']"
abstract,"Abstract Pose estimation, tracking, and action recognition of articulated objects from depth images are important and challenging problems, which are normally considered separately. In this paper, a unified paradigm based on Lie group theory is proposed, which enables us to collectively address these related problems. Our approach is also applicable to a wide range of articulated objects. Empirically it is evaluated on lab animals including mouse and fish, as well as on human hand. On these applications, it is shown to deliver competitive results compared to the state-of-the-arts, and non-trivial baselines including convolutional neural networks and regression forest methods. Moreover, new sets of annotated depth data of articulated objects are created which, together with our code, are made publicly available."
journal_title,International Journal of Computer Vision
article_title,Max-Margin Heterogeneous Information Machine for RGB-D Action Recognition
keyword,"['Action recognition\xa0', 'RGB-D videos\xa0', 'Heterogeneous data\xa0', 'Feature learning\xa0']"
history,"['2017-07', '2017-01-21', '2016-02-12', '2016-12-10']"
abstract,"Abstract We propose a novel approach, max-margin heterogeneous information machine (MMHIM), for human action recognition from RGB-D videos. MMHIM fuses heterogeneous RGB visual features and depth features, and learns effective action classifiers using the fused features. Rich heterogeneous visual and depth data are effectively compressed and projected to a learned shared space and independent private spaces, in order to reduce noise and capture useful information for recognition. Knowledge from various sources can then be shared with others in the learned space to learn cross-modal features. This guides the discovery of valuable information for recognition. To capture complex spatiotemporal structural relationships in visual and depth features, we represent both RGB and depth data in a matrix form. We formulate the recognition task as a low-rank bilinear model composed of row and column parameter matrices. The rank of the model parameter is minimized to build a low-rank classifier, which is beneficial for improving the generalization power. We also extend MMHIM to a structured prediction model that is capable of making structured outputs. Extensive experiments on a new RGB-D action dataset and two other public RGB-D action datasets show that our approaches achieve state-of-the-art results. Promising results are also shown if RGB or depth data are missing in training or testing procedure."
journal_title,International Journal of Computer Vision
article_title,Parametric Surface Representation with Bump Image for Dense 3D Modeling Using an RBG-D Camera
keyword,"['3D modeling\xa0', 'Consumer depth camera\xa0', 'Bump image\xa0', 'Real-time\xa0', 'Parametric surface\xa0']"
history,"['2017-06', '2016-11-19', '2015-09-23', '2016-11-01']"
abstract,"Abstract When constructing a dense 3D model of an indoor static scene from a sequence of RGB-D images, the choice of the 3D representation (e.g. 3D mesh, cloud of points or implicit function) is of crucial importance. In the last few years, the volumetric truncated signed distance function (TSDF) and its extensions have become popular in the community and largely used for the task of dense 3D modelling using RGB-D sensors. However, as this representation is voxel based, it offers few possibilities for manipulating and/or editing the constructed 3D model, which limits its applicability. In particular, the amount of data required to maintain the volumetric TSDF rapidly becomes huge which limits possibilities for portability. Moreover, simplifications (such as mesh extraction and surface simplification) significantly reduce the accuracy of the 3D model (especially in the color space), and editing the 3D model is difficult. We propose a novel compact, flexible and accurate 3D surface representation based on parametric surface patches augmented by geometric and color texture images. Simple parametric shapes such as planes are roughly fitted to the input depth images, and the deviations of the 3D measurements to the fitted parametric surfaces are fused into a geometric texture image (called the Bump image). A confidence and color texture image are also built. Our 3D scene representation is accurate yet memory efficient. Moreover, updating or editing the 3D model becomes trivial since it is reduced to manipulating 2D images. Our experimental results demonstrate the advantages of our proposed 3D representation through a concrete indoor scene reconstruction application."
journal_title,International Journal of Computer Vision
article_title,Generating Fluttering Patterns with Low Autocorrelation for Coded Exposure Imaging
keyword,"['Coded exposure\xa0', 'Fluttering pattern\xa0', 'Motion deblurring\xa0', 'Computational photography\xa0']"
history,"['2017-06', '2016-12-23', '2016-02-23', '2016-11-17']"
abstract,"Abstract The performance of coded exposure imaging critically depends on finding good binary sequences. Previous coded exposure imaging methods have mostly relied on random searching to find the binary codes, but that approach can easily fail to find good long sequences, due to the exponentially expanding search space. In this paper, we present two algorithms for generating the binary sequences, which are especially well suited for generating short and long binary sequences, respectively. We show that the concept of low autocorrelation binary sequences, which has been successfully exploited in the field of information theory, can be applied to generate shutter fluttering patterns. We also propose a new measure for good binary sequences. Based on the new measure, we introduce two new algorithms for coded exposure imaging - a modified Legendre sequence method and a memetic algorithm. Experiments using both synthetic and real data show that our new algorithms consistently generate better binary sequences for the coded exposure problem, yielding better deblurring and resolution enhancement results compared to previous methods of generating the binary codes."
journal_title,International Journal of Computer Vision
article_title,A Comprehensive and Versatile Camera Model for Cameras with Tilt Lenses
keyword,"['Camera models\xa0', 'Tilt lenses\xa0', 'Scheimpflug optics\xa0', 'Camera model degeneracies\xa0', 'Camera calibration\xa0', 'Bias removal\xa0', 'Stereo rectification\xa0']"
history,"['2017-06', '2016-10-22', '2016-03-14', '2016-09-30']"
abstract,"Abstract We propose camera models for cameras that are equipped with lenses that can be tilted in an arbitrary direction (often called Scheimpflug optics). The proposed models are comprehensive: they can handle all tilt lens types that are in common use for machine vision and consumer cameras and correctly describe the imaging geometry of lenses for which the ray angles in object and image space differ, which is true for many lenses. Furthermore, they are versatile since they can also be used to describe the rectification geometry of a stereo image pair in which one camera is perspective and the other camera is telecentric. We also examine the degeneracies of the models and propose methods to handle the degeneracies. Furthermore, we examine the relation of the proposed camera models to different classes of projective camera matrices and show that all classes of projective cameras can be interpreted as cameras with tilt lenses in a natural manner. In addition, we propose an algorithm that can calibrate an arbitrary combination of perspective and telecentric cameras (no matter whether they are tilted or untilted). The calibration algorithm uses a planar calibration object with circular control points. It is well known that circular control points may lead to biased calibration results. We propose two efficient algorithms to remove the bias and thus obtain accurate calibration results. Finally, we perform an extensive evaluation of the proposed camera models and calibration algorithms that establishes the validity and accuracy of the proposed models."
journal_title,International Journal of Computer Vision
article_title,Towards Reversal-Invariant Image Representation
keyword,"['Image classification\xa0', 'BoF\xa0', 'CNN\xa0', 'Reversal-invariant image representation\xa0']"
history,"['2017-06', '2016-11-28', '2016-02-10', '2016-11-01']"
abstract,"Abstract State-of-the-art image classification approaches are mainly based on robust image representation, such as the bag-of-features (BoF) model or the convolutional neural network (CNN) architecture. In real applications, the orientation (left/right) of an image or an object might vary from sample to sample, whereas some handcrafted descriptors (e.g., SIFT) and network operations (e.g., convolution) are not reversal-invariant, leading to the unsatisfied stability of image features extracted from these models. To deal with, a popular solution is to augment the dataset by adding a left-right reversed copy for each image. This strategy improves the recognition accuracy to some extent, but also brings the price of almost doubled time and memory consumptions on both the training and testing stages. In this paper, we present an alternative solution based on designing reversal-invariant representation of local patterns, so that we can obtain the identical representation for an image and its left-right reversed copy. For the BoF model, we design a reversal-invariant version of SIFT descriptor named Max-SIFT, a generalized RIDE algorithm which can be applied to a large family of local descriptors. For the CNN architecture, we present a simple idea of generating reversal-invariant deep features (RI-Deep), and, inspired by which, design reversal-invariant convolution (RI-Conv) layers to increase the CNN capacity without increasing the model complexity. Experiments reveal consistent accuracy gain on various image classification tasks, including scene understanding, fine-grained object recognition, and large-scale visual recognition."
journal_title,International Journal of Computer Vision
article_title,Markov Chain Monte Carlo for Automated Face Image Analysis
keyword,"['Face image analysis\xa0', 'Markov chain Monte Carlo\xa0', 'Model fitting\xa0', 'Morphable Model\xa0', 'Generative models\xa0', 'Top-down and bottom-up integration\xa0']"
history,"['2017-06', '2016-11-02', '2015-07-07', '2016-10-17']"
abstract,"Abstract We present a novel fully probabilistic method to interpret a single face image with the 3D Morphable Model. The new method is based on Bayesian inference and makes use of unreliable image-based information. Rather than searching a single optimal solution, we infer the posterior distribution of the model parameters given the target image. The method is a stochastic sampling algorithm with a propose-and-verify architecture based on the Metropolis–Hastings algorithm. The stochastic method can robustly integrate unreliable information and therefore does not rely on feed-forward initialization. The integrative concept is based on two ideas, a separation of proposal moves and their verification with the model (Data-Driven Markov Chain Monte Carlo), and filtering with the Metropolis acceptance rule. It does not need gradients and is less prone to local optima than standard fitters. We also introduce a new collective likelihood which models the average difference between the model and the target image rather than individual pixel differences. The average value shows a natural tendency towards a normal distribution, even when the individual pixel-wise difference is not Gaussian. We employ the new fitting method to calculate posterior models of 3D face reconstructions from single real-world images. A direct application of the algorithm with the 3D Morphable Model leads us to a fully automatic face recognition system with competitive performance on the Multi-PIE database without any database adaptation."
journal_title,International Journal of Computer Vision
article_title,Salient Object Detection: A Discriminative Regional Feature Integration Approach
keyword,"['Salient object detection\xa0', 'Data-driven\xa0']"
history,"['2017-06', '2016-12-05', '2016-02-15', '2016-11-19']"
abstract,"Abstract Feature integration provides a computational framework for saliency detection, and a lot of hand-crafted integration rules have been developed. In this paper, we present a principled extension, supervised feature integration, which learns a random forest regressor to discriminatively integrate the saliency features for saliency computation. In addition to contrast features, we introduce regional object-sensitive descriptors: the objectness descriptor characterizing the common spatial and appearance property of the salient object, and the image-specific backgroundness descriptor characterizing the appearance of the background of a specific image, which are shown more important for estimating the saliency. To the best of our knowledge, our supervised feature integration framework is the first successful approach to perform the integration over the saliency features for salient object detection, and outperforms the integration approach over the saliency maps. Together with fusing the multi-level regional saliency maps to impose the spatial saliency consistency, our approach significantly outperforms state-of-the-art methods on seven benchmark datasets. We also discuss several followup works which jointly learn the representation and the saliency map using deep learning."
journal_title,International Journal of Computer Vision
article_title,Structured Learning of Binary Codes with Column Generation for Optimizing Ranking Measures
keyword,"['Binary code\xa0', 'Hashing\xa0', 'Nearest neighbor search\xa0', 'Ranking\xa0', 'Structured learning\xa0']"
history,"['2017-06', '2017-01-10', '2015-08-11', '2016-12-20']"
abstract,"Abstract Hashing methods aim to learn a set of hash functions which map the original features to compact binary codes with similarity preserving in the Hamming space. Hashing has proven a valuable tool for large-scale information retrieval. We propose a column generation based binary code learning framework for data-dependent hash function learning. Given a set of triplets that encode the pairwise similarity comparison information, our column generation based method learns hash functions that preserve the relative comparison relations within the large-margin learning framework. Our method iteratively learns the best hash functions during the column generation procedure. Existing hashing methods optimize over simple objectives such as the reconstruction error or graph Laplacian related loss functions, instead of the performance evaluation criteria of interest—multivariate performance measures such as the AUC and NDCG. Our column generation based method can be further generalized from the triplet loss to a general structured learning based framework that allows one to directly optimize multivariate performance measures. For optimizing general ranking measures, the resulting optimization problem can involve exponentially or infinitely many variables and constraints, which is more challenging than standard structured output learning. We use a combination of column generation and cutting-plane techniques to solve the optimization problem. To speed-up the training we further explore stage-wise training and propose to optimize a simplified NDCG loss for efficient inference. We demonstrate the generality of our method by applying it to ranking prediction and image retrieval, and show that it outperforms several state-of-the-art hashing methods."
journal_title,International Journal of Computer Vision
article_title,"Particle-SfT: A Provably-Convergent, Fast Shape-from-Template Algorithm"
keyword,"['convergent\xa0', 'fast\xa0', 'isometric\xa0', 'elastic\xa0', 'particle\xa0', 'shape-from-template\xa0']"
history,"['2017-06', '2016-11-03', '2016-03-21', '2016-10-17']"
abstract,"Abstract The Shape-from-Template (SfT) problem is to recover the 3D shape of a deformable object from a single image, given a 3D template and a deformation constraint. We propose Particle-SfT, a new SfT algorithm which handles isometric and non-isometric deformations. We build Particle-SfT upon a particle system guided by deformation and reprojection constraint projections. Reconstruction is achieved by evolving particles to a globally attractive equilibrium, while taking observable external forces such as gravity into account, if any. Particle-SfT may be used to refine an existing initial shape. However, in practice we simply use the template as initial guess. This is because, as opposed to the existing refining methods, Particle-SfT has an extremely wide convergence basin. Particle-SfT is also faster than the existing refining methods. This is because it moves pieces of the shape’s mesh independently to achieve larger step size by optimal constraint projection. We proved its convergence to a fixed-point. We experimented it with synthetic and real data. It has the same accuracy as the best performing isometric method and consistently outperforms all existing elastic methods in almost all cases, while being much faster."
journal_title,International Journal of Computer Vision
article_title,Guest Editorial: Image and Language Understanding
keyword,[]
history,"['2017-05', '2017-03-31']"
abstract,None
journal_title,International Journal of Computer Vision
article_title,"Recognition, Tracking, and Optimisation"
keyword,[]
history,"['2017-05', '2017-03-23']"
abstract,None
journal_title,International Journal of Computer Vision
article_title,VQA: Visual Question Answering
keyword,['Visual Question Answering\xa0']
history,"['2017-05', '2016-11-08', '2016-04-04', '2016-10-07']"
abstract,"Abstract We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer. Mirroring real-world scenarios, such as helping the visually impaired, both the questions and answers are open-ended. Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions. Moreover, VQA is amenable to automatic evaluation, since many open-ended answers contain only a few words or a closed set of answers that can be provided in a multiple-choice format. We provide a dataset containing \(\sim \)0.25 M images, \(\sim \)0.76 M questions, and \(\sim \)10 M answers (www.visualqa.org), and discuss the information it provides. Numerous baselines and methods for VQA are provided and compared with human performance. Our VQA demo is available on CloudCV (http://cloudcv.org/vqa)."
journal_title,International Journal of Computer Vision
article_title,Sketch-a-Net: A Deep Neural Network that Beats Humans
keyword,"['Sketch recognition\xa0', 'Convolutional neural network\xa0', 'Data augmentation\xa0', 'Stroke ordering\xa0', 'Sketch abstraction\xa0']"
history,"['2017-05', '2016-07-26', '2015-12-18', '2016-07-06']"
abstract,"Abstract We propose a deep learning approach to free-hand sketch recognition that achieves state-of-the-art performance, significantly surpassing that of humans. Our superior performance is a result of modelling and exploiting the unique characteristics of free-hand sketches, i.e., consisting of an ordered set of strokes but lacking visual cues such as colour and texture, being highly iconic and abstract, and exhibiting extremely large appearance variations due to different levels of abstraction and deformation. Specifically, our deep neural network, termed Sketch-a-Net has the following novel components: (i) we propose a network architecture designed for sketch rather than natural photo statistics. (ii) Two novel data augmentation strategies are developed which exploit the unique sketch-domain properties to modify and synthesise sketch training data at multiple abstraction levels. Based on this idea we are able to both significantly increase the volume and diversity of sketches for training, and address the challenge of varying levels of sketching detail commonplace in free-hand sketches. (iii) We explore different network ensemble fusion strategies, including a re-purposed joint Bayesian scheme, to further improve recognition performance. We show that state-of-the-art deep networks specifically engineered for photos of natural objects fail to perform well on sketch recognition, regardless whether they are trained using photos or sketches. Furthermore, through visualising the learned filters, we offer useful insights in to where the superior performance of our network comes from."
journal_title,International Journal of Computer Vision
article_title,Learning Optimal Parameters for Multi-target Tracking with Contextual Interactions
keyword,"['Multi-target tracking\xa0', 'Data association\xa0', 'Network-flow\xa0', 'Structured prediction\xa0']"
history,"['2017-05', '2016-10-12', '2015-12-20', '2016-09-20']"
abstract,"Abstract We describe an end-to-end framework for learning parameters of min-cost flow multi-target tracking problem with quadratic trajectory interactions including suppression of overlapping tracks and contextual cues about co-occurrence of different objects. Our approach utilizes structured prediction with a tracking-specific loss function to learn the complete set of model parameters. In this learning framework, we evaluate two different approaches to finding an optimal set of tracks under a quadratic model objective, one based on an linear program (LP) relaxation and the other based on novel greedy variants of dynamic programming that handle pairwise interactions. We find the greedy algorithms achieve almost equivalent accuracy to the LP relaxation while being up to 10\(\times \) faster than a commercial LP solver. We evaluate trained models on three challenging benchmarks. Surprisingly, we find that with proper parameter learning, our simple data association model without explicit appearance/motion reasoning is able to achieve comparable or better accuracy than many state-of-the-art methods that use far more complex motion features or appearance affinity metric learning."
journal_title,International Journal of Computer Vision
article_title,Applying Detection Proposals to Visual Tracking for Scale and Aspect Ratio Adaptability
keyword,"['Visual tracking\xa0', 'Detection proposal\xa0', 'Scale and aspect ratio adaptability\xa0', 'Correlation filter\xa0']"
history,"['2017-05', '2016-12-26', '2015-12-16', '2016-11-17']"
abstract,"Abstract The newly proposed correlation filter based trackers can achieve appealing performance despite their great simplicity and superior speed. However, this kind of object trackers is not born with scale and aspect ratio adaptability, thus resulting in suboptimal tracking accuracy. To tackle this problem, this paper integrates the class-agnostic detection proposal method, which is widely adopted in object detection area, into a correlation filter tracker. In the tracker part, optimizations such as feature integration, robust model updating and proposal rejection are applied for efficient integration. As for proposal generation, through integrating and comparing four detection proposal generators along with two baseline methods, the quality of detection proposals is found to have considerable influence on tracking accuracy. Therefore, as the most promising proposal generator, EdgeBoxes is chosen and further enhanced with background suppression. Evaluations are mainly performed on a challenging 50-sequence dataset (OTB50) and its two subsets, 28 sequences with significant scale variation and 14 sequences with obvious aspect ratio change. Among the trackers equipped with different proposal generators, state-of-the-art trackers and existing correlation filter variants, our proposed tracker reports the highest accuracy while running efficiently at an average speed of 20.4 frames per second. Additionally, numerical performance analysis in per-sequence manner and experiment results on VOT2014 dataset are also presented to enable deeper insights into our approach."
journal_title,International Journal of Computer Vision
article_title,Deep Perceptual Mapping for Cross-Modal Face Recognition
keyword,"['Heterogeneous face recognition\xa0', 'Visible face recognition\xa0', 'Night-time surveillance\xa0']"
history,"['2017-05', '2016-07-23', '2016-01-15', '2016-07-06']"
abstract,"Abstract Cross modal face matching between the thermal and visible spectrum is a much desired capability for night-time surveillance and security applications. Due to a very large modality gap, thermal-to-visible face recognition is one of the most challenging face matching problem. In this paper, we present an approach to bridge this modality gap by a significant margin. Our approach captures the highly non-linear relationship between the two modalities by using a deep neural network. Our model attempts to learn a non-linear mapping from the visible to the thermal spectrum while preserving the identity information. We show substantive performance improvement on three difficult thermal–visible face datasets. The presented approach improves the state-of-the-art by more than 10 % on the UND-X1 dataset and by more than 15–30 % on the NVESD dataset in terms of Rank-1 identification. Our method bridges the drop in performance due to the modality gap by more than 40 %."
journal_title,Genetic Programming and Evolvable Machines
article_title,Editorial introduction
keyword,[]
history,"['2018-06', '2018-03-01']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Acknowledgment to reviewers
keyword,[]
history,"['2018-06', '2018-01-08']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Hod Lipson and Melba Kurman: Driverless: intelligent cars and the road ahead
keyword,[]
history,"['2018-06', '2017-10-16']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Guest editorial: special issue on automated design and adaptation of heuristics for scheduling and combinatorial optimisation
keyword,[]
history,"['2018-06', '2017-11-24']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Christian Blum and Günther R. Raidl: Hybrid metaheuristics—powerful tools for optimization
keyword,[]
history,"['2018-06', '2017-11-06']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,"Ian Goodfellow, Yoshua Bengio, and Aaron Courville: Deep learning"
keyword,[]
history,"['2018-06', '2017-10-29']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,A hyperheuristic approach based on low-level heuristics for the travelling thief problem
keyword,"['Heuristic selection\xa0', 'Genetic programming\xa0', 'Travelling thief problem\xa0', 'Multi-component problems\xa0']"
history,"['2018-06', '2017-07-15', '2017-02-19', '2017-06-16']"
abstract,"Abstract In this paper, we investigate the use of hyper-heuristics for the travelling thief problem (TTP). TTP is a multi-component problem, which means it has a composite structure. The problem is a combination between the travelling salesman problem and the knapsack problem. Many heuristics were proposed to deal with the two components of the problem separately. In this work, we investigate the use of automatic online heuristic selection in order to find the best combination of the different known heuristics. In order to achieve this, we propose a genetic programming based hyper-heuristic called GPHS*, and compare it to state-of-the-art algorithms. The experimental results show that the approach is competitive with those algorithms on small and mid-sized TTP instances."
journal_title,Genetic Programming and Evolvable Machines
article_title,Evolving dispatching rules for optimising many-objective criteria in the unrelated machines environment
keyword,"['Dispatching rules\xa0', 'Genetic programming\xa0', 'Many-objective optimisation\xa0', 'Scheduling\xa0', 'Unrelated machines environment\xa0']"
history,"['2018-06', '2017-09-11', '2017-02-11', '2017-06-05']"
abstract,"Abstract Dispatching rules are often a method of choice for solving various scheduling problems. Most often, they are designed by human experts in order to optimise a certain criterion. However, it is seldom the case that a schedule should optimise a single criterion all alone. More common is the case where several criteria need to be optimised at the same time. This paper deals with the problem of automatic design of dispatching rules (DRs) by the use of genetic programming, for many-objective scheduling problems. Four multi-objective and many-objective algorithms, including nondominated sorting genetic algorithm II, nondominated sorting genetic algorithm III, harmonic distance based multi-objective evolutionary algorithm and multi-objective evolutionary algorithm based on decomposition, have been used in order to obtain sets of Pareto optimal solutions for various many-objective scheduling problems. Through experiments it was shown that automatically generated multi-objective DRs not only achieve good performance when compared to standard DRs, but can also outperform automatically generated single objective DRs for most criteria combinations."
journal_title,Genetic Programming and Evolvable Machines
article_title,Evolution of shared grammars for describing simulated spatial scenes with grammatical evolution
keyword,"['Grammatical evolution\xa0', 'Dynamics of artificial languages\xa0', 'Language games\xa0', 'Multi-agent systems\xa0']"
history,"['2018-06', '2017-10-31', '2017-01-28', '2017-10-07']"
abstract,"Abstract We propose a model based on an evolutionary process combined with an adapted planning process to develop a limited spatial language with a syntactical structure in a team of artificial agents. Syntax is induced by means of a grammar and the grammar itself evolves in order to reach a syntactical agreement in the team. Evolution is implemented by adapting an evolutionary algorithm where each agent in the team manages a population of chromosomes that represent possible grammars. Grammars can be used by agents to generate utterances which are subsequently applied in language games to describe spatial relations. A planning process builds the sentences, but agents select the syntactical alternatives according to their current communicative intentions. Results  in two different linguistic task show how a shared grammar can be developed in the group of agents."
journal_title,Genetic Programming and Evolvable Machines
article_title,Evolutionary hyper-heuristics for tackling bi-objective 2D bin packing problems
keyword,"['Bin packing problem\xa0', 'Evolutionary computation\xa0', 'Hyper-heuristics\xa0', 'Heuristics\xa0', 'Multi-objective optimization\xa0', 'Genetic algorithms\xa0']"
history,"['2018-06', '2017-03-31', '2016-10-15', '2017-02-13']"
abstract,"Abstract In this article, a multi-objective evolutionary framework to build selection hyper-heuristics for solving instances of the 2D bin packing problem is presented. The approach consists of a multi-objective evolutionary learning process, using specific tailored genetic operators, to produce sets of variable length rules representing hyper-heuristics. Each hyper-heuristic builds a solution to a given problem instance by sensing the state of the instance, and deciding which single heuristic to apply at each decision point. The hyper-heuristics consider the minimization of two conflicting objectives when building a solution: the number of bins used to accommodate the pieces and the total time required to do the job. The proposed framework integrates three well-studied multi-objective evolutionary algorithms to produce sets of Pareto-approximated hyper-heuristics: the Non-dominated Sorting Genetic Algorithm-II, the Strength Pareto Evolutionary Algorithm 2, and the Generalized Differential Evolution Algorithm 3. We conduct an extensive experimental analysis using a large set of 2D bin packing problem instances containing convex and non-convex irregular pieces, under many conditions, settings and using several performance metrics. The analysis assesses the robustness and flexibility of the proposed approach, providing encouraging results when compared against a set of well-known baseline single heuristics."
journal_title,Genetic Programming and Evolvable Machines
article_title,Comparison of ensemble learning methods for creating ensembles of dispatching rules for the unrelated machines environment
keyword,"['Dispatching rules\xa0', 'Genetic programming\xa0', 'Scheduling\xa0', 'Unrelated machines environment\xa0', 'Ensemble learning\xa0']"
history,"['2018-06', '2017-04-08', '2016-10-03', '2017-03-12']"
abstract,"Abstract Dispatching rules are often the method of choice for solving various scheduling problems, especially since they are applicable in dynamic scheduling environments. Unfortunately, dispatching rules are hard to design and are also unable to deliver results which are of equal quality as results achieved by different metaheuristic methods. As a consequence, genetic programming is commonly used in order to automatically design dispatching rules. Furthermore, a great amount of research with different genetic programming methods is done to increase the performance of the generated dispatching rules. In order to additionally improve the effectiveness of the evolved dispatching rules, in this paper the use of several different ensemble learning algorithms is proposed to create ensembles of dispatching rules for the dynamic scheduling problem in the unrelated machines environment. Four different ensemble learning approaches will be considered, which will be used in order to create ensembles of dispatching rules: simple ensemble combination (proposed in this paper), BagGP, BoostGP and cooperative coevolution. Additionally, the effectiveness of these algorithms is analysed based on some ensemble learning parameters. Finally, an additional search method, which finds the optimal combinations of dispatching rules to form the ensembles, is proposed and applied. The obtained results show that by using the aforementioned ensemble learning approaches it is possible to significantly increase the performance of the generated dispatching rules."
journal_title,Genetic Programming and Evolvable Machines
article_title,Cooperative evolutionary heterogeneous simulated annealing algorithm for google machine reassignment problem
keyword,"['Machine reassignment problem\xa0', 'Simulated annealing\xa0', 'Cloud computing\xa0', 'Cooperative search\xa0']"
history,"['2018-06', '2017-05-24', '2016-10-09', '2017-04-28']"
abstract,"Abstract This paper investigates the Google machine reassignment problem (GMRP). GMRP is a real world optimisation problem which is to maximise the usage of cloud machines. Since GMRP is computationally challenging problem and exact methods are only advisable for small instances, meta-heuristic algorithms have been used to address medium and large instances. This paper proposes a cooperative evolutionary heterogeneous simulated annealing (CHSA) algorithm for GMRP. The proposed algorithm consists of several components devised to generate high quality solutions. Firstly, a population of solutions is used to effectively explore the solution space. Secondly, CHSA uses a pool of heterogeneous simulated annealing algorithms in which each one starts from a different initial solution and has its own configuration. Thirdly, a cooperative mechanism is designed to allow parallel searches to share their best solutions. Finally, a restart strategy based on mutation operators is proposed to improve the search performance and diversification. The evaluation on 30 diverse real-world instances shows that the proposed CHSA performs better compared to cooperative homogeneous SA and heterogeneous SA with no cooperation. In addition, CHSA outperformed the current state-of-the-art algorithms, providing new best solutions for eleven instances. The analysis on algorithm behaviour clearly shows the benefits of the cooperative heterogeneous approach on search performance."
journal_title,Genetic Programming and Evolvable Machines
article_title,Implementing the template method pattern in genetic programming for improved time series prediction
keyword,"['Genetic programming\xa0', 'Time series prediction\xa0', 'Software design patterns\xa0', 'Modularity\xa0']"
history,"['2018-06', '2018-03-05', '2016-10-17', '2017-12-22']"
abstract,"Abstract Modularity is an ongoing focus in genetic programming research. Enhanced modularity can accelerate solution convergence and increase human understanding and knowledge gained from evolved programs. Prior advances in modularity research have addressed programming language elements such as functions, modules, and recursion. This paper proposes improving modularity by considering non-language elements, specifically software design patterns. A new genetic programming technique implementing the template method pattern is described. This technique was tested and compared to existing genetic programming approaches in the prediction of nonlinear time series subject to abrupt changes in the underlying data generation process. Such series are often seen in areas such as finance and meteorology and have proved challenging for genetic programming to model and predict. Experimental results demonstrate the potential for incorporating additional software design patterns into genetic programming and applying these techniques to additional problem domains."
journal_title,Genetic Programming and Evolvable Machines
article_title,Comparing three online evolvable hardware implementations of a classification system
keyword,"['Evolutionary algorithms\xa0', 'Evolvable hardware\xa0', 'Classifier system\xa0', 'Field programmable gate arrays\xa0']"
history,"['2018-06', '2017-10-13', '2017-03-24', '2017-08-22']"
abstract,"Abstract In this paper, we present three implementations of an online evolvable hardware classifier of sonar signals on a 28 nm process technology FPGA, and compare their features using the most relevant metrics in the design of hardware: area, timing, power consumption, energy consumption, and performance. The three implementations are: one full-hardware implementation in which all the modules of the evolvable hardware system, the evaluation module and the Evolutionary Algorithm have been implemented on the ZedBoard™ Zynq® Evaluation Kit (XC7-Z020 ELQ484-1); and two hardware/software implementations in which the Evolutionary Algorithm has been implemented in software and run on two different processors: Zynq® XC7-Z020 and MicroBlaze™. Additionally, each processor-based implementation has been tested at several processor speeds. The results prove that the full-hardware implementation always performs better than the hardware/software implementations by a considerable margin: up to \(\times \,7.74\) faster than MicroBlaze, between \(\times \,1.39\) and \(\times \,2.11\) faster that Zynq, and \(\times \,0.198\) lower power consumption. However, the hardware/software implementations have the advantage of being more flexible for testing different options during the design phase. These figures can be used as a guideline to determine the best use for each kind of implementation."
journal_title,Genetic Programming and Evolvable Machines
article_title,Optimizing agents with genetic programming: an evaluation of hyper-heuristics in dynamic real-time logistics
keyword,"['Hyper-heuristics\xa0', 'Genetic programming\xa0', 'Multi-agent systems\xa0', 'Logistics\xa0', 'Decentralized\xa0', 'Centralized\xa0', 'Operational research\xa0', 'Optimization\xa0', 'Real-time\xa0']"
history,"['2018-06', '2017-04-06', '2016-10-15', '2017-01-27']"
abstract,"Abstract Dynamic pickup and delivery problems (PDPs) require online algorithms for managing a fleet of vehicles. Generally, vehicles can be managed either centrally or decentrally. A common way to coordinate agents decentrally is to use the contract-net protocol (CNET) that uses auctions to allocate tasks among agents. To participate in an auction, agents require a method that estimates the value of a task. Typically, this method involves an optimization algorithm, e.g. to calculate the cost to insert a customer. Recently, hyper-heuristics have been proposed for automated design of heuristics. Two properties of automatically designed heuristics are particularly promising: (1) a generated heuristic computes quickly, it is expected therefore that hyper-heuristics perform especially well for urgent problems, and (2) by using simulation-based evaluation, hyper-heuristics can create a ‘rule of thumb’ that anticipates situations in the future. In the present paper we empirically evaluate whether hyper-heuristics, more specifically genetic programming (GP), can be used to improve agents decentrally coordinated via CNET. We compare several GP settings and compare the resulting heuristic with existing centralized and decentralized algorithms based on the OptaPlanner optimization library. The tests are conducted in real-time on a dynamic PDP dataset with varying levels of dynamism, urgency, and scale. The results indicate that the evolved heuristic always outperforms the optimization algorithm in the decentralized multi-agent system (MAS) and often outperforms the centralized optimization algorithm. Our paper demonstrates that designing MASs using genetic programming is an effective way to obtain competitive performance compared to traditional operational research approaches. These results strengthen the relevance of decentralized agent based approaches in dynamic logistics."
journal_title,Genetic Programming and Evolvable Machines
article_title,"Gustavo Olague: Evolutionary computer vision, the first footprints"
keyword,[]
history,"['2017-12', '2017-10-06']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Understanding grammatical evolution: initialisation
keyword,"['Grammatical evolution\xa0', 'Initialisation\xa0', 'Representation bias\xa0', 'Tree creation\xa0', 'Symbolic regression\xa0', 'Classification\xa0', 'Design\xa0']"
history,"['2017-12', '2017-07-25', '2016-12-19', '2017-07-01']"
abstract,"Abstract Grammatical evolution is one of the most used variants of genetic programming, and ever since its introduction, several improvements have been suggested. One of these concerns the routine used to create the initial population. In this study, several proposed initialisation routines are compared; based on a detailed analysis of the generated initial populations, and subsequent results obtained on a large set of experiments, a variant of the PTC2 algorithm is shown to consistently outperform all other routines, while a variant of random initialisation provides a good compromise between efficiency and ease of implementation."
journal_title,Genetic Programming and Evolvable Machines
article_title,A meta-grammatical evolutionary process for portfolio selection and trading
keyword,"['Grammatical evolution\xa0', 'Automated trading systems\xa0', 'Meta-GE\xa0', 'Technical analysis\xa0', 'Fundamental analysis\xa0', 'Macroeconomic analysis\xa0']"
history,"['2017-12', '2017-04-17', '2016-10-02', '2017-04-04']"
abstract,"Abstract This study presents the implementation of an automated trading system that uses three critical analyses to determine time-decisions and portfolios for investment. The approach is based on a meta-grammatical evolution methodology that combines technical, fundamental and macroeconomic analysis on a hybrid top-down paradigm. First, the method provides a low-risk portfolio by analyzing countries and industries. Next, aiming to focus on the most robust companies, the system filters the portfolio by analyzing their economic variables. Finally, the system analyzes prices and volumes to optimize investment decisions during a given period. System validation involves a series of experiments in the European financial markets, which are reflected with a data set of over nine hundred companies. The final solutions have been compared with static strategies and other evolutionary implementations and the results show the effectiveness of the proposal."
journal_title,Genetic Programming and Evolvable Machines
article_title,Affective evolutionary music composition with MetaCompose
keyword,"['Evolutionary computing\xa0', 'Genetic algorithm\xa0', 'Music generation\xa0', 'Affective music\xa0', 'Creative computing\xa0']"
history,"['2017-12', '2017-06-09', '2016-09-13', '2017-06-03']"
abstract,"Abstract This paper describes the MetaCompose music generator,
 a compositional, extensible framework for affective music composition. In this context ‘affective’ refers to the music generator’s ability to express emotional information. The main purpose of MetaCompose is to create music in real-time that can express different mood-states, which we achieve through a unique combination of a graph traversal-based chord sequence generator, a search-based melody generator, a pattern-based accompaniment generator, and a theory for mood expression. Melody generation uses a novel evolutionary technique combining FI-2POP with multi-objective optimization. This allows us to explore a Pareto front of diverse solutions that are creatively equivalent under the terms of a multi-criteria objective function. Two quantitative user studies were performed to evaluate the system: one focusing on the music generation technique, and the other that explores valence expression,
 via the introduction of dissonances. The results of these studies demonstrate (i) that each part of the generation system improves the perceived quality of the music produced, and (ii) how valence expression via dissonance produces the perceived affective state. This system, which can reliably generate affect-expressive music, can subsequently be integrated in any kind of interactive application (e.g., games) to create an adaptive and dynamic soundtrack."
journal_title,Genetic Programming and Evolvable Machines
article_title,"Introduction to the peer commentary special section on “On the Mapping of Genotype to Phenotype in Evolutionary Algorithms” by Peter A. Whigham, Grant Dick, and James Maclaurin"
keyword,[]
history,"['2017-09', '2017-02-23']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Just because it works: a response to comments on “On the Mapping of Genotype to Phenotype in Evolutionary Algorithms”
keyword,"['Genetic programming\xa0', 'Biological analogy\xa0', 'Grammatical evolution\xa0', 'Representation\xa0']"
history,"['2017-09', '2017-02-24']"
abstract,"Abstract This response examines the context and implications of the comments to ""On the Mapping of Genotype to Phenotype in Evolutionary Algorithms"" that appears in this journal. The notion of metaphor is first considered and then the general themes of the commentaries addressed. The response subsequently focuses on representation and operators, noting that many of the comments support our basic premise.The main conclusion is that Sterelny's conditions do form a suitable basis for representation and operator design and that the collection of responses form an excellent basis for further discussion and research in evolutionary computation."
journal_title,Genetic Programming and Evolvable Machines
article_title,On the mapping of genotype to phenotype in evolutionary algorithms
keyword,"['Genetic programming\xa0', 'Biological analogy\xa0', 'Grammatical evolution\xa0', 'Representation\xa0']"
history,"['2017-09', '2017-02-23']"
abstract,"Abstract Analogies with molecular biology are frequently used to guide the development of artificial evolutionary search. A number of assumptions are made in using such reasoning, chief among these is that evolution in natural systems is an optimal, or at least best available, search mechanism, and that a decoupling of search space from behaviour encourages effective search. In this paper, we explore these assumptions as they relate to evolutionary algorithms, and discuss philosophical foundations from which an effective evolutionary search can be constructed. This framework is used to examine grammatical evolution (GE), a popular search method that draws heavily upon concepts from molecular biology. We identify several properties in GE that are in direct conflict with those that promote effective evolutionary search. The paper concludes with some recommendations for designing representations for effective evolutionary search."
journal_title,Genetic Programming and Evolvable Machines
article_title,"Probing the axioms of evolutionary algorithm design: Commentary on “On the mapping of genotype to phenotype in evolutionary algorithms” by Peter A. Whigham, Grant Dick, and James Maclaurin"
keyword,"['Fisher’s geometric model\xa0', '1/5 rule\xa0', 'Evolution of evolvability\xa0']"
history,"['2017-09', '2017-02-24']"
abstract,"Abstract Properties such as continuity, locality, and modularity may seem necessary when designing representations and variation operators for evolutionary algorithms, but a closer look at what happens when evolutionary algorithms perform well reveals counterexamples to such schemes. Moreover, these variational properties can themselves evolve in sufficiently complex open-ended systems. These properties of evolutionary algorithms remain very much open questions."
journal_title,Genetic Programming and Evolvable Machines
article_title,"(Over-)Realism in evolutionary computation: Commentary on “On the Mapping of Genotype to Phenotype in Evolutionary Algorithms” by Peter A. Whigham, Grant Dick, and James Maclaurin"
keyword,"['Evolutionary Computation\xa0', 'Memetic Algorithm\xa0', 'Grammatical Evolution\xa0', 'Stochastic Sampling\xa0', 'Extended Phenotype\xa0']"
history,"['2017-09', '2017-02-24']"
abstract,"Abstract Inspiring metaphors play an important role in the beginning of an investigation, but are less important in a mature research field as the real phenomena involved are understood. Nowadays, in evolutionary computation, biological analogies should be taken into consideration only if they deliver significant advantages."
journal_title,Genetic Programming and Evolvable Machines
article_title,"Distilling the salient features of natural systems: Commentary on “On the mapping of genotype to phenotype in evolutionary algorithms” by Whigham, Dick and Maclaurin"
keyword,"['Genetic Programming\xa0', 'Cayley Graph\xa0', 'Grammatical Evolution\xa0', 'Artificial Evolution\xa0', 'Program Synthesis\xa0']"
history,"['2017-09', '2017-02-28']"
abstract,"Abstract Here we comment on the article, “On the mapping of genotype to phenotype in evolutionary algorithms”, by Peter A. Whigham, Grant Dick, and James Maclaurin. The authors present a critical view on the use of genotype to phenotype mapping in Evolutionary Algorithms, and how the use of this analogy can be detrimental for problem solving. They examine a grammar-based approach to Genetic Programming (GP), Grammatical Evolution (GE), and highlight properties of GE which are detrimental to effective evolutionary search. Rather than use loose analogies and methaphors, we suggest that a focus should be (and has been in GE and other approaches to GP) on addressing one of the most significant open issues in our field, i.e., What are the sufficient set of features in natural, genetic, evolutionary and developmental systems, which can translate into the most effective computational approaches for program synthesis?"
journal_title,Genetic Programming and Evolvable Machines
article_title,Sebastian Ventura and Jose Maria Luna: Pattern mining with evolutionary algorithms
keyword,[]
history,"['2017-09', '2017-05-24']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,"Genotype–phenotype mapping implications for genetic programming representation: Commentary on “On the mapping of genotype to phenotype in evolutionary algorithms” by Peter A. Whigham, Grant Dick, and James Maclaurin"
keyword,"['Genotype–phenotype mapping\xa0', 'Representation\xa0', 'Practical guidelines for GP representation design\xa0']"
history,"['2017-09', '2017-02-24']"
abstract,"Abstract Here we comment on the article “On the mapping of genotype to phenotype in evolutionary algorithms,” by Peter A. Whigham, Grant Dick, and James Maclaurin. The article reasons about analogies from molecular biology to evolutionary algorithms and discusses conditions for biological adaptations in the context of grammatical evolution, which provide a useful perspective to GP practitioners. However, the connection of the listed implications for GP is not sufficiently convincing for the reader . Therefore this commentary will (1) examine the proposed principles one by one, challenging the authors to provide more supporting evidence where felt that this was needed, and (2) propose a methodical way to GP practitioners to apply these principles when designing GP representations."
journal_title,Genetic Programming and Evolvable Machines
article_title,"Taking “biology” just seriously enough: Commentary on “On the Mapping of Genotype to Phenotype in Evolutionary Algorithms” by Peter A. Whigham, Grant Dick, and James Maclaurin"
keyword,"['Evolutionary computation\xa0', 'Genetics\xa0', 'Software engineering\xa0', 'Grammatical evolution\xa0']"
history,"['2017-09', '2017-02-24']"
abstract,"Abstract “On the Mapping of Genotype to Phenotype in Evolutionary Algorithms,” by Peter A. Whigham, Grant Dick, and James Maclaurin, is a welcome reminder that evolutionary computation practitioners should be wary of taking their biological analogies too seriously. But more importantly, it is a reminder to practitioners to consider carefully their representations and operators, rather than blindly implementing a biological analogy without sufficient attention to the constraints of software engineering. “It works in biology, so it should work in EC” is poor, even lazy, software design. The primary contribution of this paper is exactly what a commentary should be: to (re)ignite discussions about how biological inspiration should inform EC practice."
journal_title,Genetic Programming and Evolvable Machines
article_title,"A rebuttal to Whigham, Dick, and Maclaurin by one of the inventors of Grammatical Evolution: Commentary on “On the Mapping of Genotype to Phenotype in Evolutionary Algorithms” by Peter A. Whigham, Grant Dick, and James Maclaurin"
keyword,"['Grammatical evolution\xa0', 'CFG-GP\xa0']"
history,"['2017-09', '2017-02-24']"
abstract,"Abstract The authors present a thinly veiled attack on the popular Grammatical Evolution (GE) system, the second in the space of year. The paper presents itself as a philosophical discussion on a framework they present, based on a handful of Sterelny’s guidelines. However, it quickly degenerates into an assault on GE, initially by attributing assumptions to the inventors, and latterly by the use of misleading claims. This rebuttal addresses both of these."
journal_title,Genetic Programming and Evolvable Machines
article_title,"Evolutionary algorithms and synthetic biology for directed evolution: commentary on “on the mapping of genotype to phenotype in evolutionary algorithms” by Peter A. Whigham, Grant Dick, and James Maclaurin"
keyword,"['Directed evolution\xa0', 'Synthetic biology\xa0', 'Navigating search spaces\xa0', 'Intelligent operators\xa0']"
history,"['2017-09', '2017-03-29']"
abstract,"Abstract I rehearse two issues around the commentary of Whigham and colleagues. (1) There really are many more reasons than those given as to why natural evolution cannot reasonably find or select the ‘optimal’ individual. (2) A series of experimental molecular biology programmes, known generically as directed evolution, can use operators and selection schemes that natural evolution cannot. When developed further using the methods of synthetic biology, there are no operators or schemes for in silico evolution that cannot be applied precisely to directed evolution. The issues raised apply only to natural evolution but not to directed evolution."
journal_title,Genetic Programming and Evolvable Machines
article_title,A closed asynchronous dynamic model of cellular learning automata and its application to peer-to-peer networks
keyword,"['Cellular learning automata\xa0', 'Dynamic cellular learning automata\xa0', 'Peer-to-peer networks\xa0', 'Landmark clustering algorithm\xa0']"
history,"['2017-09', '2017-02-20', '2016-11-13', '2017-02-02']"
abstract,"Abstract  Cellular Learning Automata (CLAs) are hybrid models obtained from combination of Cellular Automata (CAs) and Learning Automata (LAs). These models can be either open or closed. In closed CLAs, the states of neighboring cells of each cell called local environment affect on the action selection process of the LA of that cell whereas in open CLAs, each cell, in addition to its local environment has an exclusive environment which is observed by the cell only and the global environment which can be observed by all the cells in CLA. In dynamic models of CLAs, one of their aspects such as structure, local rule or neighborhood radius may change during the evolution of the CLA. CLAs can also be classified as synchronous CLAs or asynchronous CLAs. In a synchronous CLA, all LAs in different cells are activated synchronously whereas in an asynchronous CLA, the LAs in different cells are activated asynchronously. In this paper, a new closed asynchronous dynamic model of CLA whose structure and the number of LAs in each cell may vary with time has been introduced. To show the potential of the proposed model, a landmark clustering algorithm for solving topology mismatch problem in unstructured peer-to-peer networks has been proposed. To evaluate the proposed algorithm, computer simulations have been conducted and then the results are compared with the results obtained for two existing algorithms for solving topology mismatch problem. It has been shown that the proposed algorithm is superior to the existing algorithms with respect to communication delay and average round-trip time between peers within clusters."
journal_title,Genetic Programming and Evolvable Machines
article_title,A univariate marginal distribution algorithm based on extreme elitism and its application to the robotic inverse displacement problem
keyword,"['Univariate marginal distribution algorithm\xa0', 'Inverse displacement problem\xa0', 'Top best solutions\xa0', 'Gaussian model\xa0', 'Differential evolution algorithm\xa0']"
history,"['2017-09', '2017-03-20', '2016-03-13', '2017-01-27']"
abstract,"Abstract In this paper, a univariate marginal distribution algorithm in continuous domain (UMDA C ) based on extreme elitism (EEUMDA C ) is proposed for solving the inverse displacement problem (IDP) of robotic manipulators. This algorithm highlights the effect of a few top best solutions to form a primary evolution direction and obtains a fast convergence rate. Then it is implemented to determine the IDP of a 4-degree-of-freedom (DOF) Barrett WAM robotic arm. After that, the algorithm is combined with differential evolution (EEUMDA C -DE) to solve the IDP of a 7-DOF Barrett WAM robotic arm. In addition, three other heuristic optimization algorithms (enhanced leader particle swarm optimization, intersect mutation differential evolution, and evolution strategies) are applied to find the IDP solution of the 7-DOF arm and their performance is compared with that of EEUMDA C -DE."
journal_title,Genetic Programming and Evolvable Machines
article_title,Software review: CGP-Library
keyword,"['Software library\xa0', 'Cartesian genetic programming\xa0', 'Neuroevolution\xa0']"
history,"['2017-06', '2017-04-18']"
abstract,"Abstract CGP-Library is an open-source, cross-platform written in C which implements Cartesian Genetic Programming (CGP) and its variations. It solves both academic and real-world problems. Since its inicial release, it has undergone some refinements, and it is without doubt the best supported toolkit for CGP. In this article it is presented a critical assessment of the CGP-Library features, its main strengths and its weaknesses."
journal_title,Genetic Programming and Evolvable Machines
article_title,Solving metameric variable-length optimization problems using genetic algorithms
keyword,"['Variable-length genetic algorithms\xa0', 'Metameric variable-length problems\xa0', 'Metameric genetic algorithm\xa0', 'Sensor coverage\xa0', 'Windfarm layout\xa0', 'Composite laminate design\xa0']"
history,"['2017-06', '2016-09-26', '2016-03-23', '2016-07-22']"
abstract,"Abstract In many optimization problems, one of the goals is to determine the optimal number of analogous components to include in the system. Examples include the number of sensors in a sensor coverage problem, the number of turbines in a wind farm problem, and the number of plies in a laminate stacking problem. Using standard approaches to solve these problems requires assuming a fixed number of sensors, turbines, or plies. However, if the optimal number is not known a priori this will likely lead to a sub-optimal solution. A better method is to allow the number of components to vary. As the number of components varies, so does the dimensionality of the search space, making the use of gradient-based methods difficult. A metameric genetic algorithm (MGA), which uses a segmented variable-length genome, is proposed. Traditional genetic algorithm (GA) operators, designed to work with fixed-length genomes, are no longer valid. This paper discusses the modifications required for an effective MGA, which is then demonstrated on the aforementioned problems. This includes the representation of the solution in the genome and the recombination, mutation, and selection operators. With these modifications the MGA is able to outperform the fixed-length GA on the selected problems, even if the optimal number of components is assumed to be known a priori."
journal_title,Genetic Programming and Evolvable Machines
article_title,Recurrent Cartesian Genetic Programming of Artificial Neural Networks
keyword,"['Cartesian Genetic Programming\xa0', 'Genetic Programming\xa0', 'NeuroEvolution\xa0', 'Forecasting\xa0']"
history,"['2017-06', '2016-08-08', '2015-11-05', '2016-07-05']"
abstract,Abstract Cartesian Genetic Programming of Artificial Neural Networks is a NeuroEvolutionary method based on Cartesian Genetic Programming. Cartesian Genetic Programming has recently been extended to allow recurrent connections. This work investigates applying the same recurrent extension to Cartesian Genetic Programming of Artificial Neural Networks in order to allow the evolution of recurrent neural networks. The new Recurrent Cartesian Genetic Programming of Artificial Neural Networks method is applied to the domain of series forecasting where it is shown to significantly outperform all standard forecasting techniques used for comparison including autoregressive integrated moving average and multilayer perceptrons. An ablation study is also performed isolating which specific aspects of Recurrent Cartesian Genetic Programming of Artificial Neural Networks contribute to it’s effectiveness for series forecasting.
journal_title,Genetic Programming and Evolvable Machines
article_title,An iterative genetic programming approach to prototype generation
keyword,"['Genetic programming\xa0', 'K-nearest neighbors\xa0', 'Prototype generation\xa0', 'Pattern classification\xa0']"
history,"['2017-06', '2016-08-30', '2015-01-28', '2016-01-29']"
abstract,"Abstract In this paper, we propose a genetic programming (GP) approach to the problem of prototype generation for nearest-neighbor (NN) based classification. The problem consists of learning a set of artificial instances that effectively represents the training set of a classification problem, with the goal of reducing the storage requirements and the computational cost inherent in NN classifiers. This work introduces an iterative GP technique to learn such artificial instances based on a non-linear combination of instances available in the training set. Experiments are reported in a benchmark for prototype generation. Experimental results show our approach is very competitive with the state of the art, in terms of accuracy and in its ability to reduce the training set size."
journal_title,Genetic Programming and Evolvable Machines
article_title,An analysis of the genetic marker diversity algorithm for genetic programming
keyword,"['Genetic programming\xa0', 'Genotypic diversity\xa0', 'Structural diversity\xa0', 'Premature convergence\xa0']"
history,"['2017-06', '2016-09-06', '2015-12-01', '2016-08-22']"
abstract,"Abstract Many diversity techniques have been developed for addressing premature convergence, which is a serious problem that stifles the search effectiveness of evolutionary algorithms. However, approaches that aim to avoid premature convergence can often take longer to discover a solution. The Genetic Marker Diversity algorithm is a new technique that has been shown to find solutions significantly faster than other approaches while maintaining diversity in genetic programming. This study provides a more in-depth analysis of the search behavior of this technique compared to other state-of-the-art methods, as well as a comparison of the performance of these techniques on a larger and more modern set of test problems."
journal_title,Genetic Programming and Evolvable Machines
article_title,Recursion in tree-based genetic programming
keyword,"['Evolutionary program synthesis\xa0', 'Genetic programming\xa0', 'Recursive programs\xa0', 'Variation operators\xa0', 'Fitness landscape analysis\xa0']"
history,"['2017-06', '2016-08-31', '2015-10-12', '2016-04-08']"
abstract,"Abstract Recursion is a powerful concept that enables a solution to a problem to be expressed as a relatively simple decomposition of the original problem into sub-problems of the same type. We survey previous research about the evolution of recursive programs in tree-based Genetic Programming. We then present an analysis of the fitness landscape of recursive programs, and report results on evolving solutions to a range of problems. We conclude with guidelines concerning the choice of fitness function and variation operators, as well as the handling of the halting problem. The main findings are as follows. The distribution of fitness changes initially as we look at programs of increasing size but once some threshold has been exceeded, it shows very little variation with size. Furthermore, the proportion of halting programs decreases as size increases. Recursive programs exhibit the property of weak causality; small changes in program structure may cause big changes in semantics. Nevertheless, the evolution of recursive programs is not a needle-in-a-haystack problem; the neighbourhoods of optimal programs are populated by halting individuals of intermediate fitness. Finally, mutation-based variation operators performed the best in finding recursive solutions. Evolution was also shown to outperform random search."
journal_title,Genetic Programming and Evolvable Machines
article_title,Acknowledgment to Reviewers
keyword,[]
history,"['2017-03', '2017-02-02']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Editorial introduction
keyword,[]
history,"['2017-03', '2017-02-11']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Preface to the Special Issue on Genetic Improvement
keyword,[]
history,"['2017-03', '2016-08-27']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Krzysztof Krawiec: Behavioral program synthesis with genetic programming
keyword,[]
history,"['2017-03', '2016-11-25']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Paul Rendell: Turing machine universality of the Game of Life
keyword,[]
history,"['2017-03', '2017-01-16']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,"James Keller, Derong Liu, and David Fogel: Fundamentals of computational intelligence: neural networks, fuzzy systems, and evolutionary computation"
keyword,[]
history,"['2017-03', '2017-02-02']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Online Genetic Improvement on the java virtual machine with ECSELR
keyword,"['Genetic improvement\xa0', 'Evolutionary computation\xa0', 'Genetic programming\xa0', 'Artificial intelligence\xa0', 'Software engineering\xa0']"
history,"['2017-03', '2016-10-12', '2015-12-21', '2016-08-05']"
abstract,"Abstract Online Genetic Improvement embeds the ability to evolve and adapt inside a target software system enabling it to improve at runtime without any external dependencies or human intervention. We recently developed a general purpose tool enabling Online Genetic Improvement in software systems running on the java virtual machine. This tool, dubbed ECSELR, is embedded inside extant software systems at runtime, enabling such systems to self-improve and adapt autonomously online. We present this tool, describing its architecture and focusing on its design choices and possible uses."
journal_title,Genetic Programming and Evolvable Machines
article_title,Genetic improvement of GPU software
keyword,"['Genetic programming\xa0', 'SBSE\xa0', 'GI-GPGPU\xa0', 'Metaprogramming\xa0', 'Grammar based genetic programming\xa0', 'NVidia CUDA\xa0', 'Parallel computing\xa0', 'Dynamic programming\xa0', 'GPGPU\xa0', 'GGGP\xa0']"
history,"['2017-03', '2016-07-25', '2015-12-19', '2016-06-28']"
abstract,"Abstract We survey genetic improvement (GI) of general purpose computing on graphics cards. We summarise several experiments which demonstrate four themes. Experiments with the gzip program show that genetic programming can automatically port sequential C code to parallel code. Experiments with the StereoCamera program show that GI can upgrade legacy parallel code for new hardware and software. Experiments with NiftyReg and BarraCUDA show that GI can make substantial improvements to current parallel CUDA applications. Finally, experiments with the pknotsRG program show that with semi-automated approaches, enormous speed ups can sometimes be had by growing and grafting new code with genetic programming in combination with human input."
journal_title,Genetic Programming and Evolvable Machines
article_title,Trading between quality and non-functional properties of median filter in embedded systems
keyword,"['Genetic programming\xa0', 'Genetic improvement\xa0', 'Cartesian genetic programming\xa0', 'Median function\xa0', 'Comparison network\xa0', 'Permutation principle\xa0', 'Median filter\xa0']"
history,"['2017-03', '2016-07-19', '2015-12-20', '2016-07-06']"
abstract,"Abstract Genetic improvement has been used to improve functional and non-functional properties of software. In this paper, we propose a new approach that applies a genetic programming (GP)-based genetic improvement to trade between functional and non-functional properties of existing software. The paper investigates possibilities and opportunities for improving non-functional parameters such as execution time, code size, or power consumption of median functions implemented using comparator networks. In general, it is impossible to improve non-functional parameters of the median function without accepting occasional errors in results because optimal implementations are available. In order to address this issue, we proposed a method providing suitable compromises between accuracy, execution time and power consumption. Traditionally, a randomly generated set of test vectors is employed so as to assess the quality of GP individuals. We demonstrated that such an approach may produce biased solutions if the test vectors are generated inappropriately. In order to measure the accuracy of determining a median value and avoid such a bias, we propose and formally analyze new quality metrics which are based on the positional error calculated using the permutation principle introduced in this paper. It is shown that the proposed method enables the discovery of solutions which show a significant improvement in execution time, power consumption, or size with respect to the accurate median function while keeping errors at a moderate level. Non-functional properties of the discovered solutions are estimated using data sets and validated by physical measurements on physical microcontrollers. The benefits of the evolved implementations are demonstrated on two real-world problems—sensor data processing and image processing. It is concluded that data processing software modules offer a great opportunity for genetic improvement. The results revealed that it is not even necessary to determine the median value exactly in many cases which helps to reduce power consumption or increase performance. The discovered implementations of accurate, as well as approximate median functions, are available as C functions for download and can be employed in a custom application (http://www.fit.vutbr.cz/research/groups/ehw/median)."
journal_title,Genetic Programming and Evolvable Machines
article_title,Evolution of sustained foraging in three-dimensional environments with physics
keyword,"['Sustainable foraging\xa0', '3D environment\xa0', 'Physics simulator\xa0', 'Body–brain co-evolution\xa0', 'Genetic algorithm\xa0', 'Foraging map\xa0']"
history,"['2016-12', '2016-06-07', '2016-01-05', '2016-05-10']"
abstract,"Abstract Artificially evolving foraging behavior in simulated articulated animals has proved to be a notoriously difficult task. Here, we co-evolve the morphology and controller for virtual organisms in a three-dimensional physical environment to produce goal-directed locomotion in articulated agents. We show that following and reaching multiple food sources can evolve de novo, by evaluating each organism on multiple food sources placed on a basic pattern that is gradually randomized across generations. We devised a strategy of evolutionary “staging”, where the best organism from a set of evolutionary experiments using a particular fitness function is used to seed a new set, with a fitness function that is progressively altered to better challenge organisms as evolution improves them. We find that an organism’s efficiency at reaching the first food source does not predict its ability at finding subsequent ones because foraging efficiency crucially depends on the position of the last food source reached, an effect illustrated by “foraging maps” that capture the organism’s controller state, body position, and orientation. Our best evolved foragers are able to reach multiple food sources over 90 % of the time on average, a behavior that is key to any biologically realistic simulation where a self-sustaining population has to survive by collecting food sources in three-dimensional, physical environments."
journal_title,Genetic Programming and Evolvable Machines
article_title,A two-objective memetic approach for the node localization problem in wireless sensor networks
keyword,"['Memetic approach\xa0', 'Multi-trilateration technique\xa0', 'Self-adaptive local search\xa0', 'Localization problem\xa0', 'Wireless sensor networks\xa0']"
history,"['2016-12', '2016-07-28', '2015-11-18', '2016-05-15']"
abstract,"Abstract Wireless sensor networks (WSNs) are emerging as an efficient way to sense the physical phenomenon without the need of wired links and spending huge money on sensor devices. In WSNs, finding the accurate locations of sensor nodes is essential since the location inaccuracy makes the collected data fruitless. In this paper, we propose a two-objective memetic approach called the Three Phase Memetic Approach that finds the locations of sensor nodes with high accuracy. The proposed algorithm is composed of three operators (phases). The first phase, which is a combination of three node-estimating approaches, is used to provide good starting locations for sensor nodes. The second and third phases are then utilized for mitigating the localization errors in the first operator. To test the proposed algorithm, we compare it with the simulated annealing-based localization algorithm, genetic algorithm-based localization, Particle Swarm Optimization-based Localization algorithm, trilateration-based simulated annealing algorithm, imperialist competitive algorithm and Pareto Archived Evolution Strategy on ten randomly created and four specific network topologies with four different values of transmission ranges. The comparisons indicate that the proposed algorithm outperforms the other algorithms in terms of the coordinate estimations of sensor nodes."
journal_title,Genetic Programming and Evolvable Machines
article_title,Prediction of expected performance for a genetic programming classifier
keyword,"['Problem difficulty\xa0', 'Prediction of expected performance \xa0', 'Genetic programming\xa0', 'Supervised learning\xa0']"
history,"['2016-12', '2016-02-22', '2015-09-29', '2016-02-07']"
abstract,"Abstract The estimation of problem difficulty is an open issue in genetic programming (GP). The goal of this work is to generate models that predict the expected performance of a GP-based classifier when it is applied to an unseen task. Classification problems are described using domain-specific features, some of which are proposed in this work, and these features are given as input to the predictive models.
 These models are referred to as predictors of expected performance. We extend this approach by using an ensemble of specialized predictors (SPEP), dividing classification problems into groups and choosing the corresponding SPEP. The proposed predictors are trained using 2D synthetic classification problems with balanced datasets. The models are then used to predict the performance of the GP classifier on unseen real-world datasets that are multidimensional and imbalanced. This work is the first to provide a performance prediction of a GP system on test data,
 while previous works focused on predicting training performance. Accurate predictive models are generated by posing a symbolic regression task and solving it with GP. These results are achieved by using highly descriptive features and including a dimensionality reduction stage that simplifies the learning and testing process. The proposed approach could be extended to other classification algorithms and used as the basis of an expert system for algorithm selection."
journal_title,Genetic Programming and Evolvable Machines
article_title,Dynamic feedback neuro-evolutionary networks for forecasting the highly fluctuating electrical loads
keyword,"['Very short term electric load forecasting (VSTLF)\xa0', 'Recurrent neural networks\xa0', 'Cartesian genetic programming evolved recurrent neural network (CGPRNN)\xa0', 'Neuro-evolution\xa0']"
history,"['2016-12', '2016-05-18', '2015-11-11', '2016-02-24']"
abstract,"Abstract A computationally efficient and accurate forecasting model for highly dynamic electric load patterns of UK electric power grid is proposed and implemented using recurrent neuro-evolutionary algorithms. Cartesian genetic programming is used to find the optimum recurrent structure and network parameters to accurately forecast highly fluctuating load patterns. Fifty different models are trained and tested in diverse set of scenarios to predict single as well as more future instances in advance. The testing results demonstrated that the models are highly accurate as they attained an accuracy of as high as 98.95 %. The models trained to predict single future instances are tested to predict more future instances in advance, obtaining an accuracy of 94 %, thus proving their robustness to predict any time series."
journal_title,Genetic Programming and Evolvable Machines
article_title,Mike Preuss: Multimodal optimization by means of evolutionary algorithms
keyword,[]
history,"['2016-09', '2016-06-25']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,"Wolfgang Banzhaf and Lidia Yamamoto: Artificial Chemistries, MIT Press, 2015"
keyword,[]
history,"['2016-09', '2016-06-29']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Unveiling the properties of structured grammatical evolution
keyword,"['Genetic programming\xa0', 'Grammatical evolution\xa0', 'Locality\xa0', 'Redundancy\xa0', 'Representation\xa0']"
history,"['2016-09', '2016-02-03', '2015-03-03', '2015-12-23']"
abstract,"Abstract Structured grammatical evolution (SGE) is a new genotypic representation for grammatical evolution (GE). It comprises a hierarchical organization of the genes, where each locus is explicitly linked to a non-terminal of the grammar being used. This one-to-one correspondence ensures that the modification of a gene does not affect the derivation options of other non-terminals. We present a comprehensive set of optimization results obtained with problems from three different categories: symbolic regression, path finding, and predictive modeling. In most of the situations SGE outperforms standard GE, confirming the effectiveness of the new representation. To understand the reasons for SGE enhanced performance, we scrutinize its main features. We rely on a set of static measures to model the interactions between the representation and variation operators and assess how they influence the interplay between the genotype-phenotype spaces. The study reveals that the structured organization of SGE promotes an increased locality and is less redundant than standard GE, thus fostering an effective exploration of the search space."
journal_title,Genetic Programming and Evolvable Machines
article_title,An automatic solver for very large jigsaw puzzles using genetic algorithms
keyword,"['Computer vision\xa0', 'Genetic algorithms\xa0', 'Jigsaw puzzle\xa0']"
history,"['2016-09', '2016-02-15', '2015-08-08', '2015-12-03']"
abstract,"Abstract In this paper we propose the first effective genetic algorithm (GA)-based jigsaw puzzle solver. We introduce a novel crossover procedure that merges two “parent” solutions to an improved “child” configuration
 by detecting, extracting, and combining correctly assembled puzzle segments. The solver proposed exhibits state-of-the-art performance, as far as handling previously attempted puzzles more accurately and efficiently, as well puzzle sizes that have not been attempted before. The extended experimental results provided in this paper include, among others, a thorough inspection of up to 30,745-piece
 puzzles (compared to previous attempts on 22,755-piece puzzles), using a considerably faster concurrent implementation of the algorithm. Furthermore, we explore the impact of different phases of the novel crossover operator by experimenting with several variants of the GA. Finally, we compare different fitness functions and their effect on the overall results of the GA-based solver."
journal_title,Genetic Programming and Evolvable Machines
article_title,Learning to rank: new approach with the layered multi-population genetic programming on click-through features
keyword,"['Learning to rank\xa0', 'Click-through data\xa0', 'Layered multi-population genetic programming\xa0']"
history,"['2016-09', '2016-01-20', '2015-03-12', '2015-12-31']"
abstract,"Abstract Users’ click-through data is a valuable source of information about the performance of Web search engines, but it is included in few datasets for learning to rank. In this paper, inspired by the click-through data model, a novel approach is proposed for extracting the implicit user feedback from evidence embedded in benchmarking datasets. This process outputs a set of new features, named click-through features. Generated click-through features are used in a layered multi-population genetic programming framework to find the best possible ranking functions. The layered multi-population genetic programming framework is fast and provides more extensive search capability compared to the traditional genetic programming approaches. The performance of the proposed ranking generation framework is investigated both in the presence and in the absence of explicit click-through data in the utilized benchmark datasets. The experimental results show that click-through features can be efficiently extracted in both cases but that more effective ranking functions result when click-through features are generated from benchmark datasets with explicit click-through data. In either case, the most noticeable ranking improvements are achieved at the tops of the provided ranked lists of results, which are highly targeted by the Web users."
journal_title,Genetic Programming and Evolvable Machines
article_title,Prediction of the natural gas consumption in chemical processing facilities with genetic programming
keyword,"['Natural gas consumption prediction\xa0', 'Chemical processing\xa0', 'Modeling\xa0', 'Genetic programming\xa0']"
history,"['2016-09', '2016-01-30', '2015-11-18', '2016-01-19']"
abstract,"Abstract 
Cinkarna Ltd. is a chemical processing company in Slovenia and the country’s largest manufacturer of titanium oxides (TiO2). Chemical processing and titanium oxide manufacturing in particular requires high natural gas consumption, and it is difficult to accurately pre-order gas from suppliers. In accordance with the Energy Agency of the Republic of Slovenia regulations, each natural gas supplier regulates and determines the charges for the differences between the ordered (predicted) and the actually supplied quantities of natural gas. Yearly charges for these differences total 1.11 % of supplied natural gas costs (average 50,960 EUR per year). This paper presents natural gas consumption prediction and the minimization of associated costs. The data on daily temperature, steam boilers, sulfur acid and TiO2 production was collected from January 2012 until November 2014. Based on the collected data, a linear regression and a genetic programming model were developed. Compared to the specialist’s prediction of natural gas consumption, the linear regression and genetic programming models reduce the charges for the differences between the ordered and the actually supplied quantities by 3.00 and 5.30 times, respectively. Also, from January until November 2014 the same genetic programming model was used in practice. The results show that in a similar gas consumption regime the differences between the ordered and the actually supplied quantities are statistically significant, namely, they are 3.19 times lower (t test, p < 0.05) than in the period in which the specialist responsible for natural gas consumption made the predictions."
journal_title,Genetic Programming and Evolvable Machines
article_title,Erratum to: Gusz Eiben and Jim Smith: Introduction to evolutionary computing (second edition)
keyword,[]
history,"['2016-06', '2016-05-24']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,"Anthony Brabazon, Michael O’Neill, Sean McGarraghy: Natural computing algorithms"
keyword,[]
history,"['2016-06', '2016-03-09']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Gusz Eiben and Jim Smith (Eds): Introduction to evolutionary computing
keyword,[]
history,"['2016-06', '2016-03-29']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Partial-DNA cyclic memory for bio-inspired electronic cell
keyword,"['Embryonics\xa0', 'Genome memory\xa0', 'Gene shift\xa0', 'Reliability\xa0', 'Self-repair\xa0']"
history,"['2016-06', '2015-08-09', '2015-02-04', '2015-08-02']"
abstract,"Abstract Genome memory is an important aspect of electronic cells. Here, a novel genome memory structure called partial-DNA cyclic memory is proposed, in which cells only store a portion of the system’s entire DNA. The stored gene number is independent of the scale of embryonic array and of the target circuit, and can be set according to actual demand in the design process. Genes can be transferred in the cell and the embryonics array through intracellular and intercellular gene cyclic and non-cyclic shifts, and based on this process the embryonic array’s functional differentiation and self-repair can be achieved. In particular, lost genes caused by faulty cells can be recovered through gene updating based on the remaining normal neighbor cells during the self-repair process. A reliability model of the proposed memory structure is built considering the gene updating method, and depending on the implementations of the memory, the hardware overhead is modeled. Based on the reliability model and hardware overhead model, we can find that the memory can achieve high reliability with relatively few gene backups and with low hardware overhead. Theoretical analysis and a simulation experiment show that the new genome memory structure not only achieves functional differentiation and self-repair of the embryonics array, but also ensures system reliability while reducing hardware overhead. This has significant value in engineering applications, allowing the proposed genome memory structure to be used to design larger scale self-repair chips."
journal_title,Genetic Programming and Evolvable Machines
article_title,A new real-coded stochastic Bayesian optimization algorithm for continuous global optimization
keyword,"['Evolutionary algorithms\xa0', 'Estimation of distribution algorithms\xa0', 'Bayesian optimization algorithms\xa0', 'Bayesian networks\xa0']"
history,"['2016-06', '2016-04-04', '2014-09-27', '2015-08-07']"
abstract,"Abstract 
Estimation of distribution algorithms are considered to be a new class of evolutionary algorithms which are applied as an alternative to genetic algorithms. Such algorithms sample the new generation from a probabilistic model of promising solutions. The search space of the optimization problem is improved by such probabilistic models. In the Bayesian optimization algorithm (BOA), the set of promising solutions forms a Bayesian network and the new solutions are sampled from the built Bayesian network. This paper proposes a novel real-coded stochastic BOA for continuous global optimization by utilizing a stochastic Bayesian network. In the proposed algorithm, the new Bayesian network takes advantage of using a stochastic structure (that there is a probability distribution function for each edge in the network) and the new generation is sampled from the stochastic structure. In order to generate a new solution, some new structure, and therefore a new Bayesian network is sampled from the current stochastic structure and the new solution will be produced from the sampled Bayesian network. Due to the stochastic structure used in the sampling phase, each sample can be generated based on a different structure. Therefore the different dependency structures can be preserved. Before the new generation is generated, the stochastic network’s probability distributions are updated according to the fitness evaluation of the current generation. The proposed method is able to take advantage of using different dependency structures through the sampling phase just by using one stochastic structure. The experimental results reported in this paper show that the proposed algorithm increases the quality of the solutions on the general optimization benchmark problems."
journal_title,Genetic Programming and Evolvable Machines
article_title,Grammar-based generation of variable-selection heuristics for constraint satisfaction problems
keyword,"['Constraint satisfaction problems\xa0', 'Hyper-heuristics \xa0', 'Genetic programming\xa0', 'Variable ordering heuristics\xa0', 'Grammar-based framework\xa0']"
history,"['2016-06', '2015-09-15', '2014-11-15', '2015-08-26']"
abstract,"Abstract We propose a grammar-based genetic programming framework that generates variable-selection heuristics for solving constraint satisfaction problems. This approach can be considered as a generation hyper-heuristic. A grammar to express heuristics is extracted from successful human-designed variable-selection heuristics. The search is performed on the derivation sequences of this grammar using a strongly typed genetic programming framework. The approach brings two innovations to grammar-based hyper-heuristics in this domain: the incorporation of if-then-else rules to the function set, and the implementation of overloaded functions capable of handling different input dimensionality. Moreover, the heuristic search space is explored using not only evolutionary search, but also two alternative simpler strategies, namely, iterated local search and parallel hill climbing. We tested our approach on synthetic and real-world instances. The newly generated heuristics have an improved performance when compared against human-designed heuristics. Our results suggest that the constrained search space imposed by the proposed grammar is the main factor in the generation of good heuristics. However, to generate more general heuristics, the composition of the training set and the search methodology played an important role. We found that increasing the variability of the training set improved the generality of the evolved heuristics, and the evolutionary search strategy produced slightly better results."
journal_title,Genetic Programming and Evolvable Machines
article_title,Evolutionary design of complex approximate combinational circuits
keyword,"['Approximate circuit\xa0', 'Cartesian genetic programming\xa0', 'Binary decision diagram\xa0', 'Fitness function\xa0']"
history,"['2016-06', '2015-12-12', '2015-06-30', '2015-11-13']"
abstract,"Abstract Functional approximation is one of the methods allowing designers to approximate circuits at the level of logic behavior. By introducing a suitable functional approximation, power consumption, area or delay of a circuit can be reduced if some errors are acceptable in a particular application. As the error quantification is usually based on an arithmetic error metric in existing approximation methods, these methods are primarily suitable for the approximation of arithmetic and signal processing circuits. This paper deals with the approximation of general logic (such as pattern matching circuits and complex encoders) in which no additional information is usually available to establish a suitable error metric and hence the error of approximation is expressed in terms of Hamming distance between the output values produced by a candidate approximate circuit and the accurate circuit. We propose a circuit approximation method based on Cartesian genetic programming in which gate-level circuits are internally represented using directed acyclic graphs. In order to eliminate the well-known scalability problems of evolutionary circuit design, the error of approximation is determined by binary decision diagrams. The method is analyzed in terms of computational time and quality of approximation. It is able to deliver detailed Pareto fronts showing various compromises between the area, delay and error. Results  are presented for 16 circuits (with 27–50 inputs) that are too complex to be approximated by means of existing evolutionary circuit design methods."
journal_title,Genetic Programming and Evolvable Machines
article_title,Malachy Eaton: Evolutionary humanoid robotics
keyword,[]
history,"['2016-03', '2015-12-08']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Semantic methods in genetic programming
keyword,[]
history,"['2016-03', '2015-10-30']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Acknowledgment to Reviewers
keyword,[]
history,"['2016-03', '2016-01-09']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Editorial introduction
keyword,[]
history,"['2016-03', '2016-01-25']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Stephen H. Muggleton and Hiroaki Watanabe (Eds.): Latest advances in inductive logic programming
keyword,[]
history,"['2016-03', '2015-12-28']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Subtree semantic geometric crossover for genetic programming
keyword,"['Genetic programming\xa0', 'Semantics\xa0', 'Geometric crossover\xa0', 'Symbolic regression\xa0']"
history,"['2016-03', '2015-10-26', '2014-12-19', '2015-09-23']"
abstract,"Abstract The semantic geometric crossover (SGX) proposed by Moraglio et al. has achieved very promising results and received great attention from researchers, but has a significant disadvantage in the exponential growth in size of the solutions. We propose a crossover operator named subtree semantic geometric crossover (SSGX), with the aim of addressing this issue. It is similar to SGX but uses subtree semantic similarity to approximate the geometric property. We compare SSGX to standard crossover (SC), to SGX, and to other recent semantic-based crossover operators, testing on several symbolic regression problems. Overall our new operator out-performs the other operators on test data performance, and reduces computational time relative to most of them. Further analysis shows that while SGX is rather exploitative, and SC rather explorative, SSGX achieves a balance between the two. A simple method of further enhancing SSGX performance is also demonstrated."
journal_title,Genetic Programming and Evolvable Machines
article_title,Self-tuning geometric semantic Genetic Programming
keyword,"['Genetic Programming\xa0', 'Semantics\xa0', 'Parameters Tuning\xa0']"
history,"['2016-03', '2015-10-24', '2014-12-17', '2015-09-18']"
abstract,"Abstract The process of tuning the parameters that characterize evolutionary algorithms is difficult and can be time consuming. This paper presents a self-tuning algorithm for dynamically updating the crossover and mutation probabilities during a run of genetic programming. The genetic operators that are considered in this work are the geometric semantic genetic operators introduced by Moraglio et al. Differently from other existing self-tuning algorithms, the proposed one works by assigning a (different) crossover and mutation probability to each individual of the population. The experimental results we present show the appropriateness of the proposed self-tuning algorithm: on seven different test problems, the proposed algorithm finds solutions of a quality that is better than, or comparable to, the one achieved using the best known values for the geometric semantic crossover and mutation rates for the same problems. Also, we study how the mutation and crossover probabilities change during the execution of the proposed self-tuning algorithm, pointing out an interesting insight: mutation is basically the only operator used in the exploration phase, while crossover is used for exploitation, further improving good quality solutions."
journal_title,Genetic Programming and Evolvable Machines
article_title,Progress properties and fitness bounds for geometric semantic search operators
keyword,"['Geometric semantic genetic programming\xa0', 'Theory\xa0', 'Metric\xa0', 'Fitness landscape\xa0', 'Fitness bounds\xa0', 'Guarantees of progress\xa0']"
history,"['2016-03', '2015-10-22', '2014-12-19', '2015-09-18']"
abstract,"Abstract Metrics are essential for geometric semantic genetic programming. On one hand, they structure the semantic space and govern the behavior of geometric search operators; on the other, they determine how fitness is calculated. The interactions between these two types of metrics are an important aspect that to date was largely neglected. In this paper, we investigate these interactions and analyze their consequences. We provide a systematic theoretical analysis of the properties of abstract geometric semantic search operators under Minkowski metrics of arbitrary order. For nine combinations of popular metrics (city-block, Euclidean, and Chebyshev) used in fitness functions and of search operators, we derive pessimistic bounds on fitness change. We also define three types of progress properties (weak, potential, and strong) and verify them for operators under those metrics. The analysis allows us to determine the combinations of metrics that are most attractive in terms of progress properties and deterioration bounds."
journal_title,Genetic Programming and Evolvable Machines
article_title,Kenneth O. Stanley and Joel Lehman: Why greatness cannot be planned: the myth of the objective
keyword,[]
history,"['2015-12', '2015-10-27']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Prudent alignment and crossover of decision trees in genetic programming
keyword,"['Genetic programming\xa0', 'Decision trees\xa0', 'Crossover \xa0', 'Context\xa0', 'Alignment\xa0']"
history,"['2015-12', '2015-02-28', '2014-01-03', '2015-02-16']"
abstract,"Abstract Crossover is the central search operator responsible for navigating through unknown problem landscapes while at the same time the main conservation operator, which is supposed to preserve the already learned lessons. This paper is about a novel homologous decision tree crossover operator. Contrary to other tree crossover operators it defines the context for a decision tree node and elaborates a fast one-sample-based tree alignment procedure. The idea is to replace a sub-tree with a better one from the same context, as defined by the decision tree training process. This operator does not rely on the topological properties of the tree but rather on its behavioral properties. During empirical testing the new operator showed the best generalization capabilities."
journal_title,Genetic Programming and Evolvable Machines
article_title,A learning automata-based memetic algorithm
keyword,"['Learning automata (LA)\xa0', 'Local search\xa0', 'Memetic algorithm (MA)\xa0', 'Object migration automata (OMA)\xa0']"
history,"['2015-12', '2015-01-21', '2014-01-09', '2014-12-10']"
abstract,"Abstract Combing a genetic algorithm (GA) with a local search method produces a type of evolutionary algorithm known as a memetic algorithm (MA). Combining a GA with a learning automaton (LA) produces an MA named GALA, where the LA provides the local search function. GALA represents chromosomes as object migration automata (OMAs), whose states represent the history of the local search process. Each state in an OMA has two attributes: the value of the gene (allele), and the degree of association with those values. The local search changes the degree of association between genes and their values. In GALA a chromosome’s fitness is computed using only the value of the genes. GALA is a Lamarckian learning model as it passes on the learned traits acquired by its local search method to offspring by a modification of the genotype. Herein we introduce a modified GALA (MGALA) that behaves according to a Baldwinian learning model. In MGALA the fitness function is computed using a chromosome’s fitness and the history of the local search recorded by the OMA states. In addition, in MGALA the learned traits are not passed to the offspring. Unlike GALA, MGALA uses all the information recorded in an OMA representation of the chromosome, i.e., the degree of association between genes and their alleles, and the value of a gene, to compute the fitness of genes. We used MGALA to solve two problems: object partitioning and graph isomorphism. MGALA outperformed GALA, a canonical MA, and an OMA-based method using computer simulations, in terms of solution quality and rate of convergence."
journal_title,Genetic Programming and Evolvable Machines
article_title,Neutral genetic drift: an investigation using Cartesian Genetic Programming
keyword,"['Cartesian Genetic Programming\xa0', 'Neutral genetic drift \xa0', 'Genetic redundancy\xa0']"
history,"['2015-12', '2015-05-06', '2014-11-18', '2015-04-20']"
abstract,"Abstract Neutral genetic drift is an evolutionary mechanism which can strongly aid the escape from local optima. This makes neutral genetic drift an increasingly important property of Evolutionary Computational methods as more challenging applications are approached. Cartesian Genetic Programming (CGP) is a Genetic Programming technique which contains explicit, as well as the more common implicit, genetic redundancy. As explicit genetic redundancy is easily identified and manipulated it represents a useful tool for investigating neutral genetic drift. The contributions of this paper are as follows. Firstly the paper presents a substantial evaluation of the role and benefits of neutral genetic drift in CGP. Here it is shown that the benefits of explicit genetic redundancy are additive to the benefits of implicit genetic redundancy. This is significant as it indicates that that levels of implicit genetic redundancy present in other Evolutionary Computational methods may be insufficient to fully utilise neutral genetic drift. It is also shown than the identification and manipulation of explicit genetic redundancy is far easier than for implicit genetic redundancy. This is significant as it makes the investigations here possible and leads to new possibilities for allowing more effective use of neutral genetic drift. This is the case not only for CGP, but many other Evolutionary Computational methods which contain explicit genetic redundancy. Finally, it is also shown that neutral genetic drift has additional benefits other than aiding the escape from local optima."
journal_title,Genetic Programming and Evolvable Machines
article_title,Controlling code growth by dynamically shaping the genotype size distribution
keyword,"['Genetic programming\xa0', 'Bloat control\xa0', 'Monte Carlo methods\xa0']"
history,"['2015-12', '2015-02-27', '2014-07-08', '2014-12-29']"
abstract,"Abstract Genetic programming is a hyperheuristic optimization approach that seeks to evolve various forms of symbolic computer programs, in order to solve a wide range of problems. However, the approach can be severely hindered by a significant computational burden and stagnation of the evolution caused by uncontrolled code growth. This paper introduces HARM-GP, a novel operator equalization method that conducts an adaptive shaping of the genotype size distribution of individuals in order to effectively control code growth. Its probabilistic nature minimizes the computational overheads on the evolutionary process while its generic formulation allows it to remain independent of both the problem and the genetic variation operators. Comparative results over twelve problems with different dynamics, and over nine other algorithms taken from the literature, show that HARM-GP is excellent at controlling code growth while maintaining good overall performance. Results  also demonstrate the effectiveness of HARM-GP at limiting overfitting in real-world supervised learning problems."
journal_title,Genetic Programming and Evolvable Machines
article_title,Angelo Cangelosi and Matthew Schlesinger: Developmental robotics
keyword,[]
history,"['2015-09', '2015-07-02']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Software review: the KNIME workflow environment and its applications in genetic programming and machine learning
keyword,[]
history,"['2015-09', '2015-07-25']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,"Patricia Vargas, Ezequiel Di Paolo, Inman Harvey, and Phil Husbands (eds), The Horizons of Evolutionary Robotics, The MIT Press, 2014, ISBN: 978-0-262-02676-5, Hardcover book, 302 pages"
keyword,[]
history,"['2015-09', '2015-06-03']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,A study on Koza’s performance measures
keyword,"['Genetic Programming\xa0', 'Computational effort\xa0', 'Performance measures\xa0', 'Experimental methods\xa0', 'Measurement error\xa0']"
history,"['2015-09', '2014-12-12', '2013-11-14', '2014-11-26']"
abstract,"Abstract John R. Koza defined several metrics to measure the performance of an Evolutionary Algorithm that have been widely used by the Genetic Programming community. Despite the importance of these metrics, and the doubts that they have generated in many authors, their reliability has attracted little research attention, and is still not well understood. The lack of knowledge about these metrics has likely contributed to the decline in their usage in the last years. This paper is an attempt to increase the knowledge about these measures, exploring in which circumstances they are more reliable, providing some clues to improve how they are used, and eventually making their use more justifiable. Specifically, we investigate the amount of uncertainty associated with the measures, taking an analytical and empirical approach and reaching theoretical boundaries to the error. Additionally, a new method to calculate Koza’s performance measures is presented. It is shown that these metrics, under common experimental configurations, have an unacceptable error, which can be arbitrary large in certain conditions."
journal_title,Genetic Programming and Evolvable Machines
article_title,Investigating fitness functions for a hyper-heuristic evolutionary algorithm in the context of balanced and imbalanced data classification
keyword,"['Hyper-heuristics\xa0', 'Decision trees\xa0', 'Fitness function \xa0', 'Imbalanced data\xa0']"
history,"['2015-09', '2014-10-26', '2013-10-20', '2014-07-21']"
abstract,"Abstract In this paper, we analyse in detail the impact of different strategies to be used as fitness function during the evolutionary cycle of a hyper-heuristic evolutionary algorithm that automatically designs decision-tree induction algorithms (HEAD-DT). We divide the experimental scheme into two distinct scenarios: (1) evolving a decision-tree induction algorithm from multiple balanced data sets; and (2) evolving a decision-tree induction algorithm from multiple imbalanced data sets. In each of these scenarios, we analyse the difference in performance of well-known classification performance measures such as accuracy, F-Measure, AUC, recall, and also a lesser-known criterion, namely the relative accuracy improvement. In addition, we analyse different schemes of aggregation, such as simple average, median, and harmonic mean. Finally, we verify whether the best-performing fitness functions are capable of providing HEAD-DT with algorithms more effective than traditional decision-tree induction algorithms like C4.5, CART, and REPTree. Experimental results indicate that HEAD-DT is a good option for generating algorithms tailored to (im)balanced data, since it outperforms state-of-the-art decision-tree induction algorithms with statistical significance."
journal_title,Genetic Programming and Evolvable Machines
article_title,Review and comparative analysis of geometric semantic crossovers
keyword,"['Geometry\xa0', 'Semantics\xa0', 'Fitness landscape\xa0', 'Crossover\xa0', 'Theory\xa0', 'Experiment\xa0']"
history,"['2015-09', '2014-12-23', '2014-07-03', '2014-12-04']"
abstract,"Abstract This paper provides a structured, unified, formal and empirical perspective on all geometric semantic crossover operators proposed so far, including the exact geometric crossover by Moraglio, Krawiec, and Johnson, as well as the approximately geometric operators. We start with presenting the theory of geometric semantic genetic programming, and discuss the implications of geometric operators for the structure of fitness landscape. We prove that geometric semantic crossover can by construction produce an offspring that is not worse than the fitter parent, and that under certain conditions such an offspring is guaranteed to be not worse than the worse parent. We review all geometric semantic crossover operators presented to date in the literature, and conduct a comprehensive experimental comparison using a tree-based genetic programming framework and a representative suite of nine symbolic regression and nine Boolean function synthesis tasks. We scrutinize the performance (program error and success rate), generalization, computational cost, bloat, population diversity, and the operators’ capability to generate geometric offspring. The experiment leads to several interesting conclusions, the primary one being that an operator’s capability to produce geometric offspring is positively correlated with performance. The paper is concluded by recommendations regarding the suitability of operators for the particular domains of program induction tasks."
journal_title,Genetic Programming and Evolvable Machines
article_title,Evolutionary model building under streaming data for classification tasks: opportunities and challenges
keyword,"['Streaming data\xa0', 'Non-stationary processes\xa0', 'Dynamic environment\xa0', 'Imbalanced data\xa0', 'Task decomposition\xa0', 'Ensemble learning\xa0', 'Active learning\xa0', 'Evolvability\xa0', 'Diversity\xa0', 'Memory\xa0']"
history,"['2015-09', '2014-11-14', '2014-02-17', '2014-10-23']"
abstract,"Abstract Streaming data analysis potentially represents a significant shift in emphasis from schemes historically pursued for offline (batch) approaches to the classification task. In particular, a streaming data application implies that: (1) the data itself has no formal ‘start’ or ‘end’; (2) the properties of the process generating the data are non-stationary, thus models that function correctly for some part(s) of a stream
 may be ineffective elsewhere; (3) constraints on the time to produce a response, potentially implying an anytime operational requirement; and (4) given the prohibitive cost of employing an oracle to label a stream, a finite labelling budget is necessary. The scope of this article is to provide a survey of developments for model building under streaming environments from the perspective of both evolutionary and non-evolutionary frameworks. In doing so, we bring attention to the challenges and opportunities that developing solutions to streaming data classification tasks are likely to face using evolutionary approaches."
journal_title,Genetic Programming and Evolvable Machines
article_title,Balanced Cartesian Genetic Programming via migration and opposition-based learning: application to symbolic regression
keyword,"['Cartesian Genetic Programming\xa0', 'Biogeography-based optimization\xa0', 'Migration\xa0', 'Opposition-based learning\xa0', 'Exploration–exploitation trading-off\xa0']"
history,"['2015-06', '2014-07-29', '2013-09-02', '2014-07-09']"
abstract,"Abstract The exploration–exploitation trade-off is an important aspect of evolutionary algorithms which determines the efficiency and accuracy of these algorithms. Cartesian Genetic Programming (CGP) is a generalization of the graph based genetic programming. It is implemented with mutation only and does not have any possibility to share information among solutions. The main goal of this paper is to present an effective method for balancing the exploration and exploitation of CGP referred to as Balanced Cartesian Genetic Programming (BCGP) by incorporating distinctive features from biogeography-based optimization (BBO) and opposition-based learning. To achieve this goal, we apply BBO’s migration operator without considering any modifications in the representation of CGP. This operator has good exploitation ability and can be used to share information among individuals in CGP. In addition, in order to improve the exploration ability of CGP, a new mutation operator is integrated into CGP inspired from the concept of opposition-based learning. Experiments have been conducted on symbolic regression. The experimental results show that the proposed BCGP method outperforms the traditional CGP in terms of accuracy and the convergence speed."
journal_title,Genetic Programming and Evolvable Machines
article_title,Multiobjective optimization algorithms for motif discovery in DNA sequences
keyword,"['Computer science\xa0', 'Multiobjective optimization\xa0', 'Metaheuristics\xa0', 'Motif discovery\xa0', 'Bioinformatics\xa0']"
history,"['2015-06', '2014-09-04', '2014-01-17', '2014-07-24']"
abstract,"Abstract Optimization techniques have become powerful tools for approaching multiple NP-hard optimization problems. In this kind of problem it is practically impossible to obtain optimal solutions, thus we must apply approximation strategies such as metaheuristics. In this paper, seven metaheuristics have been used to address an important biological problem known as the motif discovery problem. As it is defined as a multiobjective optimization problem, we have adapted the proposed algorithms to this optimization context. We evaluate the proposed metaheuristics on 54 sequence datasets that belong to four organisms with different numbers of sequences and sizes. The results have been analysed in order to discover which algorithm performs best in each case. The algorithms implemented and the results achieved can assist biological researchers in the complicated task of finding DNA patterns with an important biological relevance."
journal_title,Genetic Programming and Evolvable Machines
article_title,Evolving robot sub-behaviour modules using Gene Expression Programming
keyword,"['Gene Expression Programming\xa0', 'Subsumption architecture \xa0', 'Layered learning\xa0', 'Evolutionary robotics\xa0', 'Robot behaviour coordination\xa0']"
history,"['2015-06', '2014-07-11', '2012-08-27', '2014-05-16']"
abstract,"Abstract Many approaches to AI in robotics use a multi-layered approach to determine levels of behaviour from basic operations to goal-directed behaviour, the most well-known of which is the subsumption architecture. In this paper, the performances of the unigenic Gene Expression Programming (ugGEP) and multigenic GEP (mgGEP) in evolving robot controllers for a wall following robot are analysed. Additionally, the paper introduces Regulatory Multigenic Gene Expression Programming, a new evolutionary technique that can be utilised to automatically evolve modularity in robot behaviour. The proposed technique extends the mgGEP algorithm, by incorporating a regulatory gene as part of the GEP chromosome. The regulatory gene, just as in systems biology, determines which of the genes in the chromosome to express and therefore how the controller solves the problem. In the initial experiments, the proposed algorithm is implemented for a robot wall following problem and the results compared to that of ugGEP and mgGEP. In addition to the wall following behaviour, a robot foraging behaviour is implemented with the aim of investigating whether the position of a specific module (sub-expression tree) in the overall expression tree is of importance when coding for a problem."
journal_title,Genetic Programming and Evolvable Machines
article_title,A hierarchical genetic algorithm approach for curve fitting with B-splines
keyword,"['Genetic algorithm\xa0', 'Regression\xa0', 'Curve fitting\xa0', 'B-splines\xa0']"
history,"['2015-06', '2014-09-17', '2013-06-08', '2014-05-06']"
abstract,"Abstract Automatic curve fitting using splines has been widely used in data analysis and engineering applications. An important issue associated with data fitting by splines is the adequate selection of the number and location of the knots, as well as the calculation of the spline coefficients. Typically, these parameters are estimated separately with the aim of solving this non-linear problem. In this paper, we use a hierarchical genetic algorithm to tackle the B-spline curve fitting problem. The proposed approach is based on a novel hierarchical gene structure for the chromosomal representation, which allows us to determine the number and location of the knots, and the B-spline coefficients automatically and simultaneously. Our approach is able to find optimal solutions with the fewest parameters within the B-spline basis functions. The method is fully based on genetic algorithms and does not require subjective parameters like smooth factor or knot locations to perform the solution. In order to validate the efficacy of the proposed approach, simulation results from several tests on smooth functions and comparison with a successful method from the literature have been included."
journal_title,Genetic Programming and Evolvable Machines
article_title,Exploring non-photorealistic rendering with genetic programming
keyword,"['Non-photorealistic rendering\xa0', 'Genetic programming\xa0', 'Evolutionary art.\xa0']"
history,"['2015-06', '2014-10-26', '2013-08-20', '2014-10-01']"
abstract,"Abstract The field of evolutionary art focuses on using artificial evolution as a means for generating and exploring artistic images and designs. Here, we use evolutionary computation to generate painterly styles of images. A source image is read into the system, and a genetic program is evolved that will re-render the image with non-photorealistic effects. A main contribution of this research is that the colour mixing expression is evolved, which permits a variety of interesting NPR effects to arise. The mixing expression evaluates mathematical properties of the dynamically changing canvas, which results in the evolution of adaptive NPR procedures. Automatic fitness evaluation includes Ralph’s aesthetic model, colour matching, and direct luminosity matching. A few simple techniques for economical brush stroke application on the canvas are supported, which produce different stylistic effects. Using our approach, a number of established, as well as innovative, non-photorealistic painting effects were produced."
journal_title,Genetic Programming and Evolvable Machines
article_title,Acknowledgment
keyword,[]
history,"['2015-03', '2014-12-10']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Editorial introduction
keyword,[]
history,"['2015-03', '2015-01-07']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Introducing a cross platform open source Cartesian Genetic Programming library
keyword,"['Cartesian Genetic Programming\xa0', 'Software library\xa0', 'NeuroEvolution\xa0']"
history,"['2015-03', '2014-08-31', '2014-07-21']"
abstract,"Abstract Cartesian Genetic Programming (CGP) is a form of Genetic Programming which encodes computational structures as generic cyclic/acyclic graphs. This letter introduces a new cross platform CGP library intended for use in teaching, academic research and real world applications. This new CGP library is currently capable of evolving symbolic expressions, Boolean logic circuits and Artificial Neural Networks but can easily be extended to other domains. The CGP library, documentation and tutorials are all available at www.cgplibrary.co.uk."
journal_title,Genetic Programming and Evolvable Machines
article_title,A C++ framework for geometric semantic genetic programming
keyword,"['Genetic programming\xa0', 'Semantics\xa0', 'Geometric operators\xa0', 'C++\xa0']"
history,"['2015-03', '2014-04-02', '2013-09-25', '2014-02-24']"
abstract,"Abstract Geometric semantic operators are new and promising genetic operators for genetic programming. They have the property of inducing a unimodal error surface for any supervised learning problem, i.e., any problem consisting in finding the match between a set of input data and known target values (like regression and classification). Thanks to an efficient implementation of these operators, it was possible to apply them to a set of real-life problems, obtaining very encouraging results. We have now made this implementation publicly available as open source software, and here we describe how to use it. We also reveal details of the implementation and perform an investigation of its efficiency in terms of running time and memory occupation, both theoretically and experimentally. The source code and documentation are available for download at http://gsgp.sourceforge.net."
journal_title,Genetic Programming and Evolvable Machines
article_title,Improving GP generalization: a variance-based layered learning approach
keyword,"['Genetic programming\xa0', 'Generalization\xa0', 'Layered learning\xa0', 'Overfitting\xa0', 'Variance\xa0']"
history,"['2015-03', '2014-05-08', '2013-09-20', '2014-04-08']"
abstract,"Abstract This paper introduces a new method that improves the generalization ability of genetic programming (GP) for symbolic regression problems, named variance-based layered learning GP. In this approach, several datasets, called primitive training sets, are derived from the original training data. They are generated from less complex to more complex, for a suitable complexity measure. The last primitive dataset is still less complex than the original training set. The approach decomposes the evolution process into several hierarchical layers. The first layer of the evolution starts using the least complex (smoothest) primitive training set. In the next layers, more complex primitive sets are given to the GP engine. Finally, the original training data is given to the algorithm. We use the variance of the output values of a function as a measure of the functional complexity. This measure is utilized in order to generate smoother training data, and controlling the functional complexity of the solutions to reduce the overfitting. The experiments, conducted on four real-world and three artificial symbolic regression problems, demonstrate that the approach enhances the generalization ability of the GP, and reduces the complexity of the obtained solutions."
journal_title,Genetic Programming and Evolvable Machines
article_title,GA-based approach to find the stabilizers of a given sub-space
keyword,"['Genetic algorithms\xa0', 'Pauli matrices\xa0', 'Quantum information\xa0', 'Stabilizer formalism\xa0']"
history,"['2015-03', '2014-05-07', '2013-09-09', '2014-03-10']"
abstract,"Abstract Stabilizer formalism is a powerful framework for understanding a wide class of operations in quantum information. This formalism is a framework where multiple qubit states and sub-spaces are described in a compact way in terms of operators under which they are invariant. In stabilizer formalism, one focuses the members of Pauli groups which have the stabilizing property of a given sub-space. Therefore, finding the Pauli stabilizers of a given sub-space in an efficient way is of great interest. In this paper, this problem is addressed in the field of quantum information theory. We present a two-phase algorithm to solve the problem whose order of complexity is considerably smaller than the common solution. In the first phase, a genetic algorithm is run. The results obtained by this algorithm are the matrices that can potentially be the Pauli stabilizers of the given sub-space. Then an analytical approach is applied to find the correct answers among the results of the first phase. Experimental results show that speed-ups are remarkable as compared to the common solution."
journal_title,Genetic Programming and Evolvable Machines
article_title,Training genetic programming classifiers by vicinal-risk minimization
keyword,"['Genetic programming\xa0', 'Classification\xa0', 'Vicinal-risk minimization\xa0']"
history,"['2015-03', '2014-06-03', '2013-11-19', '2014-05-13']"
abstract,"Abstract We propose and motivate the use of vicinal-risk minimization (VRM) for training genetic programming classifiers. We demonstrate that VRM has a number of attractive properties and demonstrate that it has a better correlation with generalization error compared to empirical risk minimization (ERM) so is more likely to lead to better generalization performance, in general. From the results of statistical tests over a range of real and synthetic datasets, we further demonstrate that VRM yields consistently superior generalization errors compared to conventional ERM."
journal_title,Genetic Programming and Evolvable Machines
article_title,Special issue on GECCO competitions
keyword,[]
history,"['2014-12', '2014-06-14']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Gene regulated car driving: using a gene regulatory network to drive a virtual car
keyword,"['Gene regulatory network\xa0', 'Virtual car racing\xa0', 'Machine learning\xa0', 'Incremental evolution\xa0']"
history,"['2014-12', '2014-06-21', '2013-10-18', '2014-05-19']"
abstract,"Abstract This paper presents a virtual racing car controller based on an artificial gene regulatory network. Usually used to control virtual cells in developmental models, recent works showed that gene regulatory networks are also capable to control various kinds of agents such as foraging agents, pole cart, swarm robots, etc. This paper details how a gene regulatory network is evolved to drive on any track through a three-stages incremental evolution. To do so, the inputs and outputs of the network are directly mapped to the car sensors and actuators. To make this controller a competitive racer, we have distorted its inputs online to make it drive faster and to avoid opponents. Another interesting property emerges from this approach: the regulatory network is naturally resistant to noise. To evaluate this approach, we participated in the 2013 simulated racing car competition against eight other evolutionary and scripted approaches. After its first participation, this approach finished in third place in the competition."
journal_title,Genetic Programming and Evolvable Machines
article_title,Evolving Robocode tanks for Evo Robocode
keyword,"['Genetic programming\xa0', 'Robocode\xa0', 'Co-evolution\xa0', 'SCALP\xa0']"
history,"['2014-12', '2014-06-19', '2013-10-20', '2014-05-18']"
abstract,"Abstract Evo Robocode is a competition where the challenge is to use evolutionary techniques to create a Java based controller for a simulated robot tank. The tank competes in a closed arena against other such tanks. The Robocode game is a programming platform that allows such tanks to compete. This article discusses the use of Grammatical Evolution (a form of genetic programming) together with spatial co-evolution. This system harnessed co-evolution to evolve relatively complex behaviours, within the program size constraints of the competition. The entry for the 2013 Evo Robocode competition was not evolved against any human coded robots and yet was able to compete effectively against many previously unseen opponents. The co-evolutionary system was then compared to a system that used a handcrafted fitness gradient consisting of pre-selected human coded robots. The top robots from the co-evolved system performed as well as those evolved using a hand crafted fitness function, scoring well against such robots in head to head battles."
journal_title,Genetic Programming and Evolvable Machines
article_title,Driving as a human: a track learning based adaptable architecture for a car racing controller
keyword,"['Car racing\xa0', 'Evolutionary computation\xa0', 'TORCS\xa0', 'Planning controller\xa0']"
history,"['2014-12', '2014-06-19', '2013-10-28', '2014-05-16']"
abstract,"Abstract We present the evolution and current state of the Mr. Racer car racing controller that excelled at the corresponding TORCS competitions of the last years. Although several heuristics and black-box optimization methods are employed, the basic idea of the controller architecture has been to take over many of the mechanisms human racing drivers apply. They learn the track geometry, plan ahead, and wherever necessary, adapt their plans to the current circumstances quickly. Mr. Racer consists of several modules that have partly been adapted and optimized separately, where the final tuning is usually done with respect to a certain racing track during the warmup phase of the TORCS competitions. We also undertake an experimental evaluation that investigates how the controller profits from adding some of the modules to a basic configuration and which modules are most important for reaching the best possible performance."
journal_title,Genetic Programming and Evolvable Machines
article_title,Unplugging Evolutionary Algorithms: an experiment on human-algorithmic creativity
keyword,"['Evolutionary art\xa0', 'Computational creativity\xa0', 'Interactive Evolutionary Algorithms\xa0']"
history,"['2014-12', '2014-06-15', '2013-10-14', '2014-05-10']"
abstract,"Abstract 
Understanding and emulating human creativity is a key factor when developing computer based algorithms devoted to art. This paper presents a new evolutionary approach to art and creativity aimed at comprehending human principles and motivations, behaviors and procedures from an evolutionary point of view. The results, and the collective artwork described, is the product of a new methodology derived from the Interactive Evolutionary Algorithm (IEA), that allowed a team of artists to collaborate following evolutionary procedures in a number of generations while providing interesting information from the creative process developed. Instead of relegating artists to merely evaluating the output of a standard IEA, we provided them with the fundamentals, operators and ideas extracted from IEAs, and asked them to apply those principles while creating a collective artwork. Artists thus focused on their inner creative process with an evolutionary perspective, providing insights that hopefully will allow us to improve future versions of EAs when devoted to art. This paper describes the methodology behind the work and the experiment performed, and analyzes the collective work generated, that eventually became GECCO 2013 Art Design and Creativity Competition award-winning artwork in Amsterdam."
journal_title,Genetic Programming and Evolvable Machines
article_title,Evolvability and robustness in artificial evolving systems: three perturbations
keyword,[]
history,"['2014-09', '2014-06-03']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Designing robust volunteer-based evolutionary algorithms
keyword,"['Evolutionary computation\xa0', 'Distributed algorithms\xa0', 'Fault tolerance\xa0', 'Genetic programming\xa0', 'Genetic algorithms\xa0', 'Volunteer computing\xa0', 'Peer-to-peer\xa0', 'Desktop grid\xa0']"
history,"['2014-09', '2014-01-24', '2013-05-29', '2013-12-10']"
abstract,"Abstract This paper tackles the design of scalable and fault-tolerant evolutionary algorithms computed on volunteer platforms. These platforms aggregate computational resources from contributors all around the world. Given that resources may join the system only for a limited period of time, the challenge of a volunteer-based evolutionary algorithm is to take advantage of a large amount of computational power that in turn is volatile. The paper analyzes first the speed of convergence of massively parallel evolutionary algorithms. Then, it provides some guidance about how to design efficient policies to overcome the algorithmic loss of quality when the system undergoes high rates of transient failures, i.e. computers fail only for a limited period of time and then become available again. In order to provide empirical evidence, experiments were conducted for two well-known problems which require large population sizes to be solved, the first based on a genetic algorithm and the second on genetic programming. Results  show that, in general, evolutionary algorithms undergo a graceful degradation under the stress of losing computing nodes. Additionally, new available nodes can also contribute to improving the search process. Despite losing up to 90 % of the initial computing resources, volunteer-based evolutionary algorithms can find the same solutions in a failure-prone as in a failure-free run."
journal_title,Genetic Programming and Evolvable Machines
article_title,Software mutational robustness
keyword,"['Mutational robustness\xa0', 'Genetic programming\xa0', 'Mutation testing\xa0', 'Proactive diversity\xa0', 'N-version programming\xa0', 'Neutral landscapes\xa0']"
history,"['2014-09', '2013-07-28', '2012-11-30']"
abstract,"Abstract Neutral landscapes and mutational robustness are believed to be important enablers of evolvability in biology. We apply these concepts to software, defining mutational robustness to be the fraction of random mutations to program code that leave a program’s behavior unchanged. Test cases are used to measure program behavior and mutation operators are taken from earlier work on genetic programming. Although software is often viewed as brittle, with small changes leading to catastrophic changes in behavior, our results show surprising robustness in the face of random software mutations. The paper describes empirical studies of the mutational robustness of 22 programs, including 14 production software projects, the Siemens benchmarks, and four specially constructed programs. We find that over 30 % of random mutations are neutral with respect to their test suite. The results hold across all classes of programs, for mutations at both the source code and assembly instruction levels, across various programming languages, and bear only a limited relation to test suite coverage. We conclude that mutational robustness is an inherent property of software, and that neutral variants (i.e., those that pass the test suite) often fulfill the program’s original purpose or specification. Based on these results, we conjecture that neutral mutations can be leveraged as a mechanism for generating software diversity. We demonstrate this idea by generating a population of neutral program variants and showing that the variants automatically repair latent bugs. Neutral landscapes also provide a partial explanation for recent results that use evolutionary computation to automatically repair software bugs."
journal_title,Genetic Programming and Evolvable Machines
article_title,Self-repair ability of evolved self-assembling systems in cellular automata
keyword,"['Cellular automata\xa0', 'Robustness\xa0', 'Repair\xa0', 'Self-repair\xa0', 'Self-assembly\xa0']"
history,"['2014-09', '2014-03-12', '2013-04-19', '2013-10-01']"
abstract,"Abstract Self-repairing systems are those that are able to reconfigure themselves following disruptions to bring them back into a defined normal state. In this paper we explore the self-repair ability of some cellular automata-like systems, which differ from classical cellular automata by the introduction of a local diffusion process inspired by chemical signalling processes in biological development. The update rules in these systems are evolved using genetic programming to self-assemble towards a target pattern. In particular, we demonstrate that once the update rules have been evolved for self-assembly, many of those update rules also provide a self-repair ability without any additional evolutionary process aimed specifically at self-repair."
journal_title,Genetic Programming and Evolvable Machines
article_title,On evolvability and robustness in the matrix-GRT model
keyword,"['Evolvability\xa0', 'Emergence of replication\xa0', 'GRT model\xa0', 'RNA world\xa0', 'Protein world\xa0', 'Evolutionary robustness\xa0']"
history,"['2014-09', '2014-06-08', '2013-04-30', '2014-05-16']"
abstract,"Abstract Quantifying evolution and understanding robustness are best done with a system that is both rich enough to frustrate rigging of the answer and simple enough to permit comparison against either existing systems or absolute measures. Such a system is provided by the self-referential model matrix-genome, replication and translation, based on the concept of operators, which is introduced here. Ideas are also taken from the evolving micro-controller research. This new model replaces micro-controllers by simple matrix operations. These matrices, seen as abstract proteins, work on abstract genomes, peptides or other proteins. Studying the evolutionary properties shows that the protein-only hypothesis (proteins as active elements) shows poor evolvability and the RNA-before-protein hypothesis (genomes controlling) exhibits similar intricate evolutionary dynamics as in the micro-controller model. A simple possible explanation for this surprising difference in behavior is presented. In addition to existing evolutionary models, dynamical and organizational changes or transitions occurring late in long-term experiments are demonstrated."
journal_title,Genetic Programming and Evolvable Machines
article_title,Hardware architecture of the Protein Processing Associative Memory and the effects of dimensionality and quantisation on performance
keyword,"['Protein processing\xa0', 'PPAM\xa0', 'FPGA\xa0', 'Associative memory\xa0', 'BERT2\xa0', 'Inverse kinematics\xa0', 'Dimensionality\xa0', 'Quantisation\xa0', 'Non-standard computation\xa0']"
history,"['2014-09', '2014-04-02', '2014-01-11', '2014-02-21']"
abstract,"Abstract The Protein Processor Associative Memory (PPAM) is a novel hardware architecture for a distributed, decentralised, robust and scalable, bidirectional, hetero-associative memory, that can adapt online to changes in the training data. The PPAM uses the location of data in memory to identify relationships and is therefore fundamentally different from traditional processing methods that tend to use arithmetic operations to perform computation. This paper presents the hardware architecture and details a sample digital logic implementation with an analysis of the implications of using existing techniques for such hardware architectures. It also presents the results of implementing the PPAM for a robotic application that involves learning the forward and inverse kinematics. The results show that, contrary to most other techniques, the PPAM benefits from higher dimensionality of data, and that quantisation intervals are crucial to the performance of the PPAM."
journal_title,Genetic Programming and Evolvable Machines
article_title,Daren C. Brabham: Crowdsourcing
keyword,[]
history,"['2014-06', '2014-02-05']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Software review: the HeuristicLab framework
keyword,"['Evolutionary Algorithm\xa0', 'Graphical User Interface\xa0', 'Graphic Processing Unit\xa0', 'Fitness Evaluation Function\xa0', 'Video Tutorial\xa0']"
history,"['2014-06', '2014-01-24', '2014-01-15', '2014-01-15']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,A new real-coded Bayesian optimization algorithm based on a team of learning automata for continuous optimization
keyword,"['Estimation of distribution algorithms\xa0', 'Bayesian optimization algorithm\xa0', 'Learning automata\xa0']"
history,"['2014-06', '2013-10-16', '2012-10-12', '2013-08-24']"
abstract,"Abstract Estimation of distribution algorithms have evolved as a technique for estimating population distribution in evolutionary algorithms. They estimate the distribution of the candidate solutions and then sample the next generation from the estimated distribution. Bayesian optimization algorithm is an estimation of distribution algorithm, which uses a Bayesian network to estimate the distribution of candidate solutions and then generates the next generation by sampling from the constructed network. The experimental results show that the Bayesian optimization algorithms are capable of identifying correct linkage between the variables of optimization problems. Since the problem of finding the optimal Bayesian network belongs to the class of NP-hard problems, typically Bayesian optimization algorithms use greedy algorithms to build the Bayesian network. This paper proposes a new real-coded Bayesian optimization algorithm for solving continuous optimization problems that uses a team of learning automata to build the Bayesian network. This team of learning automata tries to learn the optimal Bayesian network structure during the execution of the algorithm. The use of learning automaton leads to an algorithm with lower computation time for building the Bayesian network. The experimental results reported here show the preference of the proposed algorithm on both uni-modal and multi-modal optimization problems."
journal_title,Genetic Programming and Evolvable Machines
article_title,Probabilistic model building in genetic programming: a critical review
keyword,"['Probabilistic model building\xa0', 'Estimation of distribution\xa0', 'Ant colony\xa0', 'Genetic programming\xa0', 'Iterated density estimation\xa0', 'Prototype tree\xa0', 'Stochastic grammar\xa0']"
history,"['2014-06', '2013-09-17', '2012-12-09', '2013-06-05']"
abstract,"Abstract Probabilistic model-building algorithms (PMBA), a subset of evolutionary algorithms, have been successful in solving complex problems, in addition providing analytical information about the distribution of fit individuals. Most PMBA work has concentrated on the string representation used in typical genetic algorithms. A smaller body of work has aimed to apply the useful concepts of PMBA to genetic programming (GP), mostly concentrating on tree representation. Unfortunately, the latter research has been sporadically carried out, and reported in several different research streams, limiting substantial communication and discussion. In this paper, we aim to provide a critical review of previous applications of PMBA and related methods in GP research, to facilitate more vital communication. We illustrate the current state of research in applying PMBA to GP, noting important perspectives. We use these to categorise practical PMBA models for GP, and describe the main varieties on this basis."
journal_title,Genetic Programming and Evolvable Machines
article_title,A survey of semantic methods in genetic programming
keyword,"['Genetic programming\xa0', 'Semantics\xa0', 'Genotype/phenotype\xa0', 'Survey\xa0']"
history,"['2014-06', '2014-01-16', '2013-07-11', '2013-12-16']"
abstract,"Abstract Several methods to incorporate semantic awareness in genetic programming have been proposed in the last few years. These methods cover fundamental parts of the evolutionary process: from the population initialization, through different ways of modifying or extending the existing genetic operators, to formal methods, until the definition of completely new genetic operators. The objectives are also distinct: from the maintenance of semantic diversity to the study of semantic locality; from the use of semantics for constructing solutions which obey certain constraints to the exploitation of the geometry of the semantic topological space aimed at defining easy-to-search fitness landscapes. All these approaches have shown, in different ways and amounts, that incorporating semantic awareness may help improving the power of genetic programming. This survey analyzes and discusses the state of the art in the field, organizing the existing methods into different categories. It restricts itself to studies where semantics is intended as the set of output values of a program on the training data, a definition that is common to a rather large set of recent contributions. It does not discuss methods for incorporating semantic information into grammar-based genetic programming or approaches based on formal methods. The objective is keeping the community updated on this interesting research track, hoping to motivate new and stimulating contributions."
journal_title,Genetic Programming and Evolvable Machines
article_title,Introduction
keyword,[]
history,"['2014-03', '2014-01-04']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Peer commentary on Wolfgang Banzhaf’s “genetic programming and emergence”
keyword,[]
history,"['2014-03', '2013-12-08']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Gene I. Sher: Handbook of neuroevolution through Erlang
keyword,[]
history,"['2014-03', '2013-08-11']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Acknowledgment
keyword,[]
history,"['2014-03', '2014-01-04']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Anne Auger and Benjamin Doerr (eds): Theory of randomized search heuristics: foundations and recent developments
keyword,[]
history,"['2014-03', '2013-10-26']"
abstract,None
journal_title,Genetic Programming and Evolvable Machines
article_title,Mathematics awaits: commentary on “Genetic Programming and Emergence” by Wolfgang Banzhaf
keyword,"['Evolvability\xa0', 'Robustness\xa0', 'Subtree exchange\xa0', 'Mathematics\xa0', 'Matrix theory\xa0', 'Lagrange distribution\xa0']"
history,"['2014-03', '2013-10-10']"
abstract,"Abstract Banzhaf provides a portal to the subject of emergence, noting contentious concepts while not getting sucked into fruitless debate. Banzhaf refutes arguments against downward causation much as Samuel Johnson kicks a stone to ref ute Berkeley—by pointing to concrete examples in genetic programming, such as the growth of repetitive patterns within programs. Repetitive patterns are theoretically predicted to emerge from the evolution of evolvability and robustness under subtree exchange. Selection and genetic operators are co-equal creators of these emergent phenomena. GP systems entirely formal, and thus their emergent phenomena are essentially mathematical. The emergence of Lagrangian distributions for tree shapes under subtree exchange, for example, gives a glimpse of the possibilities for mathematical understanding of emergence in GP. The mathematics underlying emergence in genetic programming should be pursued with vigor."
journal_title,Genetic Programming and Evolvable Machines
article_title,Genetic programming: where meaning emerges from program code
keyword,"['Genetic programming\xa0', 'Emergence\xa0', 'Semantics\xa0', 'Modularity\xa0', 'Interactions\xa0']"
history,"['2014-03', '2013-10-10']"
abstract,"Abstract Program behavior results from the interactions of instructions with data. In genetic programming, a substantial part of that behavior is not explicitly rewarded by fitness function, and thus emergent. This includes the intermediate memory states traversed by the executing programs. We argue that the potentially useful intermediate states can be detected and used to make evolutionary search more effective."
journal_title,Genetic Programming and Evolvable Machines
article_title,Genetic Programming and Emergence
keyword,"['Genetic programming\xa0', 'Emergence\xa0', 'Emergent phenomena\xa0', 'Top-down causation\xa0', 'Repetitive patterns\xa0', 'Modularity\xa0']"
history,"['2014-03', '2013-08-21', '2012-11-27']"
abstract,"Abstract Emergence and its accompanying phenomena are a widespread process in nature. Despite its prominence, there is no agreement in the sciences about the concept and how to define or measure emergence. One of the most contentious issues discussed is that of top-down (or downward) causation as a defining characteristic of systems with emergence. In this contribution we shall argue that emergence happens in Genetic Programming, for all the world to see."
journal_title,Journal of Materials Science
article_title,The oxidase-like activity of hemin encapsulated by single-ring GroEL mutant and its application for colorimetric detection
keyword,[]
history,"['2018-06', '2018-03-13', '2018-01-16', '2018-03-08']"
abstract,"Abstract Supramolecular anchoring of metalloporphyrins in a protein is an attractive approach to the generation of artificial enzymes. Here, we employ the hydrophobic nanocage of single-ring mutant of bacterial GroEL protein for this purpose. We found that multiple monomeric hemin cofactors can be efficiently loaded into the protein nanocage. The as-prepared biohybrid possessed an oxidase-like catalytic activity and followed the typical Michaelis–Menten kinetics and a ping-pong mechanism in the H2O2-mediated oxidation of model substrates. In comparison with natural peroxidase, the artificial enzyme exhibited higher affinity for the model substrate. A simple and sensitive colorimetric method for the quantitative detection of H2O2 and glucose was also developed based on the artificial enzyme, with the detection limits determined to be 3.0 μM for H2O2 and 5.0 μM for glucose, respectively. The protein nanocage-based artificial enzyme is very flexible and is envisioned to be adapted readily for binding other metal complexes and catalysis of other reactions."
journal_title,Journal of Materials Science
article_title,Surface half-metallicity in the Heusler alloy Cr2CoGa with low magnetic moment
keyword,[]
history,"['2018-06', '2018-02-26', '2017-10-23', '2018-02-15']"
abstract,"Abstract Half-metallic fully compensated ferrimagnets (HM-FCFs) are important spintronic materials due to the high spin polarization and the low magnetic moment. Recently, motivated by the theoretical prediction of HM-FCF of bulk Cr2CoGa, ordered inverse Heusler structural Cr2CoGa thin films were grown by molecular beam epitaxy, and the predicted low magnetic moment and high Curie temperature were also confirmed. Here, in order to compare the electronic and magnetic properties between bulk and thin films for Cr2CoGa, we explore the structural stability, electronic and magnetic properties of Cr2CoGa (001) surface by using first-principles calculations. It is found that the nearly half-metallicity of bulk Cr2CoGa is preserved at the Cr2Ga-terminated (001) surface, and the spin polarization is a little increased compared to the bulk value. However, the Cr1Co-terminated (001) surface destroys the bulk nearly half-metallicity due to the majority-spin surface states at the Fermi level. Cr atomic magnetic moments at both (001) surfaces are greatly increased compared to those in bulk for Cr2CoGa. In addition, we reveal that the Cr2Ga-terminated (001) surface is more stable than the Cr1Co-terminated (001) surface over the whole effective chemical potential. These studies indicate that ordered inverse Heusler structural Cr2CoGa thin films are promising candidates for spintronic applications."
journal_title,Journal of Materials Science
article_title,Characterization of quaternary Zn/Sn-codoped GaN films obtained with ZnxSn0.04GaN targets at different Zn contents by the RF reactive magnetron sputtering technology
keyword,[]
history,"['2018-06', '2018-03-08', '2018-01-02', '2018-03-03']"
abstract,"Abstract Quarternary (Zn, Sn, Ga)N thin films with co-existing a large amount of acceptor and donor were purposely fabricated in order to heavily distort the GaN lattice and to extend the degenerated GaN semiconductor to a different aspect. The ZnSnGaN films were made of reactive sputtering with single cermet targets containing Zn, Sn, Ga, and GaN under the nitridation atmosphere. By varying the Zn content at fixed 4% Sn content, different Zn x Sn0.04Ga0.96−xN targets at x = 0, 0.03, 0.06, and 0.09 were prepared for Zn/Sn-x-GaN films. With increasing the Zn content, Zn/Sn-x-GaN due to the charge compensation changed from semiconducting n type to p type, and from high electron concentration of 4.1 × 1017 cm−3 to high hole concentration of 3.3 × 1017 cm−3. The optical band gap changed from 3.12 to 2.89 eV, related to the formation in ZnGa acceptor and SnGa donor defects. The hetero- and homo-junction diodes were fabricated. The n-Zn0.03Sn0.04GaN/p-Zn0.09Sn0.04GaN homo-junction diode tested at 25 °C had the turn-on voltage of 0.9 V, leakage current density of 6.0×10−5 A/cm2 at − 1 V, breakdown voltage of 4.7 V, current density of 2.4 × 10−2 A/cm2 at 5 V, ideality factor of 3.4, and barrier height of 0.65 eV."
journal_title,Journal of Materials Science
article_title,Reduced graphene oxide/Fe-phthalocyanine nanosphere cathodes for lithium-ion batteries
keyword,[]
history,"['2018-06', '2018-03-19', '2018-01-16', '2018-02-19']"
abstract,"Abstract Organic–inorganic composites show great potential for organic rechargeable lithium-ion batteries. In this work, two-dimensional phthalocyanine molecules were converted into hybrid nanoparticles with a porous structure and bound to a conductive graphene layer to act as a cathode material. The conductivity of this reduced graphene oxide/Fe-phthalocyanine (rGO/FePc) composite is improved through good interfacial connections and internal polymerization. The FePc spheres were shaped with the assistance of Fe3O4 and immobilized between the layers of reduced graphene oxide (rGO). The electrochemical properties of the organic–inorganic composites were investigated by testing in a lithium-ion cell. A high discharge capacity of 186 mAh g−1 was maintained after 100 cycles at 300 mA g−1, which demonstrates a significant improvement in the cycle life compared to previous reports of phthalocyanine-based electrochemical energy storage behaviour."
journal_title,Journal of Materials Science
article_title,Layer-controlled synthesis of wafer-scale MoSe2 nanosheets for photodetector arrays
keyword,[]
history,"['2018-06', '2018-03-01', '2017-11-29', '2018-02-12']"
abstract,"Abstract Despite huge efforts have been devoted to investigating ultrathin layers of two-dimensional (2D) transition-metal dichalcogenides (TMDs), their realistic applications in electronics and optoelectronics are hindered by limited scalability and uniformity of 2D thin layers. In this work, a two-step synthesis method was adopted to produce wafer-scale molybdenum diselenide (MoSe2) nanosheets. Molybdenum oxide (MoO3) thin film was initially prepared via atomic layer deposition (ALD) and followed by a selenization process in chemical vapor deposition (CVD) tube furnace. MoSe2 nanosheets with desired thickness can be obtained by tuning ALD cycles in preparing MoO3 layers. The synthesized MoSe2 films exhibited excellent layer controllability, homogeneity and wafer-scale uniformity. Few-layer structure of our MoSe2 with a polycrystalline crystal structure was verified by means of Raman and transmission electron microscopy (TEM) measurements. Moreover, arrays of MoSe2-based photodetectors with different device dimension were fabricated and the photo-responses of the devices were studied. The device exhibited a fast photo-response time of 50 ms, a high on/off ratio of ~ 24 and a good photo-responsivity of 11.7 mA/W, and it is found that the effective illumination area was a critical factor for application. The work opens up an attractive approach to realize the application of wafer-scale 2D materials in integrated optoelectronic-systems."
journal_title,Journal of Materials Science
article_title,Investigation of optical and electrical properties of MWCNT/rGO/poly(3-hexylthiophene) ternary composites
keyword,[]
history,"['2018-06', '2018-03-08', '2017-10-01', '2018-02-20']"
abstract,"Abstract 

Filler-induced structural modification portrays a crucial role in altering physical properties of polymer composites. A new approach by introducing 1D and 2D nanostructures into the conjugated polymer matrix could enhance structural, optical and electrical properties of the composites. A ternary composite prepared by introducing different wt% of multiwalled carbon nanotubes (MWCNTs) into the reduced graphene oxide (rGO)/poly(3-hexylthiophene-2,5-diyl) (P3HT) host matrix has been investigated. Structural and morphological investigations revealed a change in the crystalline size as well as conjugation length of the polymer units that could be attributed for tailoring the optical, electrical as well as electrochemical properties of the composites. The π–π interaction has been attributed to the observed shift in the redox potentials after incorporation of MWCNTs and rGOs into the P3HT host matrix. Improvement in electrical properties of the composites after incorporation of MWCNTs and rGOs has been attributed to softening of the interfacial grain boundary by the 3D network structure created by the well-dispersed MWCNTs and rGOs in the P3HT matrix.
"
journal_title,Journal of Materials Science
article_title,Dynamic transformation of Ti–6Al–4V during torsion in the two-phase region
keyword,[]
history,"['2018-06', '2018-03-23', '2017-12-16', '2018-03-17']"
abstract,"Abstract Isothermal torsion tests were performed on a Ti–6Al–4V alloy in the two-phase region. The results show that straining leads to an increase in the beta phase fraction, which increases slightly with strain rate. Transformation took place at 880, 940, 960, 980 and 1000 °C. The extent of this type of dynamic transformation (alpha to beta) was increased when the temperature approached the transus temperature. The reverse transformation (beta to alpha) occurred during isothermal holding after torsion and the volume fraction retransformed increased with time. The driving forces promoting dynamic and reverse transformation together with the energy barriers opposing these transformations were derived and compared. The critical stresses required to initiate dynamic transformation are calculated from the flow curves. This analysis confirms that the peak stresses are always higher than the critical stresses at the temperatures employed in the present tests, which makes it possible for the transformation to occur."
journal_title,Journal of Materials Science
article_title,Synthesis of porous zinc-based/zinc oxide composites via sol–gel and ambient pressure drying routes
keyword,[]
history,"['2018-06', '2018-02-26', '2017-10-24', '2018-02-12']"
abstract,"Abstract Porous Zn-based and ZnO composites are successfully fabricated via the sol–gel process and ambient pressure drying method using hexane as the drying solvent for the reduction in capillary force during drying process. Various highly porous Zn-based phases (Zn1-based and Zn5-based) that are studied by X-ray diffraction analysis, scanning electron microscopy and transmission electron microscopy show that they contribute through heat treatment (at 200 °C) to the development of ambient pressure dried nanoporous wurtzite (hexagonal) ZnO. A macroporous flower-like structure consisting of nanosheets is observed in porous Zn-based composites, and nanoporous structure is observed within platelets of ZnO nanoparticles. Possible routes for preparing highly porous Zn-based/ZnO composites are discovered by detailing the process for ambient pressure drying synthesis of porous wurzite ZnO."
journal_title,Journal of Materials Science
article_title,"Evolution of electronic and vibrational properties of M@Xn (M = Ag, Au, X = Ge, Si, n = 10, 12, 14) clusters: a density functional modeling"
keyword,[]
history,"['2018-06', '2018-03-01', '2017-07-18', '2018-01-04']"
abstract,"Abstract Evolution of electronic and vibrational properties of M@Xn (M = Ag, Au, X = Ge, Si, n = 10, 12, 14) nanoclusters is investigated by using first-principle density functional theory (DFT)-based calculations with effective core potentials. To explain the thermodynamic and chemical stability of the ground state cluster in each size, variation of different thermodynamic and chemical parameters, like, binding energy (BE), HOMO–LUMO gap (ΔE), vertical ionization potential (VIP) and vertical electron affinity (VEA) was studied with the variation of the size of the clusters for emphasizing the differences and similarities in the clusters. It is found that Au doping in Ge and Si cages prefers endohedral position, whereas Ag prefers to take the position at the surface of the cages. In addition, IR and Raman spectra of the clusters are also studied to understand the vibrational nature of the stable clusters. At the end, present theoretical results are compared with existing experimental data. Theoretical knowledge of the thermodynamic, chemical and vibrational properties of these specific ground state structures is important for understanding its potential application in the field of optoelectronic science."
journal_title,Journal of Materials Science
article_title,Investigating the water vapor sorption behavior of bamboo with two sorption models
keyword,[]
history,"['2018-06', '2018-03-08', '2018-01-12', '2018-02-22']"
abstract,"Abstract Studying the hygroscopic behavior of bamboo is important for industrial applications because it influences the dimensional stability and mechanical properties of the final bamboo products. In this study, the water vapor sorption behavior of 14 bamboo species was investigated using a dynamic vapor sorption apparatus and the results were analyzed using the Guggenheim–Anderson–de Boer (GAB) and Hailwood–Horrobin (H–H) models. The different bamboo species exhibited varying sorption isotherms and degrees of hysteresis. The reasons for this may be related to the different sorption isotherms of the two main cell units of bamboo, namely the fiber and parenchyma cells, and the chemical composition of bamboo. The GAB and H–H models provided good fits to the experimental data and meaningful physical parameters regarding the monolayer capacity, especially the water accessible specific surface area can be obtained from the GAB parameters. The fiber saturation point values were also determined using the GAB and H–H models, which ranged from 16.37 to 27.91% for the different bamboo species."
journal_title,Journal of Materials Science
article_title,Dual relaxation behaviors and large electrostrictive properties of Bi0.5Na0.5TiO3–Sr0.85Bi0.1TiO3 ceramics
keyword,[]
history,"['2018-06', '2018-03-05', '2017-12-29', '2018-02-27']"
abstract,"Abstract Lead-free ceramics (1 − x)Bi0.5Na0.5TiO3–xSr0.85Bi0.1TiO3 (BNT–xSBT, x = 0.4, 0.5, 0.6 and 0.7) were prepared by a solid-state reaction process. Coexistence of ferroelectric relaxation at low temperature and Maxwell–Wagner dielectric relaxation at high temperature was revealed for the first time in this system. Meanwhile, hysteresis-free P–E loops combined with a very high piezoelectric strain coefficient (d33) of 1658 pC/N concurrently with large electrostrictive coefficient Q = 0.287 m4C−2 were achieved. The ferroelectric relaxor behavior and large electrostrictive strain might be linked to easy reorientation and reversal of ergodic PNRs and the combined effect of Bi off-center position and lone pair electrons."
journal_title,Journal of Materials Science
article_title,Synthesis and application of a novel environmental C26 diglycidyl ester plasticizer based on castor oil for poly(vinyl chloride)
keyword,[]
history,"['2018-06', '2018-03-09', '2018-01-28', '2018-03-05']"
abstract,"Abstract A castor oil-derived diglycidyl ester plasticizer (C26-DGE) was prepared and incorporated into poly(vinyl chloride) (PVC) for the first time. The chemical structure of the product was characterized by Fourier transform infrared spectroscopy (FTIR), proton nuclear magnetic resonance (1H-NMR), and carbon-13 nuclear magnetic resonance (13C-NMR). The plasticizing effects of C26-DGE as a primary or secondary plasticizer for the commercial plasticizer dioctyl phthalate (DOP) were studied. The mechanical properties, thermal stability, and migration stabilities of PVC films were investigated using dynamic mechanical analysis, thermogravimetric analysis (TGA), TGA-FTIR analysis, and PVC film surface analysis. Tensile, volatility, and extraction tests were also done. The castor oil-based plasticizer was found to endow the PVC matrix with enhanced compatibility and flexibility. With partially or completely substituted DOP, C26-DGE significantly increased the thermal stability of PVC blends. Furthermore, the volatility and extraction resistance of the novel plasticizers were generally superior to those of DOP. The interaction between the C26-DGE and PVC molecules and the thermal degradation process of PVC blends were also investigated."
journal_title,Journal of Materials Science
article_title,Enhanced dielectric constant and structural transformation in Fe-doped hydroxyapatite synthesized by wet chemical method
keyword,[]
history,"['2018-06', '2018-03-19', '2018-01-08', '2018-03-14']"
abstract,"Abstract We report the synthesis of single-phase Fe-doped hydroxyapatite (HAp) [Ca10−xFe x (PO4)6(OH)2 (0.0 ≤ x ≤ 0.3)] and enhanced dielectric constant of HAp with Fe doping. Rietveld analysis shows the change in x-axis-oriented lattice constant a in Fe-doped x = 0.1 and 0.3 compositions in comparison with parent HAp, while z-axis-oriented lattice constant c does not show any considerable change. Analysis of absorbance data shows two new symmetric stretching peaks for Fe-doped x = 0.1 and x = 0.3 compositions, which are not present in parent HAp. Magnetic measurements show paramagnetic behaviour of all Fe-doped samples at 300 K. Fe-doped Ca9.9Fe0.1(PO4)6(OH)2 composition shows increase in impedance in the presence of 500 Oersted (Oe) applied magnetic field in comparison with impedance in the absence of magnetic field. Ca9.9Fe0.1(PO4)6(OH)2 composition shows increase in dielectric constant in comparison with parent HAp in frequency range 5–35 MHz. Fe-doped Ca9.9Fe0.1(PO4)6(OH)2 composition shows ~ 970% colossal magnetoimpedance at 100 Hz and ~ 200% at 20 MHz frequency.
"
journal_title,Journal of Materials Science
article_title,Impact of thermal treatments on epitaxial GayIn1−yAs1−xBix layers luminescent properties
keyword,[]
history,"['2018-06', '2018-02-21', '2017-12-11', '2018-02-13']"
abstract,"Abstract In this work, thick Ga0.485In0.515As1−xBi x  epitaxial layers were grown on semi-insulating (100)-oriented InP:Fe substrates by molecular beam epitaxy. For investigation of the buffer layer influence on Ga0.485In0.515As1−xBi x  properties, two compositions of buffers were used: lattice matched to InP:Fe substrate—Ga0.477In0.523As, and lattice matched to bismide layer—Ga0.434In0.566As. The buffer layer thickness varied from 100 to 650 nm. Three hundred-nm-thick bismide layers were grown at 280–300 °C substrate temperature with growth rate of 300 nm/h. Structural investigations of ω − 2θ rocking curves measured for (004) reflex revealed the incorporation of Bi up to 3.6% in quaternary compound. Bismide layer surface inspection by atomic force microscopy demonstrated roughness of about 0.65 nm. Despite the fact that structures are 100’s of nanometers thick, reciprocal space mapping measurement demonstrated that both the buffer and the bismide layers are fully strained. It has also been revealed that rapid annealing at the temperature range of 550–700 °C of Ga0.485In0.515As1−xBi x  layers improves photoluminescence intensity, extends carrier lifetime and enhances electron mobility."
journal_title,Journal of Materials Science
article_title,Flower-like silver nanocrystals: facile synthesis via a gas–solution interface technique
keyword,[]
history,"['2018-06', '2018-03-01', '2017-12-19', '2018-02-22']"
abstract,"Abstract In this paper, flower-like Ag nanocrystals and their fractal networks were successfully synthesized by gas–solution interface technique at the surface of AgNO3 water solution with the assistance of ammonium citrate and of gaseous N2H4 used as reductant. The synthesized flower-like silver structure consisted of a large number of petal-like silver nanoplates. They were characterized by scanning and transmission electron microscopy, absorption UV–Vis spectroscopy, and X-ray diffraction. In addition to the standard silver fcc modification, the nanostructures contained the hexagonal polymorph (4H-Ag) in the amount of about 5%. The effect of pH of the solution on the morphology of nanoparticles and on the silver crystal structure was examined. Depending on the time of treatment with gaseous hydrazine, it was possible to obtain either separate flower-like nanoparicles and their fractal networks, or continuous films formed by rather closely packed petal-like nanoparticles. The surface-enhanced Raman scattering effect was observed, and the most intense interaction of laser beam with the silver nanoparticles occurred when the solution side of the synthesized film was irradiated."
journal_title,Journal of Materials Science
article_title,Modification of polyacrylonitrile stabilized fibers via post-thermal treatment in nitrogen prior to carbonization and its effect on the structure of carbon fibers
keyword,[]
history,"['2018-06', '2018-03-08', '2017-09-08', '2017-12-06']"
abstract,"Abstract Post-thermal treatment prior to carbonization was used to modify polyacrylonitrile stabilized fibers, and in this study, the effects of this modification on the structures of the stabilized fibers and the resulting carbon fibers were investigated. The stabilized fibers were modified by thermal treatment under a nitrogen atmosphere at different temperatures, followed by continuous carbonization to obtain carbon fibers. The reaction mechanism and structural changes in the stabilized fibers during the post-treatment process were investigated by 13C solid-state nuclear magnetic resonance and X-ray diffraction analysis. The degree of stabilization of the post-treated stabilized fibers is higher than that of the as-received stabilized fibers and increases with increasing post-treatment temperature. The crystal width of the resulting carbon fibers increases continuously, whereas the crystal thickness remains nearly the same with increasing post-treatment temperature. When the post-thermal treatment for modification is conducted at 300 °C, the stabilized fibers possess the highest degree of orientation. This property is inherited by the resulting carbon fibers, which exhibit the highest degree of orientation and optimal mechanical properties."
journal_title,Journal of Materials Science
article_title,Strength and buckling behavior of defective phosphorene nanotubes under axial compression
keyword,[]
history,"['2018-06', '2018-02-22', '2017-12-15', '2018-02-15']"
abstract,"Abstract Atomic defects can be generated relatively easily in phosphorene due to their low formation energies. How these defects affect the buckling behavior of phosphorene nanotubes (PNTs) remains unexplored. Using molecular dynamics simulations, we investigate the effect of vacancies on the buckling properties of PNTs. We show that compared to a pristine PNT, the defective one exhibits a much lower buckling strength and strain. Remarkably, 1% concentration of vacancies in a PNT is able to cause a 30% reduction in buckling strength. Interestingly, for long PNTs, the buckling occurs via column or global buckling. As a result, the buckling strength decreases significantly with the increase (decrease) in the tube length (diameter) for both the pristine and defective PNTs, consistent with the Euler buckling theory. For short PNTs with small slenderness ratio (L/D), however, buckling occurs via shell or local buckling. As a result, the buckling strength increases with decreasing the tube diameter, consistent with shell buckling theory. Finally, with the increase in temperature, the buckling strength and strain can be reduced significantly for both the pristine and defective PNTs. These findings may provide important guidelines for the design and applications of PNTs-based nanodevices."
journal_title,Journal of Materials Science
article_title,Thermodynamic properties of Ag–Au–Pd alloys measured by a solid-state EMF method
keyword,[]
history,"['2018-06', '2018-03-09', '2017-11-06', '2018-02-28']"
abstract,"Abstract Although the Ag–Au–Pd system is crucial for several industrial applications and for the research on fundamental physics, no thermodynamic data on this ternary system at low temperatures have been reported in the literature. In the present study, activities of silver are directly measured by employing a solid-state EMF method, by using AgI as the solid electrolyte. The EMF was determined using a galvanic cell \( \left( - \right){\text{Pt}}\left| {\text{C}} \right.\left| {\text{Ag}} \right|{\text{AgI}}\left| {{\text{Ag-Au-Pd alloy}}} \right|{\text{C}}\left| {{\text{Pt}}\left( + \right)} \right. \), which produced novel experimental data on the thermodynamic properties of Ag–Au–Pd alloys. Darken method was used to calculate integral excess thermodynamic properties from the data. New thermodynamic characteristics, such as integral excess mixing Gibbs energy, entropy and enthalpy of the Ag–Au–Pd alloys, have been generated in a temperature range of 475 and 675 K. Isoactivity lines of silver in the system have been drawn throughout the Gibbs triangle. Thermodynamic properties of the binary Au–Pd alloys have been compared with the previous investigations."
journal_title,Journal of Materials Science
article_title,"Simultaneous optimization of Seebeck, electrical and thermal conductivity in free-solidified Bi0.4Sb1.6Te3 alloy via liquid-state manipulation"
keyword,[]
history,"['2018-06', '2018-03-12', '2017-11-21', '2018-03-06']"
abstract,"Abstract (BiSb)2Te3-based alloy is one of the best p-type thermoelectric (TE) materials near room temperature. However, it is challenging to improve its ZT value due to the interrelated Seebeck coefficient (S), electrical conductivity (σ), and thermal conductivity (κ). In this study, the synergistic optimization of S, σ, and κ has been easily achieved in Bi0.4Sb1.6Te3 alloy by liquid-state manipulation (LSM). Specifically, more Te-rich eutectic strips are observed in the LSM sample, which would increase carrier density (p) and thus improve σ. Meanwhile, via LSM, the raised effective mass m* could compensate the effect of increased p on S and thus an enhanced S is obtained. Furthermore, the larger amount of nanoparticles, higher density of lattice distortions, and dislocations in the LSM sample would contribute to scattering phonons and a lower κ is attained. As a result, the highest ZT of 0.7 at 352 K is attained which is 40% higher than that of traditional melted Bi0.4Sb1.6Te3 alloy."
journal_title,Journal of Materials Science
article_title,Density functional theory study of electronic structure of defects and the role on the strain relaxation behavior of MoS2 bilayer structures
keyword,[]
history,"['2018-06', '2018-03-23', '2017-11-28', '2018-03-09']"
abstract,"Abstract Recent capability of chemical vapor deposition (CVD) to grow large-area and high-quality monolayer and few-layered molybdenum disulfide (MoS2) structures renders intrinsic defects such as vacancies that alter the electronic properties of these structures. As a result, density functional theory (DFT) calculations are carried out to investigate the electronic structure of various types of CVD-grown vacancy defects and the role on the strain relaxation behavior of bilayer MoS2. DFT calculations suggest that additional charge states are activated in the gap between the valence band and conduction band for the atoms neighboring the defects in the layer and in the layer above the defects. In addition, the DFT results indicate that the presence of local defects lower energy barriers for strain relaxation of bilayer MoS2 attributed to sliding between the layers. These results demonstrate the modifications of the electronic properties of 2D structures and the strain due to the presence of defects."
journal_title,Journal of Materials Science
article_title,Electropolymerization in proton-functionalized anilinium salts/glycol deep eutectic solvents
keyword,[]
history,"['2018-06', '2018-02-21', '2017-11-30', '2018-02-09']"
abstract,"Abstract Novel proton-functionalized solid anilinium salts (anilinium hydrochloride ([HANI]Cl) and anilinium nitrate ([HANI]NO3)) are synthesized. Simply mixing proton-functionalized anilinium salt with glycol in appropriate ratios can get deep eutectic solvents (DESs) which are liquid at room temperature. DES system is a new type of ionic liquids (ILs) or IL analogs. Tests show that the resulting DES systems have higher conductivity and lower viscosity which are suitable for electropolymerization. The electropolymerization of aniline in novel liquid DES ([HANI]Cl/(CH2OH)2 and [HANI]NO3/(CH2OH)2) without exogenous protons is first reported. The cyclic voltammograms (CVs) in neat DES show two pairs of redox peaks. Unlike in acidic aqueous solutions, the electropolymerization of aniline in the DES needs no exogenous protons. UV–Vis and FTIR analysis show that the conductive polyaniline (PANI) is obtained. Moreover, the specific capacitance of PANI from the [HANI]Cl/(CH2OH)2 system is ca. 341 F g−1 and that from the [HANI]NO3/(CH2OH)2 is ca. 492 F g−1, which are superior to that of the PANI obtained in an acid medium. The SEM characterization indicates that the resulting PANI on ITO is cross-linked nanoporous polymer membrane, which is benefit for the capacitance performance of PANI."
journal_title,Journal of Materials Science
article_title,Fabrication of porous Co3O4 with different nanostructures by solid-state thermolysis of metal–organic framework for supercapacitors
keyword,[]
history,"['2018-06', '2018-02-26', '2018-01-08', '2018-02-19']"
abstract,"Abstract Porous Co3O4 with different structures have been synthesized by annealing cobalt-based metal–organic framework (Co-MOF) parallelepiped microcrystals. The transformation process of nanostructures at different temperatures has been investigated, which involves the depletion of Co-MOF core, formation, and crystal growth of cobalt oxide shell. Porous hollow parallelepipeds and microsheets can be obtained at 400 and 500 °C, respectively. When evaluated as electrode materials for supercapacitors, Co3O4 hollow parallelepipeds exhibit better electrochemical performances compared to Co3O4 microsheets, which can be attributed to the unique 3D hierarchical hollow structure and small particle size."
journal_title,Journal of Materials Science
article_title,Enhanced performance of GaN-based LEDs via electroplating of a patterned copper layer on the backside
keyword,[]
history,"['2018-06', '2018-03-15', '2017-12-08', '2018-02-24']"
abstract,"Abstract InGaN/GaN multi-quantum well light-emitting diodes (LEDs) are conventionally grown on a sapphire substrate due to a lack of compatible substrates with a high compressive strain. This is a result of the relatively large lattice, and thermal expansion coefficient mismatches between GaN and sapphire. The compressive strain is considered to be a major obstacle to further improve next-generation high-performance GaN-based LEDs. In this paper, we have designed, electroplated, and tested an efficient substrate using a patterned copper (Cu) layer on the backside of sapphire to relax the compressive strain in a GaN epilayer. The patterned Cu layer has a significant function in that it supports the GaN/sapphire LEDs with an external tensile stress. The external tensile stress is capable of compensating for the compressive strain in the GaN/sapphire LEDs by controlling the curvature of the wafer bowing. This patterned Cu layer, when applied to the GaN/sapphire LEDs, suppresses the compressive strain by up to 0.28 GPa. The GaN-based LEDs on this innovative and effective sapphire/Cu substrate offer improved optical and electrical performance."
journal_title,Journal of Materials Science
article_title,Theoretical design of sandwich two-dimensional structures for photocatalysts and nano-optoelectronic devices
keyword,[]
history,"['2018-06', '2018-03-08', '2017-11-09', '2018-02-02']"
abstract,"Abstract In this paper, three series of heterostructures of 2D transition metal dichalcogenides (including MoS2, MoSe2, MoTe2, WS2, WSe2, and WTe2) sandwiched by graphene (Gr), h-BN, and g-C3N4, which will be referred to as Gr sandwich heterostructures (SHS), h-BN-SHS, and g-C3N4-SHS in the rest of this paper, have been systematically studied firstly by using first-principle calculations. Gr-SHS are found to hold stable structures with an expanded band gap when MoSe2 and WSe2 are used as interlayers, indicating potential applications to Hall switch sensors. With the same type of interlayers, the stable h-BN-SHS shows additionally good response to visible light. In addition to good response to the visible light, effective electron–hole separation is also observed in g-C3N4-SHS. Such properties suggest structures in this sandwich type may be applied in plentiful areas, such as photocatalyst and solar cells. Moreover, the number and density of catalytically active sites in SHS may be dramatically increased. Consequently, we hope our findings could provide guidance for both the design of advanced materials and the corresponding nano-devices."
journal_title,Journal of Materials Science
article_title,Charge transfer mechanisms in strontium ferromolybdate with tunneling barriers
keyword,[]
history,"['2018-06', '2018-02-22', '2017-09-25', '2018-02-14']"
abstract,"Abstract The single-phase strontium ferromolybdate powder with the double perovskite structure has been synthesized by the citrate-gel method with superstructural ordering of iron and molybdenum cations of 88%. The formation of the SrMoO4 phase on the intergrain boundaries has been determined by means of the XRD studies, the Electrokinetic Sonic Analysis technique, and FESEM investigations of pressed Sr2FeMoO6-δ powders subjected to the isothermic treatment at 700 K and p(O2) = 10 Pa. The temperature dependence of the electrical resistivity in the temperature range 4.2–300 K has a metallic type in the single-phase Sr2FeMoO6-δ compound and the semiconductor type in the Sr2FeMoO6-δ–SrMoO4–Sr2FeMoO6-δ structure with dielectric sheaths. In the latter case, a hopping mechanism of charge transfer is observed. In the applied magnetic field, the temperature dependence does not change qualitatively; however, the resistivity decreases with increasing field, i.e., a negative magnetoresistive effect appears, reaching 43.6% at 10 T and 10 K. The external field forms a collinear spin structure, thus increasing the spin-polarized current through the energy barriers in the granular Sr2FeMoO6-δ–SrMoO4–Sr2FeMoO6-δ heterostructure."
journal_title,Journal of Materials Science
article_title,Effects of plastic straining on the corrosion resistance of TRIP-aided lean duplex stainless steels
keyword,[]
history,"['2018-06', '2018-03-13', '2017-12-09', '2018-03-02']"
abstract,"Abstract In the present paper, the effects of plastic deformation on the corrosion resistance of strip cast TRIP (transformation-induced plasticity)-aided stainless steel (19Cr-DSS) and conventional lean duplex stainless steel (LDX2101) were studied by observations of deformed microstructure and electrochemical experiments. The electrochemical results indicate that the corrosion susceptibility of experimental steels in 3.5% NaCl solution is increased with increasing deformation amounts. The Mott–Schottky analysis revealed that the passive films formed on both 19Cr-DSS and LDX2101 exhibit the n-type and p-type semiconducting behaviors regardless of strains. With the increase in true strain, the acceptor and donor densities are both continuously increased. The total density of acceptor and donor in 19Cr-DSS is increased more rapidly with increasing strain than that of LDX2101, indicating that the corrosion resistance of 19Cr-DSS is more sensitive to plastic deformation compared to that of LDX2101. For the TRIP-aided 19Cr-DSS, the deterioration of corrosion resistance after plastic deformation may have been caused by the decrease in low-Σ CSL boundaries especially the twin (Σ3) boundaries, the increase in dislocations, and the formation of strain-induced martensite during plastic deformation."
journal_title,Journal of Materials Science
article_title,Elasticity and internal friction of magnesium alloys at room and elevated temperatures
keyword,[]
history,"['2018-06', '2018-02-21', '2017-10-18', '2018-02-12']"
abstract,"Abstract Elastic moduli (Young’s modulus, shear modulus and bulk modulus) of three ultrafine-grained Mg-based alloys AZ31, AE42 and LAE442 were studied by resonant ultrasound spectroscopy. Evolution of these moduli and the corresponding high-frequency internal friction were measured in a temperature cycle between the room temperature and 310 °C, i.e., with heating above the recrystallization threshold temperature. The results reveal that the Li content in the LAE442 alloy has a strong impact on its elastic performance, resulting in a high E/ρ ratio, which is consistent with predictions of ab initio calculations. Simultaneously, the relaxation due to grain boundary sliding has significantly lower activation energy in LAE442 alloy."
journal_title,Journal of Materials Science
article_title,High thermal conductivity of diamond/copper composites produced with Cu–ZrC double-layer coated diamond particles
keyword,[]
history,"['2018-06', '2018-03-09', '2017-12-11', '2018-02-27']"
abstract,"Abstract A new method was proposed to fabricate diamond/Cu composites. Double-layer diamond particles were directly compressed at ultra-high pressure to prepare the preform and then sintered in a vacuum equipment for densification. The raw diamond particles were coated with zirconium carbide by magnetron sputtering for the inner layer and then deposited with copper by chemical method for the outer layer. Prepared with these particles, the composites had good interface bonding and homogeneously distributed particles in the copper matrix. The thermal conductivity of 65 vol% diamond/Cu composite was as high as 720 W m−1 K−1. When the diamond content increased to 70 vol%, the coefficient of thermal expansion was extremely low (4.33 × 10−6/K). With superb thermal–physical performance, diamond/Cu composites are potentially applicable to electronic packaging."
journal_title,Journal of Materials Science
article_title,Anionic NbO-type copper organic framework decorated with carboxylate groups for light hydrocarbons separation under ambient conditions
keyword,[]
history,"['2018-06', '2018-03-19', '2018-01-05', '2018-02-16']"
abstract,"Abstract Light hydrocarbons are important raw materials for industrial products and fine chemicals. The storage and separation of C1–C3 hydrocarbons are vital to their practical use. Here, we report efficient C1–C3 hydrocarbon adsorption and separation with a NbO-type anionic copper metal–organic framework with uncoordinated –COO− groups ([Cu2(L)·(H2O)2]·2H2O·3DMA·(CH3)2NH2) (1). Complex 1 exhibited large C2H2 (190 cm3 g−1), C2H4 (147 cm3 g−1), C2H6 (156 cm3 g−1), C3H6 (170 cm3 g−1), and C3H8 (173 cm3 g−1) uptakes and high selectivities for C2H2/CH4 (32.3), C3H6/CH4 (152), and C3H8/CH4 (127) under ambient conditions. The excellent cycling performance of the material was reflected by only 9.2 and 10.9% losses of the C2H2 and C3H6 storage capacities even after ten cycles of adsorption–desorption tests. First-principles calculations and Grand canonical Monte Carlo simulations further revealed that not only the open metal sites but also the –COO− groups played a key role in the high C2–C3 hydrocarbon uptakes. The results obtained in this study suggest that anionic 1 is a promising candidate for light hydrocarbon adsorption and natural gas purification at room temperature."
journal_title,Journal of Materials Science
article_title,Microstructure evolution and mechanical reliability of Cu/Au–Sn/Cu joints during transient liquid phase bonding
keyword,[]
history,"['2018-06', '2018-03-09', '2017-11-06', '2018-03-05']"
abstract,"Abstract The microstructure evolution and mechanical reliability of Cu/Au–Sn/Cu sandwich joints during transient liquid phase (TLP) bonding were investigated in this study. The results show that the Au–Sn solder reacted with the Cu substrate to form Au and Au6.6Cu9.6Sn3.8. During the TLP bonding process, (Au, Cu)5Sn was formed first, following which new α(Au) and Au6.6Cu9.6Sn3.8 phases appeared, to finally form a combination of α’(Au), α(Au), and Au6.6Cu9.6Sn3.8 phases when the Au–Sn solder is exhausted. The volume contraction associated with the consumption of the Au–Sn solder results in pore formation and subsequent shear strength deterioration in the Cu/Au–Sn/Cu joint. The presence of the Au6.6Cu9.6Sn3.8 phase also slightly reduced the shear strength of the joint. However, the overall shear strength of the TLP-bonded joint consisting of α’(Au)/α(Au)/Au6.6Cu9.6Sn3.8 phases without pores was approximately 50 MPa. The TLP-bonded joints possess excellent mechanical reliability, with shear strength of 28 MPa even at 350 °C, a temperature that is 70 °C higher than the melting point of the Au–Sn solder. Moreover, the shear strength of the TLP-bonded joint remains stable at 50 MPa even after exposure to high temperatures such as 250 or 350 °C, for 400 h, and only slightly decreased after 400 thermal cycles."
journal_title,Journal of Materials Science
article_title,Ronald Leslie Bell: 12th September 1929–25th December 2017
keyword,[]
history,"['2018-06', '2018-03-12', '2018-03-04']"
abstract,None
journal_title,Journal of Materials Science
article_title,The effect of Fe contents on the local structure and crystallization behavior of SiO2–CaO–P2O5–Fe2O3 glasses
keyword,[]
history,"['2018-06', '2018-02-15', '2017-12-24', '2018-02-07']"
abstract,"Abstract The glass and glass ceramics containing SiO2–CaO–Fe2O3–P2O5 were prepared by sol–gel method. The influence of the Fe contents on the crystallization and local structure of the glass and glass ceramics was systematically investigated. The crystal structure of the glass ceramics was identified by XRD characterization. Hematite phase can be precipitated from the glass matrix in all glass ceramics with various Fe contents, and the crystallographic parameters of hematite were determined by XRD Rietveld refinement. The crystallization kinetics of the glasses was investigated in detail. Relative low activation energies were obtained at low Fe contents. The local structure evolution of the glass and glass ceramics has been studied in-depth by means of FTIR and Mössbauer spectroscopy. Fe element is present both as network former and network modifier which significantly influenced the crystallization activation energies of the glasses. The results of this work may be of great significance for the material design and practical applications of bioactive magnetic glass ceramics for hyperthermia."
journal_title,Journal of Materials Science
article_title,Effect of Co partial substitution on the valence state of Ru in the Gd2−xCoxRu2O7 pyrochlore
keyword,[]
history,"['2018-06', '2018-02-27', '2017-12-11', '2018-02-20']"
abstract,"Abstract Polycrystalline samples of Gd2−xCo x Ru2O7 with x = 0.0, 0.1 and 0.4 were synthesized by the molten salt method. The samples were studied by X-ray diffraction (XRD), X-ray photoelectron spectroscopy (XPS) and electrical resistivity measurements. Rietveld refinements of the XRD patterns and XPS measurements showed that the Co2+ ion replaces Gd3+ sites. As a result, the lattice parameter a and the Ru–O bond length decrease; then, the Ru–O–Ru bond angle increases. Those changes induce a charge compensation which was detected by XPS measurements. The analysis of these results shows that the Ru 3d5/2 core level could be fitted assuming the contribution of two different chemical states of the Ru. The Ru 3d5/2 core level is localized at 280.7 and 281.6 eV, which corresponds to Ru4+ and Ru5+. The valence band XPS spectra show an increase in Co 3d states at the Fermi level as the Co content increases, which contribute to the decrease in the electrical resistivity."
journal_title,Journal of Materials Science
article_title,MoS2-filled coating on flexible polyurethane foam via layer-by-layer assembly technique: flame-retardant and smoke suppression properties
keyword,[]
history,"['2018-06', '2018-03-13', '2017-12-08', '2018-03-02']"
abstract,"Abstract In the present work, a fire-blocking coating consisting of chitosan and molybdenum disulfide (MoS2) was firstly deposited onto flexible polyurethane (FPU) foam by the layer-by-layer assembly technique. With the MoS2-filled coating, the FPU foam could burn without melt dripping during the whole combustion and keep its shape after combustion, while the pure foam was consumed completely. The analysis by thermogravimetric analysis/infrared spectrometry indicated that MoS2-filled coating could obviously reduce the amount of organic gaseous pyrolysis products and toxic volatiles during thermal decomposition of the foam. The cone calorimeter results indicated that the FPU foam with 8.5 wt% coating showed great reduction in peak of heat release rate (70%), peak smoke production rate (62.4%) and total smoke released (33.3%). Such a significant improvement in flame-retardant and the smoke suppression properties for FPU foam could be attributed to the protective effect of MoS2-filled coating."
journal_title,Journal of Materials Science
article_title,Surface passivation with nitrogen-doped carbon dots for improved perovskite solar cell performance
keyword,[]
history,"['2018-06', '2018-03-06', '2018-01-26', '2018-02-28']"
abstract,"Abstract Undercoordinated lead cations and halide anions on the surface of perovskite layer can form surface trap states and cause electronic disorders which reduce the performance of perovskite solar cells. Nitrogen-doped carbon dots (NCDs) that have rich nitrogen- and oxygen-containing functional groups can effectively interact with the unsaturated metal sites and halide anions on the surface and boundaries of perovskite grains. Herein, low-cost NCDs are utilized as efficient additives to passivate the surface of a solution-processed CH3NH3PbI3 perovskite film, which remarkably reduce charge carrier recombination, as evidenced by the results of time-resolved photoluminescence and electrochemical impedance spectrum measurements. FTIR spectra indicate the formation of hydrogen bonds between the undercoordinated iodine ions on perovskite grains and hydroxyl as well as nitrogenous groups of NCDs. In addition, NCDs additives also help increase interfacial charge transfer from perovskite to electron-transporting layer, leading to an improvement in power conversion efficiency for the solar cell device from 12.12 ± 0.28% (standard cell fabricated in same conditions) to 15.93 ± 0.15%."
journal_title,Journal of Materials Science
article_title,Synthesis and characterization of carbon-modified Li2MnP2O7/C composites prepared by spray pyrolysis
keyword,[]
history,"['2018-06', '2018-03-19', '2017-12-08', '2018-03-09']"
abstract,"Abstract Pure crystalline Li2MnP2O7/C composite was prepared by spray pyrolysis (SP) followed by annealing (AN) process. Citric acid (CA) was added into the precursor solution as a carbon source to enhance the electrochemical property. The physical and electrochemical properties in conjunction with various synthesis conditions were evaluated. Variation of carbon content, specific surface area, lattice cell volume, and anti-site concentration was revealed along with different preparation conditions of the SP followed by AN process. Electrochemical properties were relevant to various physical properties of samples, and it provided a critical factor to find the most efficient synthesis condition in the SP method. Since incorporated carbon has a significant role in enhancing the electrical conductivity as well as inducing a delicate variation of physical properties, the limitation of incorporated carbon by CA was addressed with associated reaction mechanism. For the sake of exceeding these limitations, further carbon modification with acetylene black was carried out by ball milling (BM) process. The optimal condition of BM process was designated by the resulting of electrochemical property and observing the carbon distribution on the cross section of particles. Li2MnP2O7/C composite prepared under the whole optimal condition delivered the initial discharge capacity of 64 mAh g−1 at a current rate of C/10. The potential of Mn3+/Mn2+ redox couple revealed at 4.3 V versus Li/Li+ upon the discharge process."
journal_title,Journal of Materials Science
article_title,Flexible supercapacitor with high energy density prepared by GO-induced porous coral-like polypyrrole (PPy)/PET non-woven fabrics
keyword,[]
history,"['2018-06', '2018-02-20', '2017-11-21', '2018-02-09']"
abstract,"Abstract Graphene oxide (GO)-induced porous coral-like polypyrrole have been fabricated via facile in situ polymerization. The morphologies and structures of PPy with different GO concentration were investigated by scanning electron microscopy and Fourier transform infrared spectroscopy. The results revealed that PPy/GO presented different morphologies and properties with varied amounts of GO. The electrochemical performances of prepared PPy/GO and PPy electrodes were compared. Notably, the PPy/GO electrodes showed much better electrochemical performance than the PPy electrodes. It indicated that the doping of GO in the composites significantly enhanced the electrochemical behaviors of PPy/GO electrodes. The excellent performance was the result of synergistic effects of GO and PPy structure and property. The device obtained a large specific capacitance of 568.35 F g−1 at a current density of 0.1 A/g and high energy density of 37.4 Wh kg−1. In addition, it also exhibited good cycle stability, with a capacitance retention rate of 83.4% for 500 cycles. More importantly, the electrode presented high flexibility property. The supercapacitor device fabricated is promising for the use in lightweight and flexible electronic devices."
journal_title,Journal of Materials Science
article_title,Ternary thick active layer for efficient organic solar cells
keyword,[]
history,"['2018-06', '2018-03-05', '2017-12-27', '2018-02-09']"
abstract,"Abstract Ternary organic solar cells (OSCs) hold great promise in enabling the roll-to-roll printing of environmentally friendly, mechanically flexible, and cost-effective photovoltaic devices. Nevertheless, many ternary OSCs display the best power conversion efficiency (PCE) with a thin active layer at the thickness of about 100 nm, which can be hardly translated in to the roll-to-roll processing with high reproducibility. In this paper, the ternary OSCs with a high PCE and a thick active layer were reported, which was obtained by incorporating a dye small molecule named as 2’-(5,5’-(9,9-dioctyl-9H-fluorene-2,7-diyl)bis(thiophene-5,2-diyl))bis(methanylylidene))-bis(3-ethyl-2-thioxothizolidin-4-one) (FTR)) into a PTB7-Th:PC71BM binary system. Specifically, the addition of FTR into the PTB7-Th:PC71BM binary system was found to improve the hole mobility of the active layer, which resulted in faster charge transport, more efficient charge separation, and higher PCEs even in the presence of a thick active layer. The single-junction PTB7-Th:FTR:PC71BM ternary OSCs with the active layer thickness of 160 nm presented an outstanding PCE of 9.4%, which was much higher than that 7.5% of the PTB7-Th:PC71BM binary OSCs with the active layer thickness of 160 nm. Notably, the PTB7-Th:FTR:PC71BM ternary OSCs devices exhibited excellent thickness insensitivity. In other words, the PTB7-Th:FTR:PC71BM ternary OSCs device with a thick active layer (200 nm) could still demonstrate a high PCE of over 8.2%, which was well compatible to the requirement for future roll-to-roll printing."
journal_title,Journal of Materials Science
article_title,Sintering and tribomechanical properties of gel-combustion-derived nano-alumina and its composites with carbon nanotubes
keyword,[]
history,"['2018-06', '2018-03-09', '2017-08-23', '2018-02-28']"
abstract,"Abstract Fully pure nano-α-alumina (Al2O3) was prepared following gel-combustion method. Near theoretically dense monolithic Al2O3 and its composites reinforced with multiwalled carbon nanotubes (MWCNTs) were prepared using spark plasma sintering (SPS) at 1500 °C under 40 MPa within 10 min. The shrinkage curves were guided in sequence by the crystallization of the amorphous mass followed by a solid-state sintering. The differential nature of electrical conductivity of both composite phases resulted in enhanced densification through localized joule heating. Formation of ~ 1-μm-sized equiaxed matrix grains with uniform distribution of structurally survived CNTs in it was observed in the sintered composites. Within the investigated loading span, the highest Vickers hardness (HV) values were obtained only at 0.5 wt% MWCNT loading in matrix Al2O3. Improvements in HV values for the composites at 0.2 and 2 kgf indentation loads were found to be ~ 18 and ~ 12%, respectively, in comparison with those obtained for pure matrix phase. Quantitative indentation size effect analyzed through standard mathematical models indicated the role of matrix grain refinement and proper matrix–filler load sharing in changing the true hardness. On the contrary, increased CNT concentration leaded to increased sensitivity toward size effect due to the extreme flexible nature of the filler. Unlubricated linear scratch experiments revealed ~ 30–45% lower specific wear rate (WR) values of the composite specimens compared to SPS-processed monolithic Al2O3. Microstructure and scar profile observations were utilized to describe such enhanced wear resistance of present composites.
"
journal_title,Journal of Materials Science
article_title,Sintering aluminum alloy powder using direct current electric fields at room temperature in seconds
keyword,[]
history,"['2018-06', '2018-03-12', '2017-12-11', '2018-03-05']"
abstract,"Abstract The sintering of a metallic alloy powder into bulk form using only direct current (DC) electric energy input at ambient room temperature is presented for the first time. It was found that a flash sintering phenomena is achievable in aluminum alloy powder, with no addition of external thermal energy, at applied DC electric fields in the range of 175–330 V/cm in which the formation of interparticle necks occurs rapidly and is characterized by a near-instant change in the physical properties of the compact from electrically non-conductive to electrically conducting in a time period on the order of seconds. It was found that the kinetics of this effect have a logarithmic dependence on the magnitude of the applied electric field. Above approximately 330 V/cm, the critical field strength is reached at which an incubation time for flash sintering is not required and sintering occurs instantly with the application of the DC field. This technique has promise to greatly reduce processing time and costs associated with sintering of powder metallurgy products as well as consolidation of nanostructured metals by limiting exposure to high temperatures which result in excessive grain growth."
journal_title,Journal of Materials Science
article_title,Urea-assisted synthesis of amorphous molybdenum sulfide on P-doped carbon nanotubes for enhanced hydrogen evolution
keyword,[]
history,"['2018-06', '2018-03-19', '2018-01-15', '2018-03-14']"
abstract,"Abstract Amorphous molybdenum sulfide on P-doped carbon nanotubes (MoS x /P-CNTs) composite with an original leaves–branch architecture for hydrogen evolution reaction (HER) is successfully fabricated by urea-assisted synthesis via a facile hydrothermal process. It is found that urea used in the process of preparation played a crucial role in the establishment of this unique structure, where leaves-like MoS x  nanosheets are uniformly anchored on P-CNTs substrate. Besides, the optimal amount of MoS x  on P-CNTs bundles is investigated in this paper. Due to the synergistic coupling effects of MoS x  nanosheets and P-CNTs bundles, as a result, the unique structure maintains abundant active sites, a high electrical conductivity as well as distinctive electrons transport mechanism, which gives the optimum MoS x /P-CNTs composite, a higher activity for HER with an overpotential of 151 mV (vs. RHE) to reach a current density of 10 mA cm−2 and a smaller Tafel slope of 49 mV dec−1. Stability tests indicate that the catalyst exhibits excellent electrochemical durability in 0.5 M H2SO4 solution. We envision that this work could provide new insights into the rational design of MoS x -based electrocatalysts for energy conversion and storage."
journal_title,Journal of Materials Science
article_title,Isotropic Mg3Sb2 compound prepared by solid-state reaction and ball milling combined with spark plasma sintering
keyword,[]
history,"['2018-06', '2018-02-16', '2017-10-13', '2018-02-07']"
abstract,"Abstract Mg3Sb2 compounds were synthesized via low-temperature solid-state reaction (SSR) and ball milling (BM), respectively, followed by spark plasma sintering (SPS) process. The effects of possible sintering pressure-induced orientation in the SPS process have been investigated in terms of the microstructure and thermoelectric transport properties. The results indicate that BM technique causes more severe Mg loss than pure SSR method, leading to distinct Sb phase existing in the product after SPS consolidation process. On the contrary, a single phase of Mg3Sb2 is easily obtained with the combination of SSR and SPS techniques. Besides, these BM–SPS and SSR–SPS samples exhibit the similar microstructure as well as the same electrical and thermal transport properties parallel or perpendicular to the direction of sintering pressure. The study suggests that SSR method embodies the advantages of both the composition control and the orientation elimination in Mg3Sb2 compound as compared to BM method with the specific parameters in the current work. This investigation is quite favorable for this material fabrication and the future application of thermoelectric modules and devices.
"
journal_title,Journal of Materials Science
article_title,Deformation of microfibrillated chitin film and composites
keyword,[]
history,"['2018-06', '2018-03-07', '2017-10-26', '2018-02-23']"
abstract,"Abstract Composites of poly(acrylic acid) (PAA) and chitin whiskers were prepared using evaporation method. The weight fraction of chitin whiskers (CHW) was varied from 73 to 23%. Raman was utilised for the first time to monitor the deformation of chitin film and chitin-reinforced PAA composites. The Raman band located at 1622 cm−1 was monitored for deformation. On application of tensile force, the Raman band initially found at 1622 cm−1 corresponding to the single H-bonded amide one spectrum shifted towards a lower wavenumber. Raman band shift rates of − 1.85 cm−1/% for chitin film and − 0.25, − 0.59 and − 0.59 cm−1/% for 23, 43 and 73 wt% CHW whiskers, respectively, were obtained. The Young modulus of composites materials and whiskers were 37, 16 and 115 GPa, respectively, for a two-dimensional in-plane distribution of CHW. CHW within PAA did not show any preferential alignment. At high volume or weight of PAA or low weight CHW (3, 11% chitin) monitoring of the Raman peak shift was difficult."
journal_title,Journal of Materials Science
article_title,Preparation of fabric strain sensor based on graphene for human motion monitoring
keyword,[]
history,"['2018-06', '2018-03-19', '2017-09-15', '2018-03-02']"
abstract,"Abstract To date, wearable sensors are increasingly finding their way into application of healthcare monitoring, body motion detection and so forth. A stretchable and wearable strain senor was fabricated on the basis of commercially available spandex/nylon fabric by the integration of conductive graphene network. Specifically, a simple graphene oxide dip-reduce method that enabled scalable fabrication pathway was employed. The good recovery of the graphene-coated fabric led to consistent resistance values despite the strain applied on the fabric and exhibited high gauge factor around 18.5 at 40.6% strain. Moreover, the graphene-coated fabric sensor could detect human motions such as finger bending with acceptable mechanical properties against un-coated fabrics, indicating that it has huge potential in wearable sensors applications."
journal_title,Journal of Materials Science
article_title,Enhanced metal–insulator transition in V2O3 by thermal quenching after growth
keyword,[]
history,"['2018-06', '2018-03-15', '2017-12-01', '2018-03-08']"
abstract,"Abstract The properties of oxides are critically controlled by the oxygen stoichiometry. Minimal variations in oxygen content can lead to vast changes in their properties. The addition of oxygen during synthesis may not be a precise enough knob for tuning the oxygen stoichiometry when the material has several stable and close oxidation states. We use sputtered V2O3 films as an example to show that rapid transfer of the sample away from the heating element after growth causes a temperature decrease (quenching) quick enough to freeze the correct oxygen stoichiometry in the sample. This procedure has allowed us to improve dramatically the V2O3 electronic properties without any adverse measurable effects on the structural properties. In this fashion, the metal–insulator transition resistance change was increased by two orders of magnitude, while the transition width was decreased by 20 K."
journal_title,Journal of Materials Science
article_title,Preparation of carbon nanotube/copper/carbon fiber hierarchical composites by electrophoretic deposition for enhanced thermal conductivity and interfacial properties
keyword,[]
history,"['2018-06', '2018-03-05', '2017-12-05', '2018-02-03']"
abstract,"Abstract A facile electrophoretic deposition method was proposed to deposit copper (Cu) and carbon nanotubes (CNTs) on the surface of carbon fiber (CF) to improve the thermal conductivity and interfacial properties of carbon fiber-reinforced polymer (CFRP) composites. Surface morphologies, crystallographic properties, thermal conductivity, interlaminar shear strength (ILSS) and element distribution of the composites were characterized by scanning electron microscopy (SEM), X-ray diffraction, thermal constant analysis, short-beam bending tests and SEM energy-dispersive X-ray diffractometer (SEM–EDX), respectively. The results indicate that the presence of Cu and CNTs generated networks and bridges with each other, which produced continuous heat conduction pathways and significantly enhanced both the specific surface area and roughness of the fiber surface. These pathways obviously promoted an improvement in the thermal and interfacial properties. The thermal conductivity and ILSS of the CNTs–Cu–CF/epoxy composites increased by 292 and 39.5%, respectively, compared with CF/epoxy composites. Therefore, this method is anticipated to be utilized in the future fabrication of multifunctional CFRP composites."
journal_title,Journal of Materials Science
article_title,Wool fiber-derived nitrogen-doped porous carbon prepared from molten salt carbonization method for supercapacitor application
keyword,[]
history,"['2018-06', '2018-03-05', '2017-10-23', '2018-01-12']"
abstract,"Abstract Transformation of biomass into nitrogen-doped carbon materials has been considered as effective and affordable route for energy generation and conversion. Wool fiber, as an abundant renewable biomass, contains plentiful nitrogen and sulfur element. Here, nitrogen-doped porous carbon derived from wool fiber by molten salt carbonization method has been realized in 700 °C LiCl/KCl/KNO3 melt. The wool fiber-derived carbon via molten salt carbonization (WFC-MSC) with honeycomb-like structure has a specific surface area of 787.079 m2 g−1 as well as a nitrogen content of 2.6 wt%. Using this nitrogen-doped carbon as electrode materials for supercapacitor, high specific capacitance of 318.2 F/g at 0.25 A/g and good high-rate capability are achieved. The stable cycling performance with specific capacitance of 210 F/g after 5000 cycles at 5 A/g is realized. Moreover, WFC-MSC-based symmetric supercapacitor possesses high specific energy of 20.2 Wh kg−1 with a power density of 202 W kg−1 operated a wide voltage range of 1.8 V in aqueous neutral Na2SO4 electrolyte. These results highlight the merits of the molten salt carbonization of wool fiber in producing nitrogen-doped porous carbon and suggest its prospect for application in supercapacitors."
journal_title,Journal of Materials Science
article_title,Effective reinforcement of amino-functionalized molybdenum disulfide on epoxy-based composites via strengthened interfacial interaction
keyword,[]
history,"['2018-06', '2018-02-27', '2017-10-09', '2018-02-15']"
abstract,"Abstract The effects of amino-functionalized molybdenum disulfide (f-MoS2) on the curing activity and mechanical properties of epoxy-based composites were evaluated. The f-MoS2 was prepared through the mild reaction between mercapto-ethylamine and the exfoliated MoS2. Benefiting from the universal binding ability of amino groups, good dispersion of f-MoS2 in epoxy matrix was achieved. Studies of the curing behavior of epoxy composites showed that the curing temperature and heat release during the curing process of epoxy composites with MoS2 was lower than that of neat epoxy and composites with MoS2, indicating a decreased activation energy. The f-MoS2 containing amino groups on its surface was revealed can react with epoxy matrix and enhance the curing reactions like a co-curing agent of amine-type curing agent. The mechanical properties and thermal stability of the epoxy were both enhanced by f-MoS2. The storage modulus of the EP/f-MoS2 composites was about 60% higher than that of EP/MoS2 composites, which was attributed to the improved dispersion of f-MoS2 in matrix and the strengthened interfacial interactions between f-MoS2 with epoxy than that of the neat MoS2."
journal_title,Journal of Materials Science
article_title,Removal and reuse of Ag nanoparticles by magnetic polyaniline/Fe3O4 nanofibers
keyword,[]
history,"['2018-06', '2018-03-08', '2017-12-10', '2018-02-26']"
abstract,"Abstract For the treatment of wastewater containing Ag nanoparticles (NPs), PANI/Fe3O4 nanofibers were firstly prepared by a novel self-assemble. And then, the efficiency for the removal of Ag NPs from wastewater was investigated. The magnetic performance of PANI/Fe3O4 nanofibers could be optimized by adjusting the pH of the self-assemblied system. Under pH of 3, the as-prepared nanofibers exhibited the highest magnetism and also displayed good efficiency (> 12 mg g−1) for the removal of Ag NPs. Importantly, the resulted product (PANI/Fe3O4/Ag composite) could act as a catalysis for cleaning durable pollutant, 4-nitrophenol. After 10 cycles, only slight decrease in rate constant was found, indicating excellent reusability. Those approaches provide a new way to merge the recovery of Ag NPs as pollutants and reuse of recovered Ag NPs as recyclable material for environmental remediation.
"
journal_title,Journal of Materials Science
article_title,Catalytic conversion of Kraft lignin to bio-multilayer graphene materials under different atmospheres
keyword,[]
history,"['2018-06', '2018-03-05', '2018-01-11', '2018-02-23']"
abstract,"Abstract Kraft lignin was catalytic graphitized by iron at 1000 °C in argon, hydrogen, CO2, methane, and natural gas atmospheres, respectively. The effect of atmospheric agent types on product distribution (gas, liquid, and solid carbon yields) was analyzed. The solid products were characterized by scanning electron microscopy, Raman, high-resolution transmission electron microscopy, and X-ray diffraction. Experimental results have shown that the degree of graphitization of Kraft lignin depends not only on the highest temperature, but also the type of ambient gas phase during heat treatment. Methane and natural gas in the ambient gas phase seem to accelerate the formation of multilayer graphene materials with a range of 2–30 layers, and hydrogen and carbon dioxide have an etching effect on solid carbon species during the catalytic graphitization process, while multilayer graphene-encapsulated iron nanoparticles were the main products in the case of argon."
journal_title,Journal of Materials Science
article_title,Microstructural comparison of friction-stir-welded aluminum alloy 7449 starting from different tempers
keyword,[]
history,"['2018-06', '2018-03-08', '2017-08-01', '2018-03-03']"
abstract,"Abstract Since friction stir welding (FSW) does not create defects that are normally associated with fusion welds, it has become the preferred method for joining aluminum 7XXX series alloys. This work analyzes and compares friction stir welds of two different tempers in aluminum alloy 7449. A thorough analysis was done to characterize the two as-received alloys. Weld parameters were kept identical for the two different starting tempers. Thermocouples were used in the heat-affected zone at three different depths to obtain experimental thermal profiles. Hardness traverses and differential scanning calorimetry were used to analyze the strength of the welds and to analyze precipitate evolution. Simulated thermal profiles were generated via finite element analysis for the weld centerline. Our analysis confirms that preexisting precipitates in the as-received material have an effect on the final microstructure of the welds. A highly overaged aluminum 7449 alloy responds better to FSW as compared to a slightly overaged aluminum 7449 alloy."
journal_title,Journal of Materials Science
article_title,A new polyacrylonitrile fiber for direct carbonization without oxidation
keyword,[]
history,"['2018-06', '2018-02-27', '2018-01-02', '2018-02-19']"
abstract,"Abstract Polyacrylonitrile (PAN) was cyclized by heating in an inert atmosphere and then dissolved in sulfuric acid and oxidized by nitric acid, resulting in product named OCPAN. The OCPAN was dissolved along with PAN and spun into fibers, getting modified PAN fiber (MPAN), to realize self-crosslinking and direct carbonization. The chemical structure of the OCPAN and its compatibility and co-carbonization effects with PAN were characterized through characterization methods of optical microscopy, Fourier transform infrared spectroscopy and thermogravimetric analysis. The structure and properties of the resultant carbon fibers were investigated by scanning electron microscope and monofilament strength tester. The results show that ketone aromatic heterocycles are produced in OCPAN, which are able to promote the formation of a stable structure of carbon network and produce crosslinking with PAN molecules. The carbon yield of the MPAN fiber after direct carbonation under 900 °C temperature in nitrogen is 23% higher than that of the PAN fiber without oxidation carbonized under the same condition, while the strength of the final carbon fiber is a bit lower than that derived from the PAN fiber through pre-oxidation. Therefore, the direct carbonation of PAN fiber is basically realized."
journal_title,Journal of Materials Science
article_title,Electrochemical detection of hydrogen peroxide based on silver nanoparticles via amplified electron transfer process
keyword,[]
history,"['2018-06', '2018-02-20', '2017-12-25', '2018-02-12']"
abstract,"Abstract 
A simple electrochemical sensor platform for hydrogen peroxide (H2O2) using silver nanoparticles (Ag NPs) entrenched in silicate matrix (APS(SG)) is reported. The redox molecules such as potassium ferricyanide ([Fe(CN)6]3−), methyl viologen (MV2+) and ruthenium hexamine ([Ru(NH3)6]3+) were utilized to investigate the electron transfer behavior of the APS(SG)–Ag NPs. The glassy carbon (GC) electrode modified with amine-functionalized silicate sol–gel matrix (GC/APS(SG)) exhibited a complete suppression of the electrochemical response toward MV2+ and [Ru(NH3)6]3+. However, GC/APS(SG) electrode displayed a twofold increase in the peak currents and fast electron transfer kinetics toward [Fe(CN)6]3− in comparison with GC electrode, suggesting that GC/APS(SG) electrode demonstrated an excellent anion exchange property. The GC electrode modified with APS(SG)–Ag NPs (GC/APS(SG)–Ag NPs) showed an improved electron transfer kinetics when neither positive nor negative charge of the electroactive species in the electrolyte. The GC/APS(SG)–Ag NP electrode was effectively further applied for the electrocatalytic and sensor applications toward H2O2. The present sensor exhibited the reduction of H2O2 at less negative potential and showed the experimental low detection limit of 25.0 µM with the sensitivity of 0.042 µA/µM. In addition, the developed APS(SG)–Ag NP-based amperometric sensor presented fast response, good stability and reproducibility."
journal_title,Journal of Materials Science
article_title,Rationalization of solidification mechanism of Nd–Fe–B magnets during laser directed-energy deposition
keyword,[]
history,"['2018-06', '2018-03-07', '2017-11-13', '2018-02-26']"
abstract,"Abstract Near-net fabrication techniques are highly beneficial to minimize rare earth metal usage to fabricate dense fully functional magnets. In this study, feasibility of using the directed-energy deposition technique for fabrication of magnets is evaluated. The results show that despite the ability to fabricate highly reactive materials in the laser deposition process, the magnetic coercivity and remanence of the hard magnets is significantly reduced. X-ray powder diffraction in conjunction with electron microscopy showed that the material experienced a primary Nd2Fe17Bx solidification. Consequently, the absence of the hard magnetic phase resulted in deterioration of the build properties."
journal_title,Journal of Materials Science
article_title,Ultrathin nanosheets-assembled CuO flowers for highly efficient electrocatalytic water oxidation
keyword,[]
history,"['2018-06', '2018-02-27', '2017-11-10', '2018-02-20']"
abstract,"Abstract Integration of water oxidation catalysts on conductive support without polymer binder is an appealing strategy to improve the catalytic activity for electrochemical oxygen evolution reaction. Herein, the hierarchical CuO dandelion-like materials assembled from numerous ultrathin nanosheets are directly grown on Cu foil to produce a 3D oxygen evolution anode (CuO NSDs/CF). As a result of its integrated configuration and high electrocatalytic active sites, the anode exhibits superior electrocatalytic water oxidation activity in 1.0 M NaOH solution, associated with a small overpotential of 370 mV at 10 mA cm−2 and a low Tafel slope of 41 mV dec−1. Furthermore, the anode can maintain a relatively stable current density at 1.65 V versus RHE for at least 24 h, and a high Faradaic efficiency of 98% is also achieved."
journal_title,Journal of Materials Science
article_title,Cell attachment/detachment behavior on poly( N-isopropylacrylamide)-based microgel films: the effect of microgel structure and swelling ratio
keyword,[]
history,"['2018-06', '2018-03-21', '2018-01-28', '2018-03-08']"
abstract,"Abstract Microgels are cross-linked soft particles with a three-dimensional network structure that are swollen in a good solvent. Poly(N-isopropylacrylamide) (pNIPAAm)-based microgels have attracted great attentions for their temperature responsive property, particularly in recent years, pNIPAAm-based microgel films were utilized as a new kind of thermoresponsive surface to tune cell attachment/detachment behavior via temperature stimuli. However, some results are not consistent, for example, different polymerization conditions may bring out different results even for pure pNIPAAm microgel. This work aims to find out which factor plays the critical role for successful cell detachment on the pNIPAAm-based microgel films. The results unraveled that the structure and swelling ratio of the microgel rather than the film thickness plays a key role on the successful cells detachment, unlike linear pNIPAAm films in which the cells’ attach/detach property is only determined by the film thickness. For poly(N-isopropylacrylamide–styrene) microgel film, NIH3T3 cells could only detach when the microgel has a uniform structure and the volume dilatation of the microgel (20/38 °C) is larger than 4."
journal_title,Journal of Materials Science
article_title,Enhanced thermoelectric performance of bismuth-doped magnesium silicide synthesized under high pressure
keyword,[]
history,"['2018-06', '2018-03-15', '2017-12-16', '2018-02-27']"
abstract,"Abstract Polycrystalline Mg2Si1−xBi x  compounds were prepared with high-pressure synthesis followed by spark plasma sintering. The structural and compositional analyses indicate a dominant antifluorite phase with the oxidation and volatilizing loss of Mg highly suppressed. High-pressure synthesis promotes Bi doping and the formation of interstitial Mg, both of which contribute electrons and give rise to high carrier concentration. Meanwhile, a relatively high carrier mobility is maintained with elevating carrier concentration, beneficial to the thermoelectric properties enhancement of our high-pressure synthesized samples. The optimal Mg2Si0.985Bi0.015 possesses the highest power factor and the lowest thermal conductivity. As a result, the maximal ZT of 0.98 is achieved at 883 K, one of the highest values for the Bi-doped binary Mg2Si compounds. Our results thus indicate the advantage of high pressure in synthesizing Mg2Si-based thermoelectric materials with enhanced thermoelectric performance.
"
journal_title,Journal of Materials Science
article_title,One-pot hydrothermal fabrication and enhanced lithium storage capability of SnO2 nanorods intertangled with carbon nanotubes and graphene nanosheets
keyword,[]
history,"['2018-06', '2018-03-19', '2017-12-09', '2018-03-14']"
abstract,"Abstract A three-dimensional (3D) nanoarchitectured ternary composite of SnO2 nanorods intertangled with multiwalled carbon nanotubes and graphene nanosheets (SnO2/CNTs/Gr) was synthesized via one-pot template-free hydrothermal method and investigated as anode for lithium-ion batteries. Compared to bare SnO2 and corresponding binary composites including SnO2/CNTs and SnO2/Gr, SnO2/CNTs/Gr shows significantly improved cycling stability and rate performance. The initial discharge specific capacity of SnO2/CNTs/Gr is 1391 mAh g−1 and remains 522 mAh g−1 after 50 cycles at a current density of 100 mA g−1. Meanwhile, the composite shows excellent rate reversibility. For example, 120 mAh g−1 can be retained at a high current density of up to 1600 mA g−1, and 582 mAh g−1 can still be retrieved once the current density is switched back to 50 mA g−1. The carbon nanotubes and graphene nanosheets in the composites play different enhancing effect. The significantly improved energy storage capability of SnO2/CNTs/Gr can be attributed to a synergistic effect of the intertangled CNTs and graphene nanosheets."
journal_title,Journal of Materials Science
article_title,Mechanical properties and failure behavior of AZ61 magnesium alloy at high temperatures
keyword,[]
history,"['2018-06', '2018-02-14', '2017-10-14', '2018-02-07']"
abstract,"Abstract To investigate the mechanical behavior of AZ61 alloy in a mushy state, uniaxial tensile tests of as-extruded AZ61 alloy have been implemented at temperatures of 475–575 °C at a strain rate of 3 s−1. Experimental results show that zero strength and zero ductility emerged at 575 and 525 °C, respectively. Abnormal coarse grains with sugar-like morphology and molten Mg17Al12 phases were observed in the brittle temperature range. The grain boundaries and surface were gradually covered partially or completely by a liquefied microstructure as temperatures increased. Small micropores developed into short cracks at temperatures above 525 °C and then to large cracks throughout the grain boundaries at 575 °C. It is therefore suggested that crack propagation was controlled by the quantity and distribution of molten phase in the mushy zone. Three types of interfacial wedge cracks are applied to explicate the fracture behavior of the alloy at elevated temperatures."
journal_title,Journal of Materials Science
article_title,Highly flexible electrospun carbon/graphite nanofibers from a non-processable heterocyclic rigid-rod polymer of polybisbenzimidazobenzophenanthroline-dione (BBB)
keyword,[]
history,"['2018-06', '2018-03-06', '2017-11-21', '2018-02-28']"
abstract,"Abstract Development of mechanically flexible carbon nanofibers is highly desired for the applications in modern flexible electronics and energy storage devices. This work reports the manufacture and characterization of highly flexible carbon nanofibers (CNFs) and graphitic carbon nanofibers (GCNFs) from a non-processable heteroaromatic rigid-rod polymer, polybisbenzimidazobenzophenanthroline-dione (BBB). The flexible CNFs/GCNFs were prepared by a newly developed method of electrospun nanofiber template solid-state polymerization, followed by carbonization/graphitization. In specific, BBB nanofibers were prepared first by the nanofiber template solid-state polymerization method using polyimide as template by electrospinning and heat treatment (500 °C). Subsequently, CNFs/GCNFs were obtained through carbonization under different temperatures of 1200–2700 °C. SEM, HRTEM, Raman spectroscopy, and XRD were used to characterize the morphologies and microstructures. Intriguingly, the BBB-derived CNFs/GCNFs presented extremely good mechanical flexibility that resisting to readily bending, folding, and kneading. Hence, this newly developed extremely flexible BBB-derived CNFs/GCNFs with such good performance could have great potential applications such as using as electrode materials for flexible electrochemical devices."
journal_title,Journal of Materials Science
article_title,Cagelike porous sulfonated polystyrene@polyaniline composite microspheres for high-performance supercapacitor
keyword,[]
history,"['2018-06', '2018-03-13', '2017-10-29', '2017-12-06']"
abstract,"Abstract The development of novel high-performance electrode materials has become increasingly urgent due to the broad demands on the large-capacity energy storage devices nowadays. In this work, cagelike porous sulfonated polystyrene (cSPS) microspheres are first synthesized as the skeleton structure templates, on which polyaniline (PANI) nanoparticles with a size of about 30 nm are loaded through the in situ polymerization of aniline. The novel cSPS-supported PANI composite microspheres (cSPS@PANI) possess hierarchical meso-/macroporous structure, and their BET specific surface area and pore volume reach the maximum at a moderate PANI mass fraction. The electrochemical performance of cSPS@PANI composite microspheres was evaluated through a three-electrode system with 1 M H2SO4 as the electrolyte. The specific capacitance of the cSPS@PANI composite microspheres can reach as high as 374 F g−1 at a current density of 1 A g−1, and only 11.8% is lost after 500 charge/discharge cycles. Thus, the cSPS@PANI composite microspheres can be potentially used as one of the novel outstanding electrode materials in the fabrication of high-performance energy storage devices."
journal_title,Journal of Materials Science
article_title,Graphene/PANI hybrid film with enhanced thermal conductivity by in situ polymerization
keyword,[]
history,"['2018-06', '2018-03-23', '2017-12-20', '2018-02-02']"
abstract,"Abstract Heat dissipation in time is essential for long-term reliability of electrical devices. Graphene, with superior thermal conductivity and excellent flexibility, exhibits a potential to substitute currently used graphite film for thermal management. In this work, a free-standing film with enhanced thermal conductivity and better flexibility was achieved by a facile and environmentally friendly in situ polymerization. The ‘molecular welding’ strategy was introduced for preparation of graphitized graphene oxide/polyaniline (gGO/PANI) hybrid film, and the uniformly distributed PANI, serving as a solder, connected adjacent graphene sheets and filled in air voids of GO films. Scanning electron microscopy, Fourier transform infrared spectroscopy, X-ray photoelectron spectroscopy, X-ray diffraction and Raman spectroscopy were used to determine the structure of PANI and the interaction between GO and PANI. The in-plane thermal conductivity of gGO/PANI film is enhanced by 38% to 1019.7 ± 0.1 W m−1 K−1 with addition of 12 wt% PANI, compared with that of pristine gGO film. Besides, the gGO/PANI film shows better flexibility than gGO film after 180° bending for 500 times."
journal_title,Journal of Materials Science
article_title,A study on generation of embossed carbon nanopattern by induced microdomain alignments in PAN-based block copolymer under electric field
keyword,[]
history,"['2018-06', '2018-03-15', '2017-10-26', '2018-02-09']"
abstract,"Abstract In this study, generation of a unique carbon nanostructure having embossed morphology was examined focusing on formation pathway under an external electric field. An ultrathin embossed carbon layer was prepared by exposing a polyacrylonitrile-based block copolymer (BCP) thin film to an electric field. A detailed investigation on formation process and window for experimental parameters such as field intensity and exposure time was performed systematically. An electric field was applied to prepared BCP thin films to induce regulated microdomain alignments, and subsequent thermal treatment produced an unprecedented carbon nanostructure having a unique morphology. Atomic force microscopy analysis showed that a critical field strength (ca. 10 V/μm) and exposure time (24 h) were required to obtain the carbon nanostructure. This article can provide important information for future studies on creation of nanopatterns with electric fields."
journal_title,Journal of Materials Science
article_title,In vitro minera lization kinetics of po ly( l- lactic acid)/hydroxyapatite nanocomposite materia l by attenuated tota l ref lection Fourier transform infrared mapping coup led with principa l component ana lysis
keyword,[]
history,"['2018-06', '2018-02-28', '2017-12-10', '2018-02-22']"
abstract,"Abstract Poly(l-lactic acid)/hydroxyapatite (PLLA/HA) nanocomposite, which combines the properties of PLLA and HA, is suitable to construct scaffold for bone tissue engineering. Its mineralization behavior plays a key role in composite’s property. In this present work, two PLLA/HA composites with porous and compact architecture were fabricated and soaked into simulated body fluid (SBF) at 37 °C for in vitro mineralization, respectively. An attenuated total reflection Fourier transform infrared (ATR FTIR) mapping coupled with principal component analysis was developed to investigate the mineralization kinetics. The FTIR images with an area of 300 × 300 μm2 were collected every 7 days. The results suggest that the mineralization of PLLA/HA composites in SBF follows a zero-order kinetic model, no matter what the architecture is. However, it follows a second-order model when the composite is degraded in phosphate-buffered saline solution based on our previous work. The mechanisms of the in vitro mineralization kinetics in different submersion solutions are discussed. Our results alert researchers that they should choose the mineralization medium cautiously.
"
journal_title,Journal of Materials Science
article_title,"Controllable synthesis of MoS2 nanostructures from monolayer flakes, few-layer pyramids to multilayer blocks by catalyst-assisted thermal evaporation"
keyword,[]
history,"['2018-06', '2018-02-27', '2017-09-14', '2018-02-01']"
abstract,"Abstract Molybdenum disulfide (MoS2), as a representative of two-dimensional layered materials, has been extensively investigated due to their unique structure and interesting electronic and optical properties. However, the controllable synthesis of monolayer and pyramidal MoS2 nanostructures needs improvement, and their growth mechanism requires more investigations. Here, uniform MoS2 nanostructures from monolayer flakes, few-layer pyramids to multilayer blocks were successfully fabricated by a catalyst-assisted thermal-evaporation-based chemical vapor deposition method via simply adjusting the carrier Ar gas flow rate. After the comprehensive characterization on the obtained materials, their nucleation and growth mechanisms were proposed with specifically highlighting the influence of the carrier gas flow rate, which might also be of help to understand the synthesis processes of other two-dimensional semiconducting transition metal dichalcogenides by similar method."
journal_title,Journal of Materials Science
article_title,Electroplating of porous gold films for SERS analysis of heme derivatives
keyword,[]
history,"['2018-06', '2018-02-23', '2017-11-21', '2018-01-29']"
abstract,"Abstract 
Gold porous films with an 2D inverse opal structure were prepared via electrochemical deposition for further application as SERS-active substrates for the on-chip analysis of heme B derivatives. The thickness of the deposited film was controlled through deposition charge while the grain size was dependent significantly on electrolyte content. A semiquantitative surface analysis of film composition and phase analysis of the gold films were performed by XPS and XRD methods while the observed local, Mie and Bragg plasmon resonance modes were discussed based on UV–vis reflectance data."
journal_title,Journal of Materials Science
article_title,Synthesis and characterization of Ti-doped ZrSiO4 at ambient and high-pressure conditions
keyword,[]
history,"['2018-06', '2018-03-19', '2017-11-24', '2018-02-23']"
abstract,"Abstract We have successfully synthesized for the first time a Ti-doped ZrSiO4 powder (stoichiometry Zr0.95Ti0.05SiO4) via a sol–gel route. The structural and vibrational properties have been characterized by X-ray diffraction, electron microscopy and Raman spectroscopy. Zr0.95Ti0.05SiO4 has a tetragonal zircon-type structure with a = 6.5981(2) Å and c = 5.9810(2) Å. Eight of its Raman-active modes have been measured and assigned. We also performed high-pressure synchrotron X-ray diffraction experiments. The structural behavior was studied up to 31 GPa. At this pressure, we found evidence of the onset of a phase transition, coexisting the low-pressure polymorphs (zircon) with the typical high-pressure polymorph of ZrSiO4 (reidite-type). From the analysis of unit-cell volume versus pressure using a Birch–Murnaghan equation of state, in the quasi-hydrostatic pressure regime (P < 10.5 GPa), we have determined a bulk modulus of 297 GPa. This magnitude represents an enhancement of a 30% in the value of this parameter if compared with un-doped zircon-type ZrSiO4 (bulk modulus < 227 GPa). The low compressibility of Zr0.95Ti0.05SiO4 converts this compound in a very good candidate for many technological applications. The effect of pressure on the linear compressibility of the lattice parameters is also analyzed."
journal_title,Journal of Materials Science
article_title,"Structure, bonding, stability, electronic, thermodynamic and thermoelectric properties of six different phases of indium nitride"
keyword,[]
history,"['2018-06', '2018-03-06', '2017-08-18', '2018-02-24']"
abstract,"Abstract Density functional investigation is carried out on the structure and bonding, stability, electronic, thermodynamic and thermoelectric properties on the six different phases of indium nitride. In addition to the monolayer hexagonal, zinc blende, wurtzite and rock salt, two more new possible phases, viz. caesium chloride and nickel arsenide, are also explored. The calculated crystal parameters for all six phases are compared with available experimental and theoretical values. Band structure and density of states are predicted for understanding their behaviour in metal–insulator–semiconductor domains as well as the contribution of their different atomic orbitals around the valence and conduction band edges. Phonon dispersion curves are generated to understand the dynamical stability of the considered indium nitride phases. Further, a detail comparative study is performed on various thermodynamic and thermoelectric properties of the dynamically stable indium nitride phases. An electron density contour is also generated for the stable phases to understand the nature bonding between indium and nitride in those phases."
journal_title,Journal of Materials Science
article_title,Enhanced electromechanical strain response in (Fe0.5Nb0.5)4+-modified Bi0.5(Na0.8K0.2)0.5TiO3 lead-free piezoelectric ceramics
keyword,[]
history,"['2018-06', '2018-03-08', '2017-12-05', '2018-02-13']"
abstract,"Abstract By the traditional solid-state reaction method, Bi0.5(Na0.8K0.2)0.5Ti1−x(Fe0.5Nb0.5) x O3 (marked as BNKT-xFN; x = 0.00, 0.01, 0.02, 0.03 and 0.04) piezoelectric ceramics were fabricated, and the effects of FN substitution on the dielectric, ferroelectric, piezoelectric and electric field-induced strain performance were investigated. The relative dielectric permittivity and loss tangent reveal that the phase transition temperature between ferroelectric and ergodic relaxor phase is reduced from 90 °C to room temperature (RT), even below RT, with increasing FN content. Temperature dependence of polarization–electric field loops and strain-electric field curves exhibits that the ferroelectric order is disturbed gradually, and the ergodic relaxor phase forms with increasing FN content. A large unipolar strain of 0.42% and corresponding d33* (= Smax/Emax) of 642 pm/V for the sample with x = 0.04 are obtained under 6.5 kV/mm due to the phase transition from ergodic relaxor to ferroelectric. These results indicate that the (Fe0.5Nb0.5)4+ complex ion-modified BNKT-based ceramics would have great potentials for lead-free electromechanical actuator applications."
journal_title,Journal of Materials Science
article_title,Hierarchical bicomponent TiO2 hollow spheres as a new high-capacity anode material for lithium-ion batteries
keyword,[]
history,"['2018-06', '2018-03-09', '2018-01-03', '2018-03-02']"
abstract,"Abstract Hierarchical TiO2-based hollow spheres were successfully synthesized via a hydrothermal method using FeSO4·7H2O, CoSO4·7H2O and ZnSO4·7H2O as soft templates. The as-prepared hollow spheres are well dispersed with the diameters of 2–4 μm. The shell and the interior surface of the spheres are composed of loosely packed grains, which provide a large specific surface area to facilitate lithium-ion diffusion processes. Among the three types of hybrid hollow spheres, TiO2/Fe2O3 shows the highest reversible capacity and best cycling stability (discharge capacities of 290.8 and 210.5 mAh/g were achieved after 100 cycles at 0.1C and 1C, respectively) and rate performance (from 461.1 mAh/g at 0.1C to 79.3 mAh/g at 5C with recovery to 288.6 mAh/g at 0.1C) for anode materials in lithium-ion batteries.
"
journal_title,Journal of Materials Science
article_title,Structure and chemistry of liquid Al–Cu alloys: molecular dynamics study versus thermodynamics-based modelling
keyword,[]
history,"['2018-06', '2018-02-26', '2017-09-17', '2018-02-05']"
abstract,"Abstract Classical molecular dynamics simulations, employing a modified embedded atom model (MEAM) parametrization recently developed by Trybula, have been performed and combined with thermodynamics-based modelling for weakly interacting compound-forming molten alloys, to investigate the structure and chemistry of liquid Al–Cu alloys over a broad Cu concentration range. The compound-forming model (CFM) based on experimental thermodynamic data revealed the importance of the Al2Cu “associate” in the determination of transport properties such as diffusion and viscosity as well as confirmation of the compound formation ability with regard to the available experimental data. Adequately to this fact, molecular dynamics simulation results showed strong evidence of deviation from regular metallic solution resulting from a preponderance of chemical short-range ordering, expressed by Warren–Cowley parameter and increasing abundance of icosahedral motifs with increasing Cu content. In addition, their strong impact on mass transport properties as well as the excess entropy has been detected which exhibits nonlinear compositional behaviour. Thus, we find that the Stokes–Einstein relation is unsuitable for atom transport properties determination at investigated Cu concentration range, while the Green–Kubo formalism can fully account for the experimentally observed physical phenomena. We obtain a compact and compatible view onto the structure and chemical behaviour, including atom kinetics and thermodynamics, of Al–Cu liquid alloys, which allowed us to find another hard-sphere-like metallic system in which transport properties and thermodynamics are strongly affected by packing effects. The hybrid approach presented herein gave a broader and deeper look into the liquid state of the Al–Cu alloys being missing in the literature."
journal_title,Journal of Materials Science
article_title,A novel room temperature POSS ionic liquid-based solid polymer electrolyte
keyword,[]
history,"['2018-06', '2018-02-20', '2017-08-08', '2018-02-12']"
abstract,"Abstract Ionic liquids-based solid polymer electrolytes enhance the battery’s overall performance without drawbacks in safety compared with conventional electrolyte. In order to develop a novel solid electrolyte, we synthesized a series of novel room temperature imidazolium-based polyhedral oligomeric silsesquioxane ionic liquids (POSS-ILs) consisting of POSS-COO− anions and a variety of imidazolium cations, which will be used as plasticizers of solid polymer electrolyte in this work. The thermal stabilities of POSS-ILs have been dramatically enhanced by the introduction of POSS moiety, and the initial decomposition temperatures of POSS-ILs have increased by at least 94 °C compared to their corresponded succinamic acid ionic liquids. The glass transition temperatures of POSS-ILs also have increased to − 15.9 to − 25.4 °C. Then the POSS-ILs are employed to obtain a novel solid polymer electrolyte based on blend of polyethylene oxide, poly(vinylidene fluoride-hexafluoropropylene), propylene carbonate and lithium bis(trifluoromethanesulfonyl) imide with high ionic conductivity and electrochemical windows. The ionic conductivities of POSS-ILs-based solid polymer electrolytes are up to 8.0 × 10−4 S cm−1 at 22 °C and 2.0 × 10−3 S cm−1 at 62 °C, and the electrochemical windows of POSS-ILs-based solid polymer electrolytes are stable up to 5.0 V. Moreover, the Li/LiFePO4 cell containing POSS-ILs-based solid polymer electrolytes exhibits good cycling performance and high rate stability. These results suggest that the POSS-ILs-based solid polymer electrolytes could be a suitable prospective electrolyte material for lithium-ion battery applications."
journal_title,Journal of Materials Science
article_title,Effects of POSS functionalization of carbon nanotubes on microstructure and thermomechanical behavior of carbon nanotube/polymer nanocomposites
keyword,[]
history,"['2018-06', '2018-03-05', '2017-12-22', '2018-02-26']"
abstract,"Abstract Surface modification of carbon nanotubes (CNTs) is a promising method to control the properties of a CNT/polymer system. Recent research has been directed toward chemical attachment of polyhedral oligomeric silsesquioxane (POSS) moieties to the CNT surface. POSS modification of CNTs can affect both the quality of CNT dispersion in the matrix and the interactions between polymer chains and nanotubes at the interphase region. The goal of the current study is to investigate these effects. Accordingly, nanocomposites containing POSS-modified CNTs, unmodified CNTs, and POSS were fabricated by infusion of 0.25, 0.5, and 1.0 wt% particles into a vinyl ester (VE) resin. Mechanical and thermal properties of experimental materials were evaluated using three-point bending, differential scanning calorimetry, and thermogravimetric analysis methods. The state of particle distribution/dispersion in VE matrix was also observed. Optical microscopic studies showed that both POSS/VE and CNT/VE nanocomposites possess local agglomeration. This was more extensive in CNT/VE system. However, CNT-POSS/VE systems showed a fine-textured microstructure with homogeneous distribution of CNT-POSS hybrids into VE resin. This indicates that the dispersibility of CNTs improved due to POSS functionalization. Scanning electron microscopy (SEM) of fracture surfaces revealed apparent de-bonding of agglomerates from the matrix in both POSS/VE and CNT/VE system, which is in agreement with the observed drop in their fracture strain. On the other hand, SEM studies of nanocomposites containing POSS-modified nanotubes revealed formation of a 3D network of well-dispersed CNT-POSS hybrids. SEM analysis further indicated the occurrence of a fracture mechanism with enhanced interactions between individual CNTs and VE matrix. This stiff and flexible network of individual CNTs is responsible for enhancement in elastic modulus, glass transition, and thermal decomposition temperatures of CNT-POSS/VE nanocomposites."
journal_title,Journal of Materials Science
article_title,Water vapour permeation through high barrier materials: numerical simulation and comparison with experiments
keyword,[]
history,"['2018-06', '2018-03-20', '2017-11-10', '2018-03-13']"
abstract,"Abstract The long-term thermal performance of vacuum insulation panels (VIP) is brought by the capacity of their barrier envelope to maintain the core material under vacuum. This study is focused on the detailed modelling of gas transfer through the defects of aluminium-coated polymer films used for VIPs’ envelopes. The 3D simulations were performed with monolayer and multilayer metal-coated polymer films. They have been carried out in dynamic conditions with the SYRTHES® software developed by EDF R&D. The results show that the water vapour and air permeations through a monolayer film slightly depend on the polymer substrate thickness, diffusivity and solubility, but primarily, on the defects geometry and arrangement. Regarding multilayer films, the permeation can be deduced from the ideal laminate theory. We are now able to provide and operate a numerical model, which can calculate the permeance of monolayer or multilayer metallized polymer films as a function of the coating quality and the geometry of the layers. Even if calculated permeances are ten times higher than measurements, this study improves our understanding of gas transports through VIPs’ barrier envelope and allows to manage more efficiently the relations between the films microstructures and their overall permeability. This paper is split into 6 parts: physical phenomena, methodology and modelling tools, simulation results, experiments and model validation and then, discussion and conclusion."
journal_title,Journal of Materials Science
article_title,Use of Asparagus racemosus extract as green corrosion inhibitor for mild steel in 0.5 M H2SO4
keyword,[]
history,"['2018-06', '2018-02-16', '2017-10-04', '2018-02-07']"
abstract,"Abstract The corrosion inhibition effect of Asparagus racemosus fruits extract, a species of asparagus common throughout Nepal, Sri Lanka, India, and the Himalayas, has been examined on mild steel corrosion in 0.5 M H2SO4 by using weight loss measurements, potentiodynamic polarization measurements, and electrochemical impedance spectroscopy techniques. The presence of this Sarsasapogenin-containing extract decreases the corrosion rate of mild steel in acidic solution. The maximum corrosion inhibition efficiency was observed at 100 mg L−1 inhibitor concentration in 0.5 M H2SO4. The adsorption of A. racemosus extract on the surface of mild steel has been investigated by using AFM study, SEM study, and absorption spectroscopic techniques. Due to the existence of heteroatoms in the main components, A. racemosus extract is considered to be a good inhibitor."
journal_title,Journal of Materials Science
article_title,Recent progress in the modification of carbon materials and their application in composites for electromagnetic interference shielding
keyword,[]
history,"['2018-06', '2018-02-15', '2017-11-03', '2018-02-06']"
abstract,"Abstract With the development in the modern technologies such as telecommunication instruments and scientific electronic devices, large amount of the electromagnetic radiations are produced, which lead to harmful effect on the highly sensitive electronic devices as well as on the health of human beings. To minimize the effect of electromagnetic radiations produced by different technologies, more efficient shielding materials are required which must be cost-effective, lightweight and good corrosion resistive. In this review, we focused on the shielding materials based on composites of carbon nanotubes and graphene. The typical surface modification of carbon nanotubes and graphene to optimize their interactions with polymers matrix has also summarized. It was found that the composites based on these carbon fillers were more efficient for electromagnetic interference shielding due to their unique properties (i.e., superior electrical, mechanical and thermal) together with lightweight, easy processing. Hence, the carbon nanotubes and graphene-based composites are excellent shielding materials against the electromagnetic radiations."
journal_title,Journal of Materials Science
article_title,"Studies of structural, optical, and electrical properties associated with defects in sodium-doped copper oxide (CuO/Na) nanostructures"
keyword,[]
history,"['2018-06', '2018-03-06', '2017-11-04', '2018-02-26']"
abstract,"Abstract In the present paper, we report a detailed study on the sodium (Na) doping-induced modifications in the copper oxide (CuO) nanostructure and its properties. A facile and sustainable sol–gel synthesis approach was employed for the preparation of high-quality pristine CuO- and Na-doped CuO nanostructures(1.0, 3.0, 5.0 and 7.0 mol% doping levels, CuO/Na) with controlled shape and composition. Due to the remarkable difference in the ionic radii of Cu2+ (0.73 Å) and Na+ (1.02 Å), Na+ substitution in place of Cu2+ generates strain/distortions in CuO lattice. The XRD analysis reveal the structural alteration from monoclinic to cubic symmetry with increase in doping level and also reveal the phase purity up to 3% doping level, and beyond this (i.e., for 5 and 7% doping level) small amount of impurity phase corresponding to Na2O was observed. The FTIR results further confirmed the presence of the Na–Cu–O stretching vibrations at higher Na-doped samples. Morphology of the samples indicates that the Na-doped CuO nanostructures exhibit less agglomeration compared to pristine CuO nanoparticles. The presence of Na in CuO lattice were found to greatly enhances optical and electrical properties owing to the formation of defects like copper vacancies and oxygen vacancies at the grain boundaries of the nanoparticles with increased doping of Na."
journal_title,Journal of Materials Science
article_title,"Biocompatible nanoclusters of O-carboxymethyl chitosan-coated Fe3 O4 nanoparticles: synthesis, characterization and magnetic heating efficiency"
keyword,[]
history,"['2018-06', '2018-03-05', '2017-11-17', '2018-02-26']"
abstract,"Abstract 
In this work, we developed a polymer encapsulation of Fe3O4 nanoparticles as a core–shell nanocluster with different sizes to investigate the cluster structure effect on their magnetic properties and magnetic heating behavior. Well-dispersed nanoclusters of O-carboxymethyl chitosan-coated Fe3O4 nanoparticles were synthesized by microwave-assisted co-precipitation. The cluster sizes were tunable by varying the concentration of polymers used during synthesis. Nanoclusters present superparamagnetic behavior at room temperature with a reduction in saturation magnetization as a consequence of coating layer. The shift of blocking temperature to the higher value with increasing clusters size shows the stronger magnetic interaction in larger magnetic clusters. In a low alternating magnetic field with frequency of 178 Hz and amplitude of 103 Oe, nanoclusters offer a high heating efficiency. A maximum specific absorption rate of 204 W/g is observed in the sample with hydrodynamic size of 53 nm. In vitro cytotoxicity analysis performed on HeLa cells verified that nanoclusters show a good biocompatibility and can be an excellent candidate for applications in hyperthermia cancer treatment."
journal_title,Journal of Materials Science
article_title,The study of damping property and mechanism of thermoplastic polyurethane/phenolic resin through a combined experiment and molecular dynamics simulation
keyword,[]
history,"['2018-06', '2018-03-19', '2017-12-22', '2018-03-09']"
abstract,"Abstract In this paper, the damping property of thermoplastic polyurethane (TPU) was firstly regulated by introducing the phenolic resin (PR) with more active hydroxyl group and larger molecular weight. The mechanism of enhanced damping property was systematically elucidated through the combination of molecular dynamic (MD) simulation and experimental methods. The MD simulation results showed the hydrogen bonds (H-bonds), binding energy, and fractional free volume (FFV) in the quantitative way. When the PR content increased to 40%, it had the largest number of H-bonds, highest binding energy, and relative small FFV. Meanwhile, the experimental results showed that there indeed existed H-bonds interaction between PR and TPU polymer chains. Furthermore, the glass transition temperature (Tg) as well as the loss factor (tan δ) was remarkably improved with increasing the PR content, the effective damping temperature range was broadened, the peak position was also moved to room temperature. This study can provide some reference for designing high-performance TPU-based damping materials."
journal_title,Journal of Materials Science
article_title,Design of spinous Ni/N-GN nanocomposites as novel magnetic/dielectric microwave absorbents with high-efficiency absorption performance and thin thickness
keyword,[]
history,"['2018-06', '2018-03-09', '2017-11-28', '2018-03-02']"
abstract,"Abstract Elaborately constructing magnetic/dielectric nanocomposites is believed to be an efficient pathway to enhance the microwave absorption performance of microwave absorbers. We reported a straightforward one-pot solvothermal route to fabricate spinous Ni grown on N-GN as fascinating magnetic/dielectric microwave absorbents. Ni nanostructures show spinous shape, which are regularly decorated on N-GN. Benefiting from the synergistic effect of magnetic spinous Ni nanostructures and dielectric lightweight N-GN, the N-GN/Ni nanocomposites possess tremendously increased microwave absorption characteristics. The N-GN/Ni nanocomposites exhibit a maximum RL of − 47.1 dB at 13.6 GHz when the thickness is only 1.6 mm, which is about 3 times larger than that of bare Ni. In particular, the effective absorption bandwidth (RL ≤ − 10 dB) of N-GN/Ni nanocomposites at 1.6 mm can reach 3.9 GHz ranging from 11.6 to 15.5 GHz. When the thickness is 1.1–5.0 mm, N-GN/Ni nanocomposites show a broad effective absorption bandwidth (RL ≤ − 10 dB) of 15.5 GHz ranging from 2.5 to 18 GHz, whereas the effective absorption bandwidth of bare Ni is only 0.7 GHz. The improved microwave absorption performance of N-GN/Ni nanocomposites is related to better impedance matching condition and higher attenuation capacity. The N-GN/Ni nanocomposites, which possess thin thickness, lightweight, strong absorption and broad bandwidth, are believed to have great potential as novel high-efficiency microwave absorbers."
journal_title,Journal of Materials Science
article_title,Single layer of carbon phosphide as an efficient material for optoelectronic devices
keyword,[]
history,"['2018-06', '2018-02-23', '2017-09-19', '2018-02-07']"
abstract,"Abstract Recently, a single layer of carbon phosphide allotropes were theoretically investigated and show finite energy band gap and high carrier mobility to attract rapidly growing interests. Here, we study the structural, electronic and optical properties of single-layer carbon phosphide (CP) allotropes (α-, β- and γ-phases) based on density functional theory. The thermoelectric properties like electrical conductivity, thermal conductivity, thermoelectric power, figure of merit (ZT) and compatibility factor as a function of temperature are calculated by using BoltzTrap code. The electronic band structures reveal the direct band gap of α- and β-CP monolayer (i.e., semiconducting nature), while γ-CP monolayer is semimetallic with Dirac fermions. The significant absorption is observed in α-, β- and γ-CP monolayer, which can be used as an ultraviolet–optical–nanodevice, and all three phases of monolayer of CP are directionally transparent. The transmission spectrum of monolayer of β- and γ-phase in the visible region is much higher; therefore, it is used in an anti-reflecting layer in solar cell also. The α-phase of CP monolayer in the ZT increases linearly up to 1500 K, and beyond it reached maximum values as compared to other phases. The results show that below 550 K, CP allotropes (both n- and p-types) are hitherto the best-promising thermoelectric materials. These theoretical investigations suggest that the different phases of semiconducting materials of CP are better candidate for potential application in micro-/nanoscale device, photovoltaic and optoelectronics."
journal_title,Journal of Materials Science
article_title,Fabrication of novel nanocomposites from styrene-butadiene rubber/zinc sulphide nanoparticles
keyword,[]
history,"['2018-06', '2018-03-05', '2017-10-24', '2018-02-23']"
abstract,"Abstract The present study critically investigates the evaluation of zinc sulphide nanoparticles (ZnS) as potential crystalline inclusion in styrene-butadiene rubber (SBR). The prepared nanocomposite was characterized by a Monsanto Rheometer, and the vulcanization was carried out to their respective cure time values. The X-ray diffraction reveals the decrease in the amorphous phase of composite with the addition of ZnS nanoparticles. The uniform morphology of SBR was changed into a non-uniform pattern in the presence of ZnS nanoparticles, and few agglomerations were visible at higher loading of fillers. The effective utilization of the surface of nanoparticles by SBR chains resulted in an enhancement in rheometric torque or viscosities and a reduction in optimum cure and scorch time. Thermal stability studied by thermogravimetry (TGA) showed a remarkable increase in the thermal resistance of composites, and the thermal stability increases with an increase in the concentration of ZnS. The reinforcing natures of ZnS in SBR matrix were evident from increased mechanical properties such as tensile and tear strength, modulus, compression set, hardness and heat build-up behaviours. Effective formation of conductive chains of ZnS nanoparticles at 10 phr loading results in a maximum value of electrical conductivity. The diffusion and transport mechanisms of petroleum fuels through the polymeric membranes were studied according to the concentration of nanoparticles, the effect of solvent and temperature. The mechanism of diffusion shows an anomalous trend. The activation energy of diffusion and permeation of composites was also calculated from the sorption analysis."
journal_title,Journal of Materials Science
article_title,Properties of microinjection-molded multi-walled carbon nanotubes-filled poly(lactic acid)/poly[(butylene succinate)-co-adipate] blend nanocomposites
keyword,[]
history,"['2018-06', '2018-03-08', '2017-12-29', '2018-03-01']"
abstract,"Abstract In this study, the morphological, thermal and electrical properties of microinjection-molded multi-walled carbon nanotubes (CNT)-filled poly(lactic acid) (PLA) and PLA/poly[(butylene succinate)-co-adipate] (PLA/PBSA) immiscible blends were studied systematically. The PLA/PBSA/CNT immiscible blends were prepared by melt blending of PLA, PBSA and CNT in a batch mixer. Four different types of compounding procedure were employed to investigate the influence of compounding sequence of various components on the electrical conductivity of subsequent micromoldings. Results  revealed that despite the compounding sequence, the electrical conductivity of PLA/PBSA/CNT microparts is invariably higher than that of CNT-filled mono-PLA counterparts and the selective localization of CNT in PBSA is thought to be the contributing factor. Furthermore, the prevailing high shearing conditions in microinjection molding (µIM) could lead to the coalescence of CNT-enriched PBSA domains, favoring the formation of conductive pathways in the melt flow direction, as confirmed by morphology observations. The crystallinity of PLA/PBSA immiscible blends is higher than that of mono-PLA system and a further increase in crystallinity after µIM suggested flow-induced crystallization. Moreover, thermal stability analysis indicated that the prevailing high shear rates in µIM might have a chain scission effect on PLA and PBSA."
journal_title,Journal of Materials Science
article_title,Integration of NiWO4 and Fe3O4 with graphitic carbon nitride to fabricate novel magnetically recoverable visible-light-driven photocatalysts
keyword,[]
history,"['2018-06', '2018-03-13', '2017-12-09', '2018-03-07']"
abstract,"Abstract Novel magnetically recoverable g-C3N4/Fe3O4/NiWO4 (gCN/M/NiWO4) nanocomposites, with superior visible-light photocatalytic performance, were successfully fabricated by a refluxing calcination method. These hybrid photocatalysts were characterized fairly in terms of the structure, composition, morphology, electronic, textural, thermal, and magnetic properties using XRD, EDX, SEM, TEM, HRTEM, FT-IR, UV–vis DRS, PL, N2 adsorption–desorption, TG, and VSM analyses. Also, the degradation intermediates were identified using gas chromatography–mass spectroscopy. These photocatalysts displayed excellent photocatalytic performance under visible light for degradations of RhB, MB, MO, fuchsine, and phenol pollutants, and they can be recycled by magnetic separation without major loss of activity. The highest photocatalytic efficiency was observed when the sample refluxed for 60 min and calcined at 450 °C for 3 h with 30 wt% NiWO4 content. Activity of this photocatalyst is greater than the pristine gCN by a factor of almost 12, 30, 52, 100, and 6 toward degradations of RhB, MB, MO, fuchsine, and phenol, respectively. Finally, the proposed mechanism for the superior performance of gCN/M/NiWO4 hybrid photocatalysts was discussed."
journal_title,Journal of Materials Science
article_title,Dissociation reaction of the 1/3$$ \left\langle {\bar{1}101} \right\rangle $$1¯101 edge dislocation in α-Al2O3
keyword,[]
history,"['2018-06', '2018-02-26', '2017-10-04', '2018-02-10']"
abstract,"Abstract It has been reported that dislocations with 1/3\( \left\langle {\bar{1}101} \right\rangle \) edge component of the Burgers vector are formed in {1\( \bar{1} \)04}/\( \left\langle {11\bar{2}0} \right\rangle \) low-angle grain boundaries of alumina (α-Al2O3). These dislocations dissociate into two partial dislocations with a stacking fault on the (0001) plane (Tochigi et al. in J Mater Sci 46:4428–4433, 2011). However, the dissociation reaction of these dislocations has not been determined so far. In this study, the structures of the dissociated dislocations and the (0001) stacking fault were investigated by transmission electron microscopy and theoretical calculations. It was revealed that the dissociated dislocations were generated from the 1/3\( \left\langle {\bar{1}101} \right\rangle \) perfect edge dislocation by the reaction of 1/3\( \left\langle {\bar{1}101} \right\rangle \) → 1/18\( \left\langle {\bar{4}223} \right\rangle \) + 1/18\( \left\langle {\bar{2}4\bar{2}3} \right\rangle \). Furthermore, electron energy loss spectroscopy analysis was performed to examine the atomic/electronic structure of the (0001) stacking fault. In the observed spectra, a chemical shift and intensity decrease were found at the oxygen K-edge. Theoretical spectrum analysis using first-principles calculations revealed that the characteristic features of the spectra are originated from the local atomic configurations of the (0001) stacking fault."
journal_title,Journal of Materials Science
article_title,Hierarchical three-dimensional NiMoO4-anchored rGO/Ni foam as advanced electrode material with improved supercapacitor performance
keyword,[]
history,"['2018-06', '2018-03-01', '2018-01-09', '2018-02-23']"
abstract,"Abstract Designing a novel, efficient and cost-effective nanocomposite with the advantage of robust structure and outstanding conductivity is highly promising for the electrode materials of high-performance supercapacitors. Herein, we designed and synthesized a hierarchical structured NiMoO4@rGO/NF via a facile and scalable approach by growing NiMoO4 nanowires onto the skeleton of reduced graphene oxide (rGO)/Ni foam (NF). The as-made NiMoO4@rGO/NF exhibits a superior electrochemical behavior owing to the coupling effect of homogeneous NiMoO4 nanowires and high conductivity of rGO, and it exhibits a superb capacitance value of 1877 F g−1 at 1 A g−1 and shows a ultralong life span with over 98% capacitance retention after 4000 cycles at 5 A g−1 in 2 M KOH electrolyte. Moreover, an asymmetric device employing NiMoO4@rGO/NF composite and activated carbon is assembled with an aqueous electrolyte, and it displays a maximum energy density of 40 Wh kg−1 at a specific power 218.2 W kg−1. Interestingly, the asymmetric device can remain 111.2% of its initial value even after 8000 charge/discharge cycles. These results demonstrate that the NiMoO4@rGO/NF binder-free electrode provides greatly enhanced electrochemical performance and shows promising application as an anode for energy storage."
journal_title,Journal of Materials Science
article_title,Self-sensing and mechanical performance of CNT/GNP/UHMWPE biocompatible nanocomposites
keyword,[]
history,"['2018-06', '2018-03-07', '2017-12-12', '2018-01-23']"
abstract,"Abstract Ultra-high molecular weight polyethylene (UHMWPE)-based conductive nanocomposites with reduced percolation and tunable piezoresistive behavior were prepared via solution mixing followed by compression molding using carbon nanotubes (CNT) and graphene nanoplatelets (GNP). The effect of varying wt% of GNP with fixed CNT content (0.1 wt%) on the mechanical, electrical, thermal and piezoresistive properties of UHMWPE nanocomposites was evaluated. The combination of CNT and GNP enhanced the dispersion in UHMWPE matrix and lowered the probability of CNT aggregation as GNP acted as a spacer to separate the entanglement of CNT with each other. This has allowed the formation of an effective conductive path between GNP and CNT in UHMWPE matrix. The thermal conductivity, degree of crystallinity and degradation temperature of the nanocomposites increased with increasing GNP content. The elastic modulus and yield strength of the nanocomposites were improved by 37% and 33%, respectively, for 0.1/0.3 wt% of CNT/GNP compared to neat UHMWPE. The electrical conductivity was measured using four-probe method, and the lowest electrical percolation threshold was achieved at 0.1/0.1 wt% of CNT/GNP forming a nearly two-dimensional conductive network (critical value, t = 1.20). Such improvements in mechanical and electrical properties are attributed to the synergistic effect of the two-dimensional GNP and one-dimensional CNT which limits aggregation of CNTs enabling a more efficient conductive network at low wt% of fillers. These hybrid nanocomposites exhibited strong piezoresistive response with sensitivity factor of 6.2, 15.93 and 557.44 in the linear elastic, inelastic I and inelastic II regimes, respectively, for 0.1/0.5 wt% of CNT/GNP. This study demonstrates the fabrication method and the self-sensing performance of CNT/GNP/UHMWPE nanocomposites with improved properties useful for orthopedic implants."
journal_title,Journal of Materials Science
article_title,pH-sensitive nanocarriers for Ganoderma applanatum polysaccharide release via host–guest interactions
keyword,[]
history,"['2018-06', '2018-03-07', '2017-12-29', '2018-01-29']"
abstract,"Abstract In this work, a new kind of smart nanocarriers that combine pH-responsive delivery and fluorescent markings was developed. The smart nanocarriers were based on the host–guest interaction between beta-cyclodextrin (β-CD) and rhodamine (R) which has closed-loop-hydrophobic and open-loop-hydrophilic structure in different pH. Small-size β-NaYF4:Yb,Er upconversion nanoparticles (UCNPs) with a diameter of 19 ± 2 nm, as a nanocarrier, were modified with β-CD to form water-soluble carrier. Rhodamine was conjugated with Ganoderma applanatum polysaccharide (GAP) through reductive amination reaction to form rhodamine polysaccharide complex (R-GAP). R-GAP was loaded on UCNPs in alkaline condition, and released detected by fluorescence resonance energy transfer (FRET) effect, based on the spectral overlap between UCNPs and R, under acidic conditions, besides the maximum release amounts of R-GAP reach up to 67.3% at pH 5.5. The in vitro cell cytotoxicity of R-GAP-loaded UCNPs to human colorectal cancer cell (SWWC1116) showed that R-GAP-CD-UCNPs have a better inhibition than the simple R-GAP. Confocal laser scanning microscopy (CLSM) was used to observe the localization of R-GAP in SWWC1116, and we found that R-GAP entered the cell plasm. Cell cycle analysis demonstrates that R-GAP can block SWWC1116 cells in the G2 phase. In summary, this study developed an effective strategy for pH-sensitive delivery system and fluorescent markings of polysaccharide drugs."
journal_title,Journal of Materials Science
article_title,Novel SiQDs–MoS2 heterostructures with increasing solar absorption for the photocatalytic degradation of malachite green
keyword,[]
history,"['2018-06', '2018-02-12', '2017-10-21', '2018-02-06']"
abstract,"Abstract 
Novel heterostructures based on silicon quantum dots and molybdenum disulfide nanosheets (SiQDs–MoS2) were synthesized by a hydrothermal method, in which the introduced SiQDs play a determining role in manipulating the morphology, phase and band structure of MoS2. The resultant SiQDs–MoS2 is uniform flowerlike 3D microspheres assembled from petallike 2D MoS2 nanosheets anchored with 0D SiQDs, possessing abundant active sites. Besides, the primary MoS2 nanosheets consist of both semiconductive 2H and metallic 1T phases accompanied with intralayer mesopores and expanded interlayer spacing, endowing the resulting architectures with effective electron transfer. Significantly, the as-synthesized SiQDs–MoS2 exhibits intense full solar-spectrum absorption, indicating efficient solar energy harvesting. First-principles calculations simulate similar increased spectral absorption of monolayer MoS2 adhered with a Si cluster, suggesting the existence of new energy states associated with the integration of SiQDs and MoS2 nanosheets as evidenced by photoluminescence (PL) spectral analysis. As expected, the current SiQDs–MoS2 heterostructures demonstrate substantial photocatalytic activity even under visible and near-infrared (NIR) light on degradation of malachite green (MG). The type II electronic structure of SiQDs–MoS2 was proposed, enabling sufficient photogenerated electrons and holes for the photocatalytic reactions. This study may establish a new frontier on the rational design and feasible development of the hybrid structures with the desirable morphologies, phase compositions and band structures for the catalysis and beyond."
journal_title,Journal of Materials Science
article_title,Synthesis of bactericidal polymer coatings by sequential plasma-induced polymerization of 4-vinyl pyridine and gas-phase quaternization of poly-4-vinyl pyridine
keyword,[]
history,"['2018-06', '2018-03-12', '2017-10-24', '2018-02-27']"
abstract,"Abstract Plasma-based technology is an alternative to produce universal polymer coatings with the appropriate requirements of robustness and stability for antibacterial applications. Here, we proposed a sequential two-step alternative to synthesize antibacterial polymer coatings. A non-isothermal plasma reactor, operated at atmospheric pressure (Patm) and room temperature (Troom), was used to induce free radical polymerization of 4-vinyl pyridine (4VP) on high-density polyethylene (PE). In a subsequent step, the poly-4VP (P4VP) films were treated with a bromoethane/He gas stream to produce quaternized P4VP (P4VPQ) films. Chemical structure of polymer films was validated by infrared and UV–visible spectroscopy, and morphology was evaluated by optical and atomic force microscopy; scanning electron microscopy was used to determine films thickness, which was then used to estimate the surface charge density. The bactericidal capacity was determined with a standard test by using Escherichia coli. Both types of films had an estimated charge density in the order of 1016 positive charges per cm2; P4VP films removed about 95–99% of bacteria, whereas 4PVPQ films eliminated 100%. The methodology proposed for the synthesis of antibacterial polymer coatings is simpler, faster, and more environmentally friendly than other plasma-based methods; operation at Troom and Patm may also have a significant effect on the economics and the ease of implementation of the process at commercial scale. The suggested approach may facilitate the development of new universal coatings, and operating plasma conditions could be extrapolated for engineering antibacterial coatings in industrial areas where bacterial attachment is of concern."
journal_title,Journal of Materials Science
article_title,Effects of TiO2 nanoparticle size and concentration on dielectric properties of polypropylene nanocomposites
keyword,[]
history,"['2018-06', '2018-03-19', '2017-11-14', '2018-03-14']"
abstract,"Abstract Polymer nanocomposites are promising materials for dielectric waveguides in high-data-rate communications, where extremely low loss is required. In this paper, we study the effect of titania (TiO2) nanoparticle size (30–300 nm) and concentration on the effective permittivity (εeff) and dielectric loss (tan δ) of polypropylene (PP) nanocomposites in two different frequency ranges: 100 Hz–300 kHz and 140 GHz–220 GHz. To aid the dispersion of TiO2 in the PP matrix, polypropylene-graft-maleic anhydride (PP-g-MA) is added. Using this approach, an εeff of 6.84 with tan δ of 0.0049 at 220 GHz is achieved in a 21.5 vol% 100 nm TiO2/PP nanocomposite. We find that εeff is insensitive to nanoparticle size in both frequency ranges while tan δ appears to depend on the filler size at the low frequency range. By using complex permittivity in Lichtenecker’s model, we are able to separate the loss contribution of the polymer matrix from that of the TiO2 nanoparticles. Our results provide insight into the choice of nanoparticle size and the effects of compatibilizer on millimeter-wave dielectric properties."
journal_title,Journal of Materials Science
article_title,Peapod-like one-dimensional (1D) CoP hollow nanorods embedded into graphene networks as an anode material for lithium-ion batteries
keyword,[]
history,"['2018-06', '2018-02-23', '2017-12-27', '2018-02-12']"
abstract,"Abstract In order to improve the conductivity and electrochemical performance, a novel complex peapod-like one-dimensional (1D) CoP hollow nanorod/graphene composite (CoP HR@rGO) was designed and fabricated via a simple strategy. The key of this unique structure is that it inherits the benefits from both 1D and hollow structure. Combing the advantages of 1D and hollow structure, the peapod-like CoP HR@rGO not only provides enough voids to accommodate the volume expansion during lithiation/delithiation processes, but also offers accessible channels for rapid transport and diffusion of lithium ions and electrons. In addition, the porous graphene networks wrapped on the CoP surface could provide 3D conductive networks to enhance electronic conductivity. More importantly, these ultrasmall CoP nanoparticles could provide sufficient electrochemical active sites and mass densities to improve the electrochemical performance. Thus, when evaluated as an anode for LIBs, the active material exhibits a superior specific capacity of 714.7 mAh g−1 after 100 cycles at the current density of 0.1 A g−1. Moreover, the excellent rate capability of peapod-like CoP HR@rGO electrode indicates that the as-prepared material has huge potential to be investigated and applied as a promising anode material for lithium-ion storage system with improved electrochemical performances."
journal_title,Journal of Materials Science
article_title,Graphdiyne-hybridized N-doped TiO2 nanosheets for enhanced visible light photocatalytic activity
keyword,[]
history,"['2018-06', '2018-03-14', '2017-11-07', '2018-03-07']"
abstract,"Abstract In this study, graphdiyne (GD)-hybridized nitrogen-doped TiO2 nanosheets with exposed (001) facets (GD-NTNS) have been prepared via a hydrothermal reaction and utilized as photocatalyst for the photodegradation of rhodamine B (RhB) under visible light illumination. The resultant GD-NTNS composites exhibit superior visible light photocatalytic activity than that of the bare TiO2 nanosheets (TNS) and nitrogen-doped TiO2 nanosheets (NTNS). The enhanced photoactivity can be attributed to the synergistic effects of GD and nitrogen doping with efficient electron transfer and strong visible light absorption. It has been revealed that ·O2− and h+ are the major species for the enhanced photoactivity under visible light. Our work will facilitate the potential for future design of hybrid materials for practical applications beyond photocatalysts."
journal_title,Journal of Materials Science
article_title,"Synthesis and sintering of (Mg, Co, Ni, Cu, Zn)O entropy-stabilized oxides obtained by wet chemical methods"
keyword,[]
history,"['2018-06', '2018-02-28', '2017-12-01', '2018-02-22']"
abstract,"Abstract 
Entropy-stabilized oxides represent a novel family of advanced ceramic materials with attractive functional properties. In this work, entropy-stabilized oxides, in the system (Mg, Co, Ni, Cu, Zn)O, were produced by co-precipitation and hydrothermal synthesis. Although TG/DTA and XRD analyses of as-synthetized powders point out complex thermal evolution, in both cases the desired single-phase rock salt solid solution was obtained after a proper thermal treatment. The dilatometric analysis points out the excellent sinterability of the obtained powders, which were successfully consolidated for the first time reaching nearly full density (~ 97%) at relatively low temperature (1050 °C)."
journal_title,Journal of Materials Science
article_title,Effect of flake powder metallurgy on thermal conductivity of graphite flakes reinforced aluminum matrix composites
keyword,[]
history,"['2018-06', '2018-02-20', '2017-11-02', '2018-02-12']"
abstract,"Abstract The optimization of metal–matrix composite material is linked firstly with the intrinsic properties of the matrix and the reinforcement used and secondly with the reinforcement–matrix interfacial zone and the distribution/orientation of the reinforcement inside the metal–matrix. Flake powder metallurgy was used to fabricate graphite flake reinforced aluminum matrix (Al/GF) composites fabricated by vacuum hot pressing. Two types of aluminum powders morphology were used: spherical (AlS) and flake (AlF) powders. A higher thermal conductivity in the in-plane direction of the graphite flakes was obtained for Al/GF composite materials fabricated with aluminum flake powder. In addition to a better orientation of the GF in the flake aluminum matrix, a 3D puckered surface and plane surface are formed at the Al/GF interface in, respectively, AlS/GF and AlF/GF composite materials. Due to the morphology incompatibility between the graphite flakes and the spherical powder, the damaged inner structure of GF contributes to a limited enhancement of thermal conductivity in AlS/GF composite materials."
journal_title,Journal of Materials Science
article_title,Effect of grain boundary angle on {332}<113> twinning transfer behavior in β-type Ti–15Mo–5Zr alloy
keyword,[]
history,"['2018-06', '2018-03-05', '2017-12-06', '2018-02-22']"
abstract,"Abstract The {332}<113> twin–twin and twin–dislocation pairs at various grain boundaries were systematically examined by using electron backscattered diffraction technique in a slightly deformed β-type Ti–15Mo–5Zr alloy. The effect of grain boundary angle on twinning transfer behavior in neighboring grain was quantitatively analyzed in terms of strain accommodation combined macroscopic Schmid law. The twinning transfer occurred readily at the low angle grain boundaries without significant local stress concentration and formed a twin–twin pair dominated by applied stress, i.e., macroscopic Schmid law. At the high angle grain boundaries, it often resulted in a twin–twin pair with non-Schmid factor twinning variant or a twin–dislocation pair with geometrically necessary dislocations at the boundary area dominated by the strain accommodation. The activation of non-Schmid factor twinning variant and slip system in neighboring grain was due to their high accommodative capacity while releasing the local internal stress concentration, which was caused by the twinning transfer at high angle grain boundaries."
journal_title,Journal of Materials Science
article_title,"A comprehensive evaluation of heavy metals removal from battery industry wastewaters by applying bio-residue, mineral and commercial adsorbent materials"
keyword,[]
history,"['2018-06', '2018-02-26', '2017-12-10', '2018-02-14']"
abstract,"Abstract We present a feasibility study of different adsorbent materials, namely residual fish scales biosorbent (FS), mineral dolomite (DL) and commercial resin (CR) in the heavy metals removal in multicomponent solution based on the properties of a real effluent from automotive battery recycling industry. Considering the effluent complex characteristics, the materials were assessed aiming to provide not only the heavy metals removal, but also the effluent neutralization and lower sludge generation. For this, all the studied materials were physicochemically and morphologically characterized with the aim of understanding the mechanisms involved in the process. Further, the elemental compositions of the solid and liquid phases generated from each treatment process were assessed by X-ray fluorescence spectrometry. The effluent presented highly acidic characteristics and heavy metals above the legislated limits for discharge (Fe, Zn and Pb). Each adsorbent material followed different mechanisms which led to dissimilar removal and neutralization capacities. The CR showed remarkable heavy metals removal capacity governed by an ion exchange mechanism; conversely, it did not show a neutralization effect. In contrast, FS and DL presented lower removal capacities by complex simultaneous phenomena (ion exchange, precipitation and/or complexation), but a great neutralization potential related to leaching of alkaline constituents. When sludge generation is considered as a key factor, mitigation and enhancement of treated effluent quality could alternatively be addressed by employing the materials in hybrid processes. Hence, the associated use of such materials could be viable yet very challenging for both neutralization and removal of heavy metals from the battery effluent."
journal_title,Journal of Materials Science
article_title,Effects of macromolecular diol containing different carbamate content on the micro-phase separation of waterborne polyurethane
keyword,[]
history,"['2018-06', '2018-03-07', '2017-10-03', '2017-12-08']"
abstract,"Abstract Macromolecular diols with different carbamate content were synthesized by alterative n(PPG)/n(HMDI) ratio. The molecular weights of these macromolecular diols were measured by GPC. In addition, based on these macromolecular diols, waterborne polyurethanes (WPU) were prepared by the pre-polymerization method. The structure and molecular weight of the WPU were characterized by 1HNMR, FTIR and GPC, respectively. When the mole ratio of n(PPG) and n(HMDI) decreased, the particle distribution of WPU became broader and the average particle size became larger. Furthermore, the hydrogen bonding interaction in WPU films was analyzed by the deconvolution of amino, carbonyl band and ether band of FTIR spectra. The results showed that when introduced carbamate into the macromolecular diol, the ordered hydrogen bonding interaction in hard segments increased and the interaction between carbamate and ether occurred. The increased hydrogen bonding interaction leads to the higher micro-phase separation confirmed by AFM and DSC test. Carbamate in soft segments can significantly increase the modulus of WPU in the whole temperature range. Meanwhile, the tensile strength and the elongation at break were obviously increased when introduced carbamate into the soft segments because of the crosslinked structure and micro-phase separation morphology. The tensile strength of sample WPU1 caught 28.28 MPa which was 2.37 times and the elongation at break caught 911% which was 2.18 times than that of WPU0."
journal_title,Journal of Materials Science
article_title,"An in situ silicone–silicone interpenetrating polymer network (IPN) with higher mechanical property, higher hydrophilicity, and lower protein adsorption"
keyword,[]
history,"['2018-06', '2018-03-14', '2017-10-24', '2018-02-13']"
abstract,"Abstract As medical materials, silicone polymers are poor in mechanical properties and in resistance to fouling for its non-specific adsorption of proteins, cells, etc. This paper introduces a new type of silicone–silicone interpenetrating polymer network (IPN) composing of two curing reactions: One was radical coupled reaction, and the other was ring opening of epoxy by amino groups. The IPN were characterized by Fourier transform IR spectroscopy (FT-IR), dynamic mechanical analysis, cross section scanning electron microscope, and mechanical property. IPN structure could be formed in a co-continuous phase, while the sea–island phase could be also found up to amino content, and then tear strength and elongation at break were obviously increased. ATR FT-IR, X-ray photoelectron spectroscopy, and static water contact angles confirmed that IPN surfaces showed the hydrophilicity dependent on surface amino-epoxy component. The static water contact angles were greatly decreased to the lowest 69.3°. Both qualitative and quantitative bovine serum albumin (BSA) adsorption assay confirmed that, compared with pure polydimethylsiloxane, BSA adsorption on IPN substrates were greatly decreased, with the most 85%."
journal_title,Journal of Materials Science
article_title,A review of the preparation and application of magnetic nanoparticles for surface-enhanced Raman scattering
keyword,[]
history,"['2018-06', '2018-02-06', '2017-09-11', '2018-01-31']"
abstract,"Abstract In recent years, the unique properties of magnetic functional nanomaterials have received considerable attentions and show promising applications in separation, detection, diagnosis, catalysis, environment remediation and so on. Specifically, introducing magnetic nanomaterials (MNPs) into traditional sensing techniques greatly simplifies detection operation and improves sensing performances, which makes magnetic nanomaterial-based sensing techniques become a hot research topic. Compared with other sensing techniques such as chromatography, fluorescence, mass spectrum and electrochemistry, surface-enhanced Raman scattering (SERS) displays unique properties of high-sensitivity, fingerprint specificity and nondestructive detection. The introduction of MNPs in SERS has proven to be an efficient way to resolve several critical challenges in practical SERS analysis leading to highly efficient target separation and enrichment, high-sensitive detection and precise outcomes analysis. This makes the MNPs involved SERS analysis a powerful technique with very appealing and promising application in various branches of analytical science. In this review, we first briefly introduced the preparation, encapsulation and surface modification of magnetic nanoparticles, assembly of magnetic nanoparticle–plasmonic substrates and then discussed their applications in SERS analysis, including biomedical application, environmental analysis, food safety and chemical reaction monitoring. Finally, we presented some outlooks on further developments of magnetic nanoparticles in SERS applications."
journal_title,Journal of Materials Science
article_title,Oxide-based RRAM materials for neuromorphic computing
keyword,[]
history,"['2018-06', '2018-02-20', '2017-10-27', '2018-02-10']"
abstract,"Abstract In this review, a comprehensive survey of different oxide-based resistive random-access memories (RRAMs) for neuromorphic computing is provided. We begin with the history of RRAM development, physical mechanism of conduction, fundamental of neuromorphic computing, followed by a review of a variety of RRAM oxide materials (PCMO, HfOx, TaOx, TiOx, NiOx, etc.) with a focus on their application for neuromorphic computing. Our goal is to give a broad review of oxide-based RRAM materials that can be adapted to neuromorphic computing and to help further ongoing research in the field."
journal_title,Journal of Materials Science
article_title,Synthesis of Rh nanoparticles in alcohols: magnetic and electrocatalytic properties
keyword,[]
history,"['2018-06', '2018-03-19', '2017-12-21', '2018-03-12']"
abstract,"Abstract The synthesis of Rh nanoparticles has been performed through an organometallic approach starting from the tris(allyl) rhodium complex, Rh(η3-C3H5)3, as precursor and using an alcohol as both a solvent and a stabilizer, under mild reaction conditions (room temperature; 3 bar H2). The influence of the alcohol used, among methanol, propanol or heptanol, on the morphological and structural characteristics as well as on the magnetic and electrocatalytic properties of the obtained Rh nanoparticles has been investigated. Assemblies of Rh nanoparticles of various sizes have been observed depending on the alkyl chain length of the alcohol used. A noticeable effect of the nanostructured character of these Rh nanoparticles is the appearance of a ferromagnetic ordering at room temperature due to a modified electronic structure. Magnetic moments per atom were determined as follows: 0.099, 0.073 and 0.036 µB for methanol, heptanol and propanol, respectively. The electrochemical evaluation of these Rh nanoparticles on the oxygen reduction reaction (ORR) showed that the electroactivity depends on the chain length of the alcohol; thus, Rh-heptanol system displayed the highest electroactivity for ORR."
journal_title,Journal of Materials Science
article_title,Soy protein-treated nanofillers creating adaptive interfaces in nanocomposites with effectively improved conductivity
keyword,[]
history,"['2018-06', '2018-02-27', '2018-01-21', '2018-02-06']"
abstract,"Abstract A study on effectively making conductive nanocomposites with adaptable interfaces formed between soy protein-treated nanofillers and polymer matrices with different structures is presented. Although soy protein, an abundant biomaterial with various functional groups, is basically considered as a hydrophilic material, this study demonstrated that it could be used as a novel surfactant for treating nanofillers in non-aqueous environment and the treated nanofillers were successfully incorporated into hydrophobic polymers. Confocal microscopy results showed that soy protein well interacted with CNFs, and well-dispersed soy protein-treated CNFs (s-CNFs) within both thermoplastic (polycarbonate) and thermoset (epoxy) conductive nanocomposites were observed in the optical microscopy and scanning electron microscopy images. The significant enhancements in the electrical conductivities were confirmed by the DC and AC conductivity testing for the resulting nanocomposites at low s-CNF loadings. In specific, an increase of 6 orders and 5 orders for the DC conductivities of polycarbonate and epoxy nanocomposites, respectively, is achieved at only 0.5 wt% loading of s-CNFs. The present work provides a green and adaptive nanofiller treatment method for fabrication of conductive nanocomposites."
journal_title,Journal of Materials Science
article_title,A semitopological mean-field model of discontinuous dynamic recrystallization
keyword,[]
history,"['2018-06', '2018-02-26', '2017-11-10', '2018-02-12']"
abstract,"Abstract Some mean-field models are currently available for discontinuous dynamic recrystallization (DDRX). They offer an affordable way to predict the variation of averages altered by DDRX as flow stress, grain size and recrystallized fraction. They predict also a grain-size distribution, but it appears unrealistic, at least if a deterministic equation governs the migration of grain boundaries. The present paper exposes an extension to mean-field models which introduces some topological and stochastic features in the migration equation. This extension aims to bridge the gap between mean- and full-field models. It allows predicting realistic distributions of grain size by keeping the simplicity of mean-field approaches. The results obtained are consistent with experimental data on an 18% Cr–11% Ni stainless steel."
journal_title,Journal of Materials Science
article_title,Characterization of mean grain size of interstitial-free steel based on laser ultrasonic
keyword,[]
history,"['2018-06', '2018-03-05', '2017-09-17', '2018-01-13']"
abstract,"Abstract This paper investigated a novel mean grain size characterization method via laser ultrasonic. The IF steel samples with different grain sizes were conducted with different heat treatments, respectively, and each sample was observed by EBSD and tested by laser ultrasonic. The laser ultrasonic signal was decomposed by wavelet packet transform and sorted using correlation analysis. Then the optimal components were selected to reconstruct the new signal and obtain the energy attenuation coefficient. Finally, the novel mean grain size prediction model was established according to the Rayleigh scattering and absorption attenuation. These results show that the maximum prediction error could be reduced to 5.74% by our new method, which is more precise than the traditionally used methods. Our new method improves the mean grain size evaluation to a more precise level. In addition, compared with the conventional mean grain size acquisition methods, the laser ultrasonic method has the advantages of non-contact and high efficiency, and it is a nondestructive testing method which could be used in online testing."
journal_title,Journal of Materials Science
article_title,Fabrication of biosensor based on core–shell and large void structured magnetic mesoporous microspheres immobilized with laccase for dopamine detection
keyword,[]
history,"['2018-06', '2018-03-01', '2018-01-11', '2018-02-22']"
abstract,"Abstract The Fe3O4@SiO2@vmSiO2 microspheres with ordered mesochannels and large inter-lamellar void were successfully prepared through stepwise solution-phase interface deposition. Fe3O4 nanoparticles were coated with SiO2 via the Stöber method, and they were further coated with mesoporous SiO2 using aggregation of cetyltrimethylammonium chloride as template to prepare Fe3O4@SiO2@vmSiO2. The Fe3O4@SiO2@vmSiO2 microspheres show a well-defined core–shell structure with high magnetization (~ 30.9 emu g−1), ordered mesochannel (~ 6.8 nm in diameter), and inter-lamellar void (~ 30 nm). Laccase (LAC) was immobilized on a modified Fe3O4@SiO2@vmSiO2 microsphere by covalent attachment and stabilized onto the glassy carbon electrode (GCE) surface (Fe3O4@SiO2@vmSiO2-LAC/GCE) in the fabrication of novel immobilized LAC biosensors for monitoring dopamine (DA). The electrochemical properties of the biosensor were investigated with electrochemical impedance spectroscopy and cyclic voltammetry. The immobilized LAC biosensor possesses good DA electrocatalytic activity with a linear range of 1.5–75 μmol L−1 and low detection limit of 0.177 μmol L−1 and shows strong anti-interference ability and excellent selective determination of DA that coexists with ascorbic acid. The immobilized LAC biosensor was also used to detect DA in pharmaceutical injection. The recoveries of 98.7–100.5% were obtained for the samples, which illustrate great potential for practical application."
journal_title,Journal of Materials Science
article_title,Significant enhancement of power conversion efficiency of dye-sensitized solar cells by the incorporation of TiO2–Au nanocomposite in TiO2 photoanode
keyword,[]
history,"['2018-06', '2018-03-05', '2017-09-20', '2018-02-19']"
abstract,"Abstract In this report, the effect of incorporation of hydrothermally prepared TiO2–Au nanocomposites in the photoanode of dye-sensitized solar cells (DSSCs), prepared from commercially available TiO2 nanoparticles, has been investigated. Electrophoretic deposition technique has been utilized for nanocomposite-doped photoanode preparation. The formation of hydrothermally prepared TiO2–Au nanocomposites has been confirmed by the X-ray diffraction (XRD), high-resolution transmission electron microscopy (HRTEM), UV–Vis spectroscopy. The HRTEM images establish that the particle size of Au nanoparticles dispersed in TiO2 matrix varies from 2 to 45 nm. TiO2–Au photoelectrode has been characterized by XRD, field emission scanning electron microscopy, Raman spectroscopy and photoluminescence spectroscopy in order to confirm the successful preparation of plasmonic photoanodes. Measurement of current–voltage characteristics of the plasmonic dye-sensitized solar cells under the solar simulator illumination (100 mW/cm2, AM 1.5) shows enormous enhancement of power conversion efficiency. The PCE of plasmonic DSSCs is 10.1%, which is 134% greater than the DSSCs with pristine TiO2 photoanode of the same thickness. Electro-impedance spectroscopy reveals that the back electron transfer from the conduction band of Au–TiO2 photoanode to either dye or electrolyte has been significantly suppressed in the DSSC with plasmonic photoelectrode."
journal_title,Journal of Materials Science
article_title,Preparation of core–shell structured Au@SiO2 nanocomposite catalyst with Au core size below 2 nm without high-temperature calcination procedure
keyword,[]
history,"['2018-06', '2018-03-08', '2017-10-19', '2018-01-29']"
abstract,"Abstract Preparing dispersed cores–shell structured Au@SiO2 nanocomposites with an active Au core size below 2 nm that exhibit excellent catalytic performance still remains a major challenge in catalytic synthesis. In this work, we report a novel preparation method for a one-pot system fabrication of an ultrafine core–shell structured Au@SiO2 intestine-shaped nanocomposite. The preparation is used to fabricate catalysts with an Au core size of about 1.4 nm and requires neither prefabricated Au cores nor special reducing agents. Upon extraction of cetyltrimethylammonium bromide, abundant pores with a size of around 1.9 nm are formed in the silica shell. During the catalytic reduction of 4-nitrophenol to 4-aminophenolate, the catalyst unambiguously exhibits superior catalytic activity. Despite having a low 1.7% Au content in catalyst, the nanocomposites achieve an activity of ʊ = 19.1 × 10−3 s−1 mg−1. This is due to the fact that the polyvinylpyrrolidone coating is transformed into discrete particles in an alkaline solution, which exposes large active areas on the Au."
journal_title,Journal of Materials Science
article_title,Progress in Ni-based anode materials for direct hydrocarbon solid oxide fuel cells
keyword,[]
history,"['2018-06', '2018-03-12', '2017-12-05', '2018-03-05']"
abstract,"Abstract Ni-based anode materials of solid oxide fuel cells (SOFCs) are susceptible to carbon deposition and deactivation in direct hydrocarbon fuels, greatly limiting the commercialization. Extensive studies on finding new alternative anode materials have been developed; however, new problems such as low electrochemical performance and complex cell preparation process destroyed the further research passion of Ni-free anode materials. Considering the superior catalytic activity and mature technology of Ni-based anode materials, a large number of recent research results proved that it is still important and promising to solve the carbon coking of Ni-based anode materials. In this review, progress in four typically promising Ni-based anode materials free from carbon coking has been summarized, including the noble metals, ceria, Ba-containing oxides and titanium oxide. Correspondingly, the mechanisms that improve the carbon tolerance of Ni-based modified SOFCs anodes are clearly concluded, providing the materials and theoretical basis for the use of direct hydrocarbon SOFCs as early as possible."
journal_title,Journal of Materials Science
article_title,"Local strain redistribution in a coarse-grained nickel-based superalloy subjected to shot-peening, fatigue or thermal exposure investigated using synchrotron X-ray Laue microdiffraction"
keyword,[]
history,"['2018-06', '2018-02-21', '2017-10-20', '2018-02-13']"
abstract,"Abstract 
The Laue microdiffraction technique was used to investigate the strain field caused by the shot-peening operation and its redistribution after thermal hold or fatigue in a model nickel-based superalloy with an average grain size of \(40\,{\upmu }\hbox {m}\). Micrometer and millimeter size mappings showed that the plastic deformation introduced by shot-peening in the whole sample partially relaxes after a thermal exposure at \(450^{\circ }\hbox {C}\) and was fully redistributed by the fatigue of the material, except in the hardened layer close to the sample edge. Diffraction patterns permitted to measure separately the strains related to the average alloy (\(\gamma +\gamma ^{\prime }\)) and to the \(\gamma ^{\prime }\) phase. No difference was observed between the two deviatoric strain fields. Even if there were small stresses in the inner part of the samples, the sensitivity of the Laue microdiffraction method was large enough to quantitatively characterize the crystal misorientations and the deviatoric strain redistributions. Useful data were provided not only at the grain scale but also at the mesoscopic scale, thus bridging the gap between the \(\hbox {sin}^{2}\psi \) and Ortner’s methods used to determine residual stresses, respectively, in fine and single-grain microstructures. The obtained results are also of first interest for a quantitative comparison with HR-EBSD measurements in the scanning electron microscope. Energy coupled measurements with an energy-dispersive point detector were also performed to determine the full elastic strain tensors associated with the \(\gamma \) and \(\gamma ^{\prime }\) phases. We demonstrated that, for Ni-based superalloys, the accuracy on strains and stresses was, respectively, of the order of \(1\times 10^{-3}\) and 250 MPa for the diagonal components of tensors. The measurements suffered from the 150 eV resolution of the detector which made it difficult to the separate the energies of the \(\gamma \) and \(\gamma ^{\prime }\) phases. Owing to large crystal misorientations, the microdiffraction technique was not able to determine elastic strains and hardening in the highly deformed layer, where a large amount of plastic strain and a number of defects were accumulated. Some improvements are proposed to overcome these difficulties."
journal_title,Journal of Materials Science
article_title,A review of non-destructive techniques used for mechanical damage assessment in polymer composites
keyword,[]
history,"['2018-06', '2018-01-24', '2017-09-29', '2018-01-16']"
abstract,"Abstract Polymer composite materials are being increasingly used in primary load-bearing structures in several advanced industrial fields such as aerospace vessels, railway wagons and mega-scaled wind turbines where detection of subcritical damage initiation can significantly reduce safety issues and maintenance costs. It is therefore crucial to inspect these composite structures in order to assess their structural health and to ensure their integrity. Non-destructive testing techniques (NDT) are used for this purpose, making it possible to monitor mechanical damage of composite materials under in situ or ex situ service conditions. This paper reviews the capabilities of the most common NDT techniques used to inspect the integrity of composite materials. Each technique has a detection potential and cannot allow a full diagnosis of the mechanical damage state of the material. Thus, depending on the occurring damage mechanism and the conditions of use, one technique will be preferred over another, or several techniques should be combined to improve the diagnosis of the damage state of the structures."
journal_title,Journal of Materials Science
article_title,Experimental investigation of the isothermal section of the Mg–Ni–Y system with LPSO phases at 400 °C
keyword,[]
history,"['2018-06', '2018-03-05', '2017-10-04', '2018-02-28']"
abstract,"Abstract 
Phase equilibria of the Mg–Ni–Y system were experimentally investigated through X-ray diffraction, electron probe microanalysis and transmission electron microscope measurements on thirty alloys. The isothermal section of the Mg–Ni–Y system at 400 °C was constructed according to the present experimental results. At 400 °C, thirteen ternary intermetallics including three long-period stacking ordered phases: τ1 (14H), τ2 (18R) and τ3 (10H), were observed. Their homogeneity ranges as well as the phase relationship were determined experimentally. The ternary phase of τ9 (Mg3Ni3Y4) was observed for the first time in the present work."
journal_title,Journal of Materials Science
article_title,Change in elastic properties of eutectic alloys under conditions of superplastic deformation
keyword,[]
history,"['2018-06', '2018-03-05', '2017-09-05', '2018-02-22']"
abstract,"Abstract In this study, experimental data have been obtained which reveal taking place of complex physical processes under conditions of the structural superplasticity not only in the grain boundary, as it is commonly believed, but also in the grain body. It was established for the first time that superplastic deformation of the eutectic alloys is accompanied by significant changes in their Young’s moduli. It was demonstrated that under superplastic deformation the observed changes of the elastic properties of the eutectic Sn–38wt%Pb alloy under study are caused mainly by the decomposition of supersaturated solid solutions on the basis of the alloy components and the relaxation of internal stresses. It was also found that the viscous dislocation–diffusion non-conservative flow is actively developing in the eutectic alloys under conditions of superplasticity, in contrast to the existing ideas about grain boundary sliding as the main mechanism of the matter transport. The experimental results obtained are important for the deeper understanding of the physical nature of the structural superplasticity effect."
journal_title,Journal of Materials Science
article_title,Effect of annealing on microstructure and thermoelectric properties of hot-extruded Bi–Sb–Te bulk materials
keyword,[]
history,"['2018-06', '2018-03-12', '2017-12-23', '2018-03-07']"
abstract,"Abstract The effect of annealing on the microstructure, thermoelectric properties and hardness of the hot-extruded Bi–Sb–Te materials has been investigated systematically to optimize their thermoelectric and mechanical properties. The mechanically alloyed powder was consolidated by hot extrusion at either 340 or 400 °C, followed by annealing in a temperature range of 260–400 °C. The microstructure of the annealed samples contained submicron grains with preferred (001) texture. As annealing temperature increased, the small-angle grain boundaries (SAGBs) increased because the increased amount of Te-rich and Sb-rich phases inhibits the movements of dislocations and SAGBs. The submicron microstructure led to a low thermal conductivity, for example, ~ 0.9 W/mK after annealing at TA ≥ 380 °C. The Seebeck coefficient highly depended on carrier mobility in addition to carrier concentration. For the extruded samples prepared at a lower extrusion temperature of 340 °C, the mobility increased significantly after annealing, resulting in great enhancements in the Seebeck coefficient and electrical conductivity. A peak ZT value of 0.94 and high hardness were simultaneously obtained under the conditions of hot extrusion at 340 °C and annealing at 380 °C. It seems that the combination of low-temperature extrusion and high-temperature annealing is an effective route to prepare high-performance Bi2Te3-based materials."
journal_title,Journal of Materials Science
article_title,Novel metal–ceramic composite microstructures produced through the partial reduction of CoTiO3
keyword,[]
history,"['2018-06', '2018-02-23', '2017-11-22', '2018-02-14']"
abstract,"Abstract Metal–ceramic composites exhibit desirable combinations of materials properties, but are limited by the complexity of processing, particularly for metal–ceramic nanocomposites. The in situ partial reduction technique is a simple processing method that can be used to produce tailorable metal–ceramic composite microstructures. In this work, in situ partial reduction was utilized to generate novel Co–Ti x O y  composites, including nanocomposites, through the reduction of CoTiO3. By modifying the temperature (800–1400 °C) and time (1–8 h) of reduction, composites with varying cobalt particle size and cobalt grain size were fabricated. Differences in the cobalt crystal structure and nature of the titanium oxide phase were also observed. The lowest-temperature heat treatments resulted in metal–ceramic nanocomposites. The Co–Ti x O y  composites were characterized through scanning electron microscopy, electron backscatter diffraction, transmission electron microscopy, and X-ray diffraction. The effect of processing variables on the properties of the composites was evaluated through nanoindentation of the embedded cobalt particles, and it was found that cobalt particle hardness is strongly correlated with grain size. The many useful properties of cobalt and titanium oxide, in conjunction with the range of controllable microstructures, demonstrate that the in situ partial reduction technique has excellent potential for metal–ceramic composite production."
journal_title,Journal of Materials Science
article_title,Strength of ceramic–metal joints measured in planar impact experiments
keyword,[]
history,"['2018-06', '2018-02-20', '2017-09-05', '2018-02-15']"
abstract,"Abstract SPS-processed alumina and reaction-bonded boron carbide ceramic composite (RBBC) were joined with Al10SiMg alloy by spark plasma sintering and tested in a series of planar impact experiments designed to measure dynamic tensile (spall) strength of the joints. The results of the impact testing, together with postmortem inspection of the fractured samples, confirmed the applicability of this approach for testing joint strength. The measurements show that in the case of an RBBC/metal joint, the dynamic tensile strength of the joint exceeds that of the ceramic part, and that fracture of the shock-loaded ceramic–metal pair occurred in the ceramic portion. The dynamic tensile strength of the interface between alumina and Al10SiMg alloy virtually coincides with that of the metal part, with the fracture occurring exactly at the interface. The coincidence may be explained based on the recently published results of atomistic calculations of the structure of an alumina–aluminum interface."
journal_title,Journal of Materials Science
article_title,"Effect of rolling temperature on the microstructure, texture, and magnetic properties of strip-cast grain-oriented 3% Si steel"
keyword,[]
history,"['2018-06', '2018-03-05', '2017-09-23', '2018-02-28']"
abstract,"Abstract The effect of rolling temperature on the evolution of microstructure, texture, and magnetic properties of ultra-low-carbon grain-oriented silicon steel was studied in strip-casting process. Dynamic strain-aging (DSA) behavior was observed during warm rolling in the temperature range of ~ 200 to 400 °C based on the fact that majority of the inhibitor elements remained in solution during the strip-casting process. Considering the initial coarse grains with strong {100} fiber prior to rolling, the cold-rolled specimen exhibited pronounced α-fiber and weak γ-fiber texture. However, intense shear bands and high stored energy regardless of the orientation were obtained in the warm-rolled specimens at the DSA temperature, accompanied by weak α-fiber and strong γ-fiber texture. While homogenous microstructure with lower stored energy was observed in the case of high temperature, the differences in shear bands and stored energy governed by the rolling temperature were strongly related to the extent of DSA effect, which is attributed to distinct characteristic of rolling and recrystallization texture. After recrystallization annealing, fine-grained homogeneous microstructure with strong Goss and γ-fiber texture was obtained at the DSA temperature, while relatively random texture with much more α-fiber and θ-fiber components was observed in the case of high temperature. The microstructure and texture of primary annealed sheets exhibited sufficient Goss grains and favorable surrounding matrix with pronounced γ-fiber texture, which was responsible for the perfect secondary recrystallization annealing in the warm-rolled specimens at the DSA temperature. The present study suggests that texture optimization of strip-cast grain-oriented silicon steel can be achieved by warm rolling in the appropriate temperature range, with improved magnetic properties."
journal_title,Journal of Materials Science
article_title,High-performance supercapacitors based on porous activated carbons from cattail wool
keyword,[]
history,"['2018-06', '2018-03-21', '2018-02-11', '2018-03-06']"
abstract,"Abstract As electrode materials for supercapacitors, biomass-derived activated carbons attract much attention owing to their natural abundance and low cost. In this work, porous activated carbons are facilely synthesized from cattail wool using Ni(NO3)2·6H2O and KOH as co-etching agents. Compared with the carbons singly etched with KOH, these CWAC-x materials with hierarchical pores have much higher specific surface areas and exhibit much better capacitive performance. As for CWAC-10, the specific surface area and total pore volume are as high as 1581 m2 g−1 and 0.992 cm3 g−1, respectively. For supercapacitor applications, CWAC-10 exhibits a high specific capacitance (314 F g−1 at 1.0 A g−1 in a three-electrode system), excellent cycling stability and high energy density (37.29 Wh kg−1 at a power density of 159.98 W kg−1 in a coin-type symmetric device). The enhanced electrochemical performance can be attributed to the unique structure and the existence of O and N elements."
journal_title,Journal of Materials Science
article_title,A new sodium ferrous orthophosphate NaxFe4(PO4)3 as anode materials for sodium-ion batteries
keyword,[]
history,"['2018-06', '2018-02-28', '2017-11-20', '2018-02-09']"
abstract,"Abstract A new sodium ferrous orthophosphate Na x Fe4(PO4)3 (1.1 ≤ x ≤ 1.2) with P21/n symmetry has been successfully synthesized via a solid-state reaction for the first time. The structure consists of FeO5 pyramids, FeO6 octahedron, and PO4 tetrahedra which form large six-sided tunnels along \( \vec{b} \) direction and three- or four-sided tunnels running along \( \vec{a} \) direction. When evaluated as the anode materials for sodium-ion batteries, the first discharge and charge capacities of 553 and 264 mAh g−1 for Na1.1Fe4(PO4)3/C and 583 and 315 mAh g−1 for Na1.2Fe4(PO4)3/C, respectively, can be obtained at 10 mA g−1 current density. Compared to the Na1.1Fe4(PO4)3/C, Na1.2Fe4(PO4)3/C exhibits a better cycling performance, where the charge capacity of about 100 mAh g−1 can still be maintained after 15 cycles. The electrode kinetics are investigated further by the electrochemical impedance spectroscopy.
"
journal_title,Journal of Materials Science
article_title,Gas-sensing properties of composites of Y-zeolite and SnO2
keyword,[]
history,"['2018-05', '2018-01-22', '2017-10-22', '2018-01-09']"
abstract,"Abstract Y-zeolite was first modified by means of ions exchange with Al, Ca and Na, respectively. The modified materials were characterized by using X-ray diffraction (XRD), scanning electron microscopy (SEM) and inductively coupled plasma optical emission spectrometry (ICP-OES). Gas sensors were fabricated by SnO2 and coating Y-zeolites on the outside of SnO2 surface, respectively. It was found that the responses of the composites of all types of zeolite- and SnO2-based sensors became lower comparing with that of the pure SnO2-based one response of SnO2 sensor to ethanol vapor. It indicates a suppression effect of zeolites on the response to ethanol vapor. In contrast, the response of the composite-sensing materials of the modified Y-zeolite/SnO2-based sensors except the Ca-modified one to acetone indicates a significantly improved response, 2–3 times higher than that of pure SnO2-based sensor which is smaller than the one of SnO2 sensor. The possible mechanism of the effects of the Y-zeolites on the response of the sensors has been discussed.
"
journal_title,Advances in Atmospheric Sciences
article_title,Simulating Eastern- and Central-Pacific Type ENSO Using a Simple Coupled Model
keyword,"['central-Pacific El Niño\xa0', 'eastern-Pacific El Niño\xa0', 'simple coupled model\xa0', 'simulation\xa0', 'asymmetry\xa0', '中部型El Niño\xa0', '东部型El Niño\xa0', '简单耦合模式\xa0', '模拟\xa0', '非对称性\xa0']"
history,"['2018-06', '2018-04-12', '2017-09-04', '2017-11-02', '2017-11-15']"
abstract,"Abstract Severe biases exist in state-of-the-art general circulation models (GCMs) in capturing realistic central-Pacific (CP) El Niño structures. At the same time, many observational analyses have emphasized that thermocline (TH) feedback and zonal advective (ZA) feedback play dominant roles in the development of eastern-Pacific (EP) and CP El Niño–Southern Oscillation (ENSO), respectively. In this work, a simple linear air–sea coupled model, which can accurately depict the strength distribution of the TH and ZA feedbacks in the equatorial Pacific, is used to investigate these two types of El Niño. The results indicate that the model can reproduce the main characteristics of CP ENSO if the TH feedback is switched off and the ZA feedback is retained as the only positive feedback, confirming the dominant role played by ZA feedback in the development of CP ENSO. Further experiments indicate that, through a simple nonlinear control approach, many ENSO characteristics, including the existence of both CP and EP El Niño and the asymmetries between El Niño and La Niña, can be successfully captured using the simple linear air–sea coupled model. These analyses indicate that an accurate depiction of the climatological sea surface temperature distribution and the related ZA feedback, which are the subject of severe biases in GCMs, is very important in simulating a realistic CP El Niño."
journal_title,Advances in Atmospheric Sciences
article_title,Regional Features and Seasonality of Land–Atmosphere Coupling over Eastern China
keyword,"['soil moisture\xa0', 'surface temperature\xa0', 'land–atmosphere interaction\xa0', 'evapotranspiration\xa0', 'coupling\xa0', '土壤湿度\xa0', '地表温度\xa0', '陆-气相互作用\xa0', '蒸散发\xa0', '耦合\xa0']"
history,"['2018-06', '2018-04-12', '2017-05-27', '2017-10-27', '2017-11-24']"
abstract,"Abstract Land–atmosphere coupling is a key process of the climate system, and various coupling mechanisms have been proposed before based on observational and numerical analyses. The impact of soil moisture (SM) on evapotranspiration (ET) and further surface temperature (ST) is an important aspect of such coupling. Using ERA-Interim data and CLM4.0 offline simulation results, this study further explores the relationships between SM/ST and ET to better understand the complex nature of the land–atmosphere coupling (i.e., spatial and seasonal variations) in eastern China, a typical monsoon area. It is found that two diagnostics of land–atmosphere coupling (i.e., SM–ET correlation and ST–ET correlation) are highly dependent on the climatology of SM and ST. By combining the SM–ET and ST–ET relationships, two “hot spots” of land–atmosphere coupling over eastern China are identified: Southwest China and North China. In Southwest China, ST is relatively high throughout the year, but SM is lowest in spring, resulting in a strong coupling in spring. However, in North China, SM is relatively low throughout the year, but ST is highest in summer, which leads to the strongest coupling in summer. Our results emphasize the dependence of land–atmosphere coupling on the seasonal evolution of climatic conditions and have implications for future studies related to land surface feedbacks."
journal_title,Advances in Atmospheric Sciences
article_title,SPARC Local Workshop on “WCRP Grand Challenges and Regional Climate Change”
keyword,[]
history,"['2018-06', '2018-04-12', '2018-02-19', '2018-03-02', '2018-03-04']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,First Global Carbon Dioxide Maps Produced from TanSat Measurements
keyword,[]
history,"['2018-06', '2018-04-12', '2017-12-28', '2018-02-01', '2018-02-13']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,Impact of the Winter North Pacific Oscillation on the Surface Air Temperature over Eurasia and North America: Sensitivity to the Index Definition
keyword,"['North Pacific Oscillation\xa0', 'index definition\xa0', 'surface air temperature\xa0', '北太平洋涛动\xa0', '指数定义\xa0', '地表气温\xa0']"
history,"['2018-06', '2018-04-12', '2017-04-26', '2017-09-25', '2017-11-15']"
abstract,"Abstract This study analyzes the impact of the winter North Pacific Oscillation (NPO) on the surface air temperature (SAT) variations over Eurasia and North America based on six different NPO indices. Results  show that the influences of the winter NPO on the SAT over Eurasia and North America are sensitive to the definition of the NPO index. The impact of the winter NPO on the SAT variations over Eurasia (North America) is significant (insignificant) when the anticyclonic anomaly associated with the NPO index over the North Pacific midlatitudes shifts westward and pronounced northerly wind anomalies appear around Lake Baikal. By contrast, the impact of the winter NPO on the SAT variations over Eurasia (North America) is insignificant (significant) when the anticyclonic anomaly over the North Pacific related to the NPO index shifts eastward and the associated northerly wind anomalies to its eastern flank extend to North America. The present study suggests that the NPO definition should be taken into account when analyzing the impact of the winter NPO on Eurasian and North American SAT variations."
journal_title,Advances in Atmospheric Sciences
article_title,Subseasonal Reversal of East Asian Surface Temperature Variability in Winter 2014/15
keyword,"['East Asia\xa0', 'subseasonal temperature\xa0', 'Arctic sea-ice\xa0', 'Niño4 SST\xa0', 'Pacific Decadal Oscillation\xa0', '东亚\xa0', '次季节气温\xa0', '北极海冰\xa0', 'Nino4区海温\xa0', 'PDO\xa0']"
history,"['2018-06', '2018-04-12', '2017-03-18', '2017-10-24', '2017-11-21']"
abstract,"Abstract Although there has been a considerable amount of research conducted on the East Asian winter-mean climate, subseasonal surface air temperature (SAT) variability reversals in the early and late winter remain poorly understood. In this study, we focused on the recent winter of 2014/15, in which warmer anomalies dominated in January and February but colder conditions prevailed in December. Moreover, Arctic sea-ice cover (ASIC) in September–October 2014 was lower than normal, and warmer sea surface temperature (SST) anomalies occurred in the Niño4 region in winter, together with a positive Pacific Decadal Oscillation (PDO|+) phase. Using observational data and CMIP5 historical simulations, we investigated the PDO|+ phase modulation upon the winter warm Niño4 phase (autumn ASIC reduction) influence on the subseasonal SAT variability of East Asian winter. The results show that, under a PDO|+ phase modulation, warm Niño4 SST anomalies are associated with a subseasonal delay of tropical surface heating and subsequent Hadley cell and Ferrel cell intensification in January–February, linking the tropical and midlatitude regions. Consistently, the East Asian jet stream (EAJS) is significantly decelerated in January–February and hence promotes the warm anomalies over East Asia. Under the PDO|+ phase, the decrease in ASIC is related to cold SST anomalies in the western North Pacific, which increase the meridional temperature gradient and generate an accelerated and westward-shifted EAJS in December. The westward extension of the EAJS is responsible for the eastward-propagating Rossby waves triggered by declining ASIC and thereby favors the connection between ASIC and cold conditions over East Asia."
journal_title,Advances in Atmospheric Sciences
article_title,Impact of the Spring SST Gradient between the Tropical Indian Ocean and Western Pacific on Landfalling Tropical Cyclone Frequency in China
keyword,"['tropical cyclone\xa0', 'landfall\xa0', 'sea surface temperature gradient\xa0', 'air–sea interaction\xa0', '热带气旋登陆\xa0', '海表温度梯度\xa0', '海-气相互作用\xa0']"
history,"['2018-06', '2018-04-12', '2017-04-05', '2017-09-07', '2017-11-21']"
abstract,"Abstract The present study identifies a significant influence of the sea surface temperature gradient (SSTG) between the tropical Indian Ocean (TIO; 15°S–15°N, 40°–90°E) and the western Pacific warm pool (WWP; 0°–15°N, 125°–155°E) in boreal spring on tropical cyclone (TC) landfall frequency in mainland China in boreal summer. During the period 1979–2015, a positive spring SSTG induces a zonal inter-basin circulation anomaly with lower-level convergence, mid-tropospheric ascendance and upper-level divergence over the west-central TIO, and the opposite situation over the WWP, which produces lower-level anomalous easterlies and upper-level anomalous westerlies between the TIO and WWP. This zonal circulation anomaly further warms the west-central TIO by driving warm water westward and cools the WWP by inducing local upwelling, which facilitates the persistence of the anomaly until the summer. Consequently, lower-level negative vorticity, strong vertical wind shear and lower-level anticyclonic anomalies prevail over most of the western North Pacific (WNP), which decreases the TC genesis frequency. Meanwhile, there is an anomalous mid-tropospheric anticyclone over the main WNP TC genesis region, meaning a westerly anomaly dominates over coastal regions of mainland China, which is unfavorable for steering TCs to make landfall in mainland China during summer. This implies that the spring SSTG may act as a potential indicator for TC landfall frequency in mainland China."
journal_title,Advances in Atmospheric Sciences
article_title,"Modeling the Warming Impact of Urban Land Expansion on Hot Weather Using the Weather Research and Forecasting Model: A Case Study of Beijing, China"
keyword,"['heat wave\xa0', 'numerical simulation\xa0', 'urbanization\xa0', 'surface heat flux\xa0', 'WRF\xa0', 'UCM\xa0', '热浪\xa0', '数值模拟\xa0', '城市化\xa0', '地表热通量\xa0', 'WRF模型\xa0']"
history,"['2018-06', '2018-04-12', '2017-05-31', '2017-11-15', '2017-11-29']"
abstract,"Abstract The impacts of three periods of urban land expansion during 1990–2010 on near-surface air temperature in summer in Beijing were simulated in this study, and then the interrelation between heat waves and urban warming was assessed. We ran the sensitivity tests using the mesoscaleWeather Research and Forecasting model coupled with a single urban canopy model, as well as high-resolution land cover data. The warming area expanded approximately at the same scale as the urban land expansion. The average regional warming induced by urban expansion increased but the warming speed declined slightly during 2000–2010. The smallest warming occurred at noon and then increased gradually in the afternoon before peaking at around 2000 LST—the time of sunset. In the daytime, urban warming was primarily caused by the decrease in latent heat flux at the urban surface. Urbanization led to more ground heat flux during the day and then more release at night, which resulted in nocturnal warming. Urban warming at night was higher than that in the day, although the nighttime increment in sensible heat flux was smaller. This was because the shallower planetary boundary layer at night reduced the release efficiency of near-surface heat. The simulated results also suggested that heat waves or high temperature weather enhanced urban warming intensity at night. Heat waves caused more heat to be stored in the surface during the day, greater heat released at night, and thus higher nighttime warming. Our results demonstrate a positive feedback effect between urban warming and heat waves in urban areas."
journal_title,Advances in Atmospheric Sciences
article_title,Interannual Weakening of the Tropical Pacific Walker Circulation Due to Strong Tropical Volcanism
keyword,"['Pacific Walker circulation\xa0', 'strong tropical volcanic eruptions\xa0', 'cooling effect\xa0', 'trade winds\xa0', '沃克环流\xa0', '热带强火山喷发\xa0', '降温效应\xa0', '信风\xa0']"
history,"['2018-06', '2018-04-12', '2017-05-24', '2017-10-17', '2017-11-24']"
abstract,"Abstract In order to examine the response of the tropical Pacific Walker circulation (PWC) to strong tropical volcanic eruptions (SVEs), we analyzed a three-member long-term simulation performed with HadCM3, and carried out four additional CAM4 experiments. We found that the PWC shows a significant interannual weakening after SVEs. The cooling effect from SVEs is able to cool the entire tropics. However, cooling over the Maritime Continent is stronger than that over the central-eastern tropical Pacific. Thus, non-uniform zonal temperature anomalies can be seen following SVEs. As a result, the sea level pressure gradient between the tropical Pacific and the Maritime Continent is reduced, which weakens trade winds over the tropical Pacific. Therefore, the PWC is weakened during this period. At the same time, due to the cooling subtropical and midlatitude Pacific, the Intertropical Convergence Zone (ITCZ) and South Pacific convergence zone (SPCZ) are weakened and shift to the equator. These changes also contribute to the weakened PWC. Meanwhile, through the positive Bjerknes feedback, weakened trade winds cause El Niño-like SST anomalies over the tropical Pacific, which in turn further influence the PWC. Therefore, the PWC significantly weakens after SVEs. The CAM4 experiments further confirm the influences from surface cooling over the Maritime Continent and subtropical/midlatitude Pacific on the PWC. Moreover, they indicate that the stronger cooling over the Maritime Continent plays a dominant role in weakening the PWC after SVEs. In the observations, a weakened PWC and a related El Niño-like SST pattern can be found following SVEs."
journal_title,Advances in Atmospheric Sciences
article_title,Evaluation of the New Dynamic Global Vegetation Model in CAS-ESM
keyword,"['vegetation dynamics\xa0', 'dynamic global vegetation model\xa0', 'vegetation distribution\xa0', 'carbon flux\xa0', 'leaf area index\xa0', '植被动态\xa0', '全球植被动力学模式\xa0', '植被分布\xa0', '碳通量\xa0', '叶面积指数\xa0']"
history,"['2018-06', '2018-04-12', '2017-06-21', '2017-10-18', '2017-11-15']"
abstract,"Abstract In the past several decades, dynamic global vegetation models (DGVMs) have been the most widely used and appropriate tool at the global scale to investigate vegetation–climate interactions. At the Institute of Atmospheric Physics, a new version of DGVM (IAP-DGVM) has been developed and coupled to the Common Land Model (CoLM) within the framework of the Chinese Academy of Sciences’ Earth System Model (CAS-ESM). This work reports the performance of IAP-DGVM through comparisons with that of the default DGVM of CoLM (CoLM-DGVM) and observations. With respect to CoLMDGVM, IAP-DGVM simulated fewer tropical trees, more “needleleaf evergreen boreal tree” and “broadleaf deciduous boreal shrub”, and a better representation of grasses. These contributed to a more realistic vegetation distribution in IAP-DGVM, including spatial patterns, total areas, and compositions. Moreover, IAP-DGVM also produced more accurate carbon fluxes than CoLM-DGVM when compared with observational estimates. Gross primary productivity and net primary production in IAP-DGVM were in better agreement with observations than those of CoLM-DGVM, and the tropical pattern of fire carbon emissions in IAP-DGVM was much more consistent with the observation than that in CoLM-DGVM. The leaf area index simulated by IAP-DGVM was closer to the observation than that of CoLM-DGVM; however, both simulated values about twice as large as in the observation. This evaluation provides valuable information for the application of CAS-ESM, as well as for other model communities in terms of a comparative benchmark."
journal_title,Advances in Atmospheric Sciences
article_title,Improved Land Use and Leaf Area Index Enhances WRF-3DVAR Satellite Radiance Assimilation: A Case Study Focusing on Rainfall Simulation in the Shule River Basin during July 2013
keyword,"['WRF-3DVAR\xa0', 'land use\xa0', 'leaf area index\xa0', 'radiance assimilation\xa0', 'rainfall simulation\xa0', 'WRF-3DVAR\xa0', '土地利用类型\xa0', '叶面积指数\xa0', '辐射同化\xa0', '降水模拟\xa0']"
history,"['2018-06', '2018-04-12', '2017-05-10', '2017-10-13', '2017-11-29']"
abstract,"Abstract The application of satellite radiance assimilation can improve the simulation of precipitation by numerical weather prediction models. However, substantial quantities of satellite data, especially those derived from low-level (surface-sensitive) channels, are rejected for use because of the difficulty in realistically modeling land surface emissivity and energy budgets. Here, we used an improved land use and leaf area index (LAI) dataset in the WRF-3DVAR assimilation system to explore the benefit of using improved quality of land surface information to improve rainfall simulation for the Shule River Basin in the northeastern Tibetan Plateau as a case study. The results for July 2013 show that, for low-level channels (e.g., channel 3), the underestimation of brightness temperature in the original simulation was largely removed by more realistic land surface information. In addition, more satellite data could be utilized in the assimilation because the realistic land use and LAI data allowed more satellite radiance data to pass the deviation test and get used by the assimilation, which resulted in improved initial driving fields and better simulation in terms of temperature, relative humidity, vertical convection, and cumulative precipitation."
journal_title,Advances in Atmospheric Sciences
article_title,Evaluating and Improving Wind Forecasts over South China: The Role of Orographic Parameterization in the GRAPES Model
keyword,"['small-scale orographic drag\xa0', 'GRAPES TMM\xa0', 'PBL parameterization\xa0', 'wind bias\xa0', '次网格地形\xa0', '风速预报\xa0', '拖曳\xa0', '预报误差\xa0']"
history,"['2018-06', '2018-04-12', '2017-07-04', '2017-10-16', '2017-11-29']"
abstract,"Abstract Unresolved small-scale orographic (SSO) drags are parameterized in a regional model based on the Global/Regional Assimilation and Prediction System for the Tropical Mesoscale Model (GRAPES TMM). The SSO drags are represented by adding a sink term in the momentum equations. The maximum height of the mountain within the grid box is adopted in the SSO parameterization (SSOP) scheme as compensation for the drag. The effects of the unresolved topography are parameterized as the feedbacks to the momentum tendencies on the first model level in planetary boundary layer (PBL) parameterization. The SSOP scheme has been implemented and coupled with the PBL parameterization scheme within the model physics package. A monthly simulation is designed to examine the performance of the SSOP scheme over the complex terrain areas located in the southwest of Guangdong. The verification results show that the surface wind speed bias has been much alleviated by adopting the SSOP scheme, in addition to reduction of the wind bias in the lower troposphere. The target verification over Xinyi shows that the simulations with the SSOP scheme provide improved wind estimation over the complex regions in the southwest of Guangdong."
journal_title,Advances in Atmospheric Sciences
article_title,Organizational Modes of Severe Wind-producing Convective Systems over North China
keyword,"['severe convective wind\xa0', 'organizational mode\xa0', 'convective system\xa0', 'topography\xa0', '雷暴大风\xa0', '对流组织类型\xa0', '对流系统\xa0', '地形\xa0']"
history,"['2018-05', '2018-02-19', '2017-05-05', '2017-09-04', '2017-09-12']"
abstract,"Abstract Severe weather reports and composite radar reflectivity data from 2010–14 over North China were used to analyze the distribution of severe convective wind (SCW) events and their organizational modes of radar reflectivity. The six organizational modes for SCW events (and their proportions) were cluster cells (35.4%), squall lines (18.4%), nonlinear-shaped systems (17.8%), broken lines (11.6%), individual cells (1.2%), and bow echoes (0.5%). The peak month for both squall lines and broken lines was June, whereas it was July for the other four modes. The highest numbers of SCW events were over the mountains, which were generally associated with disorganized systems of cluster cells. In contrast, SCW associated with linear systems occurred mainly over the plains, where stations recorded an average of less than one SCW event per year. Regions with a high frequency of SCW associated with nonlinear-shaped systems also experienced many SCW events associated with squall lines. Values of convective available potential energy, precipitable water, 0–3-km shear, and 0–6-km shear, were demonstrably larger over the plains than over the mountains, which had an evident effect on the organizational modes of SCW events. Therefore, topography may be an important factor in the organizational modes for SCW events over North China."
journal_title,Advances in Atmospheric Sciences
article_title,A Prototype Regional GSI-based EnKF-Variational Hybrid Data Assimilation System for the Rapid Refresh Forecasting System: Dual-Resolution Implementation and Testing Results
keyword,"['dual-resolution 3D ensemble variational data assimilation system\xa0', 'Rapid Refresh forecasting system\xa0', '双分辨率三维集合变分同化系统\xa0', '快速同化预报系统\xa0']"
history,"['2018-05', '2018-02-19', '2017-04-26', '2017-10-08', '2017-10-27']"
abstract,"Abstract A dual-resolution (DR) version of a regional ensemble Kalman filter (EnKF)-3D ensemble variational (3DEnVar) coupled hybrid data assimilation system is implemented as a prototype for the operational Rapid Refresh forecasting system. The DR 3DEnVar system combines a high-resolution (HR) deterministic background forecast with lower-resolution (LR) EnKF ensemble perturbations used for flow-dependent background error covariance to produce a HR analysis. The computational cost is substantially reduced by running the ensemble forecasts and EnKF analyses at LR. The DR 3DEnVar system is tested with 3-h cycles over a 9-day period using a 40/∼13-km grid spacing combination. The HR forecasts from the DR hybrid analyses are compared with forecasts launched from HR Gridpoint Statistical Interpolation (GSI) 3D variational (3DVar) analyses, and single LR hybrid analyses interpolated to the HR grid. With the DR 3DEnVar system, a 90% weight for the ensemble covariance yields the lowest forecast errors and the DR hybrid system clearly outperforms the HR GSI 3DVar. Humidity and wind forecasts are also better than those launched from interpolated LR hybrid analyses, but the temperature forecasts are slightly worse. The humidity forecasts are improved most. For precipitation forecasts, the DR 3DEnVar always outperforms HR GSI 3DVar. It also outperforms the LR 3DEnVar, except for the initial forecast period and lower thresholds."
journal_title,Advances in Atmospheric Sciences
article_title,Impact of Pacific Decadal Oscillation on Frequency Asymmetry of El Niño and La Niña Events
keyword,[]
history,"['2018-05', '2018-02-19', '2018-01-24', '2018-01-29', '2018-01-31']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,Numerical Study of the Influences of a Monsoon Gyre on Intensity Changes of Typhoon Chan-Hom (2015)
keyword,"['monsoon gyre\xa0', 'intensity change\xa0', 'numerical simulation\xa0', '季风涡旋\xa0', '强度变化\xa0', '数值模拟\xa0']"
history,"['2018-05', '2018-02-19', '2017-06-21', '2017-09-13', '2017-10-24']"
abstract,"Abstract Typhoon Chan-Hom (2015) underwent a weakening in the tropical western North Pacific (WNP) when it interacted with a monsoon gyre, but all operational forecasts failed to predict this intensity change. A recent observational study indicated that it resulted from its interaction with a monsoon gyre on the 15–30-day timescale. In this study, the results of two numerical experiments are presented to investigate the influence of the monsoon gyre on the intensity changes of Typhoon Chan-Hom (2015). The control experiment captures the main observed features of the weakening process of Chan-Hom (2015) during a sharp northward turn in the Philippine Sea, including the enlargement of the eye size, the development of strong convection on the eastern side of the monsoon gyre, and the corresponding strong outer inflow. The sensitivity experiment suggests that intensity changes of Chan-Hom (2015) were mainly associated with its interaction with the monsoon gyre. When Chan-Hom (2015) initially moved westward in the eastern part of the monsoon gyre, the monsoon gyre enhanced the inertial stability for the intensification of the typhoon. With its coalescence with the monsoon gyre, the development of the strong convection on the eastern side of the monsoon gyre prevented moisture and mass entering the inner core of Chan-Hom (2015), resulting in the collapse of the eyewall. Thus, the weakening happened in the deep tropical WNP region. The numerical simulations confirm the important effects of the interaction between tropical cyclones and monsoon gyres on tropical cyclone intensity."
journal_title,Advances in Atmospheric Sciences
article_title,Vortex Rossby Waves in Asymmetric Basic Flow of Typhoons
keyword,"['asymmetric basic flow\xa0', 'vortex Rossby waves\xa0', 'group velocity\xa0', 'propagation pathways\xa0', 'wave ray\xa0', '非对称基流\xa0', '涡旋Rossby波\xa0', '群速度\xa0', '传播路径\xa0', '波射线\xa0']"
history,"['2018-05', '2018-02-19', '2017-05-31', '2017-09-19', '2017-10-24']"
abstract,"Abstract Wave ray theory is employed to study features of propagation pathways (rays) of vortex Rossby waves in typhoons with asymmetric basic flow, where the tangential asymmetric basic flow is constructed by superimposing the wavenumber-1 perturbation flow on the symmetric basic flow, and the radial basic flow is derived from the non-divergence equation. Results  show that, in a certain distance, the influences of the asymmetry in the basic flow on group velocities and slopes of rays of vortex Rossby waves are mainly concentrated near the radius of maximum wind (RMW), whereas it decreases outside the RMW. The distributions of radial and tangential group velocities of the vortex Rossby waves in the asymmetric basic flow are closely related to the azimuth location of the maximum speed of the asymmetric basic flow, and the importance of radial and tangential basic flow on the group velocities would change with radius. In addition, the stronger asymmetry in the basic flow always corresponds to faster outward energy propagation of vortex Rossby waves. In short, the group velocities, and thereby the wave energy propagation and vortex Rossby wave ray slope in typhoons, would be changed by the asymmetry of the basic flow."
journal_title,Advances in Atmospheric Sciences
article_title,ENSO Frequency Asymmetry and the Pacific Decadal Oscillation in Observations and 19 CMIP5 Models
keyword,"['ENSO frequency asymmetry\xa0', 'Pacific Decadal Oscillation\xa0', 'decadal variation\xa0', 'Monte Carlo method\xa0', 'CMIP5\xa0', 'ENSO发生频率的不对称性\xa0', '北太平洋年代际振荡\xa0', '年代际变化\xa0', '蒙特卡罗方法\xa0', 'CMIP5模式\xa0']"
history,"['2018-05', '2018-02-19', '2017-04-26', '2017-10-27', '2017-11-15']"
abstract,"Abstract Using observational data and the pre-industrial simulations of 19 models from the Coupled Model Intercomparison Project Phase 5 (CMIP5), the El Niño (EN) and La Niña (LN) events in positive and negative Pacific Decadal Oscillation (PDO) phases are examined. In the observational data, with EN (LN) events the positive (negative) SST anomaly in the equatorial eastern Pacific is much stronger in positive (negative) PDO phases than in negative (positive) phases. Meanwhile, the models cannot reasonably reproduce this difference. Besides, the modulation of ENSO frequency asymmetry by the PDO is explored. Results  show that, in the observational data, EN is 300% more (58% less) frequent than LN in positive (negative) PDO phases, which is significant at the 99% confidence level using the Monte Carlo test. Most of the CMIP5 models exhibit results that are consistent with the observational data."
journal_title,Advances in Atmospheric Sciences
article_title,Characteristics and Preliminary Causes of Tropical Cyclone Extreme Rainfall Events over Hainan Island
keyword,"['Hainan Island\xa0', 'tropical cyclones\xa0', 'extreme rainfall events\xa0', 'characteristics\xa0', 'causes\xa0', '海南岛\xa0', '热带气旋\xa0', '极端降水事件\xa0', '特征\xa0', '原因\xa0']"
history,"['2018-05', '2018-02-19', '2017-03-10', '2017-10-10', '2017-10-24']"
abstract,"Abstract The characteristics of tropical cyclone (TC) extreme rainfall events over Hainan Island from 1969 to 2014 are analyzed from the viewpoint of the TC maximum daily rainfall (TMDR) using daily station precipitation data from the Meteorological Information Center of the China Meteorological Administration, TC best-track data from the Shanghai Typhoon Institute, and NCEP/NCAR reanalysis data. The frequencies of the TMDR reaching 50, 100 and 250 mm show a decreasing trend [−0.7 (10 yr)−1], a weak decreasing trend [−0.2 (10 yr)−1] and a weak increasing trend [0.1 (10 yr)−1], respectively. For seasonal variations, the TMDR of all intensity grades mainly occurs from July to October, with the frequencies of TMDR - 50 mm and - 100 mm peaking in September and the frequency of TMDR - 250 mm [TC extreme rainstorm (TCER) events] peaking in August and September. The western region (Changjiang) of the Island is always the rainfall center, independent of the intensity or frequencies of different intensity grades. The causes of TCERs are also explored and the results show that topography plays a key role in the characteristics of the rainfall events. TCERs are easily induced on the windward slopes of Wuzhi Mountain, with the coordination of TC tracks and TC wind structure. A slower speed of movement, a stronger TC intensity and a farther westward track are all conducive to extreme rainfall events. A weaker northwestern Pacific subtropical high is likely to make the 500-hPa steering flow weaker and results in slower TC movement, whereas a stronger South China Sea summer monsoon can carry a higher moisture flux. These two environmental factors are both favorable for TCERs."
journal_title,Advances in Atmospheric Sciences
article_title,Geometric Characteristics of Tropical Cyclone Eyes before Landfall in South China based on Ground-Based Radar Observations
keyword,"['tropical cyclone eye\xa0', 'geometric characteristics\xa0', 'pre-landfall\xa0', '热带气旋的眼\xa0', '几何特征\xa0', '登陆前\xa0']"
history,"['2018-05', '2018-02-19', '2017-06-08', '2017-08-28', '2017-10-09']"
abstract,"Abstract The geometric characteristics of tropical cyclone (TC) eyes before landfall in South China are examined using ground-based radar reflectivity. It is found that the median and mean eye area decrease with TC intensity, except for the severe typhoon category, and the eye size increases with height. The increasing rate of eye size is relatively greater in upper layers. Moreover, the ratio of eye size change in the vertical direction does not correlate with TC intensity. No relationship is presented between the ratio of eye size change in the vertical direction and the vertical wind shear. No relationship between the vertical change in eye size and the eye size at a certain level is found, inconsistent with other studies. No relationship exists between the vertical change in eye size and the intensity tendency. The eye roundness values range mainly from 0.5 to 0.7, and more intense TCs generally have eyes that are more circular."
journal_title,Advances in Atmospheric Sciences
article_title,Interannual Variations in Synoptic-Scale Disturbances over the Western North Pacific
keyword,"['synoptic disturbance activity\xa0', 'interannual variability\xa0', 'leading mode\xa0', 'barotropic conversion\xa0', '天气尺度扰动\xa0', '年际变化\xa0', '主要模态\xa0', '正压转换\xa0']"
history,"['2018-05', '2018-02-19', '2017-06-05', '2017-09-01', '2017-09-28']"
abstract,"Abstract The present study investigates the interannual variation of June–November synoptic disturbance activity over the western North Pacific (WNP) and its relationship with large-scale circulation for the period 1958–2014. Two leading modes of eddy kinetic energy for the disturbance variability over the WNP are obtained by EOF analysis, characterized by anomalous eddy kinetic energy over the subtropical WNP and around the Philippines, respectively. These modes explain a large portion of the interannual variance of synoptic disturbance activity over the WNP. Both are associated with lower-level cyclonic anomalies, but with different locations: over the subtropical WNP for the first mode and over the South China Sea for the second mode. Considering the impact of ENSO on synoptic disturbance activity over the WNP, we repeat the analyses after removing the effect of ENSO, which is simply defined as the components linearly regressed onto the Niño3.4 index, and find similar results, suggesting that the leading modes and their relationships with large-scale circulation exist without SST effects. Further analyses suggest that the meridional shear of zonal winds caused by cyclonic anomalies is crucial for maintaining the leading modes through barotropic conversion."
journal_title,Advances in Atmospheric Sciences
article_title,Analysis of the Characteristics of Inertia-Gravity Waves during an Orographic Precipitation Event
keyword,"['inertia-gravity waves\xa0', 'orographic precipitation\xa0', 'Fourier analysis\xa0', 'wavelet cross-spectrum analysis\xa0', '惯性重力波\xa0', '地形暴雨\xa0', '傅里叶分析\xa0', '小波分析\xa0']"
history,"['2018-05', '2018-02-19', '2017-06-25', '2017-10-27', '2017-11-06']"
abstract,"Abstract A numerical experiment was performed using the Weather Research and Forecasting (WRF) model to analyze the generation and propagation of inertia-gravity waves during an orographic rainstorm that occurred in the Sichuan area on 17 August 2014. To examine the spatial and temporal structures of the inertia-gravity waves and identify the wave types, three wavenumber-frequency spectral analysis methods (Fourier analysis, cross-spectral analysis, and wavelet cross-spectrum analysis) were applied. During the storm, inertia-gravity waves appeared at heights of 10–14 km, with periods of 80–100 min and wavelengths of 40–50 km. These waves were generated over a mountain and propagated eastward at an average speed of 15–20 m s−1. Meanwhile, comparison between the reconstructed inertia-gravity waves and accumulated precipitation showed there was a mutual promotion process between them. The Richardson number and Scorer parameter were used to demonstrate that the eastward-moving inertia-gravity waves were trapped in an effective atmospheric ducting zone with favorable reflector and critical level conditions, which were the primary causes of the long lives of the waves. Finally, numerical experiments to test the sensitivity to terrain and diabatic heating were conducted, and the results suggested a cooperative effect of terrain and diabatic heating contributed to the propagation and enhancement of the waves."
journal_title,Advances in Atmospheric Sciences
article_title,The 30–60-day Intraseasonal Variability of Sea Surface Temperature in the South China Sea dur1ing May–September
keyword,"['sea surface temperature\xa0', '30–60-day intraseasonal variability\xa0', 'South China Sea\xa0', 'vertical entrainment\xa0', '海表温度\xa0', '30-60天季节内变率\xa0', '南海\xa0', '垂直夹卷\xa0']"
history,"['2018-05', '2018-02-19', '2017-05-19', '2017-08-12', '2017-09-18']"
abstract,"Abstract This study investigates the structure and propagation of intraseasonal sea surface temperature (SST) variability in the South China Sea (SCS) on the 30–60-day timescale during boreal summer (May–September). TRMM-based SST, GODAS oceanic reanalysis and ERA-Interim atmospheric reanalysis datasets from 1998 to 2013 are used to examine quantitatively the atmospheric thermodynamic and oceanic dynamic mechanisms responsible for its formation. Power spectra show that the 30–60-day SST variability is predominant, accounting for 60% of the variance of the 10–90-day variability over most of the SCS. Composite analyses demonstrate that the 30–60-day SST variability is characterized by the alternate occurrence of basin-wide positive and negative SST anomalies in the SCS, with positive (negative) SST anomalies accompanied by anomalous northeasterlies (southwesterlies). The transition and expansion of SST anomalies are driven by the monsoonal trough–ridge seesaw pattern that migrates northward from the equator to the northern SCS. Quantitative diagnosis of the composite mixed-layer heat budgets shows that, within a strong 30–60-day cycle, the atmospheric thermal forcing is indeed a dominant factor, with the mixed-layer net heat flux (MNHF) contributing around 60% of the total SST tendency, while vertical entrainment contributes more than 30%. However, the entrainment-induced SST tendency is sometimes as large as the MNHF-induced component, implying that ocean processes are sometimes as important as surface fluxes in generating the 30–60-day SST variability in the SCS."
journal_title,Advances in Atmospheric Sciences
article_title,Idealized Experiments for Optimizing Model Parameters Using a 4D-Variational Method in an Intermediate Coupled Model of ENSO
keyword,"['intermediate coupled model\xa0', 'ENSO modeling\xa0', '4D-Var data assimilation system\xa0', 'optimization of model parameter and initial condition\xa0', '中间型耦合模式\xa0', 'ENSO模拟\xa0', '四维变分同化系统\xa0', '初条件和模式参数优化\xa0']"
history,"['2018-04', '2018-02-16', '2017-04-25', '2017-07-14', '2017-08-17']"
abstract,"Abstract Large biases exist in real-time ENSO prediction, which can be attributed to uncertainties in initial conditions and model parameters. Previously, a 4D variational (4D-Var) data assimilation system was developed for an intermediate coupled model (ICM) and used to improve ENSO modeling through optimized initial conditions. In this paper, this system is further applied to optimize model parameters. In the ICM used, one important process for ENSO is related to the anomalous temperature of subsurface water entrained into the mixed layer (Te), which is empirically and explicitly related to sea level (SL) variation. The strength of the thermocline effect on SST (referred to simply as “the thermocline effect”) is represented by an introduced parameter, αTe. A numerical procedure is developed to optimize this model parameter through the 4D-Var assimilation of SST data in a twin experiment context with an idealized setting. Experiments having their initial condition optimized only, and having their initial condition plus this additional model parameter optimized, are compared. It is shown that ENSO evolution can be more effectively recovered by including the additional optimization of this parameter in ENSO modeling. The demonstrated feasibility of optimizing model parameters and initial conditions together through the 4D-Var method provides a modeling platform for ENSO studies. Further applications of the 4D-Var data assimilation system implemented in the ICM are also discussed."
journal_title,Advances in Atmospheric Sciences
article_title,Projected Changes in Temperature and Precipitation Extremes over China as Measured by 50-yr Return Values and Periods Based on a CMIP5 Ensemble
keyword,"['CMIP5\xa0', 'extremes\xa0', 'return values and periods\xa0', 'China\xa0', 'CMIP5全球气候模式\xa0', '极端温度和降水\xa0', '50年一遇\xa0']"
history,"['2018-04', '2018-02-16', '2017-03-21', '2017-08-08', '2017-09-06']"
abstract,"Abstract Future changes in the 50-yr return level for temperature and precipitation extremes over mainland China are investigated based on a CMIP5 multi-model ensemble for RCP2.6, RCP4.5 and RCP8.5 scenarios. The following indices are analyzed: TXx and TNn (the annual maximum and minimum of daily maximum and minimum surface temperature), RX5day (the annual maximum consecutive 5-day precipitation) and CDD (maximum annual number of consecutive dry days). After first validating the model performance, future changes in the 50-yr return values and return periods for these indices are investigated along with the inter-model spread. Multi-model median changes show an increase in the 50-yr return values of TXx and a decrease for TNn, more specifically, by the end of the 21st century under RCP8.5, the present day 50-yr return period of warm events is reduced to 1.2 yr, while extreme cold events over the country are projected to essentially disappear. A general increase in RX5day 50-yr return values is found in the future. By the end of the 21st century under RCP8.5, events of the present RX5day 50-yr return period are projected to reduce to < 10 yr over most of China. Changes in CDD-50 show a dipole pattern over China, with a decrease in the values and longer return periods in the north, and vice versa in the south. Our study also highlights the need for further improvements in the representation of extreme events in climate models to assess the future risks and engineering design related to large-scale infrastructure in China."
journal_title,Advances in Atmospheric Sciences
article_title,Evaluation of TIGGE Ensemble Forecasts of Precipitation in Distinct Climate Regions in Iran
keyword,"['ensemble forecast\xa0', 'NWP\xa0', 'TIGGE\xa0', 'evaluation\xa0', 'post-processing\xa0', '集合预报\xa0', '数值天气预报\xa0', 'TIGGE\xa0', '评估\xa0', '预处理\xa0']"
history,"['2018-04', '2018-02-16', '2017-04-14', '2017-07-13', '2017-08-07']"
abstract,"Abstract The application of numerical weather prediction (NWP) products is increasing dramatically. Existing reports indicate that ensemble predictions have better skill than deterministic forecasts. In this study, numerical ensemble precipitation forecasts in the TIGGE database were evaluated using deterministic, dichotomous (yes/no), and probabilistic techniques over Iran for the period 2008–16. Thirteen rain gauges spread over eight homogeneous precipitation regimes were selected for evaluation. The Inverse Distance Weighting and Kriging methods were adopted for interpolation of the prediction values, downscaled to the stations at lead times of one to three days. To enhance the forecast quality, NWP values were post-processed via Bayesian Model Averaging. The results showed that ECMWF had better scores than other products. However, products of all centers underestimated precipitation in high precipitation regions while overestimating precipitation in other regions. This points to a systematic bias in forecasts and demands application of bias correction techniques. Based on dichotomous evaluation, NCEP did better at most stations, although all centers overpredicted the number of precipitation events. Compared to those of ECMWF and NCEP, UKMO yielded higher scores in mountainous regions, but performed poorly at other selected stations. Furthermore, the evaluations showed that all centers had better skill in wet than in dry seasons. The quality of post-processed predictions was better than those of the raw predictions. In conclusion, the accuracy of the NWP predictions made by the selected centers could be classified as medium over Iran, while post-processing of predictions is recommended to improve the quality."
journal_title,Advances in Atmospheric Sciences
article_title,Impact of SST Anomaly Events over the Kuroshio–Oyashio Extension on the “Summer Prediction Barrier”
keyword,"['Kuroshio–Oyashio Extension\xa0', 'SST\xa0', 'summer prediction barrier\xa0', 'error growth\xa0', '黑潮延伸区\xa0', 'SST\xa0', '夏季预报障碍\xa0', '误差增长\xa0']"
history,"['2018-04', '2018-02-16', '2016-12-21', '2017-06-22', '2017-07-21']"
abstract,"Abstract The “summer prediction barrier” (SPB) of SST anomalies (SSTA) over the Kuroshio–Oyashio Extension (KOE) refers to the phenomenon that prediction errors of KOE-SSTA tend to increase rapidly during boreal summer, resulting in large prediction uncertainties. The fast error growth associated with the SPB occurs in the mature-to-decaying transition phase, which is usually during the August–September–October (ASO) season, of the KOE-SSTA events to be predicted. Thus, the role of KOE-SSTA evolutionary characteristics in the transition phase in inducing the SPB is explored by performing perfect model predictability experiments in a coupled model, indicating that the SSTA events with larger mature-to-decaying transition rates (Category-1) favor a greater possibility of yielding a more significant SPB than those events with smaller transition rates (Category-2). The KOE-SSTA events in Category-1 tend to have more significant anomalous Ekman pumping in their transition phase, resulting in larger prediction errors of vertical oceanic temperature advection associated with the SSTA events. Consequently, Category-1 events possess faster error growth and larger prediction errors. In addition, the anomalous Ekman upwelling (downwelling) in the ASO season also causes SSTA cooling (warming), accelerating the transition rates of warm (cold) KOE-SSTA events. Therefore, the SSTA transition rate and error growth rate are both related with the anomalous Ekman pumping of the SSTA events to be predicted in their transition phase. This may explain why the SSTA events transferring more rapidly from the mature to decaying phase tend to have a greater possibility of yielding a more significant SPB."
journal_title,Advances in Atmospheric Sciences
article_title,"Evaluating the Capabilities of Soil Enthalpy, Soil Moisture and Soil Temperature in Predicting Seasonal Precipitation"
keyword,"['seasonal precipitation prediction\xa0', 'land surface process\xa0', 'soil enthalpy\xa0', 'soil moisture\xa0', 'soil temperature\xa0', '季节性降水预测\xa0', '陆面过程\xa0', '土壤焓\xa0', '土壤湿度\xa0', '土壤温度\xa0']"
history,"['2018-04', '2018-02-16', '2017-01-09', '2017-07-28', '2017-08-23']"
abstract,"Abstract Soil enthalpy (H) contains the combined effects of both soil moisture (w) and soil temperature (T) in the land surface hydrothermal process. In this study, the sensitivities of H to w and T are investigated using the multi-linear regression method. Results  indicate that T generally makes positive contributions to H, while w exhibits different (positive or negative) impacts due to soil ice effects. For example, w negatively contributes to H if soil contains more ice; however, after soil ice melts, w exerts positive contributions. In particular, due to lower w interannual variabilities in the deep soil layer (i.e., the fifth layer), H is more sensitive to T than to w. Moreover, to compare the potential capabilities of H, w and T in precipitation (P) prediction, the Huanghe–Huaihe Basin (HHB) and Southeast China (SEC), with similar sensitivities of H to w and T, are selected. Analyses show that, despite similar spatial distributions of H–P and T–P correlation coefficients, the former values are always higher than the latter ones. Furthermore, H provides the most effective signals for P prediction over HHB and SEC, i.e., a significant leading correlation between May H and early summer (June) P. In summary, H, which integrates the effects of T and w as an independent variable, has greater capabilities in monitoring land surface heating and improving seasonal P prediction relative to individual land surface factors (e.g., T and w)."
journal_title,Advances in Atmospheric Sciences
article_title,Variations in High-frequency Oscillations of Tropical Cyclones over the Western North Pacific
keyword,"['tropical cyclone\xa0', 'high-frequency oscillation\xa0', 'western North Pacific\xa0', 'South China Sea\xa0', '热带气旋\xa0', '高频振荡\xa0', '西北太平洋\xa0', '南海\xa0']"
history,"['2018-04', '2018-02-16', '2017-03-18', '2017-08-06', '2017-09-12']"
abstract,"Abstract Variations in the high-frequency oscillations of tropical cyclones (TCs) over the western North Pacific (WNP) are studied in numerical model simulations. Power spectrum analysis of maximum wind speeds at 10 m (MWS10) from an ensemble of 15 simulated TCs shows that oscillations are significant for all TCs. The magnitudes of oscillations in MWS10 are similar in the WNP and South China Sea (SCS); however, the mean of the averaged significant periods in the SCS (1.93 h) is shorter than that in the open water of the WNP (2.83 h). The shorter period in the SCS is examined through an ensemble of simulations, and a case simulation as well as a sensitivity experiment in which the continent is replaced by ocean for Typhoon Hagupit (2008). The analysis of the convergence efficiency within the boundary layer suggests that the shorter periods in the SCS are possibly due to the stronger terrain effect, which intensifies convergence through greater friction. The enhanced convergence strengthens the disturbance of the gradient and thermal wind balances, and then contributes to the shorter oscillation periods in the SCS."
journal_title,Advances in Atmospheric Sciences
article_title,Asymmetric Relationship between the Meridional Displacement of the Asian Westerly Jet and the Silk Road Pattern
keyword,"['Asian westerly jet\xa0', 'meridional displacement\xa0', 'Silk Road Pattern\xa0', 'asymmetric relation\xa0', 'Rossby wave source\xa0', '亚洲西风急流\xa0', '经向偏移\xa0', '丝绸之路遥相关\xa0', '不对称关系\xa0', '罗斯贝波波源\xa0']"
history,"['2018-04', '2018-02-16', '2016-12-16', '2017-08-14', '2017-09-06']"
abstract,"Abstract In previous work, a significant relationship was identified between the meridional displacement of the Asian westerly jet (JMD) and the Silk Road Pattern (SRP) in summer. The present study reveals that this relationship is robust in northward JMD years but absent in southward JMD years. In other words, the amplitude of the SRP increases with northward displacement of the jet but shows little change with southward displacement. Further analysis indicates that, in northward JMD years, the Rossby wave source (RWS) anomalies, which are primarily contributed by the planetary vortex stretching, are significantly stronger around the entrance of the Asian jet, i.e., the Mediterranean Sea–Caspian Sea area, with the spatial distribution being consistent with that related to the SRP. By contrast, in southward JMD years, the RWS anomalies are much weaker. Therefore, this study suggests that the RWS plays a crucial role in inducing the asymmetry of the JMD–SRP relationship. The results imply that climate anomalies may be stronger in strongly northward-displaced JMD years due to the concurrence of the JMD and SRP, and thus more attention should be paid to these years."
journal_title,Advances in Atmospheric Sciences
article_title,Report on IAMAS Activity since 2015 and the IAPSO-IAMAS-IAGA Scientific Assembly—Good Hope For Earth Sciences
keyword,[]
history,"['2018-04', '2018-02-16', '2017-10-10', '2017-11-20', '2017-11-29']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,Validation and Spatiotemporal Distribution of GEOS-5–Based Planetary Boundary Layer Height and Relative Humidity in China
keyword,"['GEOS-5\xa0', 'planetary boundary layer height\xa0', 'relative humidity\xa0', 'validation\xa0', 'spatiotemporal distribution\xa0', 'GEOS-5\xa0', '边界层高度\xa0', '相对湿度\xa0', '验证\xa0', '时空分布特征\xa0']"
history,"['2018-04', '2018-02-16', '2016-11-23', '2017-07-21', '2017-08-03']"
abstract,"Abstract Few studies have specifically focused on the validation and spatiotemporal distribution of planetary boundary layer height (PBLH) and relative humidity (RH) data in China. In this analysis, continuous PBLH and surface-level RH data simulated from GEOS-5 between 2004 and 2012, were validated against ground-based observations. Overall, the simulated RH was consistent with the statistical data from meteorological stations, with a correlation coefficient of 0.78 and a slope of 0.9. However, the simulated PBLH was underestimated compared to LIDAR data by a factor of approximately two, which was primarily because of poor simulation in late summer and early autumn. We further examined the spatiotemporal distribution characteristics of two factors in four regions—North China, South China, Northwest China, and the Tibetan Plateau. The results showed that the annual PBLH trends in all regions were fairly moderate but sensitive to solar radiation and precipitation, which explains why the PBLH values were ranked in order from largest to smallest as follows: Tibetan Plateau, Northwest China, North China, and South China. Strong seasonal variation of the PBLH exhibited high values in summer and low values in winter, which was also consistent with the turbulent vertical exchange. Not surprisingly, the highest RH in South China and the lowest RH in desert areas of Northwest China (less than 30%). Seasonally, South China exhibited little variation, whereas Northwest China exhibited its highest humidity in winter and lowest humidity in spring, the maximum values in the other regions were obtained from July to September."
journal_title,Advances in Atmospheric Sciences
article_title,Large-scale Circulation Control of the Occurrence of Low-level Turbulence at Hong Kong International Airport
keyword,"['LIDAR\xa0', 'temperate cyclone and anticyclone\xa0', 'western North Pacific subtropical high\xa0', 'seasonal cycle\xa0', 'topography effect\xa0', '激光雷达(LIDAR)\xa0', '温带气旋和反气旋\xa0', '副热带高压\xa0', '季节周期\xa0', '地形效应 \xa0']"
history,"['2018-04', '2018-02-16', '2017-05-08', '2017-07-31', '2017-08-17']"
abstract,"Abstract This study identifies the atmospheric circulation features that are favorable for the occurrence of low-level turbulence at Hong Kong International Airport [below 1600 feet (around 500 m)]. By using LIDAR data at the airport, turbulence and nonturbulence cases are selected. It is found that the occurrence of turbulence is significantly related to the strength of the southerly wind at 850 hPa over the South China coast. On the other hand, the east–west wind at this height demonstrates a weak relation to the occurrence. This suggests that turbulence is generated by flow passing Lantau Island from the south. The southerly wind also transports moisture from the South China Sea to Hong Kong, reducing local stability. This is favorable for the development of strong turbulence. It is also noted that the strong southerly wind during the occurrence of low-level turbulence is contributed by an anomalous zonal gradient of geopotential in the lower troposphere over the South China Sea. This gradient is caused by the combination of variations at different timescales. These are the passage of synoptic extratropical cyclones and anticyclones and the intraseasonal variation in the western North Pacific subtropical high. The seasonal variation in geopotential east of the Tibetan Plateau leads to a seasonal change in meridional wind, by which the frequency of low-level turbulence is maximized in spring and minimized in autumn."
journal_title,Advances in Atmospheric Sciences
article_title,Effects of Sea-Surface Waves and Ocean Spray on Air–Sea Momentum Fluxes
keyword,"['drag coefficient\xa0', 'marine atmospheric boundary layer\xa0', 'ocean spray droplets\xa0', 'surface waves\xa0', '海-气边界层\xa0', '海表面波浪\xa0', '海洋飞沫\xa0', '拖曳系数\xa0']"
history,"['2018-04', '2018-02-16', '2017-04-23', '2017-07-05', '2017-08-07']"
abstract,"Abstract The effects of sea-surface waves and ocean spray on the marine atmospheric boundary layer (MABL) at different wind speeds and wave ages were investigated. An MABL model was developed that introduces a wave-induced component and spray force to the total surface stress. The theoretical model solution was determined assuming the eddy viscosity coefficient varied linearly with height above the sea surface. The wave-induced component was evaluated using a directional wave spectrum and growth rate. Spray force was described using interactions between ocean-spray droplets and wind-velocity shear. Wind profiles and sea-surface drag coefficients were calculated for low to high wind speeds for wind-generated sea at different wave ages to examine surface-wave and ocean-spray effects on MABL momentum distribution. The theoretical solutions were compared with model solutions neglecting wave-induced stress and/or spray stress. Surface waves strongly affected near-surface wind profiles and sea-surface drag coefficients at low to moderate wind speeds. Drag coefficients and near-surface wind speeds were lower for young than for old waves. At high wind speeds, ocean-spray droplets produced by wind-tearing breaking-wave crests affected the MABL strongly in comparison with surface waves, implying that wave age affects the MABL only negligibly. Low drag coefficients at high wind caused by ocean-spray production increased turbulent stress in the sea-spray generation layer, accelerating near-sea-surface wind. Comparing the analytical drag coefficient values with laboratory measurements and field observations indicated that surface waves and ocean spray significantly affect the MABL at different wind speeds and wave ages."
journal_title,Advances in Atmospheric Sciences
article_title,Atmospheric profiling synthetic observation system in Tibet
keyword,[]
history,"['2018-03', '2018-01-26', '2017-10-16', '2017-11-20', '2017-11-24']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,Erratum to: The Quadrennial Ozone Symposium 2016
keyword,[]
history,"['2018-03', '2018-01-26']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,2017 was the warmest year on record for the global ocean
keyword,[]
history,"['2018-03', '2018-01-26', '2018-01-12', '2018-01-15', '2018-01-16']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,Asymmetric variations in the tropical ascending branches of Hadley circulations and the associated mechanisms and effects
keyword,"['tropical ascending branches\xa0', 'Hadley circulation\xa0', 'asymmetry\xa0', 'SST\xa0', 'trend\xa0', 'variability\xa0', '哈得莱环流\xa0', '热带上升支\xa0', '非对称性\xa0', '海温\xa0', '趋势\xa0', '变率\xa0']"
history,"['2018-03', '2018-01-26', '2017-04-13', '2017-06-14', '2017-06-22']"
abstract,"Abstract This study investigates the variations in the tropical ascending branches (TABs) of Hadley circulations (HCs) during past decades, using a variety of reanalysis datasets. The northern tropical ascending branch (NTAB) and the southern tropical ascending branch (STAB), which are defined as the ascending branches of the Northern Hemisphere HC and Southern Hemisphere HC, respectively, are identified and analyzed regarding their trends and variability. The reanalysis datasets consistently show a persistent increase in STAB during past decades, whereas they show less consistency in NTAB regarding its decadalto multidecadal variability, which generally features a decreasing trend. These asymmetric trends in STAB and NTAB are attributed to asymmetric trends in the tropical SSTs. The relationship between STAB/NTAB and tropical SSTs is further examined regarding their interannual and decadal- to multidecadal variability. On the interannual time scale, the STAB and NTAB are essentially modulated by the eastern-Pacific type of ENSO, with a strengthened (weakened) STAB (NTAB) under an El Niño condition. On the decadal- to multidecadal time scale, the variability of STAB and NTAB is closely related to the southern tropical SSTs and the meridional asymmetry of global tropical SSTs, respectively. The tropical eastern Pacific SSTs (southern tropical SSTs) dominate the tropical SST-NTAB/STAB relationship on the interannual (decadal- to multidecadal) scale, whereas the NTAB is a passive factor in this relationship. Moreover, a cross-hemispheric relationship between the NTAB/STAB and the HC upper-level meridional winds is revealed."
journal_title,Advances in Atmospheric Sciences
article_title,Three-dimensional fusion of spaceborne and ground radar reflectivity data using a neural network-based approach
keyword,"['TRMM PR\xa0', 'ground radar\xa0', '3D fusion\xa0', 'neural network\xa0', '星载测雨雷达\xa0', '地基雷达\xa0', '三维融合\xa0', '神经网络\xa0']"
history,"['2018-03', '2018-01-26', '2016-12-29', '2017-06-15', '2017-06-22']"
abstract,"Abstract The spaceborne precipitation radar onboard the Tropical Rainfall Measuring Mission satellite (TRMM PR) can provide good measurement of the vertical structure of reflectivity, while ground radar (GR) has a relatively high horizontal resolution and greater sensitivity. Fusion of TRMM PR and GR reflectivity data may maximize the advantages from both instruments. In this paper, TRMM PR and GR reflectivity data are fused using a neural network (NN)-based approach. The main steps included are: quality control of TRMM PR and GR reflectivity data; spatiotemporal matchup; GR calibration bias correction; conversion of TRMM PR data from Ku to S band; fusion of TRMM PR and GR reflectivity data with an NN method; interpolation of reflectivity data that are below PR’s sensitivity; blind areas compensation with a distance weighting-based merging approach; combination of three types of data: data with the NN method, data below PR’s sensitivity and data within compensated blind areas. During the NN fusion step, the TRMM PR data are taken as targets of the training NNs, and gridded GR data after horizontal downsampling at different heights are used as the input. The trained NNs are then used to obtain 3D high-resolution reflectivity from the original GR gridded data. After 3D fusion of the TRMM PR and GR reflectivity data, a more complete and finer-scale 3D radar reflectivity dataset incorporating characteristics from both the TRMM PR and GR observations can be obtained. The fused reflectivity data are evaluated based on a convective precipitation event through comparison with the high resolution TRMM PR and GR data with an interpolation algorithm."
journal_title,Advances in Atmospheric Sciences
article_title,Observational study of surface wind along a sloping surface over mountainous terrain during winter
keyword,"['flow separation\xa0', 'gust factor\xa0', 'leeward region\xa0', 'sloping surface\xa0', '气流分离\xa0', '阵风系数\xa0', '背风区\xa0', '坡面\xa0']"
history,"['2018-03', '2018-01-26', '2017-04-04', '2017-06-17', '2017-07-12']"
abstract,"Abstract The 2018 Winter Olympic and Paralympic Games will be held in Pyeongchang, Korea, during February and March. We examined the near surface winds and wind gusts along the sloping surface at two outdoor venues in Pyeongchang during February and March using surface wind data. The outdoor venues are located in a complex, mountainous terrain, and hence the near-surface winds form intricate patterns due to the interplay between large-scale and locally forced winds. During February and March, the dominant wind at the ridge level is westerly; however, a significant wind direction change is observed along the sloping surface at the venues. The winds on the sloping surface are also influenced by thermal forcing, showing increased upslope flow during daytime. When neutral air flows over the hill, the windward and leeward flows show a significantly different behavior. A higher correlation of the wind speed between upper- and lower-level stations is shown in the windward region compared with the leeward region. The strong synoptic wind, small width of the ridge, and steep leeward ridge slope angle provide favorable conditions for flow separation at the leeward foot of the ridge. The gust factor increases with decreasing surface elevation and is larger during daytime than nighttime. A significantly large gust factor is also observed in the leeward region."
journal_title,Advances in Atmospheric Sciences
article_title,Anomalous western Pacific subtropical high during El Niño developing summer in comparison with decaying summer
keyword,"['western Pacific subtropical high\xa0', 'El Niño\xa0', 'developing summer\xa0', 'decaying summer\xa0', 'seasonal march\xa0', '西太平洋副热带高压\xa0', 'El Niño\xa0', '发展年夏季\xa0', '衰减年夏季\xa0', '季节进程\xa0']"
history,"['2018-03', '2018-01-26', '2017-03-06', '2017-05-22', '2017-06-22']"
abstract,"Abstract The anomalous behavior of the western Pacific subtropical high (WPSH) in El Niño developing summer is studied based on the composite results of eight major El Niño events during 1979–2013. It is shown that the WPSH tends to retreat eastwards with weak intensity during the developing summer. The anomaly exhibits an intraseasonal variation with a weaker anomaly in June and July and a stronger anomaly in August, indicating that different underlying physical mechanisms may be responsible for the anomalous WPSH during early and late summer periods. In June and July, owing to the cold advection anomaly characterized as a weak northerly anomaly from high latitudes, geopotential height in East Asia is reduced and the WPSH tends to retreat eastwards slightly. By contrast, enhanced convection over the warm pool in August makes the atmosphere more sensitive to El Niño forcing. Consequently, a cyclonic anomaly in the western Pacific is induced, which is consistent with the seasonal march of atmospheric circulation from July to August. Accordingly, geopotential height in the western Pacific is reduced significantly, and the WPSH tends to retreat eastwards remarkably in August. Different from the developing summer, geopotential height in the decaying summer over East Asia and the western Pacific tends to enhance and extend northwards from June to August consistently, reaching the maximum anomaly in August. Therefore, the seasonal march plays an important role in the WPSH anomaly for both the developing and decaying summer."
journal_title,Advances in Atmospheric Sciences
article_title,Assimilation of Feng-Yun-3B satellite microwave humidity sounder data over land
keyword,"['data assimilation over land\xa0', 'Chinese satellite\xa0', 'FY-3B\xa0', 'Microwave Humidity Sounder\xa0', '陆地上空观测资料同化\xa0', '中国气象卫星\xa0', '风云三号 B 星\xa0', '微波湿度计\xa0']"
history,"['2018-03', '2018-01-26', '2017-04-10', '2017-05-11', '2017-06-22']"
abstract,"Abstract The ECMWF has been assimilating Feng-Yun-3B (FY-3B) satellite microwave humidity sounder (MWHS) data over ocean in an operational forecasting system since 24 September 2014. It is more difficult, however, to assimilate microwave observations over land and sea ice than over the open ocean due to higher uncertainties in land surface temperature, surface emissivity and less effective cloud screening. We compare approaches in which the emissivity is retrieved dynamically from MWHS channel 1 [150 GHz (vertical polarization)] with the use of an evolving emissivity atlas from 89 GHz observations from the MWHS onboard NOAA and EUMETSAT satellites. The assimilation of the additional data over land improves the fit of short-range forecasts to other observations, notably ATMS (Advanced Technology Microwave Sounder) humidity channels, and the forecast impacts are mainly neutral to slightly positive over the first five days. The forecast impacts are better in boreal summer and the Southern Hemisphere. These results suggest that the techniques tested allow for effective assimilation of MWHS/FY-3B data over land."
journal_title,Advances in Atmospheric Sciences
article_title,New method for estimating daily global solar radiation over sloped topography in China
keyword,"['sloped terrain\xa0', 'solar radiation\xa0', 'topography\xa0', 'geographic information system\xa0', '坡地\xa0', '太阳辐射\xa0', '地形\xa0', '地理信息系统\xa0']"
history,"['2018-03', '2018-01-26', '2016-09-19', '2017-01-14', '2017-07-20']"
abstract,"Abstract A new scheme for the estimation of daily global solar radiation over sloped topography in China is developed based on the Iqbal model C and MODIS cloud fraction. The effects of topography are determined using a digital elevation model. The scheme is tested using observations of solar radiation at 98 stations in China, and the results show that the mean absolute bias error is 1.51 MJ m−2 d−1 and the mean relative absolute bias error is 10.57%. Based on calculations using this scheme, the distribution of daily global solar radiation over slopes in China on four days in the middle of each season (15 January, 15 April, 15 July and 15 October 2003) at a spatial resolution of 1 km × 1 km are analyzed. To investigate the effects of topography on global solar radiation, the results determined in four mountains areas (Tianshan, Kunlun Mountains, Qinling, and Nanling) are discussed, and the typical characteristics of solar radiation over sloped surfaces revealed. In general, the new scheme can produce reasonable characteristics of solar radiation distribution at a high spatial resolution in mountain areas, which will be useful in analyses of mountain climate and planning for agricultural production."
journal_title,Advances in Atmospheric Sciences
article_title,Data assimilation method based on the constraints of confidence region
keyword,"['data assimilation\xa0', 'ensemble Kalman filter\xa0', 'error variance inflation\xa0', 'confidence region\xa0', 'Lorenz model\xa0', '数据同化\xa0', '集合 Kalman 滤波\xa0', '误差方差膨胀\xa0', '置信区间\xa0', 'Lorenz 模型\xa0']"
history,"['2018-03', '2018-01-26', '2017-03-05', '2017-06-06', '2017-07-11']"
abstract,"Abstract The ensemble Kalman filter (EnKF) is a distinguished data assimilation method that is widely used and studied in various fields including methodology and oceanography. However, due to the limited sample size or imprecise dynamics model, it is usually easy for the forecast error variance to be underestimated, which further leads to the phenomenon of filter divergence. Additionally, the assimilation results of the initial stage are poor if the initial condition settings differ greatly from the true initial state. To address these problems, the variance inflation procedure is usually adopted. In this paper, we propose a new method based on the constraints of a confidence region constructed by the observations, called EnCR, to estimate the inflation parameter of the forecast error variance of the EnKF method. In the new method, the state estimate is more robust to both the inaccurate forecast models and initial condition settings. The new method is compared with other adaptive data assimilation methods in the Lorenz-63 and Lorenz-96 models under various model parameter settings. The simulation results show that the new method performs better than the competing methods."
journal_title,Advances in Atmospheric Sciences
article_title,Statistics-based optimization of the polarimetric radar hydrometeor classification algorithm and its application for a squall line in South China
keyword,"['dual polarization radar\xa0', 'hydrometeor classification\xa0', 'fuzzy logic scheme\xa0', '双偏振雷达\xa0', '相态识别\xa0', '模糊逻辑\xa0']"
history,"['2018-03', '2018-01-26', '2016-09-16', '2017-07-04', '2017-07-11']"
abstract,"Abstract A modified hydrometeor classification algorithm (HCA) is developed in this study for Chinese polarimetric radars. This algorithm is based on the U.S. operational HCA. Meanwhile, the methodology of statistics-based optimization is proposed including calibration checking, datasets selection, membership functions modification, computation thresholds modification, and effect verification. Zhuhai radar, the first operational polarimetric radar in South China, applies these procedures. The systematic bias of calibration is corrected, the reliability of radar measurements deteriorates when the signal-to-noise ratio is low, and correlation coefficient within the melting layer is usually lower than that of the U.S. WSR-88D radar. Through modification based on statistical analysis of polarimetric variables, the localized HCA especially for Zhuhai is obtained, and it performs well over a one-month test through comparison with sounding and surface observations. The algorithm is then utilized for analysis of a squall line process on 11 May 2014 and is found to provide reasonable details with respect to horizontal and vertical structures, and the HCA results—especially in the mixed rain-hail region—can reflect the life cycle of the squall line. In addition, the kinematic and microphysical processes of cloud evolution and the differences between radar-detected hail and surface observations are also analyzed. The results of this study provide evidence for the improvement of this HCA developed specifically for China."
journal_title,Advances in Atmospheric Sciences
article_title,"Preface to the special issue: Aerosols, clouds, radiation, precipitation, and their interactions"
keyword,[]
history,"['2018-02', '2018-01-10']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,Aerosol microphysical and radiative effects on continental cloud ensembles
keyword,"['aerosol-cloud-radiation interactions\xa0', 'cloud-resolving model\xa0', 'cloud microphysics and macrophysics\xa0', 'precipitation\xa0', '气溶胶-云-辐射相互作用\xa0', '云分辨模式\xa0', '云微物理和宏观物理\xa0', '降水\xa0']"
history,"['2018-02', '2018-01-10', '2017-04-12', '2017-08-07', '2017-08-23']"
abstract,"Abstract Aerosol–cloud–radiation interactions represent one of the largest uncertainties in the current climate assessment. Much of the complexity arises from the non-monotonic responses of clouds, precipitation and radiative fluxes to aerosol perturbations under various meteorological conditions. In this study, an aerosol-aware WRF model is used to investigate the microphysical and radiative effects of aerosols in three weather systems during the March 2000 Cloud Intensive Observational Period campaign at the US Southern Great Plains. Three simulated cloud ensembles include a low-pressure deep convective cloud system, a collection of less-precipitating stratus and shallow cumulus, and a cold frontal passage. The WRF simulations are evaluated by several ground-based measurements. The microphysical properties of cloud hydrometeors, such as their mass and number concentrations, generally show monotonic trends as a function of cloud condensation nuclei concentrations. Aerosol radiative effects do not influence the trends of cloud microphysics, except for the stratus and shallow cumulus cases where aerosol semi-direct effects are identified. The precipitation changes by aerosols vary with the cloud types and their evolving stages, with a prominent aerosol invigoration effect and associated enhanced precipitation from the convective sources. The simulated aerosol direct effect suppresses precipitation in all three cases but does not overturn the aerosol indirect effect. Cloud fraction exhibits much smaller sensitivity (typically less than 2%) to aerosol perturbations, and the responses vary with aerosol concentrations and cloud regimes. The surface shortwave radiation shows a monotonic decrease by increasing aerosols, while the magnitude of the decrease depends on the cloud type."
journal_title,Advances in Atmospheric Sciences
article_title,Cloud condensation nuclei over the Bay of Bengal during the Indian summer monsoon
keyword,"['CTCZ\xa0', 'Bay of Bengal\xa0', 'monsoon\xa0', 'CCN\xa0', 'supersaturation\xa0', 'power-law relationship\xa0', '大陆热带辐合带\xa0', '孟加拉湾\xa0', '季风\xa0', '云凝结核\xa0', '过饱和度\xa0', '幂函数关系\xa0']"
history,"['2018-02', '2018-01-10', '2016-12-28', '2017-03-30', '2017-04-10']"
abstract,"Abstract The first measurements of cloud condensation nuclei (CCN) at five supersaturations were carried out onboard the research vessel “Sagar Kanya” (cruise SK-296) from the south to the head-bay of the Bay of Bengal as part of the Continental Tropical Convergence Zone (CTCZ) Project during the Indian summer monsoon of 2012. In this paper, we assess the diurnal variation in CCN distributions at supersaturations from 0.2% to 1% (in steps of 0.2%) and the power-law fit at supersaturation of 1%. The diurnal pattern shows peaks in CCN concentration (NCCN) at supersaturations from 0.2% to 1% between 0600 and 0700 LST (local standard time, UTC+0530), with relatively low concentrations between 1200 and 1400 LST, followed by a peak at around 1800 LST. The power-law fit for the CCN distribution at different supersaturation levels relates the empirical exponent (k) of supersaturation (%) and the NCCN at a supersaturation of 1%. The NCCN at a supersaturation of 0.4% is observed to vary from 702 cm−3 to 1289 cm−3, with a mean of 961±161 cm−3 (95% confidence interval), representing the CCN activity of marine air masses. Whereas, the mean NCCN of 1628±193 cm−3 at a supersaturation of 1% is higher than anticipated for the marine background. When the number of CCN spectra is 1293, the value of k is 0.57±0.03 (99% confidence interval) and its probability distribution shows cumulative counts significant at k ≈ 0.55±0.25. The results are found to be better at representing the features of the marine environment (103 cm−3 and k ≈ 0.5) and useful for validating CCN closure studies for Indian sea regions."
journal_title,Advances in Atmospheric Sciences
article_title,Aerosol optical properties and radiative impacts in the Pearl River Delta region of China during the dry season
keyword,"['aerosol properties\xa0', 'radiative forcing\xa0', 'Pearl River Delta region\xa0', 'dry season\xa0', '气溶胶特性\xa0', '辐射强迫\xa0', '珠江三角洲区域\xa0', '干季\xa0']"
history,"['2018-02', '2018-01-10', '2017-04-12', '2017-08-17', '2017-09-26']"
abstract,"Abstract Aerosol optical properties and direct radiative effects on surface irradiance were examined using seven years (2006–2012) of Cimel sunphotometer data collected at Panyu—the main atmospheric composition monitoring station in the Pearl River Delta (PRD) region of China. During the dry season (October to February), mean values of the aerosol optical depth (AOD) at 550 nm, the Ångström exponent, and the single scattering albedo at 440 nm (SSA) were 0.54, 1.33 and 0.87, respectively. About 90% of aerosols were dominated by fine-mode strongly absorbing particles. The size distribution was bimodal, with fine-mode particles dominating. The fine mode showed a peak at a radius of 0.12 μm in February and October (∼ 0.10 μm3μm-2). The mean diurnal shortwave direct radiative forcing at the surface, inside the atmosphere (FATM), and at the top of the atmosphere, was −33.4±7.0, 26.1±5.6 and −7.3±2.7Wm−2, respectively. The corresponding mean values of aerosol direct shortwave radiative forcing per AOD were −60.0 ± 7.8, 47.3 ± 8.3 and −12.8 ± 3.1 W m−2, respectively. Moreover, during the study period, FATM showed a significant decreasing trend (p < 0.01) and SSA increased from 0.87 in 2006 to 0.91 in 2012, suggesting a decreasing trend of absorbing particles being released into the atmosphere. Optical properties and radiative impacts of the absorbing particles can be used to improve the accuracy of inversion algorithms for satellite-based aerosol retrievals in the PRD region and to better constrain the climate effect of aerosols in climate models."
journal_title,Advances in Atmospheric Sciences
article_title,Growth rates of fine aerosol particles at a site near Beijing in June 2013
keyword,"['growth rate\xa0', 'fine aerosol particle\xa0', 'Xianghe\xa0', '细颗粒增长速率\xa0', '凝结增长\xa0', '香河站点\xa0', '气溶胶细颗粒物\xa0']"
history,"['2018-02', '2018-01-10', '2017-03-29', '2017-08-01', '2017-08-14']"
abstract,"Abstract Growth of fine aerosol particles is investigated during the Aerosol–CCN–Cloud Closure Experiment campaign in June 2013 at an urban site near Beijing. Analyses show a high frequency (∼ 50%) of fine aerosol particle growth events, and show that the growth rates range from 2.1 to 6.5 nm h−1 with a mean value of ∼ 5.1 nm h−1. A review of previous studies indicates that at least four mechanisms can affect the growth of fine aerosol particles: vapor condensation, intramodal coagulation, extramodal coagulation, and multi-phase chemical reaction. At the initial stage of fine aerosol particle growth, condensational growth usually plays a major role and coagulation efficiency generally increases with particle sizes. An overview of previous studies shows higher growth rates over megacity, urban and boreal forest regions than over rural and oceanic regions. This is most likely due to the higher condensational vapor, which can cause strong condensational growth of fine aerosol particles. Associated with these multiple factors of influence, there are large uncertainties for the aerosol particle growth rates, even at the same location."
journal_title,Advances in Atmospheric Sciences
article_title,Role of microphysical parameterizations with droplet relative dispersion in IAP AGCM 4.1
keyword,"['relative dispersion\xa0', 'effective radius\xa0', 'autoconversion process\xa0', 'global climate models\xa0', '云滴谱离散度\xa0', '云滴有效半径\xa0', '云水自动转化过程\xa0', '全球气候模式\xa0']"
history,"['2018-02', '2018-01-10', '2017-04-13', '2017-08-07', '2017-08-16']"
abstract,"Abstract Previous studies have shown that accurate descriptions of the cloud droplet effective radius (Re) and the autoconversion process of cloud droplets to raindrops (Ar) can effectively improve simulated clouds and surface precipitation, and reduce the uncertainty of aerosol indirect effects in GCMs. In this paper, we implement cloud microphysical schemes including two-moment Ar and Re considering relative dispersion of the cloud droplet size distribution into version 4.1 of the Institute of Atmospheric Physics’s atmospheric GCM (IAP AGCM 4.1), which is the atmospheric component of the Chinese Academy of Sciences’ Earth System Model. Analysis of the effects of different schemes shows that the newly implemented schemes can improve both the simulated shortwave and longwave cloud radiative forcings, as compared to the standard scheme, in IAP AGCM 4.1. The new schemes also effectively enhance the large-scale precipitation, especially over low latitudes, although the influences of total precipitation are insignificant for different schemes. Further studies show that similar results can be found with the Community Atmosphere Model, version 5.1."
journal_title,Advances in Atmospheric Sciences
article_title,Comparison between MODIS-derived day and night cloud cover and surface observations over the North China Plain
keyword,"['cloud cover\xa0', 'MODIS\xa0', 'cloud-top height\xa0', 'cloud optical thickness\xa0', 'aerosol optical depth\xa0', 'view zenith angle\xa0', '云量\xa0', 'MODIS\xa0', '云顶高度\xa0', '云光学厚度\xa0', '气溶胶光学厚度\xa0', '卫星观测角\xa0']"
history,"['2018-02', '2018-01-10', '2017-03-31', '2017-08-14', '2017-10-09']"
abstract,"Abstract Satellite and human visual observation are two of the most important observation approaches for cloud cover. In this study, the total cloud cover (TCC) observed by MODIS onboard the Terra and Aqua satellites was compared with Synop meteorological station observations over the North China Plain and its surrounding regions for 11 years during daytime and 7 years during nighttime. The Synop data were recorded eight times a day at 3-h intervals. Linear interpolation was used to interpolate the Synop data to the MODIS overpass time in order to reduce the temporal deviation between the satellite and Synop observations. Results  showed that MODIS-derived TCC had good consistency with the Synop observations; the correlation coefficients ranged from 0.56 in winter to 0.73 in summer for Terra MODIS, and from 0.55 in winter to 0.71 in summer for Aqua MODIS. However, they also had certain differences. On average, the MODIS-derived TCC was 15.16% higher than the Synop data, and this value was higher at nighttime (15.58%–16.64%) than daytime (12.74%–14.14%). The deviation between the MODIS and Synop TCC had large seasonal variation, being largest in winter (29.53%–31.07%) and smallest in summer (4.46%–6.07%). Analysis indicated that cloud with low cloud-top height and small cloud optical thickness was more likely to cause observation bias. Besides, an increase in the satellite view zenith angle, aerosol optical depth, or snow cover could lead to positively biased MODIS results, and this affect differed among different cloud types."
journal_title,Advances in Atmospheric Sciences
article_title,First surface-based estimation of the aerosol indirect effect over a site in southeastern China
keyword,"['ground-based measurements\xa0', 'aerosol indirect effect\xa0', 'southeastern China\xa0', '地基观测\xa0', '气溶胶间接效应\xa0', '中国东南部\xa0']"
history,"['2018-02', '2018-01-10', '2017-04-24', '2017-08-15', '2017-09-18']"
abstract,"Abstract The deployment of the U.S. Atmospheric Radiation Measurement mobile facility in Shouxian from May to December 2008 amassed the most comprehensive set of measurements of atmospheric, surface, aerosol, and cloud variables in China. This deployment provided a unique opportunity to investigate the aerosol–cloud interactions, which are most challenging and, to date, have not been examined to any great degree in China. The relationship between cloud droplet effective radius (CER) and aerosol index (AI) is very weak in summer because the cloud droplet growth is least affected by the competition for water vapor. Mean cloud liquid water path (LWP) and cloud optical depth (COD) significantly increase with increasing AI in fall. The sensitivities of CER and LWP to aerosol loading increases are not significantly different under different air mass conditions. There is a significant correlation between the changes in hourly mean AI and the changes in hourly mean CER, LWP, and COD. The aerosol first indirect effect (FIE) is estimated in terms of relative changes in both CER (FIECER) and COD (FIECOD) with changes in AI for different seasons and air masses. FIECOD and FIECER are similar in magnitude and close to the typical FIE value of ∼ 0.23, and do not change much between summer and fall or between the two different air mass conditions. Similar analyses were done using spaceborne Moderate Resolution Imaging Spectroradiometer data. The satellite-derived FIE is contrary to the FIE estimated from surface retrievals and may have large uncertainties due to some inherent limitations."
journal_title,Advances in Atmospheric Sciences
article_title,Aerosol properties and their impacts on surface CCN at the ARM Southern Great Plains site during the 2011 Midlatitude Continental Convective Clouds Experiment
keyword,"['aerosol indirect effect\xa0', 'aerosol transport\xa0', 'biomass burning smoke\xa0', '气溶胶间接效应\xa0', '气溶胶输送\xa0', '生物质燃烧烟尘\xa0']"
history,"['2018-02', '2018-01-10', '2017-02-07', '2017-04-07', '2017-05-22']"
abstract,"Abstract Aerosol particles are of particular importance because of their impacts on cloud development and precipitation processes over land and ocean. Aerosol properties as well as meteorological observations from the Department of Energy Atmospheric Radiation Measurement (ARM) platform situated in the Southern Great Plains (SGP) are utilized in this study to illustrate the dependence of continental cloud condensation nuclei (CCN) number concentration (NCCN) on aerosol type and transport pathways. ARM-SGP observations from the 2011 Midlatitude Continental Convective Clouds Experiment field campaign are presented in this study and compared with our previous work during the 2009–10 Clouds, Aerosol, and Precipitation in the Marine Boundary Layer field campaign over the current ARM Eastern North Atlantic site. Northerly winds over the SGP reflect clean, continental conditions with aerosol scattering coefficient (σsp) values less than 20 Mm−1 and NCCN values less than 100 cm−3. However, southerly winds over the SGP are responsible for the observed moderate to high correlation (R) among aerosol loading (σsp < 60 Mm−1) and NCCN, carbonaceous chemical species (biomass burning smoke), and precipitable water vapor. This suggests a common transport mechanism for smoke aerosols and moisture via the Gulf of Mexico, indicating a strong dependence on air mass type. NASA MERRA-2 reanalysis aerosol and chemical data are moderately to highly correlated with surface ARM-SGP data, suggesting that this facility can represent surface aerosol conditions in the SGP, especially during strong aerosol loading events that transport via the Gulf of Mexico. Future long-term investigations will help to understand the seasonal influences of air masses on aerosol, CCN, and cloud properties over land in comparison to over ocean."
journal_title,Advances in Atmospheric Sciences
article_title,Study of aerosol direct and indirect effects and auto-conversion processes over the West African monsoon region using a regional climate model
keyword,"['aerosol\xa0', 'cloud\xa0', 'West African monsoon\xa0', 'auto-conversion\xa0', 'RegCM\xa0', '气溶胶\xa0', '云\xa0', '西非季风\xa0', '云水自动转换\xa0', 'RegCM\xa0']"
history,"['2018-02', '2018-01-10', '2017-04-07', '2017-07-30', '2017-09-05']"
abstract,"Abstract This study assesses the direct and indirect effects of natural and anthropogenic aerosols (e.g., black carbon and sulfate) over West and Central Africa during the West African monsoon (WAM) period (June–July–August). We investigate the impacts of aerosols on the amount of cloudiness, the influences on the precipitation efficiency of clouds, and the associated radiative forcing (direct and indirect). Our study includes the implementation of three new formulations of auto-conversion parameterization [namely, the Beheng (BH), Tripoli and Cotton (TC) and Liu and Daum (R6) schemes] in RegCM4.4.1, besides the default model’s auto-conversion scheme (Kessler). Among the new schemes, BH reduces the precipitation wet bias by more than 50% over West Africa and achieves a bias reduction of around 25% over Central Africa. Results  from detailed sensitivity experiments suggest a significant path forward in terms of addressing the long-standing issue of the characteristic wet bias in RegCM. In terms of aerosol-induced radiative forcing, the impact of the various schemes is found to vary considerably (ranging from −5 to −25 W m−2)."
journal_title,Advances in Atmospheric Sciences
article_title,Climatology of cloud-base height from long-term radiosonde measurements in China
keyword,"['cloud base height\xa0', 'radiosonde\xa0', 'relative humidity\xa0', 'China\xa0', 'climatology\xa0', '云底高度\xa0', '高空探测\xa0', '相对湿度\xa0', '中国\xa0', '气候\xa0']"
history,"['2018-02', '2018-01-10', '2017-04-15', '2017-09-07', '2017-10-09']"
abstract,"Abstract Clouds are critical to the global radiation budget and hydrological cycle, but knowledge is still poor concerning the observed climatology of cloud-base height (CBH) in China. Based on fine-resolution sounding observations from the China Radiosonde Network (CRN), the method used to estimate CBH was modified, and uncertainty analyses indicated that the CBH is good enough. The accuracy of CBH estimation is verified by the comparison between the sounding-derived CBHs and those estimated from the micro-pulse lidar and millimeter-wave cloud radar. As such, the CBH climatology was compiled for the period 2006–16. Overall, the CBH exhibits large geographic variability across China, at both 0800 Local Standard Time (LST) and 2000 LST, irrespective of season. In addition, the summertime cloud base tends to be elevated to higher altitudes in dry regions [i.e., Inner Mongolia and the North China Plain (NCP)]. By comparison, the Tibetan Plateau (TP), Pearl River Delta (PRD) and Sichuan Basin (SCB) have relatively low CBHs (< 2.4 km above ground level). In terms of seasonality, the CBH reaches its maximum in summer and minimum in winter. A low cloud base tends to occur frequently (> 70%) over the TP, PRD and SCB. In contrast, at most sites over the Yangtze River Delta (YRD) and the NCP, about half the cloud belongs to the high-cloud category. The CBH does not exhibit marked diurnal variation in summer, throughout all CRN sites, probably due to the persistent cloud coverage caused by the East Asia Summer Monsson. To the best of our knowledge, this is the first CBH climatology produced from sounding measurements in China, and provides a useful reference for obtaining observational cloud base information."
journal_title,Advances in Atmospheric Sciences
article_title,Can MODIS detect trends in aerosol optical depth over land?
keyword,"['MODIS\xa0', 'AERONET\xa0', 'Aerosol Optical Depth\xa0', 'Mann–Kendall trend test\xa0', 'MODIS\xa0', 'AERONET\xa0', '气溶胶光学厚度\xa0', 'Mann–Kendall 趋势检验\xa0']"
history,"['2018-02', '2018-01-10', '2017-02-17', '2017-07-06', '2017-07-11']"
abstract,"Abstract The Moderate Resolution Imaging Spectroradiometer (MODIS) sensor onboard NASA’s Aqua satellite has been collecting valuable data about the Earth system for more than 14 years, and one of the benefits of this is that it has made it possible to detect the long-term variation in aerosol loading across the globe. However, the long-term aerosol optical depth (AOD) trends derived from MODIS need careful validation and assessment, especially over land. Using AOD products with at least 70 months’ worth of measurements collected during 2002–15 at 53 Aerosol Robotic Network (AERONET) sites over land, Mann–Kendall (MK) trends in AOD were derived and taken as the ground truth data for evaluating the corresponding results from MODIS onboard Aqua. The results showed that the AERONET AOD trends over all sites in Europe and North America, as well as most sites in Africa and Asia, can be reproduced by MODIS/Aqua. However, disagreement in AOD trends between MODIS and AERONET was found at a few sites in Australia and South America. The AOD trends calculated from AERONET instantaneous data at the MODIS overpass times were consistent with those from AERONET daily data, which suggests that the AOD trends derived from satellite measurements of 1–2 overpasses may be representative of those from daily measurements."
journal_title,Advances in Atmospheric Sciences
article_title,Preface to the special issue: Towards improving understanding and prediction of Arctic change and its linkage with Eurasian mid-latitude weather and climate
keyword,[]
history,"['2018-01', '2017-12-07']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,"Teleconnection between sea ice in the Barents Sea in June and the Silk Road, Pacific–Japan and East Asian rainfall patterns in August"
keyword,"['sea-ice reduction\xa0', 'tripole rainfall\xa0', 'Silk Road pattern\xa0', 'Pacific–Japan pattern\xa0', 'teleconnection\xa0', '海冰减少\xa0', '三极子型降水\xa0', '丝绸之路型\xa0', '太平洋-日本遥相关型\xa0', '遥相关\xa0']"
history,"['2018-01', '2017-12-07', '2017-02-01', '2017-05-31', '2017-06-22']"
abstract,"Abstract In contrast to previous studies that have tended to focus on the influence of the total Arctic sea-ice cover on the East Asian summer tripole rainfall pattern, the present study identifies the Barents Sea as the key region where the June sea-ice variability exerts the most significant impacts on the East Asian August tripole rainfall pattern, and explores the teleconnection mechanisms involved. The results reveal that a reduction in June sea ice excites anomalous upward air motion due to strong near-surface thermal forcing, which further triggers a meridional overturning wave-like pattern extending to midlatitudes. Anomalous downward motion therefore forms over the Caspian Sea, which in turn induces zonally oriented overturning circulation along the subtropical jet stream, exhibiting the east–west Rossby wave train known as the Silk Road pattern. It is suggested that the Bonin high, a subtropical anticyclone predominant near South Korea, shows a significant anomaly due to the eastward extension of the Silk Road pattern to East Asia. As a possible descending branch of the Hadley cell, the Bonin high anomaly ultimately triggers a meridional overturning, establishing the Pacific–Japan pattern. This in turn induces an anomalous anticyclone and cyclone pair over East Asia, and a tripole vertical convection anomaly meridionally oriented over East Asia. Consequently, a tripole rainfall anomaly pattern is observed over East Asia. Results  from numerical experiments using version 5 of the Community Atmosphere Model support the interpretation of this chain of events."
journal_title,Advances in Atmospheric Sciences
article_title,Record low sea-ice concentration in the central Arctic during summer 2010
keyword,"['sea ice concentration\xa0', 'central Arctic\xa0', 'Beaufort Gyre\xa0', 'Transpolar Drift\xa0', 'ice motion\xa0', 'divergence\xa0', '海冰密集度\xa0', '北极中央区\xa0', '波弗特流涡\xa0', '北极穿极流\xa0', '海冰运动\xa0', '海冰漂移辐散\xa0']"
history,"['2018-01', '2017-12-07', '2017-03-24', '2017-08-04', '2017-09-05']"
abstract,"Abstract The Arctic sea-ice extent has shown a declining trend over the past 30 years. Ice coverage reached historic minima in 2007 and again in 2012. This trend has recently been assessed to be unique over at least the last 1450 years. In the summer of 2010, a very low sea-ice concentration (SIC) appeared at high Arctic latitudes—even lower than that of surrounding pack ice at lower latitudes. This striking low ice concentration—referred to here as a record low ice concentration in the central Arctic (CARLIC)—is unique in our analysis period of 2003–15, and has not been previously reported in the literature. The CARLIC was not the result of ice melt, because sea ice was still quite thick based on in-situ ice thickness measurements. Instead, divergent ice drift appears to have been responsible for the CARLIC. A high correlation between SIC and wind stress curl suggests that the sea ice drift during the summer of 2010 responded strongly to the regional wind forcing. The drift trajectories of ice buoys exhibited a transpolar drift in the Atlantic sector and an eastward drift in the Pacific sector, which appeared to benefit the CARLIC in 2010. Under these conditions, more solar energy can penetrate into the open water, increasing melt through increased heat flux to the ocean. We speculate that this divergence of sea ice could occur more often in the coming decades, and impact on hemispheric SIC and feed back to the climate."
journal_title,Advances in Atmospheric Sciences
article_title,Using NWP to assess the influence of the Arctic atmosphere on midlatitude weather and climate
keyword,"['Arctic\xa0', 'atmosphere\xa0', 'relaxation\xa0', 'northern midlatitudes\xa0', 'linkage\xa0', 'model\xa0', '北极\xa0', '大气\xa0', '松弛系数\xa0', '北半球中纬度\xa0', '关联\xa0', '模式\xa0']"
history,"['2018-01', '2017-12-07', '2016-11-29', '2017-03-16', '2017-04-20']"
abstract,"Abstract The influence of the Arctic atmosphere on Northern Hemisphere midlatitude tropospheric weather and climate is explored by comparing the skill of two sets of 14-day weather forecast experiments using the ECMWF model with and without relaxation of the Arctic atmosphere towards ERA-Interim reanalysis data during the integration. Two pathways are identified along which the Arctic influences midlatitude weather: a pronounced one over Asia and Eastern Europe, and a secondary one over North America. In general, linkages are found to be strongest (weakest) during boreal winter (summer) when the amplitude of stationary planetary waves over the Northern Hemisphere is strongest (weakest). No discernible Arctic impact is found over the North Atlantic and North Pacific region, which is consistent with predominantly southwesterly flow. An analysis of the flow-dependence of the linkages shows that anomalous northerly flow conditions increase the Arctic influence on midlatitude weather over the continents. Specifically, an anomalous northerly flow from the Kara Sea towards West Asia leads to cold surface temperature anomalies not only over West Asia but also over Eastern and Central Europe. Finally, the results of this study are discussed in the light of potential midlatitude benefits of improved Arctic prediction capabilities."
journal_title,Advances in Atmospheric Sciences
article_title,Remarkable link between projected uncertainties of Arctic sea-ice decline and winter Eurasian climate
keyword,"['Arctic climate\xa0', 'Siberian high\xa0', 'Icelandic low\xa0', 'three-cell meridional circulation\xa0', '北极气候\xa0', '西伯利亚高压\xa0', '冰岛低压\xa0', '三圈环流\xa0']"
history,"['2018-01', '2017-12-07', '2017-06-22', '2017-09-14', '2017-09-26']"
abstract,"Abstract We identify that the projected uncertainty of the pan-Arctic sea-ice concentration (SIC) is strongly coupled with the Eurasian circulation in the boreal winter (December–March; DJFM), based on a singular value decomposition (SVD) analysis of the forced response of 11 CMIP5 models. In the models showing a stronger sea-ice decline, the Polar cell becomes weaker and there is an anomalous increase in the sea level pressure (SLP) along 60°N, including the Urals–Siberia region and the Iceland low region. There is an accompanying weakening of both the midlatitude westerly winds and the Ferrell cell, where the SVD signals are also related to anomalous sea surface temperature warming in the midlatitude North Atlantic. In the Mediterranean region, the anomalous circulation response shows a decreasing SLP and increasing precipitation. The anomalous SLP responses over the Euro-Atlantic region project on to the negative North Atlantic Oscillation–like pattern. Altogether, pan-Arctic SIC decline could strongly impact the winter Eurasian climate, but we should be cautious about the causality of their linkage."
journal_title,Advances in Atmospheric Sciences
article_title,Modulation of the Aleutian–Icelandic low seesaw and its surface impacts by the Atlantic Multidecadal Oscillation
keyword,"['Aleutian–Icelandic low seesaw\xa0', 'Atlantic Multidecadal Oscillation\xa0', 'Pacific–North America–Atlantic pattern\xa0', 'stratospheric polar vortex\xa0', '阿留申–冰岛低压振荡\xa0', '北大西洋年代际振荡\xa0', '太平洋–北美–大西洋遥相关型\xa0', '平流层极涡\xa0']"
history,"['2018-01', '2017-12-07', '2017-02-01', '2017-05-30', '2017-06-22']"
abstract,"Abstract Early studies suggested that the Aleutian–Icelandic low seesaw (AIS) features multidecadal variation. In this study, the multidecadal modulation of the AIS and associated surface climate by the Atlantic Multidecadal Oscillation (AMO) during late winter (February–March) is explored with observational data. It is shown that, in the cold phase of the AMO (AMO|−), a clear AIS is established, while this is not the case in the warm phase of the AMO (AMO|+). The surface climate over Eurasia is significantly influenced by the AMO’s modulation of the Aleutian low (AL). For example, the weak AL in AMO|− displays warmer surface temperatures over the entire Far East and along the Russian Arctic coast and into Northern Europe, but only over the Russian Far East in AMO|+. Similarly, precipitation decreases over central Europe with the weak AL in AMO|−, but decreases over northern Europe and increases over southern Europe in AMO|+.The mechanism underlying the influence of AMO|− on the AIS can be described as follows: AMO|− weakens the upward component of the Eliassen–Palm flux along the polar waveguide by reducing atmospheric blocking occurrence over the Euro–Atlantic sector, and hence drives an enhanced stratospheric polar vortex. With the intensified polar night jet, the wave trains originating over the central North Pacific can propagate horizontally through North America and extend into the North Atlantic, favoring an eastward-extended Pacific–North America–Atlantic pattern, and resulting in a significant AIS at the surface during late winter."
journal_title,Advances in Atmospheric Sciences
article_title,Precursor role of winter sea-ice in the Labrador Sea for following-spring precipitation over southeastern North America and western Europe
keyword,"['winter Labrador sea ice\xa0', 'spring precipitation\xa0', 'air-sea interaction\xa0', '前兆因子\xa0', '拉布拉多海冬季海冰\xa0', '西欧和北美春季降水异常\xa0']"
history,"['2018-01', '2017-12-07', '2016-12-09', '2017-06-24', '2017-07-07']"
abstract,"Abstract The role of winter sea-ice in the Labrador Sea as a precursor for precipitation anomalies over southeastern North America and Western Europe in the following spring is investigated. In general terms, as the sea ice increases, the precipitation also increases. In more detail, however, analyses indicate that both the winter sea-ice and the sea surface temperature (SST) anomalies related to increases in winter sea-ice in the Labrador Sea can persist into the following spring. These features play a forcing role in the spring atmosphere, which may be the physical mechanism behind the observational relationship between the winter sea-ice and spring precipitation anomalies. The oceanic forcings in spring include Arctic sea-ice anomalies and SST anomalies in the tropical Pacific and high-latitude North Atlantic. Multi-model Coupled Model Intercomparison Project Phase 5 and Atmospheric Model Intercomparison Project simulation results show that the atmospheric circulation response to the combination of sea-ice and SST is similar to that observed, which suggests that the oceanic forcings are indeed the physical reason for the enhanced spring precipitation. Sensitivity experiments conducted using an atmospheric general circulation model indicate that the increases in precipitation over southeastern North America are mainly attributable to the effect of the SST anomalies, while the increases overWestern Europe are mainly due to the sea-ice anomalies. Although model simulations reveal that the SST anomalies play the primary role in the precipitation anomalies over southeastern North America, the observational statistical analyses indicate that the area of sea-ice in the Labrador Sea seems to be the precursor that best predicts the spring precipitation anomaly."
journal_title,Advances in Atmospheric Sciences
article_title,Recent increased warming of the Alaskan marine Arctic due to midlatitude linkages
keyword,"['Alaska\xa0', 'North Pacific\xa0', 'Arctic\xa0', 'warm advection\xa0', 'polar vortex\xa0', '阿拉斯加\xa0', '北太平洋\xa0', '北极\xa0', '暖平流\xa0', '极地涡旋\xa0']"
history,"['2018-01', '2017-12-07', '2017-01-29', '2017-07-15', '2017-08-03']"
abstract,"Abstract Alaskan Arctic waters have participated in hemispheric-wide Arctic warming over the last two decades at over two times the rate of global warming. During 2008–13, this relative warming occurred only north of the Bering Strait and the atmospheric Arctic front that forms a north–south thermal barrier. This front separates the southeastern Bering Sea temperatures from Arctic air masses. Model projections show that future temperatures in the Chukchi and Beaufort seas continue to warm at a rate greater than the global rate, reaching a change of +4°C by 2040 relative to the 1981–2010 mean. Offshore at 74°N, climate models project the open water duration season to increase from a current average of three months to five months by 2040. These rates are occasionally enhanced by midlatitude connections. Beginning in August 2014, additional Arctic warming was initiated due to increased SST anomalies in the North Pacific and associated shifts to southerly winds over Alaska, especially in winter 2015–16. While global warming and equatorial teleconnections are implicated in North Pacific SSTs, the ending of the 2014–16 North Pacific warm event demonstrates the importance of internal, chaotic atmospheric natural variability on weather conditions in any given year. Impacts from global warming on Alaskan Arctic temperature increases and sea-ice and snow loss, with occasional North Pacific support, are projected to continue to propagate through the marine ecosystem in the foreseeable future. The ecological and societal consequences of such changes show a radical departure from the current Arctic environment."
journal_title,Advances in Atmospheric Sciences
article_title,Changing spring phenology dates in the Three-Rivers Headwater Region of the Tibetan Plateau during 1960–2013
keyword,"['start of growing season\xa0', 'normalized difference vegetation index\xa0', 'spring minimum temperature\xa0', 'Three-Rivers Headwater Region\xa0', 'Arctic Oscillation\xa0', '生长季开始日\xa0', '归一化植被指数\xa0', '春季最低温度\xa0', '三江源\xa0', '北极涛动\xa0']"
history,"['2018-01', '2017-12-07', '2016-12-01', '2017-06-09', '2017-08-14']"
abstract,"Abstract The variation of the vegetation growing season in the Three-Rivers Headwater Region of the Tibetan Plateau has recently become a controversial topic. One issue is that the estimated local trend in the start of the vegetation growing season (SOS) based on remote sensing data is easily affected by outliers because this data series is short. In this study, we determine that the spring minimum temperature is the most influential factor for SOS. The significant negative linear relationship between the two variables in the region is evaluated using Moderate Resolution Imaging Spectroradiometer–Normalized Difference Vegetation Index data for 2000–13. We then reconstruct the SOS time series based on the temperature data for 1960–2013. The regional mean SOS shows an advancing trend of 1.42 d (10 yr)−1 during 1960–2013, with the SOS occurring on the 160th and 151st days in 1960 and 2013, respectively. The advancing trend enhances to 6.04 d (10 yr)−1 during the past 14 years. The spatiotemporal variations of the reconstructed SOS data are similar to those deduced from remote sensing data during the past 14 years. The latter exhibit an even larger regional mean trend of SOS [7.98 d (10 yr−1)] during 2000–13. The Arctic Oscillation is found to have significantly influenced the changing SOS, especially for the eastern part of the region, during 2000–13."
journal_title,Advances in Atmospheric Sciences
article_title,Simulations of Eurasian winter temperature trends in coupled and uncoupled CFSv2
keyword,"['Eurasian winter climate\xa0', 'sea-ice loss\xa0', 'SST increase\xa0', 'CFSv2\xa0', '欧亚冬季气候\xa0', '海冰减少\xa0', '海温增加\xa0', 'NCEP第2代气候预测系统\xa0']"
history,"['2018-01', '2017-12-07', '2016-11-30', '2017-05-18', '2017-06-16']"
abstract,"Abstract Conflicting results have been presented regarding the link between Arctic sea-ice loss and midlatitude cooling, particularly over Eurasia. This study analyzes uncoupled (atmosphere-only) and coupled (ocean–atmosphere) simulations by the Climate Forecast System, version 2 (CFSv2), to examine this linkage during the Northern Hemisphere winter, focusing on the simulation of the observed surface cooling trend over Eurasia during the last three decades. The uncoupled simulations are Atmospheric Model Intercomparison Project (AMIP) runs forced with mean seasonal cycles of sea surface temperature (SST) and sea ice, using combinations of SST and sea ice from different time periods to assess the role that each plays individually, and to assess the role of atmospheric internal variability. Coupled runs are used to further investigate the role of internal variability via the analysis of initialized predictions and the evolution of the forecast with lead time.The AMIP simulations show a mean warming response over Eurasia due to SST changes, but little response to changes in sea ice. Individual runs simulate cooler periods over Eurasia, and this is shown to be concurrent with a stronger Siberian high and warming over Greenland. No substantial differences in the variability of Eurasian surface temperatures are found between the different model configurations. In the coupled runs, the region of significant warming over Eurasia is small at short leads, but increases at longer leads. It is concluded that, although the models have some capability in highlighting the temperature variability over Eurasia, the observed cooling may still be a consequence of internal variability."
journal_title,Advances in Atmospheric Sciences
article_title,Atmospheric precursors of and response to anomalous Arctic sea ice in CMIP5 models
keyword,"['sea ice–atmosphere coupling\xa0', 'stratosphere–troposphere coupling\xa0', 'atmospheric circulation\xa0', 'Eurasian climate\xa0', '海冰-大气耦合\xa0', '平流层对流层相互作用\xa0', '大气环流\xa0', '欧亚气候\xa0']"
history,"['2018-01', '2017-12-07', '2017-02-20', '2017-08-09', '2017-08-14']"
abstract,"Abstract This study examines pre-industrial control simulations from CMIP5 climate models in an effort to better understand the complex relationships between Arctic sea ice and the stratosphere, and between Arctic sea ice and cold winter temperatures over Eurasia. We present normalized regressions of Arctic sea-ice area against several atmospheric variables at extended lead and lag times. Statistically significant regressions are found at leads and lags, suggesting both atmospheric precursors of, and responses to, low sea ice; but generally, the regressions are stronger when the atmosphere leads sea ice, including a weaker polar stratospheric vortex indicated by positive polar cap height anomalies. Significant positive midlatitude eddy heat flux anomalies are also found to precede low sea ice. We argue that low sea ice and raised polar cap height are both a response to this enhanced midlatitude eddy heat flux. The so-called “warm Arctic, cold continents” anomaly pattern is present one to two months before low sea ice, but is absent in the months following low sea ice, suggesting that the Eurasian cooling and low sea ice are driven by similar processes. Lastly, our results suggest a dependence on the geographic region of low sea ice, with low Barents–Kara Sea ice correlated with a weakened polar stratospheric vortex, whilst low Sea of Okhotsk ice is correlated with a strengthened polar vortex. Overall, the results support a notion that the sea ice, polar stratospheric vortex and Eurasian surface temperatures collectively respond to large-scale changes in tropospheric circulation."
journal_title,Advances in Atmospheric Sciences
article_title,Link between the Barents Oscillation and recent boreal winter cooling over the Asian midlatitudes
keyword,"['climate change\xa0', 'Barents Oscillation\xa0', 'winter cooling\xa0', '气候变化\xa0', '巴伦支震荡\xa0', '冬季变冷\xa0']"
history,"['2018-01', '2017-12-07', '2017-01-10', '2017-05-17', '2017-06-16']"
abstract,"Abstract The link between boreal winter cooling over the midlatitudes of Asia and the Barents Oscillation (BO) since the late 1980s is discussed in this study, based on five datasets. Results  indicate that there is a large-scale boreal winter cooling during 1990–2015 over the Asian midlatitudes, and that it is a part of the decadal oscillations of long-term surface air temperature (SAT) anomalies. The SAT anomalies over the Asian midlatitudes are significantly correlated with the BO in boreal winter. When the BO is in its positive phase, anomalously high sea level pressure over the Barents region, with a clockwise wind anomaly, causes cold air from the high latitudes to move over the midlatitudes of Asia, resulting in anomalous cold conditions in that region. Therefore, the recent increasing trend of the BO has contributed to recent winter cooling over the Asian midlatitudes."
journal_title,Advances in Atmospheric Sciences
article_title,Role of extratropical cyclones in the recently observed increase in poleward moisture transport into the Arctic Ocean
keyword,"['atmospheric moisture transport\xa0', 'cyclone activity\xa0', 'atmospheric circulation\xa0', 'Arctic\xa0', 'climate change\xa0', '大气水汽输送\xa0', '气旋活动\xa0', '大气环流\xa0', '北极\xa0', '气候变化\xa0']"
history,"['2018-01', '2017-12-07', '2017-05-05', '2017-10-14', '2017-10-17']"
abstract,"Abstract Poleward atmospheric moisture transport (AMT) into the Arctic Ocean can change atmospheric moisture or water vapor content and cause cloud formation and redistribution, which may change downward longwave radiation and, in turn, surface energy budgets, air temperatures, and sea-ice production and melt. In this study, we found a consistently enhanced poleward AMT across 60°N since 1959 based on the NCAR–NCEP reanalysis. Regional analysis demonstrates that the poleward AMT predominantly occurs over the North Atlantic and North Pacific regions, contributing about 57% and 32%, respectively, to the total transport. To improve our understanding of the driving force for this enhanced poleward AMT, we explored the role that extratropical cyclone activity may play. Climatologically, about 207 extratropical cyclones move across 60°N into the Arctic Ocean each year, among which about 66 (32% of the total) and 47 (23%) originate from the North Atlantic and North Pacific Ocean, respectively. When analyzing the linear trends of the time series constructed by using a 20-year running window, we found a positive correlation of 0.70 between poleward yearly AMT and the integrated cyclone activity index (measurement of cyclone intensity, number, and duration). This shows the consistent multidecadal changes between these two parameters and may suggest cyclone activity plays a driving role in the enhanced poleward AMT. Furthermore, a composite analysis indicates that intensification and poleward extension of the Icelandic low and accompanying strengthened cyclone activity play an important role in enhancing poleward AMT over the North Atlantic region."
journal_title,Advances in Atmospheric Sciences
article_title,Effects of wind fences on the wind environment around Jang Bogo Antarctic Research Station
keyword,"['Jang Bogo Antarctic Research Station\xa0', 'CFD model\xa0', 'observation environment\xa0', 'wind fence\xa0', 'porosity\xa0', '南极张保皋科考站\xa0', '计算流体力学(CFD)模式\xa0', '观测环境\xa0', '防风栅栏\xa0', '孔隙度\xa0']"
history,"['2017-12', '2017-11-08', '2016-12-29', '2017-05-22', '2017-06-02']"
abstract,"Abstract This study investigated the flow characteristics altered by Jang Bogo Antarctic Research Station using computational fluid dynamics (CFD) modeling. The topography and buildings around Jang Bogo Station were constructed with computer-aided-design data in the CFD model domain. We simulated 16 cases with different inflow directions, and compared the flow characteristics with and without Jang Bogo Station for each inflow direction. The wind data recorded by the site’s automatic weather station (AWS) were used for comparison. Wind rose analysis showed that the wind speed and direction after the construction of Jang Bogo Station were quite different from those before construction. We also investigated how virtual wind fences would modify the flow patterns, changing the distance of the fence from the station as well as the porosity of the fence. For westerly inflows, when the AWS was downwind of Jang Bogo Station, the decrease in wind speed was maximized (−81% for west-northwesterly). The wind speed reduction was also greater as the distance of the fence was closer to Jang Bogo Station. With the same distance, the fence with medium porosity (25%–33%) maximized the wind speed reduction. These results suggest that the location and material of the wind fence should be selected carefully, or AWS data should be interpreted cautiously, for particular prevailing wind directions."
journal_title,Advances in Atmospheric Sciences
article_title,Contrasting the skills and biases of deterministic predictions for the two types of El Niño
keyword,"['ENSO\xa0', 'EP El Niño\xa0', 'CP El Niño\xa0', 'prediction skill\xa0', 'systematic bias\xa0', 'spring prediction barrier\xa0', 'ENSO\xa0', 'EP El Niño\xa0', 'CP El Niño\xa0', '预测能力\xa0', '偏差\xa0', '春季预报障碍\xa0']"
history,"['2017-12', '2017-11-08', '2017-01-03', '2017-05-13', '2017-06-21']"
abstract,"Abstract The tropical Pacific has begun to experience a new type of El Niño, which has occurred particularly frequently during the last decade, referred to as the central Pacific (CP) El Niño. Various coupled models with different degrees of complexity have been used to make real-time El Niño predictions, but high uncertainty still exists in their forecasts. It remains unknown as to how much of this uncertainty is specifically related to the new CP-type El Niño and how much is common to both this type and the conventional Eastern Pacific (EP)-type El Niño. In this study, the deterministic performance of an El Niño–Southern Oscillation (ENSO) ensemble prediction system is examined for the two types of El Niño. Ensemble hindcasts are run for the nine EP El Niño events and twelve CP El Niño events that have occurred since 1950. The results show that (1) the skill scores for the EP events are significantly better than those for the CP events, at all lead times; (2) the systematic forecast biases come mostly from the prediction of the CP events; and (3) the systematic error is characterized by an overly warm eastern Pacific during the spring season, indicating a stronger spring prediction barrier for the CP El Niño. Further improvements to coupled atmosphere–ocean models in terms of CP El Niño prediction should be recognized as a key and high-priority task for the climate prediction community."
journal_title,Advances in Atmospheric Sciences
article_title,A high-order spatiotemporal precision-matching Taylor–Li scheme for time-dependent problems
keyword,"['Taylor–Li scheme\xa0', 'high-order scheme\xa0', 'Burgers’ equation\xa0', 'Taylor-Li格式\xa0', '高阶算法\xa0', 'Burgers方程\xa0']"
history,"['2017-12', '2017-11-08', '2017-02-18', '2017-05-31', '2017-06-02']"
abstract,"Abstract Based on the Taylor series method and Li’s spatial differential method, a high-order hybrid Taylor–Li scheme is proposed. The results of a linear advection equation indicate that, using the initial values of the square-wave type, a result with third-order accuracy occurs. However, using initial values associated with the Gaussian function type, a result with very high precision appears. The study demonstrates that, when the order of the time integral is more than three, the corresponding optimal spatial difference order could be higher than six. The results indicate that the reason for why there is no improvement related to an order of spatial difference above six is the use of a time integral scheme that is not high enough. The author also proposes a recursive differential method to improve the Taylor–Li scheme’s computation speed. A more rapid and high-precision program than direct computation of the high-order space differential item is employed, and the computation speed is dramatically boosted. Based on a multiple-precision library, the ultrahigh-order Taylor–Li scheme can be used to solve the advection equation and Burgers’ equation."
journal_title,Advances in Atmospheric Sciences
article_title,Sensitivity of potential evapotranspiration estimation to the Thornthwaite and Penman–Monteith methods in the study of global drylands
keyword,"['potential evapotranspiration\xa0', 'global drylands\xa0', 'Thornthwaite\xa0', 'Penman–Monteith\xa0', '潜在蒸散发\xa0', '全球干旱区\xa0', 'Thornthwaite方法\xa0', 'Penman–Monteith方法\xa0']"
history,"['2017-12', '2017-11-08', '2016-12-19', '2017-04-28', '2017-06-16']"
abstract,"Abstract Drylands are among those regions most sensitive to climate and environmental changes and human-induced perturbations. The most widely accepted definition of the term dryland is a ratio, called the Surface Wetness Index (SWI), of annual precipitation to potential evapotranspiration (PET) being below 0.65. PET is commonly estimated using the Thornthwaite (PET Th) and Penman–Monteith equations (PET PM). The present study compared spatiotemporal characteristics of global drylands based on the SWI with PET Th and PET PM. Results  showed vast differences between PET Th and PET PM; however, the SWI derived from the two kinds of PET showed broadly similar characteristics in the interdecadal variability of global and continental drylands, except in North America, with high correlation coefficients ranging from 0.58 to 0.89. It was found that, during 1901–2014, global hyper-arid and semi-arid regions expanded, arid and dry sub-humid regions contracted, and drylands underwent interdecadal fluctuation. This was because precipitation variations made major contributions, whereas PET changes contributed to a much lesser degree. However, distinct differences in the interdecadal variability of semi-arid and dry sub-humid regions were found. This indicated that the influence of PET changes was comparable to that of precipitation variations in the global dry–wet transition zone. Additionally, the contribution of PET changes to the variations in global and continental drylands gradually enhanced with global warming, and the Thornthwaite method was found to be increasingly less applicable under climate change."
journal_title,Advances in Atmospheric Sciences
article_title,Understanding the surface temperature cold bias in CMIP5 AGCMs over the Tibetan Plateau
keyword,"['surface temperature\xa0', 'cold bias\xa0', 'CMIP5\xa0', 'AMIP\xa0', 'Tibetan Plateau\xa0', 'surface energy budget\xa0', '地表温度\xa0', '冷偏差\xa0', 'CMIP5\xa0', 'AMIP\xa0', '青藏高原\xa0', '地表能量平衡\xa0']"
history,"['2017-12', '2017-11-08', '2016-12-21', '2017-06-02', '2017-06-05']"
abstract,"Abstract The temperature biases of 28 CMIP5 AGCMs are evaluated over the Tibetan Plateau (TP) for the period 1979–2005. The results demonstrate that the majority of CMIP5 models underestimate annual and seasonal mean surface 2-m air temperatures (Tas) over the TP. In addition, the ensemble of the 28 AGCMs and half of the individual models underestimate annual mean skin temperatures (Ts) over the TP. The cold biases are larger in Tas than in Ts, and are larger over the western TP. By decomposing the Ts bias using the surface energy budget equation, we investigate the contributions to the cold surface temperature bias on the TP from various factors, including the surface albedo-induced bias, surface cloud radiative forcing, clear-sky shortwave radiation, clear-sky downward longwave radiation, surface sensible heat flux, latent heat flux, and heat storage. The results show a suite of physically interlinked processes contributing to the cold surface temperature bias. Strong negative surface albedo-induced bias associated with excessive snow cover and the surface heat fluxes are highly anticorrelated, and the cancelling out of these two terms leads to a relatively weak contribution to the cold bias. Smaller surface turbulent fluxes lead to colder lower-tropospheric temperature and lower water vapor content, which in turn cause negative clear-sky downward longwave radiation and cold bias. The results suggest that improvements in the parameterization of the area of snow cover, as well as the boundary layer, and hence surface turbulent fluxes, may help to reduce the cold bias over the TP in the models."
journal_title,Advances in Atmospheric Sciences
article_title,Multiyear observations of deposition-mode ice nucleating particles at two high-altitude stations in India
keyword,"['ice nuclei\xa0', 'diffusion chamber\xa0', 'aerosol\xa0', 'high-altitude observation\xa0', '冰核\xa0', '扩散云室\xa0', '气溶胶\xa0', '高海拔观测\xa0']"
history,"['2017-12', '2017-11-08', '2017-03-09', '2017-05-19', '2017-06-22']"
abstract,"Abstract Ice nucleating particle (INP) measurements were made at two high-altitude stations in India. Aerosols collected on filter paper at Girawali Observatory, Inter University Center for Astronomy & Astrophysics (IGO), and at the Radio Astronomy Center, Ooty (RAC), were activated in deposition mode using a thermal gradient diffusion chamber to determine the INP concentrations. The measurement campaigns at IGO were conducted during 2011, 2013 and 2014, and at RAC during 2013 and 2014. When the aerosol samples were exposed to an ice supersaturation of between 5% and 23% in the temperature range −17.6°C to −22°C, the maximum INP number concentration at IGO and RAC was 1.0 L−1 and 1.6 L−1, respectively. A maximum correlation coefficient of 0.76 was observed between the INP number concentration and ice supersaturation. The airmass trajectories analyzed for the measurement campaigns showed that the Arabian Desert and arid regions were the main INP contributors. Elemental analysis of particles showed the presence of Na, Cl, Si, Al, Fe, Cu, Co, Cd, S, Mn and K, as well as some rare-Earth elements like Mo, Ru, La, Ce, V and Zr. When aerosols in the size range 0.5–20 μm were considered, the fraction that acted as INPs was 1: 104 to 1: 106 at IGO, and 1: 103 to 1: 104 at RAC. The higher ratio of INPs to aerosols at RAC than IGO may be attributable to the presence of rare-Earth elements observed in the aerosol samples at RAC, which were absent at IGO."
journal_title,Advances in Atmospheric Sciences
article_title,The tropical Pacific–Indian Ocean associated mode simulated by LICOM2.0
keyword,"['ocean general circulation model\xa0', 'numerical simulation\xa0', 'tropical Pacific–Indian Ocean associated mode\xa0', 'subsurface ocean temperature anomaly\xa0', '大洋环流模式\xa0', '数值模拟\xa0', '热带太平洋-印度洋联合模\xa0', '次表层海温异常\xa0']"
history,"['2017-12', '2017-11-08', '2017-01-05', '2017-06-07', '2017-06-16']"
abstract,"Abstract Oceanic general circulation models have become an important tool for the study of marine status and change. This paper reports a numerical simulation carried out using LICOM2.0 and the forcing field from CORE. When compared with SODA reanalysis data and ERSST.v3b data, the patterns and variability of the tropical Pacific–Indian Ocean associated mode (PIOAM) are reproduced very well in this experiment. This indicates that, when the tropical central–western Indian Ocean and central–eastern Pacific are abnormally warmer/colder, the tropical eastern Indian Ocean and western Pacific are correspondingly colder/warmer. This further confirms that the tropical PIOAM is an important mode that is not only significant in the SST anomaly field, but also more obviously in the subsurface ocean temperature anomaly field. The surface associated mode index (SAMI) and the thermocline (i.e., subsurface) associated mode index (TAMI) calculated using the model output data are both consistent with the values of these indices derived from observation and reanalysis data. However, the model SAMI and TAMI are more closely and synchronously related to each other."
journal_title,Advances in Atmospheric Sciences
article_title,Microphysical processes of a stratiform precipitation event over eastern China: analysis using micro rain radar data
keyword,"['drop size distribution\xa0', 'micro rain radar\xa0', 'bright band\xa0', 'microphysical processes\xa0', '雨滴谱\xa0', '微降水雷达\xa0', '零度层亮带\xa0', '微物理过程\xa0']"
history,"['2017-12', '2017-11-08', '2017-01-11', '2017-05-03', '2017-06-06']"
abstract,"Abstract Data collected using the micro rain radar (MRR) situated in Jinan city, eastern China, were used to explore the altitudinal and temporal evolution of rainfall microphysical characteristics, and to analyze the bright band (BB) characteristics and hydrometeor classification. Specifically, a low-intensity and stable stratiform precipitation event that occurred from 0000 to 0550 UTC 15 February 2015 and featured a BB was studied. During this event, the rainfall intensity was less than 2 mm h−1 at a height of 300 m, which was above the radar site level, so the errors caused by the vertical air motion could be ignored. The freezing height from the radiosonde matched well with the top of the BB observed by the MRR. It was also found that the number of 0.5–1 mm diameter drops showed no noticeable variation below the BB. The maximum fall velocity and the maximum gradient fall velocity (GFV) of the raindrops appeared at the bottom of the BB. Meanwhile, a method that uses the GFV and reflectivity to identify the altitude and the thickness of the BB was established, with which the MRR can provide a reliable and real-time estimation of the 0°C isotherm. The droplet fall velocity was used to classify the types of snow crystals above the BB. In the first 20 min of the selected precipitation event, graupel prevailed above the BB; and at an altitude of 2000 m, graupel also dominated in the first 250 min. After 150 min, the existence of graupel and dendritic crystals with water droplets above the BB was inferred."
journal_title,Advances in Atmospheric Sciences
article_title,Variation in Brewer–Dobson circulation during three sudden stratospheric major warming events in the 2000s
keyword,"['sudden stratospheric major warming\xa0', 'Brewer–Dobson circulation\xa0', 'subtropical wave\xa0', '平流层爆发性增温\xa0', 'BD环流\xa0', '副热带波动\xa0']"
history,"['2017-12', '2017-11-08', '2016-12-18', '2017-06-03', '2017-06-05']"
abstract,"Abstract As the strongest subseasonal atmospheric variability during boreal winter, three remarkable sudden stratospheric major warming (SSW) events in the 2000s are investigated in terms of the Brewer–Dobson circulation (BDC) response. Our study shows that the changes of cross-isentropic velocity during the SSWs are not only confined to the polar region, but also extend to the whole Northern Hemisphere: enhanced descent in the polar region, as well as enhanced ascent in the tropics. When the acceleration of the deep branch of the BDC descends to the middle stratosphere, its strength rapidly decreases over a period of one to two weeks. The acceleration of the deep branch of the BDC is driven by the enhanced planetary wave activity in the mid-to-high-latitude stratosphere. Different from the rapid response of the deep branch of the BDC, tropical upwelling in the lower stratosphere accelerates up to 20%–40% compared with the climatology, 20–30 days after the onset of the SSWs, and the acceleration lasts for one to three months. The enhancement of tropical upwelling is associated with the large-scale wave-breaking in the subtropics interacting with the midlatitude and tropical Quasi-Biennial Oscillation–related mean flow."
journal_title,Advances in Atmospheric Sciences
article_title,Modification of the SUNFLUX solar radiation scheme with a new aerosol parameterization and its validation using observation network data
keyword,"['global solar radiation\xa0', 'SURFRAD\xa0', 'BSRN\xa0', 'AERONET\xa0', '太阳总辐射\xa0', 'SURFRAD\xa0', 'BSRN\xa0', 'AERONE\xa0']"
history,"['2017-11', '2017-09-16', '2016-10-21', '2017-04-04', '2017-04-26']"
abstract,"Abstract SUNFLUX is a fast parameterization scheme for determination of the solar radiation at the Earth’s surface. In this paper, SUNFLUX is further modified in the treatment of aerosols. A new aerosol parameterization scheme is developed for five aerosol species. Observational data from Baseline Surface Radiation Network (BSRN), Surface Radiation Budget Network (SURFRAD) and Aerosol Robotic Network (AERONET) stations are used to evaluate the accuracy of the original and modified SUNFLUX schemes. General meteorological data are available at SURFRAD stations, but not at BSRN stations. Therefore, the total precipitable water content and aerosol data are obtained from AERONET stations. Fourteen stations are selected from both BSRN and AERONET. Cloud fraction data from MODIS are further used to screen the cloud. Ten-year average aerosol mixing ratios simulated by the CAM-chem system are used to calculate the fractions of aerosol optical depth for each aerosol species, and these fractions are further used to convert the observed total aerosol optical depth into the components of individual species for use in the evaluations. The proper treatment of multiple aerosol types in the model is discussed. The evaluation results using SUNFLUX with the new aerosol scheme, in terms of the BSRN dataset, are better than those using the original aerosol scheme under clear-sky conditions. However, the results using the SURFRAD dataset are slightly worse, attributable to the differences in the input water vapor and aerosol optical depth. Sensitivity tests are conducted to investigate the error response of the SUNFLUX scheme to the errors in the input variables."
journal_title,Advances in Atmospheric Sciences
article_title,A step forward toward effectively using hyperspectral IR sounding information in NWP
keyword,[]
history,"['2017-11', '2017-09-16', '2017-07-05', '2017-07-21']"
abstract,"摘 要搭载在气象卫星上的作为全球观测资料重要来源之一的高光谱分辨率红外(IR)探测仪器, 例如搭载于 Aqua 卫星上的 AIRS, Metop-A/B 卫星上的 IASI 以及 SNPP 卫星上的 CrIS, 其观测数据通过同化应用到业务数值天气预报(NWP)模式, 能够改进数值天气预报. 在全部的卫星观测中, 红外和微波探测器的观测对数值天气预报技术具有最重要的影响(Joo 等, 2013; Cucurull 和Anthes, 2014). 虽然先进的红外探测器在数值天气预报系统中占有重要地位, 但由于其观测数据量巨大, 在全部可用的通道中也只有数百个通道的观测可被同化利用. 例如, AIRS, IAS I和CrIS 分别拥有 2372, 8461 和 1305 个观测通道, 也只有部分观测通道被主要的业务中心同化应用到了数值天气预报模式中. 为了有效地将高光谱红外遥感信息同化到数值天气预报模式中, 提出了多种筛选通道的方法. 例如, Li 和 Huang(1994)提出一种基于逐步回归的方法, 用于 AIRS 的通道筛选; Collard(2007)提出了基于信息内容分析以及相关限制条件的筛选方案; Rabier 等(2002)研究了基于雅可比矩阵及迭代方法的筛选方案, 用于顺序筛选通道以获得最大信息量; 在标准方法的基础上, Ventress 和 Dudhia(2014)发展的改进方案在通道筛选过程中可以更好的模拟和量化光谱相关误差; Migliorini(ECMWF技术备忘录, 编号727, 2014)研究了基于最优流依赖在有云情况下的通道筛选方案. 这些方法都可以有效地筛选一套通道, 为同化辐射量提供最优化信息, 尤其是地球同步卫星上的先进的高光谱探测器; 例如, 搭载在风云四号卫星上的地球同步干涉红外探测器(Yang 等, 2017). 综上所述, 通道筛选方案都是基于信息内容分析, 同时考虑非线性及其他因素(例如, 相关误差)的影响. 信息内容分析方法的一大局限在于采用线性方法筛选具有高度非线性的吸收通道(例如, 与温度相比, 水汽吸收通道的辐射量与大气中水汽的含量之间具有较大的非线性关系). 这类通道筛选方法的另一个局限在于不同吸收区间的通道被独立筛选, 由于不同通道的权重不同, 将导致主观的通道筛选结果. 最近, 一个新的通道筛选方法被提出 (Noh 等, 2017). 采用这种方法, 通过计算每个独立添加的通道对一维变分分析结果的改进来筛选通道. 在通道筛选过程中, 定义通道评分指数(CSI)作为成功筛选的标准. 在 314 个 EUMETSAT 的 IASI通道中, 通过计算每个独立通道的 CSI 贡献, 200个通道被系统自动成功筛选. 在 UKMO的统一模式中, 与目前业务使用的183个通道相比, 采用重新筛选的通道对上层大气中的水汽及总降水量的预报都具有改进作用(水汽预报误差减小). 与其他方法相比, 该方法有效地考量了非线性的作用, 尤其在水汽通道的筛选中, 使得更多的水汽通道最终被成功筛选. 该工作对于将高光谱红外探测器的遥感信息, 尤其是水汽遥感信息有效地应用到数值天气预报模式中, 具有至关重要的发展作用."
journal_title,Advances in Atmospheric Sciences
article_title,Why was the strengthening of rainfall in summer over the Yangtze River valley in 2016 less pronounced than that in 1998 under similar preceding El Niño events?—Role of midlatitude circulation in August
keyword,"['Yangtze River valley\xa0', 'summer rainfall\xa0', 'super El Niño\xa0', 'sub-seasonal variation\xa0', 'Silk Road Pattern\xa0', '长江流域\xa0', '夏季降水\xa0', '超级厄尔尼诺\xa0', '次季节变化\xa0', '丝绸之路遥相关\xa0']"
history,"['2017-11', '2017-09-16', '2017-01-04', '2017-04-29', '2017-05-26']"
abstract,"Abstract It is widely recognized that rainfall over the Yangtze River valley (YRV) strengthens considerably during the decaying summer of El Niño, as demonstrated by the catastrophic flooding suffered in the summer of 1998. Nevertheless, the rainfall over the YRV in the summer of 2016 was much weaker than that in 1998, despite the intensity of the 2016 El Niño having been as strong as that in 1998. A thorough comparison of the YRV summer rainfall anomaly between 2016 and 1998 suggests that the difference was caused by the sub-seasonal variation in the YRV rainfall anomaly between these two years, principally in August. The precipitation anomaly was negative in August 2016—different to the positive anomaly of 1998.Further analysis suggests that the weaker YRV rainfall in August 2016 could be attributable to the distinct circulation anomalies over the midlatitudes. The intensified “Silk Road Pattern” and upper-tropospheric geopotential height over the Urals region, both at their strongest since 1980, resulted in an anticyclonic circulation anomaly over midlatitude East Asia with anomalous easterly flow over the middle-to-lower reaches of the YRV in the lower troposphere. This easterly flow reduced the climatological wind, weakened the water vapor transport, and induced the weaker YRV rainfall in August 2016, as compared to that in 1998. Given the unique sub-seasonal variation of the YRV rainfall in summer 2016, more attention should be paid to midlatitude circulation—besides the signal in the tropics—to further our understanding of the predictability and variation of YRV summer rainfall."
journal_title,Advances in Atmospheric Sciences
article_title,Decadal Indian Ocean dipolar variability and its relationship with the tropical Pacific
keyword,"['Indian Ocean dipole\xa0', 'decadal variability\xa0', 'tropical Pacific decadal variability\xa0', '印度洋偶极子\xa0', '年代际变率\xa0', '热带太平年代际变率\xa0']"
history,"['2017-11', '2017-09-16', '2017-01-12', '2017-04-03', '2017-05-15']"
abstract,"Abstract A robust decadal Indian Ocean dipolar variability (DIOD) is identified in observations and found to be related to tropical Pacific decadal variability (TPDV). A Pacific Ocean–global atmosphere (POGA) experiment, with fixed radiative forcing, is conducted to evaluate the DIOD variability and its relationship with the TPDV. In this experiment, the sea surface temperature anomalies are restored to observations over the tropical Pacific, but left as interactive with the atmosphere elsewhere. The TPDV-forced DIOD, represented as the ensemble mean of 10 simulations in POGA, accounts for one third of the total variance. The forced DIOD is triggered by anomalous Walker circulation in response to the TPDV and develops following Bjerknes feedback. Thermocline anomalies do not exhibit a propagating signal, indicating an absence of oceanic planetary wave adjustment in the subtropical Indian Ocean. The DIOD–TPDV correlation differs among the 10 simulations, with a low correlation corresponding to a strong internal DIOD independent of the TPDV. The variance of this internal DIOD depends on the background state in the Indian Ocean, modulated by the thermocline depth off Sumatra/Java."
journal_title,Advances in Atmospheric Sciences
article_title,Improvement of a snow albedo parameterization in the Snow–Atmosphere–Soil Transfer model: evaluation of impacts of aerosol on seasonal snow cover
keyword,"['light-absorbing aerosols\xa0', 'snow albedo\xa0', 'SAST\xa0', 'SNICAR\xa0', '吸光性气溶胶\xa0', '积雪反照率\xa0', 'SAST\xa0', 'SNICAR\xa0']"
history,"['2017-11', '2017-09-16', '2017-01-19', '2017-04-11', '2017-05-15']"
abstract,"Abstract The presence of light-absorbing aerosols (LAA) in snow profoundly influence the surface energy balance and water budget. However, most snow-process schemes in land-surface and climate models currently do not take this into consideration. To better represent the snow process and to evaluate the impacts of LAA on snow, this study presents an improved snow albedo parameterization in the Snow–Atmosphere–Soil Transfer (SAST) model, which includes the impacts of LAA on snow. Specifically, the Snow, Ice and Aerosol Radiation (SNICAR) model is incorporated into the SAST model with an LAA mass stratigraphy scheme. The new coupled model is validated against in-situ measurements at the Swamp Angel Study Plot (SASP), Colorado, USA. Results  show that the snow albedo and snow depth are better reproduced than those in the original SAST, particularly during the period of snow ablation. Furthermore, the impacts of LAA on snow are estimated in the coupled model through case comparisons of the snowpack, with or without LAA. The LAA particles directly absorb extra solar radiation, which accelerates the growth rate of the snow grain size. Meanwhile, these larger snow particles favor more radiative absorption. The average total radiative forcing of the LAA at the SASP is 47.5 W m−2. This extra radiative absorption enhances the snowmelt rate. As a result, the peak runoff time and “snow all gone” day have shifted 18 and 19.5 days earlier, respectively, which could further impose substantial impacts on the hydrologic cycle and atmospheric processes."
journal_title,Advances in Atmospheric Sciences
article_title,Impact of the time scale of model sensitivity response on coupled model parameter estimation
keyword,"['coupled model\xa0', 'parameter estimation\xa0', 'time scale of model sensitivity\xa0', '耦合模式\xa0', '参数估计\xa0', '模式敏感性响应时间尺度\xa0']"
history,"['2017-11', '2017-09-16', '2016-12-21', '2017-05-19', '2017-05-26']"
abstract,"Abstract That a model has sensitivity responses to parameter uncertainties is a key concept in implementing model parameter estimation using filtering theory and methodology. Depending on the nature of associated physics and characteristic variability of the fluid in a coupled system, the response time scales of a model to parameters can be different, from hourly to decadal. Unlike state estimation, where the update frequency is usually linked with observational frequency, the update frequency for parameter estimation must be associated with the time scale of the model sensitivity response to the parameter being estimated. Here, with a simple coupled model, the impact of model sensitivity response time scales on coupled model parameter estimation is studied. The model includes characteristic synoptic to decadal scales by coupling a long-term varying deep ocean with a slow-varying upper ocean forced by a chaotic atmosphere. Results  show that, using the update frequency determined by the model sensitivity response time scale, both the reliability and quality of parameter estimation can be improved significantly, and thus the estimated parameters make the model more consistent with the observation. These simple model results provide a guideline for when real observations are used to optimize the parameters in a coupled general circulation model for improving climate analysis and prediction initialization."
journal_title,Advances in Atmospheric Sciences
article_title,Influence of the preceding austral summer Southern Hemisphere annular mode on the amplitude of ENSO decay
keyword,"['Southern Hemisphere Annular Mode\xa0', 'ENSO\xa0', 'Southern Ocean Dipole\xa0', '南半球环状模\xa0', 'ENSO\xa0', '南大洋偶极子\xa0']"
history,"['2017-11', '2017-09-16', '2017-01-03', '2017-05-01', '2017-05-22']"
abstract,"Abstract There is increasing evidence of the possible role of extratropical forcing in the evolution of ENSO. The Southern Hemisphere Annular Mode (SAM) is the dominant mode of atmospheric circulation in the Southern Hemisphere extratropics. This study shows that the austral summer (December–January–February; DJF) SAM may also influence the amplitude of ENSO decay during austral autumn (March–April–May; MAM). The mechanisms associated with this SAM–ENSO relationship can be briefly summarized as follows: The SAM is positively (negatively) correlated with SST in the Southern Hemisphere middle (high) latitudes. This dipole-like SST anomaly pattern is referred to as the Southern Ocean Dipole (SOD). The DJF SOD, caused by the DJF SAM, could persist until MAM and then influence atmospheric circulation, including trade winds, over the Niño3.4 area. Anomalous trade winds and SST anomalies over the Niño3.4 area related to the DJF SAM are further developed through the Bjerkness feedback, which eventually results in a cooling (warming) over the Niño3.4 area followed by the positive (negative) DJF SAM."
journal_title,Advances in Atmospheric Sciences
article_title,Dynamical feedback between synoptic eddy and low-frequency flow as simulated by BCC_CSM1.1(m)
keyword,"['model evaluation\xa0', 'synoptic eddy feedback simulation\xa0', 'eddy vorticity forcing\xa0', 'eddy-induced growth rate\xa0', 'patterns of synoptic eddy feedback\xa0', '模式评估\xa0', '涡旋反馈模拟\xa0', '涡旋涡度强迫\xa0', '涡旋增长率\xa0', '涡旋反馈模态\xa0']"
history,"['2017-11', '2017-09-16', '2017-01-12', '2017-05-08', '2017-05-11']"
abstract,"Abstract Since the interaction between atmospheric synoptic eddy (SE) (2–8 days) activity and low-frequency (LF) (monthly) flow (referred to as SELF) plays an essential role in generating and maintaining dominant climate modes, an evaluation of the performance of BCC_CSM1.1(m) in simulating the SE feedback onto the LF flow is given in this paper. The model captures well the major spatial features of climatological eddy vorticity forcing, eddy-induced growth rate, and patterns of SELF feedback for the climate modes with large magnitudes in cold seasons and small magnitudes in warm seasons for both the Northern and Southern Hemisphere. As in observations, the eddy-induced growth rate and SELF feedback patterns in the model also show positive SE feedback. Overall, the relationships between SE and LF flow show that BCC_CSM1.1(m) satisfactorily captures the basic features of positive SE feedback, which demonstrates the simulation skill of the model for LF variability. Specifically, such an evaluation can help to find model biases of BCC_CSM1.1(m) in simulating SE feedback, which will provide a reference for the model’s application."
journal_title,Advances in Atmospheric Sciences
article_title,A new Infrared Atmospheric Sounding Interferometer channel selection and assessment of its impact on Met Office NWP forecasts
keyword,"['Hyperspectral IR sounding\xa0', 'channel selection\xa0', '1D-Var\xa0', 'data assimilation\xa0', '大气红外探测器\xa0', '通道选择\xa0', '一维变分\xa0', '联合模式\xa0']"
history,"['2017-11', '2017-09-16', '2016-12-02', '2017-05-04', '2017-05-22']"
abstract,"Abstract A new set of Infrared Atmospheric Sounding Interferometer (IASI) channels was re-selected from 314 EUMETSAT channels. In selecting channels, we calculated the impact of the individually added channel on the improvement in the analysis outputs from a one-dimensional variational analysis (1D-Var) for the Unified Model (UM) data assimilation system at the Met Office, using the channel score index (CSI) as a figure of merit. Then, 200 channels were selected in order by counting each individual channel’s CSI contribution. Compared with the operationally used 183 channels for the UM at the Met Office, the new set shares 149 channels, while the other 51 channels are new. Also examined is the selection from the entropy reduction method with the same 1D-Var approach. Results  suggest that channel selection can be made in a more objective fashion using the proposed CSI method. This is because the most important channels can be selected across the whole IASI observation spectrum.In the experimental trial runs using the UM global assimilation system, the new channels had an overall neutral impact in terms of improvement in forecasts, as compared with results from the operational channels. However, upper-tropospheric moist biases shown in the control run with operational channels were significantly reduced in the experimental trial with the newly selected channels. The reduction of moist biases was mainly due to the additional water vapor channels, which are sensitive to the upper-tropospheric water vapor."
journal_title,Advances in Atmospheric Sciences
article_title,Preface to the special issue on commemorating the centenary of Duzheng YE’s birth
keyword,[]
history,"['2017-10', '2017-08-17']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,From climate to global change: Following the footprint of Prof. Duzheng YE’s research
keyword,"['Professor Duzheng YE\xa0', 'climate change\xa0', 'global change\xa0', 'human activity\xa0', 'proactive adaptation\xa0', '叶笃正教授\xa0', '气候变化\xa0', '全球变化\xa0', '人类活动\xa0', '主动适应\xa0']"
history,"['2017-10', '2017-08-17', '2016-12-02', '2017-01-18', '2017-01-19']"
abstract,"Abstract To commemorate 100 years since the birth of Professor Duzheng YE, this paper reviews the contribution of Ye and his research team to the development from climate to global change science in the past 30 or so years, including: (1) the role of climate change in global change; (2) the critical time scales and predictability of global change; (3) the sensitive regions of global change—transitional zones of climate and ecosystems; and (4) orderly human activities and adaptation to global change, with a focus on the development of a proactive strategy for adaptation to such change."
journal_title,Advances in Atmospheric Sciences
article_title,Differences and links between the East Asian and South Asian summer monsoon systems: Characteristics and Variability
keyword,"['East Asian summer monsoon\xa0', 'South Asian summer monsoon\xa0', 'spatiotemporal variability\xa0', 'rainfall\xa0', 'water vapor transport\xa0', '东亚夏季风\xa0', '南亚夏季风\xa0', '时空变率\xa0', '水汽输送\xa0']"
history,"['2017-10', '2017-08-17', '2017-01-17', '2017-04-11', '2017-05-09']"
abstract,"Abstract This paper analyzes the differences in the characteristics and spatio–temporal variabilities of summertime rainfall and water vapor transport between the East Asian summer monsoon (EASM) and South Asian summer monsoon (SASM) systems. The results show obvious differences in summertime rainfall characteristics between these two monsoon systems. The summertime rainfall cloud systems of the EASM show a mixed stratiform and cumulus cloud system, while cumulus cloud dominates the SASM. These differences may be caused by differences in the vertical shear of zonal and meridional circulations and the convergence of water vapor transport fluxes. Moreover, the leading modes of the two systems’ summertime rainfall anomalies also differ in terms of their spatiotemporal features on the interannual and interdecadal timescales. Nevertheless, several close links with respect to the spatiotemporal variabilities of summertime rainfall and water vapor transport exist between the two monsoon systems. The first modes of summertime rainfall in the SASM and EASM regions reveal a significant negative correlation on the interannual and the interdecadal timescales. This close relationship may be linked by a meridional teleconnection in the regressed summertime rainfall anomalies from India to North China through the southeastern part over the Tibetan Plateau, which we refer to as the South Asia/East Asia teleconnection pattern of Asian summer monsoon rainfall. The authors wish to dedicate this paper to Prof. Duzheng YE, and commemorate his 100th anniversary and his great contributions to the development of atmospheric dynamics."
journal_title,Advances in Atmospheric Sciences
article_title,Evolution of surface sensible heat over the Tibetan Plateau under the recent global warming hiatus
keyword,"['surface sensible heat\xa0', 'Tibetan Plateau\xa0', 'ground-air temperature difference\xa0', 'surface wind speed\xa0', 'global warming hiatus\xa0', '地表感热\xa0', '青藏高原\xa0', '地气温差\xa0', '地表风速\xa0', '全球变暖停滞\xa0']"
history,"['2017-10', '2017-08-17', '2016-12-04', '2017-05-10', '2017-05-18']"
abstract,"Abstract Based on regular surface meteorological observations and NCEP/DOE reanalysis data, this study investigates the evolution of surface sensible heat (SH) over the central and eastern Tibetan Plateau (CE-TP) under the recent global warming hiatus. The results reveal that the SH over the CE-TP presents a recovery since the slowdown of the global warming. The restored surface wind speed together with increased difference in ground-air temperature contribute to the recovery in SH. During the global warming hiatus, the persistent weakening wind speed is alleviated due to the variation of the meridional temperature gradient. Meanwhile, the ground surface temperature and the difference in ground-air temperature show a significant increasing trend in that period caused by the increased total cloud amount, especially at night. At nighttime, the increased total cloud cover reduces the surface effective radiation via a strengthening of atmospheric counter radiation and subsequently brings about a clear upward trend in ground surface temperature and the difference in ground-air temperature. Cloud–radiation feedback plays a significant role in the evolution of the surface temperature and even SH during the global warming hiatus. Consequently, besides the surface wind speed, the difference in ground-air temperature becomes another significant factor for the variation in SH since the slowdown of global warming, particularly at night."
journal_title,Advances in Atmospheric Sciences
article_title,Modeling aerosol climate effects over monsoon Asia: A collaborative research program
keyword,"['aerosol–cloud–climate interactions\xa0', 'monsoon Asia\xa0', 'climate models\xa0', '气溶胶-云-气候相互作用\xa0', '亚洲季风\xa0', '气候模式\xa0']"
history,"['2017-10', '2017-08-17', '2016-12-14', '2017-02-23', '2017-03-03']"
abstract,"Abstract This paper describes the latest progress of a collaborative research program entitled “Modeling Aerosol Climate Effects over Monsoon Asia”, under the Climate Sciences agreement between the U.S. Department of Energy and the Chinese Academy of Sciences (in the early 1980s, Professor Duzheng YE played a critical role in leading and formalizing the agreement). Here, the rationale and approach for pursuing the program, the participants, and research activities of recent years are first described, and then the highlights of the program’s key findings and relevant scientific issues, as well as follow-up studies, are presented and discussed."
journal_title,Advances in Atmospheric Sciences
article_title,Formation and variation of the atmospheric heat source over the Tibetan Plateau and its climate effects
keyword,"['atmospheric heat source\xa0', 'Tibetan Plateau\xa0', 'climate effect\xa0', 'uncertainty\xa0', '大气热源\xa0', '青藏高原\xa0', '气候效应\xa0', '不确定性\xa0']"
history,"['2017-10', '2017-08-17', '2017-01-14', '2017-06-14', '2017-06-28']"
abstract,"Abstract To cherish the memory of the late Professor Duzheng YE on what would have been his 100th birthday, and to celebrate his great accomplishment in opening a new era of Tibetan Plateau (TP) meteorology, this review paper provides an assessment of the atmospheric heat source (AHS) over the TP from different data resources, including observations from local meteorological stations, satellite remote sensing data, and various reanalysis datasets. The uncertainty and applicability of these heat source data are evaluated. Analysis regarding the formation of the AHS over the TP demonstrates that it is not only the cause of the atmospheric circulation, but is also a result of that circulation. Based on numerical experiments, the review further demonstrates that land–sea thermal contrast is only one part of the monsoon story. The thermal forcing of the Tibetan–Iranian Plateau plays a significant role in generating the Asian summer monsoon (ASM), i.e., in addition to pumping water vapor from sea to land and from the lower to the upper troposphere, it also generates a subtropical monsoon–type meridional circulation subject to the angular momentum conservation, providing an ascending-air large-scale background for the development of the ASM."
journal_title,Advances in Atmospheric Sciences
article_title,Equatorial wave expansion of instantaneous flows for diagnosis of equatorial waves from data: Formulation and illustration
keyword,"['Equatorial wave expansion\xa0', 'Instantaneous flows\xa0', None, '赤道波展开\xa0', '即时波动\xa0', '赤道平面浅水模式\xa0']"
history,"['2017-10', '2017-08-17', '2016-12-19', '2017-04-17', '2017-05-11']"
abstract,"Abstract This paper presents a method for expanding horizontal flow variables in data using the free solutions to the shallow-water system as a basis set. This method for equatorial wave expansion of instantaneous flows (EWEIF) uses dynamic constraints in conjunction with projections of data onto parabolic cylinder functions to determine the amplitude of all equatorial waves. EWEIF allows us to decompose an instantaneous wave flow into individual equatorial waves with a presumed equivalent depth without using temporal or spatial filtering a priori.Three sets of EWEIF analyses are presented. The first set is to confirm that EWEIF is capable of recovering the individual waves constructed from theoretical equatorial wave solutions under various scenarios. The other two sets demonstrate the ability of the EWEIF method to derive time series of individual equatorial waves from instantaneous wave fields without knowing a priori exactly which waves exist in the data as well as their spatial and temporal scales using outputs of an equatorial β-channel shallow-water model and ERA-Interim data. The third set of demonstrations shows, for the first time, the continuous evolutions of individual equatorial waves in the stratosphere whose amplitude is synchronized with the background zonal wind as predicted by quasi-biennial oscillation theory."
journal_title,Advances in Atmospheric Sciences
article_title,Evolving perspectives on abrupt seasonal changes of the general circulation
keyword,"['abrupt change\xa0', 'general circulation\xa0', 'Hadley cell\xa0', 'large-scale eddies\xa0', '突变\xa0', '大气环流\xa0', '哈得来环流\xa0', '大尺度涡旋\xa0']"
history,"['2017-10', '2017-08-17', '2017-03-29', '2017-06-21', '2017-06-28']"
abstract,"Abstract Professor Duzheng YE (Tu-cheng YEH) was decades ahead of his time in proposing a model experiment to investigate whether abrupt seasonal changes of the general circulation can arise through circulation feedbacks alone, unrelated to underlying inhomogeneities at the lower boundary. Here, we introduce Professor YEH’s ideas during the 1950s and 1960s on the general circulation and summarize the results and suggestions of Yeh et al. (1959) on abrupt seasonal changes. We then review recent advances in understanding abrupt seasonal changes arising from model experiments like those proposed by Yeh et al. (1959). The model experiments show that circulation feedbacks can indeed give rise to abrupt seasonal transitions. In these transitions, large-scale eddies that originate in midlatitudes and interact with the zonal mean flow and meridional overturning circulations in the tropics play central roles."
journal_title,Advances in Atmospheric Sciences
article_title,On multi-level thinking and scientific understanding
keyword,"['communication skills\xa0', 'cross-disciplinary communication\xa0', 'scientific understanding\xa0', 'unconscious assumptions\xa0', 'multiple viewpoints\xa0', 'brain hemispheres\xa0', 'biological evolution\xa0', '交流技巧\xa0', '跨领域交流\xa0', '科学理解\xa0', '无意识假设\xa0', '多重视角\xa0', '脑半球\xa0', '生物进化\xa0']"
history,"['2017-10', '2017-08-17', '2016-11-21', '2017-01-19', '2017-01-20']"
abstract,"Abstract Professor Duzheng YE’s name has been familiar to me ever since my postdoctoral years at MIT with Professors Jule CHARNEY and Norman PHILLIPS, back in the late 1960s. I had the enormous pleasure of meeting Professor YE personally in 1992 in Beijing. His concern to promote the very best science and to use it well, and his thinking on multi-level orderly human activities, reminds me not only of the communication skills we need as scientists but also of the multi-level nature of science itself. Here I want to say something (a) about what science is; (b) about why multi-level thinking—and taking more than one viewpoint—is so important for scientific as well as for other forms of understanding; and (c) about what is meant, at a deep level, by “scientific understanding” and trying to communicate it, not only with lay persons but also across professional disciplines. I hope that Professor YE would approve."
journal_title,Advances in Atmospheric Sciences
article_title,Variable and robust East Asian monsoon rainfall response to El Niño over the past 60 years (1957–2016)
keyword,"['El Niño impact\xa0', 'monsoon rainfall\xa0', 'East Asian monsoon\xa0', 'Asian monsoon\xa0', 'precipitation variability\xa0', 'monsoon–ocean interaction\xa0', 'western Pacific subtropical high\xa0', '厄尔尼诺影响\xa0', '季风降水\xa0', '东亚季风\xa0', '亚洲季风\xa0', '降水变率\xa0', '季风海洋相互作用\xa0', '西太平洋副热带高压\xa0']"
history,"['2017-10', '2017-08-17', '2017-01-15', '2017-06-01', '2017-06-05']"
abstract,"Abstract Severe flooding occurred in southern and northern China during the summer of 2016 when the 2015 super El Niño decayed to a normal condition. However, the mean precipitation during summer (June–July-August) 2016 does not show significant anomalies, suggesting that—over East Asia (EA)—seasonal mean anomalies have limited value in representing hydrological hazards. Scrutinizing season-evolving precipitation anomalies associated with 16 El Niño episodes during 1957–2016 reveals that, over EA, the spatiotemporal patterns among the four categories of El Niño events are quite variable, due to a large range of variability in the intensity and evolution of El Niño events and remarkable subseasonal migration of the rainfall anomalies. The only robust seasonal signal is the dry anomalies over central North China during the El Niño developing summer. Distinguishing strong and weak El Niño impacts is important. Only strong El Niño events can persistently enhance EA subtropical frontal precipitation from the peak season of El Niño to the ensuing summer, by stimulating intense interaction between the anomalous western Pacific anticyclone (WPAC) and underlying dipolar sea surface temperature anomalies in the Indo-Pacific warm pool, thereby maintaining the WPAC and leading to a prolonged El Niño impact on EA. A weak El Niño may also enhance the post-El Niño summer rainfall over EA, but through a different physical process: the WPAC re-emerges as a forced response to the rapid cooling in the eastern Pacific. The results suggest that the skillful prediction of rainfall over continental EA requires the accurate prediction of not only the strength and evolution of El Niño, but also the subseasonal migration of EA rainfall anomalies."
journal_title,Advances in Atmospheric Sciences
article_title,"The pioneering works of Professor Duzheng Ye on atmospheric dispersion, Tibetan Plateau meteorology, and air–sea interaction"
keyword,"['atmospheric dispersion\xa0', 'Tibetan Plateau meteorology\xa0', 'El Ni˜no\xa0', '大气能量频散\xa0', '青藏高原气象学\xa0', '厄尔尼诺\xa0']"
history,"['2017-10', '2017-08-17', '2016-10-13', '2016-12-09', '2017-01-09']"
abstract,"Abstract This paper provides an overview of the impacts of the original works of Professor Duzheng YE on a selected set of observational and model studies with which the present author has been associated over the past several decades. The main themes of these works include atmospheric energy dispersion, air–land interactions over the Tibetan Plateau, and El Ni˜norelated air–sea coupling over East Asia.The dispersive behavior of observed atmospheric fluctuations accompanying cold surge events in East Asia is demonstrated. Cold air outbreaks over Korea and southern China are coincident with the successive downstream development of troughs and ridges, with the group velocity of such wave packets being notably faster than the phase propagation speed of individual troughs and ridges. In a more general context, dispersive features are also discernible from lagged teleconnection charts and cross-spectra of observed and model-simulated geopotential height variations on 10–30-day time scales.Using the output from a high-resolution general circulation model, the relative contributions of condensational, sensible, and radiative heating to the atmospheric energy budget over the Tibetan Plateau are documented. The rapid changes of the upper tropospheric Tibetan anticyclone and East Asian mei-yu (“plum rain”) precipitation band associated with the development of the Asian monsoon system are described.The principal anomalies in sea level pressure, surface wind, precipitation and sea surface temperature over southeastern China and the Philippine Sea region during El Ni˜no events are presented. The contributions of remote El Ni˜no-related forcing and local air–sea interaction to the occurrence of these anomalies are assessed."
journal_title,Advances in Atmospheric Sciences
article_title,Determining the spectrum of the nonlinear local Lyapunov exponents in a multidimensional chaotic system
keyword,"['Lyapunov exponent\xa0', 'nonlinear local Lyapunov exponent\xa0', 'predictability\xa0', 'Lyapunov指数\xa0', '非线性局部Lyapunov指数\xa0', '可预报性\xa0']"
history,"['2017-09', '2017-08-05', '2017-01-17', '2017-03-30', '2017-04-11']"
abstract,"Abstract For an n-dimensional chaotic system, we extend the definition of the nonlinear local Lyapunov exponent (NLLE) from one- to n-dimensional spectra, and present a method for computing the NLLE spectrum. The method is tested on three chaotic systems with different complexity. The results indicate that the NLLE spectrum realistically characterizes the growth rates of initial error vectors along different directions from the linear to nonlinear phases of error growth. This represents an improvement over the traditional Lyapunov exponent spectrum, which only characterizes the error growth rates during the linear phase of error growth. In addition, because the NLLE spectrum can effectively separate the slowly and rapidly growing perturbations, it is shown to be more suitable for estimating the predictability of chaotic systems, as compared to the traditional Lyapunov exponent spectrum."
journal_title,Advances in Atmospheric Sciences
article_title,Analysis of spatial autocorrelation patterns of heavy and super-heavy rainfall in Iran
keyword,"['Iran\xa0', 'heavy rainfall\xa0', 'super-heavy rainfall\xa0', 'spatial autocorrelation\xa0', None, '伊朗\xa0', '暴雨\xa0', '特大暴雨\xa0', '空间自相关\xa0', 'G指数热点分析方法\xa0']"
history,"['2017-09', '2017-08-05', '2016-09-13', '2017-04-11', '2017-04-13']"
abstract,"Abstract Rainfall is a highly variable climatic element, and rainfall-related changes occur in spatial and temporal dimensions within a regional climate. The purpose of this study is to investigate the spatial autocorrelation changes of Iran’s heavy and super-heavy rainfall over the past 40 years. For this purpose, the daily rainfall data of 664 meteorological stations between 1971 and 2011 are used. To analyze the changes in rainfall within a decade, geostatistical techniques like spatial autocorrelation analysis of hot spots, based on the Getis-Ord G  i  statistic, are employed. Furthermore, programming features in MATLAB, Surfer, and GIS are used. The results indicate that the Caspian coast, the northwest and west of the western foothills of the Zagros Mountains of Iran, the inner regions of Iran, and southern parts of Southeast and Northeast Iran, have the highest likelihood of heavy and super-heavy rainfall. The spatial pattern of heavy rainfall shows that, despite its oscillation in different periods, the maximum positive spatial autocorrelation pattern of heavy rainfall includes areas of the west, northwest and west coast of the Caspian Sea. On the other hand, a negative spatial autocorrelation pattern of heavy rainfall is observed in central Iran and parts of the east, particularly in Zabul. Finally, it is found that patterns of super-heavy rainfall are similar to those of heavy rainfall."
journal_title,Advances in Atmospheric Sciences
article_title,"Characterization of black carbon in the ambient air of Agra, India: Seasonal variation and meteorological influence"
keyword,"['black carbon aerosol\xa0', 'seasonal variation\xa0', 'diurnal variation\xa0', 'meteorological parameter\xa0', '黑炭气溶胶\xa0', '季节变化\xa0', '日变化\xa0', '气象因子\xa0']"
history,"['2017-09', '2017-08-05', '2016-09-06', '2017-01-12', '2017-04-01']"
abstract,"Abstract This study characterizes the black carbon in Agra, India home to the Taj Mahal—and situated in the Indo-Gangetic basin. The mean black carbon concentration is 9.5 μg m−3 and, owing to excessive biomass/fossil fuel combustion and automobile emissions, the concentration varies considerably. Seasonally, the black carbon mass concentration is highest in winter, probably due to the increased fossil fuel consumption for heating and cooking, apart from a low boundary layer. The nocturnal peak rises prominently in winter, when the use of domestic heating is excessive. Meanwhile, the concentration is lowest during the monsoon season because of the turbulent atmospheric conditions and the process of washout by precipitation. The ratio of black carbon to brown carbon is less than unity during the entire study period, except in winter (December). This may be because that biomass combustion and diesel exhaust are major black carbon contributors in this region, while a higher ratio in winter may be due to the increased consumption of fossil fuel and wood for heating purposes. ANOVA reveals significant monthly variation in the concentration of black carbon; plus, it is negatively correlated with wind speed and temperature. A high black carbon mass concentration is observed at moderate (1–2 m s−1) wind speed, as compared to calm or turbulent atmospheric conditions."
journal_title,Advances in Atmospheric Sciences
article_title,Tower-based greenhouse gas measurement network design—The National Institute of Standards and Technology North East Corridor Testbed
keyword,"['greenhouse gases\xa0', 'network design\xa0', 'clustering analysis\xa0', 'Kalman filter\xa0', 'OSSE\xa0', '温室气体\xa0', '观测网络设计\xa0', '聚类分析\xa0', '卡尔曼滤波\xa0', '观测系统模拟实验\xa0']"
history,"['2017-09', '2017-08-05', '2016-04-09', '2016-11-08', '2017-01-16']"
abstract,"Abstract The North–East Corridor (NEC) Testbed project is the 3rd of three NIST (National Institute of Standards and Technology) greenhouse gas emissions testbeds designed to advance greenhouse gas measurements capabilities. A design approach for a dense observing network combined with atmospheric inversion methodologies is described. The Advanced Research Weather Research and Forecasting Model with the Stochastic Time-Inverted Lagrangian Transport model were used to derive the sensitivity of hypothetical observations to surface greenhouse gas emissions (footprints). Unlike other network design algorithms, an iterative selection algorithm, based on a k-means clustering method, was applied to minimize the similarities between the temporal response of each site and maximize sensitivity to the urban emissions contribution. Once a network was selected, a synthetic inversion Bayesian Kalman filter was used to evaluate observing system performance. We present the performances of various measurement network configurations consisting of differing numbers of towers and tower locations. Results  show that an overly spatially compact network has decreased spatial coverage, as the spatial information added per site is then suboptimal as to cover the largest possible area, whilst networks dispersed too broadly lose capabilities of constraining flux uncertainties. In addition, we explore the possibility of using a very high density network of lower cost and performance sensors characterized by larger uncertainties and temporal drift. Analysis convergence is faster with a large number of observing locations, reducing the response time of the filter. Larger uncertainties in the observations implies lower values of uncertainty reduction. On the other hand, the drift is a bias in nature, which is added to the observations and, therefore, biasing the retrieved fluxes."
journal_title,Advances in Atmospheric Sciences
article_title,"Parallel comparison of the 1982/83, 1997/98 and 2015/16 super El Niños and their effects on the extratropical stratosphere"
keyword,"['super El Niño\xa0', 'Pacific–North America (PNA) teleconnection\xa0', 'stratosphere\xa0', 'proceeding winter\xa0', '超级El Niño\xa0', '太平洋–北美遥相关\xa0', '平流层\xa0', '次年冬季\xa0']"
history,"['2017-09', '2017-08-05', '2016-10-17', '2017-03-06', '2017-04-01']"
abstract,"Abstract This study uses multiple sea surface temperature (SST) datasets to perform a parallel comparison of three super El Niños and their effects on the stratosphere. The results show that, different from ordinary El Niños, warm SST anomalies appear earliest in the western tropical Pacific and precede the super El Niño peak by more than 18 months. In the previous winter, relative to the mature phase of El Niño, as a precursor, North Pacific Oscillation-like circulation anomalies are observed. A Pacific–North America (PNA) teleconnection appears in the extratropical troposphere during the mature phase, in spite of the subtle differences between the intensities, as well as the zonal position, of the PNA lobes. Related to the negative rainfall response over the tropical Indian Ocean, the PNA teleconnection in the winter of 1997/98 is the strongest among the three super El Niños. The northern winter stratosphere shows large anomalies in the polar cap temperature and the circumpolar westerly, if the interferences from other factors are linearly filtered from the circulation data. Associated with the positive PNA response in a super El Niño winter, positive polar cap temperature anomalies and circumpolar easterly anomalies, though different in timing, are also observed in the mature winters of the three super El Niños. The stratospheric polar vortex in the next winter relative to the 1982/83 and 1997/98 events is also anomalously weaker and warmer, and the stratospheric circulation conditions remain to be seen in the coming winter following the mature phase of the 2015/16 event."
journal_title,Advances in Atmospheric Sciences
article_title,Observation-based estimation of aerosol-induced reduction of planetary boundary layer height
keyword,"['aerosol\xa0', 'radiation\xa0', 'atmospheric stability\xa0', 'surface sensible heat flux\xa0', 'planetary boundary layer height\xa0', '气溶胶\xa0', '辐射\xa0', '大气稳定度\xa0', '地面感热通量\xa0', '行星边界层高度\xa0']"
history,"['2017-09', '2017-08-05', '2016-10-14', '2017-03-10', '2017-04-26']"
abstract,"Abstract Radiative aerosols are known to influence the surface energy budget and hence the evolution of the planetary boundary layer. In this study, we develop a method to estimate the aerosol-induced reduction in the planetary boundary layer height (PBLH) based on two years of ground-based measurements at a site, the Station for Observing Regional Processes of the Earth System (SORPES), at Nanjing University, China, and radiosonde data from the meteorological station of Nanjing. The observations show that increased aerosol loads lead to a mean decrease of 67.1 W m−2 for downward shortwave radiation (DSR) and a mean increase of 19.2 W m−2 for downward longwave radiation (DLR), as well as a mean decrease of 9.6 Wm−2 for the surface sensible heat flux (SHF) in the daytime. The relative variations of DSR, DLR and SHF are shown as a function of the increment of column mass concentration of particulate matter (PM2.5). High aerosol loading can significantly increase the atmospheric stability in the planetary boundary layer during both daytime and nighttime. Based on the statistical relationship between SHF and PM2.5 column mass concentrations, the SHF under clean atmospheric conditions (same as the background days) is derived. In this case, the derived SHF, together with observed SHF, are then used to estimate changes in the PBLH related to aerosols. Our results suggest that the PBLH decreases more rapidly with increasing aerosol loading at high aerosol loading. When the daytime mean column mass concentration of PM2.5 reaches 200 mg m−2, the decrease in the PBLH at 1600 LST (local standard time) is about 450 m."
journal_title,Advances in Atmospheric Sciences
article_title,Evaluating common land model energy fluxes using FLUXNET data
keyword,"['model evaluation\xa0', 'Common Land Model\xa0', 'FLUXNET\xa0', '模式评估\xa0', '通用陆面模式\xa0', 'FLUXNET\xa0']"
history,"['2017-09', '2017-08-05', '2016-10-13', '2017-05-02', '2017-05-08']"
abstract,"Abstract Given the crucial role of land surface processes in global and regional climates, there is a pressing need to test and verify the performance of land surface models via comparisons to observations. In this study, the eddy covariance measurements from 20 FLUXNET sites spanning more than 100 site-years were utilized to evaluate the performance of the Common Land Model (CoLM) over different vegetation types in various climate zones. A decomposition method was employed to separate both the observed and simulated energy fluxes, i.e., the sensible heat flux, latent heat flux, net radiation, and ground heat flux, at three timescales ranging from stepwise (30 min) to monthly. A comparison between the simulations and observations indicated that CoLM produced satisfactory simulations of all four energy fluxes, although the different indexes did not exhibit consistent results among the different fluxes. A strong agreement between the simulations and observations was found for the seasonal cycles at the 20 sites, whereas CoLM underestimated the latent heat flux at the sites with distinct dry and wet seasons, which might be associated with its weakness in simulating soil water during the dry season. CoLM cannot explicitly simulate the midday depression of leaf gas exchange, which may explain why CoLM also has a maximum diurnal bias at noon in the summer. Of the eight selected vegetation types analyzed, CoLM performs best for evergreen broadleaf forests and worst for croplands and wetlands."
journal_title,Advances in Atmospheric Sciences
article_title,The role of initial cloud condensation nuclei concentration in hail using the WRF NSSL 2-moment microphysics scheme
keyword,"['CCN\xa0', 'hail\xa0', 'microphysics\xa0', 'thermodynamics\xa0', 'threshold\xa0', '云凝结核\xa0', '冰雹\xa0', '微物理\xa0', '热动力\xa0', '阈值\xa0']"
history,"['2017-09', '2017-08-05', '2016-09-08', '2017-03-30', '2017-04-10']"
abstract,"Abstract The effects of the initial cloud condensation nuclei (CCN) concentrations (100–3000 mg−1) on hail properties were investigated in an idealized non-severe hail storm experiment using theWeather Research and Forecasting (WRF) model, with the National Severe Storms Laboratory 2-moment microphysics scheme. The initial CCN concentration (CCNC) had obvious non-monotonic effects on the mixing ratio, number concentrations, and radius of hail, both in clouds and at the surface, with a CCNC threshold between 300 and 500 mg−1. An increasing CCNC is conducive (suppressive) to the amount of surface hail precipitation below (above) the CCNC threshold. The non-monotonic effects were due to both the thermodynamics and microphysics. Below the CCNC threshold, the mixing ratios of cloud droplets and ice crystals increased dramatically with the increasing CCNC, resulting in more latent heat released from condensation and frozen between 4 and 8 km and intensified updraft volume. The extent of the riming process, which is the primary process for hail production, increased dramatically. Above the CCNC threshold, the mixing ratio of cloud droplets and ice crystals increased continuously, but the maximum updraft volume was weakened because of reduced frozen latent heating at low level. The smaller ice crystals reduced the formation of hail and smaller clouds, with decreased rain water reducing riming efficiency so that graupel and hail also decreased with increasing CCNC, which is unfavorable for hail growth."
journal_title,Advances in Atmospheric Sciences
article_title,Simulated sensitivity of the tropical cyclone eyewall replacement cycle to the ambient temperature profile
keyword,"['tropical cyclone\xa0', 'eyewall replacement cycle\xa0', 'ambient temperature profile\xa0', '热带气旋\xa0', '眼墙替换周期\xa0', '大气温度廓线\xa0']"
history,"['2017-09', '2017-08-05', '2016-12-08', '2017-03-27', '2017-04-05']"
abstract,"Abstract In this study, the impacts of the environmental temperature profile on the tropical cyclone eyewall replacement cycle are examined using idealized numerical simulations. It is found that the environmental thermal condition can greatly affect the formation and structure of a secondary eyewall and the intensity change during the eyewall replacement cycle. Simulation with a warmer thermal profile produces a larger moat and a prolonged eyewall replacement cycle. It is revealed that the enhanced static stability greatly suppresses convection, and thus causes slow secondary eyewall formation. The possible processes influencing the decay of inner eyewall convection are investigated. It is revealed that the demise of the inner eyewall is related to a choking effect associated with outer eyewall convection, the radial distribution of moist entropy fluxes within the moat region, the enhanced static stability in the inner-core region, and the interaction between the inner and outer eyewalls due to the barotropic instability. This study motivates further research into how environmental conditions influence tropical cyclone dynamics and thermodynamics."
journal_title,Advances in Atmospheric Sciences
article_title,Unprecedented warming revealed from multi-proxy reconstruction of temperature in southern China for the past 160 years
keyword,"['centennial warming\xa0', 'temperature reconstruction\xa0', 'multi-proxy\xa0', 'southern China\xa0', '百年尺度增暖\xa0', '气温重建\xa0', '多源代用资料\xa0', '华南地区\xa0']"
history,"['2017-08', '2017-06-29', '2016-09-02', '2017-02-23', '2017-02-27']"
abstract,"Abstract Using the southern limit of snowfall recorded in Chinese documents, chronologies of tree-ring width, and tree-ring stable oxygen isotope (δ18O), the annual temperature anomaly in southern China during 1850–2009 is reconstructed using the method of signal decomposition and synthesis. The results show that the linear trend was 0.47°C (100 yr)−1 over 1871–2009, and the two most rapid warming intervals occurred in 1877–1938 and 1968–2007, at rates of 0.125°C (10 yr)−1 and 0.258°C (10 yr)−1, respectively. The decadal variation shows that the temperature in the moderate warm interval of the 1910s–1930s was notably lower than that of the 1980s–2000s, which suggests that the warming since the 1980s was unprecedented for the past 160 years, though a warming hiatus existed in the 2000s. Additionally, there was a rapid cooling starting from the 1860s, followed by a cold interval until the early 1890s, with the coldest years in 1892 and 1893. A slight temperature decline was also found from the 1940s to the late 1960s. This study provides an independent case to validate the global warming for the past 160 years and its hiatus recently, because the proxy data are not affected by urbanization."
journal_title,Advances in Atmospheric Sciences
article_title,Preface to the special issue on the program of “Carbon Budget and Relevant Issues”—A strategic scientific pioneering program of the Chinese Academy of Sciences
keyword,[]
history,"['2017-08', '2017-06-29']"
abstract,None
journal_title,Advances in Atmospheric Sciences
article_title,"Optical properties and source analysis of aerosols over a desert area in Dunhuang, Northwest china"
keyword,"['Dunhuang\xa0', 'AOD\xa0', 'Ångström exponent\xa0', 'dust aerosol\xa0', 'anthropogenic aerosols\xa0', '敦煌\xa0', 'AOD\xa0', 'Ångström波长指数\xa0', '沙尘气溶胶\xa0', '人为气溶胶\xa0']"
history,"['2017-08', '2017-06-29', '2016-08-27', '2016-10-31', '2016-11-29']"
abstract,"Abstract Aerosol observational data for 2012 obtained from Dunhuang Station of CARE-China (Campaign on Atmospheric Aerosol Research Network of China) were analyzed to achieve in-depth knowledge of aerosol optical properties over Dunhuang region. The results showed that the annual average aerosol optical depth (AOD) at 500 nm was 0.32±0.06, and the Ångström exponent (α) was 0.73 ± 0.27. Aerosol optical properties revealed significant seasonal characteristics. Frequent sandstorms in MAM (March–April–May) resulted in the seasonal maximum AOD, 0.41 ± 0.04, and a relatively smaller α value, 0.44±0.04. The tourism seasons, JJA (June–July–August) and SON (September–October–November) coincide with serious emissions of small anthropogenic aerosols. While in DJF (December–January–February), the composition of the atmosphere was a mixture of dust particles and polluted aerosols released by domestic heating; the average AOD and α were 0.29 ± 0.02 and 0.66 ± 0.17, respectively. Different air masses exhibited different degrees of influence on the aerosol concentration over Dunhuang in different seasons. During MAM, ranges of AOD (0.11–1.18) and α (0.06–0.82) were the largest under the dust influence of northwest-short-distance air mass in the four trajectories. Urban aerosols transported by northwest-short-distance air mass accounted for a very large proportion in JJA and the mixed aerosols observed in SON were mainly conveyed by air masses from the west. In DJF, the similar ranges of AOD and α under the three air mass demonstrated the analogous diffusion effects on regional pollutants over Dunhuang."
journal_title,Advances in Atmospheric Sciences
article_title,Characteristics of temperature change in China over the last 2000 years and spatial patterns of dryness/wetness during cold and warm periods
keyword,"['temperature change\xa0', 'dry-wet spatial pattern\xa0', 'cold and warm periods\xa0', 'last 2000 years\xa0', 'China\xa0', '气温变化\xa0', '旱涝格局\xa0', '冷暖期\xa0', '过去2000年\xa0', '中国\xa0']"
history,"['2017-08', '2017-06-29', '2016-10-18', '2017-03-07', '2017-03-14']"
abstract,"Abstract This paper presents new high-resolution proxies and paleoclimatic reconstructions for studying climate changes in China for the past 2000 years. Multi-proxy synthesized reconstructions show that temperature variation in China has exhibited significant 50–70-yr, 100–120-yr, and 200–250-yr cycles. Results  also show that the amplitudes of decadal and centennial temperature variation were 1.3°C and 0.7°C, respectively, with the latter significantly correlated with long-term changes in solar radiation, especially cold periods, which correspond approximately to sunspot minima. The most rapid warming in China occurred over AD 1870–2000, at a rate of 0.56° ± 0.42°C (100 yr)−1; however, temperatures recorded in the 20th century may not be unprecedented for the last 2000 years, as data show records for the periods AD 981–1100 and AD 1201–70 are comparable to the present. The ensemble means of dryness/wetness spatial patterns in eastern China across all centennial warm periods illustrate a tripole pattern: dry south of 25°N, wet from 25°–30°N, and dry to the north of 30°N. However, for all centennial cold periods, this spatial pattern also exhibits a meridional distribution. The increase in precipitation over the monsoonal regions of China associated with the 20th century warming can primarily be attributed to a mega El Ni˜no–Southern Oscillation and the Atlantic Multidecadal Oscillation. In addition, a significant association between increasing numbers of locusts and dry/cold conditions is found in eastern China. Plague intensity also generally increases in concert with wetness in northern China, while more precipitation is likely to have a negative effect in southern China."
journal_title,Advances in Atmospheric Sciences
article_title,Aircraft measurements of cloud–aerosol interaction over East Inner Mongolia
keyword,"['aircraft observation\xa0', 'aerosol\xa0', 'warm cloud\xa0', 'microphysical properties\xa0', '飞机观测\xa0', '气溶胶\xa0', '暖云\xa0', '微物理特征\xa0']"
history,"['2017-08', '2017-06-29', '2016-09-18', '2017-03-23', '2017-04-01']"
abstract,"Abstract To investigate the potential effects of aerosols on the microphysical properties of warm clouds, airborne observational data collected from 2009 to 2011 in Tongliao, Inner Mongolia, China, were statistically analyzed in this study. The results demonstrated that the vertical distribution of the aerosol number concentration (N a) was similar to that of the clean rural continent. The average aerosol effective diameter (D e) was maintained at approximately 0.4 μm at all levels. The data obtained during cloud penetrations showed that there was a progressive increase in the cloud droplet concentration (N c) and liquid water content (LWC) from outside to inside the clouds, while the N a was negatively related to the N c and LWC at the same height. The fluctuation of the N a, N c and LWC during cloud penetration was more obvious under polluted conditions (Type 1) than under clean conditions (Type 2). Moreover, the wet scavenging of cloud droplets had a significant impact on the accumulation mode of aerosols, especially on particles with diameters less than 0.4 μm. The minimum wet scavenging coefficient within the cloud was close to 0.02 under Type 1 conditions, while it increased to 0.1 under Type 2 conditions, which proved that the cloud wet scavenging effect under Type 1 conditions was stronger than that under Type 2 conditions. Additionally, cloud droplet spectra under Type 1 conditions were narrower, and their horizontal distributions were more homogeneous than those under Type 2 conditions."
journal_title,Advances in Atmospheric Sciences
article_title,Airborne observations of cloud condensation nuclei spectra and aerosols over East Inner Mongolia
keyword,"['CCN\xa0', 'aerosol\xa0', 'size distribution\xa0', 'aircraft observation\xa0', '云凝结核\xa0', '气溶胶\xa0', '粒子谱分布\xa0', '飞机观测\xa0']"
history,"['2017-08', '2017-06-29', '2016-08-23', '2017-05-06', '2017-05-22']"
abstract,"Abstract A set of vertical profiles of aerosol number concentrations, size distributions and cloud condensation nuclei (CCN) spectra was observed using a passive cloud and aerosol spectrometer (PCASP) and cloud condensation nuclei counter, over the Tongliao area, East Inner Mongolia, China. The results showed that the average aerosol number concentration in this region was much lower than that in heavily polluted areas. Monthly average aerosol number concentrations within the boundary layer reached a maximum in May and a minimum in September, and the variations in CCN number concentrations at different supersaturations showed the same trend. The parameters c and k of the empirical function N = cS  k  were 539 and 1.477 under clean conditions, and their counterparts under polluted conditions were 1615 and 1.42. Measurements from the airborne probe mounted on a Yun-12 (Y12) aircraft, together with Hybrid Single-Particle Lagrangian Integrated Trajectory model backward trajectories indicated that the air mass from the south of Tongliao contained a high concentration of aerosol particles (1000–2500 cm−3) in the middle and lower parts of the troposphere. Moreover, detailed intercomparison of data obtained on two days in 2010 indicated that the activation efficiency in terms of the ratio of N CCN to N a (aerosols measured from PCASP) was 0.74 (0.4 supersaturations) when the air mass mainly came from south of Tongliao, and this value increased to 0.83 on the relatively cleaner day. Thus, long-range transport of anthropogenic pollutants from heavily polluted mega cities, such as Beijing and Tianjin, may result in slightly decreasing activation efficiencies."
journal_title,Advances in Atmospheric Sciences
article_title,Monitoring carbon dioxide from space: Retrieval algorithm and flux inversion based on GOSAT data and using CarbonTracker-China
keyword,"['retrieval algorithm\xa0', 'satellite remote sensing\xa0', None, 'carbon flux\xa0', 'GOSAT\xa0', '反演算法\xa0', '卫星遥感\xa0', '二氧化碳\xa0', '碳通量\xa0', 'GOSAT\xa0']"
history,"['2017-08', '2017-06-29', '2016-08-25', '2017-02-08', '2017-02-13']"
abstract,"Abstract Monitoring atmospheric carbon dioxide (CO2) from space-borne state-of-the-art hyperspectral instruments can provide a high precision global dataset to improve carbon flux estimation and reduce the uncertainty of climate projection. Here, we introduce a carbon flux inversion system for estimating carbon flux with satellite measurements under the support of “The Strategic Priority Research Program of the Chinese Academy of Sciences—Climate Change: Carbon Budget and Relevant Issues”. The carbon flux inversion system is composed of two separate parts: the Institute of Atmospheric Physics Carbon Dioxide Retrieval Algorithm for Satellite Remote Sensing (IAPCAS), and CarbonTracker-China (CT-China), developed at the Chinese Academy of Sciences. The Greenhouse gases Observing SATellite (GOSAT) measurements are used in the carbon flux inversion experiment. To improve the quality of the IAPCAS-GOSAT retrieval, we have developed a post-screening and bias correction method, resulting in 25%–30% of the data remaining after quality control. Based on these data, the seasonal variation of XCO2 (column-averaged CO2 dry-air mole fraction) is studied, and a strong relation with vegetation cover and population is identified. Then, the IAPCAS-GOSAT XCO2 product is used in carbon flux estimation by CT-China. The net ecosystem CO2 exchange is −0.34 Pg C yr−1 (±0.08 Pg C yr−1), with a large error reduction of 84%, which is a significant improvement on the error reduction when compared with in situ-only inversion."
journal_title,Advances in Atmospheric Sciences
article_title,Grid-cell aerosol direct shortwave radiative forcing calculated using the SBDART model with MODIS and AERONET observations: An application in winter and summer in eastern China
keyword,"['aerosol direct radiative forcing\xa0', 'AERONET\xa0', 'MODIS\xa0', 'SBDART model\xa0', '气溶胶直接辐射强迫\xa0', 'AERONET\xa0', 'MODIS\xa0', 'SBDART模式\xa0']"
history,"['2017-08', '2017-06-29', '2016-08-31', '2017-02-07', '2017-02-09']"
abstract,"Abstract Taking winter and summer in eastern China as an example application, a grid-cell method of aerosol direct radiative forcing (ADRF) calculation is examined using the Santa Barbara DISORT Atmospheric Radiative Transfer (SBDART) model with inputs from MODIS and AERONET observations and reanalysis data. Results  show that there are significant seasonal and regional differences in climatological mean aerosol optical parameters and ADRF. Higher aerosol optical depth (AOD) occurs in summer and two prominent high aerosol loading centers are observed. Higher single scattering albedo (SSA) in summer is likely associated with the weak absorbing secondary aerosols. SSA is higher in North China during summer but higher in South China during winter. Aerosols induce negative forcing at the top of the atmosphere (TOA) and surface during both winter and summer, which may be responsible for the decrease in temperature and the increase in relative humidity. Values of ADRF at the surface are four times stronger than those at the TOA. Both AOD and ADRF present strong interannual variations; however, their amplitudes are larger in summer. Moreover, patterns and trends of ADRF do not always correspond well to those of AOD. Differences in the spatial distributions of ADRF between strong and weak monsoon years are captured effectively. Generally, the present results justify that to calculate grid-cell ADRF at a large scale using the SBDART model with observational aerosol optical properties and reanalysis data is an effective approach."
journal_title,Advances in Atmospheric Sciences
article_title,"Validation of MODIS C6 AOD products retrieved by the Dark Target method in the Beijing–Tianjin–Hebei urban agglomeration, China"
keyword,"['aerosol\xa0', 'urban agglomeration\xa0', 'MODIS\xa0', 'AOD\xa0', '气溶胶\xa0', '城市群\xa0', 'MODIS\xa0', '气溶胶光学厚度\xa0']"
history,"['2017-08', '2017-06-29', '2016-08-29', '2016-11-10', '2016-11-24']"
abstract,"Abstract The quality of the MODIS C6 3-km and 10-km aerosol optical depth (AOD) products retrieved by the Dark Target (DT) method is discussed using ground-based observations in the Beijing–Tianjin–Hebei region from 1 August 2007 to 31 July 2008. Good consistency exists between the 3-km and 10-km products and ground-based observations. The retrieval accuracy of the two products both show distinctive seasonality. The percentage falling within the expected error (EE) is largest in the winter, moderate in the spring and autumn, and smallest in the summer. A worse overestimation appears in the spring and summer (27%–66%). However, the 3-km and 10-km products over different surfaces still exhibit obvious deviations. The 10-km product performs better in the large cities, while the 3-km product has advantages in the suburbs. In urban areas, the percentage falling within EE of the 3-km AOD product (18%–59%) is lower than that for the 10-km AOD product (31%–69%). However, in suburban areas, the percentage falling within EE of the 3-km AOD product (61%–84%) is higher than for the 10 km AOD product (54%–83%).The percentages falling within EE differ considerably when the AOD is greater than 1.5 (73% and 63% for the 3-km and 10-km products, respectively). On the whole, the 3-km (10-km) AOD product performs better in suburban (urban) areas."
journal_title,Advances in Atmospheric Sciences
article_title,Interdecadal variability of the Afro-Asian summer monsoon system
keyword,"['Afro-Asian summer monsoon\xa0', 'precipitation\xa0', 'Atlantic Multidecadal Oscillation (AMO)\xa0', 'teleconnection\xa0', 'tropical easterly jet\xa0', '亚非季风系统\xa0', '降水\xa0', '北大西洋年代际振荡\xa0', '遥相关\xa0', '热带东风急流\xa0']"
history,"['2017-07', '2017-06-08', '2016-09-21', '2017-02-21', '2017-03-14']"
abstract,"Abstract The Afro-Asian summer monsoon is a zonally planetary-scale system, with a large-scale rainbelt covering Africa, South Asia and East Asia on interdecadal timescales both in the past century (1901–2014) and during the last three decades (1979–2014). A recent abrupt change of precipitation occurred in the late 1990s. Since then, the entire rainbelt of the Afro-Asia monsoon system has advanced northwards in a coordinated way. Consistent increases in precipitation over the Huanghe–Huaihe River valley and the Sahel are associated with the teleconnection pattern excited by the warm phase of the Atlantic Multidecadal Oscillation (AMO). A teleconnection wave train, with alternating cyclones/anticyclones, is detected in the upper troposphere. Along the teleconnection path, the configuration of circulation anomalies in North Africa is characterized by coupling of the upper-level anticyclone (divergence) with low-level thermal low pressure (convergence), facilitating the initiation and development of ascending motions in the Sahel. Similarly, in East Asia, a coupled circulation pattern also excites ascending motion in the Huanghe–Huaihe River valley. The synchronous increase in precipitation over the Sahel and Huanghe–Huaihe River valley can be attributed to the co-occurrences and in-phase changes of ascending motion. On the other hand, the warm phase of the AMO results in significant warming in the upper troposphere in North Africa and the northern part of East Asia. Such warming contributes to intensification of the tropical easterly jet through increasing the meridional pressure gradient both at the entrance region (East Asia) and the exit region (Africa). Accordingly, precipitation over the Sahel and Huanghe–Huaihe River valley intensifies, owing to ageostrophic secondary cells. The results of this study provide evidence for a consistent and holistic interdecadal change in the Afro-Asian summer monsoon."
journal_title,Advances in Atmospheric Sciences
article_title,Comparison of aerosol effects on simulated spring and summer hailstorm clouds
keyword,"['cloud condensation nuclei (CCN)\xa0', 'microphysical process\xa0', 'hailstorm\xa0', 'precipitation\xa0', '云凝结核(CCN)\xa0', '微物理过程\xa0', '强风暴\xa0', '降水\xa0']"
history,"['2017-07', '2017-06-08', '2016-05-31', '2017-02-08', '2017-03-17']"
abstract,"Abstract Numerical simulations are carried out to investigate the effect of cloud condensation nuclei (CCN) concentrations on microphysical processes and precipitation characteristics of hailstorms. Two hailstorm cases are simulated, a spring case and a summer case, in a semiarid region of northern China, with the Regional Atmospheric Modeling System. The results are used to investigate the differences and similarities of the CCN effects between spring and summer hailstorms. The similarities are: (1) The total hydrometeor mixing ratio decreases, while the total ice-phase mixing ratio enhances, with increasing CCN concentration; (2) Enhancement of the CCN concentration results in the production of a greater amount of small-sized hydrometeor particles, but a lessening of large-sized hydrometeor particles; (3) As the CCN concentration increases, the supercooled cloud water and rainwater make a lesser contribution to hail, while the ice-phase hydrometeors take on active roles in the growth of hail; (4) When the CCN concentration increases, the amount of total precipitation lessens, while the role played by liquid-phase rainfall in the amount of total precipitation reduces, relatively, compared to that of ice-phase precipitation. The differences between the two storms include: (1) An increase in the CCN concentration tends to reduce pristine ice mixing ratios in the spring case but enhance them in the summer case; (2) Ice-phase hydrometeor particles contribute more to hail growth in the spring case, while liquid water contributes more in the summer case; (3) An increase in the CCN concentration has different effects on surface hail precipitation in different seasons."
journal_title,Advances in Atmospheric Sciences
article_title,Two ultraviolet radiation datasets that cover China
keyword,"['ultraviolet radiation\xa0', 'observation\xa0', 'hybrid model\xa0', 'reconstruction\xa0', 'China\xa0', '紫外辐射\xa0', '观测\xa0', '混合模型\xa0', '重构\xa0', '中国\xa0']"
history,"['2017-07', '2017-06-08', '2016-12-01', '2017-02-16', '2017-03-14']"
abstract,"Abstract Ultraviolet (UV) radiation has significant effects on ecosystems, environments, and human health, as well as atmospheric processes and climate change. Two ultraviolet radiation datasets are described in this paper. One contains hourly observations of UV radiation measured at 40 Chinese Ecosystem Research Network stations from 2005 to 2015. CUV3 broadband radiometers were used to observe the UV radiation, with an accuracy of 5%, which meets the World Meteorology Organization’s measurement standards. The extremum method was used to control the quality of the measured datasets. The other dataset contains daily cumulative UV radiation estimates that were calculated using an all-sky estimation model combined with a hybrid model. The reconstructed daily UV radiation data span from 1961 to 2014. The mean absolute bias error and root-mean-square error are smaller than 30% at most stations, and most of the mean bias error values are negative, which indicates underestimation of the UV radiation intensity. These datasets can improve our basic knowledge of the spatial and temporal variations in UV radiation. Additionally, these datasets can be used in studies of potential ozone formation and atmospheric oxidation, as well as simulations of ecological processes."
journal_title,International Journal of Information Security
article_title,Outsourced pattern matching
keyword,"['94A60 Cryptography\xa0', 'Outsourced secure computation\xa0', 'Pattern matching\xa0', 'Subset sum\xa0']"
history,"['2018-06', '2017-05-02']"
abstract,"Abstract In secure delegatable computation, computationally weak devices (or clients) wish to outsource their computation and data to an untrusted server in the cloud. While most earlier work considers the general question of how to securely outsource any computation to the cloud server, we focus on concrete and important functionalities and give the first protocol for the pattern matching problem in the cloud. Loosely speaking, this problem considers a text T that is outsourced to the cloud \({\textsc {S}}\) by a sender \({\textsc {SEN}}\). In a query phase, receivers \({\textsc {REC}}_1, \ldots , {\textsc {REC}}_l\) run an efficient protocol with the server \({\textsc {S}}\) and the sender \({\textsc {SEN}}\) in order to learn the positions at which a pattern of length m matches the text (and nothing beyond that). This is called the outsourced pattern matching problem which is highly motivated in the context of delegatable computing since it offers storage alternatives for massive databases that contain confidential data (e.g., health-related data about patient history). Our constructions are simulation-based secure in the presence of semi-honest and malicious adversaries (in the random oracle model) and limit the communication in the query phase to O(m) bits plus the number of occurrences—which is optimal. In contrast to generic solutions for delegatable computation, our schemes do not rely on fully homomorphic encryption but instead use novel ideas for solving pattern matching, based on a reduction to the subset sum problem. Interestingly, we do not rely on the hardness of the problem, but rather we exploit instances that are solvable in polynomial time. A follow-up result demonstrates that the random oracle is essential in order to meet our communication bound."
journal_title,International Journal of Information Security
article_title,Verifiably encrypted cascade-instantiable blank signatures to secure progressive decision management
keyword,"['Digital signature\xa0', 'Blank signature\xa0', 'Proxy signature\xa0', 'Sanitizable signature\xa0', 'Redactable signature\xa0', 'Verifiably encrypted signature\xa0', 'Optimistic fair exchange\xa0', 'Delegation chain\xa0']"
history,"['2018-06', '2017-04-12']"
abstract,"Abstract In this paper, we introduce the notion of verifiably encrypted cascade-instantiable blank signatures (CBS) in a multi-user setting. In CBS, there is a delegation chain that starts with an originator and is followed by a sequence of proxies. The originator creates and signs a template, which may comprise fixed fields and exchangeable fields. Thereafter, each proxy along the delegation chain is able to make an instantiation of the template from the choices passed down from her direct predecessor, before generating a signature for her instantiation. First, we present a non-interactive basic CBS construction that does not rely on any shared secret parameters among the users. In verifying an instantiation signature, all the preceding instantiation signatures leading back to the template signature are also verified concurrently. It is formally proved to be secure against collusion attacks by the originator and proxies. Second, we investigate verifiably encrypted CBS to provide fairness between the originator and proxies, where the security model is stricter than basic CBS in that the adversary may also collude with the arbitrator. Efficiency analysis shows that the proposed CBS schemes enjoy linear computation costs. Finally, we extend our scheme to CBS supporting designated instantiations, free instantiations, privately verifiable template signature, identity-based CBS, as well as CBS secure against proxy-key exposure."
journal_title,International Journal of Information Security
article_title,Dynamic group size accreditation and group discounts preserving anonymity
keyword,"['Buyer privacy\xa0', 'Group size accreditation\xa0', 'Group discounts\xa0', 'Digital signatures\xa0', 'Smartphones\xa0', 'Short-range communications\xa0']"
history,"['2018-06', '2017-04-10']"
abstract,"Abstract Group discounts are used by vendors and authorities to encourage certain behaviors. For example, group discounts can be applied to highway tolls to encourage ride sharing, or by museum managers to ensure a minimum number of visitors and plan guided tours more efficiently. We show how group discounts can be offered without forcing customers to surrender their anonymity, as long as customers are equipped with some form of autonomous computing device (e.g. smartphone, tablet or computer). Specifically, we present a protocol suite for privacy-aware group discounts that allows a group of customers to prove how many they are without disclosing their identities. The group does not need to be a stable one, but can have been formed on the fly. Coupled with an anonymous payment system, this makes group discounts compatible with buyer privacy (in this case, buyer anonymity). We present a detailed complexity analysis, we give simulation results, and we report on a pilot implementation."
journal_title,International Journal of Information Security
article_title,Design and implementation of a secure and trustworthy platform for privacy-aware video surveillance
keyword,"['Video surveillance\xa0', 'Privacy\xa0', 'Identity concealment\xa0', 'Video processing\xa0']"
history,"['2018-06', '2017-04-08']"
abstract,"Abstract Worldwide, thousands of video surveillance cameras record our daily activities. People are aware that video surveillance is deployed for the sake of security. However, the privacy of individuals would be endangered if the proper measures were not considered. Privacy-aware video surveillance has historically been addressed by proposals based on detecting individuals and other sensitive parts of the video and hiding them using a variety of techniques. In this paper, we present a comprehensive solution tackling video processing, video protection and management of the Information System. We claim that a video surveillance system can protect our safety and, at the same time, guarantee our privacy. We describe the design and implementation of a privacy-aware video surveillance platform that, in order to be trustworthy, accomplishes with the properties of high detection accuracy, real-time performance and protected video utility. We have tested the proposed platform, and we demonstrate the feasibility of our approach for privacy protection."
journal_title,International Journal of Information Security
article_title,Distributed star coloring of network for IP traceback
keyword,"['Distributed star coloring\xa0', 'Hashing\xa0', 'Convergence\xa0']"
history,"['2018-06', '2017-03-27']"
abstract,"Abstract IP traceback using packet marking technique allows direct traceback of attackers. Under this strategy en route routers inject mark into packets which is later used to unambiguously identify the source of an attack. Star coloring approach allows the mark to be reused, thereby saving bit space and at the same time explicitly identify the attacker. As the Internet structure is unknown, in the present work we propose a distributed approach of assigning color (mark) to routers such that the star color template is followed without consideration of the graph structure. An algorithm is proposed to minimize the color assignment conflict. The convergence of the algorithm is also discussed. Simulation study is presented to support the convergence analysis."
journal_title,International Journal of Information Security
article_title,Anonymous subject identification and privacy information management in video surveillance
keyword,"['Anonymous subject identification\xa0', 'Privacy information management\xa0', 'Privacy protection\xa0', 'Video surveillance\xa0', 'Garbled circuit\xa0']"
history,"['2018-06', '2017-06-15']"
abstract,"Abstract The widespread deployment of surveillance cameras has raised serious privacy concerns, and many privacy-enhancing schemes have been recently proposed to automatically redact images of selected individuals in the surveillance video for protection. Of equal importance are the privacy and efficiency of techniques to first, identify those individuals for privacy protection and second, provide access to original surveillance video contents for security analysis. In this paper, we propose an anonymous subject identification and privacy data management system to be used in privacy-aware video surveillance. The anonymous subject identification system uses iris patterns to identify individuals for privacy protection. Anonymity of the iris-matching process is guaranteed through the use of a garbled-circuit (GC)-based iris matching protocol. A novel GC complexity reduction scheme is proposed by simplifying the iris masking process in the protocol. A user-centric privacy information management system is also proposed that allows subjects to anonymously access their privacy information via their iris patterns. The system is composed of two encrypted-domain protocols: The privacy information encryption protocol encrypts the original video records using the iris pattern acquired during the subject identification phase; the privacy information retrieval protocol allows the video records to be anonymously retrieved through a GC-based iris pattern matching process. Experimental results on a public iris biometric database demonstrate the validity of our framework."
journal_title,International Journal of Information Security
article_title,Stealing PINs via mobile sensors: actual risk versus user perception
keyword,"['Mobile sensors\xa0', 'JavaScript attack\xa0', 'Mobile browsers\xa0', 'User security\xa0', 'User privacy\xa0', 'Machine learning\xa0', 'PINs\xa0', 'Risk perception\xa0', 'User study\xa0']"
history,"['2018-06', '2017-04-07']"
abstract,"Abstract In this paper, we present the actual risks of stealing user PINs by using mobile sensors versus the perceived risks by users. First, we propose PINlogger.js which is a JavaScript-based side channel attack revealing user PINs on an Android mobile phone. In this attack, once the user visits a website controlled by an attacker, the JavaScript code embedded in the web page starts listening to the motion and orientation sensor streams without needing any permission from the user. By analysing these streams, it infers the user’s PIN using an artificial neural network. Based on a test set of fifty 4-digit PINs, PINlogger.js is able to correctly identify PINs in the first attempt with a success rate of 74% which increases to 86 and 94% in the second and third attempts, respectively. The high success rates of stealing user PINs on mobile devices via JavaScript indicate a serious threat to user security. With the technical understanding of the information leakage caused by mobile phone sensors, we then study users’ perception of the risks associated with these sensors. We design user studies to measure the general familiarity with different sensors and their functionality, and to investigate how concerned users are about their PIN being discovered by an app that has access to all these sensors. Our studies show that there is significant disparity between the actual and perceived levels of threat with regard to the compromise of the user PIN. We confirm our results by interviewing our participants using two different approaches, within-subject and between-subject, and compare the results. We discuss how this observation, along with other factors, renders many academic and industry solutions ineffective in preventing such side channel attacks."
journal_title,International Journal of Information Security
article_title,Using targeted Bayesian network learning for suspect identification in communication networks
keyword,"['Targeted Bayesian network learning\xa0', 'Suspect identification\xa0', 'Behavioral patterns\xa0', 'Privacy\xa0', 'Security\xa0', 'Machine learning\xa0', 'Cyber crimes\xa0', 'Criminal behavior\xa0']"
history,"['2018-04', '2017-02-08']"
abstract,"Abstract This paper proposes a machine learning application to identify mobile phone users suspected of involvement in criminal activities. The application characterizes the behavioral patterns of suspect users versus non-suspect users based on usage metadata such as call duration, call distribution, interaction time preferences and text-to-call ratios while avoiding any access to the content of calls or messages. The application is based on targeted Bayesian network learning method. It generates a graphical network that can be used by domain experts to gain intuitive insights about the key features that can help identify suspect users. The method enables experts to manage the trade-off between model complexity and accuracy using information theory metrics. Unlike other graphical Bayesian classifiers, the proposed application accomplishes the task required of a security company, namely an accurate suspect identification rate (recall) of at least 50% with no more than a 1% false identification rate. The targeted Bayesian network learning method is also used for additional tasks such as anomaly detection, distinction between “relevant” and “irrelevant” anomalies, and for associating anonymous telephone numbers with existing users by matching behavioral patterns."
journal_title,International Journal of Information Security
article_title,Accumulable optimistic fair exchange from verifiably encrypted homomorphic signatures
keyword,"['Optimistic fair exchange\xa0', 'Homomorphic signatures\xa0', 'Verifiably encrypted signatures\xa0']"
history,"['2018-04', '2017-03-22']"
abstract,"Abstract Let us consider a situation where a client (Alice) frequently buys a certain kind of product from a shop (Bob) (e.g., an online music service sells individual songs at the same price, and a client buys songs multiple times in a month). In this situation, Alice and Bob would like to aggregate the total transactions and pay once per month because individual payments are troublesome. Though optimistic fair exchange (OFE) has been considered in order to swap electronic items simultaneously, known OFE protocols cannot provide such aggregate function efficiently because various costs are bounded by the number of transactions in the period. In order to run this aggregation procedure efficiently, we introduce a new kind of OFE called accumulable OFE (AOFE) that allows clients to efficiently accumulate payments in each period. In AOFE, any memory costs, computational costs, and communication complexity of the payment round must be constant in terms of the number of transactions. Since a client usually has just a low power and poor memory device, these efficiencies are desirable in practice. Currently, known approaches (e.g., based on verifiably encrypted signature scheme) are not very successful for constructing AOFE. Thus, we consider a new approach based on a new cryptographic primitive called verifiably encrypted homomorphic signature scheme (VEHS). In this paper, we propose a generic construction of AOFE from VEHS and also present a concrete VEHS scheme over a composite-order bilinear group by using the dual-form signature techniques. This VEHS scheme is also of independent interest. Since we can prove the security of VEHS without random oracles, our AOFE protocol is also secure without random oracles. Finally, we implemented our AOFE protocol, and it is efficient enough for practical use."
journal_title,International Journal of Information Security
article_title,A methodology to measure and monitor level of operational effectiveness of a CSOC
keyword,"['Intrusion detection\xa0', 'Cybersecurity operations center\xa0', 'Level of operational effectiveness\xa0', 'Total time for alert investigation\xa0', 'Situational awareness of CSOC\xa0']"
history,"['2018-04', '2017-02-16']"
abstract,"Abstract In a cybersecurity operations center (CSOC), under normal operating conditions in a day, sufficient numbers of analysts are available to analyze the amount of alert workload generated by intrusion detection systems (IDSs). For the purpose of this paper, this means that the cybersecurity analysts can fully investigate each and every alert that is generated by the IDSs in a reasonable amount of time. However, there are a number of disruptive factors that can adversely impact the normal operating conditions such as (1) higher alert generation rates from a few IDSs, (2) new alert patterns that decreases the throughput of the alert analysis process, and (3) analyst absenteeism. The impact of all the above factors is that the alerts wait for a long duration before being analyzed, which impacts the readiness of the CSOC. It is imperative that the readiness of the CSOC be quantified, which in this paper is defined as the level of operational effectiveness (LOE) of a CSOC. LOE can be quantified and monitored by knowing the exact deviation of the CSOC conditions from normal and how long it takes for the condition to return to normal. In this paper, we quantify LOE by defining a new metric called total time for alert investigation (TTA), which is the sum of the waiting time in the queue and the analyst investigation time of an alert after its arrival in the CSOC database. A dynamic TTA monitoring framework is developed in which a nominal average TTA per hour (avgTTA/hr) is established as the baseline for normal operating condition using individual TTA of alerts that were investigated in that hour. At the baseline value of avgTTA/hr, LOE is considered to be ideal. Also, an upper-bound (threshold) value for avgTTA/hr is established, below which the LOE is considered to be optimal. Several case studies illustrate the impact of the above disruptive factors on the dynamic behavior of avgTTA/hr, which provide useful insights about the current LOE of the system. Also, the effect of actions taken to return the CSOC to its normal operating condition is studied by varying both the amount and the time of action, which in turn impacts the dynamic behavior of avgTTA/hr. Results  indicate that by using the insights learnt from measuring, monitoring, and controlling the dynamic behavior of avgTTA/hr, a manager can quantify and color-code the LOE of the CSOC. Furthermore, the above insights allow for a deeper understanding of acceptable downtime for the IDS, acceptable levels for absenteeism, and the recovery time and effort needed to return the CSOC to its ideal LOE."
journal_title,International Journal of Information Security
article_title,Dynamic reversed accumulator
keyword,"['Dynamic accumulator\xa0', 'Revocation\xa0', 'Zero-knowledge proof\xa0']"
history,"['2018-04', '2017-01-19']"
abstract,"Abstract Anonymous credential schemes have been widely employed to prove the authenticity of a member by revealing specific member attributes while concealing the real identity from the verifier. Furthermore, an accumulator is used to demonstrate the validity of the credential by providing a corresponding witness. In existing accumulator schemes, all credential holders must update their witnesses when a member joins or is revoked from the system, causing the schemes to become impractical. This paper examines the security of several recent accumulator schemes and proposes a novel approach, the dynamic reversed accumulator, which is more efficient than existing schemes because a corresponding witness can be updated when several members have been revoked."
journal_title,International Journal of Information Security
article_title,Structural analysis and detection of android botnets using machine learning techniques
keyword,"['Android botnet\xa0', 'Structural analysis\xa0', 'Unique patterns\xa0', 'Machine learning techniques\xa0', 'Statistical test\xa0']"
history,"['2018-04', '2017-02-01']"
abstract,"Abstract Nowadays, smartphone devices are an integral part of our lives since they enable us to access a large variety of services from personal to banking. The worldwide popularity and adoption of smartphone devices continue to approach the capabilities of traditional computing environments. The computer malware like botnets is becoming an emerging threat to users and network operators, especially on popular platform such as android. Due to the rapid growth of botnet applications, there is a pressing need to develop an effective solution to detect them. Most of the existing detection techniques can detect only malicious android applications, but it cannot detect android botnet applications. In this paper, we propose a structural analysis-based learning framework, which adopts machine learning techniques to classify botnets and benign applications using the botnet characteristics-related unique patterns of requested permissions and used features. The experimental evaluation based on real-world benchmark datasets shows that the selected patterns can achieve high detection accuracy with low false positive rate. The experimental and statistical tests show that the support vector machine classifier performs well compared to other classification algorithms."
journal_title,International Journal of Information Security
article_title,HoneyCirculator: distributing credential honeytoken for introspection of web-based attack cycle
keyword,"['Web-based malware\xa0', 'Client honeypot\xa0', 'Malware sandbox\xa0', 'Honeytokens\xa0', 'Information leakage\xa0']"
history,"['2018-04', '2017-01-30']"
abstract,"Abstract A web user who falsely accesses a compromised website is usually redirected to an adversary’s website and is forced to download malware after being exploited. Additionally, the adversary steals the user’s credentials by using information-leaking malware. The adversary may also try to compromise public websites owned by individual users by impersonating the website administrator using the stolen credentials. These compromised websites then become landing sites for drive-by download malware infection. Identifying malicious websites using crawling techniques requires a large amount of resources and time. To monitor the web-based attack cycle for effective detection and prevention, we propose a monitoring system called HoneyCirculator based on a honeytoken, which actively leaks bait credentials and lures adversaries to our decoy server that behaves like a compromised web content management system. To recursively analyze attack phases on the web-based attack cycle, our proposed system involves collecting malware, distributing bait credentials, monitoring fraudulent access, and inspecting compromised web content. It can instantly discover unknown malicious entities without conducting large-scale web crawling because of the direct monitoring behind the compromised web content management system. Our proposed system enables continuous and stable monitoring for about one year. In addition, almost all the malicious websites we discovered had not been previously registered in public blacklists."
journal_title,International Journal of Information Security
article_title,A game-theoretic approach for integrity assurance in resource-bounded systems
keyword,"['Message authentication\xa0', 'Game theory\xa0', 'Economics of security\xa0', 'Resource-bounded system\xa0']"
history,"['2018-04', '2017-01-31']"
abstract,"Abstract Assuring communication integrity is a central problem in security. However, overhead costs associated with cryptographic primitives used toward this end introduce significant practical implementation challenges for resource-bounded systems, such as cyber-physical systems. For example, many control systems are built on legacy components which are computationally limited, but have strict timing constraints. If integrity protection is a binary decision, it may simply be infeasible to introduce into such systems; without it, however, an adversary can forge malicious messages, which can cause significant physical or financial harm. To bridge the gap between such binary decisions, we propose a stochastic message authentication approach that can explicitly trade computational cost off for security. We introduce a formal game-theoretic framework for optimal stochastic message authentication, providing provable guarantees for resource-bounded systems based on an existing message authentication scheme. We use our framework to investigate attacker deterrence, as well as optimal stochastic message authentication when deterrence is impossible, in both short-term and long-term equilibria. Additionally, we propose two schemes for implementing stochastic message authentication in practice, one for saving computation only at the receiver and one for saving computation at both ends, and demonstrate the associated computational savings using an actual implementation."
journal_title,International Journal of Information Security
article_title,Identifier discrimination: realizing selective-ID HIBE with authorized delegation and dedicated encryption privacy
keyword,"['Hierarchical identity-based encryption\xa0', 'Authorized delegation\xa0', 'Encryption privacy\xa0', 'Identifier discrimination\xa0']"
history,['2018-03-07']
abstract,"Abstract It has been almost one and a half decades since the introduction of the concept of hierarchical identity-based encryption (HIBE) systems, and many pairing-based HIBE systems have been proposed; however, how to achieve independent private key delegation in HIBE systems is still open. Independent private key delegation in HIBE systems requires that the following three conditions are satisfied: (1) private keys are not valid delegation credentials for deriving descendants’ private keys, (2) any entity intending to derive a private key for any one of its descendants should own a valid delegation credential distributed by the root private key generator (PKG), and (3) a credential is only valid for deriving private keys for a given descendant. We present a new technique for composing private keys for entities in HIBE systems that we call identifier discrimination, aiming at resolving the problem of independent private key delegation. With the technique, we construct a selective identity secure HIBE system under the decisional bilinear Diffie–Hellman (DBDH) assumption in the standard model with the following properties. (1) Every entity in the HIBE system is prevented from deriving private keys for its descendants with the only use of its private key and the public parameters. (2) The root PKG can delegate the privilege (if needed) of generating private keys for each individual entity to any of its ancestors through authorization that we call authorized delegation, by distributing a specifically crafted secret (delegation credential) to the ancestor. (3) The encryption privacy of each ciphertext for its intended recipient is achieved, that is, ciphertexts encrypted on identity of any entity cannot be decrypted by any of its ancestors that we call dedicated encryption privacy."
journal_title,International Journal of Information Security
article_title,Deployment and performance evaluation of mobile multicoupon solutions
keyword,"['Mobile commerce\xa0', 'Electronic coupon\xa0', 'Mobile devices\xa0', 'Implementation\xa0', 'Performance evaluation\xa0', 'Group key certification\xa0']"
history,['2018-02-24']
abstract,"Abstract Mobile commerce (m-commerce) represents an important area of business with a huge potential revenue for merchants and great opportunities for customers to achieve better offers. One of the topics within m-commerce that needs important improvements on usability and efficiency is electronic coupon systems. This is because solutions for electronic coupons are focused on their theoretical definition, overlooking both their performance evaluation and their viability analysis. In this paper, we provide an evaluation framework to test multicoupon solutions. Under this framework, we evaluate two particular multicoupon schemes, obtaining interesting performance results, such as the fact that cryptographic operations are not always the most costly processes, as usually claimed by authors of multicoupon schemes. We show that message encoding can help to improve the efficiency of multicoupon solutions, even up to 50% of the overhead over the network. Moreover, we solve other issues related to the viability of these schemes, for example, using a standardized way to distribute non-standard cryptographic key material. Therefore, the viability of a multicoupon solution should be validated considering all involved factors, such as internal processing, networking, message encoding and current technology support."
journal_title,International Journal of Information Security
article_title,Reverse engineering Java Card and vulnerability exploitation: a shortcut to ROM
keyword,"['Smart card\xa0', 'Java Card\xa0', 'Reverse engineering\xa0', 'Native calls\xa0', 'Vulnerability exploitation\xa0']"
history,['2018-02-22']
abstract,"Abstract Secure elements store and manipulate assets in a secure way. The most attractive assets are the cryptographic keys stored into the memory that can be used to provide secure services to a system. For this reason, secure elements are prone to attacks. But retrieving assets inside such a highly secure device is a challenging task. This paper presents the process we used to gain access to the assets in the particular case of Java Card secure element. In a Java Card, the assets are stored securely, i.e., respecting confidentiality and integrity attributes. Only the native layers can manipulate these sensitive objects. Thus, the Java interpreter, the API and the run time act as a firewall between the assets and the Java applications that one can load into the device. Finding a vulnerability into this piece of software is of a prime importance. Finding a vulnerability into a software is often not enough to develop a complete exploit. Here, we demonstrate at the end that a Java Card applet can call the hidden native functions used to decipher the secure container that encapsulates a key. Some previous attacks have shown the ability to get access to the application code area. But the Java Card intermediate byte code detected in the dumps has shown several differences with regard to the specification, which prevents the reverse engineering of the applicative code. Thus, to avoid the execution of shell code by a hostile applet, a part of the byte code stored into the card is unknown. The transformation is done on-the-fly during the upload of an application. We present in this article a new approach for reversing the unknown instruction set of the intermediate byte code which in turn has led to reverse engineering of the Java classes of the attacked card. We discovered during the reverse that some method calls have an unusual signature. Without having access to the native code, we have inferred the semantics of the called methods and their calling convention. These methods have access to the assets of the card without being restricted by security mechanisms like the firewall. We exploit this knowledge to set up a new attack that provides a full access to the cryptographic material and allows to reset the state of the card to the initial configuration. We demonstrate the ability to call these methods at the Java level in an application to retrieve sensitive assets whatever the protections are. Then, we suggest several possibilities to mitigate these attacks."
journal_title,International Journal of Information Security
article_title,Differential audio analysis: a new side-channel attack on PIN pads
keyword,"['Information security\xa0', 'Side-channel attack\xa0', 'Acoustic emission\xa0', 'Transfer function\xa0', 'Smart card skimming\xa0', 'PCI\xa0', 'EMV\xa0', 'Pin entry device\xa0', 'Common criteria\xa0', 'PIN pad\xa0']"
history,['2018-02-16']
abstract,"Abstract This paper introduces a low-cost side-channel attack that identifies the pressed key of tamper-proof mechanical keypads by exploiting the sound that emanates from the pressed key. Classical sound-based attacks usually identify the pressed key using the fact that each key emits a characteristic sound. These techniques use, for example, the frequency spectrum to identify the key. Instead, our attack (named DAA—differential audio analysis) analyzes the differential characteristics of the sounds captured by two microphones placed inside the empty space of the device, expressed as the transfer function between the two signals. We applied our attack to four PIN entry devices—also known as PIN pads. Our technique was able to correctly recognize all 1200 keystrokes of two independently tested equipments of the same model, generating a classification rate of 100%. We also attacked the same PIN pads using the classical frequency spectrum technique, obtaining the average classification rate of only 78%. This result shows clearly the superiority of the new technique. Our attack also successfully attacked a second model from another manufacturer, with classification rate of 99.8%. However, some PIN pads do not emit sufficiently audible sound when a key is pressed. Evidently, these devices cannot be attacked analyzing audio emission. We applied our DAA attack to a device of this kind and obtained only 63% of classification success. This result shows that there are models quite vulnerable and models not as vulnerable to our attack. Finally, we present design suggestions in order to mitigate the vulnerabilities that make our attack possible. These vulnerabilities are present in many certified PIN pad models available currently in the worldwide market."
journal_title,International Journal of Information Security
article_title,Hiding information against structural re-identification
keyword,"['Anonymity\xa0', 'Privacy\xa0', 'Social networks\xa0', 'Re-identification\xa0', 'Identity separation\xa0']"
history,['2018-02-13']
abstract,"Abstract Connections between users of social networking services pose a significant privacy threat. Recently, several social network de-anonymization attacks have been proposed that can efficiently re-identify users at large scale, solely considering the graph structure. In this paper, we consider these privacy threats and analyze de-anonymization attacks at the model level against a user-controlled privacy-enhancing technique called identity separation. The latter allows creating seemingly unrelated identities in parallel, even without the consent of the service provider or other users. It has been shown that identity separation can be used efficiently against re-identification attacks if user cooperate with each other. However, while participation would be crucial, this cannot be granted in a real-life scenario. Therefore, we introduce the y-identity model, in which the user creates multiple separated identities and assigns the sensitive attribute to one of them according to a given strategy. For this, we propose a strategy to be used in real-life situations and formally prove that there is a higher bound for the expected privacy loss which is sufficiently low."
journal_title,International Journal of Information Security
article_title,Achieving dynamicity in security policies enforcement using aspects
keyword,"['Access control\xa0', 'Usage control\xa0', 'Security policies\xa0', 'AOP\xa0', 'Deployment\xa0']"
history,"['2018-02', '2017-01-09']"
abstract,"Abstract The dynamic configuration and evolution of large-scale heterogeneous systems has made the enforcement of security requirements one of the most critical phases throughout the system development lifecycle. In this paper, we propose a framework architecture to associate the security policies with the specification and the execution phases of applications defined for these systems. Our proposed framework is based on an aspect-oriented programming approach and on the organization-based access control model to dynamically enforce and manage the access and the usage control. The deployment of the framework modules, proposed in this paper, takes into account the changes that may occur in the security policy during the application execution. We also present the implementation as well as the evaluation of our proposition."
journal_title,International Journal of Information Security
article_title,Privacy-preserving smart metering revisited
keyword,"['Universally composable security\xa0', 'Privacy\xa0', 'Billing\xa0', 'Smart meters\xa0', 'Polynomial commitments\xa0']"
history,"['2018-02', '2016-11-28']"
abstract,"Abstract Privacy-preserving billing protocols are useful in settings where a meter measures user consumption of some service, such as smart metering of utility consumption, pay-as-you-drive insurance and electronic toll collection. In such settings, service providers apply fine-grained tariff policies that require meters to provide a detailed account of user consumption. The protocols allow the user to pay to the service provider without revealing the user’s consumption measurements. Our contribution is twofold. First, we propose a general model where a meter can output meter readings to multiple users, and where a user receives meter readings from multiple meters. Unlike previous schemes, our model accommodates a wider variety of smart metering applications. Second, we describe a protocol based on polynomial commitments that improves the efficiency of previous protocols for tariff policies that employ splines to compute the price due."
journal_title,International Journal of Information Security
article_title,Generalized Elias schemes for efficient harvesting of truly random bits
keyword,"['Random number generation\xa0', 'Random number conditioning\xa0', 'Vector quantization\xa0', 'Geometric random variables\xa0', 'Gaussian random variables\xa0']"
history,"['2018-02', '2017-01-02']"
abstract,"Abstract The problem of generating a sequence of true random bits (suitable for cryptographic applications) from random discrete or analog sources is considered. A generalized version, including vector quantization, of the classical approach by Elias for the generation of truly random bits is introduced, and its performance is analyzed, both in the finite case and asymptotically. The theory allows us to provide an alternative proof of the optimality of the original Elias’ scheme. We also consider the problem of deriving random bits from measurements of a Poisson process and from vectors of iid Gaussian variables. The comparison with the scheme of Elias, applied to geometric-like non-binary vectors, originally based on the iso-probability property of permutations of iid variables, confirms the potential of the generalized scheme proposed in our work."
journal_title,International Journal of Information Security
article_title,Formal modeling of random oracle programmability and verification of signature unforgeability using task-PIOAs
keyword,"['Formal methods\xa0', 'Task-PIOA\xa0', 'FDH signature\xa0', 'Random oracle\xa0', 'Programmability\xa0']"
history,"['2018-02', '2016-10-06']"
abstract,"Abstract The task-structured probabilistic I/O automata (task-PIOA) framework provides a method to formulate and to prove the computationally bounded security of non-sequential processing systems in a formal way. Formalizing non-sequential processes for strong adversaries is not easy. Actually, existing security analyses using the task-PIOA framework are for cryptographic protocols (e.g., the EGL oblivious transfer) only against simple adversaries (e.g., honest but curious adversary). For example, there is no case study for digital signature against strong active adversaries (i.e., EUF-CMA) in the task-PIOA framework. In this paper, we propose the first formalization of digital signature against EUF-CMA in the task-PIOA framework. To formalize the non-sequential process of EUF-CMA, we introduce a new technique for the iteration of an identical action in a single session. Using the task-PIOA framework allows us to verify security of signature schemes in the non-sequential scheduling manner. We show the validity and usefulness of our formulation by giving a formal security analysis of the FDH signature scheme. In order to prove the security, we also introduce a method to utilize the power of random oracles. As far as we know, this work is the first case study to clarify usefulness of random oracles in this framework."
journal_title,International Journal of Information Security
article_title,Black-box detection of XQuery injection and parameter tampering vulnerabilities in web applications
keyword,"['Web application security\xa0', 'Vulnerability scanner\xa0', 'Injection attacks\xa0', 'Fuzz testing\xa0', 'Logic vulnerabilities\xa0', 'XML injection\xa0']"
history,"['2018-02', '2017-01-11']"
abstract,"Abstract As web applications become the most popular way to deliver essential services to customers, they also become attractive targets for attackers. The attackers craft injection attacks in database-driven applications through the user-input fields intended for interacting with the applications. Even though precautionary measures such as user-input sanitization is employed at the client side of the application, the attackers can disable the JavaScript at client side and still inject attacks through HTTP parameters. The injected parameters result in attacks due to improper server-side validation of user input. The injected parameters may either contain malicious SQL/XML commands leading to SQL/XPath/XQuery injection or be invalid input that intend to violate the expected behavior of the web application. The former is known as an injection attack, while the latter is called a parameter tampering attack. While SQL injection has been intensively examined by the research community, limited work has been done so far for identifying XML injection and parameter tampering vulnerabilities. Database-driven web applications today rely on XML databases, as XML has gained rapid acceptance due to the fact that it favors integration of data with other applications and handles diverse information. Hence, this work proposes a black-box fuzzing approach to detect XQuery injection and parameter tampering vulnerabilities in web applications driven by native XML databases. A prototype XiParam is developed and tested on vulnerable applications developed with a native XML database, BaseX, as the backend. The experimental evaluation clearly demonstrates that the prototype is effective against detection of both XQuery injection and parameter tampering vulnerabilities."
journal_title,International Journal of Information Security
article_title,Secure pay-TV for chained hotels
keyword,"['TV broadcasting\xa0', 'Data security\xa0', 'Key distribution\xa0', 'Key-leakage tracing\xa0']"
history,"['2018-02', '2016-11-11']"
abstract,"Abstract There is an increasing demand of securely selling pay-TV channels to large organizations such as chained hotels. Most solutions usually employ a key generation authority to distribute secret access credentials for all users, which would cause the single-point problem of inefficient key management. Further, there is a risk of the leakage of users’ access credentials while countermeasures to find out the leaked credentials are lacking. To address such issues, we propose a leakage traceable hierarchical key distribution (LTHKD) framework with the key delegation and the key-leakage tracing. The key delegation allows the key generation authority to apportion the tasks of access credential generation to a number of group authorities; the tracing mechanism provides an efficient method to find out the leaked access credentials. We present a concrete LTHKD scheme by extending hierarchical identity-based encryption to groups with users’ access credentials elegantly encoded by unique fingerprint codes. We formally prove the security of the proposed scheme in a rigorous definition and conduct thorough theoretical and experimental analyses to evaluate the system performance. Surprisingly, the results show that the added key-leakage tracing mechanism has little affection on data encryption and decryption procedures."
journal_title,International Journal of Information Security
article_title,Commix: automating evaluation and exploitation of command injection vulnerabilities in Web applications
keyword,"['Command injection\xa0', 'Code injection\xa0', 'Exploitation\xa0', 'Software tool\xa0', 'Web security\xa0']"
history,['2018-02-01']
abstract,"Abstract Despite the prevalence and the high impact of command injection attacks, little attention has been given by the research community to this type of code injections. Although there are many software tools to detect and exploit other types of code injections, such as SQL injections or cross-site scripting, there is no dedicated and specialized software that detects and exploits, automatically, command injection vulnerabilities. This paper proposes an open-source tool that automates the process of detecting and exploiting command injection flaws on Web applications, named as COMMand Injection eXploiter (Commix). We present and elaborate on the software architecture and detection engine of Commix as well its extra functionalities that greatly facilitate penetration testers and security researchers in the detection and exploitation of command injection vulnerabilities. Moreover, based on the knowledge and the practical experience gained from the development of Commix, we propose and analyze new identified techniques that perform side-channel exploitation for command injections allowing an attacker to indirectly deduce the output of the executed command (i.e., also known as blind command injections). Furthermore, we evaluate the detection capabilities of Commix, by performing experiments against various applications. The experimental results show that Commix presents high detection accuracy, while at the same time false positives are eliminated. Finally and more importantly, we analyze several 0-day command injection vulnerabilities that Commix detected in real-world applications. Despite its short release time, Commix has been embraced by the security community and comes preinstalled in many security-oriented operating systems including the well-known Kali Linux."
journal_title,International Journal of Information Security
article_title,Talos: no more ransomware victims with formal methods
keyword,"['Malware\xa0', 'Mobile\xa0', 'Ransomware\xa0', 'Security\xa0', 'Model checking\xa0', 'Android\xa0']"
history,['2017-12-19']
abstract,"Abstract Ransomware is a very effective form of malware that is recently spreading out on an impressive number of workstations and smartphones. This malware blocks the access to the infected machine or to the files located in the infected machine. The attackers will restore the machine and files only after the payment of a certain amount of money, usually given in the form of bitcoins. Commercial solutions are still ineffective to recognize the last variants of ransomware, and the problem has been poorly investigated in literature. In this paper we discuss a methodology based on formal methods for detecting ransomware malware on Android devices. We have implemented our method in a tool named Talos. We evaluate the method, and the obtained results show that Talos is very effective in recognizing ransomware (accuracy of 0.99) even when it is obfuscated (accuracy still remains at 0.99)."
journal_title,International Journal of Information Security
article_title,DomainProfiler: toward accurate and early discovery of domain names abused in future
keyword,"['Network-level security and protection\xa0', 'Domain name\xa0', 'DNS\xa0', 'Malware\xa0', 'Temporal variation pattern\xa0']"
history,['2017-12-16']
abstract,"Abstract Domain names are at the base of today’s cyber-attacks. Attackers abuse the domain name system (DNS) to mystify their attack ecosystems; they systematically generate a huge volume of distinct domain names to make it infeasible for blacklisting approaches to keep up with newly generated malicious domain names. To solve this problem, we propose DomainProfiler for discovering malicious domain names that are likely to be abused in future. The key idea with our system is to exploit temporal variation patterns (TVPs) of domain names. The TVPs of domain names include information about how and when a domain name has been listed in legitimate/popular and/or malicious domain name lists. On the basis of this idea, our system actively collects historical DNS logs, analyzes their TVPs, and predicts whether a given domain name will be used for malicious purposes. Our evaluation revealed that DomainProfiler can predict malicious domain names 220 days beforehand with a true positive rate of 0.985. Moreover, we verified the effectiveness of our system in terms of the benefits from our TVPs and defense against cyber-attacks."
journal_title,International Journal of Information Security
article_title,Comparing apples with apples: performance analysis of lattice-based authenticated key exchange protocols
keyword,"['Lattice-based cryptography\xa0', 'Key exchange\xa0', 'Authenticated key exchange\xa0', 'Post-quantum cryptography\xa0']"
history,['2017-12-09']
abstract,"Abstract In view of the expected cryptanalysis (of both classical and quantum adversaries), it is important to find alternatives for currently used cryptographic primitives. In the past years, several authenticated key exchange protocols (AKE) that base their security on presumably quantum hard problems, such as lattice-based AKEs, were proposed. Since very different proposals for generic AKEs as well as direct AKEs, i.e., protocols directly based on lattice-based problems without additional authentication, exist, the performance of lattice-based AKEs is not evaluated and compared thoroughly. In particular, it is an open question whether the direct constructions are more efficient than generic approaches as it is often the case for other primitives. In this paper, we fill this gap. We compare existing lattice-based authenticated key exchange protocols, generic and direct. Therefore, we first find the most efficient suitable primitives to instantiate the generic protocols. Afterward, we choose parameters for each AKE yielding approximately 100 or 192 bits of security. We implement all protocols using the same libraries and compare the resulting performance. We find that our instantiation of the AKE by Peikert (PQCrypto, 2014) is the most efficient lattice-based AKE. Particularly, it is faster than the direct AKE by Zhang et al. (EUROCRYPT, 2015)."
journal_title,International Journal of Information Security
article_title,Design and implementation of Negative Authentication System
keyword,"['Cyber-security\xa0', 'Levels of abstraction\xa0', 'Security event\xa0', 'Passwords\xa0', 'Authentication\xa0', 'Negative Authentication\xa0', 'Hashing\xa0', 'Salting\xa0']"
history,['2017-11-21']
abstract,"Abstract Modern society is mostly dependent on online activities like official or social communications, fund transfers and so on. Unauthorized system access is one of the utmost concerns than ever before in cyber systems. For any cyber system, robust authentication is an absolute necessity for ensuring security and reliable access to all type of transactions. However, more than 80% of the current authentication systems are password based, and surprisingly, they are prone to direct and indirect cracking via guessing or side channel attacks. The inspiration of Negative Authentication System (NAS) is based on the negative selection algorithm. In NAS, the password-based authentication data for valid users are termed as password profile or self-region (positive profile); any element other than the self-region is defined as non-self-region in the same representative space. The anti-password detectors are generated which covers most of the non-self-region. There are also some uncovered regions left in the non-self-region for inducing uncertainty to the attackers. In this work, we describe the design and implementation of three approaches of NAS and its efficacy over the other authentication methods. These three approaches represent three different ways to achieve obfuscation of password points with non-password space. The experiments are conducted with both real and simulated password profiles to justify the efficiency of different implementations of NAS."
journal_title,International Journal of Information Security
article_title,Integrity-verifiable conjunctive keyword searchable encryption in cloud storage
keyword,"['Conjunctive keyword search\xa0', 'Integrity authentication\xa0', 'Searchable encryption\xa0', 'Secure cloud storage\xa0']"
history,['2017-11-08']
abstract,"Abstract Conjunctive searchable encryption is an efficient way to perform multi-keyword search over encrypted data in cloud storage. However, most existing methods do not take into account the integrity verification of the search result. Moreover, existing integrity verification methods can only verify the integrity of single-keyword search results, which cannot meet the requirements of conjunctive search. To address this problem, we proposed a conjunctive keyword searchable encryption scheme with an authentication mechanism that can efficiently verify the integrity of search results. The proposed scheme is based on the dynamic searchable symmetric encryption and adopts the Merkle tree and bilinear map accumulator to prove the correctness of set operations. It supports conjunctive keyword as input for conjunctive search and gives the server the ability to prove the integrity of the search result to the user. Formal proofs and extensive experiments show that the proposed scheme is efficient, unforgeable and adaptive secure against chosen-keyword attacks."
journal_title,International Journal of Information Security
article_title,Defeating SQL injection attack in authentication security: an experimental study
keyword,"['Web-application\xa0', 'SQL injection\xa0', 'Naive Bayes\xa0', 'SVM\xa0', 'Tree-based\xa0', 'Edit-distance\xa0', 'Classification\xa0']"
history,['2017-11-07']
abstract,"Abstract Whenever web-application executes dynamic SQL statements it may come under SQL injection attack. To evaluate the existing practices of its detection, we consider two different security scenarios for the web-application authentication that generates dynamic SQL query with the user input data. Accordingly, we generate two different datasets by considering all possible vulnerabilities in the run-time queries. We present proposed approach based on edit-distance to classify a dynamic SQL query as normal or malicious using web-profile prepared with the dynamic SQL queries during training phase. We evaluate the dataset using proposed approach and some well-known supervised classification approaches. Our proposed method is found more effective in detecting SQL injection attack under both the scenarios of authentication security."
journal_title,International Journal of Information Security
article_title,An efficient homomorphic MAC-based scheme against data and tag pollution attacks in network coding-enabled wireless networks
keyword,"['Network coding\xa0', 'Security\xa0', 'Data pollution attack\xa0', 'Tag pollution attack\xa0', 'Wireless networks\xa0']"
history,"['2017-11', '2016-09-19']"
abstract,"Abstract Recent research efforts have shown that wireless networks can benefit from network coding (NC) technology in terms of bandwidth, robustness to packet losses, delay and energy consumption. However, NC-enabled wireless networks are susceptible to a severe security threat, known as data pollution attack, where a malicious node injects into the network polluted packets that prevent the destination nodes from decoding correctly. Due to recoding, occurred at the intermediate nodes, according to the core principle of NC, the polluted packets propagate quickly into other packets and corrupt bunches of legitimate packets leading to network resource waste. Hence, a lot of research effort has been devoted to schemes against data pollution attacks. Homomorphic MAC-based schemes are a promising solution against data pollution attacks. However, most of them are susceptible to a new type of pollution attack, called tag pollution attack, where an adversary node randomly modifies tags appended to the end of the transmitted packets. Therefore, in this paper, we propose an efficient homomorphic message authentication code-based scheme, called HMAC, providing resistance against data pollution attacks and tag pollution attacks in NC-enabled wireless networks. Our proposed scheme makes use of three types of homomorphic tags (i.e., MACs, D-MACs and one signature) which are appended to the end of the coded packet. Our results show that the proposed HMAC scheme is more efficient compared to other competitive tag pollution immune schemes in terms of complexity, communication overhead and key storage overhead."
journal_title,International Journal of Information Security
article_title,On the efficiency of user identification: a system-based approach
keyword,"['User identification\xa0', 'Anonymity\xa0', 'Machine learning\xa0']"
history,"['2017-11', '2016-07-05']"
abstract,"Abstract In the Internet era, users’ fundamental privacy and anonymity rights have received significant research and regulatory attention. This is not only a result of the exponential growth of data that users generate when accomplishing their daily task by means of computing devices with advanced capabilities, but also because of inherent data properties that allow them to be linked with a real or soft identity. Service providers exploit these facts for user monitoring and identification, albeit impacting users’ anonymity, based mainly on personal identifiable information or on sensors that generate unique data to provide personalized services. In this paper, we report on the feasibility of user identification using general system features like memory, CPU and network data, as provided by the underlying operating system. We provide a general framework based on supervised machine learning algorithms both for distinguishing users and informing them about their anonymity exposure. We conduct a series of experiments to collect trial datasets for users’ engagement on a shared computing platform. We evaluate various well-known classifiers in terms of their effectiveness in distinguishing users, and we perform a sensitivity analysis of their configuration setup to discover optimal settings under diverse conditions. Furthermore, we examine the bounds of sampling data to eliminate the chances of user identification and thus promote anonymity. Overall results show that under certain configurations users’ anonymity can be preserved, while in other cases users’ identification can be inferred with high accuracy, without relying on personal identifiable information."
journal_title,International Journal of Information Security
article_title,"Periodicity in software vulnerability discovery, patching and exploitation"
keyword,"['Vulnerability\xa0', 'Laws of vulnerabilities\xa0', 'Seasonality\xa0', 'Periodicity\xa0', 'Operating system\xa0']"
history,"['2017-11', '2016-07-19']"
abstract,"Abstract Periodicity in key processes related to software vulnerabilities need to be taken into account for assessing security at a given time. Here, we examine the actual multi-year field datasets for some of the most used software systems (operating systems and Web-related software) for potential annual variations in vulnerability discovery processes. We also examine weekly periodicity in the patching and exploitation of the vulnerabilities. Accurate projections of the vulnerability discovery process are required to optimally allocate the effort needed to develop patches for handling discovered vulnerabilities. A time series analysis that combines the periodic pattern and longer-term trends allows the developers to predict future needs more accurately. We analyze eighteen datasets of software systems for annual seasonality in their vulnerability discovery processes. This analysis shows that there are indeed repetitive annual patterns. Next, some of the datasets from a large number of major organizations that record the result of daily scans are examined for potential weekly periodicity and its statistical significance. The results show a 7-day periodicity in the presence of unpatched vulnerabilities, as well as in the exploitation pattern. The seasonal index approach is used to examine the statistical significance of the observed periodicity. The autocorrelation function is used to identify the exact periodicity. The results show that periodicity needs to be considered for optimal resource allocations and for evaluation of security risks."
journal_title,International Journal of Information Security
article_title,Secure computation of hidden Markov models and secure floating-point arithmetic in the malicious model
keyword,"['Secure computation\xa0', 'Floating point\xa0', 'Hidden Markov models\xa0', 'Gaussian mixture models\xa0']"
history,"['2017-11', '2016-09-23']"
abstract,"Abstract Hidden Markov model (HMM) is a popular statistical tool with a large number of applications in pattern recognition. In some of these applications, such as speaker recognition, the computation involves personal data that can identify individuals and must be protected. We thus treat the problem of designing privacy-preserving techniques for HMM and companion Gaussian mixture model computation suitable for use in speaker recognition and other applications. We provide secure solutions for both two-party and multi-party computation models and both semi-honest and malicious settings. In the two-party setting, the server does not have access in the clear to either the user-based HMM or user input (i.e., current observations) and thus the computation is based on threshold homomorphic encryption, while the multi-party setting uses threshold linear secret sharing as the underlying data protection mechanism. All solutions use floating-point arithmetic, which allows us to achieve high accuracy and provable security guarantees, while maintaining reasonable performance. A substantial part of this work is dedicated to building secure protocols for floating-point operations in the two-party setting, which are of independent interest."
journal_title,International Journal of Information Security
article_title,Development of dynamic protection against timing channels
keyword,"['Cryptography\xa0', 'Heterogeneous computing\xa0', 'Fault tolerance\xa0', 'Algorithmic complexity\xa0']"
history,"['2017-11', '2016-12-22']"
abstract,"Abstract Information systems face many threats, such as covert channels, which declassify hidden information by, e.g., analyzing the program execution time. Such threats exist at various stages of the execution of instructions. Even if software developers are able to neutralize these threats in source code, new attack vectors can arise in compiler-generated machine code from these representations. Existing approaches for preventing vulnerabilities have numerous restrictions related to both their functionality and the range of threats that can be found and removed. This study presents a technique for removing threats and generating safer code using dynamic compilation in an execution environment by combining information from program analysis of the malicious code and re-compiling such code to run securely. The proposed approach stores summary information in the form of rules that can be shared among analyses. The annotations enable us to conduct the analyses to mitigate threats. Developers can update the analyses and control the volume of resources that are allocated to perform these analyses by changing the precision. The authors’ experiments show that the binary code created by applying the suggested method is of high quality."
journal_title,International Journal of Information Security
article_title,rPIR: ramp secret sharing-based communication-efficient private information retrieval
keyword,"['Private information retrieval\xa0', 'PIR\xa0', 'Information-theoretic PIR\xa0', 'Secret sharing\xa0']"
history,"['2017-11', '2016-09-02']"
abstract,"Abstract Even as data and analytics-driven applications are becoming increasingly popular, retrieving data from shared databases poses a threat to the privacy of their users. For example, investors/patients retrieve records about stocks/diseases they are interested in from a stock/medical database. Knowledge of such interest is sensitive information that the database server would have access to, unless some mitigating measures are deployed. Private information retrieval (PIR) is a promising security primitive to protect the privacy of users’ interests. PIR allows the retrieval of a data record from a database without letting the database server know which record is being retrieved. The privacy guarantees could either be information theoretic or computational. Alternatively, anonymizers, which hide the identities of data users, may be used to protect the privacy of users’ interests for some situations. In this paper, we study rPIR, a new family of information-theoretic PIR schemes using ramp secret sharing. We have designed four rPIR schemes, using three ramp secret sharing approaches, achieving answer communication costs close to the cost of non-private information retrieval. Evaluation shows that, for many practical settings, rPIR schemes can achieve lower communication costs and the same level of privacy compared with traditional information-theoretic PIR schemes and anonymizers. Efficacy of the proposed schemes is demonstrated for two very different scenarios (outsourced data sharing and P2P content delivery) with realistic analysis and experiments. In many situations of these two scenarios, rPIR’s advantage of low communication cost outweighs its disadvantages, which results in less expenditure and/or better quality of service compared with what may be achieved if traditional information-theoretic PIR and anonymizers are used."
journal_title,International Journal of Information Security
article_title,OnionDNS: a seizure-resistant top-level domain
keyword,"['Tor hidden services\xa0', 'DNS\xa0', 'Proof-of-work\xa0', 'Censorship resistance\xa0']"
history,['2017-10-24']
abstract,"Abstract The Domain Name System (DNS) provides the critical service of mapping canonical names to IP addresses. Recognizing this, a number of parties have increasingly attempted to perform “domain seizures” on targets by having them delisted from DNS. Such operations often occur without providing due process to the owners of these domains, a practice made potentially worse by recent legislative proposals. We address this problem by creating OnionDNS, an anonymous top-level domain and resolution service for the Internet. Our solution relies on the establishment of a hidden service running DNS within Tor and uses a variety of mechanisms to ensure a high-performance architecture with strong integrity guarantees for resolved records. We then present our anonymous domain registrar and detail the protocol for securely transferring the service to another party. Finally, we also conduct both performance and legal analyses to further demonstrate the robustness of this approach. In so doing, we show that the delisting of domains from DNS can be mitigated in an efficient and secure manner."
journal_title,International Journal of Information Security
article_title,Optimization algorithm for k-anonymization of datasets with low information loss
keyword,"['Security and protection\xa0', 'Database models\xa0', None, 'Large-scale dataset\xa0', 'Graph problem\xa0', 'Optimization\xa0']"
history,['2017-10-23']
abstract,"Abstract Anonymization is the modification of data to mask the correspondence between a person and sensitive information in the data. Several anonymization models such as k-anonymity have been intensively studied. Recently, a new model with less information loss than existing models was proposed; this is a type of non-homogeneous generalization. In this paper, we present an alternative anonymization algorithm that further reduces the information loss using optimization techniques. We also prove that a modified dataset is checked whether it satisfies the k-anonymity by a polynomial-time algorithm. Computational experiments were conducted and demonstrated the efficiency of our algorithm even on large datasets."
journal_title,International Journal of Information Security
article_title,Analysis of privacy in mobile telephony systems
keyword,"['Privacy\xa0', 'Automatic verification\xa0', 'ProVerif\xa0', 'Mobile telephony\xa0', 'Pseudonym\xa0']"
history,"['2017-10', '2016-07-05']"
abstract,"Abstract We present a thorough experimental and formal analysis of users’ privacy in mobile telephony systems. In particular, we experimentally analyse the use of pseudonyms and point out weak deployed policies leading to some critical scenarios which make it possible to violate a user’s privacy. We also expose some protocol’s vulnerabilities resulting in breaches of the anonymity and/or user unlinkability. We show these breaches translate in actual attacks which are feasible to implement on real networks and discuss our prototype implementation. In order to countermeasure these attacks, we propose realistic solutions. Finally, we provide the theoretical framework for the automatic verification of the unlinkability and anonymity of the fixed 2G/3G procedures and automatically verify them using the ProVerif tool."
journal_title,International Journal of Information Security
article_title,Detecting zero-day attacks using context-aware anomaly detection at the application-layer
keyword,"['Intrusion detection\xa0', 'Machine learning\xa0', 'Anomaly detection\xa0', 'Protocol analysis\xa0', 'Deep packet inspection\xa0']"
history,"['2017-10', '2016-07-20']"
abstract,"Abstract Anomaly detection allows for the identification of unknown and novel attacks in network traffic. However, current approaches for anomaly detection of network packet payloads are limited to the analysis of plain byte sequences. Experiments have shown that application-layer attacks become difficult to detect in the presence of attack obfuscation using payload customization. The ability to incorporate syntactic context into anomaly detection provides valuable information and increases detection accuracy. In this contribution, we address the issue of incorporating protocol context into payload-based anomaly detection. We present a new data representation, called \({c}_n\)-grams, that allows to integrate syntactic and sequential features of payloads in an unified feature space and provides the basis for context-aware detection of network intrusions. We conduct experiments on both text-based and binary application-layer protocols which demonstrate superior accuracy on the detection of various types of attacks over regular anomaly detection methods. Furthermore, we show how \({c}_n\)-grams can be used to interpret detected anomalies and thus, provide explainable decisions in practice."
journal_title,International Journal of Information Security
article_title,A Spatio-Temporal malware and country clustering algorithm: 2012 IIJ MITF case study
keyword,"['Botnet\xa0', 'Malware clustering\xa0', 'Country clustering\xa0', 'Spatial\xa0', 'Temporal\xa0', 'Spatio-Temporal\xa0', 'Phishing\xa0', 'Spam e-mail\xa0', 'Malicious websites\xa0']"
history,"['2017-10', '2016-07-12']"
abstract,"Abstract A huge number of botnet malware variants can be downloaded by zombie personal computers as secondary injections and upgrades according to their botmasters to perform different distributed/coordinated cyber attacks such as phishing, spam e-mail, malicious Web sites, ransomware, DDoS. In order to generate a faster response to new threats and better understanding of botnet activities, grouping them based on their malicious behaviors has become extremely important. This paper presents a Spatio-Temporal malware clustering algorithm based on its (weekly-hourly-country) features. The dataset contains more than 32 million of malware download logs from 100 honeypots set up by Malware Investigation Task Force (MITF) of Internet Initiative Japan Inc. (IIJ) from 2011 to 2012. The Top-20 malware clustering results coincidentally correspond to Conficker.B and Conficker.C with relatively high precision and recall rates up to 100.0, 88.9 % and 91.7, 100.0 %, respectively. On the other hand, the resulting two clusters of Top-20 countries are comparable to those with high and low growth rates recently reported in 2015 by Asghari et al. Therefore, our approach can be validated and evaluated to yield precision and recall of up to 75.0 and 86.7 %, respectively."
journal_title,International Journal of Information Security
article_title,Certificateless and identity-based authenticated asymmetric group key agreement
keyword,"['Certificateless public key cryptosystem\xa0', 'Identity-based public key cryptosystem\xa0', 'Group key agreement\xa0', 'Asymmetric group key agreement\xa0']"
history,"['2017-10', '2016-06-29']"
abstract,"Abstract Group key agreement (GKA) is one of the traditional ways to guarantee the subsequent secure group communications. However, conventional GKA protocols face two limitations, i.e., they require two or more rounds to establish secure channels and are sender restricted. Asymmetric group key agreement (AGKA) eliminates above two limitations of GKA. It allows a group of users to establish a public group encryption key and a different secret decryption key of each group member in one round. Any user who knows the group encryption key can encrypt to the group members. This paper studies authenticated AGKA in certificateless and identity-based public key cryptosystems. We formalize the security model of certificateless authenticated asymmetric group key agreement and realize a one-round certificateless authenticated asymmetric group key agreement protocol to resist active attacks in the real world. We also investigate the relation between certificateless authenticated AGKA and identity-based authenticated AGKA. We propose a concrete conversion from certificateless authenticated AGKA to session key escrow-free identity-based authenticated AGKA."
journal_title,International Journal of Information Security
article_title,Generic construction of an $$\mathrm {eCK}$$eCK-secure key exchange protocol in the standard model
keyword,"['Public-key cryptography\xa0', 'Key exchange protocols\xa0', None, 'Standard model\xa0']"
history,"['2017-10', '2016-08-05']"
abstract,"Abstract LaMacchia, Lauter and Mityagin presented a strong security model for authenticated key agreement, namely the \(\mathrm {eCK}\) model. They also constructed a protocol, namely the NAXOS protocol, that enjoys a simple security proof in the \(\mathrm {eCK}\) model. However, the NAXOS protocol uses a random oracle-based technique to combine the long-term secret key and the per session randomness, so-called NAXOS trick, in order to achieve the \(\mathrm {eCK}\) security definition. For NAXOS trick-based protocols, the leakage of per session randomness modeled in the \(\mathrm {eCK}\) model is somewhat unnatural, because the \(\mathrm {eCK}\) model leaks per session randomness, while the output of the NAXOS trick computation remains safe. In this work, we present a standard model \(\mathrm {eCK}\)-secure protocol construction, eliminating the NAXOS trick. Moreover, our protocol is a generic construction, which can be instantiated with arbitrary suitable cryptographic primitives. Thus, we present a generic \(\mathrm {eCK}\)-secure, NAXOS-free, standard model key exchange protocol. To the best of our knowledge this is the first paper on generic transformation of a \(\mathrm {CCA2}\)-secure public-key encryption scheme to an \(\mathrm {eCK}\)-secure key exchange protocol in the standard model."
journal_title,International Journal of Information Security
article_title,Mutual authentications to parties with QR-code applications in mobile systems
keyword,"['Authentication\xa0', 'Mutual authentication\xa0', 'Quick response code\xa0', 'Gong–Needham–Yahalom logic\xa0', 'Mobile system\xa0']"
history,"['2017-10', '2016-09-14']"
abstract,"Abstract User authentication over the Internet has long been an issue for Internet service providers and users. A good authentication protocol must provide high security and mutual authentication on both sides. In addition, it must balance security and usability, which has been shown in the literature to be a difficult problem. To solve this problem, we propose a novel mutual authentication protocol with high security and usability. The proposed protocol was developed for quick response code, a type of two-dimensional barcode that can be photographed and quickly decoded by smartphones. We implemented a prototype using the proposed mutual authentication protocol and demonstrated how the prototype improves usability in a mobile communication system. We also used the Gong–Needham–Yahalom logic with several well-known attack models to analyze the security of the proposed protocol, and we obtained satisfactory results. We expect that using the proposed protocol, Internet service providers will be able to provide a mutual authentication mechanism with high security and usability."
journal_title,International Journal of Information Security
article_title,Access right management by extended password capabilities
keyword,"['Access right\xa0', 'Distribution\xa0', 'Password\xa0', 'Reduction\xa0', 'Revocation\xa0']"
history,['2017-08-23']
abstract,"Abstract With reference to a classic protection system featuring active subjects that reference protected objects, we approach the problem of identifying the objects that each subject can access, and the operations that the subject can carry out on these objects. Password capabilities are a classical solution to this problem. We propose a new form of password capability, called extended password capability (or e-capability, for short). An e-capability can specify any combination of access rights. A subject that holds a given e-capability can generate new e-capabilities for reduced sets of access rights. Furthermore, a subject that created a given object is in a position to revoke the access permissions granted by every e-capability referencing this object, completely or in part. The size of an e-capability is comparable to that of a traditional password capability. The number of passwords that need to be stored in memory permanently is kept to a minimum, and is equal to a single password for each object."
journal_title,International Journal of Information Security
article_title,Ciphertext-policy attribute-based encryption supporting access policy update and its extension with preserved attributes
keyword,"['Attribute-based encryption\xa0', 'Access policy update\xa0', 'Ciphertext-policy\xa0']"
history,['2017-08-07']
abstract,"Abstract Attribute-based encryption (ABE) allows one-to-many encryption with static access control. In many occasions, the access control policy must be updated, but the original encryptor might be unavailable to re-encrypt the message, which makes it impractical. Unfortunately, to date the work in ABE does not consider this issue yet, and hence this hinders the adoption of ABE in practice. In this work, we consider how to update access policies in ciphertext-policy attribute-based encryption (CP-ABE) systems efficiently without encrypting each ciphertext with new access policies. We introduce a new notion of CP-ABE supporting access policy update that captures the functionalities of attribute addition and revocation to access policies. We formalize the security requirements for this notion and subsequently construct two provably secure CP-ABE schemes supporting AND-gate access policy with constant-size ciphertext for user decryption. The security of our schemes are proved under the augmented multi-sequences of exponents decisional Diffie–Hellman assumption. We also present a different construction in which certain attributes in an access policy can be preserved by the original encryptor, while other attributes can be revoked efficiently so that the ability of attribute revocation can be appropriately restrained."
journal_title,International Journal of Information Security
article_title,"Multi-cast key distribution: scalable, dynamic and provably secure construction"
keyword,"['Multi-cast key distribution\xa0', 'Exposure resilience\xa0', 'Star topology\xa0', 'Backward secrecy\xa0']"
history,['2017-08-04']
abstract,"Abstract In this paper, we propose a two-round dynamic multi-cast key distribution (DMKD) protocol under the star topology with a central authentication server. Users can share a common session key without revealing any information of the session key to the server and can join/leave to/from the group at any time even after establishing the session key. Our protocol is scalable because communication and computation costs of each user are independent from the number of users. Also, our protocol is still secure if either private key or session-specific randomness of a user is exposed. Furthermore, time-based backward secrecy is guaranteed by renewing the session key for every time period even if the session key is exposed. We introduce the first formal security definition for DMKD under the star topology in order to capture such strong exposure resilience and time-based backward secrecy. We prove that our protocol is secure in our security model in the standard model."
journal_title,International Journal of Information Security
article_title,TermID: a distributed swarm intelligence-based approach for wireless intrusion detection
keyword,"['Computer intrusion detection\xa0', 'Wireless networks\xa0', 'Machine learning\xa0', 'Swarm intelligence\xa0', 'Ant colony\xa0', 'Distributed computing\xa0']"
history,"['2017-08', '2016-06-18']"
abstract,"Abstract With the mushrooming of wireless access infrastructures, the amount of data generated, transferred and consumed by the users of such networks has taken enormous proportions. This fact further complicates the task of network intrusion detection, especially when advanced machine learning (ML) operations are involved in the process. In wireless environments, the monitored data are naturally distributed among the numerous sensor nodes of the system. Therefore, the analysis of data must either happen in a central location after first collecting it from the sensors or locally through collaboration by viewing the problem through a distributed ML perspective. In both cases, concerns are risen regarding the requirements of this demanding task in matters of required network resources and achieved security/privacy. This paper proposes TermID, a distributed network intrusion detection system that is well suited for wireless networks. The system is based on classification rule induction and swarm intelligence principles to achieve efficient model training for intrusion detection purposes, without exchanging sensitive data. An additional achievement is that the produced model is easily readable by humans. While these are the main design principles of our approach, the accuracy of the produced model is not compromised by the distribution of the tasks and remains at competitive levels. Both the aforementioned claims are verified by the results of detailed experiments withheld with the use of a publicly available security-focused wireless dataset."
journal_title,International Journal of Information Security
article_title,ADroid: anomaly-based detection of malicious events in Android platforms
keyword,"['Anomaly detection\xa0', 'Behavior\xa0', 'Malicious event\xa0', 'Malware\xa0', 'Mobile device\xa0', 'Security\xa0']"
history,"['2017-08', '2016-06-03']"
abstract,"Abstract As mobile devices become more and more adopted by users for daily personal and professional activities, associated security risks and impact to them also increase. Although there are a number of proposals aimed at fighting against such incidents, the topic still remains challenging. This paper presents ADroid, a novel security tool for Android platforms with three main distinguishing characteristics. First, three groups of features are monitored over time: interfaces usage, application-related and communication-related features. Second, a lightweight anomaly-based detection procedure is performed over these features in order to determine the occurrence of unexpected abnormal activities. Third, the user can also create specific white/black lists to indicate in an easy way certain allowed/undesired activities which, if so, should trigger an alarm by the supervision system. ADroid has been implemented in a real environment and evaluated through experimentation. The detection accuracy exhibited and the resources consumption involved in its operation show the goodness and promising capabilities of the system."
journal_title,International Journal of Information Security
article_title,Stateful Data Usage Control for Android Mobile Devices
keyword,"['Usage control\xa0', 'Mobile devices\xa0', 'XACML\xa0', 'Android\xa0']"
history,"['2017-08', '2016-06-17']"
abstract,"Abstract Modern mobile devices allow their users to download data from the network, such as documents or photos, to store local copies and to use them. Many real scenarios would benefit from this capability of mobile devices to easily and quickly share data among a set of users but, in case of critical data, the usage of these copies must be regulated by proper security policies. To this aim, we propose a framework for regulating the usage of data when they have been downloaded on mobile devices, i.e., they have been copied outside the producer’s domain. Our framework regulates the usage of the local copy by enforcing the Usage Control policy which has been embedded in the data by the producer. Such policy is written in UXACML, an extension of the XACML language for expressing Usage Control model-based policies, whose main feature is to include predicates which must be satisfied for the whole execution of the access to the data. Hence, the proposed framework goes beyond the traditional access control capabilities, being able to interrupt an ongoing access to the data as soon as the policy is no longer satisfied. This paper details the proposed approach, defines the architecture and the workflow of the main functionalities of the proposed framework, describes the implementation of a working prototype for Android devices, presents the related performance figures, and discusses the security of the prototype."
journal_title,International Journal of Information Security
article_title,Network-based detection of Android malicious apps
keyword,"['Android\xa0', 'Mobile bots\xa0', 'Malware\xa0', 'Network-behavior\xa0', 'Malicious app\xa0', 'Known and unknown apps\xa0', 'Encrypted communication\xa0', 'Network traces\xa0', 'Detection\xa0', 'Machine learning\xa0']"
history,"['2017-08', '2016-08-01']"
abstract,"Abstract Users leverage mobile devices for their daily Internet needs by running various mobile applications (apps) such as social networking, e-mailing, news-reading, and video/audio streaming. Mobile device have become major targets for malicious apps due to their heavy network activity and is a research challenge in the current era. The majority of the research reported in the literature is focused on host-based systems rather than the network-based; unable to detect malicious activities occurring on mobile device through the Internet. This paper presents a detection app model for classification of apps. We investigate the accuracy of various machine learning models, in the context of known and unknown apps, benign and normal apps, with or without encrypted message-based app, and operating system version independence of classification. The best resulted machine learning(ML)-based model is embedded into the detection app for efficient and effective detection. We collect a dataset of network activities of 18 different malware families-based apps and 14 genuine apps and use it to develop ML-based detectors. We show that, it is possible to detect malicious app using network traces with the traditional ML techniques, and results revealed the accuracy (95–99.9 %) in detection of apps in different scenarios. The model proposed is proved efficient and suitable for mobile devices. Due to the widespread penetration of Android OS into the market, it has become the main target for the attackers. Hence, the proposed system is deployed on Android environment."
journal_title,International Journal of Information Security
article_title,"Designing vulnerability testing tools for web services: approach, components, and tools"
keyword,"['Software vulnerabilities\xa0', 'Vulnerability detection\xa0', 'Security testing\xa0', 'Web services\xa0']"
history,"['2017-08', '2016-06-14']"
abstract,"Abstract This paper proposes a generic approach for designing vulnerability testing tools for web services, which includes the definition of the testing procedure and the tool components. Based on the proposed approach, we present the design of three innovative testing tools that implement three complementary techniques (improved penetration testing, attack signatures and interface monitoring, and runtime anomaly detection) for detecting injection vulnerabilities, thus offering an extensive support for different scenarios. A case study has been designed to demonstrate the tools for the particular case of SQL Injection vulnerabilities. The experimental evaluation demonstrates that the tools can effectively be used in different scenarios and that they outperform well-known commercial tools by achieving higher detection coverage and lower false-positive rates."
journal_title,International Journal of Information Security
article_title,HiveSec: security in resource-constrained wireless networks inspired by beehives and bee swarms
keyword,"['Security\xa0', 'Key management\xa0', 'Resource-constrained networks\xa0', 'Internet of things\xa0', 'Security in RFID\xa0', 'Security in wireless body area networks\xa0']"
history,"['2017-08', '2016-07-06']"
abstract,"Abstract Cryptographic algorithms rely on the strengths of all their fundamental components and expect them to be harmonious in accomplishing desired levels of security in applications. In order for a security solution to be sophisticated and to provide high security (measured in terms of the security goals it satisfies), the solution needs to typically involve complex mathematical operations and/or multiple stages of operation. While these might offer increased security, such solutions might not be applicable to all systems. We refer to resource-constrained wireless networks, such as radio frequency identification and wireless body area networks, where the resources available on-chip are often decided by the balance between device costs, requirements of longevity and usability. The constraints, thus, require designing solutions that use simple logical operations and are based on reuse of functions, while introducing sufficient unpredictability to increase security. In this paper, we present a key management and message signature generation scheme called HiveSec, whose design is inspired by the symmetry in beehives and the nature of bee swarms, and which offers security through unpredictability and reduced resource usage. We validate our work through simulation studies and security analysis."
journal_title,International Journal of Information Security
article_title,Efficient revocable hierarchical identity-based encryption using cryptographic accumulators
keyword,"['Revocation\xa0', 'Cryptographic accumulator\xa0', 'Private key update\xa0', 'Dual system encryption\xa0', 'Hierarchical identity-based encryption\xa0']"
history,['2017-07-31']
abstract,"Abstract Hierarchical identity-based encryption is an important extension from IBE and has found many applications in the network world. Private key revocation is a crucial requirement for any public key system. In this paper, we propose a novel revocation method for the hierarchical identity-based encryption. Existing revocable hierarchical identity-based encryption schemes have several disadvantages: the key update size increases logarithmically with the number of users in the system, the public information of key update received by each user is different and always related to the level of the identity hierarchy and the security proof of the revocable scheme is very complex. In our scheme, cryptographic accumulators are used to compress hierarchical levels and revoked users’ information into constant values. So we achieve almost constant size of private key update which is irrelevant with the user number in the system. Because of the compression of hierarchical information we can use simple dual system encryption techniques to prove our scheme to be fully secure under several common assumptions without resorting to complex nested dual system encryption techniques."
journal_title,International Journal of Information Security
article_title,Watermarking protocols: an excursus to motivate a new approach
keyword,"['Watermarking protocols\xa0', 'Digital copyright protection\xa0']"
history,['2017-07-05']
abstract,"Abstract Digital watermarking is one of the techniques that can be used to support digital copyright protection. It enables copyright owners to insert a perceptually invisible watermark within any copy of content that is distributed on the Internet. The main aim is to use watermarks to implement copyright identification and content tracking. However, digital watermarking is not sufficient to ensure an adequate copyright protection, if it is not employed in conjunction with watermarking protocols, which define the schemes of the web transactions by which buyers can purchase protected digital content distributed by content providers in a secure manner. Therefore, watermarking protocols play a central role in the field of digital copyright protection by means of watermarking techniques. They have to ensure both a correct content protection and an easy participation of buyers in the purchase transactions of the contents distributed on the Internet. This paper presents a new watermarking protocol based on an innovative, buyer centric, and mediated design approach. The result is a secure protocol that enables buyers to easily participate in the transactions by which they can buy digital protected content, and this makes the protocol suited for the current web context."
journal_title,International Journal of Information Security
article_title,"STORK: a real, heterogeneous, large-scale eID management system"
keyword,"['Identity management systems\xa0', 'STORK project\xa0', 'EU identity management\xa0', 'Interoperability\xa0', 'Privacy\xa0', 'Large-scale\xa0', 'SAML\xa0']"
history,['2017-07-05']
abstract,"Abstract Verifying who someone is on the Internet is a prerequisite for online services that process sensitive or valuable information. While this has been solved with national or sectorial electronic identification (eID) schemes, general, cross-border solutions are rare. Cross-border eID difficulties have several origins: (i) incompatible national eID models; (ii) different legislations with incompatible objectives; (iii) lack of common language and semantics; (iv) different common procedures, specially in what concerns mandates and delegation; (v) different implementations of the same eID models. These have been addressed by STORK, a project that developed a federated cross-border eID system that was piloted in about twenty European Union Member States in service sectors as sensitive as eBanking and eHealth. STORK designed and implemented a large-scale interoperability framework, allowing different systems of different models to coexist, using a common language with a common semantics and satisfying national privacy legislations. The experience gained from this large-scale pilot fed into EU policy-making, in particular, the recently enacted eIDAS Regulation requiring mutual recognition of eID by 2018 has been directly influenced by STORK and its lessons learned."
journal_title,International Journal of Information Security
article_title,Optimal noise functions for location privacy on continuous regions
keyword,"['Location privacy\xa0', None, 'Geo-indistinguishability\xa0', 'Symmetric mechanisms\xa0', 'Location-based services\xa0', 'Noise functions\xa0', 'Distinguishability functions\xa0']"
history,['2017-06-28']
abstract,"Abstract Users of location-based services are highly vulnerable to privacy risks since they need to disclose, at least partially, their locations to benefit from these services. One possibility to limit these risks is to obfuscate the location of a user by adding random noise drawn from a noise function. In this paper, we require the noise functions to satisfy a generic location privacy notion called \(\ell \)-privacy, which makes the position of the user in a given region \(\mathcal {X}\) relatively indistinguishable from other points in \(\mathcal {X}\). We also aim at minimizing the loss in the service utility due to such obfuscation. While existing optimization frameworks regard the region \(\mathcal {X}\) restrictively as a finite set of points, we consider the more realistic case in which the region is rather continuous with a nonzero area. In this situation, we demonstrate that circular noise functions are enough to satisfy \(\ell \)-privacy on \(\mathcal {X}\) and equivalently on the entire space without any penalty in the utility. Afterward, we describe a large parametric space of noise functions that satisfy \(\ell \)-privacy on \(\mathcal {X}\), and show that this space has always an optimal member, regardless of \(\ell \) and \(\mathcal {X}\). We also investigate the recent notion of \(\epsilon \)-geo-indistinguishability as an instance of \(\ell \)-privacy and prove in this case that with respect to any increasing loss function, the planar Laplace noise function is optimal for any region having a nonzero area."
journal_title,International Journal of Information Security
article_title,A framework for estimating information security risk assessment method completeness
keyword,"['Information security\xa0', 'Risk assessment\xa0', 'Methodology\xa0', 'Completeness\xa0']"
history,['2017-06-28']
abstract,"Abstract In general, an information security risk assessment (ISRA) method produces risk estimates, where risk is the product of the probability of occurrence of an event and the associated consequences for the given organization. ISRA practices vary among industries and disciplines, resulting in various approaches and methods for risk assessments. There exist several methods for comparing ISRA methods, but these are scoped to compare the content of the methods to a predefined set of criteria, rather than process tasks to be carried out and the issues the method is designed to address. It is the lack of an all-inclusive and comprehensive comparison that motivates this work. This paper proposes the Core Unified Risk Framework (CURF) as an all-inclusive approach to compare different methods, all-inclusive since we grew CURF organically by adding new issues and tasks from each reviewed method. If a task or issue was present in surveyed ISRA method, but not in CURF, it was appended to the model, thus obtaining a measure of completeness for the studied methods. The scope of this work is primarily functional approaches risk assessment procedures, which are the formal ISRA methods that focus on assessments of assets, threats, vulnerabilities, and protections, often with measures of probability and consequence. The proposed approach allowed for a detailed qualitative comparison of processes and activities in each method and provided a measure of completeness. This study does not address aspects beyond risk identification, estimation, and evaluation; considering the total of all three activities, we found the “ISO/IEC 27005 Information Security Risk Management” to be the most complete approach at present. For risk estimation only, we found the Factor Analysis of Information Risk and ISO/IEC 27005:2011 as the most complete frameworks. In addition, this study discovers and analyzes several gaps in the surveyed methods."
journal_title,International Journal of Information Security
article_title,Improved yoking proof protocols for preserving anonymity
keyword,"['RFID\xa0', 'Privacy\xa0', 'Yoking proof\xa0', 'Anonymity\xa0']"
history,['2017-06-22']
abstract,"Abstract In emerging RFID applications, the yoking proof provides a method not only to ensure the physical proximity of multiple objects but also to verify that a pair of RFID tags has been scanned simultaneously by a reader. Previous studies have focused on generating the yoking proof, but have not been successful in preserving the anonymity of tags. In this paper, we address two attacks on tracking RFID tags and propose a new yoking proof protocol to improve anonymity of the tags. For better practicality, we also present authenticated yoking proof generation against DoS attacks on the system. Our analysis shows that the proposed protocols achieves improved anonymity effectively. Specifically, the protocols require the least number of computational steps and modules in a tag, while preserving its anonymity."
journal_title,International Journal of Information Security
article_title,Supervised machine learning using encrypted training data
keyword,"['Classification\xa0', 'Security\xa0', 'integrity\xa0', 'protection\xa0', 'Machine learning\xa0', 'Privacy protection\xa0', 'Homomorphic encryption\xa0']"
history,['2017-06-19']
abstract,"Abstract Preservation of privacy in data mining and machine learning has emerged as an absolute prerequisite in many practical scenarios, especially when the processing of sensitive data is outsourced to an external third party. Currently, privacy preservation methods are mainly based on randomization and/or perturbation, secure multiparty computations and cryptographic methods. In this paper, we take advantage of the partial homomorphic property of some cryptosystems to train simple machine learning models with encrypted data. Our basic scenario has three parties: multiple Data Owners, which provide encrypted training examples; the Algorithm Owner (or Application), which processes them to adjust the parameters of its models; and a semi-trusted third party, which provides privacy and secure computation services to the Application in some operations not supported by the homomorphic cryptosystem. In particular, we focus on two issues: the use of multiple-key cryptosystems, and the impact of the quantization of real-valued input data required before encryption. In addition, we develop primitives based on the outsourcing of a reduced set of operations that allows to implement general machine learning algorithms using efficient dedicated hardware. As applications, we consider the training of classifiers using privacy-protected data and the tracking of a moving target using encrypted distance measurements."
journal_title,International Journal of Information Security
article_title,Integrity analysis of authenticated encryption based on stream ciphers
keyword,"['Authenticated encryption\xa0', 'Stream cipher\xa0', 'Universal hash function\xa0', 'Provable security\xa0', 'Integrity\xa0', 'Releasing unverified plaintext\xa0']"
history,['2017-06-02']
abstract,"Abstract We study the security of authenticated encryption based on a stream cipher and a universal hash function. We consider ChaCha20-Poly1305 and generic constructions proposed by Sarkar, where the generic constructions include 14 AEAD (authenticated encryption with associated data) schemes and 3 DAEAD (deterministic AEAD) schemes. In this paper, we analyze the integrity of these schemes both in the standard INT-CTXT (integrity of ciphertext) notion and in the RUP (releasing unverified plaintext) setting called INT-RUP notion. We present INT-CTXT attacks against 3 out of the 14 AEAD schemes and 1 out of the 3 DAEAD schemes. We then show INT-RUP attacks against 1 out of the 14 AEAD schemes and the 2 remaining DAEAD schemes. Next, we consider ChaCha20-Poly1305 and show that it is provably secure in the INT-RUP notion. Finally, we show that the remaining 10 AEAD schemes are provably secure in the INT-RUP notion."
journal_title,International Journal of Information Security
article_title,A modified exhaustive search on a password system using SHA-1
keyword,"['Security evaluation\xa0', 'SHA-1\xa0', 'Microsoft Office\xa0', 'Exhaustive search\xa0', 'Password cracking\xa0']"
history,"['2017-06', '2016-06-20']"
abstract,"Abstract In this paper, we show a method of exhaustive search on a password system that uses SHA-1 iteratively. Our method uses both the technique shown in Steube [16] and a technique for computing repetitions of SHA-1. Combining these two techniques reduces the total number of operations. We also show how to apply our method to MS Office (Microsoft Office) 2007/2010."
journal_title,International Journal of Information Security
article_title,A certificateless approach to onion routing
keyword,"['Anonymity\xa0', 'Onion routing\xa0', 'Certificateless cryptography\xa0', 'Tor\xa0']"
history,"['2017-06', '2016-06-17']"
abstract,"Abstract Onion routing protocols allow users to establish anonymous channels to preserve their privacy over a public network. Several protocols implementing this primitive have been proposed in recent years, and The onion routing network (Tor), a real-life implementation, provides an onion routing service to thousands of users over the Internet. This paper presents Certificateless Onion Routing a new approach to the problem. Starting from the identity-based solution (PB-OR) of Kate et al. (ACM TISSEC 2000), we adopt the certificateless setting introduced by Al-Riyami and Paterson in 2003. Such a setting is particularly well suited in practice as it retains the good aspects of identity-based cryptography (no PKI is required) and traditional public key cryptography (there is no key escrow). Next, we present a novel certificateless key-encapsulation mechanism and we show how to turn it into a very efficient (and provably secure!) certificateless onion routing protocol. When compared with Tor and PB-OR, our protocol offers better performances, especially when current security levels (i.e., 128 bits) are considered. In particular, our scheme significantly improves the computational costs required from each router. In this sense, our solution is up to 7 times faster than PB-OR and up to 11 times faster than Tor."
journal_title,International Journal of Information Security
article_title,Efficient identity-based online/offline encryption and signcryption with short ciphertext
keyword,"['Identity-based\xa0', 'Online/offline\xa0', 'Encryption\xa0', 'Signcryption\xa0']"
history,"['2017-06', '2016-02-18']"
abstract,"Abstract The technique of online/offline is regarded as a promising approach to speed up the computation of encryption, because the most part of computation, such as pairing over points on elliptic curve and exponentiation in groups, can be pre-computed in the offline phase without knowing the message to be encrypted and/or recipient’s identity. The online phase only requires light computation, such as modular multiplication. In this paper, we propose two novel identity-based online/offline schemes: a full secure identity-based online/offline encryption scheme and an identity-based online/offline signcryption scheme. Compared to the other schemes in the literature, our schemes achieve the shortest ciphertext size in both offline and online phases and demonstrate the best performance in offline computation. Our schemes are applicable to devices with limited computation power. They are proven secure in the random oracle model."
journal_title,International Journal of Information Security
article_title,A key management scheme evaluation using Markov processes
keyword,"['Key management\xa0', 'Markov processes\xa0', 'Content access control\xa0', 'Linear hierarchies\xa0']"
history,"['2017-06', '2016-06-04']"
abstract,"Abstract Content access control aims at ensuring that, in a system with several resources, users can only access resources they are authorized to. Resources are encrypted using cryptographic keys. Generating, distributing and renewing these keys are the challenges faced by key management schemes. While most of the existing key management schemes are typically evaluated by simulation. We propose, for the first time, to use Markovian processes for this purpose. Markovian processes give more accurate evaluation. The key tables-based key management scheme for linear hierarchies (KTLH) is a particularly interesting key management scheme; it was initially proposed for securing group communications, but could easily be adapted to other application such as wireless sensor networks. KTLH requires each user to maintain a set of keys. The keys and size of the key set change dynamically, making the evaluation of the overheads of KTLH a challenging task. Our contribution is threefold, we have (1) modeled KTLH using Markov processes, (2) evaluated KTLH according to its storage, computation and bandwidth overheads and compared it to existing key management schemes and (3) shown how our approach could be generalized to other key management schemes."
journal_title,International Journal of Information Security
article_title,Entropy analysis to classify unknown packing algorithms for malware detection
keyword,"['Entropy analysis\xa0', 'Original entry point (OEP)\xa0', 'Symbolic aggregate approximation (SAX)\xa0', 'Piecewise aggregate approximation (PAA)\xa0']"
history,"['2017-06', '2016-05-04']"
abstract,"Abstract The proportion of packed malware has been growing rapidly and now comprises more than 80 % of all existing malware. In this paper, we propose a method for classifying the packing algorithms of given unknown packed executables, regardless of whether they are malware or benign programs. First, we scale the entropy values of a given executable and convert the entropy values of a particular location of memory into symbolic representations. Our proposed method uses symbolic aggregate approximation (SAX), which is known to be effective for large data conversions. Second, we classify the distribution of symbols using supervised learning classification methods, i.e., naive Bayes and support vector machines for detecting packing algorithms. The results of our experiments involving a collection of 324 packed benign programs and 326 packed malware programs with 19 packing algorithms demonstrate that our method can identify packing algorithms of given executables with a high accuracy of 95.35 %, a recall of 95.83 %, and a precision of 94.13 %. We propose four similarity measurements for detecting packing algorithms based on SAX representations of the entropy values and an incremental aggregate analysis. Among these four metrics, the fidelity similarity measurement demonstrates the best matching result, i.e., a rate of accuracy ranging from 95.0 to 99.9 %, which is from 2 to 13  higher than that of the other three metrics. Our study confirms that packing algorithms can be identified through an entropy analysis based on a measure of the uncertainty of the running processes and without prior knowledge of the executables."
journal_title,International Journal of Information Security
article_title,Making random permutations from physically unclonable constants
keyword,"['Privacy and security\xa0', 'Physically unclonable functions \xa0', 'Random permutations\xa0']"
history,"['2017-06', '2016-03-17']"
abstract,"Abstract The recent availability of reliable schemes for physically unclonable constants (PUC) opens interesting possibilities in the field of security. In this paper, we explore the possibility of using PUCs to embed in a chip random permutations to be used, for example, as building blocks in cryptographic constructions such as sponge functions, substitution–permutation networks, and so on. We show that the most difficult part is the generation of random integers using as the only randomness source the bit-string produced by the PUC. In order to solve the integer generation problem, we propose a partial rejection method that allows the designer to trade-off between entropy and efficiency. The results show that the proposed schemes can be implemented with reasonable complexity."
journal_title,International Journal of Information Security
article_title,ZombieCoin 2.0: managing next-generation botnets using Bitcoin
keyword,"['Botnets\xa0', 'Bitcoin\xa0', 'Cryptocurrencies\xa0', 'C&C\xa0']"
history,['2017-06-01']
abstract,"Abstract Botnets are the preeminent source of online crime and arguably one of the greatest threats to the Internet infrastructure. In this paper, we present ZombieCoin, a botnet command-and-control (C&C) mechanism that leverages the Bitcoin network. ZombieCoin offers considerable advantages over existing C&C techniques, most notably the fact that Bitcoin is designed to resist the very same takedown campaigns and regulatory processes that are the most often-used methods to combat botnets today. Furthermore, we describe how the Bitcoin network enables novel C&C techniques, which dramatically expand the scope of this threat, including the possibilities of flexible rendezvous scheduling, efficient botnet partitioning, and fine-grained control over bots. We validate our claims by implementing ZombieCoin bots which we then deploy and successfully control over the Bitcoin network. Our findings lead us to believe that Bitcoin-based C&C mechanisms are a highly desirable option that botmasters will pursue in the near future. We hope our study provides a useful first step towards devising effective countermeasures for this threat."
journal_title,International Journal of Information Security
article_title,Linkable message tagging: solving the key distribution problem of signature schemes
keyword,"['Message authentication\xa0', 'Key distribution problem\xa0', 'Message tagging\xa0', 'Digital signatures\xa0', '94A60\xa0', '68P25\xa0']"
history,"['2017-06', '2016-03-30']"
abstract,"Abstract Digital signatures guarantee practical security only if the corresponding verification keys are distributed authentically; however, arguably, satisfying solutions for the latter have not been found yet. This paper introduces a novel approach for cryptographic message authentication where this problem does not arise: A linkable message tagging scheme (LMT) identifies pairs of messages and accompanying authentication tags as related if and only if these tags were created using the same secret key. Importantly, our primitive fully avoids public keys and hence elegantly sidesteps the key distribution problem of signature schemes. As an application of LMT we envision an email authentication system with minimal user interaction. Email clients could routinely equip all outgoing messages with corresponding tags and verify for incoming messages whether they indeed originate from the same entity as previously or subsequently received messages with identical sender address. As technical contributions we formalize the notions of LMT and its (more efficient) variant CMT (classifiable message tagging), including corresponding notions of unforgeability. For both variants we propose a range of provably secure constructions, basing on different hardness assumptions, with and without requiring random oracles. This article extends prior work of the same authors that appeared in the proceedings of ACISP 2015 (Günther and Poettering in 2015)."
journal_title,International Journal of Information Security
article_title,Broadcast anonymous routing (BAR): scalable real-time anonymous communication
keyword,"['Sender/receiver anonymity\xa0', 'Unlinkability\xa0', 'Dc-net\xa0', 'Mix-nets\xa0']"
history,"['2017-06', '2016-02-03']"
abstract,"Abstract We propose BAR, a scalable anonymous Internet communication system that combines broadcasting features of dc-net with layered encryption of mix-nets. The main advantage of BAR over other broadcast systems is bandwidth configurability: by using selective broadcasting it can significantly reduce the required bandwidth for a small increase in latency, without affecting anonymity. Unlike mix-net systems, BAR provides unlinkability protection while minimizing the use of public key operations. BAR provides sender, receiver and session anonymity with forward secrecy. We analyze the efficiency of BAR for several anonymity configurations by using a prototype implementation."
journal_title,International Journal of Information Security
article_title,Flexible ciphertext-policy attribute-based encryption supporting AND-gate and threshold with short ciphertexts
keyword,"['Attribute-based encryption\xa0', 'Ciphertext policy\xa0', 'Expressive\xa0', 'Provable security\xa0', 'Pairings\xa0']"
history,['2017-05-17']
abstract,"Abstract Ciphertext-policy attribute-based encryption (CP-ABE) is a very promising cryptographic primitive that allows a data owner to encrypt messages and manage access policies themselves. Most of the existing CP-ABE schemes suffer from efficiency drawbacks due to long ciphertexts, which impacts their adoption in applications where data are shared and stored. In this work, we aim to address this gap by proposing a CP-ABE which features constant-size ciphertext and supports access policies of an AND-gate and a threshold, which make ciphertext policies more expressive and applicable to many practical applications. Prior CP-ABE schemes with short ciphertexts such as that of Herranz et al. (in: Public key cryptography—PKC, Springer, 2010) only allow access policies to be a single AND-gate or a single threshold only. Combinations between these short CP-ABE constructions will result in systems insecure against collusion attacks, which makes the effort to enable access policies with an AND-gate and a threshold gate at the same time becomes very challenging. We present such a scheme that solves this drawback. Our scheme is efficient, expressive and secure. In our construction, the encryptor chooses two subsets of a certain universe of attributes \(S_1\), \(S_2\) with a threshold value \(t_1\) that only users who have at least \(t_1\) attributes in \(S_1\) and all attributes in \(S_2\) can decrypt the ciphertext. The scheme is proven secure against selective chosen plaintext attacks in the standard model by reduction to the augmented multi-sequence of exponents decisional Diffie–Hellman (aMSE-DDH) problem."
journal_title,International Journal of Information Security
article_title,A pairing-based cryptographic approach for data security in the cloud
keyword,"['Cloud storage\xa0', 'Attribute-based encryption\xa0', 'Short signatures\xa0', 'Pairings\xa0']"
history,['2017-04-28']
abstract,"Abstract This paper presents AES4SeC, a security scheme fully constructed over cryptographic pairings. The main building blocks of AES4SeC are attribute-based encryption (ABE) and short signatures (SSign), with generalized constructions for the Type 3 pairing. AES4SeC was developed as an end-to-end storage service for hybrid cloud models and integrated to a file-sharing application for scenarios where data owners upload content to the cloud and selectively decide who is able to access that content. An experimental evaluation of AES4SeC was conducted by testing different security levels, recommended key sizes, and cryptographic engine constructions. This led to a wide experimental evaluation in terms of the running times of the primitive operations (encrypt, decrypt, sign, verify) and the space complexity of the ciphertexts, private and public keys, and the signatures. The implementation results revealed the feasibility and flexibility of AES4SeC in real scenarios, whereas a fine-tuning evaluation revealed that the best results in terms of performance and memory requirements are obtained using Type 3 pairings over type F elliptic curves. This is a relevant result because most of the ABE and SSign schemes in the literature are provided for the Type 1 pairing (symmetric) over type A curves, which exhibited poorer results."
journal_title,International Journal of Information Security
article_title,A new strong security model for stateful authenticated group key exchange
keyword,"['Stateful group key exchange\xa0', 'Dynamic group key exchange\xa0', 'Tree-based group key exchange\xa0', 'Security model\xa0', 'Ephemeral key leakage\xa0', '94A60\xa0']"
history,['2017-04-17']
abstract,"Abstract Stateful authenticated group key exchange (stAGKE) represents an important class of authenticated group key exchange (AGKE) such as tree-based AGKE. The computation of either ephemeral public key or session key in a new stAGKE session may be based on the ephemeral secret state from some previously established session. We notice that earlier AGKE models may be not able to provide appropriate security arguments for stAGKE. In this work, a new model is proposed for stAGKE to formulate security properties in particular for resistance to the leakage attacks on ephemeral key. To be of independent interest, the new model is also flexible, which can be used for analyzing either stateless or stateful AGKE protocols. We show the validity of our model by introducing a new tree-based protocol construction for stAGKE. The proposed scheme is proven secure in our new proposed model without random oracles."
journal_title,International Journal of Information Security
article_title,When time meets test
keyword,"['Security\xa0', 'Software testing\xa0', 'Fuzzing\xa0', 'Timing attacks\xa0', 'Smart card\xa0', 'Java Card\xa0']"
history,['2017-04-10']
abstract,"Abstract One of the main challenges in system’s development is to give a proof of evidence that its functionalities are correctly implemented. This objective is mostly achieved via testing techniques, which include software testing to check whether a system meets its functionalities, or security testing to express what should not happen. For the latter case, fuzzing is considered as first class citizen. It consists in exercising the system with (randomly) generated and eventually modified inputs in order to test its resistance. While fuzzing is definitively the fastest and the easiest way for testing applications, it suffers from severe limitations. Indeed, the precision of the model used for input generation: a random and/or simple model cannot reach all states and significant values. Moreover, a higher model precision can result in a combinatorial explosion of test cases. In this paper, we suggest a new approach whose main ingredient is to combine timing attacks with fuzzing techniques. This new approach, which is dedicated to work on Java Card, allows not only reducing the test space explosion, but also to simplify the fuzzing process configuration. The technique has been implemented, and we present the results obtained on two applets loaded in a Java Card."
journal_title,International Journal of Information Security
article_title,Restricted usage of anonymous credentials in vehicular ad hoc networks for misbehavior detection
keyword,"['Misbehavior\xa0', 'Vehicular ad hoc networks\xa0', 'Anonymous credentials system\xa0', 'Idemix\xa0', 'Privacy\xa0', 'Auditability\xa0', 'Revocation\xa0']"
history,"['2017-04', '2016-04-09']"
abstract,"Abstract The automobile industry is entering a new era of digitalization with major impact on human mobility and transportation infrastructures. A result of such a convergence between the automobile and information technologies is vehicular ad hoc network (VANET), a type of mobile ad hoc networks that has recently enjoyed a lot of attention from the industry, the research community, lawmakers and privacy activists. In VANET, vehicles frequently broadcast various types of messages, including location data. This enables innovative applications and improvements in safety and driving experience. As messages broadcasted in the VANET are digitally signed and the receiver must be able to verify the sender’s authentication and message integrity, there is a need to ensure broadcast authentication and protect driver’s anonymity. However, communication in VANETs takes place with high frequency, and malicious vehicles can hide behind anonymity in order to duplicate packets and get advantage over other vehicles in the network. Indeed, state-of-the-art approaches to privacy-preserving messages broadcast in the VANET typically ensure that each vehicle has a number of pseudonymous certificates that are changed regularly in order to thwart an automated tracing of its activities. However, the possibility of uncontrolled simultaneous use of pseudonyms by misbehaving vehicles remain unaddressed. This paper proposes a set of anonymous credential system based protocols for VANET that enables the detection and limitation of pseudonym/credential overspending. The revocation of the misbehaving vehicle can be also achieved through the proposed solutions. With the prototypical implementation of the proposed protocols, it has been shown that the successful detection of fraud, i.e., pseudonyms overspending and the subsequent revocation of credentials are possible in VANET."
journal_title,International Journal of Information Security
article_title,ASICS: authenticated key exchange security incorporating certification systems
keyword,"['Authenticated key exchange (AKE)\xa0', 'Unknown key share (UKS)\xa0attacks\xa0', 'Certification authority (CA)\xa0', 'Invalid public keys\xa0', 'PKI\xa0', '94A60\xa0']"
history,"['2017-04', '2016-01-04']"
abstract,"Abstract Most security models for authenticated key exchange (AKE) do not explicitly model the associated certification system, which includes the certification authority and its behaviour. However, there are several well-known and realistic attacks on AKE protocols which exploit various forms of malicious key registration and which therefore lie outside the scope of these models. We provide the first systematic analysis of AKE security incorporating certification systems. We define a family of security models that, in addition to allowing different sets of standard AKE adversary queries, also permit the adversary to register arbitrary bitstrings as keys. For this model family, we prove generic results that enable the design and verification of protocols that achieve security even if some keys have been produced maliciously. Our approach is applicable to a wide range of models and protocols; as a concrete illustration of its power, we apply it to the CMQV protocol in the natural strengthening of the eCK model to the ASICS setting."
journal_title,International Journal of Information Security
article_title,On improving resistance to Denial of Service and key provisioning scalability of the DTLS handshake
keyword,"['Security\xa0', 'DTLS\xa0', 'Denial of Service\xa0', ' Key provisioning\xa0']"
history,"['2017-04', '2016-03-25']"
abstract,"Abstract DTLS is a transport layer security protocol designed to provide secure communication over unreliable datagram protocols. Before starting to communicate, a DTLS client and server perform a specific handshake in order to establish a secure session and agree on a common security context. However, the DTLS handshake is affected by two relevant issues. First, the DTLS server is vulnerable to a specific Denial of Service (DoS) attack aimed at forcing the establishment of several half-open sessions. This may exhaust memory and network resources on the server, so making it less responsive or even unavailable to legitimate clients. Second, although it is one of the most efficient key provisioning approaches adopted in DTLS, the pre-shared key provisioning mode does not scale well with the number of clients, it may result in scalability issues on the server side, and it complicates key re-provisioning in dynamic scenarios. This paper presents a single and efficient security architecture which addresses both issues, by substantially limiting the impact of DoS, and reducing the number of keys stored on the server side to one unit only. Our approach does not break the existing standard and does not require any additional message exchange between DTLS client and server. Our experimental results show that our approach requires a shorter amount of time to complete a handshake execution and consistently reduces the time a DTLS server is exposed to a DoS instance. We also show that it considerably improves a DTLS server in terms of service availability and robustness against DoS attack."
journal_title,International Journal of Information Security
article_title,A method for identifying compromised clients based on DNS traffic analysis
keyword,"['DNS\xa0', 'Traffic analysis\xa0', 'Client identification\xa0', 'Fast-flux\xa0', 'Domain-flux\xa0', 'Malware detection\xa0']"
history,"['2017-04', '2016-05-21']"
abstract,"Abstract DNS is widely abused by Internet criminals in order to provide reliable communication within malicious network infrastructure as well as flexible and resilient hosting of malicious content. This paper presents a novel detection method that can be used for identifying potentially compromised clients based on DNS traffic analysis. The proposed method identifies suspicious agile DNS mappings, i.e., mappings characterized by fast changing domain names or/and IP addresses, often used by malicious services. The approach discovers clients that have queried domains contained within identified suspicious domain-to-IP mappings, thus assisting in pinpointing potentially compromised clients within the network. The proposed approach targets compromised clients in large-scale operational networks. We have evaluated the proposed approach using an extensive set of DNS traffic traces from different operational ISP networks. The evaluation illustrates a great potential of accurately identifying suspicious domain-to-IP mappings and potentially compromised clients. Furthermore, the achieved performance indicate that the novel detection approach is promising in view of the adoption in operational ISP networks. Finally, the proposed approach targets both Fast-flux and Domain-flux, thus having an advantage over existing detection methods that identify compromised clients."
journal_title,International Journal of Information Security
article_title,PiSHi: click the images and I tell if you are a human
keyword,"['Image CAPTCHA\xa0', 'User interaction patterns\xa0', 'Decision making\xa0', 'Security\xa0', 'Usability\xa0']"
history,"['2017-04', '2016-02-02']"
abstract,"Abstract This paper introduces pictorial intelligent system for human identification (PiSHi), an image-based captcha which uses three human cognitive abilities to distinguish humans from machines. The first is the human ability to easily recognise the image’s upright orientation. The second is the human brain’s ability in recognising a picture’s content when it is only partially visible. And the third is the human ability in unconscious decision making when encountering pictorial challenges. This work models such complicated human patterns in problem solving for the first time. In order to extract these behavioural patterns and save them in a pattern database, we have implemented our own captcha and performed a series of experiments. PiSHi’s interface presents the user with a set of distorted pictures and asks her to click on the upright orientation of all the pictures in any preferred order. Next, it captures the user’s interaction patterns, compares them with the ones saved in the pattern database, and grants her a corresponding credit. Based on this credit, the user either passes or fails the test, and participates in updating the picture database. Our experiments indicate that human users can solve our proposed captcha effectively—with an accuracy of 99.44 %. Besides, our proposed system is secure against several types of attacks including random guessing and reverse image search engines. The results offer the possibility of utilising the identified human behavioural models in practical captchas."
journal_title,International Journal of Information Security
article_title,Two-factor authentication for the Bitcoin protocol
keyword,"['Bitcoin\xa0', 'Two-party ECDSA\xa0', 'Two-factor authentication\xa0', 'Block chain\xa0', 'Security and privacy\xa0', 'Digital signatures\xa0', 'Mobile and wireless security\xa0']"
history,"['2017-04', '2016-04-05']"
abstract,"Abstract We show how to realize two-factor authentication for a Bitcoin wallet. To do so, we explain how to employ an ECDSA adaption of the two-party signature protocol by MacKenzie and Reiter (Int J Inf Secur 2(3–4):218–239, 2004. doi: 10.1007/s10207-004-0041-0) in the context of Bitcoin and present a prototypic implementation of a Bitcoin wallet that offers both: two-factor authentication and verification over a separate channel. Since we use a smart phone as the second authentication factor, our solution can be used with hardware already available to most users and the user experience is quite similar to the existing online banking authentication methods."
journal_title,International Journal of Information Security
article_title,"A formal modeling and analysis approach for access control rules, policies, and their combinations"
keyword,"['Access control (AC)\xa0', 'XACML\xa0', 'AC combining algorithms\xa0', 'Modeling\xa0', 'Analysis\xa0']"
history,"['2017-02', '2016-01-27']"
abstract,"Abstract Approaches to access control (AC) policy languages, such as eXtensible access control markup language, do not provide a formal representation for specifying rule- and policy-combining algorithms or for verifying properties of AC policies. Some authors propose formal representations for these combining algorithms. However, the proposed models are not expressive enough to represent formally history-based classes of these algorithms, such as ordered-permit-overrides. In addition, some other authors propose a formal representation but do not present automated support for formal verification of properties of AC policies that use these algorithms. This paper demonstrates a new representation that can express all existing AC rule and policy combinations of which the authors are aware. This representation can also be used to automate the formal verification of properties of AC policies related to these algorithms. A new modeling representation for rule- and policy-combining algorithms based on state machines is used to specify rule- and policy-combining algorithms. Examples of these algorithms are programmed in the language of the SPIN model checker, and the programs are then used to support the automated formal verification of properties of AC policies. We present our approach and then use the AC policies and properties of CONTINUE, a conference management system, to compare it with prior work. Our first contribution is a new modeling representation for combining algorithms based on state machines. The second contribution is the formal verification of AC properties under certain combining algorithms that are beyond the capability of other approaches."
journal_title,International Journal of Information Security
article_title,A Data Classification Method for Inconsistency and Incompleteness Detection in Access Control Policy Sets
keyword,"['Policy validation\xa0', 'Data classification\xa0', 'Access control\xa0', 'Inconsistency\xa0', 'Incompleteness\xa0', 'Redundancy\xa0']"
history,"['2017-02', '2016-01-30']"
abstract,"Abstract Access control policies may contain anomalies such as incompleteness and inconsistency, which can result in security vulnerabilities. Detecting such anomalies in large sets of complex policies automatically is a difficult and challenging problem. In this paper, we propose a novel method for detecting inconsistency and incompleteness in access control policies with the help of data classification tools well known in data mining. Our proposed method consists of three phases: firstly, we perform parsing on the policy data set; this includes ordering of attributes and normalization of Boolean expressions. Secondly, we generate decision trees with the help of our proposed algorithm, which is a modification of the well-known C4.5 algorithm. Thirdly, we execute our proposed anomaly detection algorithm on the resulting decision trees. The results of the anomaly detection algorithm are presented to the policy administrator who will take remediation measures. In contrast to other known policy validation methods, our method provides means for handling incompleteness, continuous values and complex Boolean expressions. In order to demonstrate the efficiency of our method in discovering inconsistencies, incompleteness and redundancies in access control policies, we also provide a proof-of-concept implementation."
journal_title,International Journal of Information Security
article_title,Double-authentication-preventing signatures
keyword,"['Digital signatures\xa0', 'Double signatures\xa0', 'Dishonest signer\xa0', 'Coercion\xa0', 'Compelled certificate creation attack\xa0', 'Self-enforcement\xa0', 'Two-to-one trapdoor functions\xa0', '94A60 Cryptography\xa0']"
history,"['2017-02', '2015-12-12']"
abstract,"Abstract Digital signatures are often used by trusted authorities to make unique bindings between a subject and a digital object; for example, certificate authorities certify a public key belongs to a domain name, and time-stamping authorities certify that a certain piece of information existed at a certain time. Traditional digital signature schemes however impose no uniqueness conditions, so a trusted authority could make multiple certifications for the same subject but different objects, be it intentionally, by accident, or following a (legal or illegal) coercion. We propose the notion of a double-authentication-preventing signature, in which a value to be signed is split into two parts: a subject and a message. If a signer ever signs two different messages for the same subject, enough information is revealed to allow anyone to compute valid signatures on behalf of the signer. This double-signature forgeability property discourages signers from misbehaving—a form of self-enforcement—and would give binding authorities like CAs some cryptographic arguments to resist legal coercion. We give a generic construction using a new type of trapdoor functions with extractability properties, which we show can be instantiated using the group of sign-agnostic quadratic residues modulo a Blum integer; we show an additional application of these new extractable trapdoor functions to standard digital signatures."
journal_title,International Journal of Information Security
article_title,Write-only oblivious RAM-based privacy-preserved access of outsourced data
keyword,"['Oblivious RAM\xa0', 'Private Information Retrieval\xa0', 'Outsourced data\xa0']"
history,"['2017-02', '2016-04-15']"
abstract,"Abstract Data outsourcing is plagued with several security and privacy concerns. Oblivious RAM (ORAM) can be used to address one of the many concerns, specifically to protect the privacy of data access pattern from outsourced cloud storage. This is achieved by simulating each original read or write operation with some read and write operations on both real and dummy data items. This paper proposes two single-server write-only ORAM schemes and one multi-server scheme, which simulate only the write operations and protect only the write pattern. The reduction in functionality however allows to build much simpler and efficient (in terms of communication/storage cost) ORAMs. Our schemes can achieve constant communication cost with acceptable storage usage. Write-only ORAM can be used in two situations: (i) only the write pattern is considered to contain sensitive information and needs protection. (ii) In outsourced data sharing, ORAM cannot be used to protect read pattern anyway due to access control issues, and Private Information Retrieval (PIR) has to be used instead. In this paper, we also study how to augment ORAM to support the use of PIR in the latter situation."
journal_title,International Journal of Information Security
article_title,An extended access control mechanism exploiting data dependencies
keyword,"['Query rewriting\xa0', 'Data dependencies\xa0', 'Functional dependencies\xa0', 'Discretionary access control\xa0']"
history,"['2017-02', '2016-02-27']"
abstract,"Abstract In general, access control mechanisms in DBMSs ensure that users access only those portions of data for which they have authorizations, according to a predefined set of access control policies. However, it has been shown that access control mechanisms might be not enough. A clear example is the inference problem due to functional dependencies, which might allow a user to discover unauthorized data by exploiting authorized data. In this paper, we wish to investigate data dependencies (e.g., functional dependencies, foreign key constraints, and knowledge-based implications) from a different perspective. In particular, the aim was to investigate data dependencies as a mean for increasing the DBMS utility, that is, the number of queries that can be safely answered, rather than as channels for releasing sensitive data. We believe that, under given circumstances, this unauthorized release may give more benefits than issues. As such, we present a query rewriting technique capable of extending defined access control policies by exploiting data dependencies, in order to authorize unauthorized but inferable data."
journal_title,International Journal of Information Security
article_title,Message from the guest editors
keyword,[]
history,"['2016-11', '2016-10-08']"
abstract,None
journal_title,International Journal of Information Security
article_title,Analyzing proposals for improving authentication on the TLS-/SSL-protected Web
keyword,"['Web security\xa0', 'Authentication\xa0', 'TLS\xa0', 'HTTPS\xa0', 'Certificates\xa0']"
history,"['2016-11', '2016-02-03']"
abstract,"Abstract “Secure” Web browsing with HTTPS uses TLS/SSL and X.509 certificates to provide authenticated, confidential communication between Web clients and Web servers. The authentication component of the system has a variety of weaknesses, which have led to a variety of proposals for improving the current environment. In this paper, we survey, analyze, compare and contrast five prominent proposals. To do this, we attempt to systematically capture the properties one might require of such a system: authentication properties, forensics/privacy properties, usability properties and pragmatic properties. Enumerating these properties is an important part of understanding these proposals and the nature of the authentication problem for the secure Web. Finally, we offer a few conclusions and suggestions pertaining to these proposals and possible future directions of research."
journal_title,International Journal of Information Security
article_title,Improving the ISO/IEC 11770 standard for key management techniques
keyword,"['Formal analysis\xa0', 'ISO\xa0', 'Protocol standards\xa0', 'Security protocols\xa0']"
history,"['2016-11', '2015-11-23']"
abstract,"Abstract We provide the first systematic analysis of the ISO/IEC 11770 standard for key management techniques (2009, 2009), which describes a set of key establishment, key agreement, and key transport protocols. We analyse the claimed security properties, as well as additional modern requirements on key management protocols, for over 30 protocols and their variants. Our formal, tool-supported analysis of the protocols uncovers several incorrect claims in the standard. We provide concrete suggestions for improving the standard."
journal_title,International Journal of Information Security
article_title,Secure modular password authentication for the web using channel bindings
keyword,"['Password authentication\xa0', 'Transport Layer Security\xa0', 'Channel binding\xa0']"
history,"['2016-11', '2016-09-21']"
abstract,"Abstract Secure protocols for password-based user authentication are well-studied in the cryptographic literature but have failed to see wide-spread adoption on the internet; most proposals to date require extensive modifications to the Transport Layer Security (TLS) protocol, making deployment challenging. Recently, a few modular designs have been proposed in which a cryptographically secure password-based mutual authentication protocol is run inside a confidential (but not necessarily authenticated) channel such as TLS; the password protocol is bound to the established channel to prevent active attacks. Such protocols are useful in practice for a variety of reasons: security no longer relies on users’ ability to validate server certificates and can potentially be implemented with no modifications to the secure channel protocol library. We provide a systematic study of such authentication protocols. Building on recent advances in modeling TLS, we give a formal definition of the intended security goal, which we call password-authenticated and confidential channel establishment (PACCE). We show generically that combining a secure channel protocol, such as TLS, with a password authentication or password-authenticated key exchange protocol, where the two protocols are bound together using the transcript of the secure channel’s handshake, the server’s certificate, or the server’s domain name, results in a secure PACCE protocol. Our prototypes based on TLS are available as a cross-platform client-side Firefox browser extension as well as an Android application and a server-side web application that can easily be installed on servers."
journal_title,International Journal of Information Security
article_title,Unpicking PLAID: a cryptographic analysis of an ISO-standards-track authentication protocol
keyword,"['Protocol analysis\xa0', 'ISO standard\xa0', 'PLAID\xa0', 'Authentication protocol\xa0', 'Privacy\xa0']"
history,"['2016-11', '2016-01-02']"
abstract,"Abstract The Protocol for Lightweight Authentication of Identity (PLAID) aims at secure and private authentication between a smart card and a terminal. Originally developed by a unit of the Australian Department of Human Services for physical and logical access control, PLAID has now been standardized as an Australian standard AS-5185-2010 and is currently in the fast-track standardization process for ISO/IEC 25185-1. We present a cryptographic evaluation of PLAID. As well as reporting a number of undesirable cryptographic features of the protocol, we show that the privacy properties of PLAID are significantly weaker than claimed: using a variety of techniques, we can fingerprint and then later identify cards. These techniques involve a novel application of standard statistical and data analysis techniques in cryptography. We discuss potential countermeasures to our attacks and comment on our experiences with the standardization process of PLAID."
journal_title,International Journal of Information Security
article_title,Measuring protocol strength with security goals
keyword,"['Partial Order\xa0', 'Atomic Formula\xa0', 'Trust Third Party\xa0', 'Cryptographic Protocol\xa0', 'Security Goal\xa0']"
history,"['2016-11', '2016-02-17']"
abstract,"Abstract Flaws in published standards for security protocols are found regularly, often after systems implementing those standards have been deployed. Because of deployment constraints and disagreements among stakeholders, different fixes may be proposed and debated. In this process, security improvements must be balanced with issues of functionality and compatibility. This paper provides a family of rigorous metrics for protocol security improvements. These metrics are sets of first-order formulas in a goal language \(\mathcal {GL}(\varPi )\) associated with a protocol \(\varPi \). The semantics of \(\mathcal {GL}(\varPi )\) is compatible with many ways to analyze protocols, and some metrics in this family are supported by many protocol analysis tools. Other metrics are supported by our Cryptographic Protocol Shapes Analyzer cpsa. This family of metrics refines several “hierarchies” of security goals in the literature. Our metrics are applicable even when, to mitigate a flaw, participants must enforce policies that constrain protocol execution. We recommend that protocols submitted to standards groups characterize their goals using formulas in \(\mathcal {GL}(\varPi )\), and that discussions comparing alternative protocol refinements measure their security in these terms."
journal_title,International Journal of Information Security
article_title,New facets of mobile botnet: architecture and evaluation
keyword,"['Mobile botnets\xa0', 'DNS amplification\xa0', 'Covert channel \xa0', 'Cyber security\xa0']"
history,"['2016-10', '2015-12-31']"
abstract,"Abstract It is without a doubt that botnets pose a growing threat to the Internet, with DDoS attacks of any kind carried out by botnets to be on the rise. Nowadays, botmasters rely on advanced Command and Control (C&C) infrastructures to achieve their goals and most importantly to remain undetected. This work introduces two novel botnet architectures that consist only of mobile devices and evaluates both their impact in terms of DNS amplification and TCP flooding attacks, and their cost pertaining to the maintenance of the C&C channel. The first one puts forward the idea of using a continually changing mobile HTTP proxy in front of the botherder, while the other capitalizes on DNS protocol as a covert channel for coordinating the botnet. That is, for the latter, the messages exchanged among the bots and the herder appear as legitimate DNS transactions. Also, a third architecture is described and assessed, which is basically an optimized variation of the first one. Namely, it utilizes a mixed layout where all the attacking bots are mobile, but the proxy machines are typical PCs not involved in the actual attack. For the DNS amplification attack, which is by nature more powerful, we report an amplification factor that fluctuates between 32.7 and 34.1. Also, regarding the imposed C&C cost, we assert that it is minimal (about 0.25 Mbps) per bot in the worst case happening momentarily when the bot learns about the parameters of the attack."
journal_title,International Journal of Information Security
article_title,"If it looks like a spammer and behaves like a spammer, it must be a spammer: analysis and detection of microblogging spam accounts"
keyword,"['Online social networks\xa0', 'Microblogging\xa0', 'Account abuse\xa0', 'Spam detection\xa0', 'Spam analysis\xa0']"
history,"['2016-10', '2016-02-20']"
abstract,"Abstract Spam in online social networks (OSNs) is a systemic problem that imposes a threat to these services in terms of undermining their value to advertisers and potential investors, as well as negatively affecting users’ engagement. As spammers continuously keep creating newer accounts and evasive techniques upon being caught, a deeper understanding of their spamming strategies is vital to the design of future social media defense mechanisms. In this work, we present a unique analysis of spam accounts in OSNs viewed through the lens of their behavioral characteristics. Our analysis includes over 100 million messages collected from Twitter over the course of 1 month. We show that there exist two behaviorally distinct categories of spammers and that they employ different spamming strategies. Then, we illustrate how users in these two categories demonstrate different individual properties as well as social interaction patterns. Finally, we analyze the detectability of spam accounts with respect to three categories of features, namely content attributes, social interactions, and profile properties."
journal_title,International Journal of Information Security
article_title,Private and oblivious set and multiset operations
keyword,"['Set and multiset operations\xa0', 'Oblivious algorithms\xa0', 'Secure multi-party computation\xa0', 'Secret sharing\xa0', 'Oblivious sorting\xa0']"
history,"['2016-10', '2015-10-03']"
abstract,"Abstract Privacy-preserving set operations are a popular research topic. Despite a large body of literature, the great majority of the available solutions are two-party protocols and expect that each participant knows her input set in the clear. In this work, we put forward a new framework for secure multi-party set and multiset operations in which the inputs can be arbitrarily partitioned among the participants, knowledge of an input (multi)set is not required for any party, and the secure set operations can be composed and can also be securely outsourced to third-party computation providers. In this framework, we construct a comprehensive suite of secure protocols for set operations and their various extensions. Our protocols are secure in the information-theoretic sense and are designed to minimize the round complexity. We then also build support for multiset operations by providing (i) a generic conversion from a multiset to a set, which makes the protocols for set operations applicable to multisets and (ii) direct instantiations of multiset operations of improved performance. All of our protocols have communication and computation complexity of \(O(m \log m)\) and logarithmic round complexity for sets or multisets of size m, which compares favorably with prior work. Practicality of our solutions is shown through experimental results, and novel optimizations based on set compaction allow us to improve performance of our protocols in practice. Our protocols are secure in both semi-honest and malicious security models."
journal_title,International Journal of Information Security
article_title,Time-specific encryption from forward-secure encryption: generic and direct constructions
keyword,"['Time-specific encryption\xa0', 'Forward-secure encryption\xa0', 'Hierarchical identity-based encryption\xa0']"
history,"['2016-10', '2015-11-21']"
abstract,"Abstract Paterson and Quaglia (SCN 2010) proposed the concept of time-specific encryption (TSE) and its efficient constructions. TSE is a type of public-key encryption with an additional functionality where an encryptor can specify a suitable time interval, meaning that the ciphertexts may only be decrypted within this time interval. In this work, we propose a new methodology for designing efficient TSE schemes by using forward-secure encryption (FSE), and based on this methodology, we present a specific TSE scheme using Boneh–Boyen–Goh FSE, and a generic construction from any FSE. Our proposed TSE schemes are practical in all aspects with regard to computational costs and data sizes. The sizes of the ciphertext and the public parameter in our schemes are significantly smaller than those in previous schemes in an asymptotic sense."
journal_title,International Journal of Information Security
article_title,Efficient wildcard search over encrypted data
keyword,"['Searchable symmetric encryption\xa0', 'Cloud computing\xa0', 'Wildcard search\xa0']"
history,"['2016-10', '2015-09-04']"
abstract,"Abstract Searchable encryption is an important technique that allows the data owners to store their encrypted data in the cloud. It also maintains the ability to search a keyword over encrypted data. In practice, searchable encryption scheme supporting wildcard search is very important and widely used. In this paper, we propose a new wildcard search technique to use one wildcard to represent any number of characters. Based on Bloom filter with a novel specified characters position technique, we construct a new searchable symmetric scheme to support wildcard search over encrypted data. This scheme is more efficient than prior schemes, and it can be strengthened to be secure against an adaptive attacker (CKA-2 security). Moreover, this scheme can be dynamic to support file addition and deletion. Our wildcard search technique is of independent interest."
journal_title,International Journal of Information Security
article_title,Efficient and verifiable algorithms for secure outsourcing of cryptographic computations
keyword,"['Secure outsourcing algorithms\xa0', 'Modular exponentiation \xa0', 'Mobile computing\xa0', 'Secure cloud computing\xa0', 'Privacy\xa0']"
history,"['2016-10', '2015-11-30']"
abstract,"Abstract Reducing computational cost of cryptographic computations for resource-constrained devices is an active research area. One of the practical solutions is to securely outsource the computations to an external and more powerful cloud server. Modular exponentiations are the most expensive computation from the cryptographic point of view. Therefore, outsourcing modular exponentiations to a single, external and potentially untrusted cloud server while ensuring the security and privacy provides an efficient solution. In this paper, we propose new efficient outsourcing algorithms for modular exponentiations using only one untrusted cloud server. These algorithms cover public-base and private-exponent, private-base and public-exponent, private-base and private-exponent, more generally private-base and private-exponents simultaneous modular exponentiations. Our algorithms are the most efficient solutions utilizing only one single untrusted server with the best checkability probabilities. Furthermore, unlike existing schemes, which have fixed checkability probability, our algorithms provide adjustable predetermined checkability parameters. Finally, we apply our algorithms to outsource oblivious transfer protocols and blind signatures which are expensive primitives in modern cryptography."
journal_title,International Journal of Information Security
article_title,Flow-based reputation with uncertainty: evidence-based subjective logic
keyword,"['Reputation systems\xa0', 'Evidence theory\xa0', 'Subjective logic\xa0', 'Flow-based reputation models\xa0']"
history,"['2016-08', '2015-08-20']"
abstract,"Abstract The concept of reputation is widely used as a measure of trustworthiness based on ratings from members in a community. The adoption of reputation systems, however, relies on their ability to capture the actual trustworthiness of a target. Several reputation models for aggregating trust information have been proposed in the literature. The choice of model has an impact on the reliability of the aggregated trust information as well as on the procedure used to compute reputations. Two prominent models are flow-based reputation (e.g., EigenTrust, PageRank) and subjective logic-based reputation. Flow-based models provide an automated method to aggregate trust information, but they are not able to express the level of uncertainty in the information. In contrast, subjective logic extends probabilistic models with an explicit notion of uncertainty, but the calculation of reputation depends on the structure of the trust network and often requires information to be discarded. These are severe drawbacks. In this work, we observe that the ‘opinion discounting’ operation in subjective logic has a number of basic problems. We resolve these problems by providing a new discounting operator that describes the flow of evidence from one party to another. The adoption of our discounting rule results in a consistent subjective logic algebra that is entirely based on the handling of evidence. We show that the new algebra enables the construction of an automated reputation assessment procedure for arbitrary trust networks, where the calculation no longer depends on the structure of the network, and does not need to throw away any information. Thus, we obtain the best of both worlds: flow-based reputation and consistent handling of uncertainties."
journal_title,International Journal of Information Security
article_title,On the analysis of time-aware protocols in universal composability framework
keyword,"['Time-aware protocols\xa0', 'Cryptanalysis\xa0', 'Provable security\xa0', 'Universal composability\xa0']"
history,"['2016-08', '2015-08-23']"
abstract,"Abstract We consider the analysis of time-aware cryptographic protocols in the universal composability (UC) framework (Canetti in 2000). The tasks we consider are the timeliness of messages within an instance as well as the time of validity of cryptographic credentials where the lifetime of time stamps overlaps lots of instances. We point out that the UC analysis of time-aware protocols with global access to real time clock cannot be carried out directly within the standard model. For the resolution of the corresponding problem, we considered two ways: one is the introduction of an auxiliary timing oracle into the ideal system, while the other consists of two time models: a quantized real time source and an abstract “random-time” source, and we show an essential equivalence between them. The time models provide not only theoretical but also practical benefits."
journal_title,International Journal of Information Security
article_title,A practical privacy-preserving targeted advertising scheme for IPTV users
keyword,"['IPTV\xa0', 'Targeted advertising\xa0', 'Privacy\xa0', 'Cryptography\xa0', 'Cloud computing\xa0']"
history,"['2016-08', '2015-07-26']"
abstract,"Abstract In this work, we present a privacy-preserving scheme for targeted advertising via the Internet Protocol TV (IPTV). The scheme uses a communication model involving a collection of subscribers, a content provider (IPTV), advertisers and a semi-trusted server. To target potential customers, the advertiser can utilize not only demographic information of subscribers, but also their watching habits. The latter includes watching history, preferences for IPTV content and watching rate, which are periodically (e.g., weekly) published on a semi-trusted server (e.g., cloud server) along with anonymized demographics. Since the published data may leak sensitive information about subscribers, it is safeguarded using cryptographic techniques in addition to the anonymization of demographics. The techniques used by the advertiser, which can be manifested in its queries to the server, are considered (trade) secrets and therefore are protected as well. The server is oblivious to the published data and the queries of the advertiser as well as its own responses to these queries. Only a legitimate advertiser, endorsed with so-called trapdoors by the IPTV, can query the cloud server and access the query results. Even when some background information about users is available, query responses do not leak sensitive information about the IPTV users. The performance of the proposed scheme is evaluated with experiments, which show that the scheme is practical. The algorithms demonstrate both weak and strong scaling property and take advantage of high level of parallelism. The scheme can also be applied as a recommendation system."
journal_title,International Journal of Information Security
article_title,Privacy-preserving authentication framework using bloom filter for secure vehicular communications
keyword,"['VANETs\xa0', 'Authentication\xa0', 'Aggregate signature verification\xa0', 'Bloom filters\xa0']"
history,"['2016-08', '2015-09-07']"
abstract,"Abstract Vehicular ad hoc networks (VANETs) are the future of the intelligent transportation systems (ITS), which aim to improve traffic safety. The received message in VANETs can contain the malicious content that may affect the entire network; hence, these networks are more prone to such attacks. Thus, security is a major consideration before the deployment of such network. In this paper, a secure privacy-preserving authentication framework is proposed, which employs the use of pseudonyms for anonymous communication. A new digital signature scheme and aggregate verification scheme are designed for vehicular communications, and the ID-based signature scheme is used for vehicle-to-RSU communication. The multiple authorities are involved in revealing the identity of the vehicle in case of revocation. The signature verification scheme is improved by the use of bloom filters, and the results achieved by the proposed scheme have been implemented on a simulated environment."
journal_title,International Journal of Information Security
article_title,A cryptographic study of tokenization systems
keyword,"['Payment card industry standard\xa0', 'Tokenization\xa0', 'Symmetric encryption\xa0', 'Format-preserving encryption\xa0', 'Provable security\xa0']"
history,"['2016-08', '2016-01-22']"
abstract,"Abstract Payments through cards have become very popular in today’s world. All businesses now have options to receive payments through this instrument; moreover, most organizations store card information of its customers in some way to enable easy payments in future. Credit card data are a very sensitive information, and theft of this data is a serious threat to any company. Any organization that stores credit card data needs to achieve payment card industry (PCI) compliance, which is an intricate process where the organization needs to demonstrate that the data it stores are safe. Recently, there has been a paradigm shift in treatment of the problem of storage of payment card information. In this new paradigm instead of the real credit card data a token is stored, this process is called “tokenization.” The token “looks like” the credit/debit card number, but ideally has no relation with the credit card number that it represents. This solution relieves the merchant from the burden of PCI compliance in several ways. Though tokenization systems are heavily in use, to our knowledge, a formal cryptographic study of this problem has not yet been done. In this paper, we initiate a study in this direction. We formally define the syntax of a tokenization system and several notions of security for such systems. Finally, we provide some constructions of tokenizers and analyze their security in light of our definitions."
journal_title,International Journal of Information Security
article_title,Malware detection using bilayer behavior abstraction and improved one-class support vector machines
keyword,"['Malware detection\xa0', 'Behavior feature extraction\xa0', 'Machine learning\xa0', 'One-class classification\xa0']"
history,"['2016-08', '2015-08-09']"
abstract,"Abstract Malware detection is one of the most challenging problems in computer security. Recently, methods based on machine learning are very popular in unknown and variant malware detection. In order to achieve a successful learning, extracting discriminant and stable features is the most important prerequisite. In this paper, we propose a bilayer behavior abstraction method based on semantic analysis of dynamic API sequences. Operations on sensitive system resources and complex behaviors are abstracted in an interpretable way at different semantic layers. At the lower layer, raw API calls are combined to abstract low-layer behaviors via data dependency analysis. At the higher layer, low-layer behaviors are further combined to construct more complex high-layer behaviors with good interpretability. The extracted low-layer and high-layer behaviors are finally embedded into a high-dimensional vector space. Hence, the abstracted behaviors can be directly used by many popular machine learning algorithms. Besides, to tackle the problem that benign programs are not adequately sampled or malware and benign programs are severely imbalanced, an improved one-class support vector machine (OC-SVM) named OC-SVM-Neg is proposed which makes use of the available negative samples. Experimental results show that the proposed feature extraction method with OC-SVM-Neg outperforms binary classifiers on the false alarm rate and the generalization ability."
journal_title,International Journal of Information Security
article_title,Understanding trust in privacy-aware video surveillance systems
keyword,"['Video surveillance\xa0', 'Privacy\xa0', 'Trust\xa0']"
history,"['2016-06', '2015-04-07']"
abstract,"Abstract Recent advances in pervasive video surveillance systems pave the way for a comprehensive surveillance of every aspect of our lives, hence, leading us to a state of dataveillance. Computerized and interconnected systems of cameras could be used to profile, track and monitor individuals for the sake of security. Notwithstanding, these systems clearly interfere with the fundamental right of the individuals to privacy. Most literature on privacy in video surveillance systems concentrates on the goal of detecting faces and other regions of interest and in proposing different methods to protect them. However, the trustworthiness of those systems and, by extension, of the privacy they provide are mostly neglected. In this article, we define the concept of trustworthy privacy-aware video surveillance system. Moreover, we assess the techniques proposed in the literature according to their suitability for such a video surveillance system. Finally, we describe the properties that a deployment of a trustworthy video surveillance system must fulfill."
journal_title,International Journal of Information Security
article_title,Broadcast encryption with dealership
keyword,"['Broadcast encryption\xa0', 'Dealership\xa0', 'Provable security\xa0']"
history,"['2016-06', '2015-04-07']"
abstract,"Abstract In this paper, we introduce a new cryptographic primitive called broadcast encryption with dealership. This notion, which has never been discussed in the cryptography literature, is applicable to many realistic broadcast services, for example subscription-based television service. Specifically, the new primitive enables a dealer to bulk buy the access to some products (e.g., TV channels) from the broadcaster, and hence, it will enable the dealer to resell the contents to the subscribers with a cheaper rate. Therefore, this creates business opportunity model for the dealer. We highlight the security consideration in such a scenario and capture the security requirements in the security model. Subsequently, we present a concrete scheme, which is proven secure under the decisional bilinear Diffie–Hellman exponent and the Diffie–Hellman exponent assumptions."
journal_title,International Journal of Information Security
article_title,Effectiveness and performance analysis of model-oriented security requirements engineering to elicit security requirements: a systematic solution for developing secure software systems
keyword,"['Assets\xa0', 'Security requirements\xa0', 'Security requirements engineering\xa0', 'Software systems\xa0', 'Threats\xa0', 'Vulnerabilities\xa0']"
history,"['2016-06', '2015-11-21']"
abstract,"Abstract Software systems are becoming more and more critical in every domain of human society. These systems are used not only by corporates and governments, but also by individuals and across networks of organizations. The wide use of software systems has resulted in the need to contain a large amount of critical information and processes, which certainly need to remain secure. As a consequence, it is important to ensure that the systems are secure by considering security requirements at the early phases of software development life cycle. In this paper, we propose to consider security requirements as functional requirements and apply model-oriented security requirements engineering framework as a systematic solution to elicit security requirements for e-governance software systems. As the result, high level of security can be achieved by more coverage of assets and threats, and identifying more traces of vulnerabilities in the early stages of requirements engineering. This in turn will help to elicit effective security requirements as countermeasures with business requirements."
journal_title,International Journal of Information Security
article_title,Taking back control of privacy: a novel framework for preserving cloud-based firewall policy confidentiality
keyword,"['Firewall\xa0', 'Cloud computing\xa0', 'Privacy\xa0', ' Bloom Filter\xa0']"
history,"['2016-06', '2015-05-26']"
abstract,"Abstract As the cloud computing paradigm evolves, new types of cloud-based services have become available, including security services. Some of the most important and most commonly adopted security services are firewall services. These cannot be easily deployed in a cloud, however, because of a lack of mechanisms preserving firewall policy confidentiality. Even if they were provided, the customer traffic flowing through the Cloud Service Provider infrastructure would still be exposed to eavesdropping and information gaining by performing analysis. To bypass these issues, the following article introduces a novel framework, known as the Ladon Hybrid Cloud, for preserving cloud-based firewall policy confidentiality. It is shown that in this framework, a high level of privacy is provided thanks to leveraging an anonymized firewall approach and a hybrid cloud model. A number of optimization techniques, which help to further improve the Ladon Hybrid Cloud privacy level, are also introduced. Finally, analysis performed on the framework shows that it is possible to find a trade-off between the Ladon Hybrid Cloud privacy level, its congestion probability, and efficiency. This argument has been demonstrated through the results of conducted experiments."
journal_title,International Journal of Information Security
article_title,Detection of firewall configuration errors with updatable tree
keyword,"['Firewall\xa0', 'Configuration update\xa0', 'Conflicts\xa0', 'Tree\xa0']"
history,"['2016-06', '2015-05-19']"
abstract,"Abstract The fundamental goals of security policy are to allow uninterrupted access to the network resources for authenticated users and to deny access to unauthenticated users. For this purpose, firewalls are frequently deployed in every size network. However, bad configurations may cause serious security breaches and network vulnerabilities. In particular, conflicted filtering rules lead to block legitimate traffic and to accept unwanted packets. This fact troubles administrators who have to insert and delete filtering rules in a huge configuration file. We propose in this paper a quick method for managing a firewall configuration file. We represent the set of filtering rules by a firewall anomaly tree (FAT). Then, an administrator can update the FAT by inserting and deleting some filtering rules. The FAT modification automatically reveals emerged anomalies and helps the administrator to find the adequate position for a new added filtering rule. All the algorithms presented in the paper have been implemented, and computer experiments show the usefulness of updating the FAT data structure in order to quickly detect anomalies when dealing with a huge firewall configuration file."
journal_title,International Journal of Information Security
article_title,Multi-Keyword search over encrypted data with scoring and search pattern obfuscation
keyword,"['Encrypted cloud data\xa0', 'Secure search\xa0', ' Privacy preservation\xa0', 'Efficiency\xa0', 'Scoring\xa0']"
history,"['2016-06', '2015-05-23']"
abstract,"Abstract Search over encrypted data recently became a critical operation that raised a considerable amount of interest in both academia and industry. Especially, as outsourcing, sensitive data to cloud prove to be a strong trend to benefit from the unmatched storage and computing capacities thereof. Indeed, privacy-preserving search over encrypted data, an apt term to address privacy-related issues concomitant in outsourcing sensitive data, have been widely investigated in the literature under different models and assumptions. In this work, we propose an efficient scheme that allows privacy-preserving search over encrypted data using queries with multiple keywords. Most important contributions of this work are as follows. Firstly, using a property referred as \(\delta \)-mean query obfuscation, the proposed scheme hides the search patterns, which are allowed to leak in many works in the literature including our preliminary work on the subject Orencik et al. (2013) [1]. Secondly, a two-server setting is employed to eliminate the correlation between the queries and matching documents sent to the user under the assumption that the two servers are not colluding. Thirdly, we propose a novel compression scheme that reduces both the communication cost between the two servers and the computation cost of the search operation more than 55 times compared to the standard approach. And finally, the proposed scheme also provides an effective scoring and ranking capability that is based on term frequency–inverse document frequency (tf-idf) weights of keyword–document pairs. Our analyses demonstrate that the proposed scheme is privacy-preserving, efficient and effective."
journal_title,International Journal of Information Security
article_title,Efficient parallelizable hashing using small non-compressing primitives
keyword,"['Hash function\xa0', 'Small primitives\xa0', ' Collision resistance\xa0', 'Preimage resistance\xa0', ' Parallelizable\xa0']"
history,"['2016-06', '2015-04-29']"
abstract,"Abstract A well-established method of constructing hash functions is to base them on non-compressing primitives, such as one-way functions or permutations. In this work, we present \(S^r\), an \(rn\)-to-\(n\)-bit compression function (for \(r\ge 1\)) making \(2r-1\) calls to \(n\)-to-\(n\)-bit primitives (random functions or permutations). \(S^r\) compresses its inputs at a rate (the amount of message blocks per primitive call) up to almost 1/2, and it outperforms all existing schemes with respect to rate and/or the size of underlying primitives. For instance, instantiated with the \(1600\)-bit permutation of NIST’s SHA-3 hash function standard, it offers about \(800\)-bit security at a rate of almost 1/2, while SHA-3-512 itself achieves only \(512\)-bit security at a rate of about \(1/3\). We prove that \(S^r\) achieves asymptotically optimal collision security against semi-adaptive adversaries up to almost \(2^{n/2}\) queries and that it can be made preimage secure up to \(2^n\) queries using a simple tweak."
journal_title,International Journal of Information Security
article_title,Message from the Guest Editors
keyword,[]
history,"['2016-04', '2016-01-25']"
abstract,None
journal_title,International Journal of Information Security
article_title,A hybrid approach to vector-based homomorphic tallying remote voting
keyword,"['Cryptography\xa0', 'E-voting\xa0', ' Homomorphic tallying\xa0', 'Zero-knowledge proof\xa0']"
history,"['2016-04', '2015-03-05']"
abstract,"Abstract Vector-based homomorphic tallying remote voting schemes provide an efficient protocol for vote tallying, but they require voters to prove in zero-knowledge that the ballots they cast have been properly generated. This is usually achieved by means of the so-called zero-knowledge range proofs, which should be verified by the polling station before tallying. In this paper, we present an end-to-end verifiable hybrid proposal in which ballots are proven to be correct by making use of a zero-knowledge proof of mixing but still using a homomorphic tallying for gathering the election results. Our proposal offers all the advantages of the homomorphic tallying paradigm, while it avoids the elevated computational cost of range proofs. As a result, ballot verification performance is improved in comparison with the equivalent homomorphic systems. The proposed voting scheme is suitable for multi-candidate elections as well as for elections in which the votes have different weights."
journal_title,International Journal of Information Security
article_title,Resolving privacy-preserving relationships over outsourced encrypted data storages
keyword,"['Searchable encryption\xa0', 'Outsourcing data\xa0', 'Homomorphic encryption\xa0', 'Privacy-preserving relationships\xa0', 'Cloud computing\xa0']"
history,"['2016-04', '2015-04-03']"
abstract,"Abstract Due to the numerous advantages in terms of cost reduction, usability, and flexibility, today we are witnessing the adoption of solutions where individuals and enterprises prefer to outsource (part of) their private information or assets for processing to third parties. Yet, such adoption will not become a complete success unless outsourced data storages reliably guarantee the privacy of sensitive information. With this aim in mind, some data storage providers offer the possibility of encrypting assets, achieving a remarkable degree of privacy, but at the expense of usability. At best, advanced cryptographic primitives can be directly implemented over the encrypted data to allow its owners to perform certain operations, such as keyword-based searches, on the side of the data storages. The paper at hand proposes a novel approach based on fully homomorphic encryption to correlate encrypted pieces of data in outsourced data storages. The goal was to enrich searchable encryption solutions by transparently adding related keywords to a given query, yet preventing the data storages to know the outsourced information, the received query, the resulting response, or the relationship between queries and responses. The conducted experiments show that nowadays, the main bottleneck resides in the inefficiency of the existing fully homomorphic encryption algorithms. Nevertheless, our proposal is not tied to any particular algorithm, thereby allowing users to select the most efficient in terms of computing time."
journal_title,International Journal of Information Security
article_title,Behavior-based approach to detect spam over IP telephony attacks
keyword,"['VoIP\xa0', 'SPIT detection\xa0', 'Behavior-based approach\xa0', 'Supervised learning methods\xa0', 'ROC\xa0']"
history,"['2016-04', '2015-03-24']"
abstract,"Abstract Spam over IP telephony (SPIT) is expected to become a serious problem as the use of voice over IP grows. This kind of spam is appreciated by spammers due to its effectiveness and low cost. Many anti-SPIT solutions are applied to resolve this problem but there are still limited in some cases. Thus, in this paper, we propose a system to detect SPIT attacks through behavior-based approach. Our framework operates in three steps: (1) collecting significant calls attributes by exploring and analyzing network traces using OPNET environment; (2) applying sliding windows strategy to properly maintain the callers profiles; and (3) classifying caller (i.e., legitimate or SPITter) using ten supervised learning methods: NaïveBayes, BayesNet, SMO RBFKernel, SMO PolyKernel, MultiLayerPerceptron with two and three layers, NBTree, J48, Bagging and AdaBoostM1. The results of our experiments demonstrate the great performance of these methods. Our study, based on receiver operating characteristics curves, shows that the AdaBoostM1 classifier is more efficient than the other methods and achieve an almost perfect detection rate with acceptable training time."
journal_title,International Journal of Information Security
article_title,Preventing sensitive relationships disclosure for better social media preservation
keyword,"['Social media preservation\xa0', 'Information disclosure\xa0', 'Social networks\xa0', 'Privacy\xa0', 'Relationship discovery\xa0', 'Crowdsourcing\xa0']"
history,"['2016-04', '2015-02-22']"
abstract,"Abstract A fundamental aspect of all social networks is information sharing. It is one of the most common forms of online interaction that is tightly associated with social media preservation and information disclosure. As such, information sharing is commonly viewed as a key enabler for social media preservation tasks. In the current situation, where information sharing and inter-user communications are made instantly possible via the widespread use of ubiquitous technologies, privacy related, and particularly information disclosure issues, are the obvious, much discussed, immediate consequences of information sharing. As a result, information disclosure, especially when multimedia data come to play, is critical for appropriate social media preservation strategies that consider and respect the privacy of social network users. Social media preservation must align with privacy protection solutions and consequently must protect sensitive information that social network users would like to keep private. In this paper, we propose a new approach to implement a privacy-oriented social media preservation strategy that prevents the disclosure of sensitive information. Instead of using a preserve-all strategy, we present a framework to personalize social media preservation tasks. We then describe our proposed rule-based algorithm to evaluate information disclosure addressing mainly relationship type disclosure and using shared photos. We also provide an experimental study to investigate the efficiency and the relevance of our approach."
journal_title,International Journal of Information Security
article_title,Link-time smart card code hardening
keyword,"['Smart card\xa0', 'Fault\xa0', 'Software protection\xa0', 'Binary rewriting\xa0', 'Overhead\xa0']"
history,"['2016-04', '2015-03-27']"
abstract,"Abstract This paper presents a feasibility study to protect smart card software against fault-injection attacks by means of link-time code rewriting. This approach avoids the drawbacks of source code hardening, avoids the need for manual assembly writing, and is applicable in conjunction with closed third-party compilers. We implemented a range of cookbook code hardening recipes in a prototype link-time rewriter and evaluate their coverage and associated overhead to conclude that this approach is promising. We demonstrate that the overhead of using an automated link-time approach is not significantly higher than what can be obtained with compile-time hardening or with manual hardening of compiler-generated assembly code."
journal_title,International Journal of Information Security
article_title,A uniform approach for access control and business models with explicit rule realization
keyword,"['Access control models\xa0', 'Business models\xa0', 'Access control rules\xa0', 'Patterns\xa0', 'Resource–Event–Agent\xa0']"
history,"['2016-04', '2015-02-11']"
abstract,"Abstract Access control is an important part of security in software, such as business applications, since it determines the access of users to objects and operations and the constraints of this access. Business and access control models are expressed using different representations. In addition, access control rules are not generally defined explicitly from access control models. Even though the business model and access control model are two separate modeling abstractions, they are inter-connected as access control is part of any business model. Therefore, the first goal is to add access control models to business models using the same fundamental building blocks. The second goal is to use these models and define general access control rules explicitly from these models so that the connection between models and their realizations are also present. This paper describes a new common representation for business models and classes of access control models based on the Resource–Event–Agent (REA) modeling approach to business models. In addition, the connection between models and their represented rules is clearly defined. We present a uniform approach to business and access control models. First, access control primitives are mapped onto REA-based access control patterns. Then, REA-based access control patterns are combined to define access control models. Based on these models, general access control rules are expressed in Extended Backus–Naur Form."
journal_title,International Journal of Information Security
article_title,Efficient attribute-based signature and signcryption realizing expressive access structures
keyword,"['Attribute-based signature\xa0', 'Signcryption\xa0', 'Public verifiability\xa0', 'Signer privacy\xa0', 'LSSS-realizable access structure\xa0']"
history,"['2016-02', '2015-05-19']"
abstract,"Abstract This paper addresses the open problem of designing attribute-based signature (ABS) schemes with constant number of bilinear pairing operations for signature verification or short signatures for more general policies posed by Gagné et al. in Pairing 2012. Designing constant-size ABS for expressive access structures is a challenging task. We design two key-policy ABS schemes with constant-size signature for expressive linear secret-sharing scheme (LSSS)-realizable monotone access structures. Both the schemes utilize only 3 pairing operations in signature verification process. The first scheme is small universe construction, while the second scheme supports large universes of attributes. The signing key is computed according to LSSS-realizable access structure over signer’s attributes, and the message is signed with an attribute set satisfying the access structure. Our ABS schemes provide the existential unforgeability in selective attribute set security model and preserve signer privacy. We also propose a new attribute-based signcryption (ABSC) scheme for LSSS-realizable access structures utilizing only 6 pairings and making the ciphertext size constant. Our scheme is significantly more efficient than existing ABSC schemes. While the secret key (signing key or decryption key) size increases by a factor of number of attributes used in the system, the number of pairing evaluations is reduced to constant. Our protocol achieves (a) ciphertext indistinguishability under adaptive chosen ciphertext attacks assuming the hardness of decisional Bilinear Diffie–Hellman Exponent problem and (b) existential unforgeability under adaptive chosen message attack assuming the hardness of computational Diffie–Hellman Exponent problem. The security proofs are in selective attribute set security model without using any random oracle heuristic. In addition, our ABSC achieves public verifiability of the ciphertext, enabling any party to verify the integrity and validity of the ciphertext."
journal_title,Algorithmica
article_title,Guest Editorial: Special Issue on Combinatorial Optimization and Applications
keyword,[]
history,"['2018-06', '2018-03-28']"
abstract,None
journal_title,Algorithmica
article_title,Optimal Self-Assembly of Finite Shapes at Temperature 1 in 3D
keyword,"['Self-assembly\xa0', 'Algorithmic self-assembly\xa0', 'Kolmogorov complexity\xa0', 'Scaled shapes\xa0', 'Optimal encoding\xa0', 'Optimal self-assembly\xa0', 'Temperature 1\xa0', 'Non-cooperative self-assembly\xa0']"
history,"['2018-06', '2016-12-12', '2016-04-13', '2016-11-24']"
abstract,"Abstract Tile self-assembly in which tiles may bind in a non-cooperative fashion is often referred to as “temperature 1 self-assembly” or simply “non-cooperative self-assembly”. In this type of self-assembly, a tile may non-cooperatively bind to an assembly via (at least) one of its sides, unlike in cooperative self-assembly, in which some tiles may be required to bind on two or more sides. Cooperative self-assembly leads to highly non-trivial theoretical behavior but two-dimensional non-cooperative self-assembly is conjectured to be only capable of producing highly-regular shapes and patterns, which, in general, cannot be interpreted as complex computation. Remarkably, Cook et al. (Temperature 1 self-assembly: deterministic assembly in 3D and probabilistic assembly in 2D. In: Proceedings of the 22nd Annual ACM–SIAM Symposium on Discrete Algorithms 2011) showed that three-dimensional non-cooperative self-assembly is essentially as powerful as cooperative self-assembly, with respect to Turing universality and self-assembly of \(N \times N\) squares. In this paper, we consider the non-cooperative self-assembly of just-barely 3D shapes. Working in a three-dimensional variant of Winfree’s abstract Tile Assembly Model, we show that, for an arbitrary finite, connected shape \(X \subset {\mathbb {Z}}^2\), there is a tile set that uniquely self-assembles at temperature 1 into a 3D representation of a scaled-up version of X with optimal program-size complexity, where the “program-size complexity”, also known as “tile complexity”, of a shape is the minimum number of tile types required to uniquely self-assemble it. Moreover, our construction is “just barely” 3D in the sense that it only places tiles in the \(z = 0\) and \(z = 1\) planes. Our result is essentially a just-barely 3D temperature 1 simulation of a similar 2D temperature 2 result by Soloveichik and Winfree (SIAM J Comput 36(6):1544–1569, 2007)."
journal_title,Algorithmica
article_title,Structural and Algorithmic Properties of 2-Community Structures
keyword,"['Graph theory\xa0', 'Complexity\xa0', 'Graph partitioning\xa0', 'Community structure\xa0', 'Clustering\xa0', 'Social networks\xa0']"
history,"['2018-06', '2017-02-06', '2016-04-08', '2017-01-23']"
abstract,"Abstract We investigate the structural and algorithmic properties of 2-community structures in graphs introduced recently by Olsen (Math Soc Sci 66(3):331–336, 2013). A 2-community structure is a partition of a vertex set into two parts such that for each vertex the numbers of neighbours in/outside its own part and the sizes of the parts are correlated. We show that some well studied graph classes as graphs of maximum degree 3, minimum degree at least \(|V|-3\), trees and also others, have always a 2-community structure. Furthermore, a 2-community structure can be found in polynomial time in all these classes, even with additional request of connectivity in both parts. We introduce a concept of a weak 2-community and prove that in general graphs it is NP-complete to find a balanced weak 2-community structure with or without request for connectivity in both parts. On the other hand, we present a polynomial-time algorithm to solve the problem (without the condition for connectivity of parts) in graphs of degree at most 3."
journal_title,Algorithmica
article_title,"Scaffolding Problems Revisited: Complexity, Approximation and Fixed Parameter Tractable Algorithms, and Some Special Cases"
keyword,"['Complexity\xa0', 'Approximation\xa0', 'Lower bound\xa0', 'Kernel\xa0', 'Scaffolding\xa0']"
history,"['2018-06', '2018-01-29', '2016-04-20', '2018-01-11']"
abstract,"Abstract This paper is devoted to new results about the scaffolding problem, an integral problem of genome inference in bioinformatics. The problem consists in finding a collection of disjoint cycles and paths covering a particular graph called the “scaffold graph”. We examine the difficulty and the approximability of the scaffolding problem in special classes of graphs, either close to trees, or very dense. We propose negative and positive results, exploring the frontier between difficulty and tractability of computing and/or approximating a solution to the problem. Also, we explore a new direction through related problems consisting in finding a family of edges having a strong effect on solution weight."
journal_title,Algorithmica
article_title,"Trees, Paths, Stars, Caterpillars and Spiders"
keyword,"['Graph decomposition\xa0', 'Arboricity\xa0', 'Interval number\xa0', 'Subcoloring\xa0', 'NP-hardness\xa0']"
history,"['2018-06', '2016-10-25', '2016-03-08', '2016-10-21']"
abstract,"Abstract For any \(k \ge 2\), deciding whether the linear arboricity, star arboricity, caterpillar arboricity, spider arboricity, track number, unit track number, and subchromatic index, respectively, of a bipartite graph are at most k are all NP-complete."
journal_title,Algorithmica
article_title,Optimal Approximation Algorithms for Maximum Distance-Bounded Subgraph Problems
keyword,"[None, None, 'Maximum distance-bounded subgraph problems\xa0', '(In)approximability\xa0']"
history,"['2018-06', '2017-07-21', '2016-04-20', '2017-07-08']"
abstract,"Abstract In this paper we study the (in)approximability of two distance-based relaxed variants of the maximum clique problem (Max Clique), named Max d-Clique and Max d-Club: A d-clique in a graph \(G = (V, E)\) is a subset \(S\subseteq V\) of vertices such that for every pair of vertices \(u, v\in S\), the distance between u and v is at most d in G. A d-club in a graph \(G = (V, E)\) is a subset \(S'\subseteq V\) of vertices that induces a subgraph of G of diameter at most d. Given a graph G with n vertices, the goal of Max d-Clique (Max d-Club, resp.) is to find a d-clique (d-club, resp.) of maximum cardinality in G. Since Max 1-Clique and Max 1-Club are identical to Max Clique, the inapproximabilty for Max Clique shown by Zuckerman in 2007 is transferred to them. Namely, Max 1-Clique and Max 1-Club cannot be efficiently approximated within a factor of \(n^{1-\varepsilon }\) for any \(\varepsilon > 0\) unless \(\mathcal{P} = \mathcal{NP}\). Also, in 2002, Marin\(\breve{\mathrm{c}}\)ek and Mohar showed that it is \(\mathcal{NP}\)-hard to approximate Max d-Club to within a factor of \(n^{1/3-\varepsilon }\) for any \(\varepsilon >0\) and any fixed \(d\ge 2\). In this paper, we strengthen the hardness result; we prove that, for any \(\varepsilon > 0\) and any fixed \(d\ge 2\), it is \(\mathcal{NP}\)-hard to approximate Max d-Club to within a factor of \(n^{1/2-\varepsilon }\). Then, we design a polynomial-time algorithm which achieves an optimal approximation ratio of \(O(n^{1/2})\) for any integer \(d\ge 2\). By using the similar ideas, we show the \(O(n^{1/2})\)-approximation algorithm for Max d-Clique for any \(d\ge 2\). This is the best possible in polynomial time unless \(\mathcal{P} = \mathcal{NP}\), as we can prove the \(\varOmega (n^{1/2-\varepsilon })\)-inapproximability."
journal_title,Algorithmica
article_title,Discovering Small Target Sets in Social Networks: A Fast and Effective Algorithm
keyword,"['Social networks\xa0', 'Information diffusions\xa0', 'Algorithms\xa0']"
history,"['2018-06', '2017-10-26', '2016-04-16', '2017-10-14']"
abstract,"Abstract Given a network represented by a graph \(G=(V,E)\), we consider a dynamical process of influence diffusion in G that evolves as follows: Initially only the nodes of a given \(S\subseteq V\) are influenced; subsequently, at each round, the set of influenced nodes is augmented by all the nodes in the network that have a sufficiently large number of already influenced neighbors. The question is to determine a small subset of nodes S (a target set) that can influence the whole network. This is a widely studied problem that abstracts many phenomena in the social, economic, biological, and physical sciences. It is known that the above optimization problem is hard to approximate within a factor of \(2^{\log ^{1-\epsilon }|V|}\), for any \(\epsilon >0\). In this paper, we present a fast and surprisingly simple algorithm that exhibits the following features: (1) when applied to trees, cycles, or complete graphs, it always produces an optimal solution (i.e, a minimum size target set); (2) when applied to arbitrary networks, it always produces a solution of cardinality which improves on previously known upper bounds; (3) when applied to real-life networks, it always produces solutions that substantially outperform the ones obtained by previously published algorithms (for which no proof of optimality or performance guarantee is known in any class of graphs)."
journal_title,Algorithmica
article_title,Deleting Edges to Restrict the Size of an Epidemic: A New Application for Treewidth
keyword,"['Edge-deletion\xa0', 'Treewidth\xa0', 'Network epidemiology\xa0', 'Graph contagion\xa0']"
history,"['2018-06', '2017-04-20', '2016-04-20', '2017-04-11']"
abstract,"Abstract Motivated by applications in network epidemiology, we consider the problem of determining whether it is possible to delete at most k edges from a given input graph (of small treewidth) so that the resulting graph avoids a set \(\mathcal {F}\) of forbidden subgraphs; of particular interest is the problem of determining whether it is possible to delete at most k edges so that the resulting graph has no connected component of more than h vertices, as this bounds the worst-case size of an epidemic. While even this special case of the problem is NP-complete in general (even when \(h=3\)), we provide evidence that many of the real-world networks of interest are likely to have small treewidth, and we describe an algorithm which solves the general problem in time \(2^{O(|\mathcal {F}|w^r)}n\) on an input graph having n vertices and whose treewidth is bounded by a fixed constant w, if each of the subgraphs we wish to avoid has at most r vertices. For the special case in which we wish only to ensure that no component has more than h vertices, we improve on this to give an algorithm running in time \(O((wh)^{2w}n)\), which we have implemented and tested on real datasets based on cattle movements."
journal_title,Algorithmica
article_title,Editorial: Special Issue on Computing and Combinatorics
keyword,[]
history,"['2018-05', '2018-02-26']"
abstract,None
journal_title,Algorithmica
article_title,Preface to the Special Issue on Theory of Genetic and Evolutionary Computation
keyword,[]
history,"['2018-05', '2017-10-03']"
abstract,None
journal_title,Algorithmica
article_title,Evaluation of Circuits Over Nilpotent and Polycyclic Groups
keyword,[]
history,"['2018-05', '2017-07-05', '2015-10-29', '2017-06-30']"
abstract,"Abstract We study the circuit evaluation problem (also known as the compressed word problem) for finitely generated linear groups. The best upper bound for this problem is coRP (the complements of problems in randomized polynomial time), which is shown by a reduction to polynomial identity testing for arithmetic circuits. Conversely, the compressed word problem for the linear group \({\mathsf {SL}}_3({\mathbb {Z}})\) is equivalent to polynomial identity testing. In the paper, we show that the compressed word problem for every finitely generated nilpotent group is in \({\mathsf {DET}} \subseteq {\mathsf {NC}}^2\). Within the larger class of polycyclic groups we find examples where the compressed word problem is at least as hard as polynomial identity testing for skew arithmetic circuits. It is a major open problem, whether polynomial identity testing for skew arithmetic circuits can be solved in polynomial time."
journal_title,Algorithmica
article_title,Static and Self-Adjusting Mutation Strengths for Multi-valued Decision Variables
keyword,"['Theory of randomized search heuristics\xa0', 'Runtime analysis\xa0', 'Genetic algorithms\xa0', 'Parameter choice\xa0', 'Parameter control\xa0']"
history,"['2018-05', '2017-07-05', '2016-10-18', '2017-06-26']"
abstract,"Abstract The most common representation in evolutionary computation are bit strings. With very little theoretical work existing on how to use evolutionary algorithms for decision variables taking more than two values, we study the run time of simple evolutionary algorithms on some OneMax-like functions defined over \(\varOmega = \{0, 1, \ldots , r-1\}^n\). We observe a crucial difference in how we extend the one-bit-flip and standard-bit mutation operators to the multi-valued domain. While it is natural to modify a random position of the string or select each position of the solution vector for modification independently with probability 1/n, there are various ways to then change such a position. If we change each selected position to a random value different from the original one, we obtain an expected run time of \(\varTheta (nr \log n)\). If we change each selected position by \(+1\) or \(-1\) (random choice), the optimization time reduces to \(\varTheta (nr + n\log n)\). If we use a random mutation strength \(i \in \{0,1,\ldots ,r-1\}\) with probability inversely proportional to i and change the selected position by \(+i\) or \(-i\) (random choice), then the optimization time becomes \(\varTheta (n \log (r)(\log n +\log r))\), which is asymptotically faster than the previous if \(r = \omega (\log (n) \log \log (n))\). Interestingly, a better expected performance can be achieved with a self-adjusting mutation strength that is based on the success of previous iterations. For the mutation operator that modifies a randomly chosen position, we show that the self-adjusting mutation strength yields an expected optimization time of \(\varTheta (n (\log n + \log r))\), which is best possible among all dynamic mutation strengths. In our proofs, we use a new multiplicative drift theorem for computing lower bounds, which is not restricted to processes that move only towards the target."
journal_title,Algorithmica
article_title,"Optimal Static and Self-Adjusting Parameter Choices for the $$(1+(\lambda ,\lambda ))$$(1+(λ,λ)) Genetic Algorithm"
keyword,"['Theory of randomized search heuristics\xa0', 'Runtime analysis\xa0', 'Genetic algorithms\xa0', 'Parameter choice\xa0', 'Parameter control\xa0']"
history,"['2018-05', '2017-08-07', '2016-10-24', '2017-06-27']"
abstract,"Abstract The \((1+(\lambda ,\lambda ))\) genetic algorithm proposed in Doerr et al. (Theor Comput Sci 567:87–104, 2015) is one of the few examples for which a super-constant speed-up of the expected optimization time through the use of crossover could be rigorously demonstrated. It was proven that the expected optimization time of this algorithm on OneMax is \(O(\max \{n \log (n) / \lambda , \lambda n\})\) for any offspring population size \(\lambda \in \{1,\ldots ,n\}\) (and the other parameters suitably dependent on \(\lambda \)) and it was shown experimentally that a self-adjusting choice of \(\lambda \) leads to a better, most likely linear, runtime. In this work, we study more precisely how the optimization time depends on the parameter choices, leading to the following results on how to optimally choose the population size, the mutation probability, and the crossover bias both in a static and a dynamic fashion. For the mutation probability and the crossover bias depending on \(\lambda \) as in Doerr et al. 
(2015), we improve the previous runtime bound to \(O(\max \{n \log (n) / \lambda , n \lambda \log \log (\lambda )/\log (\lambda )\})\). This expression is minimized by a value of \(\lambda \) slightly larger than what the previous result suggested and gives an expected optimization time of \(O\left( n \sqrt{\log (n) \log \log \log (n) / \log \log (n)}\right) \). We show that no static choice in the three-dimensional parameter space of offspring population, mutation probability, and crossover bias gives an asymptotically better runtime. We also prove that the self-adjusting parameter choice suggested in Doerr et al. 
(2015) outperforms all static choices and yields the conjectured linear expected runtime. This is asymptotically optimal among all possible parameter choices."
journal_title,Algorithmica
article_title,How to Escape Local Optima in Black Box Optimisation: When Non-elitism Outperforms Elitism
keyword,"['Evolutionary algorithms\xa0', 'Runtime analysis\xa0', 'Population genetics\xa0', 'Strong selection weak mutation regime\xa0', 'Metropolis algorithm\xa0', 'Simulated annealing\xa0', 'Black box optimisation\xa0']"
history,"['2018-05', '2017-09-06', '2016-10-14', '2017-08-19']"
abstract,"Abstract Escaping local optima is one of the major obstacles to function optimisation. Using the metaphor of a fitness landscape, local optima correspond to hills separated by fitness valleys that have to be overcome. We define a class of fitness valleys of tunable difficulty by considering their length, representing the Hamming path between the two optima and their depth, the drop in fitness. For this function class we present a runtime comparison between stochastic search algorithms using different search strategies. The (\(1+1\)) EA is a simple and well-studied evolutionary algorithm that has to jump across the valley to a point of higher fitness because it does not accept worsening moves (elitism). In contrast, the Metropolis algorithm and the Strong Selection Weak Mutation (SSWM) algorithm, a famous process in population genetics, are both able to cross the fitness valley by accepting worsening moves. We show that the runtime of the (\(1+1\)) EA depends critically on the length of the valley while the runtimes of the non-elitist algorithms depend crucially on the depth of the valley. Moreover, we show that both SSWM and Metropolis can also efficiently optimise a rugged function consisting of consecutive valleys."
journal_title,Algorithmica
article_title,Optimal Mutation Rates for the (1+$$\lambda $$λ) EA on OneMax Through Asymptotically Tight Drift Analysis
keyword,"['Runtime analysis\xa0', 'Populations\xa0', 'Mutation\xa0']"
history,"['2018-05', '2017-08-17', '2016-09-30', '2017-08-08']"
abstract,"Abstract We study the (1+\(\lambda \)) EA, a classical population-based evolutionary algorithm, with mutation probability c / n, where \(c>0\) and \(\lambda \) are constant, on the benchmark function OneMax, which counts the number of 1-bits in a bitstring. We improve a well-established result that allows to determine the first hitting time from the expected progress (drift) of a stochastic process, known as the variable drift theorem. Using our improved result, we show that upper and lower bounds on the expected runtime of the (1+\(\lambda \)) EA obtained from variable drift theorems are at most apart by a small lower order term if the exact drift is known. This reduces the analysis of expected optimization time to finding an exact expression for the drift. We then give an exact closed-form expression for the drift and develop a method to approximate it very efficiently, enabling us to determine approximate optimal mutation rates for the (1+\(\lambda \)) EA for various parameter settings of c and \(\lambda \) and also for moderate sizes of n. This makes the need for potentially lengthy and costly experiments in order to optimize c for fixed n and \(\lambda \) for the optimization of OneMax unnecessary. Interestingly, even for moderate n and not too small \(\lambda \) it turns out that mutation rates up to 10% larger than the asymptotically optimal rate 1 / n minimize the expected runtime. However, in absolute terms the expected runtime does not change by much when replacing 1 / n with the optimal mutation rate."
journal_title,Algorithmica
article_title,The $$(1+1)$$(1+1) Elitist Black-Box Complexity of LeadingOnes
keyword,"['Black-box complexity\xa0', 'Query complexity\xa0', 'LeadingOnes\xa0', 'Elitist algorithm\xa0', 'Memory restriction\xa0', 'Truncation selection\xa0', 'Evolutionary algorithms\xa0']"
history,"['2018-05', '2017-03-21', '2016-09-04', '2017-03-07']"
abstract,"Abstract One important goal of black-box complexity theory is the development of complexity models allowing to derive meaningful lower bounds for whole classes of randomized search heuristics. Complementing classical runtime analysis, black-box models help us to understand how algorithmic choices such as the population size, the variation operators, or the selection rules influence the optimization time. One example for such a result is the \(\varOmega (n \log n)\) lower bound for unary unbiased algorithms on functions with a unique global optimum (Lehre and Witt in Algorithmica 64:623–642, 2012), which tells us that higher arity operators or biased sampling strategies are needed when trying to beat this bound. In lack of analyzing techniques, such non-trivial lower bounds are very rare in the existing literature on black-box optimization and therefore remain to be one of the main challenges in black-box complexity theory. With this paper we contribute to our technical toolbox for lower bound computations by proposing a new type of information-theoretic argument. We regard the permutation- and bit-invariant version of LeadingOnes and prove that its \((1+1)\) elitist black-box complexity is \(\varOmega (n^2)\), a bound that is matched by \((1+1)\)-type evolutionary algorithms. The \((1+1)\) elitist complexity of LeadingOnes is thus considerably larger than its unrestricted one, which is known to be of order \(n\log \log n\) (Afshani et al. in Lecture notes in computer science, vol 8066, pp 1–11. Springer, New York, 2013). The \(\varOmega (n^2)\) lower bound does not rely on the fact that elitist black-box algorithms are not allowed to make use of absolute fitness values. In contrast, we show that even if absolute fitness values are revealed to the otherwise elitist algorithm, it cannot significantly profit from this additional information. Our result thus shows that for LeadingOnes the memory-restriction, together with the selection requirement, has a substantial impact on the best possible performance."
journal_title,Algorithmica
article_title,Sampling in Space Restricted Settings
keyword,[]
history,"['2018-05', '2017-06-14', '2015-11-01', '2017-06-09']"
abstract,"Abstract Space efficient algorithms play an important role in dealing with large amount of data. In such settings, one would like to analyze the large data using small amount of “working space”. One of the key steps in many algorithms for analyzing large data is to maintain a (or a small number) random sample from the data points. In this paper, we consider two space restricted settings—(i) the streaming model, where data arrives over time and one can use only a small amount of storage, and (ii) the query model, where we can structure the data in low space and answer sampling queries. In this paper, we prove the following results in the above two settings: In the streaming setting, we would like to maintain a random sample from the elements seen so far. We prove that one can maintain a random sample using \(O(\log n)\) random bits and \(O(\log n)\) bits of space, where n is the number of elements seen so far. We can extend this to the case when elements have weights as well.  In the query model, there are n elements with weights \(w_1, \ldots , w_n\) (which are w-bit integers) and one would like to sample a random element with probability proportional to its weight. Bringmann and Larsen (STOC 2013) showed how to sample such an element using \(nw +1 \) bits of space (whereas, the information theoretic lower bound is nw). We consider the approximate sampling problem, where we are given an error parameter \(\varepsilon \), and the sampling probability of an element can be off by an \(\varepsilon \) factor. We give matching upper and lower bounds for this problem. "
journal_title,Algorithmica
article_title,Towards Flexible Demands in Online Leasing Problems
keyword,"['Online algorithms\xa0', 'Leasing\xa0', 'Infrastructure problems\xa0', 'Parking permit problem\xa0', 'Deadlines\xa0', 'Set cover leasing\xa0', 'Facility leasing\xa0']"
history,"['2018-05', '2018-02-20', '2015-10-25', '2018-02-16']"
abstract,"Abstract We consider online leasing problems in which demands arrive over time and need to be served by leasing resources. We introduce a new model for these problems in which a resource can be leased for K different durations each incurring a different cost (longer leases cost less per time unit). Each demand i can be served any time between its arrival \(a_i\) and its deadline \(a_i + d_i\) by a leased resource. The objective is to meet all deadlines while minimizing the total leasing costs. This model is a natural generalization of Meyerson’s ParkingPermitProblem (in: Proceedings of the 46th annual IEEE symposium on foundations of computer science, FOCS ’05, IEEE Computer Society, Washington, pp 274–284, 2005) in which \(d_i=0\) for all i. We propose an online algorithm that is \(\varTheta (K + \frac{d_\textit{max}}{l_\textit{min}})\)-competitive, where \(d_\textit{max}\) and \(l_\textit{min}\) denote the largest \(d_i\) and the shortest available lease length, respectively. We also extend SetCoverLeasing and FacilityLeasing to their respective variants in which deadlines are added. For the former, we give an \(\mathcal {O}\left( \log (m \cdot (K + \frac{d_\textit{max}}{l_\textit{min}}))\log l_\textit{max} \right) \)-competitive randomized algorithm, where m represents the number of subsets and \(l_\textit{max}\) represents the largest available lease length. This improves on existing solutions for the original SetCoverLeasing problem. For the latter, we give an \(\mathcal {O}\left( (K + \frac{d_\textit{max}}{l_\textit{min}})\log l_{\text {max}} \right) \)-competitive deterministic algorithm."
journal_title,Algorithmica
article_title,A General Bin Packing Game: Interest Taken into Account
keyword,"['Game theory\xa0', 'Price of anarchy\xa0', 'Bin packing\xa0']"
history,"['2018-05', '2017-08-14', '2015-10-30', '2017-08-09']"
abstract,"Abstract In this paper we study a general bin packing game with an interest matrix, which is a generalization of all the currently known bin packing games. In this game, there are some items with positive sizes and identical bins with unit capacity as in the classical bin packing problem; additionally we are given an interest matrix with rational entries, whose element \(a_{ij}\) stands for how much item i likes item j. The payoff of item i is the sum of \({a_{ij}}\) over all items j in the same bin with item i, and each item wants to stay in a bin where it can fit and its payoff is maximized. We find that if the matrix is symmetric, a Nash Equilibrium (NE) always exists. However the Price of Anarchy (PoA) may be very large, therefore we consider several special cases and give bounds for PoA. We present some results for the asymmetric case, too. Moreover we introduce a new metric, called the Price of Harmony (PoH for short), which we think is more accurate to describe the quality of an NE in the new model."
journal_title,Algorithmica
article_title,Improved Approximation Algorithms for the Maximum Happy Vertices and Edges Problems
keyword,"['Maximum Happy Vertices\xa0', 'Maximum Happy Edges\xa0', 'Approximation algorithm\xa0', 'Randomized rounding\xa0', 'Network homophyly\xa0', '68W25\xa0', '90C27\xa0']"
history,"['2018-05', '2017-03-23', '2015-11-07', '2017-03-04']"
abstract,"Abstract The Maximum Happy Vertices (MHV) problem and the Maximum Happy Edges (MHE) problem are two fundamental problems arising in the study of the homophyly phenomenon in large scale networks. Both of these two problems are NP-hard. Interestingly, the MHE problem is a natural generalization of Multiway Uncut, the complement of the classic Multiway Cut problem. In this paper, we present new approximation algorithms for MHV and MHE based on randomized LP-rounding technique and non-uniform approach. Specifically, we show that MHV can be approximated within \(\frac{1}{\varDelta +1/g(\varDelta )}\), where \(\varDelta \) is the maximum vertex degree and \(g(\varDelta ) = (\sqrt{\varDelta } + \sqrt{\varDelta +1})^2 \varDelta \), and MHE can be approximated within \(\frac{1}{2} + \frac{\sqrt{2}}{4}f(k) \ge 0.8535\), where \(f(k) \ge 1\) is a function of the color number k. These results improve over the previous approximation ratios for MHV, MHE as well as Multiway Uncut in the literature."
journal_title,Algorithmica
article_title,The Impact of a Sparse Migration Topology on the Runtime of Island Models in Dynamic Optimization
keyword,"['Evolutionary algorithms\xa0', 'Island models\xa0', 'Dynamic problems\xa0', 'Populations\xa0', 'Runtime analysis\xa0']"
history,"['2018-05', '2017-09-20', '2016-10-14', '2017-09-15']"
abstract,"Abstract Island models denote a distributed system of evolutionary algorithms which operate independently, but occasionally share their solutions with each other along the so-called migration topology. We investigate the impact of the migration topology by introducing a simplified island model with behavior similar to \(\lambda \) islands optimizing the so-called Maze fitness function (Kötzing and Molter in Proceedings of parallel problem solving from nature (PPSN XII), Springer, Berlin, pp 113–122, 2012). Previous work has shown that when a complete migration topology is used, migration must not occur too frequently, nor too soon before the optimum changes, to track the optimum of the Maze function. We show that using a sparse migration topology alleviates these restrictions. More specifically, we prove that there exist choices of model parameters for which using a unidirectional ring of logarithmic diameter as the migration topology allows the model to track the oscillating optimum through n Maze-like phases with high probability, while using any graph of diameter less than \(c\ln n\) for some sufficiently small constant \(c>0\) results in the island model losing track of the optimum with overwhelming probability. Experimentally, we show that very frequent migration on a ring topology is not an effective diversity mechanism, while a lower migration rate allows the ring topology to track the optimum for a wider range of oscillation patterns. When migration occurs only rarely, we prove that dense migration topologies of small diameter may be advantageous. Combined, our results show that the sparse migration topology is able to track the optimum through a wider range of oscillation patterns, and cope with a wider range of migration frequencies."
journal_title,Algorithmica
article_title,An Algorithmic Framework for Labeling Network Maps
keyword,"['Labeling\xa0', 'Metro maps\xa0', 'Computational cartography\xa0', 'Dynamic programming\xa0', 'Integer linear programming\xa0', 'Experimental evaluation\xa0']"
history,"['2018-05', '2018-01-22', '2015-10-30', '2017-07-22']"
abstract,"Abstract Drawing network maps automatically comprises two challenging steps, namely laying out the map and placing non-overlapping labels. In this paper we tackle the problem of labeling an already existing network map considering the application of metro maps. We present a flexible and versatile labeling model that subsumes different labeling styles. We show that labeling a single line of the network is NP-hard, even if we make very restricting requirements about the labeling style that is used with this model. For a restricted variant of that model, we then introduce an efficient algorithm that optimally labels a single line with respect to a given cost function. Based on that algorithm, we present a general and sophisticated workflow for multiple metro lines, which is experimentally evaluated on real-world metro maps."
journal_title,Algorithmica
article_title,Editorial: Special Issue on Algorithms and Computation
keyword,[]
history,['2018-04-12']
abstract,None
journal_title,Algorithmica
article_title,Parameterized Algorithms for Max Colorable Induced Subgraph Problem on Perfect Graphs
keyword,"['Maximum induced subgraphs\xa0', 'Perfect graphs\xa0', 'Co-chordal graphs\xa0', 'Randomized FPT algorithms\xa0', 'Polynomial kernel lower bounds\xa0']"
history,"['2018-04-05', '2016-05-10', '2018-03-19']"
abstract,"Abstract We address the parameterized complexity of Max Colorable Induced Subgraph on perfect graphs. The problem asks for a maximum sized q-colorable induced subgraph of an input graph G. Yannakakis and Gavril (Inf Process Lett 24:133–137, 1987) showed that this problem is NP-complete even on split graphs if q is part of input, but gave an \(n^{O(q)}\) algorithm on chordal graphs. We first observe that the problem is W[2]-hard when parameterized by q, even on split graphs. However, when parameterized by \(\ell \), the number of vertices in the solution, we give two fixed-parameter tractable algorithms. The first algorithm runs in time \(5.44^{\ell } (n+t)^{{\mathcal {O}}(1)}\) where t is the number of maximal independent sets of the input graph.  The second algorithm runs in time \({\mathcal {O}}(6.75^{\ell + o(\ell )} n^{{\mathcal {O}}(1)})\) on graph classes where the maximum independent set of an induced subgraph can be found in polynomial time.  The first algorithm is efficient when the input graph contains only polynomially many maximal independent sets; for example split graphs and co-chordal graphs. Finally, we show that (under standard complexity-theoretic assumption) the problem does not admit a polynomial kernel on split and perfect graphs in the following sense:(a) On split graphs, we do not expect a polynomial kernel if q is a part of the input.  (b) On perfect graphs, we do not expect a polynomial kernel even for fixed values of \(q\ge 2\).  "
journal_title,Algorithmica
article_title,Editor’s Note: Special Issue Dedicated to the 60th Birthday of Gregory Gutin
keyword,[]
history,['2018-04-03']
abstract,None
journal_title,Algorithmica
article_title,A Simple Projection Algorithm for Linear Programming Problems
keyword,"['Linear programming\xa0', 'Zonotope\xa0', 'Projection\xa0', 'Binary search\xa0']"
history,"['2018-04-03', '2016-12-27', '2018-03-28']"
abstract,"Abstract Fujishige et al. propose the LP-Newton method, a new algorithm for linear programming problem (LP). They address LPs which have a lower and an upper bound for each variable, and reformulate the problem by introducing a related zonotope. The LP-Newton method repeats projections onto the zonotope by Wolfe’s algorithm. For the LP-Newton method, Fujishige et al. show that the algorithm terminates in a finite number of iterations. Furthermore, they show that if all the inputs are rational numbers, then the number of projections is bounded by a polynomial in L, where L is the input length of the problem. In this paper, we propose a modification to their algorithm using a binary search. In addition to its finiteness, if all the inputs are rational numbers and the optimal value is an integer, then the number of projections is bounded by \(L+1\), that is, a linear bound."
journal_title,Algorithmica
article_title,Network Pollution Games
keyword,"['Algorithmic mechanism design\xa0', 'Approximation algorithms\xa0', 'Planar graphs\xa0', 'Pollution control\xa0']"
history,"['2018-04-02', '2016-11-16', '2018-03-24']"
abstract,"Abstract The problem of pollution control has been mainly studied in the environmental economics literature where the methodology of game theory is applied for the pollution control. To the best of our knowledge this is the first time this problem is studied from the computational point of view. We introduce a new network model for pollution control and present two applications of this model. On a high level, our model comprises a graph whose nodes represent the agents, which can be thought of as the sources of pollution in the network. The edges between agents represent the effect of spread of pollution. The government who is the regulator, is responsible for the maximization of the social welfare and sets bounds on the levels of emitted pollution in both local areas as well as globally in the whole network. We first prove that the above optimization problem is NP-hard even on some special cases of graphs such as trees. We then turn our attention on the classes of trees and planar graphs which model realistic scenarios of the emitted pollution in water and air, respectively. We derive approximation algorithms for these two kinds of networks and provide deterministic truthful and truthful in expectation mechanisms. In some settings of the problem that we study, we achieve the best possible approximation results under standard complexity theoretic assumptions. Our approximation algorithm on planar graphs is obtained by a novel decomposition technique to deal with constraints on vertices. We note that no known planar decomposition techniques can be used here and our technique can be of independent interest. For trees we design a two level dynamic programming approach to obtain an FPTAS. This approach is crucial to deal with the global pollution quota constraint. It uses a special multiple choice, multi-dimensional knapsack problem where coefficients of all constraints except one are bounded by a polynomial of the input size. We furthermore derive truthful in expectation mechanisms on general networks with bounded degree."
journal_title,Algorithmica
article_title,From Discrepancy to Majority
keyword,"['Set discrepancy\xa0', 'Majority\xa0', 'Algorithms\xa0', 'Lower bounds\xa0', 'Query complexity\xa0']"
history,"['2018-04', '2017-03-16', '2016-07-28', '2017-03-07']"
abstract,"Abstract We show how to select an item with the majority color from n two-colored items, given access to the items only through an oracle that returns the discrepancy of subsets of k items (the absolute value of the difference between the numbers of items with each color). We use \(n/\lfloor \tfrac{k}{2}\rfloor +O(k)\) queries, improving a previous method by De Marco and Kranakis that used \(n-k+k^2/2\) queries. We also prove a lower bound of \(n/(k-1)-O (n^{1/3})\) on the number of queries needed, both for discrepancy queries and to queries that return the partition of items into monochromatic subsets. This improves a lower bound of \(\lfloor n/k\rfloor \) by De Marco and Kranakis."
journal_title,Algorithmica
article_title,Approximating the Generalized Minimum Manhattan Network Problem
keyword,"['Approximation algorithms\xa0', 'Computational geometry\xa0', 'Minimum Manhattan Network\xa0']"
history,"['2018-04', '2017-03-02', '2015-02-17', '2017-02-21']"
abstract,"Abstract We consider the generalized minimum Manhattan network problem (GMMN). The input to this problem is a set R of n pairs of terminals, which are points in \(\mathbb {R}^2\). The goal is to find a minimum-length rectilinear network that connects every pair in R by a Manhattan path, that is, a path of axis-parallel line segments whose total length equals the pair’s Manhattan distance. This problem is a natural generalization of the extensively studied minimum Manhattan network problem (MMN) in which R consists of all possible pairs of terminals. Another important special case is the well-known rectilinear Steiner arborescence problem (RSA). As a generalization of these problems, GMMN is NP-hard. No approximation algorithms are known for general GMMN. We obtain an \(O(\log n)\)-approximation algorithm for GMMN. Our solution is based on a stabbing technique, a novel way of attacking Manhattan network problems. Some parts of our algorithm generalize to higher dimensions, yielding a simple \(O(\log ^{d+1} n)\)-approximation algorithm for the problem in arbitrary fixed dimension d. As a corollary, we obtain an exponential improvement upon the previously best \(O(n^\varepsilon )\)-ratio for MMN in d dimensions (ESA 2011). En route, we show that an existing \(O(\log n)\)-approximation algorithm for 2D-RSA generalizes to higher dimensions."
journal_title,Algorithmica
article_title,Optimal Staged Self-Assembly of General Shapes
keyword,"['DNA computing\xa0', 'Biocomputing\xa0', 'Staging\xa0', '2HAM\xa0', 'Hierarchical\xa0']"
history,"['2018-04', '2017-05-04', '2016-09-13', '2017-04-25']"
abstract,"Abstract We analyze the number of tile types t, bins b, and stages necessary to assemble \(n \times n\) squares and scaled shapes in the staged tile assembly model. For \(n \times n\) squares, we prove \(\mathcal {O}\left( \frac{\log {n} - tb - t\log t}{b^2} + \frac{\log \log b}{\log t}\right) \) stages suffice and \(\varOmega \left( \frac{\log {n} - tb - t\log t}{b^2}\right) \) are necessary for almost all n. For shapes S with Kolmogorov complexity K(S), we prove \(\mathcal {O}\left( \frac{K(S) - tb - t\log t}{b^2} + \frac{\log \log b}{\log t}\right) \) stages suffice and \(\varOmega \left( \frac{K(S) - tb - t\log t}{b^2}\right) \) are necessary to assemble a scaled version of S, for almost all S. We obtain similarly tight bounds when the more powerful flexible glues are permitted."
journal_title,Algorithmica
article_title,Greedy Oriented Flows
keyword,"['Greedy algorithm\xa0', 'Regular matroid\xa0', 'Max flow\xa0', 'Cycle cancelling\xa0']"
history,"['2018-04', '2017-03-30', '2014-09-18', '2017-03-23']"
abstract,"Abstract We investigate the following greedy approach to attack linear programs of type \(\max \{1^{T} x\mid l\le Ax\le u\}\) where A has entries in \(\{-1,0,1\}\): The greedy algorithm starts with a feasible solution x and, iteratively, chooses an improving variable and raises it until some constraint becomes tight. In the special case, where A is the edge-path incidence matrix of some digraph \(G=(V,E)\), and \(l=0\), this greedy algorithm corresponds to the Ford–Fulkerson algorithm to solve the max ( s ,  t )-flow problem in G w.r.t. edge-capacities u. It is well-known that the Ford–Fulkerson algorithm always terminates with an optimal flow, and that the number of augmentations strongly depends on the choice of paths in each iteration. The Edmonds–Karp rule that prefers paths with fewer arcs leads to a running time of at most \(|E|^2\) augmentations. The paper investigates general types of matrices A and preference rules on the variables that make the greedy algorithm efficient. In this paper, we identify conditions that guarantee for the greedy algorithm not to cycle, and/or optimality of the greedy algorithm, and/or to yield a quadratic (in the number of rows) number of augmentations. We illustrate our approach with flow and circulation problems on regular oriented matroids."
journal_title,Algorithmica
article_title,An $$O(\log \mathrm {OPT})$$O(logOPT)-Approximation for Covering and Packing Minor Models of $$\theta _r$$θr
keyword,"['Erdős–Pósa property\xa0', 'Packings in graphs\xa0', 'Coverings in graphs\xa0', None, 'Approximation algorithms\xa0', 'Protrusion decomposition\xa0', '05C70\xa0']"
history,"['2018-04', '2017-04-28', '2015-10-26', '2017-04-12']"
abstract,"Abstract Given two graphs G and H, we define \(\mathsf{v}\hbox {-}\mathsf{cover}_{H}(G)\) (resp. \(\mathsf{e}\hbox {-}\mathsf{cover}_{H}(G)\)) as the minimum number of vertices (resp. edges) whose removal from G produces a graph without any minor isomorphic to H. Also \(\mathsf{v}\hbox {-}\mathsf{pack}_{H}(G)\) (resp. \(\mathsf{e}\hbox {-}\mathsf{pack}_{H}(G)\)) is the maximum number of vertex- (resp. edge-) disjoint subgraphs of G that contain a minor isomorphic to H. We denote by \(\theta _{r}\) the graph with two vertices and r parallel edges between them. When \(H=\theta _{r}\), the parameters \(\mathsf{v}\hbox {-}\mathsf{cover}_{H}\), \(\mathsf{e}\hbox {-}\mathsf{cover}_{H}\), \(\mathsf{v}\hbox {-}\mathsf{pack}_{H}\), and \(\mathsf{e}\hbox {-}\mathsf{pack}_{H}\) are NP-hard to compute (for sufficiently big values of r). Drawing upon combinatorial results in Chatzidimitriou et al. (Minors in graphs of large \(\theta _r\)-girth, 2015, arXiv:1510.03041), we give an algorithmic proof that if \(\mathsf{v}\hbox {-}\mathsf{pack}_{{\theta _{r}}}(G)\le k\), then \(\mathsf{v}\hbox {-}\mathsf{cover}_{\theta _{r}}(G) = O(k\log k)\), and similarly for \(\mathsf{e}\hbox {-}\mathsf{pack}_{\theta _{r}}\) and  \(\mathsf{e}\hbox {-}\mathsf{cover}_{\theta _{r}}\). In other words, the class of graphs containing \({\theta _{r}}\) as a minor has the vertex/edge Erdős–Pósa property, for every positive integer r. Using the algorithmic machinery of our proofs we introduce a unified approach for the design of an \(O(\log \mathrm{OPT})\)-approximation algorithm for \(\mathsf{v}\hbox {-}\mathsf{pack}_{{\theta _{r}}}\), \(\mathsf{v}\hbox {-}\mathsf{cover}_{{\theta _{r}}}\), \(\mathsf{e}\hbox {-}\mathsf{pack}_{{\theta _{r}}}\), and \(\mathsf{e}\hbox {-}\mathsf{cover}_{{\theta _{r}}}\) that runs in \(O(n\cdot \log (n)\cdot m)\) steps. Also, we derive several new Erdős–Pósa-type results from the techniques that we introduce."
journal_title,Algorithmica
article_title,"Simultaneous Embedding: Edge Orderings, Relative Positions, Cutvertices"
keyword,"['Simultaneous planarity\xa0', 'Efficient algorithm\xa0', 'Graph drawing\xa0']"
history,"['2018-04', '2017-03-15', '2015-06-24', '2017-03-03']"
abstract,"Abstract A simultaneous embedding (with fixed edges) of two graphs \(G^{\textcircled {1}}\) and \(G^{\textcircled {2}}\) with common graph \(G=G^{\textcircled {1}} \cap G^{\textcircled {2}}\) is a pair of planar drawings of \(G^{\textcircled {1}}\) and \(G^{\textcircled {2}}\) that coincide on G. It is an open question whether there is a polynomial-time algorithm that decides whether two graphs admit a simultaneous embedding (problem Sefe). In this paper, we present two results. First, a set of three linear-time preprocessing algorithms that remove certain substructures from a given Sefe instance, producing a set of equivalent Sefe instances without such substructures. The structures we can remove are (1) cutvertices of the union graph \(G^\cup = G^{\textcircled {1}} \cup G^{\textcircled {2}}\), (2) most separating pairs of \(G^\cup \), and (3) connected components of G that are biconnected but not a cycle. Second, we give an \(O(n^3)\)-time algorithm solving Sefe for instances with the following restriction. Let u be a pole of a P-node \(\mu \) in the SPQR-tree of a block of \(G^{\textcircled {1}}\) or \(G^{\textcircled {2}}\). Then at most three virtual edges of \(\mu \) may contain common edges incident to u. All algorithms extend to the sunflower case, i.e., to the case of more than two graphs pairwise intersecting in the same common graph."
journal_title,Algorithmica
article_title,How Unsplittable-Flow-Covering Helps Scheduling with Job-Dependent Cost Functions
keyword,"['Approximation algorithms\xa0', 'Scheduling\xa0', 'Job-dependent cost functions\xa0', 'Unsplittable flow\xa0', 'Approximation algorithms (68W25)\xa0']"
history,"['2018-04', '2017-03-17', '2016-05-11', '2017-03-03']"
abstract,"Abstract Generalizing many well-known and natural scheduling problems, scheduling with job-specific cost functions has gained a lot of attention recently. In this setting, each job incurs a cost depending on its completion time, given by a private cost function, and one seeks to schedule the jobs to minimize the total sum of these costs. The framework captures many important scheduling objectives such as weighted flow time or weighted tardiness. Still, the general case as well as the mentioned special cases are far from being very well understood yet, even for only one machine. Aiming for better general understanding of this problem, in this paper we focus on the case of uniform job release dates on one machine for which the state of the art is a 4-approximation algorithm. This is true even for a special case that is equivalent to the covering version of the well-studied and prominent unsplittable flow on a path problem, which is interesting in its own right. For that covering problem, we present a quasi-polynomial time \((1+\varepsilon )\)-approximation algorithm that yields an \((e+\varepsilon )\)-approximation for the above scheduling problem. Moreover, for the latter we devise the best possible resource augmentation result regarding speed: a polynomial time algorithm which computes a solution with optimal cost at \(1+\varepsilon \) speedup. Finally, we present an elegant QPTAS for the special case where the cost functions of the jobs fall into at most \(\log n\) many classes. This algorithm allows the jobs even to have up to \(\log n\) many distinct release dates. All proposed quasi-polynomial time algorithms require the input data to be quasi-polynomially bounded."
journal_title,Algorithmica
article_title,On the Efficiency of All-Pay Mechanisms
keyword,"['Nash equilibrium\xa0', 'Price of anarchy\xa0', 'All-pay auction\xa0']"
history,"['2018-04', '2017-03-17', '2016-05-21', '2017-02-20']"
abstract,"Abstract We study the inefficiency of mixed Nash equilibria, expressed as the price of anarchy, of all-pay auctions in three different environments: combinatorial, multi-unit and single-item auctions. First, we consider item-bidding combinatorial auctions where m all-pay auctions run in parallel, one for each good. For fractionally subadditive valuations, we strengthen the upper bound from 2 (Syrgkanis and Tardos in Proceedings of the 45th symposium on theory of computing (STOC ’13), 2013) to 1.82 by proving some structural properties that characterize the mixed Nash equilibria of the game. Next, we design an all-pay mechanism with a randomized allocation rule for the multi-unit auction. We show that, for bidders with submodular valuations, the mechanism admits a unique, \(75\%\) efficient, pure Nash equilibrium. The efficiency of this mechanism outperforms all the known bounds on the price of anarchy of mixed Nash equilibria in mechanisms used for multi-unit auctions. Finally, we analyze single-item all-pay auctions motivated by their connection to contests and show tight bounds on the price of anarchy with respect to social welfare, revenue and maximum bid."
journal_title,Algorithmica
article_title,Semi-Group Range Sum Revisited: Query-Space Lower Bound Tightened
keyword,"['Range sum queries\xa0', 'Semi-group\xa0', 'Lower bound\xa0', 'Length decomposition property\xa0']"
history,"['2018-04', '2017-04-03', '2015-08-16', '2017-03-24']"
abstract,"Abstract Let \(\mathcal {D}\) be a set of n elements \(e_1,\ldots , e_n\) drawn from a commutative semigroup. Given two integers x, y satisfying \(1 \le x \le y \le n\), a range sum query returns the sum of the \(y-x+1\) elements \(e_x\), \(e_{x+1}\),..., \(e_y\). The goal of indexing is to store \(\mathcal {D}\) in a data structure so that all such queries can be answered efficiently in the worst case. This paper proves a new lower bound in the semigroup model on the tradeoff between space and query time for the above problem. We show that, if the query time needs to be at most an integer t, a structure must use  Open image in new window space. The bound is asymptotically tight for every \(t \ge 2\), and is matched by an existing structure. Previously, the best lower bounds either had a substantially smaller non-linear factor (Yao in Space-time tradeoff for answering range queries (extended abstract). In: STOC, pp. 128–136, 1982), or were tight only for constant t (Alon and Schieber in Optimal preprocessing for answering on-line product queries. Technical Report TR 71/87, Tel-Aviv University, 1987). Our lower bound is asymptotically tight bidirectionally, namely, it also answers the following question: if the space needs to be bounded by an integer m, what is the best query time achievable? The techniques behind our lower bound are drastically different from those of Yao (Space-time tradeoff for answering range queries (extended abstract). In: STOC, pp. 128–136, 1982) and Alon and Schieber (Optimal preprocessing for answering on-line product queries. Technical Report TR 71/87, Tel-Aviv University, 1987), and reveal new insight on the characteristics of the problem."
journal_title,Algorithmica
article_title,An Improved Approximation Algorithm for Knapsack Median Using Sparsification
keyword,"['Approximation algorithm\xa0', 'Combinatorial optimization\xa0', 'Randomized algorithm\xa0', 'Facility-location problems\xa0']"
history,"['2018-04', '2018-01-29', '2015-08-31', '2017-02-20']"
abstract,"Abstract Knapsack median is a generalization of the classic k-median problem in which we replace the cardinality constraint with a knapsack constraint. It is currently known to be 32-approximable. We improve on the best known algorithms in several ways, including adding randomization and applying sparsification as a preprocessing step. The latter improvement produces the first LP for this problem with bounded integrality gap. The new algorithm obtains an approximation factor of 17.46. We also give a 3.05 approximation with small budget violation."
journal_title,Algorithmica
article_title,Estimating the Makespan of the Two-Valued Restricted Assignment Problem
keyword,"['Unrelated scheduling\xa0', 'Restricted assignment\xa0', 'Configuration LP\xa0', 'Integrality gap\xa0', 'Estimation algorithm\xa0']"
history,"['2018-04', '2017-04-27', '2016-09-20', '2017-04-12']"
abstract,"Abstract We consider a special case of the scheduling problem on unrelated machines, namely the restricted assignment problem with two different processing times. We show that the configuration LP has an integrality gap of at most \(\frac{5}{3} \approx 1.667\) for this problem. This allows us to estimate the optimal makespan within a factor of \(\frac{5}{3}\), improving upon the previously best known estimation algorithm with ratio \(\frac{11}{6} \approx 1.833\) due to Chakrabarty et al. (in: Proceedings of the twenty-sixth annual ACM-SIAM symposium on discrete algorithms (SODA 2015), pp 1087–1101, 2015)."
journal_title,Algorithmica
article_title,"Algorithms Parameterized by Vertex Cover and Modular Width, Through Potential Maximal Cliques"
keyword,"['Parametrized algorithms\xa0', 'Potential maximal cliques\xa0', 'Treewidth\xa0', 'Vertex cover\xa0']"
history,"['2018-04', '2017-02-27', '2016-05-26', '2017-02-20']"
abstract,"Abstract In this paper we give upper bounds on the number of minimal separators and potential maximal cliques of graphs w.r.t. two graph parameters, namely vertex cover (\({\text {vc}}\)) and modular width (\({\text {mw}}\)). We prove that for any graph, the number of its minimal separators is \({\mathcal {O}}^*(3^{{\text {vc}}})\) and \({\mathcal {O}}^*(1.6181^{{\text {mw}}})\), and the number of potential maximal cliques is \({\mathcal {O}}^*(4^{{\text {vc}}})\) and \({\mathcal {O}}^*(1.7347^{{\text {mw}}})\), and these objects can be listed within the same running times (The \({\mathcal {O}}^*\) notation suppresses polynomial factors in the size of the input). Combined with known applications of potential maximal cliques, we deduce that a large family of problems, e.g., Treewidth, Minimum Fill-in, Longest Induced Path, Feedback vertex set and many others, can be solved in time \({\mathcal {O}}^*(4^{{\text {vc}}})\) or \({\mathcal {O}}^*(1.7347^{{\text {mw}}})\). With slightly different techniques, we prove that the Treedepth problem can be also solved in single-exponential time, for both parameters."
journal_title,Algorithmica
article_title,The Fair OWA One-to-One Assignment Problem: NP-Hardness and Polynomial Time Special Cases
keyword,"['Assignment problem\xa0', 'Fairness\xa0', 'Ordered weighted average\xa0', 'Complexity\xa0']"
history,"['2018-03-30', '2017-09-14', '2018-03-23']"
abstract,"Abstract We consider a one-to-one assignment problem consisting of matching n objects with n agents. Any matching leads to a utility vector whose n components measure the satisfaction of the various agents. We want to find an assignment maximizing a global utility defined as an ordered weighted average (OWA) of the n individual utilities. OWA weights are assumed to be non-increasing with ranks of satisfaction so as to include an idea of fairness in the definition of social utility. We first prove that the problem is NP-hard; then we propose a polynomial algorithm under some restrictions on the set of admissible weight vectors, proving that the problem belongs to XP."
journal_title,Algorithmica
article_title,"On (1, $$\epsilon $$ϵ)-Restricted Max–Min Fair Allocation Problem"
keyword,"['Max–min fair allocation\xa0', 'Hypergraph matching\xa0', 'Integrality gap\xa0']"
history,"['2018-03-29', '2017-01-23', '2018-01-12']"
abstract,"Abstract We study the max–min fair allocation problem in which a set of m indivisible items are to be distributed among n agents such that the minimum utility among all agents is maximized. In the restricted setting, the utility of each item j on agent i is either 0 or some non-negative weight \(w_j\). For this setting, Asadpour et al. (ACM Trans Algorithms 8(3):24, 2012) showed that a certain configuration-LP can be used to estimate the optimal value to within a factor of \(4+\delta \), for any \(\delta >0\), which was recently extended by Annamalai et al. (in: Indyk (ed) Proceedings of the twenty-sixth annual ACMSIAM symposium on discrete algorithms, SODA 2015, San Diego, CA, USA, January 4–6, 2015) to give a polynomial-time 13-approximation algorithm for the problem. For hardness results, Bezáková and Dani (SIGecom Exch 5(3):11–18, 2005) showed that it is \(\mathsf {NP}\)-hard to approximate the problem within any ratio smaller than 2. In this paper we consider the \((1,\epsilon )\)-restricted max–min fair allocation problem in which each item j is either heavy \((w_j = 1)\) or light \((w_j = \epsilon )\), for some parameter \(\epsilon \in (0,1)\). We show that the \((1,\epsilon )\)-restricted case is also \(\mathsf {NP}\)-hard to approximate within any ratio smaller than 2. Using the configuration-LP, we are able to estimate the optimal value of the problem to within a factor of \(3+\delta \), for any \(\delta >0\). Extending this idea, we also obtain a quasi-polynomial time \((3+4\epsilon )\)-approximation algorithm and a polynomial time 9-approximation algorithm. Moreover, we show that as \(\epsilon \) tends to 0, the approximation ratio of our polynomial-time algorithm approaches \(3+2\sqrt{2}\approx 5.83\)."
journal_title,Algorithmica
article_title,Lift-and-Project Methods for Set Cover and Knapsack
keyword,"['Set cover\xa0', 'Sub-exponential algorithms\xa0', 'Approximation algorithms\xa0', 'Lift-and-project methods\xa0', 'Knapsack\xa0']"
history,"['2018-03-28', '2016-10-06', '2018-03-15']"
abstract,"Abstract We study the applicability of lift-and-project methods to the Set Cover and Knapsack problems. Inspired by recent work of Karlin et al. (IPCO 2011), who examined this connection for Knapsack, we consider the applicability and limitations of these methods for Set Cover, as well as extend the existing results for Knapsack. For the Set Cover problem, Cygan et al. (IPL 2009) gave sub-exponential-time approximation algorithms with approximation ratios better than \(\ln n\). We present a very simple combinatorial algorithm which has nearly the same time-approximation tradeoff as the algorithm of Cygan et al. We then adapt this to an LP-based algorithm using the LP hierarchy of Lovász and Schrijver. However, our approach involves the trick of “lifting the objective function”. We show that this trick is essential, by demonstrating an integrality gap of \((1-\varepsilon )\ln n\) at level \(\Omega (n)\) of the stronger LP hierarchy of Sherali and Adams (when the objective function is not lifted). Finally, we show that the SDP hierarchy of Lovász and Schrijver (\(\mathrm{LS}_+\)) reduces the integrality gap for Knapsack to \((1+\varepsilon )\) at level O(1). This stands in contrast to Set Cover (where the work of Aleknovich et al. (STOC 2005) rules out any improvement using \(\mathrm{LS}_+\)), and extends the work of Karlin et al., who demonstrated such an improvement only for the more powerful SDP hierarchy of Lasserre. Our \(\mathrm{LS}_+\)-based rounding and analysis are quite different from theirs (in particular, not relying on the decomposition theorem they prove for the Lasserre hierarchy), and to the best of our knowledge represents the first explicit demonstration of such a reduction in the integrality gap of \(\mathrm{LS}_+\) relaxations after a constant number of rounds."
journal_title,Algorithmica
article_title,On Almost Monge All Scores Matrices
keyword,"['Sequence alignment\xa0', 'Longest common subsequences\xa0', 'DIST matrices\xa0', 'Monge matrices\xa0', 'All path score computations\xa0', 'Multiple-source shortest-paths\xa0']"
history,"['2018-03-27', '2016-10-29', '2018-03-19']"
abstract,"Abstract The all scores matrix of a grid graph is a matrix containing the optimal scores of paths from every vertex on the first row of the graph to every vertex on its last row. This matrix is commonly used to solve diverse string comparison problems. All scores matrices have the Monge property, and this was exploited by previous works that used all scores matrices for solving various problems. In this paper, we study an extension of grid graphs that contain an additional set of edges, called bridges. Our main result is to show several properties of the all scores matrices of such graphs. We also apply these properties to obtain an \(O(r(nm+n^2))\) time algorithm for constructing the all scores matrix of an \(m\times n\) grid graph with r bridges and bounded integer weights."
journal_title,Algorithmica
article_title,New Online Algorithms for Story Scheduling in Web Advertising
keyword,"['Storyboarding\xa0', 'Competitive analysis\xa0', 'One ad position\xa0', 'Multiple ad positions\xa0']"
history,"['2018-03-22', '2016-12-13', '2018-03-15']"
abstract,"Abstract We study storyboarding where advertisers wish to present sequences of ads (stories) uninterruptedly on a major ad position of a web page. These jobs/stories arrive online and are triggered by the browsing history of a user who at any time continues surfing with probability \(\beta \). The goal of an ad server is to construct a schedule maximizing the expected reward. The problem was introduced by Dasgupta, Ghosh, Nazerzadeh and Raghavan (SODA’09) who presented a 7-competitive online algorithm. They also showed that no deterministic online strategy can achieve a competitiveness smaller than 2, for general \(\beta \). We present improved algorithms for storyboarding. First we give a simple online strategy that achieves a competitive ratio of \(4/(2-\beta )\), which is upper bounded by 4 for any \(\beta \). The algorithm is also \(1/(1-\beta )\)-competitive, which gives better bounds for small \(\beta \). As the main result of this paper we devise a refined algorithm that attains a competitive ratio of \(c=1+\phi \), where \(\phi =(1+\sqrt{5})/2\) is the Golden Ratio. This performance guarantee of \(c\approx 2.618\) is close to the lower bound of 2. Additionally, we study for the first time a problem extension where stories may be presented simultaneously on several ad positions of a web page. For this parallel setting we provide an algorithm whose competitive ratio is upper bounded by \(1/(3-2\sqrt{2})\approx 5.828\), for any \(\beta \). All our algorithms work in phases and have to make scheduling decisions only every once in a while."
journal_title,Algorithmica
article_title,Counting Minimum Weight Arborescences
keyword,"['Minimum weight arborescence\xa0', 'Matrix tree theorem\xa0', 'Counting\xa0']"
history,"['2018-03-22', '2017-06-17', '2018-03-13']"
abstract,"Abstract In a directed graph \(D = (V, A)\) with a specified vertex \(r \in V\), an arc subset \(B \subseteq A\) is called an r-arborescence if B has no arc entering r and there is a unique path from r to v in (V, B) for each \(v \in V \backslash \{ r \}\). The problem of finding a minimum weight r-arborescence in a weighted digraph has been studied for decades starting with Chu and Liu (Sci Sin 14:1396–1400, 1965), Edmonds (J Res Natl Bur Stand 71B:233–240, 1967) and Bock (Developments in operations research, Gordon and Breach, New York, pp 29–44, 1971). In this paper, we focus on the number of minimum weight arborescences. We present an algorithm for counting minimum weight r-arborescences in \(O(n^{\omega })\) time, where n is the number of vertices of an input digraph and \(\omega \) is the matrix multiplication exponent."
journal_title,Algorithmica
article_title,Guarding Orthogonal Art Galleries with Sliding k-Transmitters: Hardness and Approximation
keyword,"['Art gallery problem\xa0', None, None]"
history,"['2018-03-22', '2017-02-06', '2018-03-19']"
abstract,"Abstract A sliding k-transmitter inside an orthogonal polygon P, for a fixed \(k\ge 0\), is a point guard that travels along an axis-parallel line segment s in P. The sliding k-transmitter can see a point \(p\in P\) if the perpendicular from p onto s intersects the boundary of P in at most k points. In the Minimum Sliding k-Transmitters (\({\hbox {ST}}_k\)) problem, the objective is to guard P with the minimum number of sliding k-transmitters. In this paper, we give a constant-factor approximation algorithm for the \({\hbox {ST}}_k\) problem on P for any fixed \(k\ge 0\). Moreover, we show that the \({\hbox {ST}}_0\) problem is NP-hard on orthogonal polygons with holes even if only horizontal sliding 0-transmitters are allowed. For \(k>0\), the problem is NP-hard even in the extremely restricted case where P is simple and monotone. Finally, we study art gallery theorems; i.e., we give upper and lower bounds on the number of sliding transmitters required to guard P relative to the number of vertices of P."
journal_title,Algorithmica
article_title,Correction to: Trading Off Worst and Expected Cost in Decision Tree Problems
keyword,[]
history,"['2018-03-20', '2017-10-11', '2018-02-26']"
abstract,None
journal_title,Algorithmica
article_title,Fast A p proximation Algorithms for p-Centers in Large $$\delta $$δ-Hy perbolic Gra phs
keyword,"['p-centers\xa0', 'Clustering\xa0', 'Delta-hyperbolicity\xa0']"
history,"['2018-03-20', '2017-02-24', '2018-03-08']"
abstract,"Abstract We provide a quasilinear time algorithm for the p-center problem with an additive error less than or equal to 3 times the input graph’s hyperbolic constant. Specifically, for the graph \(G=(V,E)\) with n vertices, m edges and hyperbolic constant \(\delta \), we construct an algorithm for p-centers in time \(O(p(\delta +1)(n+m)\log (n))\) with radius not exceeding \(r_p + \delta \) when \(p \le 2\) and \(r_p + 3\delta \) when \(p \ge 3\), where \(r_p\) are the optimal radii. Prior work identified p-centers with accuracy \(r_p+\delta \) but with time complexity \(O((n^3\log n + n^2m)\log ({{\mathrm{diam}}}(G)))\) which is impractical for large graphs."
journal_title,Algorithmica
article_title,Sorting by Swaps with Noisy Comparisons
keyword,"['Sorting\xa0', 'Random swaps\xa0', 'Evolutionary algorithms\xa0', 'Comparison-based\xa0', 'Noise\xa0', 'Optimization heuristics\xa0']"
history,"['2018-03-19', '2017-06-08', '2018-03-15']"
abstract,"Abstract We study sorting of permutations by random swaps if each comparison gives the wrong result with some fixed probability \(p<1/2\). We use this process as prototype for the behaviour of randomized, comparison-based optimization heuristics in the presence of noisy comparisons. As quality measure, we compute the expected fitness of the stationary distribution. To measure the runtime, we compute the minimal number of steps after which the average fitness approximates the expected fitness of the stationary distribution. We study the process where in each round a random pair of elements at distance at most r are compared. We give theoretical results for the extreme cases \(r=1\) and \(r=n\), and experimental results for the intermediate cases. We find a trade-off between faster convergence (for large r) and better quality of the solution after convergence (for small r)."
journal_title,Algorithmica
article_title,Cutwidth: Obstructions and Algorithmic Aspects
keyword,"['Cutwidth\xa0', 'Obstructions\xa0', 'Immersions\xa0', 'Fixed-parameter tractability\xa0']"
history,"['2018-03-15', '2017-04-13', '2018-03-02']"
abstract,"Abstract Cutwidth is one of the classic layout parameters for graphs. It measures how well one can order the vertices of a graph in a linear manner, so that the maximum number of edges between any prefix and its complement suffix is minimized. As graphs of cutwidth at most k are closed under taking immersions, the results of Robertson and Seymour imply that there is a finite list of minimal immersion obstructions for admitting a cut layout of width at most k. We prove that every minimal immersion obstruction for cutwidth at most k has size at most \(2^{{O}(k^3\log k)}\). As an interesting algorithmic byproduct, we design a new fixed-parameter algorithm for computing the cutwidth of a graph that runs in time \(2^{{O}(k^2\log k)}\cdot n\), where k is the optimum width and n is the number of vertices. While being slower by a \(\log k\)-factor in the exponent than the fastest known algorithm, given by Thilikos et al. (J Algorithms 56(1):1–24, 2005; J Algorithms 56(1):25–49, 2005), our algorithm has the advantage of being simpler and self-contained; arguably, it explains better the combinatorics of optimum-width layouts."
journal_title,Algorithmica
article_title,Online Packet Scheduling for CIOQ and Buffered Crossbar Switches
keyword,"['Online algorithms\xa0', 'Competitive analysis\xa0', 'Scheduling\xa0', 'Buffer management\xa0', 'CIOQ switches\xa0', 'Buffered crossbar switches\xa0']"
history,"['2018-03-05', '2017-04-17', '2018-02-16']"
abstract,"Abstract We consider the problem of online packet scheduling in Combined Input and Output Queued (CIOQ) and buffered crossbar switches. In the widely used CIOQ switches, packet buffers (queues) are placed at both input and output ports. An \(N \times N\) CIOQ switch has N input ports and N output ports, where each input port is equipped with N queues, each of which corresponds to an output port, and each output port is equipped with only one queue. In each time slot, arbitrarily many packets may arrive at each input port, and only one packet can be transmitted from each output port. Packets are transferred from the queues of input ports to the queues of output ports through the internal fabric. Buffered crossbar switches follow a similar design, but are equipped with additional buffers in their internal fabric. In either model, our goal is to maximize the number or, in case the packets have weights, the total weight of transmitted packets. Our main objective is to devise online algorithms that are both competitive and efficient. We improve the previously known results for both switch models, both for unweighted and weighted packets. For unweighted packets, Kesselman and Rosén (J. Algorithms 60(1):60–83, 2006) give an online algorithm that is 3-competitive for CIOQ switches. We give a faster, more practical algorithm achieving the same competitive ratio. In the buffered crossbar model, we also show 3-competitiveness, improving the previously known ratio of 4. For weighted packets, we give 5.83- and 14.83-competitive algorithms with an elegant analysis for CIOQ and buffered crossbar switches, respectively. This improves upon the previously known ratios of 6 and 16.24."
journal_title,Algorithmica
article_title,Guest Editorial: Special Issue on Theoretical Informatics
keyword,[]
history,"['2018-03', '2017-11-13']"
abstract,None
journal_title,Algorithmica
article_title,Tree Compression Using String Grammars
keyword,"['Grammar-based compression\xa0', 'Tree compression\xa0', 'Expression evaluation\xa0']"
history,"['2018-03', '2017-02-06', '2016-06-30', '2017-01-13']"
abstract,"Abstract We study the compressed representation of a ranked tree by a (string) straight-line program (SLP) for its preorder traversal, and compare it with the well-studied representation by straight-line context free tree grammars (which are also known as tree straight-line programs or TSLPs). Although SLPs may be exponentially more succinct than TSLPs, we show that many simple tree queries can still be performed efficiently on SLPs, such as computing the height of a tree, tree navigation, or evaluation of Boolean expressions. Other problems on tree traversals turn out to be intractable, e.g. pattern matching and evaluation of tree automata. These problems can be still solved in polynomial time for TSLPs."
journal_title,Algorithmica
article_title,Independent Set of Convex Polygons: From $$n^{\epsilon }$$nϵ to $$1+\epsilon $$1+ϵ via Shrinking
keyword,"['Approximation algorithms\xa0', 'Independent Set\xa0', 'Geometric Intersection Graphs\xa0', 'PTAS\xa0', 'Shrinking\xa0', 'Resource augmentation\xa0', 'Convex Polygons\xa0']"
history,"['2018-03', '2017-07-19', '2016-06-30', '2017-07-09']"
abstract,"Abstract In the Independent Set of Convex Polygons problem we are given a set of weighted convex polygons in the plane and we want to compute a maximum weight subset of non-overlapping polygons. This is a very natural and well-studied problem with applications in many different areas. Unfortunately, there is a very large gap between the known upper and lower bounds for this problem. The best polynomial time algorithm we know has an approximation ratio of \(n^{\epsilon }\) and the best known lower bound shows only strong \({\mathsf {NP}}\)-hardness. In this paper we close this gap, assuming that we are allowed to shrink the polygons a little bit, by a factor \(1-\delta \) for an arbitrarily small constant \(\delta >0\), while the compared optimal solution cannot do this (resource augmentation). In this setting, we improve the approximation ratio of \(n^{\epsilon }\) to \((1+\epsilon )\) which matches the above lower bound that still holds if we can shrink the polygons."
journal_title,Algorithmica
article_title,On the Planar Split Thickness of Graphs
keyword,"['Planarity\xa0', 'Splittable\xa0', 'Thickness\xa0', 'Graph drawing\xa0', 'Graph theory\xa0', 'Complete graphs\xa0', 'Genus-1 graphs\xa0', 'NP-hardness\xa0', 'Approximation\xa0', 'Fixed-parameter tractable\xa0']"
history,"['2018-03', '2017-06-02', '2016-06-30', '2017-05-25']"
abstract,"Abstract Motivated by applications in graph drawing and information visualization, we examine the planar split thickness of a graph, that is, the smallest k such that the graph is k-splittable into a planar graph. A k-split operation substitutes a vertex v by at most k new vertices such that each neighbor of v is connected to at least one of the new vertices. We first examine the planar split thickness of complete graphs, complete bipartite graphs, multipartite graphs, bounded degree graphs, and genus-1 graphs. We then prove that it is NP-hard to recognize graphs that are 2-splittable into a planar graph, and show that one can approximate the planar split thickness of a graph within a constant factor. If the treewidth is bounded, then we can even verify k-splittability in linear time, for a constant k."
journal_title,Algorithmica
article_title,Comparison-Based Buffer Management in QoS Switches
keyword,"['Online algorithms\xa0', 'Competitive analysis\xa0', 'Network switches\xa0', 'Buffer management\xa0', 'Quality of service\xa0', 'Comparison-based\xa0']"
history,"['2018-03', '2017-11-04', '2016-07-11', '2017-10-18']"
abstract,"Abstract The following online problem arises in network devices, e.g., switches, with quality of service (QoS) guarantees. In each time step, an arbitrary number of packets arrive at a single buffer and only one packet can be transmitted. The differentiated service concept is implemented by attributing each packet with a non-negative value corresponding to its service level. The goal is to maximize the total value of transmitted packets. We consider two models of this problem, the FIFO and the bounded-delay model. In the FIFO model, the buffer can store a limited number of packets and the sequence of transmitted packets has to be a subsequence of the arriving packets. In this model, a buffer management algorithm can reject arriving packets and preempt buffered packets. In the bounded-delay model, the buffer has unbounded capacity, but each packet has a deadline and packets can only be transmitted before their deadlines. Here, a buffer management algorithm determines the packet to be sent in each time step. We study comparison-based buffer management algorithms, i.e., algorithms that make their decisions based solely on the relative order between packet values with no regard to the actual values. This kind of algorithm proves to be robust in the realm of QoS switches. Kesselman et al. (SIAM J Comput 33(3):563–583, 2004) present two deterministic comparison-based online algorithms, one for each model, which are 2-competitive. For a long time, it has been an open problem, whether a comparison-based online algorithm exists, in either model, with a competitive ratio below 2. In the FIFO model, we present a lower bound of \(1+1/\sqrt{2} \approx 1.707\) on the competitive ratio of any deterministic comparison-based algorithm and give an algorithm that matches this lower bound in the case of monotonic sequences, i.e., packets arrive in a non-decreasing order according to their values. In the bounded-delay model, we show that no deterministic comparison-based algorithm exists with a competitive ratio below 2. In the special s-uniform case, where the difference between the arrival time and deadline of any packet equals s, we present a randomized comparison-based algorithm that is 5 / 3-competitive."
journal_title,Algorithmica
article_title,Improved Approximation Algorithms for Capacitated Fault-Tolerant k-Center
keyword,"['Capacitated k-center\xa0', 'Fault tolerance\xa0', 'Approximation algorithm\xa0', 'Non-uniform capacities\xa0', 'Linear Programming\xa0', 'LP rounding\xa0']"
history,"['2018-03', '2017-11-29', '2016-08-04', '2017-11-18']"
abstract,"Abstract In the \(k\)-center problem, given a metric space V and a positive integer k, one wants to select k elements (centers) of V and an assignment from V to centers, minimizing the maximum distance between an element of V and its assigned center. One of the most general variants is the capacitated \(\alpha \)-fault-tolerant k-center, where centers have a limit on the number of assigned elements, and, if any \(\alpha \) centers fail, there is a reassignment from V to non-faulty centers. In this paper, we present a new approach to tackle fault tolerance, by selecting and pre-opening a set of backup centers, then solving the obtained residual instance. For the \(\{0,L\}\)-capacitated case, we give approximations with factor 6 for the basic problem, and 7 for the so called conservative variant, when only clients whose centers failed may be reassigned. Our algorithms improve on the best previously known factors of 9 and 17, respectively. Moreover, we consider the case with general capacities. Assuming \(\alpha \) is constant, our method leads to the first approximations for this case. We also derive approximations for the capacitated fault-tolerant k-supplier problem."
journal_title,Algorithmica
article_title,Stabbing Circles for Sets of Segments in the Plane
keyword,"['Stabbing circle\xa0', 'Stabbing line segments\xa0', 'Voronoi diagram\xa0', 'Cluster Voronoi diagrams\xa0', 'Hausdorff Voronoi diagram\xa0', 'Farthest-color Voronoi diagram\xa0']"
history,"['2018-03', '2017-03-13', '2016-07-22', '2017-02-27']"
abstract,"Abstract Stabbing a set S of n segments in the plane by a line is a well-known problem. In this paper we consider the variation where the stabbing object is a circle instead of a line. We show that the problem is tightly connected to two cluster Voronoi diagrams, in particular, the Hausdorff and the farthest-color Voronoi diagram. Based on these diagrams, we provide a method to compute a representation of all the combinatorially different stabbing circles for S, and the stabbing circles with maximum and minimum radius. We give conditions under which our method is fast. These conditions are satisfied if the segments in S are parallel, resulting in a \(O(n \log ^2{n})\) time and O(n) space algorithm. We also observe that the stabbing circle problem for S can be solved in worst-case optimal \(O(n^2)\) time and space by reducing the problem to computing the stabbing planes for a set of segments in 3D. Finally we show that the problem of computing the stabbing circle of minimum radius for a set of n parallel segments of equal length has an \(\varOmega (n \log n)\) lower bound."
journal_title,Algorithmica
article_title,Improved Spanning Ratio for Low Degree Plane Spanners
keyword,"['Computational geometry\xa0', 'Graphs\xa0', 'Graph theory\xa0', 'Plane\xa0', 'Spanners\xa0', 'Spanning graph\xa0', 'Spanning ratio\xa0', 'Degree\xa0', 'Bounded degree\xa0']"
history,"['2018-03', '2017-03-20', '2016-06-30', '2017-03-13']"
abstract,Abstract We describe an algorithm that builds a plane spanner with a maximum degree of 8 and a spanning ratio of \({\approx }4.414\) with respect to the complete graph. This is the best currently known spanning ratio for a plane spanner with a maximum degree of less than 14.
journal_title,Algorithmica
article_title,Simple Approximation Algorithms for Balanced MAX 2SAT
keyword,"['Maximum satisfiability\xa0', 'Approximation algorithm\xa0', 'Greedy algorithm\xa0', 'Spectral algorithm\xa0', 'Balanced instances\xa0', 'Priority algorithm\xa0']"
history,"['2018-03', '2017-04-21', '2016-06-29', '2017-04-11']"
abstract,"Abstract We study simple algorithms for the balanced MAX 2SAT problem, where we are given weighted clauses of length one and two with the property that for each variable x the total weight of clauses that x appears in equals the total weight of clauses for \(\overline{x}\). We show that such instances have a simple structural property in that any optimal solution can satisfy at most the total weight of the clauses minus half the total weight of the unit clauses. Using this property and a novel analysis of the computation tree, we are able to show that a large class of greedy algorithms, including Johnson’s algorithm, gives a \(\frac{3}{4}\)-approximation algorithm for balanced MAX 2SAT; a similar statement is false for general MAX 2SAT instances. We further give a spectral 0.81-approximation algorithm for balanced MAX E2SAT instances (in which each clause has exactly 2 literals) by a reduction to a spectral algorithm of Trevisan for the maximum colored cut problem. We provide experimental results showing that this spectral algorithm performs well and is slightly better than Johnson’s algorithm and the Goemans–Williamson semidefinite programming algorithm on balanced MAX E2SAT instances."
journal_title,Algorithmica
article_title,Routing in Unit Disk Graphs
keyword,"['Routing scheme\xa0', 'Unit disk graph\xa0', 'Well-separated pair decomposition\xa0']"
history,"['2018-03', '2017-03-30', '2016-08-05', '2017-03-24']"
abstract,"Abstract Let \(S \subset \mathbb {R}^2\) be a set of n sites. The unit disk graph \({{\mathrm{UD}}}(S)\) on S has vertex set S and an edge between two distinct sites \(s,t \in S\) if and only if s and t have Euclidean distance \(|st| \le 1\). A routing scheme R for \({{\mathrm{UD}}}(S)\) assigns to each site \(s \in S\) a label \(\ell (s)\) and a routing table \(\rho (s)\). For any two sites \(s, t \in S\), the scheme R must be able to route a packet from s to t in the following way: given a current site r (initially, \(r = s\)), a header h (initially empty), and the label \(\ell (t)\) of the target, the scheme R consults the routing table \(\rho (r)\) to compute a neighbor \(r'\) of r, a new header \(h'\), and the label \(\ell (t')\) of an intermediate target \(t'\). (The label of the original target may be stored at the header \(h'\).) The packet is then routed to \(r'\), and the procedure is repeated until the packet reaches t. The resulting sequence of sites is called the routing path. The stretch of R is the maximum ratio of the (Euclidean) length of the routing path produced by R and the shortest path in \({{\mathrm{UD}}}(S)\), over all pairs of distinct sites in S. For any given \(\varepsilon > 0\), we show how to construct a routing scheme for \({{\mathrm{UD}}}(S)\) with stretch \(1+\varepsilon \) using labels of \(O(\log n)\) bits and routing tables of \(O(\varepsilon ^{-5}\log ^2 n \log ^2 D)\) bits, where D is the (Euclidean) diameter of \({{\mathrm{UD}}}(S)\). The header size is \(O(\log n \log D)\) bits."
journal_title,Algorithmica
article_title,Faster Information Gathering in Ad-Hoc Radio Tree Networks
keyword,[]
history,"['2018-03', '2017-06-20', '2016-06-28', '2017-06-10']"
abstract,"Abstract We study information gathering in ad-hoc radio networks. Initially, each node of the network has a piece of information called a rumor, and the overall objective is to gather all these rumors in the designated target node. The ad-hoc property refers to the fact that the topology of the network is unknown when the computation starts. Aggregation of rumors is not allowed, which means that each node may transmit at most one rumor in one step. We focus on networks with tree topologies, that is we assume that the network is a tree with all edges directed towards the root, but, being ad-hoc, its actual topology is not known. We provide two deterministic algorithms for this problem. For the model that does not assume any collision detection nor acknowledgement mechanisms, we give an \(O(n\log \log n)\)-time algorithm, improving the previous upper bound of \(O(n\log n)\). We then show that this running time can be reduced to O(n), which is asymptotically optimal, if the model allows for acknowledgements of successful transmissions."
journal_title,Algorithmica
article_title,Structural Parameterizations of Undirected Feedback Vertex Set: FPT Algorithms and Kernelization
keyword,"['Parameterized complexity\xa0', 'Kernelization\xa0', 'Feedback vertex set\xa0', 'Structural parameterization\xa0', None]"
history,"['2018-02-26', '2017-03-30', '2018-02-12']"
abstract,"Abstract A feedback vertex set in an undirected graph is a subset of vertices whose removal results in an acyclic graph. We consider the parameterized and kernelization complexity of feedback vertex set where the parameter is the size of some structure in the input. In particular, we consider parameterizations where the parameter is (instead of the solution size), the distance to a class of graphs where the problem is polynomial time solvable, and sometimes smaller than the solution size. Here, by distance to a class of graphs, we mean the minimum number of vertices whose removal results in a graph in the class. Such a set of vertices is also called the ‘deletion set’. In this paper, we show that FVS is fixed-parameter tractable by an \({{\mathcal {O}}}(2^k n^{{{\mathcal {O}}}(1)})\) time algorithm, but is unlikely to have polynomial kernel when parameterized by the number of vertices of the graph whose degree is at least 4. This answers a question asked in an earlier paper. We also show that an algorithm with running time \({{\mathcal {O}}}((\sqrt{2} - \epsilon )^k n^{{{\mathcal {O}}}(1)})\) is not possible unless SETH fails.  When parameterized by k, the number of vertices, whose deletion results in a split graph, we give an \({{\mathcal {O}}}(3.148^k n^{{{\mathcal {O}}}(1)})\) time algorithm.  When parameterized by k, the number of vertices whose deletion results in a cluster graph (a disjoint union of cliques), we give an \({{\mathcal {O}}}(5^k n^{{{\mathcal {O}}}(1)})\) algorithm.  Regarding kernelization results, we show that When parameterized by k, the number of vertices, whose deletion results in a pseudo-forest, FVS has an \({{\mathcal {O}}}(k^7)\) vertices kernel improving from the previously known \({{\mathcal {O}}}(k^{10})\) bound.  When parameterized by the number k of vertices, whose deletion results in a mock-d-forest, we give a kernel with \({{\mathcal {O}}}(k^{3d+3})\) vertices. We also prove a lower bound of \(\varOmega (k^{d+2})\) size (under complexity theoretic assumptions). Mock-forest is a graph where each vertex is contained in at most one cycle. Mock-d-forest for a constant d is a mock-forest where each component has at most d cycles. "
journal_title,Algorithmica
article_title,"$$(k,n-k)$$(k,n-k)- Max- Cut: An $$\mathcal{O}^*(2^p)$$O∗(2p)-Time Algorithm and a Polynomial Kernel"
keyword,"['Max-Cut\xa0', 'Parameterized algorithm\xa0', 'Kernel\xa0', 'Bounded search tree\xa0']"
history,"['2018-02-20', '2016-03-15', '2018-02-09']"
abstract,"Abstract Max-Cut is a well-known classical NP-hard problem. This problem asks whether the vertex-set of a given graph \(G=(V,E)\) can be partitioned into two disjoint subsets, A and B, such that there exist at least p edges with one endpoint in A and the other endpoint in B. It is well known that if \(p\le |E|/2\), the answer is necessarily positive. A widely-studied variant of particular interest to parameterized complexity, called \((k,n-k)\)-Max-Cut, restricts the size of the subset A to be exactly k. For the \((k,n-k)\)-Max-Cut problem, we obtain an \(\mathcal{O}^*(2^p)\)-time algorithm, improving upon the previous best \(\mathcal{O}^*(4^{p+o(p)})\)-time algorithm, as well as the first polynomial kernel. Our algorithm relies on a delicate combination of methods and notions, including independent sets, depth-search trees, bounded search trees, dynamic programming and treewidth, while our kernel relies on examination of the closed neighborhood of the neighborhood of a certain independent set of the graph G."
journal_title,Algorithmica
article_title,Approximation Schemes for Minimizing the Maximum Lateness on a Single Machine with Release Times Under Non-availability or Deadline Constraints
keyword,"['Single machine scheduling\xa0', 'Release times\xa0', 'Lateness\xa0', 'Deadlines\xa0', 'Approximation algorithms\xa0']"
history,"['2018-02-20', '2017-04-12', '2018-02-07']"
abstract,"Abstract In this paper, we consider four single-machine scheduling problems with release times, with the aim of minimizing the maximum lateness. In the first problem we have a common deadline for all the jobs. The second problem looks for the Pareto frontier with respect to the two objective functions maximum lateness and makespan. The third problem is associated with a non-availability constraint. In the fourth one, the non-availability interval is related to the operator who is organizing the execution of jobs on the machine (no job can start, and neither can complete during the operator non-availability period). For each of the four problems, we establish the existence of a polynomial time approximation scheme."
journal_title,Algorithmica
article_title,Path Refinement in Weighted Regions
keyword,"['Computational geometry\xa0', 'Weighted regions\xa0', 'Shortest path\xa0', 'Refinement\xa0']"
history,"['2018-02-16', '2015-08-13', '2018-02-06']"
abstract,"Abstract In this paper, we study the weighted region problem (WRP) which is to compute a shortest path in a weighted partitioning of a plane. Recent results show that WRP is not solvable in any algebraic computation model over the rational numbers. Therefore, it is unlikely that WRP can be solved in polynomial time. Research has thus focused on determining approximate solutions for WRP. Approximate solutions for WRP typically show qualitatively different behaviors. We first formulate two qualitative criteria for weighted shortest paths. Then, we show how to produce a path that is quantitatively close-to-optimal and qualitatively satisfactory. More precisely, we propose an algorithm to transform any given approximate linear path into a linear path with the same (or shorter) weighted length for which we can prove that it satisfies the required qualitative criteria. This algorithm has a linear time complexity in the size of the given path. At the end, we explain our experiments on some triangular irregular networks (TINs) from Earth’s terrain. The results show that using the proposed algorithm, on average, 51% in query time and 69% in memory usage could be saved, in comparison with the existing method."
journal_title,Algorithmica
article_title,Self-Stabilizing Balls and Bins in Batches
keyword,"['Balls-into-bins\xa0', 'Self-stabilizing\xa0', '2-Choice\xa0', 'Positive recurrent\xa0', 'Maximum load\xa0']"
history,"['2018-02-15', '2016-08-29', '2018-01-24']"
abstract,"Abstract A fundamental problem in distributed computing is the distribution of requests to a set of uniform servers without a centralized controller. Classically, such problems are modeled as static balls into bins processes, where m balls (tasks) are to be distributed among n bins (servers). In a seminal work, Azar et al. (SIAM J Comput 29(1):180–200, 1999.  https://doi.org/10.1137/S0097539795288490) proposed the sequential strategy \(\textsc {Greedy}[{d}]\) for \(n=m\). Each ball queries the load of d random bins and is allocated to a least loaded of them. Azar et al. 
(1999) showed that \(d=2\) yields an exponential improvement compared to \(d=1\). Berenbrink et al. (SIAM J Comput 35(6):1350–1385, 2006.  https://doi.org/10.1137/S009753970444435X) extended this to \(m\gg n\), showing that for \(d=2\) the maximal load difference is independent of m (in contrast to the \(d=1\) case). We propose a new variant of an infinite balls-into-bins process. In each round an expected number of \(\lambda n\) new balls arrive and are distributed (in parallel) to the bins. Subsequently, each non-empty bin deletes one of its balls. This setting models a set of servers processing incoming requests, where clients can query a server’s current load but receive no information about parallel requests. We study the \(\textsc {Greedy}[{d}]\) distribution scheme in this setting and show a strong self-stabilizing property: for any arrival rate \(\lambda =\lambda (n)<1\), the system load is time-invariant. Moreover, for any (even super-exponential) round t, the maximum system load is (w.h.p.)  Open image in new window  for \(d=1\) and  Open image in new window  for \(d=2\). In particular, \(\textsc {Greedy}[{2}]\) has an exponentially smaller system load for high arrival rates."
journal_title,Algorithmica
article_title,Quasimetric Embeddings and Their Applications
keyword,"['Metric embeddings\xa0', 'Quasimetrics\xa0', 'Outliers\xa0', 'Random embeddings\xa0', 'Treewidth\xa0', 'Directed Sparsest-Cut\xa0', 'Directed Multicut\xa0']"
history,"['2018-02-13', '2016-07-08', '2018-02-06']"
abstract,"Abstract We study generalizations of classical metric embedding results to the case of quasimetric spaces; that is, spaces that do not necessarily satisfy symmetry. Quasimetric spaces arise naturally from the shortest-path distances on directed graphs. Perhaps surprisingly, very little is known about low-distortion embeddings for quasimetric spaces.Random embeddings into ultrametric spaces are arguably one of the most successful geometric tools in the context of algorithm design. We extend this to the quasimetric case as follows. We show that any n-point quasimetric space supported on a graph of treewidth t admits a random embedding into quasiultrametric spaces with distortion \(O(t \log ^2 n)\), where quasiultrametrics are a natural generalization of ultrametrics. This result allows us to obtain \(t\log ^{O(1)} n\)-approximation algorithms for the Directed Non-Bipartite Sparsest Cut and the Directed Multicut problems on n-vertex graphs of treewidth t, with running time polynomial in both n and t. The above results are obtained by considering a generalization of random partitions to the quasimetric case, which we refer to as random quasipartitions. Using this definition and a construction of Chuzhoy and Khanna (JACM 56(2):6, 2009) we derive a polynomial lower bound on the distortion of random embeddings of general quasimetric spaces into quasiultrametric spaces. Finally, we establish a lower bound for embedding the shortest-path quasimetric of a graph G into graphs that exclude G as a minor. This lower bound is used to show that several embedding results from the metric case do not have natural analogues in the quasimetric setting."
journal_title,Algorithmica
article_title,Preface to Special Issue Dedicated to the 60th Birthday of Gregory Gutin
keyword,[]
history,['2018-02-12']
abstract,None
journal_title,Algorithmica
article_title,Not-All-Equal and 1-in-Degree Decompositions: Algorithmic Complexity and Applications
keyword,"['Not-All-Equal decomposition\xa0', '1-in-Degree decomposition\xa0', 'Total perfect dominating set\xa0', 'Zero-sum flow\xa0', 'Zero-sum vertex flow\xa0', '68Q17\xa0', '68R10\xa0', '05C20\xa0']"
history,"['2018-02-07', '2015-08-05', '2018-01-27']"
abstract,"Abstract A Not-All-Equal decomposition of a graph G is a decomposition of the vertices of G into two parts such that each vertex in G has at least one neighbor in each part. Also, a 1-in-Degree decomposition of a graph G is a decomposition of the vertices of G into two parts A and B such that each vertex in the graph G has exactly one neighbor in part A. Among our results, we show that for a given graph G, if G does not have any cycle of length congruent to 2 mod 4, then there is a polynomial time algorithm to decide whether G has a 1-in-Degree decomposition. In sharp contrast, we prove that for every r, \(r\ge 3\), for a given r-regular bipartite graph G determining whether G has a 1-in-Degree decomposition is \( \mathbf {NP} \)-complete. These complexity results have been especially useful in proving \( \mathbf {NP} \)-completeness of various graph related problems for restricted classes of graphs. In consequence of these results we show that for a given bipartite 3-regular graph G determining whether there is a vector in the null-space of the 0,1-adjacency matrix of G such that its entries belong to \(\{ \pm \, 1,\pm \,2\}\) is \(\mathbf {NP} \)-complete. Among other results, we introduce a new version of Planar 1-in-3 SAT and we prove that this version is also \( \mathbf {NP} \)-complete. In consequence of this result, we show that for a given planar (3, 4)-semiregular graph G determining whether there is a vector in the null-space of the 0,1-incidence matrix of G such that its entries belong to \(\{ \pm \,1,\pm \,2\}\) is \(\mathbf {NP} \)-complete."
journal_title,Algorithmica
article_title,Dynamic Path Queries in Linear Space
keyword,"['Dynamic data structures\xa0', 'Path queries\xa0', 'Fractional cascading\xa0', 'Directed topology trees\xa0']"
history,"['2018-02-02', '2016-08-27', '2018-01-27']"
abstract,"Abstract In the path reporting problem, we preprocess a tree on n nodes each of which is assigned a weight, such that given an arbitrary path and a weight range, we can report the nodes whose weights are within the range. We consider this problem in dynamic settings, and propose the first non-trivial linear-space solution that supports path reporting in \(O((\lg n{/}\lg \lg n)^2 + occ \lg n{/}\lg \lg n)\) time, where occ is the output size, and the insertion and deletion of a node of an arbitrary degree in \(O(\lg ^{2+\epsilon } n)\) amortized time, for any constant \(\epsilon \in (0, 1)\). Obvious solutions based on directly dynamizing solutions to the static version of this problem all require \(\Omega ((\lg n{/}\lg \lg n)^2)\) time for each node reported, and thus our query time is much faster. We also design data structures that support path counting and path reporting queries in \(O((\lg n{/}\lg \lg n)^2)\) time, and insertions and deletions in \(O((\lg n{/}\lg \lg n)^2)\) amortized time. This matches the best known results for dynamic two-dimensional range counting (He and Munro in Comput Geom 47(2):268–281, 2014) and range selection (He et al., in: Proceedings of the 22nd international symposium on algorithms and computation, ISAAC, Yokohama, Japan, 2011), which can be viewed as special cases of path counting and path selection."
journal_title,Algorithmica
article_title,Solving Problems on Graphs of High Rank-Width
keyword,"['Fixed-parameter algorithms\xa0', 'Rank-width\xa0', 'Monadic second-order logic\xa0', 'Parameterized complexity\xa0']"
history,"['2018-02', '2017-02-13', '2016-05-03', '2017-02-02']"
abstract,"Abstract A modulator in a graph is a vertex set whose deletion places the considered graph into some specified graph class. The cardinality of a modulator to various graph classes has long been used as a structural parameter which can be exploited to obtain fixed-parameter algorithms for a range of hard problems. Here we investigate what happens when a graph contains a modulator which is large but “well-structured” (in the sense of having bounded rank-width). Can such modulators still be exploited to obtain efficient algorithms? And is it even possible to find such modulators efficiently? We first show that the parameters derived from such well-structured modulators are more powerful for fixed-parameter algorithms than the cardinality of modulators and rank-width itself. Then, we develop a fixed-parameter algorithm for finding such well-structured modulators to every graph class which can be characterized by a finite set of forbidden induced subgraphs. We proceed by showing how well-structured modulators can be used to obtain efficient parameterized algorithms for Minimum Vertex Cover and Maximum Clique. Finally, we use the concept of well-structured modulators to develop an algorithmic meta-theorem for deciding problems expressible in monadic second order logic, and prove that this result is tight in the sense that it cannot be generalized to LinEMSO problems."
