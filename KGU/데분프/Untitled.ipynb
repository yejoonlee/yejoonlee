{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = datasets.MNIST('./mnist_data/',\n",
    "                             download=False,\n",
    "                             train=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(), # image to Tensor\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,)) # image, label\n",
    "                             ])) \n",
    "\n",
    "val_dataset = datasets.MNIST(\"./mnist_data/\",\n",
    "                             download=False,\n",
    "                             train=False,\n",
    "                             transform= transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307, ),(0.3081, ))\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                            transforms.Resize((28,28)),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307, ),(0.3081, ))])\n",
    "\n",
    "data = torchvision.datasets.ImageFolder(root = './data2',\n",
    "                                       transform = trans)\n",
    "\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "concate_dataset = torch.utils.data.ConcatDataset([trn_dataset, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trn_loader = torch.utils.data.DataLoader(trn_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                        drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data,\n",
    "#                         batch_size=batch_size,\n",
    "                       shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n"
     ]
    }
   ],
   "source": [
    "# construct model on cuda if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # 항상 torch.nn.Module을 상속받고 시작\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        conv1 = nn.Conv2d(1, 6, 5, 1)  # 6@24*24\n",
    "        # activation ReLU\n",
    "        pool1 = nn.MaxPool2d(2)  # 6@12*12\n",
    "        conv2 = nn.Conv2d(6, 16, 5, 1)  # 16@8*8\n",
    "        # activation ReLU\n",
    "        pool2 = nn.MaxPool2d(2)  # 16@4*4\n",
    "\n",
    "        self.conv_module = nn.Sequential(\n",
    "            conv1,\n",
    "            nn.ReLU(),\n",
    "            pool1,\n",
    "            conv2,\n",
    "            nn.ReLU(),\n",
    "            pool2\n",
    "        )\n",
    "\n",
    "        fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        # activation ReLU\n",
    "        fc2 = nn.Linear(120, 84)\n",
    "        # activation ReLU\n",
    "        fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            nn.ReLU(),\n",
    "            fc2,\n",
    "            nn.ReLU(),\n",
    "            fc3\n",
    "        )\n",
    "\n",
    "        # gpu로 할당\n",
    "        if use_cuda:\n",
    "            self.conv_module = self.conv_module.cuda()\n",
    "            self.fc_module = self.fc_module.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_module(x)  # @16*4*4\n",
    "        # make linear\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]:  # 16, 4, 4\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc_module(out)\n",
    "        return F.softmax(out, dim=1)\n",
    "\n",
    "cnn = CNNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/2 | step: 100/937 | trn loss: 1.9250 | val loss: 1.7268\n",
      "epoch: 1/2 | step: 200/937 | trn loss: 1.6951 | val loss: 1.6463\n",
      "epoch: 1/2 | step: 300/937 | trn loss: 1.6361 | val loss: 1.6092\n",
      "epoch: 1/2 | step: 400/937 | trn loss: 1.6046 | val loss: 1.6119\n",
      "epoch: 1/2 | step: 500/937 | trn loss: 1.6054 | val loss: 1.6010\n",
      "epoch: 1/2 | step: 600/937 | trn loss: 1.6030 | val loss: 1.5941\n",
      "epoch: 1/2 | step: 700/937 | trn loss: 1.5827 | val loss: 1.5296\n",
      "epoch: 1/2 | step: 800/937 | trn loss: 1.5172 | val loss: 1.5014\n",
      "epoch: 1/2 | step: 900/937 | trn loss: 1.5055 | val loss: 1.4960\n",
      "epoch: 2/2 | step: 100/937 | trn loss: 1.5000 | val loss: 1.4912\n",
      "epoch: 2/2 | step: 200/937 | trn loss: 1.4946 | val loss: 1.4941\n",
      "epoch: 2/2 | step: 300/937 | trn loss: 1.4963 | val loss: 1.4905\n",
      "epoch: 2/2 | step: 400/937 | trn loss: 1.4990 | val loss: 1.5065\n",
      "epoch: 2/2 | step: 500/937 | trn loss: 1.4939 | val loss: 1.4914\n",
      "epoch: 2/2 | step: 600/937 | trn loss: 1.4934 | val loss: 1.4834\n",
      "epoch: 2/2 | step: 700/937 | trn loss: 1.4904 | val loss: 1.4894\n",
      "epoch: 2/2 | step: 800/937 | trn loss: 1.4889 | val loss: 1.4864\n",
      "epoch: 2/2 | step: 900/937 | trn loss: 1.4902 | val loss: 1.4856\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# backpropagation method\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "# hyper-parameters\n",
    "num_epochs = 2\n",
    "num_batches = len(trn_loader)\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(trn_loader):\n",
    "        x, label = data\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "            label = label.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        model_output = cnn(x)\n",
    "        # calculate loss\n",
    "        loss = criterion(model_output, label)\n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "\n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del model_output\n",
    "\n",
    "        # 학습과정 출력\n",
    "        if (i + 1) % 100 == 0:  # every 100 mini-batches\n",
    "            with torch.no_grad():  # very very very very important!!!\n",
    "                val_loss = 0.0\n",
    "                for j, val in enumerate(val_loader):\n",
    "                    val_x, val_label = val\n",
    "                    if use_cuda:\n",
    "                        val_x = val_x.cuda()\n",
    "                        val_label = val_label.cuda()\n",
    "                    val_output = cnn(val_x)\n",
    "                    v_loss = criterion(val_output, val_label)\n",
    "                    val_loss += v_loss\n",
    "\n",
    "            print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "                epoch + 1, num_epochs, i + 1, num_batches, trn_loss / 100, val_loss / len(val_loader)\n",
    "            ))\n",
    "\n",
    "            trn_loss_list.append(trn_loss / 100)\n",
    "            val_loss_list.append(val_loss / len(val_loader))\n",
    "            trn_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9761618589743589\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "acc = []\n",
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "#     X_test, Y_test = val_loader\n",
    "    for i, data in enumerate(val_loader):\n",
    "        x_test, Y_test = data\n",
    "\n",
    "        prediction = cnn(x_test)\n",
    "#         print(prediction)\n",
    "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        acc.append(accuracy.item())\n",
    "    print(statistics.mean(acc))\n",
    "#         print('Accuracy%d:'%i, accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ccf171a508b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     X_single_data = val_loader[r:r + 1][0].view(-1, 28 * 28).float().to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_single_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mY_single_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "\n",
    "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
    "    r = random.randint(0, len(val_loader) - 1)\n",
    "#     X_single_data = val_loader[r:r + 1][0].view(-1, 28 * 28).float().to(device)\n",
    "    X_single_data = val_loader[r:r + 1]\n",
    "    Y_single_data = val_loader[r:r + 1][1]\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = cnn(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(x_test[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 6, 7, 3, 2, 1, 8, 3, 0, 4, 2, 6, 9, 2, 9, 4, 2, 4, 2, 9, 7, 0, 4, 6,\n",
      "        9, 0, 2, 7, 3, 4, 4, 5, 5, 2, 2, 5, 9, 5, 0, 4, 4, 3, 6, 3, 8, 5, 1, 7,\n",
      "        8, 3, 1, 4, 9, 0, 2, 2, 7, 8, 2, 8, 9, 3, 9, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b2171b4505e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0msingle_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "#     X_test, Y_test = val_loader\n",
    "#     print('Label: ', Y_test.item())\n",
    "#     single_prediction = cnn(x_test)\n",
    "#     print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    for i, data in enumerate(val_loader):\n",
    "        x_test, Y_test = data\n",
    "        \n",
    "        print(Y_test)\n",
    "\n",
    "\n",
    "        print('Label: ', Y_test.item())\n",
    "        single_prediction = cnn(x_test)\n",
    "        print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  0\n",
      "Prediction:  8\n",
      "Label:  0\n",
      "Prediction:  8\n",
      "Label:  0\n",
      "Prediction:  8\n",
      "Label:  0\n",
      "Prediction:  8\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  5\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  2\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  2\n",
      "Prediction:  8\n",
      "Label:  2\n",
      "Prediction:  8\n",
      "Label:  2\n",
      "Prediction:  8\n",
      "Label:  3\n",
      "Prediction:  8\n",
      "Label:  3\n",
      "Prediction:  8\n",
      "Label:  3\n",
      "Prediction:  5\n",
      "Label:  3\n",
      "Prediction:  5\n",
      "Label:  3\n",
      "Prediction:  8\n",
      "Label:  3\n",
      "Prediction:  5\n",
      "Label:  3\n",
      "Prediction:  8\n",
      "Label:  3\n",
      "Prediction:  5\n",
      "Label:  4\n",
      "Prediction:  8\n",
      "Label:  4\n",
      "Prediction:  4\n",
      "Label:  4\n",
      "Prediction:  4\n",
      "Label:  5\n",
      "Prediction:  5\n",
      "Label:  5\n",
      "Prediction:  8\n",
      "Label:  5\n",
      "Prediction:  5\n",
      "Label:  5\n",
      "Prediction:  8\n",
      "Label:  6\n",
      "Prediction:  8\n",
      "Label:  6\n",
      "Prediction:  8\n",
      "Label:  6\n",
      "Prediction:  8\n",
      "Label:  6\n",
      "Prediction:  8\n",
      "Label:  6\n",
      "Prediction:  8\n",
      "Label:  6\n",
      "Prediction:  8\n",
      "Label:  6\n",
      "Prediction:  8\n",
      "Label:  7\n",
      "Prediction:  8\n",
      "Label:  7\n",
      "Prediction:  8\n",
      "Label:  7\n",
      "Prediction:  8\n",
      "Label:  7\n",
      "Prediction:  8\n",
      "Label:  7\n",
      "Prediction:  8\n",
      "Label:  7\n",
      "Prediction:  9\n",
      "Label:  7\n",
      "Prediction:  8\n",
      "Label:  7\n",
      "Prediction:  8\n",
      "Label:  8\n",
      "Prediction:  8\n",
      "Label:  8\n",
      "Prediction:  8\n",
      "Label:  8\n",
      "Prediction:  8\n",
      "Label:  8\n",
      "Prediction:  8\n",
      "Label:  8\n",
      "Prediction:  8\n",
      "Label:  8\n",
      "Prediction:  2\n",
      "Label:  8\n",
      "Prediction:  8\n",
      "Label:  8\n",
      "Prediction:  8\n",
      "Label:  9\n",
      "Prediction:  3\n",
      "Label:  9\n",
      "Prediction:  3\n",
      "Label:  9\n",
      "Prediction:  3\n",
      "Label:  9\n",
      "Prediction:  8\n",
      "Label:  9\n",
      "Prediction:  8\n",
      "Label:  9\n",
      "Prediction:  8\n",
      "accuracy =  0.15714285714285714\n"
     ]
    }
   ],
   "source": [
    "# prediction = cnn(images)\n",
    "# print(prediction)\n",
    "num_cor = 0\n",
    "num_inc = 0\n",
    "with torch.no_grad():\n",
    "    for data in loader:\n",
    "        x_test, Y_test = data\n",
    "        lab = Y_test.item()\n",
    "        pred = cnn(x_test)\n",
    "        print('Label: ', lab)\n",
    "        print('Prediction: ', torch.argmax(pred, 1).item())\n",
    "        \n",
    "        if lab == torch.argmax(pred, 1).item():\n",
    "            num_cor += 1\n",
    "            continue\n",
    "        \n",
    "        num_inc += 1\n",
    "        \n",
    "print(\"accuracy = \", num_cor/(num_cor+num_inc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
