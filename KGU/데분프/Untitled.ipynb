{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = datasets.MNIST('./mnist_data/',\n",
    "                             download=False,\n",
    "                             train=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(), # image to Tensor\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,)) # image, label\n",
    "                             ]))\n",
    "\n",
    "val_dataset = datasets.MNIST(\"./mnist_data/\",\n",
    "                             download=False,\n",
    "                             train=False,\n",
    "                             transform= transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307, ),(0.3081, ))\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trn_loader = torch.utils.data.DataLoader(trn_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                        drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n"
     ]
    }
   ],
   "source": [
    "# construct model on cuda if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # 항상 torch.nn.Module을 상속받고 시작\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        conv1 = nn.Conv2d(1, 6, 5, 1)  # 6@24*24\n",
    "        # activation ReLU\n",
    "        pool1 = nn.MaxPool2d(2)  # 6@12*12\n",
    "        conv2 = nn.Conv2d(6, 16, 5, 1)  # 16@8*8\n",
    "        # activation ReLU\n",
    "        pool2 = nn.MaxPool2d(2)  # 16@4*4\n",
    "\n",
    "        self.conv_module = nn.Sequential(\n",
    "            conv1,\n",
    "            nn.ReLU(),\n",
    "            pool1,\n",
    "            conv2,\n",
    "            nn.ReLU(),\n",
    "            pool2\n",
    "        )\n",
    "\n",
    "        fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        # activation ReLU\n",
    "        fc2 = nn.Linear(120, 84)\n",
    "        # activation ReLU\n",
    "        fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            nn.ReLU(),\n",
    "            fc2,\n",
    "            nn.ReLU(),\n",
    "            fc3\n",
    "        )\n",
    "\n",
    "        # gpu로 할당\n",
    "        if use_cuda:\n",
    "            self.conv_module = self.conv_module.cuda()\n",
    "            self.fc_module = self.fc_module.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_module(x)  # @16*4*4\n",
    "        # make linear\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]:  # 16, 4, 4\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc_module(out)\n",
    "        return F.softmax(out, dim=1)\n",
    "\n",
    "cnn = CNNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/2 | step: 100/937 | trn loss: 1.9557 | val loss: 1.7077\n",
      "epoch: 1/2 | step: 200/937 | trn loss: 1.6718 | val loss: 1.6285\n",
      "epoch: 1/2 | step: 300/937 | trn loss: 1.6259 | val loss: 1.5721\n",
      "epoch: 1/2 | step: 400/937 | trn loss: 1.5610 | val loss: 1.5335\n",
      "epoch: 1/2 | step: 500/937 | trn loss: 1.5325 | val loss: 1.5341\n",
      "epoch: 1/2 | step: 600/937 | trn loss: 1.5187 | val loss: 1.5210\n",
      "epoch: 1/2 | step: 700/937 | trn loss: 1.5142 | val loss: 1.5113\n",
      "epoch: 1/2 | step: 800/937 | trn loss: 1.5127 | val loss: 1.5038\n",
      "epoch: 1/2 | step: 900/937 | trn loss: 1.5059 | val loss: 1.4984\n",
      "epoch: 2/2 | step: 100/937 | trn loss: 1.5001 | val loss: 1.4917\n",
      "epoch: 2/2 | step: 200/937 | trn loss: 1.4997 | val loss: 1.4917\n",
      "epoch: 2/2 | step: 300/937 | trn loss: 1.4982 | val loss: 1.4914\n",
      "epoch: 2/2 | step: 400/937 | trn loss: 1.4950 | val loss: 1.4873\n",
      "epoch: 2/2 | step: 500/937 | trn loss: 1.4908 | val loss: 1.4957\n",
      "epoch: 2/2 | step: 600/937 | trn loss: 1.4932 | val loss: 1.4961\n",
      "epoch: 2/2 | step: 700/937 | trn loss: 1.4916 | val loss: 1.4926\n",
      "epoch: 2/2 | step: 800/937 | trn loss: 1.4886 | val loss: 1.4895\n",
      "epoch: 2/2 | step: 900/937 | trn loss: 1.4944 | val loss: 1.4889\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# backpropagation method\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "# hyper-parameters\n",
    "num_epochs = 2\n",
    "num_batches = len(trn_loader)\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(trn_loader):\n",
    "        x, label = data\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "            label = label.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        model_output = cnn(x)\n",
    "        # calculate loss\n",
    "        loss = criterion(model_output, label)\n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "\n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del model_output\n",
    "\n",
    "        # 학습과정 출력\n",
    "        if (i + 1) % 100 == 0:  # every 100 mini-batches\n",
    "            with torch.no_grad():  # very very very very important!!!\n",
    "                val_loss = 0.0\n",
    "                for j, val in enumerate(val_loader):\n",
    "                    val_x, val_label = val\n",
    "                    if use_cuda:\n",
    "                        val_x = val_x.cuda()\n",
    "                        val_label = val_label.cuda()\n",
    "                    val_output = cnn(val_x)\n",
    "                    v_loss = criterion(val_output, val_label)\n",
    "                    val_loss += v_loss\n",
    "\n",
    "            print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "                epoch + 1, num_epochs, i + 1, num_batches, trn_loss / 100, val_loss / len(val_loader)\n",
    "            ))\n",
    "\n",
    "            trn_loss_list.append(trn_loss / 100)\n",
    "            val_loss_list.append(val_loss / len(val_loader))\n",
    "            trn_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "#     X_test, Y_test = val_loader\n",
    "    for i, data in enumerate(val_loader):\n",
    "        x_test, Y_test = data\n",
    "\n",
    "        prediction = cnn(x_test)\n",
    "        print(prediction)\n",
    "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "\n",
    "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
    "    r = random.randint(0, len(val_loader) - 1)\n",
    "    X_single_data = val_loader[r:r + 1][0].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = val_loader[r:r + 1][1]\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = cnn(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(x_test[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                            transforms.Resize((28,28)),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307, ),(0.3081, ))])\n",
    "\n",
    "data = torchvision.datasets.ImageFolder(root = './data',\n",
    "                                       transform = trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(data,\n",
    "                   shuffle = False)\n",
    "\n",
    "dataiter = iter(loader)\n",
    "images, labels = dataiter.next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  0\n",
      "Prediction:  8\n",
      "Label:  0\n",
      "Prediction:  8\n",
      "Label:  0\n",
      "Prediction:  0\n",
      "Label:  1\n",
      "Prediction:  8\n",
      "Label:  1\n",
      "Prediction:  8\n",
      "Label:  1\n",
      "Prediction:  0\n",
      "Label:  2\n",
      "Prediction:  2\n",
      "Label:  2\n",
      "Prediction:  2\n",
      "Label:  2\n",
      "Prediction:  8\n",
      "Label:  3\n",
      "Prediction:  8\n",
      "Label:  3\n",
      "Prediction:  2\n",
      "Label:  3\n",
      "Prediction:  8\n",
      "Label:  4\n",
      "Prediction:  5\n",
      "Label:  4\n",
      "Prediction:  3\n",
      "Label:  4\n",
      "Prediction:  0\n",
      "Label:  5\n",
      "Prediction:  5\n",
      "Label:  5\n",
      "Prediction:  8\n",
      "Label:  5\n",
      "Prediction:  5\n",
      "Label:  6\n",
      "Prediction:  5\n",
      "Label:  6\n",
      "Prediction:  8\n",
      "Label:  6\n",
      "Prediction:  0\n",
      "Label:  7\n",
      "Prediction:  0\n",
      "Label:  7\n",
      "Prediction:  2\n",
      "Label:  7\n",
      "Prediction:  8\n",
      "Label:  8\n",
      "Prediction:  8\n",
      "Label:  8\n",
      "Prediction:  2\n",
      "Label:  8\n",
      "Prediction:  5\n",
      "Label:  9\n",
      "Prediction:  0\n",
      "Label:  9\n",
      "Prediction:  3\n",
      "Label:  9\n",
      "Prediction:  0\n"
     ]
    }
   ],
   "source": [
    "# prediction = cnn(images)\n",
    "# print(prediction)\n",
    "\n",
    "for data in loader:\n",
    "    x_test, Y_test = data\n",
    "    \n",
    "    print('Label: ', Y_test.item())\n",
    "    single_prediction = cnn(x_test)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
