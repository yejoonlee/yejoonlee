{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = datasets.MNIST('./mnist_data/',\n",
    "                             download=False,\n",
    "                             train=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(), # image to Tensor\n",
    "                                 transforms.Normalize((0.1307,), (0.3081,)) # image, label\n",
    "                             ])) \n",
    "\n",
    "val_dataset = datasets.MNIST(\"./mnist_data/\",\n",
    "                             download=False,\n",
    "                             train=False,\n",
    "                             transform= transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307, ),(0.3081, ))\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                            transforms.Resize((28,28)),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307, ),(0.3081, ))])\n",
    "\n",
    "data = torchvision.datasets.ImageFolder(root = './data2',\n",
    "                                       transform = trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "concate_dataset = torch.utils.data.ConcatDataset([trn_dataset, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trn_loader = torch.utils.data.DataLoader(concate_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                        drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data,\n",
    "                        batch_size=batch_size,\n",
    "                       shuffle = False,\n",
    "                       drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n"
     ]
    }
   ],
   "source": [
    "# construct model on cuda if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # 항상 torch.nn.Module을 상속받고 시작\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        conv1 = nn.Conv2d(1, 6, 5, 1)  # 6@24*24\n",
    "        # activation ReLU\n",
    "        pool1 = nn.MaxPool2d(2)  # 6@12*12\n",
    "        conv2 = nn.Conv2d(6, 16, 5, 1)  # 16@8*8\n",
    "        # activation ReLU\n",
    "        pool2 = nn.MaxPool2d(2)  # 16@4*4\n",
    "\n",
    "        self.conv_module = nn.Sequential(\n",
    "            conv1,\n",
    "            nn.ReLU(),\n",
    "            pool1,\n",
    "            conv2,\n",
    "            nn.ReLU(),\n",
    "            pool2\n",
    "        )\n",
    "\n",
    "        fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        # activation ReLU\n",
    "        fc2 = nn.Linear(120, 84)\n",
    "        # activation ReLU\n",
    "        fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        self.fc_module = nn.Sequential(\n",
    "            fc1,\n",
    "            nn.ReLU(),\n",
    "            fc2,\n",
    "            nn.ReLU(),\n",
    "            fc3\n",
    "        )\n",
    "\n",
    "        # gpu로 할당\n",
    "        if use_cuda:\n",
    "            self.conv_module = self.conv_module.cuda()\n",
    "            self.fc_module = self.fc_module.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_module(x)  # @16*4*4\n",
    "        # make linear\n",
    "        dim = 1\n",
    "        for d in out.size()[1:]:  # 16, 4, 4\n",
    "            dim = dim * d\n",
    "        out = out.view(-1, dim)\n",
    "        out = self.fc_module(out)\n",
    "        return F.softmax(out, dim=1)\n",
    "\n",
    "cnn = CNNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/2 | step: 100/973 | trn loss: 1.9778 | val loss: 1.8004\n",
      "epoch: 1/2 | step: 200/973 | trn loss: 1.8167 | val loss: 1.7792\n",
      "epoch: 1/2 | step: 300/973 | trn loss: 1.8008 | val loss: 1.7726\n",
      "epoch: 1/2 | step: 400/973 | trn loss: 1.6347 | val loss: 1.5367\n",
      "epoch: 1/2 | step: 500/973 | trn loss: 1.5493 | val loss: 1.5147\n",
      "epoch: 1/2 | step: 600/973 | trn loss: 1.5360 | val loss: 1.5104\n",
      "epoch: 1/2 | step: 700/973 | trn loss: 1.5252 | val loss: 1.5043\n",
      "epoch: 1/2 | step: 800/973 | trn loss: 1.5184 | val loss: 1.4970\n",
      "epoch: 1/2 | step: 900/973 | trn loss: 1.5182 | val loss: 1.5056\n",
      "epoch: 2/2 | step: 100/973 | trn loss: 1.5093 | val loss: 1.4932\n",
      "epoch: 2/2 | step: 200/973 | trn loss: 1.5098 | val loss: 1.4947\n",
      "epoch: 2/2 | step: 300/973 | trn loss: 1.5009 | val loss: 1.4926\n",
      "epoch: 2/2 | step: 400/973 | trn loss: 1.4986 | val loss: 1.4937\n",
      "epoch: 2/2 | step: 500/973 | trn loss: 1.5050 | val loss: 1.4871\n",
      "epoch: 2/2 | step: 600/973 | trn loss: 1.5010 | val loss: 1.4857\n",
      "epoch: 2/2 | step: 700/973 | trn loss: 1.5023 | val loss: 1.4850\n",
      "epoch: 2/2 | step: 800/973 | trn loss: 1.5001 | val loss: 1.4920\n",
      "epoch: 2/2 | step: 900/973 | trn loss: 1.4959 | val loss: 1.4847\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# backpropagation method\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "# hyper-parameters\n",
    "num_epochs = 2\n",
    "num_batches = len(trn_loader)\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(trn_loader):\n",
    "        x, label = data\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "            label = label.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        model_output = cnn(x)\n",
    "        # calculate loss\n",
    "        loss = criterion(model_output, label)\n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "\n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del model_output\n",
    "\n",
    "        # 학습과정 출력\n",
    "        if (i + 1) % 100 == 0:  # every 100 mini-batches\n",
    "            with torch.no_grad():  # very very very very important!!!\n",
    "                val_loss = 0.0\n",
    "                for j, val in enumerate(val_loader):\n",
    "                    val_x, val_label = val\n",
    "                    if use_cuda:\n",
    "                        val_x = val_x.cuda()\n",
    "                        val_label = val_label.cuda()\n",
    "                    val_output = cnn(val_x)\n",
    "                    v_loss = criterion(val_output, val_label)\n",
    "                    val_loss += v_loss\n",
    "\n",
    "            print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "                epoch + 1, num_epochs, i + 1, num_batches, trn_loss / 100, val_loss / len(val_loader)\n",
    "            ))\n",
    "\n",
    "            trn_loss_list.append(trn_loss / 100)\n",
    "            val_loss_list.append(val_loss / len(val_loader))\n",
    "            trn_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0: 0.96875\n",
      "Accuracy1: 0.96875\n",
      "Accuracy2: 0.984375\n",
      "Accuracy3: 0.9375\n",
      "Accuracy4: 0.984375\n",
      "Accuracy5: 1.0\n",
      "Accuracy6: 0.984375\n",
      "Accuracy7: 0.984375\n",
      "Accuracy8: 1.0\n",
      "Accuracy9: 0.984375\n",
      "Accuracy10: 1.0\n",
      "Accuracy11: 0.9375\n",
      "Accuracy12: 0.96875\n",
      "Accuracy13: 0.96875\n",
      "Accuracy14: 0.96875\n",
      "Accuracy15: 0.984375\n",
      "Accuracy16: 0.921875\n",
      "Accuracy17: 0.96875\n",
      "Accuracy18: 0.9375\n",
      "Accuracy19: 0.984375\n",
      "Accuracy20: 0.984375\n",
      "Accuracy21: 1.0\n",
      "Accuracy22: 0.921875\n",
      "Accuracy23: 0.96875\n",
      "Accuracy24: 1.0\n",
      "Accuracy25: 0.984375\n",
      "Accuracy26: 0.984375\n",
      "Accuracy27: 0.953125\n",
      "Accuracy28: 0.953125\n",
      "Accuracy29: 0.984375\n",
      "Accuracy30: 0.984375\n",
      "Accuracy31: 0.984375\n",
      "Accuracy32: 1.0\n",
      "Accuracy33: 0.953125\n",
      "Accuracy34: 0.984375\n",
      "Accuracy35: 0.96875\n",
      "Accuracy36: 0.984375\n",
      "Accuracy37: 1.0\n",
      "Accuracy38: 0.953125\n",
      "Accuracy39: 0.953125\n",
      "Accuracy40: 0.984375\n",
      "Accuracy41: 0.984375\n",
      "Accuracy42: 1.0\n",
      "Accuracy43: 1.0\n",
      "Accuracy44: 0.984375\n",
      "Accuracy45: 0.984375\n",
      "Accuracy46: 0.96875\n",
      "Accuracy47: 0.96875\n",
      "Accuracy48: 1.0\n",
      "Accuracy49: 0.953125\n",
      "Accuracy50: 0.984375\n",
      "Accuracy51: 0.96875\n",
      "Accuracy52: 0.96875\n",
      "Accuracy53: 0.984375\n",
      "Accuracy54: 0.984375\n",
      "Accuracy55: 0.96875\n",
      "Accuracy56: 0.953125\n",
      "Accuracy57: 0.96875\n",
      "Accuracy58: 0.984375\n",
      "Accuracy59: 0.984375\n",
      "Accuracy60: 0.984375\n",
      "Accuracy61: 0.953125\n",
      "Accuracy62: 0.984375\n",
      "Accuracy63: 0.984375\n",
      "Accuracy64: 0.96875\n",
      "Accuracy65: 0.984375\n",
      "Accuracy66: 0.9375\n",
      "Accuracy67: 0.96875\n",
      "Accuracy68: 0.984375\n",
      "Accuracy69: 0.96875\n",
      "Accuracy70: 0.9375\n",
      "Accuracy71: 0.9375\n",
      "Accuracy72: 0.984375\n",
      "Accuracy73: 0.96875\n",
      "Accuracy74: 1.0\n",
      "Accuracy75: 0.96875\n",
      "Accuracy76: 0.96875\n",
      "Accuracy77: 0.9375\n",
      "Accuracy78: 1.0\n",
      "Accuracy79: 1.0\n",
      "Accuracy80: 0.953125\n",
      "Accuracy81: 1.0\n",
      "Accuracy82: 1.0\n",
      "Accuracy83: 0.984375\n",
      "Accuracy84: 0.984375\n",
      "Accuracy85: 0.96875\n",
      "Accuracy86: 0.984375\n",
      "Accuracy87: 0.953125\n",
      "Accuracy88: 1.0\n",
      "Accuracy89: 0.96875\n",
      "Accuracy90: 1.0\n",
      "Accuracy91: 0.96875\n",
      "Accuracy92: 1.0\n",
      "Accuracy93: 1.0\n",
      "Accuracy94: 0.953125\n",
      "Accuracy95: 0.984375\n",
      "Accuracy96: 1.0\n",
      "Accuracy97: 1.0\n",
      "Accuracy98: 0.96875\n",
      "Accuracy99: 1.0\n",
      "Accuracy100: 0.953125\n",
      "Accuracy101: 0.953125\n",
      "Accuracy102: 1.0\n",
      "Accuracy103: 0.96875\n",
      "Accuracy104: 0.96875\n",
      "Accuracy105: 0.96875\n",
      "Accuracy106: 0.953125\n",
      "Accuracy107: 0.984375\n",
      "Accuracy108: 0.953125\n",
      "Accuracy109: 0.9375\n",
      "Accuracy110: 0.953125\n",
      "Accuracy111: 0.984375\n",
      "Accuracy112: 0.953125\n",
      "Accuracy113: 1.0\n",
      "Accuracy114: 0.96875\n",
      "Accuracy115: 0.953125\n",
      "Accuracy116: 1.0\n",
      "Accuracy117: 0.984375\n",
      "Accuracy118: 0.984375\n",
      "Accuracy119: 0.984375\n",
      "Accuracy120: 0.984375\n",
      "Accuracy121: 0.953125\n",
      "Accuracy122: 1.0\n",
      "Accuracy123: 0.984375\n",
      "Accuracy124: 0.96875\n",
      "Accuracy125: 0.96875\n",
      "Accuracy126: 0.953125\n",
      "Accuracy127: 0.921875\n",
      "Accuracy128: 0.96875\n",
      "Accuracy129: 0.984375\n",
      "Accuracy130: 0.96875\n",
      "Accuracy131: 0.984375\n",
      "Accuracy132: 0.96875\n",
      "Accuracy133: 0.984375\n",
      "Accuracy134: 0.9375\n",
      "Accuracy135: 1.0\n",
      "Accuracy136: 0.953125\n",
      "Accuracy137: 1.0\n",
      "Accuracy138: 0.96875\n",
      "Accuracy139: 0.953125\n",
      "Accuracy140: 0.984375\n",
      "Accuracy141: 0.96875\n",
      "Accuracy142: 0.96875\n",
      "Accuracy143: 1.0\n",
      "Accuracy144: 0.984375\n",
      "Accuracy145: 0.984375\n",
      "Accuracy146: 1.0\n",
      "Accuracy147: 0.9375\n",
      "Accuracy148: 1.0\n",
      "Accuracy149: 0.984375\n",
      "Accuracy150: 1.0\n",
      "Accuracy151: 0.984375\n",
      "Accuracy152: 1.0\n",
      "Accuracy153: 0.96875\n",
      "Accuracy154: 0.9375\n",
      "Accuracy155: 0.9375\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "#     X_test, Y_test = val_loader\n",
    "    for i, data in enumerate(val_loader):\n",
    "        x_test, Y_test = data\n",
    "\n",
    "        prediction = cnn(x_test)\n",
    "#         print(prediction)\n",
    "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        print('Accuracy%d:'%i, accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ccf171a508b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     X_single_data = val_loader[r:r + 1][0].view(-1, 28 * 28).float().to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_single_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mY_single_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "\n",
    "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
    "    r = random.randint(0, len(val_loader) - 1)\n",
    "#     X_single_data = val_loader[r:r + 1][0].view(-1, 28 * 28).float().to(device)\n",
    "    X_single_data = val_loader[r:r + 1]\n",
    "    Y_single_data = val_loader[r:r + 1][1]\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = cnn(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(x_test[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e252a41375d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msingle_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "#     X_test, Y_test = val_loader\n",
    "    for i, data in enumerate(val_loader):\n",
    "        x_test, Y_test = data\n",
    "\n",
    "        print('Label: ', Y_test.item())\n",
    "        single_prediction = cnn(x_test)\n",
    "        print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = cnn(images)\n",
    "# print(prediction)\n",
    "with torch.no_grad():\n",
    "    for data in loader:\n",
    "        x_test, Y_test = data\n",
    "\n",
    "        print('Label: ', Y_test.item())\n",
    "        single_prediction = cnn(x_test)\n",
    "        print('Prediction: ', torch.argmax(single_prediction, 1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
